reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 1
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 1
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1918943-172.17.0.11-1597379304032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38146,DS-304ce45d-887f-42d4-a9ea-4ca836ab6c28,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-c13ee379-5184-4ba5-805d-d6b4c12b4868,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-7e5f58c0-8b9d-4dae-8c79-0d957b252e55,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-196b50b2-ca71-434d-9332-110a22da8734,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-e705cf3c-fc6e-4190-8ac3-08c259f9f94e,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-d17a3d29-b50c-4e1f-8210-0148caf3d10b,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-d7c750cc-b288-4c19-b0ff-2081e13acd11,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-fddb6c26-d7a5-4ab8-8ec8-cb6a631b5dbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1918943-172.17.0.11-1597379304032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38146,DS-304ce45d-887f-42d4-a9ea-4ca836ab6c28,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-c13ee379-5184-4ba5-805d-d6b4c12b4868,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-7e5f58c0-8b9d-4dae-8c79-0d957b252e55,DISK], DatanodeInfoWithStorage[127.0.0.1:41311,DS-196b50b2-ca71-434d-9332-110a22da8734,DISK], DatanodeInfoWithStorage[127.0.0.1:45563,DS-e705cf3c-fc6e-4190-8ac3-08c259f9f94e,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-d17a3d29-b50c-4e1f-8210-0148caf3d10b,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-d7c750cc-b288-4c19-b0ff-2081e13acd11,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-fddb6c26-d7a5-4ab8-8ec8-cb6a631b5dbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 1
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1216156060-172.17.0.11-1597379712533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38722,DS-62d194c0-dc99-4fab-a162-dc67660a8bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-87af73d1-15b0-4b1b-84bf-f373e82c142d,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-b6972219-e402-4926-8665-2235462ee808,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-16717b08-efdd-4a39-bfbb-b71a6082ccf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-ca538bc2-5802-4ae1-868a-8a478bb41260,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-b22ee95e-6f1a-4dad-8530-4bea8b63c314,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-fad80ddb-ea89-479c-bc20-c2066d797ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-2f4b95b9-075d-4bd5-bbc9-fce107d15908,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1216156060-172.17.0.11-1597379712533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38722,DS-62d194c0-dc99-4fab-a162-dc67660a8bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-87af73d1-15b0-4b1b-84bf-f373e82c142d,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-b6972219-e402-4926-8665-2235462ee808,DISK], DatanodeInfoWithStorage[127.0.0.1:33723,DS-16717b08-efdd-4a39-bfbb-b71a6082ccf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-ca538bc2-5802-4ae1-868a-8a478bb41260,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-b22ee95e-6f1a-4dad-8530-4bea8b63c314,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-fad80ddb-ea89-479c-bc20-c2066d797ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-2f4b95b9-075d-4bd5-bbc9-fce107d15908,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 1
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-125307963-172.17.0.11-1597379782839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33857,DS-fcae1371-5b2e-4761-b1cd-bfeab6021de6,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-4c543117-737e-42c5-a2e2-85dcee80b007,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-1bed9275-e322-4c42-bff3-066c7b8c364c,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-73ba11b0-0fa8-4185-8c4c-97c6264aa8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-24116b4c-94d8-470c-b512-e7ea59f1d361,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-96d5d278-f807-435a-ae9d-14b67c0fa365,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-987e95b7-bf8d-409d-84be-9f99238031ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46671,DS-b2e64fcd-e19b-4c2d-a4f8-438c47369046,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-125307963-172.17.0.11-1597379782839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33857,DS-fcae1371-5b2e-4761-b1cd-bfeab6021de6,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-4c543117-737e-42c5-a2e2-85dcee80b007,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-1bed9275-e322-4c42-bff3-066c7b8c364c,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-73ba11b0-0fa8-4185-8c4c-97c6264aa8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-24116b4c-94d8-470c-b512-e7ea59f1d361,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-96d5d278-f807-435a-ae9d-14b67c0fa365,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-987e95b7-bf8d-409d-84be-9f99238031ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46671,DS-b2e64fcd-e19b-4c2d-a4f8-438c47369046,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 1
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-485400936-172.17.0.11-1597380543432:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41771,DS-3afef0b7-b384-4254-8120-38c447affaf9,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-3dec84a0-8a47-4edd-8683-511c321362e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-c638a80c-ddb2-4051-82a1-e99808218653,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-23a9dbe0-7e7c-42be-a45a-c8d12aee8d47,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-9a34a04c-e2d7-4615-8249-b70eb54fa7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-eaec4183-f838-4518-8e10-6c8e69e28052,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-cd6bafb8-3d3d-4521-a4f5-5bc6a21306e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-084abbc3-5d2f-440b-ae7f-1ce2047773ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-485400936-172.17.0.11-1597380543432:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41771,DS-3afef0b7-b384-4254-8120-38c447affaf9,DISK], DatanodeInfoWithStorage[127.0.0.1:41595,DS-3dec84a0-8a47-4edd-8683-511c321362e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-c638a80c-ddb2-4051-82a1-e99808218653,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-23a9dbe0-7e7c-42be-a45a-c8d12aee8d47,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-9a34a04c-e2d7-4615-8249-b70eb54fa7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36341,DS-eaec4183-f838-4518-8e10-6c8e69e28052,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-cd6bafb8-3d3d-4521-a4f5-5bc6a21306e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-084abbc3-5d2f-440b-ae7f-1ce2047773ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 1
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1334691395-172.17.0.11-1597380917881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34431,DS-874725fa-2415-4897-9ff3-5ec414645c10,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-facc9713-4a1c-4841-bc16-1662f822493a,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-f5f3f4aa-0f96-4964-b35f-3830f1477aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-1414e2a2-fd71-4b37-850b-a78d356e26a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-73f095e5-a90b-491e-92a8-60a8984e91ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-94f6221c-442e-4967-9c7f-5f355757dd35,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-b4dccb6a-9acb-4ada-8535-86adeda8a912,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-9fa865d8-e58f-4546-b1bd-77d9471b5df7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1334691395-172.17.0.11-1597380917881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34431,DS-874725fa-2415-4897-9ff3-5ec414645c10,DISK], DatanodeInfoWithStorage[127.0.0.1:46817,DS-facc9713-4a1c-4841-bc16-1662f822493a,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-f5f3f4aa-0f96-4964-b35f-3830f1477aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:39818,DS-1414e2a2-fd71-4b37-850b-a78d356e26a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-73f095e5-a90b-491e-92a8-60a8984e91ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-94f6221c-442e-4967-9c7f-5f355757dd35,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-b4dccb6a-9acb-4ada-8535-86adeda8a912,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-9fa865d8-e58f-4546-b1bd-77d9471b5df7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 1
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1077955773-172.17.0.11-1597381372980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45401,DS-080c0232-980e-4511-a8b9-bca0120080b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-2c539093-8e6c-4de1-9010-3f98220c4c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-edf6338d-1a21-45c3-a232-7b7d5613008e,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-99df99ac-1541-424e-b473-c495b0d6310c,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-86bd49b5-e788-472b-a238-74cf4b42952a,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-e70f4ad2-416a-4954-95e2-5eafa9777b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-c0cb411d-20cb-4cac-8152-5272be3ee295,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-c21346e0-a466-40e8-982a-9be8f927a7ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1077955773-172.17.0.11-1597381372980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45401,DS-080c0232-980e-4511-a8b9-bca0120080b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-2c539093-8e6c-4de1-9010-3f98220c4c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-edf6338d-1a21-45c3-a232-7b7d5613008e,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-99df99ac-1541-424e-b473-c495b0d6310c,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-86bd49b5-e788-472b-a238-74cf4b42952a,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-e70f4ad2-416a-4954-95e2-5eafa9777b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-c0cb411d-20cb-4cac-8152-5272be3ee295,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-c21346e0-a466-40e8-982a-9be8f927a7ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 1
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1328584456-172.17.0.11-1597383037637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42060,DS-c3551d0b-d3b4-4650-b8b5-ae956ff61c51,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-5fa225de-0b1e-4d33-ab33-9d20a7eac7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-0d49e54d-23bf-4e98-8ddb-0f324dd2d201,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-d6d9356b-1abe-4623-a064-64d00db8c041,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-59b6d5df-e807-4f52-94a8-02d37638db70,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-95101de1-2d68-41bc-8c91-3e595dffa0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-1ce5b67b-5a83-410e-84f6-00d644bb2e46,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-91937495-282a-4973-8cf0-01389f389413,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1328584456-172.17.0.11-1597383037637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42060,DS-c3551d0b-d3b4-4650-b8b5-ae956ff61c51,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-5fa225de-0b1e-4d33-ab33-9d20a7eac7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-0d49e54d-23bf-4e98-8ddb-0f324dd2d201,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-d6d9356b-1abe-4623-a064-64d00db8c041,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-59b6d5df-e807-4f52-94a8-02d37638db70,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-95101de1-2d68-41bc-8c91-3e595dffa0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-1ce5b67b-5a83-410e-84f6-00d644bb2e46,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-91937495-282a-4973-8cf0-01389f389413,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 1
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-84437098-172.17.0.11-1597383115379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44728,DS-eb577051-e7bc-46a5-abe7-a478b8475c33,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-a47779df-556d-4858-83d0-a3bd591e4193,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-5a826c50-2041-40ea-869b-ebc775961fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-a32452c1-3727-4978-b943-4242944a1fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-825e660d-2166-42ab-8672-a1b5dbd01493,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-f1203927-ba62-40d5-b02d-a456efe0db02,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-f92e0037-8d4e-4b40-b007-9990edc37248,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-d919aaf3-1a69-4cdf-84f3-3c03a7553a5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-84437098-172.17.0.11-1597383115379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44728,DS-eb577051-e7bc-46a5-abe7-a478b8475c33,DISK], DatanodeInfoWithStorage[127.0.0.1:41921,DS-a47779df-556d-4858-83d0-a3bd591e4193,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-5a826c50-2041-40ea-869b-ebc775961fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-a32452c1-3727-4978-b943-4242944a1fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-825e660d-2166-42ab-8672-a1b5dbd01493,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-f1203927-ba62-40d5-b02d-a456efe0db02,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-f92e0037-8d4e-4b40-b007-9990edc37248,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-d919aaf3-1a69-4cdf-84f3-3c03a7553a5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 1
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1206216452-172.17.0.11-1597383588104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45313,DS-6613ee30-a597-433e-ad29-f1ede564a0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-8defd3da-f1dd-4446-8c81-20b72f91ff24,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-1ea5ec46-0770-4121-865d-c97516aa7631,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-4fffbe46-5644-49eb-8740-a157e2997d07,DISK], DatanodeInfoWithStorage[127.0.0.1:33900,DS-321bd197-96d5-4a05-bba0-78e1ea25e955,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-547633f0-76ee-4984-87a4-d0641a54eac2,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-f6f129c8-ac3e-463e-b3aa-5b347f1874aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-2597f4eb-754d-4db1-b8dd-6877b78eda82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1206216452-172.17.0.11-1597383588104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45313,DS-6613ee30-a597-433e-ad29-f1ede564a0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-8defd3da-f1dd-4446-8c81-20b72f91ff24,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-1ea5ec46-0770-4121-865d-c97516aa7631,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-4fffbe46-5644-49eb-8740-a157e2997d07,DISK], DatanodeInfoWithStorage[127.0.0.1:33900,DS-321bd197-96d5-4a05-bba0-78e1ea25e955,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-547633f0-76ee-4984-87a4-d0641a54eac2,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-f6f129c8-ac3e-463e-b3aa-5b347f1874aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40965,DS-2597f4eb-754d-4db1-b8dd-6877b78eda82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 1
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-158504168-172.17.0.11-1597383702162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46839,DS-643ccbba-04c6-464c-967b-4ead61e9c8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-19fe9600-7076-4e69-8fa1-fc19738beb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-ac2aafca-59cc-4e32-985f-73940e51527c,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-b8b021bd-337b-45f3-8308-e9e9ec607bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-188677b5-93aa-4cac-95b0-4407330e6edb,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-4996a53e-3b3d-4673-ac0b-c0f5e855f6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-63c4a78d-d826-45e0-bb6c-1bded2e5e1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-117b9eb1-2970-41c1-8168-d293520230c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-158504168-172.17.0.11-1597383702162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46839,DS-643ccbba-04c6-464c-967b-4ead61e9c8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-19fe9600-7076-4e69-8fa1-fc19738beb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-ac2aafca-59cc-4e32-985f-73940e51527c,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-b8b021bd-337b-45f3-8308-e9e9ec607bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-188677b5-93aa-4cac-95b0-4407330e6edb,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-4996a53e-3b3d-4673-ac0b-c0f5e855f6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-63c4a78d-d826-45e0-bb6c-1bded2e5e1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-117b9eb1-2970-41c1-8168-d293520230c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 1
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2112135955-172.17.0.11-1597383892621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44080,DS-9688dbbc-a3c5-4c6e-889d-6d74db9b150e,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-db261e07-8e73-4e41-a0a5-6cdc40c62dea,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-c499e463-6d95-4e37-8ab2-fa5322c8df48,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-4bf9e29d-37b2-4de5-99cf-ec7969a978d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-2fd81abd-f519-433f-9e00-10d5e2f3a81a,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-ca704543-9ea4-4c91-b79a-42ecad60c46c,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-72a76241-288e-4ea2-8b0b-16441b5a86a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-d578a55b-ffa4-4237-b683-833f1c731a13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2112135955-172.17.0.11-1597383892621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44080,DS-9688dbbc-a3c5-4c6e-889d-6d74db9b150e,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-db261e07-8e73-4e41-a0a5-6cdc40c62dea,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-c499e463-6d95-4e37-8ab2-fa5322c8df48,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-4bf9e29d-37b2-4de5-99cf-ec7969a978d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-2fd81abd-f519-433f-9e00-10d5e2f3a81a,DISK], DatanodeInfoWithStorage[127.0.0.1:36082,DS-ca704543-9ea4-4c91-b79a-42ecad60c46c,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-72a76241-288e-4ea2-8b0b-16441b5a86a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-d578a55b-ffa4-4237-b683-833f1c731a13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 1
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1170174293-172.17.0.11-1597384202232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43868,DS-63c38861-5d84-4250-a3e5-dd3f1eee1d67,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-e387e710-c8c9-4fc5-b18c-6f2ae72c5272,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-2335d248-4a97-467a-beb1-e2e3c56398ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-83c32d98-4eac-4c7a-b3b0-e4553c893251,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-2f8e1793-aedd-405f-9692-bcf2987a9fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-7aa63b2e-564b-4e5f-91ac-c3efafdcfb28,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-5c917b35-b7f0-497b-bd49-c2c0025a711c,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-9a81cbbb-2e38-41ad-a2fd-a0d0c662ce09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1170174293-172.17.0.11-1597384202232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43868,DS-63c38861-5d84-4250-a3e5-dd3f1eee1d67,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-e387e710-c8c9-4fc5-b18c-6f2ae72c5272,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-2335d248-4a97-467a-beb1-e2e3c56398ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-83c32d98-4eac-4c7a-b3b0-e4553c893251,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-2f8e1793-aedd-405f-9692-bcf2987a9fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35139,DS-7aa63b2e-564b-4e5f-91ac-c3efafdcfb28,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-5c917b35-b7f0-497b-bd49-c2c0025a711c,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-9a81cbbb-2e38-41ad-a2fd-a0d0c662ce09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 1
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-754413991-172.17.0.11-1597384369041:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42122,DS-5f4c647e-48eb-48e4-bd3a-92b29851a71a,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-4f0ff9d8-aa99-4dbf-ba1b-b66b65f98601,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-2eae75e0-5dcd-4c59-9b6c-99560e59a7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-d8c390ba-913d-469a-8402-0c1e8c911ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-62c0bb15-6986-4bc4-ba7b-e6d7807556e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-6eb385c6-b334-4071-82d5-82a90028ef87,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-69fe5149-6a14-4e4f-a064-63bac1f22497,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-2e9500df-f06b-4322-b45b-db8dc63c468c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-754413991-172.17.0.11-1597384369041:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42122,DS-5f4c647e-48eb-48e4-bd3a-92b29851a71a,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-4f0ff9d8-aa99-4dbf-ba1b-b66b65f98601,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-2eae75e0-5dcd-4c59-9b6c-99560e59a7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-d8c390ba-913d-469a-8402-0c1e8c911ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-62c0bb15-6986-4bc4-ba7b-e6d7807556e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-6eb385c6-b334-4071-82d5-82a90028ef87,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-69fe5149-6a14-4e4f-a064-63bac1f22497,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-2e9500df-f06b-4322-b45b-db8dc63c468c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 1
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-662399816-172.17.0.11-1597384439819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34131,DS-9fb81544-ba3d-4fb1-97b2-fdcdb396a081,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-79d61a3d-a574-4784-92bf-e2d124d6704d,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-2a52827c-3392-4592-b67a-5d02ef2cac7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-f353f652-3d0c-402f-a6b9-438c84c1f33a,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-023ca335-0d3c-46da-bc7f-857aa8b666b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-ee4324ae-4009-4157-9e20-f02c62388203,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-e67d878b-3bbb-4063-84e4-79dbcf8542a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-7dfce9d1-7af2-49e6-9949-8dbfc9c648f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-662399816-172.17.0.11-1597384439819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34131,DS-9fb81544-ba3d-4fb1-97b2-fdcdb396a081,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-79d61a3d-a574-4784-92bf-e2d124d6704d,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-2a52827c-3392-4592-b67a-5d02ef2cac7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-f353f652-3d0c-402f-a6b9-438c84c1f33a,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-023ca335-0d3c-46da-bc7f-857aa8b666b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-ee4324ae-4009-4157-9e20-f02c62388203,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-e67d878b-3bbb-4063-84e4-79dbcf8542a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-7dfce9d1-7af2-49e6-9949-8dbfc9c648f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5617
