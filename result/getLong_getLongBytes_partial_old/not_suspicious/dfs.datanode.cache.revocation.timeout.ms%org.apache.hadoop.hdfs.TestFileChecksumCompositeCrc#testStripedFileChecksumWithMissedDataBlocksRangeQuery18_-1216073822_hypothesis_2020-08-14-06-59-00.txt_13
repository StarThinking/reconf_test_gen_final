reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 900000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 900000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1442729734-172.17.0.3-1597388497688:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38215,DS-eae83ed8-d90c-4217-8ea4-f10d84830782,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-b41a5691-40ab-4b04-ba04-86365de592d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-c63f0d6a-22ea-48db-821b-23bd82f6e161,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-50c24d54-1155-457e-b8f5-ae01e6939e56,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-4665510c-6196-411a-a435-2251aa164547,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-0461910b-32f1-43a9-838c-86a76317b4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-02021a2f-14ef-4cf9-8de0-1131a3107ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-fab0e80f-8a7b-43ad-8aee-bff5e5cac0f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1442729734-172.17.0.3-1597388497688:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38215,DS-eae83ed8-d90c-4217-8ea4-f10d84830782,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-b41a5691-40ab-4b04-ba04-86365de592d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-c63f0d6a-22ea-48db-821b-23bd82f6e161,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-50c24d54-1155-457e-b8f5-ae01e6939e56,DISK], DatanodeInfoWithStorage[127.0.0.1:40189,DS-4665510c-6196-411a-a435-2251aa164547,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-0461910b-32f1-43a9-838c-86a76317b4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-02021a2f-14ef-4cf9-8de0-1131a3107ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-fab0e80f-8a7b-43ad-8aee-bff5e5cac0f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 900000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1812616699-172.17.0.3-1597388715215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36003,DS-7c41209f-acab-4ff5-b7be-a1ce9f1e5ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-f566c0b0-f786-47cf-8e52-e86547639ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-b29b80ab-a4d4-429c-9851-a13936af234f,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-e3efe3e5-d71f-4446-9a72-5862fa3462ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-8ef4cd01-7765-4ae3-8fbd-d95ba231c934,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-c210bf26-336b-4aa7-8d6a-7e6e4949cb7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-fe35d065-0fa7-4726-a4c2-274c275cc9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-c880bbe8-01ed-459b-815f-e7ff0e87b00f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1812616699-172.17.0.3-1597388715215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36003,DS-7c41209f-acab-4ff5-b7be-a1ce9f1e5ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-f566c0b0-f786-47cf-8e52-e86547639ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-b29b80ab-a4d4-429c-9851-a13936af234f,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-e3efe3e5-d71f-4446-9a72-5862fa3462ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-8ef4cd01-7765-4ae3-8fbd-d95ba231c934,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-c210bf26-336b-4aa7-8d6a-7e6e4949cb7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42477,DS-fe35d065-0fa7-4726-a4c2-274c275cc9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45252,DS-c880bbe8-01ed-459b-815f-e7ff0e87b00f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 900000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-161264767-172.17.0.3-1597389377065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35687,DS-826df49e-dde7-41d4-8cea-ee2504095c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-46908b4e-0b7a-4f5d-8c61-6e4b490cff2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-0a4650d3-6880-48c3-96a3-8ad6bb44f1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-201da51e-cdc0-4818-80c5-a104a6b0c83e,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-6e836cad-1295-463d-bd8e-c63d74f0d321,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-4e38de4e-5bdd-4315-aa3e-22c066a6cb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-705587c4-033a-435d-ad80-78ae01a045c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-2e8e202c-ca2a-4991-8641-6b6eb6b7c48b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-161264767-172.17.0.3-1597389377065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35687,DS-826df49e-dde7-41d4-8cea-ee2504095c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-46908b4e-0b7a-4f5d-8c61-6e4b490cff2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-0a4650d3-6880-48c3-96a3-8ad6bb44f1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-201da51e-cdc0-4818-80c5-a104a6b0c83e,DISK], DatanodeInfoWithStorage[127.0.0.1:43519,DS-6e836cad-1295-463d-bd8e-c63d74f0d321,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-4e38de4e-5bdd-4315-aa3e-22c066a6cb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42414,DS-705587c4-033a-435d-ad80-78ae01a045c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-2e8e202c-ca2a-4991-8641-6b6eb6b7c48b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 900000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-773324012-172.17.0.3-1597389452812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34672,DS-725dbf7b-852a-4fd7-b7a2-26b6416639af,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-9cfc024d-5b76-48c9-b9ac-b0a59a4e2a21,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-49debb52-738e-47b3-b04d-3be0d012defd,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-6454a6cf-a106-490e-9e2e-89478295c289,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-6649401d-0a21-4e62-a50b-b2f7a634bde3,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-5b684a63-ca01-4c90-bb33-84832a955e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-d5ee5678-69ef-4b01-a3b9-6e670dae9983,DISK], DatanodeInfoWithStorage[127.0.0.1:36211,DS-7de614d3-6e77-4658-a6fc-717ed52efc56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-773324012-172.17.0.3-1597389452812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34672,DS-725dbf7b-852a-4fd7-b7a2-26b6416639af,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-9cfc024d-5b76-48c9-b9ac-b0a59a4e2a21,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-49debb52-738e-47b3-b04d-3be0d012defd,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-6454a6cf-a106-490e-9e2e-89478295c289,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-6649401d-0a21-4e62-a50b-b2f7a634bde3,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-5b684a63-ca01-4c90-bb33-84832a955e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-d5ee5678-69ef-4b01-a3b9-6e670dae9983,DISK], DatanodeInfoWithStorage[127.0.0.1:36211,DS-7de614d3-6e77-4658-a6fc-717ed52efc56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 900000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1024541386-172.17.0.3-1597389888036:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40383,DS-d030cc81-c03f-43d9-853d-5138005696a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-c721e4ad-b8ec-447e-bf44-e79707d3873d,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-5bdc4173-f69f-4a7e-926f-cd4802334887,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-985644db-3f8b-4e64-be55-9e4ca55a4b29,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-e888f26f-6141-4c4c-8de9-f7e89cb2a142,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-caf201e0-b19c-4597-bf17-db1d1cad9a72,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-c9627fc1-0ba0-4acf-af40-b74a19b871bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-ff31a8a9-eb2c-4b47-b27c-e54e0a773e21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1024541386-172.17.0.3-1597389888036:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40383,DS-d030cc81-c03f-43d9-853d-5138005696a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-c721e4ad-b8ec-447e-bf44-e79707d3873d,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-5bdc4173-f69f-4a7e-926f-cd4802334887,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-985644db-3f8b-4e64-be55-9e4ca55a4b29,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-e888f26f-6141-4c4c-8de9-f7e89cb2a142,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-caf201e0-b19c-4597-bf17-db1d1cad9a72,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-c9627fc1-0ba0-4acf-af40-b74a19b871bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-ff31a8a9-eb2c-4b47-b27c-e54e0a773e21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 900000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1650699533-172.17.0.3-1597389956556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40589,DS-7af3855c-4f23-4223-b2b7-a18818bb624e,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-46718f74-69e0-4dd6-96fa-3e40334ad1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-2d48ce3c-21c0-4eda-a7b1-c463ba53edcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-7087d3f0-58db-42ab-98b0-32d2747e2f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-e5143ee1-4ab4-4620-9550-b56d241a74f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-d8782d67-b38d-4df3-836b-86256ef8039a,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-bc596e6c-bb30-4ee2-802f-059cb74374f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-7ec1dfa3-a799-4b44-917f-6ea7cfe01861,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1650699533-172.17.0.3-1597389956556:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40589,DS-7af3855c-4f23-4223-b2b7-a18818bb624e,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-46718f74-69e0-4dd6-96fa-3e40334ad1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-2d48ce3c-21c0-4eda-a7b1-c463ba53edcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-7087d3f0-58db-42ab-98b0-32d2747e2f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-e5143ee1-4ab4-4620-9550-b56d241a74f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-d8782d67-b38d-4df3-836b-86256ef8039a,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-bc596e6c-bb30-4ee2-802f-059cb74374f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-7ec1dfa3-a799-4b44-917f-6ea7cfe01861,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 900000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1405248761-172.17.0.3-1597390326423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40947,DS-66c82880-8042-49d7-bc0d-77cf1b79b254,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-c1f2099c-54d0-4229-8461-1e9adc91af0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-e8e0674d-de8b-4457-8003-7f3505e63c24,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-477b8197-7fd9-4d9d-af87-69a8bc7821e0,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-23c409fd-4dd2-4795-8de4-32d1b25a136b,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-d9832959-b948-47ba-9942-4dbc8ac10a98,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-fe7d601e-1b6c-4ad7-999c-ad3667d1a760,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-4e94cf25-1521-473d-8638-92862d66a211,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1405248761-172.17.0.3-1597390326423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40947,DS-66c82880-8042-49d7-bc0d-77cf1b79b254,DISK], DatanodeInfoWithStorage[127.0.0.1:39135,DS-c1f2099c-54d0-4229-8461-1e9adc91af0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-e8e0674d-de8b-4457-8003-7f3505e63c24,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-477b8197-7fd9-4d9d-af87-69a8bc7821e0,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-23c409fd-4dd2-4795-8de4-32d1b25a136b,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-d9832959-b948-47ba-9942-4dbc8ac10a98,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-fe7d601e-1b6c-4ad7-999c-ad3667d1a760,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-4e94cf25-1521-473d-8638-92862d66a211,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 900000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-874522937-172.17.0.3-1597391273598:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42951,DS-8513d57e-24bb-4b20-a9ef-2b54dc1d9b53,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-2c39e230-f58a-4f84-833e-0e9c795cfff9,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-a5dba614-0107-4604-baba-be845f032312,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-2717123e-3fb2-427e-905b-61c436206c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-de65cd42-5ec6-427d-a7d4-231f891d98b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-ba1778ed-be03-4288-b14b-5cfca1954ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-029f7d00-f1ba-4af3-8ca4-2d3605cdb909,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-67871ce1-2760-4206-8665-0e8337630d6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-874522937-172.17.0.3-1597391273598:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42951,DS-8513d57e-24bb-4b20-a9ef-2b54dc1d9b53,DISK], DatanodeInfoWithStorage[127.0.0.1:43795,DS-2c39e230-f58a-4f84-833e-0e9c795cfff9,DISK], DatanodeInfoWithStorage[127.0.0.1:41894,DS-a5dba614-0107-4604-baba-be845f032312,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-2717123e-3fb2-427e-905b-61c436206c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-de65cd42-5ec6-427d-a7d4-231f891d98b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-ba1778ed-be03-4288-b14b-5cfca1954ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-029f7d00-f1ba-4af3-8ca4-2d3605cdb909,DISK], DatanodeInfoWithStorage[127.0.0.1:41706,DS-67871ce1-2760-4206-8665-0e8337630d6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 900000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1799037006-172.17.0.3-1597391309047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40741,DS-2fe6a1ea-e178-4318-ab11-0802a2055bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-4c757b49-1f35-4ee1-b86e-6fdfcfd50875,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-a88137b0-f342-42ed-8542-d2ad79c4ce38,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-0f32c227-dfa9-4234-9874-f2768f82bca2,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-1a12d952-6d95-4177-a9e8-63b127c124eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-0aa22d33-39eb-4a1b-a811-ab64c5b25cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-4307c3cb-66e7-42b7-aa3a-6a08167b04a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-20cd2772-4a3d-44dd-a7b2-a0ed05461dba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1799037006-172.17.0.3-1597391309047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40741,DS-2fe6a1ea-e178-4318-ab11-0802a2055bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-4c757b49-1f35-4ee1-b86e-6fdfcfd50875,DISK], DatanodeInfoWithStorage[127.0.0.1:43450,DS-a88137b0-f342-42ed-8542-d2ad79c4ce38,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-0f32c227-dfa9-4234-9874-f2768f82bca2,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-1a12d952-6d95-4177-a9e8-63b127c124eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-0aa22d33-39eb-4a1b-a811-ab64c5b25cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-4307c3cb-66e7-42b7-aa3a-6a08167b04a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-20cd2772-4a3d-44dd-a7b2-a0ed05461dba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 900000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-190662201-172.17.0.3-1597391666681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33525,DS-ce0cecbe-f4eb-4f52-8ce1-6c659d79436e,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-a067ec4c-4c15-42f9-94d4-c8d13cdd6a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-e783a2e5-b5d3-4a9c-a644-5df6717696e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-1ea1706d-b361-4890-b147-dc85bc8a206d,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-811856a6-89e6-430d-a582-25f63305a42f,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-21aa94ac-2f92-4dce-9fe1-9e27f546b353,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-9aad59d5-936f-405c-ab03-38c0db4d49cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-2e5596ea-19f2-4a0c-b62c-48d9f2e52cd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-190662201-172.17.0.3-1597391666681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33525,DS-ce0cecbe-f4eb-4f52-8ce1-6c659d79436e,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-a067ec4c-4c15-42f9-94d4-c8d13cdd6a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-e783a2e5-b5d3-4a9c-a644-5df6717696e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-1ea1706d-b361-4890-b147-dc85bc8a206d,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-811856a6-89e6-430d-a582-25f63305a42f,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-21aa94ac-2f92-4dce-9fe1-9e27f546b353,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-9aad59d5-936f-405c-ab03-38c0db4d49cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-2e5596ea-19f2-4a0c-b62c-48d9f2e52cd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 900000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1686572129-172.17.0.3-1597391738011:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43472,DS-90e9f973-1d7f-4686-957e-036e84672222,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-1aff4977-a049-4295-b94f-01163b9e9507,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-439fadc5-4d27-44bc-a098-ac2a28c1eebf,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-cbe32e93-e6ad-4ae3-ac64-03409452d205,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-9ed7a2a9-d24d-48ca-8bef-030e7bb97be5,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-e243a96a-7eec-4895-99f7-b141ce0d7ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-4ef87486-d0f3-485c-ab6e-016eada6d4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-08dd0877-5ae1-48ab-b6cf-281c048abe47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1686572129-172.17.0.3-1597391738011:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43472,DS-90e9f973-1d7f-4686-957e-036e84672222,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-1aff4977-a049-4295-b94f-01163b9e9507,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-439fadc5-4d27-44bc-a098-ac2a28c1eebf,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-cbe32e93-e6ad-4ae3-ac64-03409452d205,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-9ed7a2a9-d24d-48ca-8bef-030e7bb97be5,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-e243a96a-7eec-4895-99f7-b141ce0d7ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-4ef87486-d0f3-485c-ab6e-016eada6d4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-08dd0877-5ae1-48ab-b6cf-281c048abe47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 900000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1210346775-172.17.0.3-1597391984425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43272,DS-342240ab-0164-4420-b014-d0602aca927a,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-d9d95ce5-ee66-472f-a44d-21c3e648da79,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-7d178de5-00fa-462f-bb36-bd2316e3c5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-5f9f251c-b073-4707-8110-a2698f45b986,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-e2b9e1a6-e51c-459d-aa15-c3ca0c8fa27c,DISK], DatanodeInfoWithStorage[127.0.0.1:36431,DS-12625e3e-50a0-43de-baa4-9830d362f241,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-55b863b6-7e0f-4985-aebc-5cdc662ab7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-f7067735-a97e-49e1-b088-b96b0b8ffcff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1210346775-172.17.0.3-1597391984425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43272,DS-342240ab-0164-4420-b014-d0602aca927a,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-d9d95ce5-ee66-472f-a44d-21c3e648da79,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-7d178de5-00fa-462f-bb36-bd2316e3c5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-5f9f251c-b073-4707-8110-a2698f45b986,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-e2b9e1a6-e51c-459d-aa15-c3ca0c8fa27c,DISK], DatanodeInfoWithStorage[127.0.0.1:36431,DS-12625e3e-50a0-43de-baa4-9830d362f241,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-55b863b6-7e0f-4985-aebc-5cdc662ab7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-f7067735-a97e-49e1-b088-b96b0b8ffcff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 900000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1072838834-172.17.0.3-1597392636748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45200,DS-9837f01a-eac6-4b53-8790-e4bb80a2952b,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-119911e5-0bd5-4bbf-b62b-d38937320425,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-87a2a4f5-c51a-473c-afc6-a4d0fd2bc501,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-1312f916-cf73-468b-9096-7c831da86cba,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-da61bba1-a0d6-4f75-8520-7d40eb7b47e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-e8a8e4c6-e2f1-44eb-b9fd-67c304eafcc0,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-27e8decc-dbbf-4296-8e0d-fad0d01f96b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-9bf1c86d-fc9c-4159-bd06-4d730d318afb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1072838834-172.17.0.3-1597392636748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45200,DS-9837f01a-eac6-4b53-8790-e4bb80a2952b,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-119911e5-0bd5-4bbf-b62b-d38937320425,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-87a2a4f5-c51a-473c-afc6-a4d0fd2bc501,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-1312f916-cf73-468b-9096-7c831da86cba,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-da61bba1-a0d6-4f75-8520-7d40eb7b47e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-e8a8e4c6-e2f1-44eb-b9fd-67c304eafcc0,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-27e8decc-dbbf-4296-8e0d-fad0d01f96b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-9bf1c86d-fc9c-4159-bd06-4d730d318afb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 900000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-561993397-172.17.0.3-1597392733144:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45304,DS-0296cb90-cd41-43fd-9e1a-8429d0f91bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-dc3a7979-75c7-4309-b9f1-ec98b03548ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-e14ae062-a862-4d01-863e-be205d2fe1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-55ee6fba-2f73-4c9b-b25c-6cd603dfb4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-b1de4194-2a5a-48b4-a873-0255bcec2dec,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-23fd37ca-016d-48ad-b5b3-ed60018e6d89,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-dd56e57c-2971-4c88-adcc-4042c638303a,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-6a65ccda-fce7-495a-bc5a-2a3fe69cf051,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-561993397-172.17.0.3-1597392733144:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45304,DS-0296cb90-cd41-43fd-9e1a-8429d0f91bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-dc3a7979-75c7-4309-b9f1-ec98b03548ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-e14ae062-a862-4d01-863e-be205d2fe1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-55ee6fba-2f73-4c9b-b25c-6cd603dfb4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-b1de4194-2a5a-48b4-a873-0255bcec2dec,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-23fd37ca-016d-48ad-b5b3-ed60018e6d89,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-dd56e57c-2971-4c88-adcc-4042c638303a,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-6a65ccda-fce7-495a-bc5a-2a3fe69cf051,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 900000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-446903947-172.17.0.3-1597393412502:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43941,DS-2dadf976-f46f-47f9-b800-a23952b79da6,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-d1f5d767-76fa-447b-99bf-9c0cd2590eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-a4241907-ad9f-4c57-86be-42d4a45fa69c,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-df585d57-067f-4045-9096-b4e3d1e2badf,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-7cf381e7-2cc6-4a17-a91e-716a428eac97,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-e6915df9-1146-4ab9-866a-d057f32bf524,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-417f9477-3fd7-43cc-bf6f-878a4cdf35a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36529,DS-10006cc1-48e5-4c36-aa35-3f266f1f6a44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-446903947-172.17.0.3-1597393412502:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43941,DS-2dadf976-f46f-47f9-b800-a23952b79da6,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-d1f5d767-76fa-447b-99bf-9c0cd2590eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-a4241907-ad9f-4c57-86be-42d4a45fa69c,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-df585d57-067f-4045-9096-b4e3d1e2badf,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-7cf381e7-2cc6-4a17-a91e-716a428eac97,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-e6915df9-1146-4ab9-866a-d057f32bf524,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-417f9477-3fd7-43cc-bf6f-878a4cdf35a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36529,DS-10006cc1-48e5-4c36-aa35-3f266f1f6a44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.timeout.ms
component: hdfs:DataNode
v1: 900000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1379420259-172.17.0.3-1597393478521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46384,DS-f9286f82-f329-473b-88fe-3e0b63a4b6af,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-3463f55b-a6c7-452a-8169-42903ff5d7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-0367c7ad-237e-44af-8b8c-1a4e56204502,DISK], DatanodeInfoWithStorage[127.0.0.1:33667,DS-747f954d-ab3b-4d75-94f5-2b06beec86d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-eb219cc2-7796-48b8-8fbc-48f659867cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-0720ba02-334f-4a7d-87f8-de6954ec0e58,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-26121feb-9b7a-40cf-8673-759e727bb5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-ec958edc-37a5-4241-b80b-4f2d668ff025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1379420259-172.17.0.3-1597393478521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46384,DS-f9286f82-f329-473b-88fe-3e0b63a4b6af,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-3463f55b-a6c7-452a-8169-42903ff5d7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-0367c7ad-237e-44af-8b8c-1a4e56204502,DISK], DatanodeInfoWithStorage[127.0.0.1:33667,DS-747f954d-ab3b-4d75-94f5-2b06beec86d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-eb219cc2-7796-48b8-8fbc-48f659867cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-0720ba02-334f-4a7d-87f8-de6954ec0e58,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-26121feb-9b7a-40cf-8673-759e727bb5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-ec958edc-37a5-4241-b80b-4f2d668ff025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5338
