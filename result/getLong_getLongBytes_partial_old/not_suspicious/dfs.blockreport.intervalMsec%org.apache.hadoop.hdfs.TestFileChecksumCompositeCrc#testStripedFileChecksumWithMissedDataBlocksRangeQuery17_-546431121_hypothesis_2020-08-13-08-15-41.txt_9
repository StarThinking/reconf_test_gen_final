reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1312767712-172.17.0.9-1597306698635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40389,DS-df2df3bc-1608-47e1-a537-1317921b069c,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-d0496da8-c451-4cb7-9bad-67695f1e62fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-502a5864-e812-4426-9b5c-768e20e35567,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-e39798a4-b159-4e98-a9e6-b53af815807b,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-9b44b608-2bc2-4631-808f-95536c803a66,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-c8b25e26-3201-460e-8416-00fd44a3d117,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-dd14f0ee-052c-4455-8cd7-95689d6873c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-1abc1d57-31c2-4157-8cd0-96f6ec52a37e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1312767712-172.17.0.9-1597306698635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40389,DS-df2df3bc-1608-47e1-a537-1317921b069c,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-d0496da8-c451-4cb7-9bad-67695f1e62fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-502a5864-e812-4426-9b5c-768e20e35567,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-e39798a4-b159-4e98-a9e6-b53af815807b,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-9b44b608-2bc2-4631-808f-95536c803a66,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-c8b25e26-3201-460e-8416-00fd44a3d117,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-dd14f0ee-052c-4455-8cd7-95689d6873c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-1abc1d57-31c2-4157-8cd0-96f6ec52a37e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-526760959-172.17.0.9-1597306910234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41563,DS-7e814b69-f96b-4843-9a10-c4e3b45501e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-3ac55641-bfa6-40ec-b393-78d3b9d905fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-9d888148-ee1b-4a4a-bffc-8a39e1fa37fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-298e00d4-74f3-4ce8-8149-02eca60df64d,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-ae02b823-4f37-4ede-b240-0be02980bc91,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-264c9a8f-5946-4e2d-8811-4a8ff7df9353,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-aca5abda-51c8-45b9-bb44-fc69d892c360,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-9b4997c3-e7a6-48cd-8165-cce830f1e035,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-526760959-172.17.0.9-1597306910234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41563,DS-7e814b69-f96b-4843-9a10-c4e3b45501e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-3ac55641-bfa6-40ec-b393-78d3b9d905fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-9d888148-ee1b-4a4a-bffc-8a39e1fa37fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-298e00d4-74f3-4ce8-8149-02eca60df64d,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-ae02b823-4f37-4ede-b240-0be02980bc91,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-264c9a8f-5946-4e2d-8811-4a8ff7df9353,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-aca5abda-51c8-45b9-bb44-fc69d892c360,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-9b4997c3-e7a6-48cd-8165-cce830f1e035,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1787539604-172.17.0.9-1597306983395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40125,DS-2d721f61-aae2-41b5-8189-2ec1f94fd3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-f30a3456-e199-4759-a7f2-b0f4ce51e904,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-54e2b597-4eb3-4429-8d3b-d0527811c268,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-f46b4f53-e823-4163-8f70-59f58925495c,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-0b208796-430b-4f46-b074-dd7fa01d14be,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-c27248d3-dfa8-42e2-b100-b323ce0f29ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-32dfbe75-1bc0-4450-b70b-0fe648a6fb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-855574ce-d1d2-431d-866c-0b153d4cf949,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1787539604-172.17.0.9-1597306983395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40125,DS-2d721f61-aae2-41b5-8189-2ec1f94fd3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-f30a3456-e199-4759-a7f2-b0f4ce51e904,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-54e2b597-4eb3-4429-8d3b-d0527811c268,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-f46b4f53-e823-4163-8f70-59f58925495c,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-0b208796-430b-4f46-b074-dd7fa01d14be,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-c27248d3-dfa8-42e2-b100-b323ce0f29ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-32dfbe75-1bc0-4450-b70b-0fe648a6fb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-855574ce-d1d2-431d-866c-0b153d4cf949,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-906883944-172.17.0.9-1597307216834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42105,DS-defecf5e-1f14-46ec-95d5-5162debb235c,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-a1223bcb-10f3-49b1-a0bf-4e808da18962,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-19b8eac6-8ae6-4ab4-8f0b-e07c301609ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-cf1914b9-9f4c-42a7-ab8a-58fadb3dd638,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-f1f1cfa5-f8b9-4577-9a5c-6eb2496ad512,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-301c7de6-859a-41ef-ab74-7a4567dc45cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-7d490bb4-e742-4daa-bef6-c5c50c886756,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-a8f8f2ec-cd88-4e45-9b0e-ac2c78d73956,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-906883944-172.17.0.9-1597307216834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42105,DS-defecf5e-1f14-46ec-95d5-5162debb235c,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-a1223bcb-10f3-49b1-a0bf-4e808da18962,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-19b8eac6-8ae6-4ab4-8f0b-e07c301609ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39166,DS-cf1914b9-9f4c-42a7-ab8a-58fadb3dd638,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-f1f1cfa5-f8b9-4577-9a5c-6eb2496ad512,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-301c7de6-859a-41ef-ab74-7a4567dc45cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38541,DS-7d490bb4-e742-4daa-bef6-c5c50c886756,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-a8f8f2ec-cd88-4e45-9b0e-ac2c78d73956,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2139422537-172.17.0.9-1597307280582:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33973,DS-6463e4bb-84f2-4747-9408-440877d68b75,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-fd5ed420-1144-4003-a1fa-2431c3a685e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-fe9f9e67-8f36-4bbf-ac3f-5680a1ced91f,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-fa22e4dd-6f12-4512-a22f-1b1b50ab66a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-f3ca0f13-9017-48b5-8851-d3588f6380e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-f04c800d-14c5-459b-ba84-2e95dfd08d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-e1e9d422-510c-4f19-b2e7-d2f6e5ae1b03,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-628b2a63-59a1-4962-a92c-38be93b572f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2139422537-172.17.0.9-1597307280582:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33973,DS-6463e4bb-84f2-4747-9408-440877d68b75,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-fd5ed420-1144-4003-a1fa-2431c3a685e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-fe9f9e67-8f36-4bbf-ac3f-5680a1ced91f,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-fa22e4dd-6f12-4512-a22f-1b1b50ab66a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-f3ca0f13-9017-48b5-8851-d3588f6380e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-f04c800d-14c5-459b-ba84-2e95dfd08d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-e1e9d422-510c-4f19-b2e7-d2f6e5ae1b03,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-628b2a63-59a1-4962-a92c-38be93b572f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2107686939-172.17.0.9-1597307457988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35883,DS-e72be144-e87f-4b49-9a6f-f493f435fa6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-ca88b01e-78c6-41c8-97c1-3e10b48ad325,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-ca02ed32-9240-42ab-a67e-b07ae6f8b208,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-4718b58c-011c-4b22-8dc6-17215ee3fb33,DISK], DatanodeInfoWithStorage[127.0.0.1:46659,DS-06413e6b-2978-47c1-849b-903a88f4d60b,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-a503b30d-e94f-4816-8689-5e30f49f38f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-9827071f-7709-4e81-ae21-0b6dab672847,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-33cc2718-dfd3-4185-9032-8e0f42f94290,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2107686939-172.17.0.9-1597307457988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35883,DS-e72be144-e87f-4b49-9a6f-f493f435fa6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-ca88b01e-78c6-41c8-97c1-3e10b48ad325,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-ca02ed32-9240-42ab-a67e-b07ae6f8b208,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-4718b58c-011c-4b22-8dc6-17215ee3fb33,DISK], DatanodeInfoWithStorage[127.0.0.1:46659,DS-06413e6b-2978-47c1-849b-903a88f4d60b,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-a503b30d-e94f-4816-8689-5e30f49f38f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-9827071f-7709-4e81-ae21-0b6dab672847,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-33cc2718-dfd3-4185-9032-8e0f42f94290,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1659993430-172.17.0.9-1597307695179:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45400,DS-f01c1491-6b2b-4721-a805-95a7ad4bad36,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-e6095505-d3bc-4925-8348-75f799309d10,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-0ef98865-a3cb-48fe-b3c9-f911f52fc1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-499cdb56-2d6d-49a7-9517-bebbe33ac6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-04309017-1560-4166-9579-8ecf6f9ecf76,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-94c8ebbf-a5e6-489f-9ac8-5f6debf803c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-fb608750-94bd-4da4-87c4-711bfd4f0022,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-88374d21-486b-4d73-9042-4a08e78cc550,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1659993430-172.17.0.9-1597307695179:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45400,DS-f01c1491-6b2b-4721-a805-95a7ad4bad36,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-e6095505-d3bc-4925-8348-75f799309d10,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-0ef98865-a3cb-48fe-b3c9-f911f52fc1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-499cdb56-2d6d-49a7-9517-bebbe33ac6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-04309017-1560-4166-9579-8ecf6f9ecf76,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-94c8ebbf-a5e6-489f-9ac8-5f6debf803c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44865,DS-fb608750-94bd-4da4-87c4-711bfd4f0022,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-88374d21-486b-4d73-9042-4a08e78cc550,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-945014222-172.17.0.9-1597307812072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39221,DS-01b32cad-12fe-47f2-98fb-4d5c45730773,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-e3fd399e-f743-4470-b74a-9a50dc32679e,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-d489a7ec-6957-4a3b-85b4-2b998180e363,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-dcc79224-483b-4288-ba16-bb54d8bc85b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-dc8c051e-b0d2-42fd-8491-7e0f9fc87c84,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-b980e15c-abfc-4c2f-b7a2-b4e420358554,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-0202f70d-4672-4ba0-9b84-999a8b6d4aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-437d52fd-7403-4422-a0c0-2139d922df26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-945014222-172.17.0.9-1597307812072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39221,DS-01b32cad-12fe-47f2-98fb-4d5c45730773,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-e3fd399e-f743-4470-b74a-9a50dc32679e,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-d489a7ec-6957-4a3b-85b4-2b998180e363,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-dcc79224-483b-4288-ba16-bb54d8bc85b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-dc8c051e-b0d2-42fd-8491-7e0f9fc87c84,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-b980e15c-abfc-4c2f-b7a2-b4e420358554,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-0202f70d-4672-4ba0-9b84-999a8b6d4aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-437d52fd-7403-4422-a0c0-2139d922df26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-928898057-172.17.0.9-1597308233233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36816,DS-d31e517b-88ea-4b58-8875-97f4b2a8e8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-c5da21f7-fcd5-456b-919f-988f50de8ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-539dbe0a-2168-42dd-b834-abe5c64ff1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-2adaee05-6718-4c81-acc0-6ac60fbc3574,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-903417d2-84b8-4726-8a4f-6d15120c8c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-714e940f-587e-4dc6-9c29-37a56e9e5c05,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-f721caea-a8a6-4b08-b250-6eba731abbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-68e6e0dc-6f4d-4885-82f0-b7431a1097c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-928898057-172.17.0.9-1597308233233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36816,DS-d31e517b-88ea-4b58-8875-97f4b2a8e8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43507,DS-c5da21f7-fcd5-456b-919f-988f50de8ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-539dbe0a-2168-42dd-b834-abe5c64ff1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-2adaee05-6718-4c81-acc0-6ac60fbc3574,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-903417d2-84b8-4726-8a4f-6d15120c8c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44460,DS-714e940f-587e-4dc6-9c29-37a56e9e5c05,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-f721caea-a8a6-4b08-b250-6eba731abbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39817,DS-68e6e0dc-6f4d-4885-82f0-b7431a1097c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-732518625-172.17.0.9-1597308265680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39979,DS-c288dd6c-c11d-401f-a494-211184c9e862,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-f140cc2e-a6d2-4261-b0e5-057650432e45,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-1a2582f1-8ba9-4ad6-bc20-e724a4a6d7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-92fa51ad-5ed6-408e-9eb8-490d0fc8df90,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-5551f7db-7b9e-4f63-9664-9479c7541e19,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-2acee35b-e17d-40c5-93d7-eb53522c65aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-ea11d178-3939-40e6-808c-e25fd6eb0e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-f4aaa733-043a-4d54-9517-b8c898afcebe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-732518625-172.17.0.9-1597308265680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39979,DS-c288dd6c-c11d-401f-a494-211184c9e862,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-f140cc2e-a6d2-4261-b0e5-057650432e45,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-1a2582f1-8ba9-4ad6-bc20-e724a4a6d7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-92fa51ad-5ed6-408e-9eb8-490d0fc8df90,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-5551f7db-7b9e-4f63-9664-9479c7541e19,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-2acee35b-e17d-40c5-93d7-eb53522c65aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-ea11d178-3939-40e6-808c-e25fd6eb0e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-f4aaa733-043a-4d54-9517-b8c898afcebe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-971890737-172.17.0.9-1597308490653:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45719,DS-aaa40669-2310-4ae8-9dd6-82551b9a5c56,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-922cf2ae-1109-4327-ba98-68108e6f4498,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-89e492b9-8b91-4089-a1cb-ee1ed64816cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-806a9baf-28a1-46ee-9d8c-4b480a01c2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-f64076ec-08e1-4488-8ea2-502e4d2586f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-9cd4719e-49c4-4d3e-ba29-ac15292c88fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-e49fd311-da73-4475-adfd-0f2973074b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-e85ed5ac-2665-4c40-ab7c-9da2e4fd6292,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-971890737-172.17.0.9-1597308490653:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45719,DS-aaa40669-2310-4ae8-9dd6-82551b9a5c56,DISK], DatanodeInfoWithStorage[127.0.0.1:36631,DS-922cf2ae-1109-4327-ba98-68108e6f4498,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-89e492b9-8b91-4089-a1cb-ee1ed64816cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-806a9baf-28a1-46ee-9d8c-4b480a01c2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-f64076ec-08e1-4488-8ea2-502e4d2586f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-9cd4719e-49c4-4d3e-ba29-ac15292c88fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-e49fd311-da73-4475-adfd-0f2973074b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-e85ed5ac-2665-4c40-ab7c-9da2e4fd6292,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1336428760-172.17.0.9-1597308668572:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37567,DS-cb1307ef-9337-4d79-a9f9-09cc6b882dda,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-9fa232a8-9e88-4ba2-a247-9b987e477b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-42ba4820-c3a5-4f32-8dcc-de7faa4a5c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-44e3e8d7-b9c1-4873-b137-308d1608e4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-8af17b3b-8f4e-4213-91bc-0757d0088875,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-52ed8110-70a5-43a7-85f7-5d46affe0707,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-4afcd4f4-f11e-4872-901d-fb9769aef6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-1f16fc50-1b5b-486c-913e-c39284c648dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1336428760-172.17.0.9-1597308668572:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37567,DS-cb1307ef-9337-4d79-a9f9-09cc6b882dda,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-9fa232a8-9e88-4ba2-a247-9b987e477b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-42ba4820-c3a5-4f32-8dcc-de7faa4a5c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37887,DS-44e3e8d7-b9c1-4873-b137-308d1608e4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-8af17b3b-8f4e-4213-91bc-0757d0088875,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-52ed8110-70a5-43a7-85f7-5d46affe0707,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-4afcd4f4-f11e-4872-901d-fb9769aef6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-1f16fc50-1b5b-486c-913e-c39284c648dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1378492897-172.17.0.9-1597309491287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46664,DS-b9def0a6-0f98-416a-9fb5-f24d413a344d,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-c7a4ade6-69cf-45d9-9c77-5a20b225a94f,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-176f8b79-19eb-4047-92e8-ef97972612b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-7927b2b5-49aa-4248-a28a-a8f70be6419e,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-0efd855a-1a43-40b9-a0ec-04a8d64e543b,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-1e566afa-2288-45d2-bfa1-af805e1a48f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-70e0d34d-f51e-433a-913e-af5205b6432d,DISK], DatanodeInfoWithStorage[127.0.0.1:44817,DS-801421f4-ed16-417a-8ef9-d90e4b52863e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1378492897-172.17.0.9-1597309491287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46664,DS-b9def0a6-0f98-416a-9fb5-f24d413a344d,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-c7a4ade6-69cf-45d9-9c77-5a20b225a94f,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-176f8b79-19eb-4047-92e8-ef97972612b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-7927b2b5-49aa-4248-a28a-a8f70be6419e,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-0efd855a-1a43-40b9-a0ec-04a8d64e543b,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-1e566afa-2288-45d2-bfa1-af805e1a48f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-70e0d34d-f51e-433a-913e-af5205b6432d,DISK], DatanodeInfoWithStorage[127.0.0.1:44817,DS-801421f4-ed16-417a-8ef9-d90e4b52863e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1248319799-172.17.0.9-1597309896589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44952,DS-9498e442-28a9-4348-bf17-5b6526d7f381,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-d5e53fc7-3531-47d8-8ad1-65ebfd70c2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-b06259d0-fb64-41d4-b7c7-32751596b46b,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-8bd328ac-38f1-411e-9709-7c4f99e17b30,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-355025c5-4b03-4567-b7fc-1699468fcdba,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-ef2430fd-5548-4072-a30a-5b690f1a1ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-fece9db6-a410-457b-8615-056448ce5cef,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-3a7f506a-b380-4a66-83e6-832697cc3b72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1248319799-172.17.0.9-1597309896589:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44952,DS-9498e442-28a9-4348-bf17-5b6526d7f381,DISK], DatanodeInfoWithStorage[127.0.0.1:43262,DS-d5e53fc7-3531-47d8-8ad1-65ebfd70c2d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-b06259d0-fb64-41d4-b7c7-32751596b46b,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-8bd328ac-38f1-411e-9709-7c4f99e17b30,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-355025c5-4b03-4567-b7fc-1699468fcdba,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-ef2430fd-5548-4072-a30a-5b690f1a1ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-fece9db6-a410-457b-8615-056448ce5cef,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-3a7f506a-b380-4a66-83e6-832697cc3b72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1039128246-172.17.0.9-1597310222064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45526,DS-6f45826a-544f-455b-a471-a33a81407324,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-cf3a4c43-b0e0-43ba-8398-a80b4077cc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-5ff446ea-501a-4170-904b-c4981de5c3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-3473f848-066e-4cea-9b89-f791c37f79bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-ec2a9794-d2c5-4ac6-a2b4-84085a6b3896,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-21417348-5ece-4cf2-b152-558a6038830a,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-0f26e330-8485-404f-a1a8-7995fdd9963c,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-58ce0f4d-2de3-4f58-9981-f03a1a69bce5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1039128246-172.17.0.9-1597310222064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45526,DS-6f45826a-544f-455b-a471-a33a81407324,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-cf3a4c43-b0e0-43ba-8398-a80b4077cc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-5ff446ea-501a-4170-904b-c4981de5c3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-3473f848-066e-4cea-9b89-f791c37f79bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-ec2a9794-d2c5-4ac6-a2b4-84085a6b3896,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-21417348-5ece-4cf2-b152-558a6038830a,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-0f26e330-8485-404f-a1a8-7995fdd9963c,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-58ce0f4d-2de3-4f58-9981-f03a1a69bce5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1792212945-172.17.0.9-1597310661147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42639,DS-a58679e7-b22a-4151-9cc8-e4c1323e3457,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-9e29e379-6c75-42ef-a8aa-351963a9dcc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-1f405544-9842-4a67-8298-ccb9a604925b,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-15595c2c-c250-40e2-b4df-828fabd26a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-1d691950-a4bc-4df5-ac73-f70cb1f8a42d,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-43a2a1ba-adc7-444d-90e6-8dfb5ef1c177,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-ce1392a7-0939-47e9-828d-d142d38c7b87,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-6e6899d0-5911-4e3c-965b-c50e768e626c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1792212945-172.17.0.9-1597310661147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42639,DS-a58679e7-b22a-4151-9cc8-e4c1323e3457,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-9e29e379-6c75-42ef-a8aa-351963a9dcc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42108,DS-1f405544-9842-4a67-8298-ccb9a604925b,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-15595c2c-c250-40e2-b4df-828fabd26a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-1d691950-a4bc-4df5-ac73-f70cb1f8a42d,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-43a2a1ba-adc7-444d-90e6-8dfb5ef1c177,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-ce1392a7-0939-47e9-828d-d142d38c7b87,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-6e6899d0-5911-4e3c-965b-c50e768e626c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-25056150-172.17.0.9-1597310767326:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37539,DS-d6332619-f0b3-4220-9e70-c5677f813a93,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-3272b68b-7a7d-4d33-8334-ce445f82035d,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-df87c637-2aa7-418a-afac-428566946a86,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-0dfcb0d4-d031-403c-b327-700cb8f6e60c,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-82e8c4f2-005b-48ce-a9a6-dc56e4bfb31e,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-f96607d7-dd9c-4dc2-a1bb-021218bbbdf7,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-fc1f8386-008f-401d-bc0f-917484f40486,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-c4981e5f-cc51-4d58-ab4a-07cda415fabe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-25056150-172.17.0.9-1597310767326:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37539,DS-d6332619-f0b3-4220-9e70-c5677f813a93,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-3272b68b-7a7d-4d33-8334-ce445f82035d,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-df87c637-2aa7-418a-afac-428566946a86,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-0dfcb0d4-d031-403c-b327-700cb8f6e60c,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-82e8c4f2-005b-48ce-a9a6-dc56e4bfb31e,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-f96607d7-dd9c-4dc2-a1bb-021218bbbdf7,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-fc1f8386-008f-401d-bc0f-917484f40486,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-c4981e5f-cc51-4d58-ab4a-07cda415fabe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1158937982-172.17.0.9-1597311126208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36146,DS-867a8325-6c64-45cd-b9cb-940b160ecc25,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-52132067-f042-4b18-a537-0de1231e0076,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-d196e2d2-17d3-438d-a3f0-dfa512a6b77e,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-327628f2-614f-4772-a677-9475dd92145b,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-65126f27-c020-4fd8-81bb-b38b78dd2b64,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-3b0455a2-5ff0-4422-823e-6b26139d677d,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-17f1b081-4356-43aa-917a-7b40d4e65ead,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-bca28792-c3d6-4aac-a3e1-c030ba5e0321,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1158937982-172.17.0.9-1597311126208:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36146,DS-867a8325-6c64-45cd-b9cb-940b160ecc25,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-52132067-f042-4b18-a537-0de1231e0076,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-d196e2d2-17d3-438d-a3f0-dfa512a6b77e,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-327628f2-614f-4772-a677-9475dd92145b,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-65126f27-c020-4fd8-81bb-b38b78dd2b64,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-3b0455a2-5ff0-4422-823e-6b26139d677d,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-17f1b081-4356-43aa-917a-7b40d4e65ead,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-bca28792-c3d6-4aac-a3e1-c030ba5e0321,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1695422719-172.17.0.9-1597311668146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44765,DS-c9f27722-6231-4a81-9705-3f8d72df69e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-06915e9f-5536-45b4-a7dc-b11659184d75,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-0d01e0e7-7146-4293-b13a-431f45adc61e,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-cea6151e-a26e-4c44-ac16-c600c948a358,DISK], DatanodeInfoWithStorage[127.0.0.1:33796,DS-4d81bb9a-358e-4064-bb14-be0d90f67404,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-96a71c81-3126-40eb-9f0e-dbf8f1ea2016,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-6372ab75-af2c-46bf-9514-8f2d4a9bcfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-b552bad7-7995-4fb5-b0b3-1574a842f95d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1695422719-172.17.0.9-1597311668146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44765,DS-c9f27722-6231-4a81-9705-3f8d72df69e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-06915e9f-5536-45b4-a7dc-b11659184d75,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-0d01e0e7-7146-4293-b13a-431f45adc61e,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-cea6151e-a26e-4c44-ac16-c600c948a358,DISK], DatanodeInfoWithStorage[127.0.0.1:33796,DS-4d81bb9a-358e-4064-bb14-be0d90f67404,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-96a71c81-3126-40eb-9f0e-dbf8f1ea2016,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-6372ab75-af2c-46bf-9514-8f2d4a9bcfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-b552bad7-7995-4fb5-b0b3-1574a842f95d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5452
