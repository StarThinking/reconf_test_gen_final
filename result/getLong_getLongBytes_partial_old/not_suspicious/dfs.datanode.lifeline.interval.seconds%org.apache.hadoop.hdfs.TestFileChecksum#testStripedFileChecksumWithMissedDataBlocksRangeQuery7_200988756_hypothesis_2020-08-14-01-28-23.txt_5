reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1874681869-172.17.0.15-1597368595329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44527,DS-aa99dbf5-7b94-43b9-b0a8-a7c92eda72c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-ee71d3dd-ca83-4d1a-90d7-4b56b2df437a,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-0a55edc3-0542-43cb-ab33-44d4493fffe2,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-a65c5397-322a-4442-b17b-87342d5ac169,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-3e71a5f3-11ab-44b4-b727-39c17307bcbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-45e602eb-5b0c-477e-bd11-7a041a5d1012,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-1afcb258-86ad-433f-bfcf-634b929075cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-1126ed3f-2bff-4a9b-a82b-155656f0335d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1874681869-172.17.0.15-1597368595329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44527,DS-aa99dbf5-7b94-43b9-b0a8-a7c92eda72c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-ee71d3dd-ca83-4d1a-90d7-4b56b2df437a,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-0a55edc3-0542-43cb-ab33-44d4493fffe2,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-a65c5397-322a-4442-b17b-87342d5ac169,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-3e71a5f3-11ab-44b4-b727-39c17307bcbf,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-45e602eb-5b0c-477e-bd11-7a041a5d1012,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-1afcb258-86ad-433f-bfcf-634b929075cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-1126ed3f-2bff-4a9b-a82b-155656f0335d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1997222169-172.17.0.15-1597368872113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33793,DS-0cb7112b-7fe1-49ee-b0d8-0f7028ad54f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-224fd4b8-dd60-4e64-a63f-233103c2fdbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-25017a92-14df-4093-a523-3d12d588b036,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-b806e17a-bd17-4b3e-a4f9-133157e4e513,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-6cb7305f-86d7-4c45-b0cb-3a23caa2b979,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-c5c043c8-1575-4616-877c-fb60bf5d066b,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-51e42f56-4c40-4f16-a26c-fcafdde9f1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-d439deab-3179-4f06-a74b-152c6c5a09b3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1997222169-172.17.0.15-1597368872113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33793,DS-0cb7112b-7fe1-49ee-b0d8-0f7028ad54f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-224fd4b8-dd60-4e64-a63f-233103c2fdbe,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-25017a92-14df-4093-a523-3d12d588b036,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-b806e17a-bd17-4b3e-a4f9-133157e4e513,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-6cb7305f-86d7-4c45-b0cb-3a23caa2b979,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-c5c043c8-1575-4616-877c-fb60bf5d066b,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-51e42f56-4c40-4f16-a26c-fcafdde9f1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-d439deab-3179-4f06-a74b-152c6c5a09b3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1127146414-172.17.0.15-1597368907648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35861,DS-fec6d756-f747-4992-9a3e-36ab08563e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-17720268-4605-4b51-856e-30be0a592392,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-91253dd1-2859-46b9-a66a-80990c1e61d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-42aefa23-aa83-4a6c-a957-25acc9db732d,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-7263fd49-55d0-4a45-a895-320d1bc88550,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-bb56af28-2ebe-4de7-9ae7-ce35a2483a86,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-98f00ceb-1c40-49e0-a5e6-d8ccd5b47f57,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-9a04fae7-bb13-4b78-92f5-9cf3a18334ca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1127146414-172.17.0.15-1597368907648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35861,DS-fec6d756-f747-4992-9a3e-36ab08563e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-17720268-4605-4b51-856e-30be0a592392,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-91253dd1-2859-46b9-a66a-80990c1e61d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-42aefa23-aa83-4a6c-a957-25acc9db732d,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-7263fd49-55d0-4a45-a895-320d1bc88550,DISK], DatanodeInfoWithStorage[127.0.0.1:33997,DS-bb56af28-2ebe-4de7-9ae7-ce35a2483a86,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-98f00ceb-1c40-49e0-a5e6-d8ccd5b47f57,DISK], DatanodeInfoWithStorage[127.0.0.1:32824,DS-9a04fae7-bb13-4b78-92f5-9cf3a18334ca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488259801-172.17.0.15-1597368981484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46203,DS-995b14a4-014b-4ecf-b6e8-e9615686eb50,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-590a0298-a774-4bb8-87b3-47674729df5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-3c785d49-8b17-4cff-a95f-9e0670f6a706,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-3409afb7-e589-40e6-a6a1-fbf1d289601b,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-9d9629a7-dfa2-4ffe-afb6-8e25f194a577,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-34ce063c-81ff-4376-8e93-7d2201096036,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-240309b3-e173-47f5-968b-4ec8f19119d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-bfd38b09-6451-455b-8904-cf1c9e6e757f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-488259801-172.17.0.15-1597368981484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46203,DS-995b14a4-014b-4ecf-b6e8-e9615686eb50,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-590a0298-a774-4bb8-87b3-47674729df5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-3c785d49-8b17-4cff-a95f-9e0670f6a706,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-3409afb7-e589-40e6-a6a1-fbf1d289601b,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-9d9629a7-dfa2-4ffe-afb6-8e25f194a577,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-34ce063c-81ff-4376-8e93-7d2201096036,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-240309b3-e173-47f5-968b-4ec8f19119d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-bfd38b09-6451-455b-8904-cf1c9e6e757f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2138725541-172.17.0.15-1597369053992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46625,DS-f07555d4-bb4e-4da8-8113-c4ff47399c58,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-a5633896-9750-4662-b80d-7580c0ff6d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40005,DS-a91691af-3257-4730-ae0b-60234bb5fbbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-accd92fa-398a-4210-bdb1-954acafc7b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-433807e4-e27e-49ef-9fd6-415a6e882edf,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-02ec0a15-e58f-476e-b4eb-e0c579da638b,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-ba89a6bb-5001-41b4-ac7e-034fe104c7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-12e8606e-d3fa-493b-b4eb-ae716ebaa33e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2138725541-172.17.0.15-1597369053992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46625,DS-f07555d4-bb4e-4da8-8113-c4ff47399c58,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-a5633896-9750-4662-b80d-7580c0ff6d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40005,DS-a91691af-3257-4730-ae0b-60234bb5fbbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-accd92fa-398a-4210-bdb1-954acafc7b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-433807e4-e27e-49ef-9fd6-415a6e882edf,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-02ec0a15-e58f-476e-b4eb-e0c579da638b,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-ba89a6bb-5001-41b4-ac7e-034fe104c7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-12e8606e-d3fa-493b-b4eb-ae716ebaa33e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2074473618-172.17.0.15-1597369281691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33470,DS-db2fdadc-db8e-4ea6-a588-3df6cde9e992,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-9003fd15-32f6-4327-b014-d6c3ddf86bce,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-a01b83c2-afb6-495e-9cb8-a6d25814da63,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-758f9920-e487-4063-9071-faa0854bdd0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-cf2ec05b-48f7-4abd-82cc-6e47e452276e,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-7067e1c2-5f02-4157-9f15-f54ed8e0a046,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-1aab4fbd-9150-44ee-acc2-145aa234876d,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-80d31f98-2299-4df9-b77c-8c753760cf71,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2074473618-172.17.0.15-1597369281691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33470,DS-db2fdadc-db8e-4ea6-a588-3df6cde9e992,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-9003fd15-32f6-4327-b014-d6c3ddf86bce,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-a01b83c2-afb6-495e-9cb8-a6d25814da63,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-758f9920-e487-4063-9071-faa0854bdd0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-cf2ec05b-48f7-4abd-82cc-6e47e452276e,DISK], DatanodeInfoWithStorage[127.0.0.1:35106,DS-7067e1c2-5f02-4157-9f15-f54ed8e0a046,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-1aab4fbd-9150-44ee-acc2-145aa234876d,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-80d31f98-2299-4df9-b77c-8c753760cf71,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794244326-172.17.0.15-1597369552509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37600,DS-d5b2e9b5-2655-456a-97dd-68ec4d826b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-9a37ecb4-5e98-492e-9558-e963c57b0c12,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-7319b198-85ce-4bd0-a291-52a7cfb4b9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-f74cde21-7af5-4c43-a357-da88fedee807,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-2feb6c4a-5bbf-4a09-bea7-2f871fd61fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-dba50bab-5ecf-414f-96fa-35dfe463d1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-a00cb431-ebef-4e08-b58e-5e933662b735,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-21c672ae-8e14-4c0e-9b05-10376201d045,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794244326-172.17.0.15-1597369552509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37600,DS-d5b2e9b5-2655-456a-97dd-68ec4d826b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-9a37ecb4-5e98-492e-9558-e963c57b0c12,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-7319b198-85ce-4bd0-a291-52a7cfb4b9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-f74cde21-7af5-4c43-a357-da88fedee807,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-2feb6c4a-5bbf-4a09-bea7-2f871fd61fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-dba50bab-5ecf-414f-96fa-35dfe463d1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-a00cb431-ebef-4e08-b58e-5e933662b735,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-21c672ae-8e14-4c0e-9b05-10376201d045,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347420061-172.17.0.15-1597369588081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41303,DS-53914681-d48b-4b97-b1bd-23b232f16198,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-d37f6396-1bb0-49b2-b4f3-004b528fed8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-07c4ca37-c143-47c9-a571-78e113fb8337,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-b8987a78-fdfc-4d02-93d4-d88fbaade5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-2f786b8c-fa8c-4a5a-a5aa-363b580e79e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-b32eed92-cfa1-4250-ace1-33662ba7baab,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-8a9c55e5-614a-47e4-aaeb-44e94e6396a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-fbecc2ba-cf76-4e65-8325-abbc4b2c102c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347420061-172.17.0.15-1597369588081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41303,DS-53914681-d48b-4b97-b1bd-23b232f16198,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-d37f6396-1bb0-49b2-b4f3-004b528fed8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-07c4ca37-c143-47c9-a571-78e113fb8337,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-b8987a78-fdfc-4d02-93d4-d88fbaade5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-2f786b8c-fa8c-4a5a-a5aa-363b580e79e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-b32eed92-cfa1-4250-ace1-33662ba7baab,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-8a9c55e5-614a-47e4-aaeb-44e94e6396a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-fbecc2ba-cf76-4e65-8325-abbc4b2c102c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697156761-172.17.0.15-1597369624616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34792,DS-c6853fef-0ae2-4e69-9eba-74afe97ea8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-cc49ff9f-f345-4da1-9d7e-dad847697853,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-6c5b0818-37e9-4115-a195-851a63f99211,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-85abb585-7456-4981-9cab-dbd5e768e1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-233bd49f-1c68-4041-af7e-7a89c0eee4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-2d466dda-a24a-4466-a5f1-600cafb7d596,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-eede89e4-aedc-4f8c-9271-98c5217b3dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-f03fdb29-0e8f-44bd-9233-582592079cb4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697156761-172.17.0.15-1597369624616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34792,DS-c6853fef-0ae2-4e69-9eba-74afe97ea8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-cc49ff9f-f345-4da1-9d7e-dad847697853,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-6c5b0818-37e9-4115-a195-851a63f99211,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-85abb585-7456-4981-9cab-dbd5e768e1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-233bd49f-1c68-4041-af7e-7a89c0eee4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-2d466dda-a24a-4466-a5f1-600cafb7d596,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-eede89e4-aedc-4f8c-9271-98c5217b3dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-f03fdb29-0e8f-44bd-9233-582592079cb4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-97698238-172.17.0.15-1597369658241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39306,DS-2886b4f2-bee0-4e85-8cce-8df86a2e08f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-e56edc13-a54b-4a6d-8c23-0bd89460a0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-2ac7099e-5352-49c2-a39b-b0a3ff534545,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-fa68f74d-686e-416a-87bd-b9ed729feb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-2aa1c684-3908-4a39-ade1-9326204cc1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-2e14ca3d-9bc8-48b1-8b9c-4a82e6029d75,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-de1862c6-0286-48b1-81d2-7bb8853c4c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-da3d6b55-cdc2-40e9-9cb0-17e87b2f25a0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-97698238-172.17.0.15-1597369658241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39306,DS-2886b4f2-bee0-4e85-8cce-8df86a2e08f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-e56edc13-a54b-4a6d-8c23-0bd89460a0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-2ac7099e-5352-49c2-a39b-b0a3ff534545,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-fa68f74d-686e-416a-87bd-b9ed729feb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-2aa1c684-3908-4a39-ade1-9326204cc1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-2e14ca3d-9bc8-48b1-8b9c-4a82e6029d75,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-de1862c6-0286-48b1-81d2-7bb8853c4c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-da3d6b55-cdc2-40e9-9cb0-17e87b2f25a0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1065463964-172.17.0.15-1597370149023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36217,DS-e3918d3c-a02e-47dd-a6f0-dc3aec0ae6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-197a93b5-2bab-4f1a-9b85-93252ea04125,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-d7b7cc92-a66f-4016-a720-437f2cb69466,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-b438498b-aedd-4805-acb1-0fd3700df322,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-bd02fd27-0ecf-4011-9b34-1eac315d01bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-17a84db6-0cee-4b83-9fdd-4c1d2e80b0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-e729300e-75e6-40c4-9550-304945f7a298,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-d43d0d6b-4f62-4b49-bab6-8646602138d0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1065463964-172.17.0.15-1597370149023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36217,DS-e3918d3c-a02e-47dd-a6f0-dc3aec0ae6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37874,DS-197a93b5-2bab-4f1a-9b85-93252ea04125,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-d7b7cc92-a66f-4016-a720-437f2cb69466,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-b438498b-aedd-4805-acb1-0fd3700df322,DISK], DatanodeInfoWithStorage[127.0.0.1:37058,DS-bd02fd27-0ecf-4011-9b34-1eac315d01bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-17a84db6-0cee-4b83-9fdd-4c1d2e80b0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41661,DS-e729300e-75e6-40c4-9550-304945f7a298,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-d43d0d6b-4f62-4b49-bab6-8646602138d0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-703162312-172.17.0.15-1597370317720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46468,DS-bfe7416e-3c99-43db-8c9a-5488ab2c1cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-f1643681-ca4b-4491-8277-0a940bb00491,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-431a0612-7cc5-49c4-a456-d183a211465e,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-90cf7af1-6190-449d-beeb-95f4c8c89fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-91ee0aae-4ae7-4c5c-8d83-326cf3929357,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-df8e701b-ddd5-4f1c-baee-1b0c2aa88b19,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-8d433853-1ce0-458b-9d1f-bb522ac77c43,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-6d8ff45a-bae1-4356-a98d-b242c420ad5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-703162312-172.17.0.15-1597370317720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46468,DS-bfe7416e-3c99-43db-8c9a-5488ab2c1cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-f1643681-ca4b-4491-8277-0a940bb00491,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-431a0612-7cc5-49c4-a456-d183a211465e,DISK], DatanodeInfoWithStorage[127.0.0.1:34154,DS-90cf7af1-6190-449d-beeb-95f4c8c89fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-91ee0aae-4ae7-4c5c-8d83-326cf3929357,DISK], DatanodeInfoWithStorage[127.0.0.1:42002,DS-df8e701b-ddd5-4f1c-baee-1b0c2aa88b19,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-8d433853-1ce0-458b-9d1f-bb522ac77c43,DISK], DatanodeInfoWithStorage[127.0.0.1:36323,DS-6d8ff45a-bae1-4356-a98d-b242c420ad5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1579314143-172.17.0.15-1597370416745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33913,DS-f652da57-95ce-4690-97d3-f8ee705e1306,DISK], DatanodeInfoWithStorage[127.0.0.1:44417,DS-ad9a908e-6efa-4637-af81-344b7dc00b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-aa0cae4e-f90c-4240-9a88-bb9efc9fa9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-0b401969-68e2-4451-a085-4d20ae940f37,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-333952aa-c5a4-4a0e-b982-c0917e5e2c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-2fc5aaf3-5d2a-41c3-97a7-661a7cc89d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-cd3bfc6d-cd0f-43a4-b662-34f868062c11,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-d777f6bd-bcae-4aaa-bf68-5e77008a1b39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1579314143-172.17.0.15-1597370416745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33913,DS-f652da57-95ce-4690-97d3-f8ee705e1306,DISK], DatanodeInfoWithStorage[127.0.0.1:44417,DS-ad9a908e-6efa-4637-af81-344b7dc00b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-aa0cae4e-f90c-4240-9a88-bb9efc9fa9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-0b401969-68e2-4451-a085-4d20ae940f37,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-333952aa-c5a4-4a0e-b982-c0917e5e2c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35200,DS-2fc5aaf3-5d2a-41c3-97a7-661a7cc89d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-cd3bfc6d-cd0f-43a4-b662-34f868062c11,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-d777f6bd-bcae-4aaa-bf68-5e77008a1b39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1946550264-172.17.0.15-1597370489188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41553,DS-15b3d286-f4a3-44c6-8c0b-ad8f61de984d,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-43bbf859-effe-4528-a0d1-1cf53bc2b2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-dad9f09f-cc76-4b2d-a359-ee1ba267cf12,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-36311fe1-6ea0-4c1d-8908-70d9e2cb78da,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-b2d93477-406e-40ed-9d6d-e306de5edd94,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-6cf6772c-c004-4ece-9ff7-20845fbfef53,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-638710ec-012f-4b8b-8ca3-6108edd761b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-2dde94a6-33e5-4cfd-a24d-e075df8f7b25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1946550264-172.17.0.15-1597370489188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41553,DS-15b3d286-f4a3-44c6-8c0b-ad8f61de984d,DISK], DatanodeInfoWithStorage[127.0.0.1:41983,DS-43bbf859-effe-4528-a0d1-1cf53bc2b2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-dad9f09f-cc76-4b2d-a359-ee1ba267cf12,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-36311fe1-6ea0-4c1d-8908-70d9e2cb78da,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-b2d93477-406e-40ed-9d6d-e306de5edd94,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-6cf6772c-c004-4ece-9ff7-20845fbfef53,DISK], DatanodeInfoWithStorage[127.0.0.1:33010,DS-638710ec-012f-4b8b-8ca3-6108edd761b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-2dde94a6-33e5-4cfd-a24d-e075df8f7b25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2054713562-172.17.0.15-1597370775578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33918,DS-f072b1db-efb0-46a2-a4af-cbd95b5f55e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-f9a40d95-5595-420e-80f9-075eb9b085c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-15f0e2a4-9681-460e-9323-0a2bfc1a0031,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-1eb51c47-c276-44ef-8783-65d6ace55c92,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-2809c52f-ec94-4131-bede-5a5ba8f20c81,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-8bd75329-87d9-45ee-8efd-c1cd1374937e,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-20aa027f-03dd-4c8f-8c5c-149692d9ce5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-b229698d-87b8-441a-9fed-689e3cff9a21,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2054713562-172.17.0.15-1597370775578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33918,DS-f072b1db-efb0-46a2-a4af-cbd95b5f55e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-f9a40d95-5595-420e-80f9-075eb9b085c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-15f0e2a4-9681-460e-9323-0a2bfc1a0031,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-1eb51c47-c276-44ef-8783-65d6ace55c92,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-2809c52f-ec94-4131-bede-5a5ba8f20c81,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-8bd75329-87d9-45ee-8efd-c1cd1374937e,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-20aa027f-03dd-4c8f-8c5c-149692d9ce5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-b229698d-87b8-441a-9fed-689e3cff9a21,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456776447-172.17.0.15-1597370915915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33414,DS-68b526a7-cb4d-408e-83eb-8d1bf81c024a,DISK], DatanodeInfoWithStorage[127.0.0.1:39710,DS-63cfbedc-b7c2-4050-b302-3c0f0c90d88f,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-4781c69e-f03a-4868-bb1f-7d921a167510,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-ae4ed302-db91-4bb9-beab-5a55205683e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-8b8ca720-8cd4-47f6-847f-11d930682751,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-3175df42-73ec-471c-a910-8340a74d5ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-5ecc2df1-77ed-492a-bbd3-fbfa52708ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-bf6555dc-aba2-4d8f-a429-e1aaad74b328,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456776447-172.17.0.15-1597370915915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33414,DS-68b526a7-cb4d-408e-83eb-8d1bf81c024a,DISK], DatanodeInfoWithStorage[127.0.0.1:39710,DS-63cfbedc-b7c2-4050-b302-3c0f0c90d88f,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-4781c69e-f03a-4868-bb1f-7d921a167510,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-ae4ed302-db91-4bb9-beab-5a55205683e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-8b8ca720-8cd4-47f6-847f-11d930682751,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-3175df42-73ec-471c-a910-8340a74d5ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-5ecc2df1-77ed-492a-bbd3-fbfa52708ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-bf6555dc-aba2-4d8f-a429-e1aaad74b328,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1134160743-172.17.0.15-1597371092605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45033,DS-72dbd6de-0dd1-4ddb-ba3b-c849e6cdd1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-f7c9f722-6757-4464-a04c-e3574d6fa83c,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-9e247c17-44c6-4e1d-bcf8-be74befd08ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-ef6d051f-ec46-4e21-95fa-541e01fb8577,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-fb79a36f-a4ee-4228-9015-66786c2d2035,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-b299c0b2-3331-431e-aed8-097694795208,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-54da216c-a128-479c-938d-4eab3cf7ea06,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-2c66eaa1-8298-4c68-bbdf-f27163166864,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1134160743-172.17.0.15-1597371092605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45033,DS-72dbd6de-0dd1-4ddb-ba3b-c849e6cdd1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-f7c9f722-6757-4464-a04c-e3574d6fa83c,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-9e247c17-44c6-4e1d-bcf8-be74befd08ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-ef6d051f-ec46-4e21-95fa-541e01fb8577,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-fb79a36f-a4ee-4228-9015-66786c2d2035,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-b299c0b2-3331-431e-aed8-097694795208,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-54da216c-a128-479c-938d-4eab3cf7ea06,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-2c66eaa1-8298-4c68-bbdf-f27163166864,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-477254611-172.17.0.15-1597371272673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46260,DS-85b93f79-51f4-4145-a29a-f0715d6ea841,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-72da310b-8e83-4db6-984d-0b822803a667,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-12a6e91f-8790-42b8-a941-d25ba399e497,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-793ccf3d-8237-4161-b8e3-3013dee359a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-dd834706-d236-4dda-8600-237a5d3f2d90,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-87f72749-f383-44f1-8329-9cb80bd6a3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-423e1b59-4d47-4a32-8089-b50a05b35bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-0fc779e3-78eb-4d21-9b91-2520c907f202,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-477254611-172.17.0.15-1597371272673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46260,DS-85b93f79-51f4-4145-a29a-f0715d6ea841,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-72da310b-8e83-4db6-984d-0b822803a667,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-12a6e91f-8790-42b8-a941-d25ba399e497,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-793ccf3d-8237-4161-b8e3-3013dee359a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-dd834706-d236-4dda-8600-237a5d3f2d90,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-87f72749-f383-44f1-8329-9cb80bd6a3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-423e1b59-4d47-4a32-8089-b50a05b35bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-0fc779e3-78eb-4d21-9b91-2520c907f202,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-909588592-172.17.0.15-1597371352078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33944,DS-f48ea0eb-c021-4ae7-9691-1bbdd39c1300,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-7c47f44d-a535-4575-bf6e-72b4b0b6d3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-a6c0135c-bf76-42e9-ba6d-2d0e500c2a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-ec10158e-c9a3-427f-aa65-cf8a67620ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-fd5749da-3755-4d49-bc1c-e977825b8a48,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-f1c2e136-141f-40f8-a749-f3362247895c,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-31486018-5e8c-4512-b47a-4a7000c4cfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-1c14d599-17eb-4ca1-86e3-5ef1395f1e94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-909588592-172.17.0.15-1597371352078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33944,DS-f48ea0eb-c021-4ae7-9691-1bbdd39c1300,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-7c47f44d-a535-4575-bf6e-72b4b0b6d3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-a6c0135c-bf76-42e9-ba6d-2d0e500c2a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-ec10158e-c9a3-427f-aa65-cf8a67620ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-fd5749da-3755-4d49-bc1c-e977825b8a48,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-f1c2e136-141f-40f8-a749-f3362247895c,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-31486018-5e8c-4512-b47a-4a7000c4cfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-1c14d599-17eb-4ca1-86e3-5ef1395f1e94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1727772758-172.17.0.15-1597371466054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44025,DS-5ad07e8d-cd7b-45f5-a9b0-a68846194651,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-6e6bb532-6372-49e6-b5af-8e8250c0fb40,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-178765cc-266f-4e81-834a-86a2d55bb785,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-ba052e25-6b52-4bcb-8870-01563e210101,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-95aec888-bbf3-4983-98bc-adf383f561c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-0135da48-68b1-4810-80e2-0333f8326d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45250,DS-8124c516-7360-42c1-8f87-196202bfeb34,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-10d0918a-9480-4d5e-95fc-9d9eca471a2e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1727772758-172.17.0.15-1597371466054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44025,DS-5ad07e8d-cd7b-45f5-a9b0-a68846194651,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-6e6bb532-6372-49e6-b5af-8e8250c0fb40,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-178765cc-266f-4e81-834a-86a2d55bb785,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-ba052e25-6b52-4bcb-8870-01563e210101,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-95aec888-bbf3-4983-98bc-adf383f561c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-0135da48-68b1-4810-80e2-0333f8326d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:45250,DS-8124c516-7360-42c1-8f87-196202bfeb34,DISK], DatanodeInfoWithStorage[127.0.0.1:34978,DS-10d0918a-9480-4d5e-95fc-9d9eca471a2e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1983214197-172.17.0.15-1597371502920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45013,DS-3201052b-651d-4124-a70f-e8d5a8a1d136,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-ac11237f-b8da-492a-83e5-5627466f5a79,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-19af6d5f-fa02-4a19-83db-e179432a9853,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-0bf2eeaf-d5e0-41ee-88f5-dc242cfe6c34,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-29b04f94-8401-4702-bf57-4b183c4a79fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-3f671aae-26fb-4d0b-8f41-0dd9c4677bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-76579348-c635-46a0-ae9a-84535ff512e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-03472028-35f8-4a65-8d2d-261e1ddaaf2d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1983214197-172.17.0.15-1597371502920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45013,DS-3201052b-651d-4124-a70f-e8d5a8a1d136,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-ac11237f-b8da-492a-83e5-5627466f5a79,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-19af6d5f-fa02-4a19-83db-e179432a9853,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-0bf2eeaf-d5e0-41ee-88f5-dc242cfe6c34,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-29b04f94-8401-4702-bf57-4b183c4a79fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-3f671aae-26fb-4d0b-8f41-0dd9c4677bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-76579348-c635-46a0-ae9a-84535ff512e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-03472028-35f8-4a65-8d2d-261e1ddaaf2d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-676007552-172.17.0.15-1597371640886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44257,DS-9cb758c3-4d45-4b73-8d72-bd7d791133e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-0da3cb94-3bca-4c22-82da-102bd5ea954a,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-4ad728f1-04d8-4eec-882f-bb7e72053ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-aba28854-9a40-4292-91f6-7df2759cf7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-a0091a49-0457-479e-adf4-79d44b5f3d01,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-44541638-df22-4633-8608-e66c8fea4699,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-4128d3e9-07b0-4919-bd79-07443f85a64d,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-6c3acb74-5218-44c3-8ab5-b834e288e6a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-676007552-172.17.0.15-1597371640886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44257,DS-9cb758c3-4d45-4b73-8d72-bd7d791133e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-0da3cb94-3bca-4c22-82da-102bd5ea954a,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-4ad728f1-04d8-4eec-882f-bb7e72053ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-aba28854-9a40-4292-91f6-7df2759cf7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-a0091a49-0457-479e-adf4-79d44b5f3d01,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-44541638-df22-4633-8608-e66c8fea4699,DISK], DatanodeInfoWithStorage[127.0.0.1:36596,DS-4128d3e9-07b0-4919-bd79-07443f85a64d,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-6c3acb74-5218-44c3-8ab5-b834e288e6a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214758366-172.17.0.15-1597371754178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36212,DS-2c1e49bc-1337-45d0-a4f0-c5d94308812c,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-3b319cb6-eb06-4b37-91ea-87042433145c,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-85e4d70c-2ec4-4b4e-aabd-db4278ac3abd,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-6a2de337-db7c-4504-85f6-eb30f3a0b4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-2ed36d4a-5726-4e8e-b172-498145091c14,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-624f8616-bec7-4446-9d78-97fc7ff151f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-5837d9ce-72ad-41fc-84b2-ee3ab5d3b106,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-3e84a53a-f357-42b6-ab31-1f2d53b14723,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214758366-172.17.0.15-1597371754178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36212,DS-2c1e49bc-1337-45d0-a4f0-c5d94308812c,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-3b319cb6-eb06-4b37-91ea-87042433145c,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-85e4d70c-2ec4-4b4e-aabd-db4278ac3abd,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-6a2de337-db7c-4504-85f6-eb30f3a0b4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40913,DS-2ed36d4a-5726-4e8e-b172-498145091c14,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-624f8616-bec7-4446-9d78-97fc7ff151f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-5837d9ce-72ad-41fc-84b2-ee3ab5d3b106,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-3e84a53a-f357-42b6-ab31-1f2d53b14723,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211576771-172.17.0.15-1597371824523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41201,DS-78d83714-2f44-4c40-9135-31357a368035,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-9cce748e-64b5-411a-bf1e-0713432f2002,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-468e3a2e-2e0a-4709-a840-5f9486ec1336,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-c74fa80b-8b9e-490a-a65b-b6fc1f5e9eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-c8874cb7-e5a5-42cf-a19c-4cf2acc6f35c,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-64dfe87c-67c6-4a1d-95d4-2880459e1d13,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-c2326c91-b971-4574-98d5-04b82926118c,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-87f64173-c9a2-4dc8-a37c-58d0c0d333ca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211576771-172.17.0.15-1597371824523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41201,DS-78d83714-2f44-4c40-9135-31357a368035,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-9cce748e-64b5-411a-bf1e-0713432f2002,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-468e3a2e-2e0a-4709-a840-5f9486ec1336,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-c74fa80b-8b9e-490a-a65b-b6fc1f5e9eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-c8874cb7-e5a5-42cf-a19c-4cf2acc6f35c,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-64dfe87c-67c6-4a1d-95d4-2880459e1d13,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-c2326c91-b971-4574-98d5-04b82926118c,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-87f64173-c9a2-4dc8-a37c-58d0c0d333ca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2129103885-172.17.0.15-1597371901014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46811,DS-8e18d686-739c-462a-8464-106c0384b051,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-1d58278d-cd98-42ed-8535-b2c26e31588b,DISK], DatanodeInfoWithStorage[127.0.0.1:46579,DS-adeddaf5-4b3e-456a-8890-7044acb108f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-3267e9a2-8339-4581-857b-80afa727b03a,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-ebb8e40e-e51d-41b9-b74c-93f639a04c36,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-a03c70ce-891e-452c-a773-ed33946b17ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-897bc71d-598d-4687-98c6-d37b9ec58963,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-f667e584-44c8-433f-abd4-ba24ed2970ed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2129103885-172.17.0.15-1597371901014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46811,DS-8e18d686-739c-462a-8464-106c0384b051,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-1d58278d-cd98-42ed-8535-b2c26e31588b,DISK], DatanodeInfoWithStorage[127.0.0.1:46579,DS-adeddaf5-4b3e-456a-8890-7044acb108f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-3267e9a2-8339-4581-857b-80afa727b03a,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-ebb8e40e-e51d-41b9-b74c-93f639a04c36,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-a03c70ce-891e-452c-a773-ed33946b17ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-897bc71d-598d-4687-98c6-d37b9ec58963,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-f667e584-44c8-433f-abd4-ba24ed2970ed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-485764495-172.17.0.15-1597372115405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43131,DS-33d2450b-cabb-4fd9-ae9f-7cb89d1df4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-fa1dbcd2-1b66-4ad8-915c-ffe1fc36dd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-8b1faf74-a33c-40eb-ba1c-7429aafb8ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-b68fbf53-0008-4897-bec6-5c99151f9d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-2fa01b9e-ea48-430d-ab76-73206125e903,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-3ddf5bab-feb3-443b-ac40-d0453a3bc99a,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-9773adeb-b95d-4b0d-a942-e904bce2a9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-a4119ca8-517a-4ab7-ab87-4abb58368ccd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-485764495-172.17.0.15-1597372115405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43131,DS-33d2450b-cabb-4fd9-ae9f-7cb89d1df4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-fa1dbcd2-1b66-4ad8-915c-ffe1fc36dd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-8b1faf74-a33c-40eb-ba1c-7429aafb8ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-b68fbf53-0008-4897-bec6-5c99151f9d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-2fa01b9e-ea48-430d-ab76-73206125e903,DISK], DatanodeInfoWithStorage[127.0.0.1:35433,DS-3ddf5bab-feb3-443b-ac40-d0453a3bc99a,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-9773adeb-b95d-4b0d-a942-e904bce2a9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-a4119ca8-517a-4ab7-ab87-4abb58368ccd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347860268-172.17.0.15-1597372229886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44915,DS-f4efe96d-1562-4e66-88f7-eff2b539338c,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-728c7adf-694b-4ade-bda4-d9ade97ec6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-4a52de2c-32f3-4e47-9ceb-538c9f89c4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-3baf98e6-2689-466f-b0d5-8c666834bc1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-28b71381-ea2a-4aa6-8723-4c266ebef201,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-83f8d82f-e449-45ae-8c62-b1b7e772e1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-4bc574a0-150e-4490-98ff-b383163342f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-dd0b9fe0-8c8e-47b5-9500-26bddf128b13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347860268-172.17.0.15-1597372229886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44915,DS-f4efe96d-1562-4e66-88f7-eff2b539338c,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-728c7adf-694b-4ade-bda4-d9ade97ec6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-4a52de2c-32f3-4e47-9ceb-538c9f89c4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-3baf98e6-2689-466f-b0d5-8c666834bc1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-28b71381-ea2a-4aa6-8723-4c266ebef201,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-83f8d82f-e449-45ae-8c62-b1b7e772e1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-4bc574a0-150e-4490-98ff-b383163342f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-dd0b9fe0-8c8e-47b5-9500-26bddf128b13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1580204113-172.17.0.15-1597372529052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45465,DS-2b715b3e-d4c3-4374-929e-5af3ae2388c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-8317be07-6b2b-4f22-b811-3e57c0808090,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-5a80ddc7-ae68-4470-ba1e-285f8d6f9e29,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-d8195113-5ce2-4bc0-9926-dea406781740,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-74c3230d-0c3f-4724-850a-7e7aae2a07d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-f36ffc59-291f-494d-977f-514b73152609,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-93ee1c96-9da9-45d6-9759-5294d7bbcfb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-54fe4028-c034-4b10-98a2-f198f6e011f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1580204113-172.17.0.15-1597372529052:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45465,DS-2b715b3e-d4c3-4374-929e-5af3ae2388c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-8317be07-6b2b-4f22-b811-3e57c0808090,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-5a80ddc7-ae68-4470-ba1e-285f8d6f9e29,DISK], DatanodeInfoWithStorage[127.0.0.1:35311,DS-d8195113-5ce2-4bc0-9926-dea406781740,DISK], DatanodeInfoWithStorage[127.0.0.1:35966,DS-74c3230d-0c3f-4724-850a-7e7aae2a07d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34838,DS-f36ffc59-291f-494d-977f-514b73152609,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-93ee1c96-9da9-45d6-9759-5294d7bbcfb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-54fe4028-c034-4b10-98a2-f198f6e011f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1355116287-172.17.0.15-1597372569382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37482,DS-7f06cdba-b281-45bc-b62e-380e11fe8d00,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-0c36dc26-5b69-46fa-a0db-7047bb41619d,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-cdd7bb03-f9e3-4d14-bb9a-a71e3b5298da,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-b5ea4c1a-d4aa-4e2e-a60f-ed85e507f9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-cf894a67-b710-4044-9dac-82fbd4882e34,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-0bb2e0a3-d1cf-4744-9152-ead9d50f2de7,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-be450f7d-0e94-4e86-876c-eb088ce6feb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-4322b8fa-b753-4fc3-8b65-5c73be35d2db,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1355116287-172.17.0.15-1597372569382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37482,DS-7f06cdba-b281-45bc-b62e-380e11fe8d00,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-0c36dc26-5b69-46fa-a0db-7047bb41619d,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-cdd7bb03-f9e3-4d14-bb9a-a71e3b5298da,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-b5ea4c1a-d4aa-4e2e-a60f-ed85e507f9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:32778,DS-cf894a67-b710-4044-9dac-82fbd4882e34,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-0bb2e0a3-d1cf-4744-9152-ead9d50f2de7,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-be450f7d-0e94-4e86-876c-eb088ce6feb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-4322b8fa-b753-4fc3-8b65-5c73be35d2db,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1689150698-172.17.0.15-1597372712854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41522,DS-d4d00c9e-b1fc-4080-97f3-465aa8b84312,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-5f4817e2-8a1e-479e-b6e2-93bc04ad57a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-df4bfea8-fc64-40bf-b53b-cb7e64e1dc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-7a4c1431-1dac-4624-a45a-6a5b376e71bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-b8a5ec0a-4a70-4a71-8625-6d535f32ce1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-5fc73b13-68a2-4444-aa35-666cc60386b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-78444057-d561-42ce-b450-ab97dd1962a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-9cc2b467-7fce-4991-97f6-99c45051a896,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1689150698-172.17.0.15-1597372712854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41522,DS-d4d00c9e-b1fc-4080-97f3-465aa8b84312,DISK], DatanodeInfoWithStorage[127.0.0.1:37392,DS-5f4817e2-8a1e-479e-b6e2-93bc04ad57a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-df4bfea8-fc64-40bf-b53b-cb7e64e1dc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-7a4c1431-1dac-4624-a45a-6a5b376e71bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-b8a5ec0a-4a70-4a71-8625-6d535f32ce1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-5fc73b13-68a2-4444-aa35-666cc60386b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-78444057-d561-42ce-b450-ab97dd1962a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-9cc2b467-7fce-4991-97f6-99c45051a896,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-955314718-172.17.0.15-1597373019971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37600,DS-eef773c9-9a11-42aa-8122-19b73e8dc5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-2a531fa0-0e53-4705-b232-6ddd63d022b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-cdd9e6d4-3ab8-4c64-af48-eedfe79ab711,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-447a5dc6-b5a5-47a5-a961-b098e433a024,DISK], DatanodeInfoWithStorage[127.0.0.1:35943,DS-b978fc54-a80f-4af2-a960-e02e51293be8,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-55d968a3-4b33-49b2-bd54-78f1c96d10c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-ed4d7858-1c75-4836-b66f-fa271bd6a44c,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-379f90d2-c8c3-4a9c-a4e0-9cbc5d3e9b89,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-955314718-172.17.0.15-1597373019971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37600,DS-eef773c9-9a11-42aa-8122-19b73e8dc5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-2a531fa0-0e53-4705-b232-6ddd63d022b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-cdd9e6d4-3ab8-4c64-af48-eedfe79ab711,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-447a5dc6-b5a5-47a5-a961-b098e433a024,DISK], DatanodeInfoWithStorage[127.0.0.1:35943,DS-b978fc54-a80f-4af2-a960-e02e51293be8,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-55d968a3-4b33-49b2-bd54-78f1c96d10c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-ed4d7858-1c75-4836-b66f-fa271bd6a44c,DISK], DatanodeInfoWithStorage[127.0.0.1:38531,DS-379f90d2-c8c3-4a9c-a4e0-9cbc5d3e9b89,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315847684-172.17.0.15-1597373088736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34432,DS-b7ceffab-8c6d-4c07-a3c0-566766754069,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-5fd220a0-fc41-47d4-9da0-9fe1843e1081,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-d6473637-f687-4c92-9c26-e832ae147d44,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-0fed484f-bd45-49de-a919-49d931ee5d64,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-a5961808-6dda-49ea-ab13-253dcb8448ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-abb13251-e733-41cb-a6fb-383a8af3709d,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-ddadf346-3187-4794-a73a-c9db7fcad010,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-65d2f4ce-95b1-4f34-b635-305838463e74,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315847684-172.17.0.15-1597373088736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34432,DS-b7ceffab-8c6d-4c07-a3c0-566766754069,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-5fd220a0-fc41-47d4-9da0-9fe1843e1081,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-d6473637-f687-4c92-9c26-e832ae147d44,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-0fed484f-bd45-49de-a919-49d931ee5d64,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-a5961808-6dda-49ea-ab13-253dcb8448ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-abb13251-e733-41cb-a6fb-383a8af3709d,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-ddadf346-3187-4794-a73a-c9db7fcad010,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-65d2f4ce-95b1-4f34-b635-305838463e74,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046411882-172.17.0.15-1597373155237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40006,DS-a99508ce-03b1-449e-9a59-67485cbc601f,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-d055239e-5532-429c-b425-ee8aa37dc013,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-92078c77-5e94-4c09-ad8f-eab7b03ce016,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-679ba878-be59-409a-a022-745d38ff48a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-aec8b12b-602a-4b76-8d7f-a44001d075f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-04bd826d-77cb-42a8-b673-8d7b967e09f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-52816f42-25a7-493f-aa5f-9750e18b0df9,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-2db12691-2887-402a-ae80-8a5185a47973,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1046411882-172.17.0.15-1597373155237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40006,DS-a99508ce-03b1-449e-9a59-67485cbc601f,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-d055239e-5532-429c-b425-ee8aa37dc013,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-92078c77-5e94-4c09-ad8f-eab7b03ce016,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-679ba878-be59-409a-a022-745d38ff48a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-aec8b12b-602a-4b76-8d7f-a44001d075f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-04bd826d-77cb-42a8-b673-8d7b967e09f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41013,DS-52816f42-25a7-493f-aa5f-9750e18b0df9,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-2db12691-2887-402a-ae80-8a5185a47973,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879444360-172.17.0.15-1597373189980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37534,DS-ae0d8a56-f60f-48eb-b178-72106e2965ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-19549596-74e8-41c3-b57c-50b2eb2577be,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-5d5af657-9d1c-4182-86cf-f66566a3937b,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-5f0d4a94-3202-4178-88e2-e5a906070fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-ad93aece-c40d-471a-a051-fd7bf95bb53f,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-0f682bd3-c0ef-4c20-b50f-e4a532803f94,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-f5eec8a2-8166-4a41-a7f3-2be7d218d36d,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-f99faac2-8c43-4d12-9f48-b1b46dc66f40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879444360-172.17.0.15-1597373189980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37534,DS-ae0d8a56-f60f-48eb-b178-72106e2965ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-19549596-74e8-41c3-b57c-50b2eb2577be,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-5d5af657-9d1c-4182-86cf-f66566a3937b,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-5f0d4a94-3202-4178-88e2-e5a906070fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-ad93aece-c40d-471a-a051-fd7bf95bb53f,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-0f682bd3-c0ef-4c20-b50f-e4a532803f94,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-f5eec8a2-8166-4a41-a7f3-2be7d218d36d,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-f99faac2-8c43-4d12-9f48-b1b46dc66f40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1813409490-172.17.0.15-1597373264303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40651,DS-44178d4a-410e-4650-9782-52dff87a781a,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-ba57da20-9968-4412-a5a6-92d35e743b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-b3b38783-b8ff-43f1-8cc1-487b86fa60e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-fd68c0fd-0021-4180-9bef-49b290b74a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-ab536bc8-4613-40d0-bd51-7aa820072ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-f0d7b4d0-39ce-4d5d-8405-22600c15b7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-3d1d8b4c-1221-4547-b471-ac8f3347cc57,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-101ae9d2-292e-4f32-b0cf-8cb3e3f341b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1813409490-172.17.0.15-1597373264303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40651,DS-44178d4a-410e-4650-9782-52dff87a781a,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-ba57da20-9968-4412-a5a6-92d35e743b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-b3b38783-b8ff-43f1-8cc1-487b86fa60e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-fd68c0fd-0021-4180-9bef-49b290b74a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-ab536bc8-4613-40d0-bd51-7aa820072ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-f0d7b4d0-39ce-4d5d-8405-22600c15b7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-3d1d8b4c-1221-4547-b471-ac8f3347cc57,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-101ae9d2-292e-4f32-b0cf-8cb3e3f341b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1951058544-172.17.0.15-1597373423970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34674,DS-0a1ba32b-03e9-45ad-aebf-642479642066,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-0e99a8a9-d470-47b8-b9b5-f94a7b311c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-2727faa1-f54a-438c-bde1-c09a5fee461a,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-e8d30f6e-4ab9-4168-a8f8-6980b25c13cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-6dd126e4-c76e-437b-9582-eda602d98ced,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-1d703cf1-7e7f-41a9-905d-a091ff67dd36,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-25f898d9-05ed-441c-a726-677d737b95ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-c8652f0e-ddbb-464d-b70f-5638bd0141fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1951058544-172.17.0.15-1597373423970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34674,DS-0a1ba32b-03e9-45ad-aebf-642479642066,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-0e99a8a9-d470-47b8-b9b5-f94a7b311c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-2727faa1-f54a-438c-bde1-c09a5fee461a,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-e8d30f6e-4ab9-4168-a8f8-6980b25c13cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-6dd126e4-c76e-437b-9582-eda602d98ced,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-1d703cf1-7e7f-41a9-905d-a091ff67dd36,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-25f898d9-05ed-441c-a726-677d737b95ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-c8652f0e-ddbb-464d-b70f-5638bd0141fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-986014857-172.17.0.15-1597373734049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36999,DS-4ddf5216-d3eb-478f-a650-b8c0d9b8e64e,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-2366a6a8-dba1-4b09-9f13-1de529d71f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-0aeb5c1c-1e3f-4762-91dc-469033b07ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-8a0aab3a-6f5c-4008-a876-9a770bf5ca42,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-ce79fec6-cd07-46fa-9daa-df4b714a7413,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-0f3e53ee-0c8b-4406-a894-32ddf41e58cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-fb38985c-a05d-4d71-924c-4bf3d8517215,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-1e53f40f-380a-4194-8ae2-b408c7c1c8d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-986014857-172.17.0.15-1597373734049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36999,DS-4ddf5216-d3eb-478f-a650-b8c0d9b8e64e,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-2366a6a8-dba1-4b09-9f13-1de529d71f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-0aeb5c1c-1e3f-4762-91dc-469033b07ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-8a0aab3a-6f5c-4008-a876-9a770bf5ca42,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-ce79fec6-cd07-46fa-9daa-df4b714a7413,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-0f3e53ee-0c8b-4406-a894-32ddf41e58cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-fb38985c-a05d-4d71-924c-4bf3d8517215,DISK], DatanodeInfoWithStorage[127.0.0.1:38951,DS-1e53f40f-380a-4194-8ae2-b408c7c1c8d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 15 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 5328
