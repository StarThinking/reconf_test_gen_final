reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1755024079-172.17.0.16-1597506995463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41502,DS-332656d8-cd9b-40a3-abd5-5122a1802552,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-524ef5e4-3efd-4d5f-94f7-13c6ebeeb0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-6ee9c239-3451-40ca-9f59-c0ed124c4dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-7eef6a21-84a0-4195-b164-68c0ec32409a,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-9ab3c97b-01f4-44c0-a69e-c139b53f85a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-4b0bf18b-f573-4c02-b1fb-12332b43e354,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-22dc4759-3bc9-427f-ab06-b5d2fd70460f,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-0a9f92e6-7c87-4eb3-ac1e-6279dc85f553,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1755024079-172.17.0.16-1597506995463:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41502,DS-332656d8-cd9b-40a3-abd5-5122a1802552,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-524ef5e4-3efd-4d5f-94f7-13c6ebeeb0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-6ee9c239-3451-40ca-9f59-c0ed124c4dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-7eef6a21-84a0-4195-b164-68c0ec32409a,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-9ab3c97b-01f4-44c0-a69e-c139b53f85a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-4b0bf18b-f573-4c02-b1fb-12332b43e354,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-22dc4759-3bc9-427f-ab06-b5d2fd70460f,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-0a9f92e6-7c87-4eb3-ac1e-6279dc85f553,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1863753570-172.17.0.16-1597508087057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39893,DS-485fe5a2-ff06-4e71-bb13-d48d13f3dc78,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-27558110-3a57-4a2c-84c5-6843f15a0091,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-fe135aa4-92d8-4053-886d-933bc40c94ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-52237e5c-ef08-47a2-834c-c46b64ed132f,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-dec4c41a-5a98-4a17-b38f-4bd07723f840,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-896c9242-385a-43a0-8234-f87022befbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-6b6ce794-45f1-4e38-85ef-c2651c7389b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-95753a72-084e-439d-af47-e1f931d0f35d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1863753570-172.17.0.16-1597508087057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39893,DS-485fe5a2-ff06-4e71-bb13-d48d13f3dc78,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-27558110-3a57-4a2c-84c5-6843f15a0091,DISK], DatanodeInfoWithStorage[127.0.0.1:33266,DS-fe135aa4-92d8-4053-886d-933bc40c94ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-52237e5c-ef08-47a2-834c-c46b64ed132f,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-dec4c41a-5a98-4a17-b38f-4bd07723f840,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-896c9242-385a-43a0-8234-f87022befbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-6b6ce794-45f1-4e38-85ef-c2651c7389b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-95753a72-084e-439d-af47-e1f931d0f35d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1074666972-172.17.0.16-1597508232350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44698,DS-1a7f36bd-99c7-4fc0-af3c-4b8c9bf34212,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-eeba749f-b551-4e6b-b5b4-71330292205e,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-1ff9ad20-1c79-47c4-8d1e-4ed9b0bed05a,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-8624f8bf-f267-4c28-b4c5-05860939b611,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-da17778c-e2bf-42c4-81b7-8d3df0a1ff11,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-954a8f2b-347e-4933-b51b-02c7761f1cba,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-5c8a72c3-28e7-4498-93d9-db59c06e30d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-f5829035-253f-4cee-8eb2-41bfdbffed6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1074666972-172.17.0.16-1597508232350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44698,DS-1a7f36bd-99c7-4fc0-af3c-4b8c9bf34212,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-eeba749f-b551-4e6b-b5b4-71330292205e,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-1ff9ad20-1c79-47c4-8d1e-4ed9b0bed05a,DISK], DatanodeInfoWithStorage[127.0.0.1:39302,DS-8624f8bf-f267-4c28-b4c5-05860939b611,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-da17778c-e2bf-42c4-81b7-8d3df0a1ff11,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-954a8f2b-347e-4933-b51b-02c7761f1cba,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-5c8a72c3-28e7-4498-93d9-db59c06e30d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-f5829035-253f-4cee-8eb2-41bfdbffed6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-510115785-172.17.0.16-1597508407562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35861,DS-f76b7f7f-1133-44f7-aabf-b3d11fa866f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-3778f3da-a6c8-4dd3-8b43-9a84430c8b93,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-99f2a8f8-fde2-44d9-810b-c49c522536b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-a1b44a1e-b71e-434a-b087-a247daf6a5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-2bd2f7e4-3a42-4ef8-9058-cbe0ee541f49,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-647c11e6-d835-4652-bf08-9489b5acfb13,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-cb11ecef-c5fc-436c-b232-eb31daa14bef,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-72c164ca-c1b9-4b2e-9cc0-cb4e2c52022e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-510115785-172.17.0.16-1597508407562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35861,DS-f76b7f7f-1133-44f7-aabf-b3d11fa866f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-3778f3da-a6c8-4dd3-8b43-9a84430c8b93,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-99f2a8f8-fde2-44d9-810b-c49c522536b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-a1b44a1e-b71e-434a-b087-a247daf6a5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-2bd2f7e4-3a42-4ef8-9058-cbe0ee541f49,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-647c11e6-d835-4652-bf08-9489b5acfb13,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-cb11ecef-c5fc-436c-b232-eb31daa14bef,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-72c164ca-c1b9-4b2e-9cc0-cb4e2c52022e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1428961111-172.17.0.16-1597508486846:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33252,DS-1a848e1d-0fcd-48ca-b257-732b0b67b30e,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-65c7ebc1-a8bb-4ec2-9cda-f2c984e5f384,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-064342ec-7461-4dd4-bcca-6b5a9632b1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-544ae4cf-2124-4fb7-9f30-597350b6e4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-8a7d6710-84be-4441-9e99-f69d41e8ed07,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-1c878999-080d-4104-b612-1e79ae7c3b53,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-32fb8a52-0006-48ac-a8fa-90427285f068,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-319b0be4-fd42-487c-a5e6-1a5325bdd162,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1428961111-172.17.0.16-1597508486846:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33252,DS-1a848e1d-0fcd-48ca-b257-732b0b67b30e,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-65c7ebc1-a8bb-4ec2-9cda-f2c984e5f384,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-064342ec-7461-4dd4-bcca-6b5a9632b1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-544ae4cf-2124-4fb7-9f30-597350b6e4a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-8a7d6710-84be-4441-9e99-f69d41e8ed07,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-1c878999-080d-4104-b612-1e79ae7c3b53,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-32fb8a52-0006-48ac-a8fa-90427285f068,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-319b0be4-fd42-487c-a5e6-1a5325bdd162,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-673231324-172.17.0.16-1597508721834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45177,DS-cad47739-4672-4499-9807-0e333b817e49,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-490980c5-ffd8-4a66-beb5-45f412886f15,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-2fd85c09-841b-49ff-a903-338b211a3909,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-bb6b2874-ec0a-46ff-acb6-a52eb66b7283,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-2c3805ab-74bf-4bbc-b120-c5750e5f0b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-116a28fe-4b0a-46bb-9071-e49b29599dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-547ad56a-5373-4862-b339-1717ea993eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-b3da89ea-a13e-40a4-81a5-d24b0983211c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-673231324-172.17.0.16-1597508721834:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45177,DS-cad47739-4672-4499-9807-0e333b817e49,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-490980c5-ffd8-4a66-beb5-45f412886f15,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-2fd85c09-841b-49ff-a903-338b211a3909,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-bb6b2874-ec0a-46ff-acb6-a52eb66b7283,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-2c3805ab-74bf-4bbc-b120-c5750e5f0b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-116a28fe-4b0a-46bb-9071-e49b29599dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-547ad56a-5373-4862-b339-1717ea993eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-b3da89ea-a13e-40a4-81a5-d24b0983211c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1411481231-172.17.0.16-1597509294148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38672,DS-ebdbbd4d-fb4b-493b-a65a-bc020151d80a,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-9fa6d080-84c1-4c45-bf01-134c1090e2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-09642eee-b6d3-49fb-a849-9d9d442c755e,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-1b2ec5ca-72df-4cd9-bfcb-1b155611c1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-dd5cccdd-a30e-467a-a963-a78644e1ba7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-f67be56f-1f71-48d9-9e6f-06bfb4d46fba,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-e8316efd-87b4-48da-8089-ccf9cdb59973,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-498d9c03-22d5-48d2-9986-fa040659ba27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1411481231-172.17.0.16-1597509294148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38672,DS-ebdbbd4d-fb4b-493b-a65a-bc020151d80a,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-9fa6d080-84c1-4c45-bf01-134c1090e2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-09642eee-b6d3-49fb-a849-9d9d442c755e,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-1b2ec5ca-72df-4cd9-bfcb-1b155611c1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-dd5cccdd-a30e-467a-a963-a78644e1ba7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-f67be56f-1f71-48d9-9e6f-06bfb4d46fba,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-e8316efd-87b4-48da-8089-ccf9cdb59973,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-498d9c03-22d5-48d2-9986-fa040659ba27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1871931621-172.17.0.16-1597509910015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42635,DS-ed6c72ec-f0cd-4154-be6b-c4804a8f17f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-8c477b4a-7415-41b1-8d4e-bab54a364986,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-315427ef-3381-45e2-9115-3e161b07778c,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-dca022cf-7087-4020-a8f5-11fa595f1d35,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-a3d8b07d-2c5c-4d4f-b83a-fcb5cd25bff3,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-fe2493d7-783c-4941-a2f7-13c7f33bdab1,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-ec98c084-52ce-404e-ac94-36dd5f70ad46,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-4a4f0836-7311-4b4e-b0f9-4abe7534a038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1871931621-172.17.0.16-1597509910015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42635,DS-ed6c72ec-f0cd-4154-be6b-c4804a8f17f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-8c477b4a-7415-41b1-8d4e-bab54a364986,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-315427ef-3381-45e2-9115-3e161b07778c,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-dca022cf-7087-4020-a8f5-11fa595f1d35,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-a3d8b07d-2c5c-4d4f-b83a-fcb5cd25bff3,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-fe2493d7-783c-4941-a2f7-13c7f33bdab1,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-ec98c084-52ce-404e-ac94-36dd5f70ad46,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-4a4f0836-7311-4b4e-b0f9-4abe7534a038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-202080723-172.17.0.16-1597510653301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37037,DS-3f265427-eddf-4ab6-9c55-534350592761,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-5e13ea50-4d9b-43fc-8f7d-dce3d991e028,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-d5d7ce4a-75fd-4a0c-aad2-4d9c99eab25a,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-868281ef-bb2a-4354-9dea-8d21fbd18680,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-ac00d2f8-6296-4a39-bee4-d7394af3a84b,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-25f95614-31a6-4cd3-b2f9-71730867ed64,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-349693b4-0493-42c2-95af-9646cb2576f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-eebbcea9-e0d5-4f2c-a10c-a55e8e9656e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-202080723-172.17.0.16-1597510653301:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37037,DS-3f265427-eddf-4ab6-9c55-534350592761,DISK], DatanodeInfoWithStorage[127.0.0.1:32853,DS-5e13ea50-4d9b-43fc-8f7d-dce3d991e028,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-d5d7ce4a-75fd-4a0c-aad2-4d9c99eab25a,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-868281ef-bb2a-4354-9dea-8d21fbd18680,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-ac00d2f8-6296-4a39-bee4-d7394af3a84b,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-25f95614-31a6-4cd3-b2f9-71730867ed64,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-349693b4-0493-42c2-95af-9646cb2576f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-eebbcea9-e0d5-4f2c-a10c-a55e8e9656e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1235549846-172.17.0.16-1597510778255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41739,DS-2a1079c4-5834-44b0-8fd0-d3430c9188a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-18367d54-4d88-4631-8ff1-d6e908b30c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-03c8828f-e35b-4bce-8f2c-bfdea5666936,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-680e20ad-53f6-4ca8-aaca-2d067a08a9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-c8ca04cb-28a7-48e6-a3d0-e99cf6c0694d,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-cbf77aba-3a6f-4653-81d7-99588ffcb627,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-744ef4ab-adc9-4a55-bc46-be011075350a,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-97a964c6-b19b-4104-bc52-13c95bc3cc1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1235549846-172.17.0.16-1597510778255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41739,DS-2a1079c4-5834-44b0-8fd0-d3430c9188a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-18367d54-4d88-4631-8ff1-d6e908b30c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-03c8828f-e35b-4bce-8f2c-bfdea5666936,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-680e20ad-53f6-4ca8-aaca-2d067a08a9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-c8ca04cb-28a7-48e6-a3d0-e99cf6c0694d,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-cbf77aba-3a6f-4653-81d7-99588ffcb627,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-744ef4ab-adc9-4a55-bc46-be011075350a,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-97a964c6-b19b-4104-bc52-13c95bc3cc1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1599424029-172.17.0.16-1597510816675:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33488,DS-d7b98d80-ed10-43d7-a61d-09b5e76cd8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-51895fb7-5136-45f0-8214-e5b7ad6efeec,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-3eef0c45-d64c-4e73-a585-7e547e9e701d,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-0ca29175-7f23-4b85-994b-ec65f0407bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-4b785bc9-c6fd-4d21-ace0-d54a731dc89c,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-8da035cf-62b3-423e-8f0f-1a0d902455d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-6dfb272b-e97c-4a95-a269-1f5508ad8a35,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-33ee94a9-907e-47aa-8d0f-072e6df6143e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1599424029-172.17.0.16-1597510816675:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33488,DS-d7b98d80-ed10-43d7-a61d-09b5e76cd8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-51895fb7-5136-45f0-8214-e5b7ad6efeec,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-3eef0c45-d64c-4e73-a585-7e547e9e701d,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-0ca29175-7f23-4b85-994b-ec65f0407bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-4b785bc9-c6fd-4d21-ace0-d54a731dc89c,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-8da035cf-62b3-423e-8f0f-1a0d902455d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-6dfb272b-e97c-4a95-a269-1f5508ad8a35,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-33ee94a9-907e-47aa-8d0f-072e6df6143e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1266635253-172.17.0.16-1597511285022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37441,DS-30051c78-9b5d-4b97-bda7-c18b3221a9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-3a942397-e76f-4043-9255-af629eb83b34,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-171c69e7-20d5-44bc-af25-175cd2984fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-c8d60572-15ad-4a32-88e2-f6328e9cbe65,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-176efe0e-f84d-467f-93a9-62f99733b663,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-96ad68b8-d16f-43f7-a586-18319f7577c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-659e3131-94f0-44f1-8196-f3a1e828271f,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-2712677c-be0d-4e9c-9f66-245008b95e3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1266635253-172.17.0.16-1597511285022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37441,DS-30051c78-9b5d-4b97-bda7-c18b3221a9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-3a942397-e76f-4043-9255-af629eb83b34,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-171c69e7-20d5-44bc-af25-175cd2984fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-c8d60572-15ad-4a32-88e2-f6328e9cbe65,DISK], DatanodeInfoWithStorage[127.0.0.1:33932,DS-176efe0e-f84d-467f-93a9-62f99733b663,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-96ad68b8-d16f-43f7-a586-18319f7577c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-659e3131-94f0-44f1-8196-f3a1e828271f,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-2712677c-be0d-4e9c-9f66-245008b95e3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1826609222-172.17.0.16-1597511531300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40514,DS-a4db8709-1f88-4cd7-a3bd-2b17653efc11,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-39f036ff-1f3e-415f-96cc-95f7f2f88dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-60747912-84a1-4223-8a82-b7725fe4db88,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-a858bff4-7116-44d6-9726-c9cecd173354,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-29816931-042f-490b-ab49-d94f3e9941c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-64c59b8b-db71-4fe5-ae59-efa63f081667,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-70747fca-2510-4f99-8975-c136a14aabf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-dc530bd6-240a-4f79-8cbb-bef664c731c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1826609222-172.17.0.16-1597511531300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40514,DS-a4db8709-1f88-4cd7-a3bd-2b17653efc11,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-39f036ff-1f3e-415f-96cc-95f7f2f88dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-60747912-84a1-4223-8a82-b7725fe4db88,DISK], DatanodeInfoWithStorage[127.0.0.1:45008,DS-a858bff4-7116-44d6-9726-c9cecd173354,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-29816931-042f-490b-ab49-d94f3e9941c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-64c59b8b-db71-4fe5-ae59-efa63f081667,DISK], DatanodeInfoWithStorage[127.0.0.1:43238,DS-70747fca-2510-4f99-8975-c136a14aabf3,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-dc530bd6-240a-4f79-8cbb-bef664c731c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-743954643-172.17.0.16-1597511718040:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38084,DS-ed5c02db-f868-4af6-b81d-829aeded3ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-1e375705-bd20-4661-9591-a95da5cfbb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-6e00f363-7024-4f06-ac3d-931c0fc4bf75,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-c4b119f3-0fac-4cc4-b072-e56f89e3310d,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-fc97ecea-d2ae-4bcd-87a7-59b5da9baa69,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-f7608376-8b6d-411d-884c-7b62adcec07e,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-d16b4f89-4182-417a-b5a4-d7b18ab21e60,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-4f9e0203-7ef4-4699-baac-1408a2b93cbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-743954643-172.17.0.16-1597511718040:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38084,DS-ed5c02db-f868-4af6-b81d-829aeded3ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-1e375705-bd20-4661-9591-a95da5cfbb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-6e00f363-7024-4f06-ac3d-931c0fc4bf75,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-c4b119f3-0fac-4cc4-b072-e56f89e3310d,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-fc97ecea-d2ae-4bcd-87a7-59b5da9baa69,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-f7608376-8b6d-411d-884c-7b62adcec07e,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-d16b4f89-4182-417a-b5a4-d7b18ab21e60,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-4f9e0203-7ef4-4699-baac-1408a2b93cbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 700000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-207150323-172.17.0.16-1597512336106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41356,DS-0685e897-863e-4f5e-9262-a96e1ffeb9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-1edb488f-8e55-4878-b454-2c1aeb0df957,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-6b004ccf-1d02-4227-83d9-421d7945b15e,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-04b23b16-a085-4b74-96f7-8462f0c0bc65,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-1358a56b-ffce-4ba4-a59b-368141c1caae,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-e447ef31-7f01-40fd-9da2-013ab66a62fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-9b6e65cb-a8ca-400c-bef2-b2ca6d93b088,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-8f030d7e-63a9-455a-af6a-2def65760d2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-207150323-172.17.0.16-1597512336106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41356,DS-0685e897-863e-4f5e-9262-a96e1ffeb9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-1edb488f-8e55-4878-b454-2c1aeb0df957,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-6b004ccf-1d02-4227-83d9-421d7945b15e,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-04b23b16-a085-4b74-96f7-8462f0c0bc65,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-1358a56b-ffce-4ba4-a59b-368141c1caae,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-e447ef31-7f01-40fd-9da2-013ab66a62fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-9b6e65cb-a8ca-400c-bef2-b2ca6d93b088,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-8f030d7e-63a9-455a-af6a-2def65760d2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5523
