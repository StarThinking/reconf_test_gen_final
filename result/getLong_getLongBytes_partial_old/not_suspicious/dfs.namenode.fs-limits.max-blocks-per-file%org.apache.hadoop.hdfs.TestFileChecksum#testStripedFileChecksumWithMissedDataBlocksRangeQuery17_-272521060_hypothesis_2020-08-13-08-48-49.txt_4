reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-930452355-172.17.0.3-1597308544515:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38507,DS-e8f83813-5238-4070-ba9e-7bfbac10d548,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-837960f6-0bee-4fa3-bdb4-9ff42107e7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-a239aa65-c222-4039-9b6f-6feb6e35f2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-37c6166d-c50c-4d6c-ae6e-c256a36b1a31,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-5d31ffb7-b9ec-4b79-89cc-03d94eac20fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33751,DS-316757d2-9004-452d-9cac-24d28e620a90,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-16ba7029-6009-4bb2-b12b-252dd4e287f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-f072f195-819d-4752-bbaa-a5cdcf3a827e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-930452355-172.17.0.3-1597308544515:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38507,DS-e8f83813-5238-4070-ba9e-7bfbac10d548,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-837960f6-0bee-4fa3-bdb4-9ff42107e7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-a239aa65-c222-4039-9b6f-6feb6e35f2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-37c6166d-c50c-4d6c-ae6e-c256a36b1a31,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-5d31ffb7-b9ec-4b79-89cc-03d94eac20fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33751,DS-316757d2-9004-452d-9cac-24d28e620a90,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-16ba7029-6009-4bb2-b12b-252dd4e287f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46741,DS-f072f195-819d-4752-bbaa-a5cdcf3a827e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-356505960-172.17.0.3-1597309764259:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45564,DS-c4b6f190-d62c-4382-ab79-0d7586a84991,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-e81c9ea5-b857-4cc4-8163-31cb969c3a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-1b0927d0-db0c-4f75-8ddd-5b9590ab3f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-4d8cd3ee-1045-4303-9c8a-b71ca8059bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-09a9c3f7-4813-4a73-9e47-35e6119d1863,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-edf64209-a948-4dea-ba83-22bd78ce7772,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-a386f077-f3b1-44b6-813d-0dc235c76587,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-c58bf0aa-69e4-4ac6-bf69-1353ded00ecf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-356505960-172.17.0.3-1597309764259:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45564,DS-c4b6f190-d62c-4382-ab79-0d7586a84991,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-e81c9ea5-b857-4cc4-8163-31cb969c3a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-1b0927d0-db0c-4f75-8ddd-5b9590ab3f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33943,DS-4d8cd3ee-1045-4303-9c8a-b71ca8059bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-09a9c3f7-4813-4a73-9e47-35e6119d1863,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-edf64209-a948-4dea-ba83-22bd78ce7772,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-a386f077-f3b1-44b6-813d-0dc235c76587,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-c58bf0aa-69e4-4ac6-bf69-1353ded00ecf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-108327374-172.17.0.3-1597309975219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41795,DS-ca7870bd-03aa-4104-a461-a5ab6bb7005a,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-b71530b0-444d-410a-91e9-8913d3da1609,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-0d498124-53d7-4202-91e0-b8060d117e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-398bd51b-bbd4-489a-a08a-db62cc95df5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-6c3a8709-5c5c-440a-87d7-1a590c130aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-bc27c9c8-520f-4eb1-8b12-5431d5329f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-f797f70a-ec61-4f4d-a7d5-567a778b1d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-10cebb5b-fa7b-4f06-9d09-ff6a6f074051,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-108327374-172.17.0.3-1597309975219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41795,DS-ca7870bd-03aa-4104-a461-a5ab6bb7005a,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-b71530b0-444d-410a-91e9-8913d3da1609,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-0d498124-53d7-4202-91e0-b8060d117e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-398bd51b-bbd4-489a-a08a-db62cc95df5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-6c3a8709-5c5c-440a-87d7-1a590c130aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-bc27c9c8-520f-4eb1-8b12-5431d5329f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-f797f70a-ec61-4f4d-a7d5-567a778b1d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-10cebb5b-fa7b-4f06-9d09-ff6a6f074051,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1946129569-172.17.0.3-1597310008056:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39258,DS-0fba30c8-e484-44d5-9ad9-696797be0c95,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-3bb8917a-4771-4eac-827f-46844aad30cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-f4ddbfb4-beb9-4a78-9a4b-f0adac2f263c,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-c511e9d0-c2d7-419e-93ad-d77c64f96432,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-b3847fc2-461d-4598-b90f-faea45193560,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-585b0fca-944e-4de4-950e-6a3c0888c1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-954e1f5f-2a21-4153-a285-7ddfb2a09471,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-ec573b4f-3e42-4160-bb78-5d1de2c81ade,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1946129569-172.17.0.3-1597310008056:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39258,DS-0fba30c8-e484-44d5-9ad9-696797be0c95,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-3bb8917a-4771-4eac-827f-46844aad30cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-f4ddbfb4-beb9-4a78-9a4b-f0adac2f263c,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-c511e9d0-c2d7-419e-93ad-d77c64f96432,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-b3847fc2-461d-4598-b90f-faea45193560,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-585b0fca-944e-4de4-950e-6a3c0888c1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-954e1f5f-2a21-4153-a285-7ddfb2a09471,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-ec573b4f-3e42-4160-bb78-5d1de2c81ade,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1034133068-172.17.0.3-1597310631790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40106,DS-12664000-ba0c-4dd8-bcc4-cf8ef0499fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-2f469e11-12e5-4a91-937f-b3b6dc65c186,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-68e70b98-0f30-4c32-a3a0-ce409f4ce9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-71f6b01f-c8a7-4bfd-bb6f-9e9b2fcf82da,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-0d9c9b92-fe68-4c29-8415-5ad4b6a0b07b,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-3ce70245-ea7b-4a06-8247-579c1785190c,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-3a49fe0a-855f-4928-a231-fe338be44d20,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-6e4d4398-ea80-4529-bb0b-c70f7477622d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1034133068-172.17.0.3-1597310631790:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40106,DS-12664000-ba0c-4dd8-bcc4-cf8ef0499fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-2f469e11-12e5-4a91-937f-b3b6dc65c186,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-68e70b98-0f30-4c32-a3a0-ce409f4ce9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-71f6b01f-c8a7-4bfd-bb6f-9e9b2fcf82da,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-0d9c9b92-fe68-4c29-8415-5ad4b6a0b07b,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-3ce70245-ea7b-4a06-8247-579c1785190c,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-3a49fe0a-855f-4928-a231-fe338be44d20,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-6e4d4398-ea80-4529-bb0b-c70f7477622d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-70605706-172.17.0.3-1597310889538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38457,DS-f5b4b58a-996f-4df2-8472-d6f295f46599,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-83917c41-cfa1-4406-888c-3051f1ee26d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-03804281-5a58-4025-a57b-d47ba2705790,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-341de8f8-67c3-4f4e-b38a-ce49353d58b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-e1d3a593-637e-4b0c-ad86-cf6b5711be20,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-ae8ee8c8-7afc-48cd-84a6-bf96e9850750,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-d78216af-2582-4c58-afc7-a94387c08456,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-ae92a32c-43bc-47c0-9389-7e55f37c920d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-70605706-172.17.0.3-1597310889538:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38457,DS-f5b4b58a-996f-4df2-8472-d6f295f46599,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-83917c41-cfa1-4406-888c-3051f1ee26d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-03804281-5a58-4025-a57b-d47ba2705790,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-341de8f8-67c3-4f4e-b38a-ce49353d58b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-e1d3a593-637e-4b0c-ad86-cf6b5711be20,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-ae8ee8c8-7afc-48cd-84a6-bf96e9850750,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-d78216af-2582-4c58-afc7-a94387c08456,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-ae92a32c-43bc-47c0-9389-7e55f37c920d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-797840708-172.17.0.3-1597311681854:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42664,DS-6033b7c6-6085-4d05-9aa7-63d2f0095c49,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-054ea48c-cf1f-4bca-a9cc-f3e2204fabff,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-1f36e91b-a3f0-4494-b966-f0633c53191f,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-c5519d7b-f8a5-4693-9e14-eaa268f5d8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-9b9e8f91-d1fc-46d3-8410-0e7fc1e70565,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-1098a06a-1a87-4492-a90b-49bc6e1b842b,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-bbf4c618-e127-4c36-b09e-a5ee852488d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-a3184e4c-22dd-4624-8730-d0b019144555,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-797840708-172.17.0.3-1597311681854:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42664,DS-6033b7c6-6085-4d05-9aa7-63d2f0095c49,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-054ea48c-cf1f-4bca-a9cc-f3e2204fabff,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-1f36e91b-a3f0-4494-b966-f0633c53191f,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-c5519d7b-f8a5-4693-9e14-eaa268f5d8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-9b9e8f91-d1fc-46d3-8410-0e7fc1e70565,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-1098a06a-1a87-4492-a90b-49bc6e1b842b,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-bbf4c618-e127-4c36-b09e-a5ee852488d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-a3184e4c-22dd-4624-8730-d0b019144555,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1798737629-172.17.0.3-1597311751146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45772,DS-d3af87f2-b9b6-43f0-8f1f-ad95017c53d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-0cbf3888-c932-416d-bfa6-750ddd31af88,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-7f41e5e7-f5ee-4263-986a-ff7ace615405,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-0205571e-1b84-4e4c-acdb-5cbfb7c6a19f,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-cc653fb8-2d29-46fe-a92c-1de8c3f469e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-768b3905-50f0-47a6-b1ba-ad9d5c732bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-4d03aa2c-9087-4e38-b0ae-808d867c937d,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-8df86485-f163-4e7d-9ed3-93a457dd8011,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1798737629-172.17.0.3-1597311751146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45772,DS-d3af87f2-b9b6-43f0-8f1f-ad95017c53d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-0cbf3888-c932-416d-bfa6-750ddd31af88,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-7f41e5e7-f5ee-4263-986a-ff7ace615405,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-0205571e-1b84-4e4c-acdb-5cbfb7c6a19f,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-cc653fb8-2d29-46fe-a92c-1de8c3f469e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-768b3905-50f0-47a6-b1ba-ad9d5c732bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-4d03aa2c-9087-4e38-b0ae-808d867c937d,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-8df86485-f163-4e7d-9ed3-93a457dd8011,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2071977637-172.17.0.3-1597312219189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36989,DS-f806c53f-1065-4cfa-86ce-61ca20af0098,DISK], DatanodeInfoWithStorage[127.0.0.1:40995,DS-151ee49f-5ac0-49b9-8729-16affd0df523,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-2ddbb1a3-49e2-4c25-979d-d4e3b71fca07,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-bd33fed9-1700-40af-817c-f3bf47c2dca4,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-888fc351-e3ac-4517-b869-53d8992be8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-a551515d-4f35-41ae-9192-cbd5bb45dec4,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-8a20ccae-b291-4a5d-86df-9016731ada68,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-f58bf7c8-68fe-4f90-ae9e-d9f87055e817,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2071977637-172.17.0.3-1597312219189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36989,DS-f806c53f-1065-4cfa-86ce-61ca20af0098,DISK], DatanodeInfoWithStorage[127.0.0.1:40995,DS-151ee49f-5ac0-49b9-8729-16affd0df523,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-2ddbb1a3-49e2-4c25-979d-d4e3b71fca07,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-bd33fed9-1700-40af-817c-f3bf47c2dca4,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-888fc351-e3ac-4517-b869-53d8992be8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-a551515d-4f35-41ae-9192-cbd5bb45dec4,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-8a20ccae-b291-4a5d-86df-9016731ada68,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-f58bf7c8-68fe-4f90-ae9e-d9f87055e817,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2025064728-172.17.0.3-1597312323239:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36742,DS-12e62cb0-6896-4d43-adb1-f79d960d7eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-79778f74-7303-47ea-ab4b-d6bab0119dce,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-c0885baf-4c27-4cfe-830e-2bfb12e39a05,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-e67cc6a3-c092-4f86-b1cf-5a0ed433ba99,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-c111cc31-9e80-4a66-b5e2-af2aed816a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-3063b3ed-ad93-44bb-bb45-067ddebb60ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-cf521f8a-e67f-4b5c-b585-1904c656fc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-6032defe-2806-4909-9ee8-95d87d543ed4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2025064728-172.17.0.3-1597312323239:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36742,DS-12e62cb0-6896-4d43-adb1-f79d960d7eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-79778f74-7303-47ea-ab4b-d6bab0119dce,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-c0885baf-4c27-4cfe-830e-2bfb12e39a05,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-e67cc6a3-c092-4f86-b1cf-5a0ed433ba99,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-c111cc31-9e80-4a66-b5e2-af2aed816a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-3063b3ed-ad93-44bb-bb45-067ddebb60ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-cf521f8a-e67f-4b5c-b585-1904c656fc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-6032defe-2806-4909-9ee8-95d87d543ed4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-562766550-172.17.0.3-1597312353878:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42543,DS-3257a456-d7e5-4cd2-a2ed-8db1c6b6baa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-521c019e-7880-4f72-ac59-3b1019b47d16,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-4e9e2d6a-16a0-4e74-acc0-394697a96f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-9052a996-25f7-4129-abc0-aed81d5d52dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-47ed76f1-5218-4f70-be7d-86f78ea2e295,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-42aeacbd-5bbe-44c0-9d29-1f39fa7fd8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-a394dab5-b8fd-45fe-8f16-d034fc00125a,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-d6a3e993-6aa3-47ed-b623-4d212d1bb855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-562766550-172.17.0.3-1597312353878:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42543,DS-3257a456-d7e5-4cd2-a2ed-8db1c6b6baa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-521c019e-7880-4f72-ac59-3b1019b47d16,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-4e9e2d6a-16a0-4e74-acc0-394697a96f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-9052a996-25f7-4129-abc0-aed81d5d52dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-47ed76f1-5218-4f70-be7d-86f78ea2e295,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-42aeacbd-5bbe-44c0-9d29-1f39fa7fd8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-a394dab5-b8fd-45fe-8f16-d034fc00125a,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-d6a3e993-6aa3-47ed-b623-4d212d1bb855,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-214912651-172.17.0.3-1597312783103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44551,DS-4c9bf5b4-6b3e-4b71-af8c-a0d56722dcec,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-e8c93d35-7932-451d-93a5-edad88724f26,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-8f4d4528-300b-4615-8a75-67cc32ac7519,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-508cae06-85dd-47e0-9527-7c03edbf0eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-f594ddd5-0a17-42bd-8d20-58949bde0cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-b4b95fbd-ff7c-488d-955f-1a9b049b9ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-0f787861-1912-49c4-9f7f-d2ed6ab2b628,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-6e48785b-ed51-4c66-9373-066d7b3eebb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-214912651-172.17.0.3-1597312783103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44551,DS-4c9bf5b4-6b3e-4b71-af8c-a0d56722dcec,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-e8c93d35-7932-451d-93a5-edad88724f26,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-8f4d4528-300b-4615-8a75-67cc32ac7519,DISK], DatanodeInfoWithStorage[127.0.0.1:34814,DS-508cae06-85dd-47e0-9527-7c03edbf0eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-f594ddd5-0a17-42bd-8d20-58949bde0cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-b4b95fbd-ff7c-488d-955f-1a9b049b9ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-0f787861-1912-49c4-9f7f-d2ed6ab2b628,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-6e48785b-ed51-4c66-9373-066d7b3eebb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-924204530-172.17.0.3-1597313170219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33408,DS-d824af75-3157-43be-9634-c91086135572,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-4f93ab3d-6341-45e1-be00-c45763a9d35c,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-cd06a423-1ef9-49da-8b97-895f36bede48,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-2e6c71fe-ae74-4513-9cdd-d974b2794ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-7f4f4254-1c75-4c35-87a4-c9830b4e227f,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-4e3ebc43-5ecb-4273-b78d-119d126ed510,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-2adec8bd-1759-42b3-b7d0-60ee52e8eccb,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-b2cbe88c-d4c5-4ac3-b438-21069ec6236f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-924204530-172.17.0.3-1597313170219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33408,DS-d824af75-3157-43be-9634-c91086135572,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-4f93ab3d-6341-45e1-be00-c45763a9d35c,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-cd06a423-1ef9-49da-8b97-895f36bede48,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-2e6c71fe-ae74-4513-9cdd-d974b2794ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-7f4f4254-1c75-4c35-87a4-c9830b4e227f,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-4e3ebc43-5ecb-4273-b78d-119d126ed510,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-2adec8bd-1759-42b3-b7d0-60ee52e8eccb,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-b2cbe88c-d4c5-4ac3-b438-21069ec6236f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1540667339-172.17.0.3-1597313204606:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39064,DS-a4677183-c430-4755-bbe0-db0a43ab52e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-f3a2728b-e641-4727-8791-5a20b1bb1d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-efed0f3c-f0b3-4609-a2db-26cd2a250418,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-91aa1b8f-dae5-441a-98c9-d5bfd4f16266,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-672e9f5f-8618-4b4f-af98-5832679f3f36,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-e8ec7686-f4ba-4432-8e9b-a1ca89e3f90f,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-cd4d1e49-767c-4ac3-ab4c-ad8f0dc8a70a,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-87949503-542a-4817-898b-fb72070a1f46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1540667339-172.17.0.3-1597313204606:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39064,DS-a4677183-c430-4755-bbe0-db0a43ab52e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-f3a2728b-e641-4727-8791-5a20b1bb1d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-efed0f3c-f0b3-4609-a2db-26cd2a250418,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-91aa1b8f-dae5-441a-98c9-d5bfd4f16266,DISK], DatanodeInfoWithStorage[127.0.0.1:43521,DS-672e9f5f-8618-4b4f-af98-5832679f3f36,DISK], DatanodeInfoWithStorage[127.0.0.1:32936,DS-e8ec7686-f4ba-4432-8e9b-a1ca89e3f90f,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-cd4d1e49-767c-4ac3-ab4c-ad8f0dc8a70a,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-87949503-542a-4817-898b-fb72070a1f46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.fs-limits.max-blocks-per-file
component: hdfs:NameNode
v1: 10000
v2: 100
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-826710009-172.17.0.3-1597313316768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46128,DS-9b71a490-787c-4d70-9843-2b7c6e7b17a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-bb86add0-7e8d-4182-9911-e139b2af1b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-726ed9ac-9bca-4de2-ba95-fe1353ff5a71,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-5baea1e7-0f98-4f34-9b02-6f8ea5140e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-14e0af79-9c75-4119-9c90-fab53d698e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-a5aea01d-6335-4c7b-b005-91f70c56b106,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-2be6c7ce-913f-404c-942d-d8a5e2bc76b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-a8c9ece9-6ca3-4845-8035-2e6e777c4355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-826710009-172.17.0.3-1597313316768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46128,DS-9b71a490-787c-4d70-9843-2b7c6e7b17a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-bb86add0-7e8d-4182-9911-e139b2af1b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-726ed9ac-9bca-4de2-ba95-fe1353ff5a71,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-5baea1e7-0f98-4f34-9b02-6f8ea5140e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-14e0af79-9c75-4119-9c90-fab53d698e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-a5aea01d-6335-4c7b-b005-91f70c56b106,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-2be6c7ce-913f-404c-942d-d8a5e2bc76b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-a8c9ece9-6ca3-4845-8035-2e6e777c4355,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 4916
