reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-498318129-172.17.0.8-1597567589415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41418,DS-fca67d81-145b-45c7-998b-0573985aeabd,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-7fe0c3fb-c77b-404d-a928-4f067e8b6346,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-84ca4a9d-f2b7-473d-9193-3bbf8c60c8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-bf2cfa02-5bc5-4ae2-b37b-3900ff981fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-3eed1b0e-bb2a-4f3b-b295-8836a0377ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-c83f878d-0426-46ac-b7a0-dad9fcafa9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-9d843d45-f4fc-43c9-b535-417d3948f723,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-e0ec93a7-4f70-4bec-9567-18a17917fee3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-498318129-172.17.0.8-1597567589415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41418,DS-fca67d81-145b-45c7-998b-0573985aeabd,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-7fe0c3fb-c77b-404d-a928-4f067e8b6346,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-84ca4a9d-f2b7-473d-9193-3bbf8c60c8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-bf2cfa02-5bc5-4ae2-b37b-3900ff981fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-3eed1b0e-bb2a-4f3b-b295-8836a0377ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-c83f878d-0426-46ac-b7a0-dad9fcafa9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46101,DS-9d843d45-f4fc-43c9-b535-417d3948f723,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-e0ec93a7-4f70-4bec-9567-18a17917fee3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347702691-172.17.0.8-1597567748630:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38405,DS-d744b28e-dde1-469a-a5ab-ae11c16d3e84,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-173985c4-610a-4382-8aa5-4f86805e4659,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-16d55712-b539-493a-ad66-b5067df4ed46,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-d7895eae-f83c-4989-9674-8555088387b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-cdb7a762-94ba-48bc-a5ad-548dabbba2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-8f804d50-700f-42f3-b724-5b4fc5440c16,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-cd8456c3-bcb0-4c84-90e3-53a31abb3e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-092a3414-f842-4c63-9b47-19c7cbbf18e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1347702691-172.17.0.8-1597567748630:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38405,DS-d744b28e-dde1-469a-a5ab-ae11c16d3e84,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-173985c4-610a-4382-8aa5-4f86805e4659,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-16d55712-b539-493a-ad66-b5067df4ed46,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-d7895eae-f83c-4989-9674-8555088387b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-cdb7a762-94ba-48bc-a5ad-548dabbba2b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-8f804d50-700f-42f3-b724-5b4fc5440c16,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-cd8456c3-bcb0-4c84-90e3-53a31abb3e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-092a3414-f842-4c63-9b47-19c7cbbf18e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2123964551-172.17.0.8-1597568046769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42690,DS-5e21987e-d579-40d7-aa4d-5730fff454df,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-0d8a5245-d9b0-49a1-a90c-a66d1c6f0de0,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-9758836e-1167-4a44-a25a-64249c85f34a,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-6648b40a-2271-4f06-a860-5769552f25cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-dffc2cbe-a8ac-4f75-b3c8-d566a5cff1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-5f1c9ea9-2f55-49a4-9ca7-df5dda6cea66,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-59f59c13-3cb4-42c2-b4b5-37ef90103fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-17d4f05d-249a-4137-a201-c483d0302a71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2123964551-172.17.0.8-1597568046769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42690,DS-5e21987e-d579-40d7-aa4d-5730fff454df,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-0d8a5245-d9b0-49a1-a90c-a66d1c6f0de0,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-9758836e-1167-4a44-a25a-64249c85f34a,DISK], DatanodeInfoWithStorage[127.0.0.1:46712,DS-6648b40a-2271-4f06-a860-5769552f25cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38743,DS-dffc2cbe-a8ac-4f75-b3c8-d566a5cff1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-5f1c9ea9-2f55-49a4-9ca7-df5dda6cea66,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-59f59c13-3cb4-42c2-b4b5-37ef90103fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-17d4f05d-249a-4137-a201-c483d0302a71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1093545066-172.17.0.8-1597568092829:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42703,DS-4e31f259-a18d-46fb-94bf-6b43c4ad7931,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-2a8302ad-50b8-4da8-9c5a-c01722d64b50,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-8297cc96-adb2-4946-8661-2ae6a71e85aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-65ae6c82-d0a0-48ad-96b2-5673e59e4c84,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-a7598646-af6b-4579-afa8-416da2c8b45a,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-086f09d2-2e38-4f03-845e-b43e9a2a3e15,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-119a20fc-116b-421c-b3cd-e0c017d06f17,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-8003d56c-1609-473a-9dff-539426070e42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1093545066-172.17.0.8-1597568092829:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42703,DS-4e31f259-a18d-46fb-94bf-6b43c4ad7931,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-2a8302ad-50b8-4da8-9c5a-c01722d64b50,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-8297cc96-adb2-4946-8661-2ae6a71e85aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-65ae6c82-d0a0-48ad-96b2-5673e59e4c84,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-a7598646-af6b-4579-afa8-416da2c8b45a,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-086f09d2-2e38-4f03-845e-b43e9a2a3e15,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-119a20fc-116b-421c-b3cd-e0c017d06f17,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-8003d56c-1609-473a-9dff-539426070e42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-702811468-172.17.0.8-1597568829377:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44085,DS-24ae2407-8a25-435e-94c5-123869131d07,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-21ab9dec-83b7-4883-8e16-766218f2b457,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-52ae072a-ca84-4a5a-86fe-3ab8efed9f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-7fb8f016-9119-400e-9d07-7596b4ac3a87,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-1f5e825a-b838-4956-9f97-b909435c2341,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-6707006f-3c42-4940-b330-d78df1285fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-7efb51e8-3f2b-4865-8e1f-4fb2f8bb359f,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-96547b56-3731-489d-9260-82fca48e8945,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-702811468-172.17.0.8-1597568829377:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44085,DS-24ae2407-8a25-435e-94c5-123869131d07,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-21ab9dec-83b7-4883-8e16-766218f2b457,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-52ae072a-ca84-4a5a-86fe-3ab8efed9f3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-7fb8f016-9119-400e-9d07-7596b4ac3a87,DISK], DatanodeInfoWithStorage[127.0.0.1:38383,DS-1f5e825a-b838-4956-9f97-b909435c2341,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-6707006f-3c42-4940-b330-d78df1285fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-7efb51e8-3f2b-4865-8e1f-4fb2f8bb359f,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-96547b56-3731-489d-9260-82fca48e8945,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-734789706-172.17.0.8-1597569056307:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40356,DS-f16a3b73-5004-4005-85f6-076aa3f96a00,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-eefa9a99-2b25-43c4-bff5-bfddd7ff2141,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-554c405f-2a1b-42a5-b363-58020f71a13a,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-544b451f-6d6c-45c2-acf7-db88d4767680,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-c87e72a8-1b77-4222-b6b6-904ff5c7ced5,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-cca5e9ca-c5cd-418c-8bca-eed19f248938,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-d70552c8-c1d8-4c29-a29e-825bb846eefa,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-26dc2818-307e-4949-a8a4-9c5499f0dfdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-734789706-172.17.0.8-1597569056307:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40356,DS-f16a3b73-5004-4005-85f6-076aa3f96a00,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-eefa9a99-2b25-43c4-bff5-bfddd7ff2141,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-554c405f-2a1b-42a5-b363-58020f71a13a,DISK], DatanodeInfoWithStorage[127.0.0.1:34781,DS-544b451f-6d6c-45c2-acf7-db88d4767680,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-c87e72a8-1b77-4222-b6b6-904ff5c7ced5,DISK], DatanodeInfoWithStorage[127.0.0.1:39391,DS-cca5e9ca-c5cd-418c-8bca-eed19f248938,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-d70552c8-c1d8-4c29-a29e-825bb846eefa,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-26dc2818-307e-4949-a8a4-9c5499f0dfdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-329213409-172.17.0.8-1597569631507:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32910,DS-7c208888-4391-4d9e-8cfe-4423171b5e86,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-189ec31f-5f69-4f1e-9c06-b925b5c8cbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-26a49af5-072c-4d08-b67f-4dff6b5d52b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-9687d0b5-a7ef-4b3b-b824-9b602c4e3049,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-748b57a7-1562-499e-a4b9-8a2e6983a883,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-d688d483-6472-4d50-a836-6839b488e7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-4f56a49b-53bf-41de-93dc-e86e7ceb9d41,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-a68a4a06-7c29-4150-add4-e87ecb528738,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-329213409-172.17.0.8-1597569631507:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32910,DS-7c208888-4391-4d9e-8cfe-4423171b5e86,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-189ec31f-5f69-4f1e-9c06-b925b5c8cbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-26a49af5-072c-4d08-b67f-4dff6b5d52b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-9687d0b5-a7ef-4b3b-b824-9b602c4e3049,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-748b57a7-1562-499e-a4b9-8a2e6983a883,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-d688d483-6472-4d50-a836-6839b488e7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-4f56a49b-53bf-41de-93dc-e86e7ceb9d41,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-a68a4a06-7c29-4150-add4-e87ecb528738,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102595725-172.17.0.8-1597569674339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40706,DS-d0f47690-c536-4b48-bc90-c9950fc803ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-be2bfde8-797f-40a2-9a97-a00d3f64db92,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-667cd5f2-2952-48b0-9a62-bb5b12a545cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-bb7acc97-57a7-4408-bc63-e7547f7719a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-96fbbf08-33d2-4fad-8b51-593092fcec2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-7131198a-f6b3-4da0-b81d-84ed148cfb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-388cad34-cbd4-4ad4-8cdb-02f8044c9b38,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-5ce6b546-6cbc-4a2b-9251-0a2b7305ada7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102595725-172.17.0.8-1597569674339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40706,DS-d0f47690-c536-4b48-bc90-c9950fc803ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-be2bfde8-797f-40a2-9a97-a00d3f64db92,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-667cd5f2-2952-48b0-9a62-bb5b12a545cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-bb7acc97-57a7-4408-bc63-e7547f7719a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38217,DS-96fbbf08-33d2-4fad-8b51-593092fcec2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-7131198a-f6b3-4da0-b81d-84ed148cfb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-388cad34-cbd4-4ad4-8cdb-02f8044c9b38,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-5ce6b546-6cbc-4a2b-9251-0a2b7305ada7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268102544-172.17.0.8-1597569905652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41956,DS-9355bad4-c173-4042-bf3b-d9df9240bdba,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-3d60eeb1-e8ad-4e4e-b185-7bca5e2f02eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-4765b7f8-e89c-4054-b1c9-60c469945245,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-da3a9559-a5dd-4baf-b2b3-41b093e6c2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-eda29031-2f1b-4797-8367-2c223bcc6ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-c69ffba9-3d1d-4c5f-848b-52ed8e628bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-53bdf06e-76ba-4926-91ee-96ed54fc0704,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-072442f8-f595-475d-8c2b-caafcfb81961,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268102544-172.17.0.8-1597569905652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41956,DS-9355bad4-c173-4042-bf3b-d9df9240bdba,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-3d60eeb1-e8ad-4e4e-b185-7bca5e2f02eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41358,DS-4765b7f8-e89c-4054-b1c9-60c469945245,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-da3a9559-a5dd-4baf-b2b3-41b093e6c2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-eda29031-2f1b-4797-8367-2c223bcc6ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:41477,DS-c69ffba9-3d1d-4c5f-848b-52ed8e628bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-53bdf06e-76ba-4926-91ee-96ed54fc0704,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-072442f8-f595-475d-8c2b-caafcfb81961,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121914581-172.17.0.8-1597570204998:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36989,DS-2106851b-185c-4c8a-935c-113844fe72e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-fe64e7e6-d6b9-4a04-9388-7096cd9adc71,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-45e088cc-c7c8-482b-940e-2fa06ee7a8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-a390db34-c873-4d8b-8b67-84b2875004e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-f1a01a0e-93fe-40d7-920b-030b8ffb2081,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-a7640291-cc49-483b-904e-1c164bca6431,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-65e8021f-6691-4479-a3d7-859f0ee86442,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-2c9f4191-7942-4cdc-acdc-5e4f7c0e8b63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121914581-172.17.0.8-1597570204998:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36989,DS-2106851b-185c-4c8a-935c-113844fe72e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-fe64e7e6-d6b9-4a04-9388-7096cd9adc71,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-45e088cc-c7c8-482b-940e-2fa06ee7a8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-a390db34-c873-4d8b-8b67-84b2875004e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-f1a01a0e-93fe-40d7-920b-030b8ffb2081,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-a7640291-cc49-483b-904e-1c164bca6431,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-65e8021f-6691-4479-a3d7-859f0ee86442,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-2c9f4191-7942-4cdc-acdc-5e4f7c0e8b63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888982541-172.17.0.8-1597570900312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40421,DS-6c4932c2-e258-4004-9cad-23ec22680686,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-a823bcad-4db0-45de-abaa-b70c72096cda,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-23067320-2b7b-4b14-aa50-0524cb2b146e,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-af056a94-f250-43ca-ae93-273789e5ff70,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-4da4bc0c-0b91-4351-a834-54590bf75273,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-70234e68-b1f9-47c4-84ad-344f50d9cbca,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-484dacbd-4cc2-45b3-a37a-b02746d8bbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-09d38bba-d147-44f2-9a34-74cfb2df3a96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1888982541-172.17.0.8-1597570900312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40421,DS-6c4932c2-e258-4004-9cad-23ec22680686,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-a823bcad-4db0-45de-abaa-b70c72096cda,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-23067320-2b7b-4b14-aa50-0524cb2b146e,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-af056a94-f250-43ca-ae93-273789e5ff70,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-4da4bc0c-0b91-4351-a834-54590bf75273,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-70234e68-b1f9-47c4-84ad-344f50d9cbca,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-484dacbd-4cc2-45b3-a37a-b02746d8bbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-09d38bba-d147-44f2-9a34-74cfb2df3a96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008139565-172.17.0.8-1597571038306:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36626,DS-1d6eb9ca-a793-4ad5-b43c-e3db45653c28,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-e2f4ea8e-94cf-47b9-b8ea-d965889d8261,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-1d18874d-7b4c-4db1-bb5d-b8494cd556e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46539,DS-05d28dd0-0703-4106-933b-23ef2f73ead6,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-42248290-1b34-4715-91fd-afae335943a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-2aeef1e7-bdd9-4539-94e2-82f3f3f1bb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-3276aca8-e3b6-4df5-89a2-d951b1017a11,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-4c2ba5d0-a0c6-4019-948b-4137fa9afa70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008139565-172.17.0.8-1597571038306:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36626,DS-1d6eb9ca-a793-4ad5-b43c-e3db45653c28,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-e2f4ea8e-94cf-47b9-b8ea-d965889d8261,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-1d18874d-7b4c-4db1-bb5d-b8494cd556e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46539,DS-05d28dd0-0703-4106-933b-23ef2f73ead6,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-42248290-1b34-4715-91fd-afae335943a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-2aeef1e7-bdd9-4539-94e2-82f3f3f1bb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-3276aca8-e3b6-4df5-89a2-d951b1017a11,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-4c2ba5d0-a0c6-4019-948b-4137fa9afa70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-986605595-172.17.0.8-1597571399019:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38813,DS-9e4ceaa7-37d9-4667-b70d-bc5fc992177d,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-158e8a88-c044-4848-bd9d-c2a364e6b8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-346f8d4c-ff62-48f0-adab-e1c8cb3fbdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-a70f3de3-42b8-4adf-bdc7-a4da21931ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:34959,DS-32ae501d-0242-4858-9017-eba87b39898a,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-8796da71-6cf9-4ed4-9b89-c54c6ba686b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-a9e4bbdb-7df2-4616-a497-4e692648bc60,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-ae997f78-0dfb-4d39-a593-e94a4c88964a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-986605595-172.17.0.8-1597571399019:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38813,DS-9e4ceaa7-37d9-4667-b70d-bc5fc992177d,DISK], DatanodeInfoWithStorage[127.0.0.1:45734,DS-158e8a88-c044-4848-bd9d-c2a364e6b8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-346f8d4c-ff62-48f0-adab-e1c8cb3fbdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-a70f3de3-42b8-4adf-bdc7-a4da21931ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:34959,DS-32ae501d-0242-4858-9017-eba87b39898a,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-8796da71-6cf9-4ed4-9b89-c54c6ba686b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45887,DS-a9e4bbdb-7df2-4616-a497-4e692648bc60,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-ae997f78-0dfb-4d39-a593-e94a4c88964a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-83114513-172.17.0.8-1597571805767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33827,DS-e14b1b98-4516-45ae-aae5-81699a842da6,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-bca51661-ba52-4753-948d-0095b7f1104c,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-3bd851d8-903d-46a5-b9cc-9ada3168a3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-ccddf71b-5446-4a64-8870-5ef8c8cb9389,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-2cdecbfa-8b25-4c80-82ea-610e70b0c326,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-680578a9-9523-4bc5-a034-1075a8aae3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-e2973002-a873-436f-8a9b-c7f12a4e840e,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-313f8b83-2404-40dd-bc20-50af965edaeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-83114513-172.17.0.8-1597571805767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33827,DS-e14b1b98-4516-45ae-aae5-81699a842da6,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-bca51661-ba52-4753-948d-0095b7f1104c,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-3bd851d8-903d-46a5-b9cc-9ada3168a3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-ccddf71b-5446-4a64-8870-5ef8c8cb9389,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-2cdecbfa-8b25-4c80-82ea-610e70b0c326,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-680578a9-9523-4bc5-a034-1075a8aae3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-e2973002-a873-436f-8a9b-c7f12a4e840e,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-313f8b83-2404-40dd-bc20-50af965edaeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781877122-172.17.0.8-1597572005754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39359,DS-2732eb07-3fd8-4760-aeb9-cb88e184b6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-61a837a7-88a8-44dd-afa2-fb2a91172023,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-f26debb5-dd6d-4ad8-b0ba-678c85b5305f,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-b64bc627-2359-4fb1-9ade-c26a10509605,DISK], DatanodeInfoWithStorage[127.0.0.1:35530,DS-16bff46d-8cc4-44cc-ae8f-812dee96badd,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-031b996f-1502-472c-8973-8478bac4430e,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-ba75d7be-f950-44d2-9d54-e7ecbf8960a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-1e1baf33-c296-4e58-a9c3-6ecbc70aa3eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781877122-172.17.0.8-1597572005754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39359,DS-2732eb07-3fd8-4760-aeb9-cb88e184b6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-61a837a7-88a8-44dd-afa2-fb2a91172023,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-f26debb5-dd6d-4ad8-b0ba-678c85b5305f,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-b64bc627-2359-4fb1-9ade-c26a10509605,DISK], DatanodeInfoWithStorage[127.0.0.1:35530,DS-16bff46d-8cc4-44cc-ae8f-812dee96badd,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-031b996f-1502-472c-8973-8478bac4430e,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-ba75d7be-f950-44d2-9d54-e7ecbf8960a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-1e1baf33-c296-4e58-a9c3-6ecbc70aa3eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1193345254-172.17.0.8-1597572353049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45030,DS-c68047d5-7b0d-4e22-a051-b4b5d8dff55b,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-7701f785-e75a-4b8b-a6e3-0b6ae24dc256,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-b2540d99-dfb3-4075-8437-7cca77f90ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-e5e530d4-e3b1-4723-b42d-5b6afeebd7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-ab1186c2-d60d-474a-a3d6-946994fc768e,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-593507e0-7177-48d4-8d3c-4c5e1afbea7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-42b14b6b-f15f-4771-b253-edf56932b8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-d7f351bb-accf-4c37-9b06-11c4f8768460,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1193345254-172.17.0.8-1597572353049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45030,DS-c68047d5-7b0d-4e22-a051-b4b5d8dff55b,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-7701f785-e75a-4b8b-a6e3-0b6ae24dc256,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-b2540d99-dfb3-4075-8437-7cca77f90ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-e5e530d4-e3b1-4723-b42d-5b6afeebd7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-ab1186c2-d60d-474a-a3d6-946994fc768e,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-593507e0-7177-48d4-8d3c-4c5e1afbea7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-42b14b6b-f15f-4771-b253-edf56932b8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-d7f351bb-accf-4c37-9b06-11c4f8768460,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1540492108-172.17.0.8-1597572416891:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33385,DS-94d0ceba-e820-4b82-8399-2330f4ee4342,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-1c492bd8-8ded-4f04-bfe2-ec58c804c9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-c8ae1bcd-a6cc-43c0-9fcd-251bdd4488ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-16404f19-0070-412e-ae6f-ae4ba607072d,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-d2740321-ab46-4955-ac9e-fa34513b2fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37458,DS-3145685f-e533-4370-9eef-6e70e020aff8,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-2121a379-4055-4d6f-8664-9c26e3744844,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-cd965097-70c5-48e5-b33d-82a654ecf40f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1540492108-172.17.0.8-1597572416891:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33385,DS-94d0ceba-e820-4b82-8399-2330f4ee4342,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-1c492bd8-8ded-4f04-bfe2-ec58c804c9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-c8ae1bcd-a6cc-43c0-9fcd-251bdd4488ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-16404f19-0070-412e-ae6f-ae4ba607072d,DISK], DatanodeInfoWithStorage[127.0.0.1:42759,DS-d2740321-ab46-4955-ac9e-fa34513b2fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37458,DS-3145685f-e533-4370-9eef-6e70e020aff8,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-2121a379-4055-4d6f-8664-9c26e3744844,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-cd965097-70c5-48e5-b33d-82a654ecf40f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-797671941-172.17.0.8-1597572723668:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40401,DS-29befb0e-092f-453b-9060-3967be966eed,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-902b9cfb-7e04-4cce-bfa5-d19aa4ee55cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-382c682c-ebb6-46bd-af36-8d99e24ee5df,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-17ef0443-83af-49bb-8d46-2e4c4421e0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-f7e135f9-e6fe-4f3c-823c-7af6d90d50e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-155f246e-9f55-48e2-95e3-60adbb56d0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-237c6546-5532-4f2d-acf5-93ae9773459e,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-967ce6eb-c837-45b1-8852-8f0f9103d7a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-797671941-172.17.0.8-1597572723668:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40401,DS-29befb0e-092f-453b-9060-3967be966eed,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-902b9cfb-7e04-4cce-bfa5-d19aa4ee55cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-382c682c-ebb6-46bd-af36-8d99e24ee5df,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-17ef0443-83af-49bb-8d46-2e4c4421e0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-f7e135f9-e6fe-4f3c-823c-7af6d90d50e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-155f246e-9f55-48e2-95e3-60adbb56d0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-237c6546-5532-4f2d-acf5-93ae9773459e,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-967ce6eb-c837-45b1-8852-8f0f9103d7a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097543966-172.17.0.8-1597572763656:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38221,DS-f665d4cc-be2a-4917-815a-302e728f1759,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-e9829adf-16a3-43fa-adc6-f7f005b39de9,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-66498d64-0d62-44fd-b8dd-40e5013e8b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-fd42ea25-b743-4328-b354-0cd44f567082,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-fe04aff8-b75d-4899-b6b4-1f59953bd9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-99e64fab-e6f9-4fa3-8640-730733c81005,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-53a70b04-04a0-4658-b6df-037023fd1000,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-8fca61ca-af29-48c8-8795-1a57fd56de2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097543966-172.17.0.8-1597572763656:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38221,DS-f665d4cc-be2a-4917-815a-302e728f1759,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-e9829adf-16a3-43fa-adc6-f7f005b39de9,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-66498d64-0d62-44fd-b8dd-40e5013e8b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-fd42ea25-b743-4328-b354-0cd44f567082,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-fe04aff8-b75d-4899-b6b4-1f59953bd9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-99e64fab-e6f9-4fa3-8640-730733c81005,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-53a70b04-04a0-4658-b6df-037023fd1000,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-8fca61ca-af29-48c8-8795-1a57fd56de2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 268435456
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-411866210-172.17.0.8-1597573133254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39757,DS-f294d299-55ed-4f08-b8a4-fa35b4f1d852,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-cda14a65-6cbd-4ccb-ae7a-5c529eadaa87,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-82dbcdf7-c34b-4da5-8f4e-a6dfa9dbc213,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-4d500956-d49a-426c-8556-9925f05fb677,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-ba824a95-6cdc-484e-a1bc-61ce5bfb485e,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-6287045e-d56d-465d-b2d7-206bb510a746,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-97398b8b-5dda-49bb-839c-83167f90c0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-201194a4-0236-4326-a7da-81014cff887d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-411866210-172.17.0.8-1597573133254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39757,DS-f294d299-55ed-4f08-b8a4-fa35b4f1d852,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-cda14a65-6cbd-4ccb-ae7a-5c529eadaa87,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-82dbcdf7-c34b-4da5-8f4e-a6dfa9dbc213,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-4d500956-d49a-426c-8556-9925f05fb677,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-ba824a95-6cdc-484e-a1bc-61ce5bfb485e,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-6287045e-d56d-465d-b2d7-206bb510a746,DISK], DatanodeInfoWithStorage[127.0.0.1:41255,DS-97398b8b-5dda-49bb-839c-83167f90c0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-201194a4-0236-4326-a7da-81014cff887d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5666
