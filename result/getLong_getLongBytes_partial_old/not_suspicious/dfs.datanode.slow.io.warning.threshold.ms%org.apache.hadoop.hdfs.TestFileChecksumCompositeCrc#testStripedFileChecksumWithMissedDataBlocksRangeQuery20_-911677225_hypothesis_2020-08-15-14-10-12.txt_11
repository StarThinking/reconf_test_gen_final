reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1536379420-172.17.0.5-1597500628680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36328,DS-3bf511a5-77ec-42ad-b51f-13c8b45484b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-0d8fdcfc-b7cc-4cd4-afeb-6052af566845,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-3816503c-62e3-45a6-a5c4-73bada297afa,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-cef1687e-1878-43bd-830f-5eb34393743a,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-562e81a0-d1f1-464a-a087-fffe5848067d,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-19d7da73-124a-4e2d-82c6-2dd5dc8303ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-38b3ef32-e3ad-4d97-b6b5-beedb35bd115,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-83c9aac5-315f-4fbf-89a0-8383ee2ba06b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1536379420-172.17.0.5-1597500628680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36328,DS-3bf511a5-77ec-42ad-b51f-13c8b45484b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-0d8fdcfc-b7cc-4cd4-afeb-6052af566845,DISK], DatanodeInfoWithStorage[127.0.0.1:36180,DS-3816503c-62e3-45a6-a5c4-73bada297afa,DISK], DatanodeInfoWithStorage[127.0.0.1:37678,DS-cef1687e-1878-43bd-830f-5eb34393743a,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-562e81a0-d1f1-464a-a087-fffe5848067d,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-19d7da73-124a-4e2d-82c6-2dd5dc8303ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-38b3ef32-e3ad-4d97-b6b5-beedb35bd115,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-83c9aac5-315f-4fbf-89a0-8383ee2ba06b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-615525606-172.17.0.5-1597500731270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40747,DS-5e733ebc-9f6d-4004-93c4-9b7143e7af26,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-592ed5a8-08b3-4839-9948-415ad493312a,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-1cf94b29-94c2-49ba-9c56-c2f96eb3afd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-19d68f32-41f0-41c4-947b-0ce4e3978bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-76727b10-375a-4509-b756-b8a576f4940e,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-3fa7ed97-b696-4f7f-8a35-012191e6f218,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-1d45eb44-d3b5-4673-9e95-a60506468c73,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-074ee8a4-17ab-48fa-8479-d25c86679c56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-615525606-172.17.0.5-1597500731270:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40747,DS-5e733ebc-9f6d-4004-93c4-9b7143e7af26,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-592ed5a8-08b3-4839-9948-415ad493312a,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-1cf94b29-94c2-49ba-9c56-c2f96eb3afd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-19d68f32-41f0-41c4-947b-0ce4e3978bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-76727b10-375a-4509-b756-b8a576f4940e,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-3fa7ed97-b696-4f7f-8a35-012191e6f218,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-1d45eb44-d3b5-4673-9e95-a60506468c73,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-074ee8a4-17ab-48fa-8479-d25c86679c56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057298608-172.17.0.5-1597500770559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34038,DS-50c37134-e3d2-4106-a5eb-430fc1f19dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-04c68db7-5ab9-4c07-908d-5e17db38731b,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-9b6cec8a-665e-4fe6-94cc-30aa1159a181,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-85037454-d72e-4949-a1f2-fb7a2b5a5939,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-9648e4b4-10e1-493c-8049-7c521985bc05,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-a213a3ef-46fe-4bc3-9924-512cd7b7de31,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-91c18b56-549d-45ba-8215-8442f4b6227b,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-b6990b77-15a3-4c35-b869-d29a3bee18c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057298608-172.17.0.5-1597500770559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34038,DS-50c37134-e3d2-4106-a5eb-430fc1f19dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-04c68db7-5ab9-4c07-908d-5e17db38731b,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-9b6cec8a-665e-4fe6-94cc-30aa1159a181,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-85037454-d72e-4949-a1f2-fb7a2b5a5939,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-9648e4b4-10e1-493c-8049-7c521985bc05,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-a213a3ef-46fe-4bc3-9924-512cd7b7de31,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-91c18b56-549d-45ba-8215-8442f4b6227b,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-b6990b77-15a3-4c35-b869-d29a3bee18c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1709146477-172.17.0.5-1597500805791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46854,DS-b70c152c-e38b-4adf-b9ff-b7f1b7176542,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-3951fbcf-9532-417f-8099-92a310ec7129,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-3cf7652e-e364-4199-bc75-c508f50ee25c,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-76bdc2f8-e5a4-4fcd-b97a-bd4e97731e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-d75f19de-3909-42ea-a1d6-df53aa1b8dff,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-6f3bc775-6982-434c-8282-67ecd8dfba7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-43f775eb-d98c-4792-8491-c516489f586d,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-011fe77d-ca01-4914-8437-1d66bd3ce048,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1709146477-172.17.0.5-1597500805791:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46854,DS-b70c152c-e38b-4adf-b9ff-b7f1b7176542,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-3951fbcf-9532-417f-8099-92a310ec7129,DISK], DatanodeInfoWithStorage[127.0.0.1:34539,DS-3cf7652e-e364-4199-bc75-c508f50ee25c,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-76bdc2f8-e5a4-4fcd-b97a-bd4e97731e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-d75f19de-3909-42ea-a1d6-df53aa1b8dff,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-6f3bc775-6982-434c-8282-67ecd8dfba7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-43f775eb-d98c-4792-8491-c516489f586d,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-011fe77d-ca01-4914-8437-1d66bd3ce048,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-156771-172.17.0.5-1597500942955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43147,DS-bcc83871-0ffd-4382-97ba-11bc557d494d,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-4fffd2cd-5030-492b-a3af-7c3131c8bbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-3055c091-4ad9-44b0-bed5-02fc85652591,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-6087a56f-82ee-4e8d-86d9-52ddaaba4be7,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-ee5ab87e-d3ca-4136-80a1-ad65ba81a683,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-85cbd276-b566-42bd-a9ef-9a7b2e6f2156,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-f6d0157c-c5bb-4083-9a9e-2e557180951f,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-0e94ceff-6f3e-40b2-80ec-dc45953c55d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-156771-172.17.0.5-1597500942955:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43147,DS-bcc83871-0ffd-4382-97ba-11bc557d494d,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-4fffd2cd-5030-492b-a3af-7c3131c8bbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-3055c091-4ad9-44b0-bed5-02fc85652591,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-6087a56f-82ee-4e8d-86d9-52ddaaba4be7,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-ee5ab87e-d3ca-4136-80a1-ad65ba81a683,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-85cbd276-b566-42bd-a9ef-9a7b2e6f2156,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-f6d0157c-c5bb-4083-9a9e-2e557180951f,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-0e94ceff-6f3e-40b2-80ec-dc45953c55d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1706606425-172.17.0.5-1597502071215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41510,DS-f6093b58-3219-4fa2-b902-8ef99fb54fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-cbfcb1a1-ccf9-4829-982c-b3ab58eb862a,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-55f4e813-089b-4873-8baa-a8c24e204678,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-d8fb280d-4f24-47cc-acc8-935730194f11,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-0b7f7a09-b4ee-466e-ae8c-a3e6f831bfcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-ded35289-07af-4bbd-a927-d1c3e5046e66,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-a31a25ec-8d45-4cec-81b7-b77af5bed3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-3f8c2fab-252c-4a05-af9d-a72dd2768bca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1706606425-172.17.0.5-1597502071215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41510,DS-f6093b58-3219-4fa2-b902-8ef99fb54fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-cbfcb1a1-ccf9-4829-982c-b3ab58eb862a,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-55f4e813-089b-4873-8baa-a8c24e204678,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-d8fb280d-4f24-47cc-acc8-935730194f11,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-0b7f7a09-b4ee-466e-ae8c-a3e6f831bfcd,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-ded35289-07af-4bbd-a927-d1c3e5046e66,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-a31a25ec-8d45-4cec-81b7-b77af5bed3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-3f8c2fab-252c-4a05-af9d-a72dd2768bca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-502539160-172.17.0.5-1597502215749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33140,DS-49f97d58-bcdd-418b-9853-690673a549fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-fd574bc9-9ea1-4bd1-a562-0f2617148b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-be736369-d4fc-44a4-b188-5cd5bece7944,DISK], DatanodeInfoWithStorage[127.0.0.1:33097,DS-1e033115-a482-4194-ae3d-15f074f7e081,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-da38496a-e288-465c-a386-9c5454466146,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-3886fd66-f947-4f99-85de-5b57377dfede,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-4d60bbd2-416d-4786-b404-d8199ad544ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-71f2866d-6542-4923-870f-f4c45cfb6033,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-502539160-172.17.0.5-1597502215749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33140,DS-49f97d58-bcdd-418b-9853-690673a549fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-fd574bc9-9ea1-4bd1-a562-0f2617148b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-be736369-d4fc-44a4-b188-5cd5bece7944,DISK], DatanodeInfoWithStorage[127.0.0.1:33097,DS-1e033115-a482-4194-ae3d-15f074f7e081,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-da38496a-e288-465c-a386-9c5454466146,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-3886fd66-f947-4f99-85de-5b57377dfede,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-4d60bbd2-416d-4786-b404-d8199ad544ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-71f2866d-6542-4923-870f-f4c45cfb6033,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-179323170-172.17.0.5-1597502588879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43001,DS-1d0593f5-afbb-4d9f-920b-8a78cc05509b,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-671c67cd-67f1-4a98-b66a-0c6a005081bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-abce6aa4-40d2-446f-a66f-7ed2900ebae4,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-044b0bb6-efa0-4feb-a73e-6961ab6cfbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-35e9815e-fc50-4070-9c4d-3bc24cafd77a,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-34ccf09e-5e01-4fc7-a11a-8e35b85bdd91,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-e59ba081-5f7c-4e28-b607-9fe6716c7655,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-1f7f6761-6bd7-45cb-a275-5e45ce8169bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-179323170-172.17.0.5-1597502588879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43001,DS-1d0593f5-afbb-4d9f-920b-8a78cc05509b,DISK], DatanodeInfoWithStorage[127.0.0.1:34026,DS-671c67cd-67f1-4a98-b66a-0c6a005081bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-abce6aa4-40d2-446f-a66f-7ed2900ebae4,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-044b0bb6-efa0-4feb-a73e-6961ab6cfbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-35e9815e-fc50-4070-9c4d-3bc24cafd77a,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-34ccf09e-5e01-4fc7-a11a-8e35b85bdd91,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-e59ba081-5f7c-4e28-b607-9fe6716c7655,DISK], DatanodeInfoWithStorage[127.0.0.1:33668,DS-1f7f6761-6bd7-45cb-a275-5e45ce8169bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-772378355-172.17.0.5-1597502728395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38452,DS-262fe71d-ba13-4293-9e12-4cdcee147025,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-a7ece283-9f3e-4328-adf7-1f0693c32553,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-3f77a3a8-9cbf-4385-92ed-ef9cd36561fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-9e3ccc70-dc15-4574-a00d-a5e8c154be51,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-e684d2a2-4247-4c63-b85e-894aa5acb4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-8caaf997-c0a5-450b-886f-20dee9af7c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-f0a02457-1fde-45ce-8dd9-78131dc33e04,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-381a0b4c-f053-472d-8dae-543ecea0afdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-772378355-172.17.0.5-1597502728395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38452,DS-262fe71d-ba13-4293-9e12-4cdcee147025,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-a7ece283-9f3e-4328-adf7-1f0693c32553,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-3f77a3a8-9cbf-4385-92ed-ef9cd36561fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-9e3ccc70-dc15-4574-a00d-a5e8c154be51,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-e684d2a2-4247-4c63-b85e-894aa5acb4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-8caaf997-c0a5-450b-886f-20dee9af7c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-f0a02457-1fde-45ce-8dd9-78131dc33e04,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-381a0b4c-f053-472d-8dae-543ecea0afdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-922891039-172.17.0.5-1597502790635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33508,DS-7f960c74-a719-4ecc-b9a0-33138811dddb,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-41459790-1cd1-490c-8863-772bff659136,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-44f92213-e7be-48a9-8a90-6697b2804a16,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-cecbbe69-ad3d-4bfb-8167-94854c5ddfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-da5ea535-1ca4-48f7-8f69-da8f2bf55580,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-adf99663-b07c-46da-bdd8-093050a106f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-b786ee79-ff9b-4284-8814-87ffcc471195,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-b1d7cb6d-82b8-4993-a3c0-8e9c3876ab6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-922891039-172.17.0.5-1597502790635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33508,DS-7f960c74-a719-4ecc-b9a0-33138811dddb,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-41459790-1cd1-490c-8863-772bff659136,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-44f92213-e7be-48a9-8a90-6697b2804a16,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-cecbbe69-ad3d-4bfb-8167-94854c5ddfa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-da5ea535-1ca4-48f7-8f69-da8f2bf55580,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-adf99663-b07c-46da-bdd8-093050a106f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-b786ee79-ff9b-4284-8814-87ffcc471195,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-b1d7cb6d-82b8-4993-a3c0-8e9c3876ab6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1189856680-172.17.0.5-1597503009412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44397,DS-64c6c5df-2395-4e3e-b699-625a51cb7fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-c6250987-a4c0-4238-ad90-d52680d6609c,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-a1c4ba43-d78b-43de-8b0d-2d08fd4ef8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-75e573f1-645b-4cfa-a2b1-839a2cab5e43,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-49dae403-53ff-4334-9770-a4f4a809408f,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-054b3794-97b6-4870-83ce-eba2500a3116,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-bc15cbcf-5c7f-4c1c-a19d-457d26572652,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-1eb8b86e-8398-4c61-a393-af834b39073a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1189856680-172.17.0.5-1597503009412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44397,DS-64c6c5df-2395-4e3e-b699-625a51cb7fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-c6250987-a4c0-4238-ad90-d52680d6609c,DISK], DatanodeInfoWithStorage[127.0.0.1:44230,DS-a1c4ba43-d78b-43de-8b0d-2d08fd4ef8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-75e573f1-645b-4cfa-a2b1-839a2cab5e43,DISK], DatanodeInfoWithStorage[127.0.0.1:45554,DS-49dae403-53ff-4334-9770-a4f4a809408f,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-054b3794-97b6-4870-83ce-eba2500a3116,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-bc15cbcf-5c7f-4c1c-a19d-457d26572652,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-1eb8b86e-8398-4c61-a393-af834b39073a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1425119173-172.17.0.5-1597503222492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35472,DS-4a4d2283-86f9-4b8a-8372-aadba9f7d09c,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-f6914d67-5087-41f4-aacb-d3e5b9f57edb,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-63db2c09-22f4-4582-b38c-a30c896fb1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-725df9f2-3938-44b2-9d30-c50d2cafa2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-7905f516-5f81-41e8-a683-fc67a0e4d697,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-2190e65e-f6b8-47eb-9852-566a3676a156,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-6b94969f-7a56-4ebb-a325-bdfbf0eb5ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-6b4c6e3e-e690-41f6-82c7-de1ab813651d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1425119173-172.17.0.5-1597503222492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35472,DS-4a4d2283-86f9-4b8a-8372-aadba9f7d09c,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-f6914d67-5087-41f4-aacb-d3e5b9f57edb,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-63db2c09-22f4-4582-b38c-a30c896fb1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-725df9f2-3938-44b2-9d30-c50d2cafa2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-7905f516-5f81-41e8-a683-fc67a0e4d697,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-2190e65e-f6b8-47eb-9852-566a3676a156,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-6b94969f-7a56-4ebb-a325-bdfbf0eb5ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-6b4c6e3e-e690-41f6-82c7-de1ab813651d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-456299030-172.17.0.5-1597503324244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35454,DS-9a32ab79-6d46-4fca-9cc2-39d913bc767b,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-95411749-7d42-4fa3-8a1c-4fcf5e1fa3db,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-9fad263a-11d5-46c2-a079-cf6047a026c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-fad54cd1-d4e4-483a-afe9-3bf825560217,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-e76ba415-793b-4b27-af2e-c20999dace5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-1240839f-c751-48ef-8187-0957f0c7fc10,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-a9e8d334-a899-469e-b105-a6d210cf5f87,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-c4570fb3-4eed-401f-8caa-161ae7f1bfdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-456299030-172.17.0.5-1597503324244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35454,DS-9a32ab79-6d46-4fca-9cc2-39d913bc767b,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-95411749-7d42-4fa3-8a1c-4fcf5e1fa3db,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-9fad263a-11d5-46c2-a079-cf6047a026c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-fad54cd1-d4e4-483a-afe9-3bf825560217,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-e76ba415-793b-4b27-af2e-c20999dace5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-1240839f-c751-48ef-8187-0957f0c7fc10,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-a9e8d334-a899-469e-b105-a6d210cf5f87,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-c4570fb3-4eed-401f-8caa-161ae7f1bfdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1646130692-172.17.0.5-1597504068689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36108,DS-4e72e528-bd8d-47da-bddc-acbd9643be30,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-ff99240f-e96c-4e7f-bd0f-d9c1144a2dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-2894d132-ecab-4475-a34e-db73e31e7702,DISK], DatanodeInfoWithStorage[127.0.0.1:35994,DS-c93bea4c-fd61-472d-b405-65555122785e,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-63ab235c-3dde-4d11-b3b8-c55581f1bbba,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-12a5fee7-2321-4c53-b5ec-941ae5eed62d,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-67c956db-fd53-4a2c-93e7-f50de77c024e,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-d65d4f7d-63c7-4387-bc5c-c482784ab5b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1646130692-172.17.0.5-1597504068689:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36108,DS-4e72e528-bd8d-47da-bddc-acbd9643be30,DISK], DatanodeInfoWithStorage[127.0.0.1:39910,DS-ff99240f-e96c-4e7f-bd0f-d9c1144a2dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45664,DS-2894d132-ecab-4475-a34e-db73e31e7702,DISK], DatanodeInfoWithStorage[127.0.0.1:35994,DS-c93bea4c-fd61-472d-b405-65555122785e,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-63ab235c-3dde-4d11-b3b8-c55581f1bbba,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-12a5fee7-2321-4c53-b5ec-941ae5eed62d,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-67c956db-fd53-4a2c-93e7-f50de77c024e,DISK], DatanodeInfoWithStorage[127.0.0.1:44049,DS-d65d4f7d-63c7-4387-bc5c-c482784ab5b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-336710573-172.17.0.5-1597504475961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35471,DS-c6ddfb3b-851b-4916-917c-6ccab599c807,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-0014d29d-5b66-4c31-aaf2-4bbad41b07a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-f406a997-8b3c-481f-b884-3be5c4da981f,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-642fc0d6-3581-4586-bebe-d1ca1f37fed6,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-0a199b02-88b9-4de1-ad62-5a49b9f5c51a,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-df4d4c4d-919f-492f-9d6c-d31d3fd2ac5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-aa675dbc-fa9c-4864-aacf-59eb95b0db95,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-a4776fc2-7b6c-4449-80c4-c79a6586dbe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-336710573-172.17.0.5-1597504475961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35471,DS-c6ddfb3b-851b-4916-917c-6ccab599c807,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-0014d29d-5b66-4c31-aaf2-4bbad41b07a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-f406a997-8b3c-481f-b884-3be5c4da981f,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-642fc0d6-3581-4586-bebe-d1ca1f37fed6,DISK], DatanodeInfoWithStorage[127.0.0.1:33063,DS-0a199b02-88b9-4de1-ad62-5a49b9f5c51a,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-df4d4c4d-919f-492f-9d6c-d31d3fd2ac5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-aa675dbc-fa9c-4864-aacf-59eb95b0db95,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-a4776fc2-7b6c-4449-80c4-c79a6586dbe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-133818229-172.17.0.5-1597504576631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36866,DS-3b4def79-16ab-4d63-93a6-8fc6be0dad7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-ebcf0e92-502b-49da-9e3f-3b901a8078e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-9aa9c2af-da89-4fb5-85ab-0783aea4e6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-b1289024-8893-4241-b784-653073e74a48,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-8fd724f3-052f-4009-9dcc-f84e6ff58dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-508438ef-4e06-4f94-abdd-f68d8af30220,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-dd8f6709-25fc-42ad-ad77-33ca88b8c407,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-d8b1bea5-e043-43e2-9a8c-a1f5748a7421,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-133818229-172.17.0.5-1597504576631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36866,DS-3b4def79-16ab-4d63-93a6-8fc6be0dad7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-ebcf0e92-502b-49da-9e3f-3b901a8078e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33794,DS-9aa9c2af-da89-4fb5-85ab-0783aea4e6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-b1289024-8893-4241-b784-653073e74a48,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-8fd724f3-052f-4009-9dcc-f84e6ff58dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:42376,DS-508438ef-4e06-4f94-abdd-f68d8af30220,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-dd8f6709-25fc-42ad-ad77-33ca88b8c407,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-d8b1bea5-e043-43e2-9a8c-a1f5748a7421,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2047157589-172.17.0.5-1597504613975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43461,DS-12b72747-1076-4566-99b3-0cb88f721a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-8f103f61-4982-4fb9-8807-bc267c12a105,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-326b1fb9-7da2-4584-8987-b968011fbaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-272ce1ff-3f68-4153-b706-87a9cecec3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-18dfbd7c-4be6-4927-bbca-980e2d287a45,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-98b0b204-81a1-467a-b122-3992d96e01b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-3690f458-6802-4950-a597-b53affb2c0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-c439e16b-f534-46c0-9df3-a840d3f1e0bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2047157589-172.17.0.5-1597504613975:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43461,DS-12b72747-1076-4566-99b3-0cb88f721a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-8f103f61-4982-4fb9-8807-bc267c12a105,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-326b1fb9-7da2-4584-8987-b968011fbaa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-272ce1ff-3f68-4153-b706-87a9cecec3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-18dfbd7c-4be6-4927-bbca-980e2d287a45,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-98b0b204-81a1-467a-b122-3992d96e01b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-3690f458-6802-4950-a597-b53affb2c0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-c439e16b-f534-46c0-9df3-a840d3f1e0bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1032916795-172.17.0.5-1597505028304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42285,DS-64d2b8c0-5fe5-4db7-9698-231bc972ceb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-883e40be-cc2f-4af8-8681-778a73b5af57,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-536c2a41-cab7-4888-a6a5-0154bf8512b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35561,DS-55a22cd6-853a-4518-8ab8-8cff5e0a88fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-b49a4d9d-d850-48ed-8279-1094c9890d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-8b42f617-e8fb-4717-82f9-8dab714e2cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-a26c9af8-e9e2-4692-a259-f875d578728e,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-3d5d7182-5daa-4ab2-9dfc-963410cdeef0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1032916795-172.17.0.5-1597505028304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42285,DS-64d2b8c0-5fe5-4db7-9698-231bc972ceb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-883e40be-cc2f-4af8-8681-778a73b5af57,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-536c2a41-cab7-4888-a6a5-0154bf8512b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35561,DS-55a22cd6-853a-4518-8ab8-8cff5e0a88fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42104,DS-b49a4d9d-d850-48ed-8279-1094c9890d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34394,DS-8b42f617-e8fb-4717-82f9-8dab714e2cd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-a26c9af8-e9e2-4692-a259-f875d578728e,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-3d5d7182-5daa-4ab2-9dfc-963410cdeef0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1323733152-172.17.0.5-1597505322433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33307,DS-db3ba5f8-7b8c-4159-8cae-a2b602c55a80,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-e431da46-5823-4f87-bdc5-a7b0071641cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-b876ede5-459e-42c0-a953-9427ab8eb60e,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-3f8ce5c3-ade2-4c64-84ba-6371acc685dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-777915d3-9a01-42c2-b680-d83444412b11,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-787fde52-324b-4d6d-8176-175d56e51600,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-ccffddf3-82d5-425a-8fc9-a4eaa041a878,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-7d73f546-a574-4ad0-9754-75353dbba861,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1323733152-172.17.0.5-1597505322433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33307,DS-db3ba5f8-7b8c-4159-8cae-a2b602c55a80,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-e431da46-5823-4f87-bdc5-a7b0071641cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-b876ede5-459e-42c0-a953-9427ab8eb60e,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-3f8ce5c3-ade2-4c64-84ba-6371acc685dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-777915d3-9a01-42c2-b680-d83444412b11,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-787fde52-324b-4d6d-8176-175d56e51600,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-ccffddf3-82d5-425a-8fc9-a4eaa041a878,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-7d73f546-a574-4ad0-9754-75353dbba861,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1219293992-172.17.0.5-1597505484969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43326,DS-75770a99-26dd-4c22-9807-ddb4efa72b01,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-e858d20b-c78e-4310-9921-cf8f4339be0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-20c4d835-5493-4567-b163-eb4cdc2d6926,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-8359ffb4-0a56-41cb-a7c4-bc236cfe4f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-cf47717e-d91f-4b15-b264-446a88ca16a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-2a06784f-1b8e-4247-8947-1bf3396be944,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-071bdba6-2dbd-42ea-9b2c-0bc455acbf63,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-078f3f6b-6b36-41e5-95c6-d1bcf0aad232,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1219293992-172.17.0.5-1597505484969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43326,DS-75770a99-26dd-4c22-9807-ddb4efa72b01,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-e858d20b-c78e-4310-9921-cf8f4339be0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37808,DS-20c4d835-5493-4567-b163-eb4cdc2d6926,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-8359ffb4-0a56-41cb-a7c4-bc236cfe4f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-cf47717e-d91f-4b15-b264-446a88ca16a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-2a06784f-1b8e-4247-8947-1bf3396be944,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-071bdba6-2dbd-42ea-9b2c-0bc455acbf63,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-078f3f6b-6b36-41e5-95c6-d1bcf0aad232,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5266
