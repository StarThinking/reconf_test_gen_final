reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794748528-172.17.0.6-1597480685401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35547,DS-99a7de81-8e64-484d-b53e-23701a53ddde,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-f446820b-326d-45d1-991b-56cec1b7068c,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-302439b7-f6d8-4334-990c-9808d2f374a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-4b6d663a-044d-4d92-9f5d-1bb1e9733a67,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-803dbdec-0662-4b70-8822-978d77bfa010,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-1be8bcac-16cf-4ed5-9237-a827e4810304,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-4c4d9a7b-7f72-48c2-8a95-3df73e4ea656,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-f8101214-7e65-4a6b-b3ed-a2db1d459dbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794748528-172.17.0.6-1597480685401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35547,DS-99a7de81-8e64-484d-b53e-23701a53ddde,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-f446820b-326d-45d1-991b-56cec1b7068c,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-302439b7-f6d8-4334-990c-9808d2f374a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-4b6d663a-044d-4d92-9f5d-1bb1e9733a67,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-803dbdec-0662-4b70-8822-978d77bfa010,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-1be8bcac-16cf-4ed5-9237-a827e4810304,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-4c4d9a7b-7f72-48c2-8a95-3df73e4ea656,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-f8101214-7e65-4a6b-b3ed-a2db1d459dbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475775065-172.17.0.6-1597481230596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42593,DS-dda43b01-b94d-4297-b4f9-7615e8e6d207,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-d8f5aa18-af4f-4b5b-b9c0-e4ec54cb0298,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-453c46f5-3d65-4036-ad55-c33db9a4bec2,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-e19aad8c-a1ac-4ac3-b4c5-7f40630d6af7,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-4aaa4861-2f36-4845-aea6-c5ffebb0a76b,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-a862db9f-cca9-4efa-b803-587b0af6842a,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-549a0675-cca5-4299-b807-9088b03fb24d,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-b7eaa8a0-291b-45f1-9aed-6179975b00b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475775065-172.17.0.6-1597481230596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42593,DS-dda43b01-b94d-4297-b4f9-7615e8e6d207,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-d8f5aa18-af4f-4b5b-b9c0-e4ec54cb0298,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-453c46f5-3d65-4036-ad55-c33db9a4bec2,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-e19aad8c-a1ac-4ac3-b4c5-7f40630d6af7,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-4aaa4861-2f36-4845-aea6-c5ffebb0a76b,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-a862db9f-cca9-4efa-b803-587b0af6842a,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-549a0675-cca5-4299-b807-9088b03fb24d,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-b7eaa8a0-291b-45f1-9aed-6179975b00b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1768651758-172.17.0.6-1597481412462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40952,DS-e4da0b57-a3a3-4e08-9893-26c969c98bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-1e7b1c41-0df9-47db-af25-61eda690261c,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-1a77a0ce-2a04-4136-8642-e5539b3ca10f,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-fa6c43c0-8c48-4997-bf34-e2a122985c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-c05fb0e7-f67c-4a3f-abac-393073148071,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-5202c876-1fb8-49c1-8e4f-f650a9402135,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-bfb4ed8d-b858-4a2d-93f8-c41d093aad5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-45f68511-629d-4710-80bf-518866cf1e6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1768651758-172.17.0.6-1597481412462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40952,DS-e4da0b57-a3a3-4e08-9893-26c969c98bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-1e7b1c41-0df9-47db-af25-61eda690261c,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-1a77a0ce-2a04-4136-8642-e5539b3ca10f,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-fa6c43c0-8c48-4997-bf34-e2a122985c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-c05fb0e7-f67c-4a3f-abac-393073148071,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-5202c876-1fb8-49c1-8e4f-f650a9402135,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-bfb4ed8d-b858-4a2d-93f8-c41d093aad5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-45f68511-629d-4710-80bf-518866cf1e6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1209173003-172.17.0.6-1597481947776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41158,DS-e54a5aa7-3209-4971-bb26-caf31c0059d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-de1eabbc-4661-4581-a1f0-bb1a9ffc45aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-e09fc456-8423-45d1-ad68-217e339671ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-be185320-8adc-4d1d-a749-5b9369018bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43760,DS-988af710-13e6-4b10-b78e-d6b87b380782,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-e0f9231a-4283-4ba4-ab70-dfa715b3cbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-cf66c7dc-93a6-4dae-9ef6-88603d763a00,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-a86c9d09-6bac-448b-b97b-b0ec2d2db770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1209173003-172.17.0.6-1597481947776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41158,DS-e54a5aa7-3209-4971-bb26-caf31c0059d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-de1eabbc-4661-4581-a1f0-bb1a9ffc45aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-e09fc456-8423-45d1-ad68-217e339671ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-be185320-8adc-4d1d-a749-5b9369018bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43760,DS-988af710-13e6-4b10-b78e-d6b87b380782,DISK], DatanodeInfoWithStorage[127.0.0.1:37624,DS-e0f9231a-4283-4ba4-ab70-dfa715b3cbe8,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-cf66c7dc-93a6-4dae-9ef6-88603d763a00,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-a86c9d09-6bac-448b-b97b-b0ec2d2db770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-704463383-172.17.0.6-1597482023976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38951,DS-a83cd871-ecb0-4102-993c-7e11c2e2996b,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-299d0e25-879c-4626-8f4c-737dd765420f,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-16b612f4-5224-4140-aa22-5dbd90444d02,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-959f30b2-664c-4fb0-8ab5-8e6913cadb29,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-2cc4ed08-a4ec-463f-a128-3c165dde9872,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-b02bf588-9d20-4844-835d-4e4f9dd8f545,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-9f4887aa-7a3a-4389-93af-d03e4274cefc,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-39884c95-7085-4c18-8115-b850fe8700e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-704463383-172.17.0.6-1597482023976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38951,DS-a83cd871-ecb0-4102-993c-7e11c2e2996b,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-299d0e25-879c-4626-8f4c-737dd765420f,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-16b612f4-5224-4140-aa22-5dbd90444d02,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-959f30b2-664c-4fb0-8ab5-8e6913cadb29,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-2cc4ed08-a4ec-463f-a128-3c165dde9872,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-b02bf588-9d20-4844-835d-4e4f9dd8f545,DISK], DatanodeInfoWithStorage[127.0.0.1:43302,DS-9f4887aa-7a3a-4389-93af-d03e4274cefc,DISK], DatanodeInfoWithStorage[127.0.0.1:44790,DS-39884c95-7085-4c18-8115-b850fe8700e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1762589589-172.17.0.6-1597482092982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35373,DS-6e474243-7cd5-44d5-8906-ef1946315b29,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-a2479b46-757c-4f72-a687-da4bf4066d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-d0a41e6a-03ea-44ff-bc6f-ee1e0ceb6bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-9027e96f-192a-426f-b186-9fc25c69faa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-89279479-7e54-4cce-975a-08275791ddf0,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-e10b0405-e50c-45c0-a397-57049fa7c8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-0b0b4cca-382e-426f-9f86-048ae429d94d,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-a9242b55-ce6c-4e23-bc6d-6db1fe902db8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1762589589-172.17.0.6-1597482092982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35373,DS-6e474243-7cd5-44d5-8906-ef1946315b29,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-a2479b46-757c-4f72-a687-da4bf4066d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-d0a41e6a-03ea-44ff-bc6f-ee1e0ceb6bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-9027e96f-192a-426f-b186-9fc25c69faa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-89279479-7e54-4cce-975a-08275791ddf0,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-e10b0405-e50c-45c0-a397-57049fa7c8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36401,DS-0b0b4cca-382e-426f-9f86-048ae429d94d,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-a9242b55-ce6c-4e23-bc6d-6db1fe902db8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-438317945-172.17.0.6-1597482451390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35083,DS-c292dd62-78f5-4aa8-8451-b4216d405a73,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-9d055074-6737-46da-a6ed-4486e3479370,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-c7b7c5aa-a110-4d91-8363-b5380ecc5829,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-340a5711-b7c8-4967-b500-c7f6be681e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-055400dd-d0f1-46ba-aa4f-03b7b1504042,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-9364195e-6dcb-4d82-9392-88aa75eacb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-2108b0bc-8fef-40c5-9b5d-6243ec003e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-fa777ea8-07fd-421a-b5a3-701eb7ddd9a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-438317945-172.17.0.6-1597482451390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35083,DS-c292dd62-78f5-4aa8-8451-b4216d405a73,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-9d055074-6737-46da-a6ed-4486e3479370,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-c7b7c5aa-a110-4d91-8363-b5380ecc5829,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-340a5711-b7c8-4967-b500-c7f6be681e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-055400dd-d0f1-46ba-aa4f-03b7b1504042,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-9364195e-6dcb-4d82-9392-88aa75eacb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-2108b0bc-8fef-40c5-9b5d-6243ec003e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-fa777ea8-07fd-421a-b5a3-701eb7ddd9a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-67541526-172.17.0.6-1597482607543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34957,DS-60aab39d-3292-4e38-bf41-d789f265ebdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-f00a8c6a-1261-4deb-ae4b-7209280ace0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41968,DS-effb6e5a-188f-4bd0-a897-f539a5313335,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-1135dce1-43a4-4096-82ad-a4ae508ec56a,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-fdb2155d-b35d-4e55-a321-9b70e53e8a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-979830de-5131-4d2f-a495-2b1196059760,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-a91d6ccd-e76a-4449-b949-801fdd923090,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-6320c640-6290-4f96-88da-3d1399f7d846,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-67541526-172.17.0.6-1597482607543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34957,DS-60aab39d-3292-4e38-bf41-d789f265ebdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-f00a8c6a-1261-4deb-ae4b-7209280ace0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41968,DS-effb6e5a-188f-4bd0-a897-f539a5313335,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-1135dce1-43a4-4096-82ad-a4ae508ec56a,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-fdb2155d-b35d-4e55-a321-9b70e53e8a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-979830de-5131-4d2f-a495-2b1196059760,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-a91d6ccd-e76a-4449-b949-801fdd923090,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-6320c640-6290-4f96-88da-3d1399f7d846,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841359130-172.17.0.6-1597483262685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37986,DS-34327302-8d6c-4e87-8d27-f4e787d8eea7,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-12de8a46-71e8-49ca-af9e-0f2ff5d3070b,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-811a34d9-c282-4a11-99d1-03a7a4c53c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-25c93a8b-5360-4370-a013-3201eb584183,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-22807e68-6264-4163-9e53-67d818da363b,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-831b46ce-a4dd-46f0-9999-3f5c10a6be00,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-4d36b64b-5682-4cd8-b004-a7b27ad45c90,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-d5079d9d-75cc-4768-b8e1-81248d8f877e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841359130-172.17.0.6-1597483262685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37986,DS-34327302-8d6c-4e87-8d27-f4e787d8eea7,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-12de8a46-71e8-49ca-af9e-0f2ff5d3070b,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-811a34d9-c282-4a11-99d1-03a7a4c53c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-25c93a8b-5360-4370-a013-3201eb584183,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-22807e68-6264-4163-9e53-67d818da363b,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-831b46ce-a4dd-46f0-9999-3f5c10a6be00,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-4d36b64b-5682-4cd8-b004-a7b27ad45c90,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-d5079d9d-75cc-4768-b8e1-81248d8f877e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-31826423-172.17.0.6-1597484108332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35150,DS-748e308a-7675-4743-81af-ff1f1b2d4d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-ec73ffd7-417e-42d9-8d60-7dbc67678b23,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-7820f350-4fce-410f-8c0d-293429972298,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-a03db96e-bc2e-4c03-b3d9-6e04f10040eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-29ac2dbd-513f-4e39-89d0-149990df5dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-186044f2-b209-4512-8589-00b604739340,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-06df4e82-9667-4c27-9092-7afa8617fa17,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-f98e2847-70e3-4e08-8e24-6857f490823b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-31826423-172.17.0.6-1597484108332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35150,DS-748e308a-7675-4743-81af-ff1f1b2d4d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-ec73ffd7-417e-42d9-8d60-7dbc67678b23,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-7820f350-4fce-410f-8c0d-293429972298,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-a03db96e-bc2e-4c03-b3d9-6e04f10040eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-29ac2dbd-513f-4e39-89d0-149990df5dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-186044f2-b209-4512-8589-00b604739340,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-06df4e82-9667-4c27-9092-7afa8617fa17,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-f98e2847-70e3-4e08-8e24-6857f490823b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980146516-172.17.0.6-1597484631682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46180,DS-3a7a4a83-1bff-4298-bbc3-01de31c217ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-bd580407-8df8-47e3-af0d-fa4a2e1c2a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-66ff60c5-00ad-41e0-bc8b-d04412045ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-afc7bbb4-feef-4529-9d73-8d7c7b1faed0,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-a7db3f60-acf0-468b-9004-9629ff3f00e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-1bac5168-9350-449b-8895-dccd4a465cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-3e5e5374-162d-498a-99d8-e0b1091766ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-e1c6507a-2743-4469-b59b-795bd6075b44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980146516-172.17.0.6-1597484631682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46180,DS-3a7a4a83-1bff-4298-bbc3-01de31c217ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-bd580407-8df8-47e3-af0d-fa4a2e1c2a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-66ff60c5-00ad-41e0-bc8b-d04412045ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:40530,DS-afc7bbb4-feef-4529-9d73-8d7c7b1faed0,DISK], DatanodeInfoWithStorage[127.0.0.1:36775,DS-a7db3f60-acf0-468b-9004-9629ff3f00e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43000,DS-1bac5168-9350-449b-8895-dccd4a465cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-3e5e5374-162d-498a-99d8-e0b1091766ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-e1c6507a-2743-4469-b59b-795bd6075b44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994716067-172.17.0.6-1597484699932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41081,DS-07a0a154-6d53-4235-95a1-7469b7b4c564,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-bdae200e-9f8c-408a-81c6-c8d1f400ae5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-c46e3023-1363-48c8-ae85-3c719aa40cef,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-4fb168a7-fb3b-4048-a36a-2409edfc0441,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-00acb124-6c0f-41df-abcd-6eb5e86627a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-e3590ae6-2e9e-425f-a2bc-a0313ff6f20b,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-5603f861-aa6e-45bf-a0eb-3bf26bdb45e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-0bc81cec-8aec-43de-a73b-0be96f96c312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994716067-172.17.0.6-1597484699932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41081,DS-07a0a154-6d53-4235-95a1-7469b7b4c564,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-bdae200e-9f8c-408a-81c6-c8d1f400ae5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-c46e3023-1363-48c8-ae85-3c719aa40cef,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-4fb168a7-fb3b-4048-a36a-2409edfc0441,DISK], DatanodeInfoWithStorage[127.0.0.1:41491,DS-00acb124-6c0f-41df-abcd-6eb5e86627a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-e3590ae6-2e9e-425f-a2bc-a0313ff6f20b,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-5603f861-aa6e-45bf-a0eb-3bf26bdb45e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-0bc81cec-8aec-43de-a73b-0be96f96c312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-624432688-172.17.0.6-1597484809340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41226,DS-fa3b8a7f-3d34-4848-ad2a-abdce1dc358b,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-da0213e0-14d1-4f7b-90ed-eee65b5305bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-a56c8d6f-7979-4b11-8777-6d3c9c38dcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-7a04cb28-65a7-4ee1-a400-5d20c0242bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-ffcb7f12-852f-4839-8f01-98ee5a01dc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-d1152f6b-5d04-4322-9d39-0e6a0dd593f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-332c4820-d867-4656-9e94-577f2c5f5f92,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-9c90285e-cf21-474a-8717-ff619a0d582a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-624432688-172.17.0.6-1597484809340:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41226,DS-fa3b8a7f-3d34-4848-ad2a-abdce1dc358b,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-da0213e0-14d1-4f7b-90ed-eee65b5305bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-a56c8d6f-7979-4b11-8777-6d3c9c38dcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-7a04cb28-65a7-4ee1-a400-5d20c0242bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-ffcb7f12-852f-4839-8f01-98ee5a01dc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-d1152f6b-5d04-4322-9d39-0e6a0dd593f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-332c4820-d867-4656-9e94-577f2c5f5f92,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-9c90285e-cf21-474a-8717-ff619a0d582a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1679666406-172.17.0.6-1597484913668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40127,DS-cb416db1-e055-493b-8f62-5f42752f949c,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-f4994a54-f2dc-4042-b625-2ccaa2988a33,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-8cdba5fb-58c9-4f6f-863f-3cc130f0f416,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-efa2ed4d-9577-4501-8fae-18878e295ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-1160b9b6-b1a9-4694-b211-609ec5a20512,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-e4ac5eda-4043-436d-88d6-dad7ce86c6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-d2fb6fda-95e5-49ff-ad53-634ff564cecb,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-052ae3e8-ec81-478d-9f42-2a8fef752c65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1679666406-172.17.0.6-1597484913668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40127,DS-cb416db1-e055-493b-8f62-5f42752f949c,DISK], DatanodeInfoWithStorage[127.0.0.1:37605,DS-f4994a54-f2dc-4042-b625-2ccaa2988a33,DISK], DatanodeInfoWithStorage[127.0.0.1:43581,DS-8cdba5fb-58c9-4f6f-863f-3cc130f0f416,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-efa2ed4d-9577-4501-8fae-18878e295ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-1160b9b6-b1a9-4694-b211-609ec5a20512,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-e4ac5eda-4043-436d-88d6-dad7ce86c6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-d2fb6fda-95e5-49ff-ad53-634ff564cecb,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-052ae3e8-ec81-478d-9f42-2a8fef752c65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-844450288-172.17.0.6-1597484949402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46139,DS-29bf3f92-323a-4b80-b194-5873d179a593,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-d3ed254b-0299-4f59-9c94-42acd9a1b64a,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-960104b4-1343-4c48-ba1d-70bc3d83ec5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-bd5841f6-9162-4225-a6d9-76ca79a76cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-91acc1c6-6aba-4823-8fc2-50d9c90a808f,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-b83a682e-dbed-4cff-9c5d-533fe4afc239,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-a4ce88d2-f6ac-43b7-bd30-e264380f937c,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-11b5ce7f-c4c6-4eaf-b4e2-57a6cf32b57f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-844450288-172.17.0.6-1597484949402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46139,DS-29bf3f92-323a-4b80-b194-5873d179a593,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-d3ed254b-0299-4f59-9c94-42acd9a1b64a,DISK], DatanodeInfoWithStorage[127.0.0.1:45711,DS-960104b4-1343-4c48-ba1d-70bc3d83ec5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-bd5841f6-9162-4225-a6d9-76ca79a76cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-91acc1c6-6aba-4823-8fc2-50d9c90a808f,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-b83a682e-dbed-4cff-9c5d-533fe4afc239,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-a4ce88d2-f6ac-43b7-bd30-e264380f937c,DISK], DatanodeInfoWithStorage[127.0.0.1:36124,DS-11b5ce7f-c4c6-4eaf-b4e2-57a6cf32b57f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-404571113-172.17.0.6-1597485099351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45481,DS-bb26f3bf-c258-467f-89d4-531f3d384d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-d3cb1ff9-a4fe-49c9-9f47-23a23d277d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-c221aeff-d1ac-4f8e-95c4-5de210712257,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-5afcbcbc-e52b-45a4-b9d6-167971985d07,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-e04067f9-a9ee-4ec0-afa1-f947102532c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-c5a14e35-e261-4d12-a827-77edb4cd2552,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-e7ec62c5-17d7-4a0a-8619-f11efa3da0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-68dcf00d-2e5b-49fe-ba9b-28e5ffdd38b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-404571113-172.17.0.6-1597485099351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45481,DS-bb26f3bf-c258-467f-89d4-531f3d384d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-d3cb1ff9-a4fe-49c9-9f47-23a23d277d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-c221aeff-d1ac-4f8e-95c4-5de210712257,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-5afcbcbc-e52b-45a4-b9d6-167971985d07,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-e04067f9-a9ee-4ec0-afa1-f947102532c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-c5a14e35-e261-4d12-a827-77edb4cd2552,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-e7ec62c5-17d7-4a0a-8619-f11efa3da0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-68dcf00d-2e5b-49fe-ba9b-28e5ffdd38b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597767529-172.17.0.6-1597485404145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34718,DS-83ea8f2b-3730-4bd4-b1cd-d40c9aaf73b3,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-59a8dfa7-6cb5-4f7b-b658-7920e187dd48,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-59fd6282-d1c6-4741-9db0-7f8d7d8a9c68,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-cb03dc21-5783-48c8-bcf1-cb0b5933e129,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-cfde53e4-bd8c-4e36-b2db-13b635e9bf05,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-de3726f4-0b9e-4ecb-8de0-0488f2a25e49,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-fa220c4a-e8fc-4525-a900-2cfd742e6e71,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-d2c561b4-ee56-4006-a6e7-07a86da489f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597767529-172.17.0.6-1597485404145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34718,DS-83ea8f2b-3730-4bd4-b1cd-d40c9aaf73b3,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-59a8dfa7-6cb5-4f7b-b658-7920e187dd48,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-59fd6282-d1c6-4741-9db0-7f8d7d8a9c68,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-cb03dc21-5783-48c8-bcf1-cb0b5933e129,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-cfde53e4-bd8c-4e36-b2db-13b635e9bf05,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-de3726f4-0b9e-4ecb-8de0-0488f2a25e49,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-fa220c4a-e8fc-4525-a900-2cfd742e6e71,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-d2c561b4-ee56-4006-a6e7-07a86da489f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035856479-172.17.0.6-1597485634461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37749,DS-09b33490-81f6-40f1-8b83-3dc0edde812a,DISK], DatanodeInfoWithStorage[127.0.0.1:38183,DS-ef6e01dc-6964-4e96-8c27-fcc4c35f1fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-037a32e2-1e75-4438-ab6a-8a9b096332a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-baec7179-2ca1-4222-8dcb-dc42029291c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-182035c3-4b46-47ae-87db-258cccd0d327,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-ce9df373-6ed8-44c5-918d-dee537004a85,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-8d22ba39-707a-4654-942f-dbb63b4e874f,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-b7435913-94f2-43cf-b24c-684abf297bfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035856479-172.17.0.6-1597485634461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37749,DS-09b33490-81f6-40f1-8b83-3dc0edde812a,DISK], DatanodeInfoWithStorage[127.0.0.1:38183,DS-ef6e01dc-6964-4e96-8c27-fcc4c35f1fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-037a32e2-1e75-4438-ab6a-8a9b096332a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35113,DS-baec7179-2ca1-4222-8dcb-dc42029291c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-182035c3-4b46-47ae-87db-258cccd0d327,DISK], DatanodeInfoWithStorage[127.0.0.1:33128,DS-ce9df373-6ed8-44c5-918d-dee537004a85,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-8d22ba39-707a-4654-942f-dbb63b4e874f,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-b7435913-94f2-43cf-b24c-684abf297bfa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-365021960-172.17.0.6-1597485675649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44115,DS-cfff4eee-321b-4c79-83a8-5ce2d771fd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-8bbc4e1f-a207-4003-a84c-415eebd0bb36,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-f5802f23-b90b-4480-9c2e-e21e4adbc554,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-2c92fa45-a3d7-4c80-91ae-e6d9bf6e1a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-4b794947-e573-4e7e-abac-3dc798b79c66,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-2ffdfade-9697-47d5-b9b2-5fa9e14e3b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-3fa67c55-d57a-4ff1-8440-a74984f781a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-f92a1730-f5e8-4e50-8a6a-e4dad9c797c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-365021960-172.17.0.6-1597485675649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44115,DS-cfff4eee-321b-4c79-83a8-5ce2d771fd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-8bbc4e1f-a207-4003-a84c-415eebd0bb36,DISK], DatanodeInfoWithStorage[127.0.0.1:41000,DS-f5802f23-b90b-4480-9c2e-e21e4adbc554,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-2c92fa45-a3d7-4c80-91ae-e6d9bf6e1a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-4b794947-e573-4e7e-abac-3dc798b79c66,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-2ffdfade-9697-47d5-b9b2-5fa9e14e3b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-3fa67c55-d57a-4ff1-8440-a74984f781a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-f92a1730-f5e8-4e50-8a6a-e4dad9c797c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1972570205-172.17.0.6-1597485736579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42376,DS-fe2ce118-a249-4b50-b2c0-8e8b2451eb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-f574630b-d676-45ee-9fd5-8f6ac3ccfa4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-49143789-1673-4979-b394-0f56c051d080,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-13084a55-8a33-4592-81ca-4f1cfbf08fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-9e446807-63ea-438b-90b2-1275070c7820,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-9e7a6964-f5ba-4f22-a803-039ee2b12f83,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-b66d36c9-07e0-4e41-8477-36c46ed98d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-d34200d9-89bc-47fc-8daa-387d2f58c2a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1972570205-172.17.0.6-1597485736579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42376,DS-fe2ce118-a249-4b50-b2c0-8e8b2451eb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-f574630b-d676-45ee-9fd5-8f6ac3ccfa4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-49143789-1673-4979-b394-0f56c051d080,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-13084a55-8a33-4592-81ca-4f1cfbf08fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-9e446807-63ea-438b-90b2-1275070c7820,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-9e7a6964-f5ba-4f22-a803-039ee2b12f83,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-b66d36c9-07e0-4e41-8477-36c46ed98d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42000,DS-d34200d9-89bc-47fc-8daa-387d2f58c2a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-71057343-172.17.0.6-1597485922628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44432,DS-8f1f7d6c-3110-4fa9-b881-56da1d323e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-6d70e3f9-4031-44c7-8a60-4d647e4037e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-bcca80ad-e68b-40c3-8c38-e28f20e82c12,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-3c696f11-5d04-4d7f-84f7-b7f81d215d48,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-433f1e46-3628-41e5-83eb-0730f1fe3881,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-c9352350-2d9c-4ac7-9714-1eccbb0703c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-8314e6d0-fba4-413f-a1ab-52fb000cad98,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-4549431f-a96b-43b8-9c62-f3882d61b20e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-71057343-172.17.0.6-1597485922628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44432,DS-8f1f7d6c-3110-4fa9-b881-56da1d323e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-6d70e3f9-4031-44c7-8a60-4d647e4037e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-bcca80ad-e68b-40c3-8c38-e28f20e82c12,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-3c696f11-5d04-4d7f-84f7-b7f81d215d48,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-433f1e46-3628-41e5-83eb-0730f1fe3881,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-c9352350-2d9c-4ac7-9714-1eccbb0703c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-8314e6d0-fba4-413f-a1ab-52fb000cad98,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-4549431f-a96b-43b8-9c62-f3882d61b20e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5619
