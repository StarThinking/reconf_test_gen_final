reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2054741956-172.17.0.13-1597502922243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45535,DS-c25c9fcf-ad82-4bc0-9791-6d1fd0c5510e,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-0c76be8f-a8ed-45f6-9868-aaf4e819ae9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-9cf3ac13-c639-4df3-8b26-710a15f09bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-5e443847-648a-450b-84b9-a64b661c1b56,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-caff0b1e-7373-47d5-a630-ff9bd86c08f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-ac98fe6a-3b8b-4e8e-b271-df638ea47902,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-3238d45b-3ae2-499c-88ae-bb760ebfeb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-d8edff91-aadc-48d9-a078-57aedf84a37f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2054741956-172.17.0.13-1597502922243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45535,DS-c25c9fcf-ad82-4bc0-9791-6d1fd0c5510e,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-0c76be8f-a8ed-45f6-9868-aaf4e819ae9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-9cf3ac13-c639-4df3-8b26-710a15f09bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-5e443847-648a-450b-84b9-a64b661c1b56,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-caff0b1e-7373-47d5-a630-ff9bd86c08f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-ac98fe6a-3b8b-4e8e-b271-df638ea47902,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-3238d45b-3ae2-499c-88ae-bb760ebfeb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-d8edff91-aadc-48d9-a078-57aedf84a37f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2037561828-172.17.0.13-1597503066465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39683,DS-53dd483a-a856-4ba5-8827-b771c14a28b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-c1244720-f3fe-4fb5-b659-3584da4b1613,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-7a157613-5eed-4d93-ae65-6cc8eded73ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-e1258cbd-c22c-49d9-9b77-95277bf5658b,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-4c9d8cd3-ca55-40cd-b64d-a8f7412e0fad,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-c98dc8ba-baf3-44d9-83d6-de633b666944,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-aa77d4f7-5fe8-4edd-afd5-39f7b2ec3318,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-1dd996a8-66a4-4b3e-950b-37395ce5efc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2037561828-172.17.0.13-1597503066465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39683,DS-53dd483a-a856-4ba5-8827-b771c14a28b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-c1244720-f3fe-4fb5-b659-3584da4b1613,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-7a157613-5eed-4d93-ae65-6cc8eded73ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-e1258cbd-c22c-49d9-9b77-95277bf5658b,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-4c9d8cd3-ca55-40cd-b64d-a8f7412e0fad,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-c98dc8ba-baf3-44d9-83d6-de633b666944,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-aa77d4f7-5fe8-4edd-afd5-39f7b2ec3318,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-1dd996a8-66a4-4b3e-950b-37395ce5efc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109454836-172.17.0.13-1597503198630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38066,DS-ebee45b7-f417-4e6b-87c7-43e1e43a0d11,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-d94b4f36-2a70-45f2-a41a-4f3e57465bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-e4e915ea-22ef-4952-b8ed-c741a6b79d29,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-19d46ed1-5680-464f-a293-05d88d3dd406,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-33ff813a-42f0-4342-a54c-afcc06330b31,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-80b1d62f-502c-477e-bc8f-be3efc14aa5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-7044f7dc-1cd5-4f6a-8edb-d437b779d502,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-c502b3c1-7240-4d69-a8a8-8cd45bc63dac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109454836-172.17.0.13-1597503198630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38066,DS-ebee45b7-f417-4e6b-87c7-43e1e43a0d11,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-d94b4f36-2a70-45f2-a41a-4f3e57465bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-e4e915ea-22ef-4952-b8ed-c741a6b79d29,DISK], DatanodeInfoWithStorage[127.0.0.1:36475,DS-19d46ed1-5680-464f-a293-05d88d3dd406,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-33ff813a-42f0-4342-a54c-afcc06330b31,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-80b1d62f-502c-477e-bc8f-be3efc14aa5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-7044f7dc-1cd5-4f6a-8edb-d437b779d502,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-c502b3c1-7240-4d69-a8a8-8cd45bc63dac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1637592797-172.17.0.13-1597503492144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34864,DS-22a1f39e-55de-442d-a5bc-0309b3797cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-b3afeae6-fa21-40d8-b05c-85f9a5a82304,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-5a2028ef-9646-4ee9-8e14-ca8ff15eb876,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-f89b4798-e499-434a-b999-30bafeacd530,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-3174bead-c784-4ef0-84ad-a9eefdb92be5,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-86c2b33b-29da-4596-8f74-fb86c3240e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-85508687-9848-4ad6-bfba-30a29b1bf48b,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-e8659cf4-4e1e-420b-bc10-d909cb717b13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1637592797-172.17.0.13-1597503492144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34864,DS-22a1f39e-55de-442d-a5bc-0309b3797cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-b3afeae6-fa21-40d8-b05c-85f9a5a82304,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-5a2028ef-9646-4ee9-8e14-ca8ff15eb876,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-f89b4798-e499-434a-b999-30bafeacd530,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-3174bead-c784-4ef0-84ad-a9eefdb92be5,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-86c2b33b-29da-4596-8f74-fb86c3240e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-85508687-9848-4ad6-bfba-30a29b1bf48b,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-e8659cf4-4e1e-420b-bc10-d909cb717b13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1541119939-172.17.0.13-1597504012322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40918,DS-7787f800-ada8-4fd5-b30a-a0d1379a78b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-9cf4b5bc-f3d4-41fb-9eb7-636c66894e97,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-0d03832c-6577-4bf9-9894-674cd36d74b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-ad8cc481-0e68-43f4-8e8f-54ab463a7a20,DISK], DatanodeInfoWithStorage[127.0.0.1:36345,DS-6c94563c-d37c-4501-a839-c43747ee1c26,DISK], DatanodeInfoWithStorage[127.0.0.1:45331,DS-081d2322-4a41-4e8a-9666-7dae5cb1146c,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-09551a0f-6f69-40b8-aec7-a68479f91c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-19820997-d773-4746-bad9-0d0b5798fc1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1541119939-172.17.0.13-1597504012322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40918,DS-7787f800-ada8-4fd5-b30a-a0d1379a78b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-9cf4b5bc-f3d4-41fb-9eb7-636c66894e97,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-0d03832c-6577-4bf9-9894-674cd36d74b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-ad8cc481-0e68-43f4-8e8f-54ab463a7a20,DISK], DatanodeInfoWithStorage[127.0.0.1:36345,DS-6c94563c-d37c-4501-a839-c43747ee1c26,DISK], DatanodeInfoWithStorage[127.0.0.1:45331,DS-081d2322-4a41-4e8a-9666-7dae5cb1146c,DISK], DatanodeInfoWithStorage[127.0.0.1:36215,DS-09551a0f-6f69-40b8-aec7-a68479f91c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-19820997-d773-4746-bad9-0d0b5798fc1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337852279-172.17.0.13-1597504343906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40407,DS-72254e66-40c8-4b08-a43f-59b4b70ff562,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-b5b3ded2-e343-47ce-8153-8e2397f2e130,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-2b0a8bc3-5647-4331-a602-4c92d73768aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-f8a47998-2b54-49a2-a8cf-301dee2dfbc1,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-2f6e5ebe-54a0-4a6a-8d10-92c36ee6de27,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-59ef4337-138d-4944-86cc-146479977f62,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-f0fd8f31-8c07-4f3b-bf1b-7bb99c44ce29,DISK], DatanodeInfoWithStorage[127.0.0.1:43760,DS-e386d6af-da67-41f2-aee9-309c1af6f3d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337852279-172.17.0.13-1597504343906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40407,DS-72254e66-40c8-4b08-a43f-59b4b70ff562,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-b5b3ded2-e343-47ce-8153-8e2397f2e130,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-2b0a8bc3-5647-4331-a602-4c92d73768aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-f8a47998-2b54-49a2-a8cf-301dee2dfbc1,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-2f6e5ebe-54a0-4a6a-8d10-92c36ee6de27,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-59ef4337-138d-4944-86cc-146479977f62,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-f0fd8f31-8c07-4f3b-bf1b-7bb99c44ce29,DISK], DatanodeInfoWithStorage[127.0.0.1:43760,DS-e386d6af-da67-41f2-aee9-309c1af6f3d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1086754014-172.17.0.13-1597504394184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41962,DS-8011e2c4-9595-452b-9db0-98cdf6c663b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-d740445e-0457-4741-b8e3-a925c196b565,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-b55a7597-18c4-4980-abb9-7826dbcc04e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-179dad3b-8647-4c0a-82f8-a556658a398b,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-006ffcf2-7ab4-4e26-8245-f3b44e732c05,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-ef01122d-c98d-42dd-a9ba-1fe68c5ce0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-4aac7f14-23d2-43a1-89ab-5dcd54330b41,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-36115210-014c-4da2-b793-b0a4b346996b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1086754014-172.17.0.13-1597504394184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41962,DS-8011e2c4-9595-452b-9db0-98cdf6c663b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-d740445e-0457-4741-b8e3-a925c196b565,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-b55a7597-18c4-4980-abb9-7826dbcc04e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-179dad3b-8647-4c0a-82f8-a556658a398b,DISK], DatanodeInfoWithStorage[127.0.0.1:35533,DS-006ffcf2-7ab4-4e26-8245-f3b44e732c05,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-ef01122d-c98d-42dd-a9ba-1fe68c5ce0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-4aac7f14-23d2-43a1-89ab-5dcd54330b41,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-36115210-014c-4da2-b793-b0a4b346996b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-77943373-172.17.0.13-1597504442305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35801,DS-a7e7df1c-8810-4ba9-9d59-c42e0b56ca63,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-a2821ded-5eb1-4991-a9b4-904b2b98f2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-7e073fff-76b6-4078-bc3d-26837df81ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-b0be9cb0-c6fa-4cc8-972b-6ec84ebde7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-0b35c42e-c537-447d-8b17-2960bb5f0dae,DISK], DatanodeInfoWithStorage[127.0.0.1:46636,DS-1afbc988-714b-4637-b453-30377eefd7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-9e1c01be-0b62-44d3-9b85-537c0220689c,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-bb4d57f9-9ff7-44b3-b7f9-c11fd436488d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-77943373-172.17.0.13-1597504442305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35801,DS-a7e7df1c-8810-4ba9-9d59-c42e0b56ca63,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-a2821ded-5eb1-4991-a9b4-904b2b98f2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-7e073fff-76b6-4078-bc3d-26837df81ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:35679,DS-b0be9cb0-c6fa-4cc8-972b-6ec84ebde7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-0b35c42e-c537-447d-8b17-2960bb5f0dae,DISK], DatanodeInfoWithStorage[127.0.0.1:46636,DS-1afbc988-714b-4637-b453-30377eefd7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-9e1c01be-0b62-44d3-9b85-537c0220689c,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-bb4d57f9-9ff7-44b3-b7f9-c11fd436488d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1850193856-172.17.0.13-1597504827635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37241,DS-37cc4618-a01d-46c4-956b-3002b94fc7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-a8a56f91-3eaa-4c45-860e-17a0c3e52fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-0ce7f7e6-6ed7-41cd-a2a1-314a4c37f639,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-e9ae45fd-5a7f-4ade-b9ce-5a30c91c7fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-d42b23e9-3e0a-41f2-86bc-9ba9caf2a1af,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-1da6c4e8-cf16-46cf-8cbb-cb5f7dd5a74b,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-2e3a48c4-90b8-46f1-83c3-d6a26667e83d,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-b8edcd09-f8ee-4482-b404-796f514a4e69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1850193856-172.17.0.13-1597504827635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37241,DS-37cc4618-a01d-46c4-956b-3002b94fc7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-a8a56f91-3eaa-4c45-860e-17a0c3e52fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36249,DS-0ce7f7e6-6ed7-41cd-a2a1-314a4c37f639,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-e9ae45fd-5a7f-4ade-b9ce-5a30c91c7fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-d42b23e9-3e0a-41f2-86bc-9ba9caf2a1af,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-1da6c4e8-cf16-46cf-8cbb-cb5f7dd5a74b,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-2e3a48c4-90b8-46f1-83c3-d6a26667e83d,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-b8edcd09-f8ee-4482-b404-796f514a4e69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177526607-172.17.0.13-1597504958397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34205,DS-ba8d1e3b-cec7-4794-bb0d-88d11e29666c,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-eda0fd52-d0fb-4421-aea9-5c493c5f17f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-5dd381d2-686a-4a40-bf49-37c32377f341,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-83ee913c-e76f-402b-baf2-bbdd43112d03,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-8202bbb5-d83b-413a-bc77-2ce3e02e5ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-11cdaae9-311b-4ff6-8fe3-9f6ee6479bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-5af0f8a0-a3ed-4aff-b7ad-67a1bcc81477,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-6c014c66-1b8f-4db5-9dad-5c60ef0ddd4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177526607-172.17.0.13-1597504958397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34205,DS-ba8d1e3b-cec7-4794-bb0d-88d11e29666c,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-eda0fd52-d0fb-4421-aea9-5c493c5f17f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-5dd381d2-686a-4a40-bf49-37c32377f341,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-83ee913c-e76f-402b-baf2-bbdd43112d03,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-8202bbb5-d83b-413a-bc77-2ce3e02e5ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-11cdaae9-311b-4ff6-8fe3-9f6ee6479bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-5af0f8a0-a3ed-4aff-b7ad-67a1bcc81477,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-6c014c66-1b8f-4db5-9dad-5c60ef0ddd4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-732020527-172.17.0.13-1597505401361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46264,DS-ebaff101-5079-4d70-9ea1-0477517cc931,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-d334c017-1f92-48fb-84e4-00ceb35d439b,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-e5e4ea1e-ad6e-4855-88a2-546b83987405,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-ad7f1598-4f12-4cf5-ba3a-081df4cc80fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-882ad219-796c-40b2-909d-fefbdc40d0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-f377539f-45f7-48cb-b435-768bdf6a732e,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-1226573e-7658-462c-8a59-ef3556e808fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-d6117ef9-e853-4e46-bb11-9e67489e9d2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-732020527-172.17.0.13-1597505401361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46264,DS-ebaff101-5079-4d70-9ea1-0477517cc931,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-d334c017-1f92-48fb-84e4-00ceb35d439b,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-e5e4ea1e-ad6e-4855-88a2-546b83987405,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-ad7f1598-4f12-4cf5-ba3a-081df4cc80fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-882ad219-796c-40b2-909d-fefbdc40d0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37259,DS-f377539f-45f7-48cb-b435-768bdf6a732e,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-1226573e-7658-462c-8a59-ef3556e808fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-d6117ef9-e853-4e46-bb11-9e67489e9d2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1737192759-172.17.0.13-1597505905633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39447,DS-34a0a58b-7ddd-417d-8215-9eebd92f9719,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-7e060452-7f69-413a-98b8-ac8fc2272082,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-a5993dff-76f0-437e-af96-b5bcbe3fe65c,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-38a92a26-7463-4f24-b331-6e47990eae47,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-ad6da7fa-e54d-49fd-adff-a41fe0ce0418,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-8efea6cc-5a82-4d97-9ccf-d6e977a4179e,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-d30c09eb-aa5c-4aaf-a671-6411a2bf1202,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-dc795dde-c2b6-48eb-98d0-a0f4aa7a6baa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1737192759-172.17.0.13-1597505905633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39447,DS-34a0a58b-7ddd-417d-8215-9eebd92f9719,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-7e060452-7f69-413a-98b8-ac8fc2272082,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-a5993dff-76f0-437e-af96-b5bcbe3fe65c,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-38a92a26-7463-4f24-b331-6e47990eae47,DISK], DatanodeInfoWithStorage[127.0.0.1:43724,DS-ad6da7fa-e54d-49fd-adff-a41fe0ce0418,DISK], DatanodeInfoWithStorage[127.0.0.1:39009,DS-8efea6cc-5a82-4d97-9ccf-d6e977a4179e,DISK], DatanodeInfoWithStorage[127.0.0.1:38064,DS-d30c09eb-aa5c-4aaf-a671-6411a2bf1202,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-dc795dde-c2b6-48eb-98d0-a0f4aa7a6baa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2081092763-172.17.0.13-1597506147751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34291,DS-d561d0d9-9aef-480d-b015-d5e6ee582605,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-249edb05-1e90-43b1-a562-10e9c8b3644f,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-f89b8f4a-ccc0-4df5-835c-279e9937611b,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-e536b385-6de0-4762-8e28-21233a543d93,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-9746c94f-a43b-4d91-9a86-877b1066eba8,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-ec838d6a-69e0-4066-adfe-80e01cf92b64,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-69ab0ed2-c847-4390-ad23-1486ef5a668f,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-4cf490df-64cf-45e1-9d0f-310c401e1fb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2081092763-172.17.0.13-1597506147751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34291,DS-d561d0d9-9aef-480d-b015-d5e6ee582605,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-249edb05-1e90-43b1-a562-10e9c8b3644f,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-f89b8f4a-ccc0-4df5-835c-279e9937611b,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-e536b385-6de0-4762-8e28-21233a543d93,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-9746c94f-a43b-4d91-9a86-877b1066eba8,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-ec838d6a-69e0-4066-adfe-80e01cf92b64,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-69ab0ed2-c847-4390-ad23-1486ef5a668f,DISK], DatanodeInfoWithStorage[127.0.0.1:38260,DS-4cf490df-64cf-45e1-9d0f-310c401e1fb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-630589070-172.17.0.13-1597507473628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39270,DS-afb73d48-39c1-468c-985a-3077197e44e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-972111a4-fe54-432e-ae74-e193219b00d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-a9d0bd5d-021b-4821-ab58-271755c39a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-1c5ed61a-371d-47aa-8cb9-0fce35531a76,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-36534b22-b3b6-4ea3-8d1c-8ffd9f1c5f49,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-1351fa6c-d81f-4438-8b06-871d981298a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-4c20575d-4562-40a3-809a-5f0d9639c15e,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-4b8e32bc-fc0a-43e9-9878-f3f5ff378fc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-630589070-172.17.0.13-1597507473628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39270,DS-afb73d48-39c1-468c-985a-3077197e44e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36788,DS-972111a4-fe54-432e-ae74-e193219b00d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36408,DS-a9d0bd5d-021b-4821-ab58-271755c39a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-1c5ed61a-371d-47aa-8cb9-0fce35531a76,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-36534b22-b3b6-4ea3-8d1c-8ffd9f1c5f49,DISK], DatanodeInfoWithStorage[127.0.0.1:39466,DS-1351fa6c-d81f-4438-8b06-871d981298a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-4c20575d-4562-40a3-809a-5f0d9639c15e,DISK], DatanodeInfoWithStorage[127.0.0.1:42635,DS-4b8e32bc-fc0a-43e9-9878-f3f5ff378fc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1202251472-172.17.0.13-1597507653712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41374,DS-310f4570-a6d4-4e92-910d-3ee47384db26,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-17923608-0580-4ab4-87f6-f3e3fb4f8e25,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-10dd4a62-396b-41ff-8b0d-c857c9d54af5,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-4c89c7a9-5eef-4155-b9a3-be18aaf4027a,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-05b78a47-c5d1-48ad-9a6f-9b1dfe1d15f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-825c9e63-f346-41bf-ada6-493cbb0302e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-acace211-24af-44d3-b790-a60bc8cb14ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-1c5619d7-b842-4e4e-b620-00df70fa7ed7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1202251472-172.17.0.13-1597507653712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41374,DS-310f4570-a6d4-4e92-910d-3ee47384db26,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-17923608-0580-4ab4-87f6-f3e3fb4f8e25,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-10dd4a62-396b-41ff-8b0d-c857c9d54af5,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-4c89c7a9-5eef-4155-b9a3-be18aaf4027a,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-05b78a47-c5d1-48ad-9a6f-9b1dfe1d15f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-825c9e63-f346-41bf-ada6-493cbb0302e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-acace211-24af-44d3-b790-a60bc8cb14ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-1c5619d7-b842-4e4e-b620-00df70fa7ed7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102738835-172.17.0.13-1597507748294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43204,DS-4aa1d33a-a444-4ecf-85b3-ff6b6a9e07b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-93043947-4390-48e5-a19c-b1d2050f7f84,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-69518b4e-9ea2-41a8-96c7-c8b16510af06,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-16362ca4-7501-49d6-ba62-784bcfdee87d,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-1e7ac58b-b123-438e-8df4-45f76e3f5ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-20815407-4374-47db-ac2f-b28e6182bf6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-f3cc2aeb-019c-4502-909c-1cd980b8c4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-0fbb3f14-9219-4939-b53b-f4c2008b95c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2102738835-172.17.0.13-1597507748294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43204,DS-4aa1d33a-a444-4ecf-85b3-ff6b6a9e07b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-93043947-4390-48e5-a19c-b1d2050f7f84,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-69518b4e-9ea2-41a8-96c7-c8b16510af06,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-16362ca4-7501-49d6-ba62-784bcfdee87d,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-1e7ac58b-b123-438e-8df4-45f76e3f5ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-20815407-4374-47db-ac2f-b28e6182bf6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-f3cc2aeb-019c-4502-909c-1cd980b8c4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-0fbb3f14-9219-4939-b53b-f4c2008b95c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1640822572-172.17.0.13-1597507886687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39659,DS-57d7607a-1ebe-4cb5-8fb7-995ded50ddcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-2725dd00-db73-4184-97a6-485613970f40,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-1381debf-9ad6-44ec-84f9-667cafe6a5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-e7ef56dc-1be5-4f43-9287-67f490eb4171,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-5bd3963c-4af8-4d38-a089-e9bcbf81462c,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-9a7267ce-96f4-4eba-9eab-ef19c2dd9a25,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-e2068621-be45-4121-98b7-74ad5dd6517e,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-df1ff303-00a9-4489-ac30-e9a6f0454e15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1640822572-172.17.0.13-1597507886687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39659,DS-57d7607a-1ebe-4cb5-8fb7-995ded50ddcf,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-2725dd00-db73-4184-97a6-485613970f40,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-1381debf-9ad6-44ec-84f9-667cafe6a5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-e7ef56dc-1be5-4f43-9287-67f490eb4171,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-5bd3963c-4af8-4d38-a089-e9bcbf81462c,DISK], DatanodeInfoWithStorage[127.0.0.1:45899,DS-9a7267ce-96f4-4eba-9eab-ef19c2dd9a25,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-e2068621-be45-4121-98b7-74ad5dd6517e,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-df1ff303-00a9-4489-ac30-e9a6f0454e15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1838417222-172.17.0.13-1597508078286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38627,DS-eff6012e-e6c2-4a85-9753-68c56ecf0e52,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-2d184896-d10c-4432-806e-aad54cdebc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-368c6bd3-1f6d-424f-a6de-f220b56edd4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-ccf3be14-5cbd-41e8-91af-5468627a28d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-0f432f73-66f2-46d5-9d31-4f3c9517d69c,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-250d3420-5c4f-4be2-9e01-84776d98a724,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-dceaeb1d-557f-428b-9a48-03d42b0f7373,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-1f1b5718-86f3-4212-8751-3cb50202c1d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1838417222-172.17.0.13-1597508078286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38627,DS-eff6012e-e6c2-4a85-9753-68c56ecf0e52,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-2d184896-d10c-4432-806e-aad54cdebc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-368c6bd3-1f6d-424f-a6de-f220b56edd4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-ccf3be14-5cbd-41e8-91af-5468627a28d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37397,DS-0f432f73-66f2-46d5-9d31-4f3c9517d69c,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-250d3420-5c4f-4be2-9e01-84776d98a724,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-dceaeb1d-557f-428b-9a48-03d42b0f7373,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-1f1b5718-86f3-4212-8751-3cb50202c1d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.cache.timeout.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-877148791-172.17.0.13-1597508513741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41262,DS-bf092965-6ca9-4252-b761-e698bed7db5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-ab2dfff3-b2a3-4d04-a293-a52d66f17ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-4fc5a2f6-5e72-4f0e-aec0-149e947dd8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-27c255fa-0983-4e56-bd9f-b418c28e9e86,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-42455bf1-0639-4d12-84c8-22e93cc015a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-b73fd67d-3dec-4260-b9d1-7522235169d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41130,DS-40c67c99-9450-4b9d-8f07-172044c6e2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-a3df1347-830a-40af-b9d8-b6747c7cef3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-877148791-172.17.0.13-1597508513741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41262,DS-bf092965-6ca9-4252-b761-e698bed7db5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-ab2dfff3-b2a3-4d04-a293-a52d66f17ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-4fc5a2f6-5e72-4f0e-aec0-149e947dd8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-27c255fa-0983-4e56-bd9f-b418c28e9e86,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-42455bf1-0639-4d12-84c8-22e93cc015a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-b73fd67d-3dec-4260-b9d1-7522235169d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41130,DS-40c67c99-9450-4b9d-8f07-172044c6e2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-a3df1347-830a-40af-b9d8-b6747c7cef3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 7038
