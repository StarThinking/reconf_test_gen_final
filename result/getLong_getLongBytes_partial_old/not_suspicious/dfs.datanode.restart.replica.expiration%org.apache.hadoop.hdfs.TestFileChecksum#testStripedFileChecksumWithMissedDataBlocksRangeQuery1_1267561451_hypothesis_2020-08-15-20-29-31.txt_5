reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-373910693-172.17.0.7-1597523387223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39640,DS-0d264aa1-12da-4d72-a21d-a1c1161ec585,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-56fbce9b-f4cb-4ca9-a69d-faeec0dde8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-65cd4e6b-c762-4592-9421-38ae27bf4f32,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-09d6f923-7f81-4543-a972-402047139c60,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-3abba002-478a-4be8-a360-e5f7e3c4667b,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-82bca537-81de-4eaa-bd4f-4c10e2632451,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-bf9ec374-cd78-43de-8152-18db5d15918e,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-57d89111-d494-4a01-ba27-6b687106905d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-373910693-172.17.0.7-1597523387223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39640,DS-0d264aa1-12da-4d72-a21d-a1c1161ec585,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-56fbce9b-f4cb-4ca9-a69d-faeec0dde8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-65cd4e6b-c762-4592-9421-38ae27bf4f32,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-09d6f923-7f81-4543-a972-402047139c60,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-3abba002-478a-4be8-a360-e5f7e3c4667b,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-82bca537-81de-4eaa-bd4f-4c10e2632451,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-bf9ec374-cd78-43de-8152-18db5d15918e,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-57d89111-d494-4a01-ba27-6b687106905d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-646314835-172.17.0.7-1597523462364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35096,DS-1c50e4e3-8681-4fad-a6f7-1581c16f0b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-0aac3f30-119e-41d3-b0a8-0be9880df67d,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-484f9034-8477-4c7b-b795-6b3fdcc2992c,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-b6f2479a-8115-42cd-9618-66bed43a0369,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-7467360a-beaa-4e01-ba2d-6580ef913e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-8afa9a28-2d7a-4fb3-b163-35fb249d2833,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-4424fec8-eccf-490d-9f0f-8f6c28c28fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-12a678b3-2aa2-4401-91f5-60cc8507406b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-646314835-172.17.0.7-1597523462364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35096,DS-1c50e4e3-8681-4fad-a6f7-1581c16f0b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-0aac3f30-119e-41d3-b0a8-0be9880df67d,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-484f9034-8477-4c7b-b795-6b3fdcc2992c,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-b6f2479a-8115-42cd-9618-66bed43a0369,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-7467360a-beaa-4e01-ba2d-6580ef913e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-8afa9a28-2d7a-4fb3-b163-35fb249d2833,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-4424fec8-eccf-490d-9f0f-8f6c28c28fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-12a678b3-2aa2-4401-91f5-60cc8507406b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-818883595-172.17.0.7-1597523738827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34175,DS-21837ad3-eebc-49f1-95e4-9eba5149c3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-ef5a235d-7139-4b8c-9ddf-98b69ba2426b,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-b5cc73cf-7170-4a72-a071-8ad16f155c27,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-4ba0dd8b-9042-4642-a8c0-c24e9445b2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-d2f36ce6-f34f-4e2c-bed5-e5970575c3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-48650d04-e1ee-4376-8b6b-803aa250e960,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-219fed1d-dd31-429e-a4d4-4fd38a66fd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-bf478970-2bb8-46c9-87b0-93009b1d7f28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-818883595-172.17.0.7-1597523738827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34175,DS-21837ad3-eebc-49f1-95e4-9eba5149c3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40655,DS-ef5a235d-7139-4b8c-9ddf-98b69ba2426b,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-b5cc73cf-7170-4a72-a071-8ad16f155c27,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-4ba0dd8b-9042-4642-a8c0-c24e9445b2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-d2f36ce6-f34f-4e2c-bed5-e5970575c3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-48650d04-e1ee-4376-8b6b-803aa250e960,DISK], DatanodeInfoWithStorage[127.0.0.1:41757,DS-219fed1d-dd31-429e-a4d4-4fd38a66fd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-bf478970-2bb8-46c9-87b0-93009b1d7f28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1683103948-172.17.0.7-1597523776328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46692,DS-d67512e5-219f-4970-a540-13d65be67e35,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-f2dc47bd-a85d-4680-99d6-81aa4eca9514,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-61e07dca-eae2-400f-848b-e7fff1c1d836,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-f9888afe-1eba-408c-ab9b-ac1e4795e345,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-bea71275-be03-4825-9f52-57306f2f05cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-6065e890-b1bb-4178-8174-9b7f32d0dad1,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-8b66774a-bba1-4856-9954-127e1dce301a,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-82fe9f4b-7e98-4c54-9f31-44d7882d0fe1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1683103948-172.17.0.7-1597523776328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46692,DS-d67512e5-219f-4970-a540-13d65be67e35,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-f2dc47bd-a85d-4680-99d6-81aa4eca9514,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-61e07dca-eae2-400f-848b-e7fff1c1d836,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-f9888afe-1eba-408c-ab9b-ac1e4795e345,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-bea71275-be03-4825-9f52-57306f2f05cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-6065e890-b1bb-4178-8174-9b7f32d0dad1,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-8b66774a-bba1-4856-9954-127e1dce301a,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-82fe9f4b-7e98-4c54-9f31-44d7882d0fe1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-13625385-172.17.0.7-1597524171373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44811,DS-6ac5afa9-1868-4708-b577-884d06395cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-c7fb620b-16d6-47e9-a54f-82c8053c7936,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-2c98dcd7-3890-49e9-bf82-ea664afaa464,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-9a84501f-bb83-4e1a-b8a2-8f295c282a49,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-f2a0bb1e-394b-42e2-8d54-61711e5deb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-91a409c9-5927-4e82-935b-913b87f47ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-ecb2cb45-4ae2-4e82-a865-5eb70e535b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-1fc99296-92e5-4ebf-8baa-cef89f230215,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-13625385-172.17.0.7-1597524171373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44811,DS-6ac5afa9-1868-4708-b577-884d06395cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42861,DS-c7fb620b-16d6-47e9-a54f-82c8053c7936,DISK], DatanodeInfoWithStorage[127.0.0.1:43589,DS-2c98dcd7-3890-49e9-bf82-ea664afaa464,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-9a84501f-bb83-4e1a-b8a2-8f295c282a49,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-f2a0bb1e-394b-42e2-8d54-61711e5deb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46202,DS-91a409c9-5927-4e82-935b-913b87f47ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-ecb2cb45-4ae2-4e82-a865-5eb70e535b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-1fc99296-92e5-4ebf-8baa-cef89f230215,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1638906521-172.17.0.7-1597524310660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43916,DS-3492d379-934d-4f4b-91cf-8f0479979609,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-bca3b204-f095-4e02-ae16-388e8f7d4a91,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-263dafb5-2186-492e-9b60-62c381b43a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-46790e5b-a684-481c-a587-eeaf56e56831,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-296e0440-405c-4ba3-bcaa-9ffe5df58454,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-e0bcd582-9cb5-4e1b-b3df-0f030790c8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-5ad092e1-8a20-4c6d-9d92-33af916525e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-b3204758-681d-4a91-ab15-12b16eef9ff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1638906521-172.17.0.7-1597524310660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43916,DS-3492d379-934d-4f4b-91cf-8f0479979609,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-bca3b204-f095-4e02-ae16-388e8f7d4a91,DISK], DatanodeInfoWithStorage[127.0.0.1:36438,DS-263dafb5-2186-492e-9b60-62c381b43a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-46790e5b-a684-481c-a587-eeaf56e56831,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-296e0440-405c-4ba3-bcaa-9ffe5df58454,DISK], DatanodeInfoWithStorage[127.0.0.1:38795,DS-e0bcd582-9cb5-4e1b-b3df-0f030790c8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38090,DS-5ad092e1-8a20-4c6d-9d92-33af916525e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40933,DS-b3204758-681d-4a91-ab15-12b16eef9ff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628483584-172.17.0.7-1597524586833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40095,DS-54f6635d-d2bc-4162-8a37-8bc0850f3f14,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-f78b1bcc-60a4-4663-b8c2-b57627c39959,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-63e3b291-e126-42ab-aead-14387b8829cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-2358afc4-b6e7-49c4-869b-04f02106c97d,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-ce01c110-c07b-49c8-a624-23490096d064,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-042ef775-a3e8-41b5-b7e2-96501ead6652,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-f6cedeec-f4e9-4c17-8297-59c213ba5809,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-f9431cd2-cdaa-40fc-9b37-a51c8a8f94ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1628483584-172.17.0.7-1597524586833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40095,DS-54f6635d-d2bc-4162-8a37-8bc0850f3f14,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-f78b1bcc-60a4-4663-b8c2-b57627c39959,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-63e3b291-e126-42ab-aead-14387b8829cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-2358afc4-b6e7-49c4-869b-04f02106c97d,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-ce01c110-c07b-49c8-a624-23490096d064,DISK], DatanodeInfoWithStorage[127.0.0.1:36399,DS-042ef775-a3e8-41b5-b7e2-96501ead6652,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-f6cedeec-f4e9-4c17-8297-59c213ba5809,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-f9431cd2-cdaa-40fc-9b37-a51c8a8f94ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-979732538-172.17.0.7-1597525020869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39629,DS-c580c6f5-57fa-4c05-852f-b0e6ddbfef32,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-247810e7-c727-4296-9a43-3a48b3513e87,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-74aaf6b0-b207-4cfd-a033-632eeb7045ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-714ac24a-fa62-4abc-937f-5ed4be49e6df,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-ad9cc571-4dfd-4c3a-924a-91bf0bc45940,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-494f6710-b916-44ad-8a24-9d7c321b0b05,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-e13ab587-f518-4f3b-8f8a-bd3b644038a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-7fa6e73e-cca2-4d39-8b57-503be259ef76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-979732538-172.17.0.7-1597525020869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39629,DS-c580c6f5-57fa-4c05-852f-b0e6ddbfef32,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-247810e7-c727-4296-9a43-3a48b3513e87,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-74aaf6b0-b207-4cfd-a033-632eeb7045ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44221,DS-714ac24a-fa62-4abc-937f-5ed4be49e6df,DISK], DatanodeInfoWithStorage[127.0.0.1:42750,DS-ad9cc571-4dfd-4c3a-924a-91bf0bc45940,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-494f6710-b916-44ad-8a24-9d7c321b0b05,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-e13ab587-f518-4f3b-8f8a-bd3b644038a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-7fa6e73e-cca2-4d39-8b57-503be259ef76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-57708217-172.17.0.7-1597525099222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36400,DS-40887455-acef-4360-8d0c-bd3250c42387,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-309da2fd-0967-4c73-b972-524d2be886b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-65e7d414-4c8b-4a70-b8a1-148592744a48,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-182fd001-548b-483f-8192-3751faf0daaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-e5106466-f0af-4427-a0dc-1c6a28155c27,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-dec7a1b1-a6ed-43d3-b7c0-70dca7f6d378,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-27585d84-402d-46c2-960c-8896bd26beb1,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-99e15568-eca4-42fc-acc4-cebd654b6f60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-57708217-172.17.0.7-1597525099222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36400,DS-40887455-acef-4360-8d0c-bd3250c42387,DISK], DatanodeInfoWithStorage[127.0.0.1:43039,DS-309da2fd-0967-4c73-b972-524d2be886b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-65e7d414-4c8b-4a70-b8a1-148592744a48,DISK], DatanodeInfoWithStorage[127.0.0.1:45532,DS-182fd001-548b-483f-8192-3751faf0daaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-e5106466-f0af-4427-a0dc-1c6a28155c27,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-dec7a1b1-a6ed-43d3-b7c0-70dca7f6d378,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-27585d84-402d-46c2-960c-8896bd26beb1,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-99e15568-eca4-42fc-acc4-cebd654b6f60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-510766591-172.17.0.7-1597525133466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41227,DS-13120a5a-bb19-4662-957d-0b47e84245dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-ef25573c-2577-41e7-a526-3ccc4340027f,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-4aee571f-e44d-4e3d-940a-56212686f1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-2e417791-6efb-4c73-b007-f91f9525a868,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-302cc4ff-5bf8-46cb-ad50-d3834975cbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-33abc228-5ca0-4152-ba48-87f5fb4064f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-b77a5271-d445-4852-b429-63be0fdc0192,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-74ece691-75ef-4c33-9de8-0d029c4fcce5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-510766591-172.17.0.7-1597525133466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41227,DS-13120a5a-bb19-4662-957d-0b47e84245dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41190,DS-ef25573c-2577-41e7-a526-3ccc4340027f,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-4aee571f-e44d-4e3d-940a-56212686f1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-2e417791-6efb-4c73-b007-f91f9525a868,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-302cc4ff-5bf8-46cb-ad50-d3834975cbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-33abc228-5ca0-4152-ba48-87f5fb4064f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-b77a5271-d445-4852-b429-63be0fdc0192,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-74ece691-75ef-4c33-9de8-0d029c4fcce5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-473323189-172.17.0.7-1597525399680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38044,DS-8438dd10-80f7-4216-9699-244e06c7406c,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-c3e17706-ddea-403d-bdaa-7a18f137ff63,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-82505fc1-8749-40dc-844b-ba4f1b414c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-c60d937c-837e-46d9-b1ba-554cbef03ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-2920687a-2137-40e1-902c-7ab4131947e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-42bc7752-3248-4a32-b0c7-2a60c1689aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-1c407726-80ce-4cc4-a98b-044b6ec555d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-a01a2751-48b2-4c1e-ac5b-29823ea0ae6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-473323189-172.17.0.7-1597525399680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38044,DS-8438dd10-80f7-4216-9699-244e06c7406c,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-c3e17706-ddea-403d-bdaa-7a18f137ff63,DISK], DatanodeInfoWithStorage[127.0.0.1:46534,DS-82505fc1-8749-40dc-844b-ba4f1b414c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-c60d937c-837e-46d9-b1ba-554cbef03ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-2920687a-2137-40e1-902c-7ab4131947e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-42bc7752-3248-4a32-b0c7-2a60c1689aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-1c407726-80ce-4cc4-a98b-044b6ec555d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-a01a2751-48b2-4c1e-ac5b-29823ea0ae6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235022425-172.17.0.7-1597525737302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42967,DS-64276024-ad74-4f01-822a-799933562cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-86ec53b7-43fc-495e-8866-c6067a0f03db,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-f74e08c7-113a-4c0e-905c-5d999dced9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43169,DS-6fe831d7-ed04-4197-bee0-c6836f5cb7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-e51be153-e725-4e78-9225-eeb00c9c9878,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-f18610e2-5e43-455c-a2c9-54b0eda4eb14,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-5dc557cf-c999-44c6-a447-8322e7f5bcf8,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-761a2c87-31ae-46d9-9f97-40faf91248cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235022425-172.17.0.7-1597525737302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42967,DS-64276024-ad74-4f01-822a-799933562cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-86ec53b7-43fc-495e-8866-c6067a0f03db,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-f74e08c7-113a-4c0e-905c-5d999dced9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43169,DS-6fe831d7-ed04-4197-bee0-c6836f5cb7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-e51be153-e725-4e78-9225-eeb00c9c9878,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-f18610e2-5e43-455c-a2c9-54b0eda4eb14,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-5dc557cf-c999-44c6-a447-8322e7f5bcf8,DISK], DatanodeInfoWithStorage[127.0.0.1:46297,DS-761a2c87-31ae-46d9-9f97-40faf91248cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553798153-172.17.0.7-1597525875528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46398,DS-b7f2e7ca-9812-4c8f-bfb2-75ae0a04aa5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-a81e9d51-bb25-4b91-8690-4bca4c0ef2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-bd4993b2-78f8-4468-acba-c7ca44a780c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-7700cef5-8837-4237-a021-9898538a29c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-23ed095b-154e-4f81-ad98-9317370bb1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-7b2b138b-58d4-40e0-a894-652f4e50e6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-d7c586c6-8693-4e37-aa83-520148f2efe4,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-7e321f70-3f77-480f-91de-2273b98c1ec9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553798153-172.17.0.7-1597525875528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46398,DS-b7f2e7ca-9812-4c8f-bfb2-75ae0a04aa5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-a81e9d51-bb25-4b91-8690-4bca4c0ef2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-bd4993b2-78f8-4468-acba-c7ca44a780c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-7700cef5-8837-4237-a021-9898538a29c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-23ed095b-154e-4f81-ad98-9317370bb1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-7b2b138b-58d4-40e0-a894-652f4e50e6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-d7c586c6-8693-4e37-aa83-520148f2efe4,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-7e321f70-3f77-480f-91de-2273b98c1ec9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1029812075-172.17.0.7-1597526021504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43446,DS-3cca532e-022f-4400-9cc7-dfd32239c6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39278,DS-406c0401-3c61-44fe-b43d-e2bb181d1d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-71e8185c-c1d1-4901-8a17-55d1afa44b30,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-4d072c10-89b9-4f9e-8262-8d5cb20e602c,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-526c101b-e35f-4c8e-9315-fd7e2a6e106f,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-c1467918-d845-419a-8508-6e4ffd43b21e,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-ee86c8ae-4ff7-4bab-a24c-a94febd97f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-99497c42-06e8-4d73-9cda-8d725d84e97f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1029812075-172.17.0.7-1597526021504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43446,DS-3cca532e-022f-4400-9cc7-dfd32239c6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39278,DS-406c0401-3c61-44fe-b43d-e2bb181d1d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-71e8185c-c1d1-4901-8a17-55d1afa44b30,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-4d072c10-89b9-4f9e-8262-8d5cb20e602c,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-526c101b-e35f-4c8e-9315-fd7e2a6e106f,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-c1467918-d845-419a-8508-6e4ffd43b21e,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-ee86c8ae-4ff7-4bab-a24c-a94febd97f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-99497c42-06e8-4d73-9cda-8d725d84e97f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486767010-172.17.0.7-1597526964254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40950,DS-8aad5f8b-dc43-4c7d-9ff6-f51d3efc2a20,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-e1f6e5fd-28ae-4ad0-a381-13720e5b40c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-575f4eab-c7c0-43e8-a21e-3d2112979fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-92475eff-d1a2-4369-ab13-9c3ebf74b907,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-ad8ebdfe-26ba-415c-b1a0-54c3cd243333,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-065eee1a-8877-4062-93c9-9e689127f91f,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-9b2b414e-426f-426f-b4ac-6205b0e0aae1,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-eb5cdeb6-2ce4-4db7-9926-d83d01a15212,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486767010-172.17.0.7-1597526964254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40950,DS-8aad5f8b-dc43-4c7d-9ff6-f51d3efc2a20,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-e1f6e5fd-28ae-4ad0-a381-13720e5b40c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-575f4eab-c7c0-43e8-a21e-3d2112979fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-92475eff-d1a2-4369-ab13-9c3ebf74b907,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-ad8ebdfe-26ba-415c-b1a0-54c3cd243333,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-065eee1a-8877-4062-93c9-9e689127f91f,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-9b2b414e-426f-426f-b4ac-6205b0e0aae1,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-eb5cdeb6-2ce4-4db7-9926-d83d01a15212,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1532267779-172.17.0.7-1597527362867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39107,DS-ddf65955-1a3d-417a-b529-2ea1469a9a48,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-475b7db4-097f-49b7-84a1-7dc43add29b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-313690b5-a035-4ec6-88a9-c044a0f6a717,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-49166c28-0bd4-4e26-b114-151d58d40fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-a6044c51-ac7b-456c-a8ba-ae977b0d5f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-38d93b77-f0f6-4fba-863a-83a8fc4d44d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-778a8566-427d-4f42-b354-fde44b4a9c66,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-18b67840-3551-4989-a451-0e2dda9f032b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1532267779-172.17.0.7-1597527362867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39107,DS-ddf65955-1a3d-417a-b529-2ea1469a9a48,DISK], DatanodeInfoWithStorage[127.0.0.1:43323,DS-475b7db4-097f-49b7-84a1-7dc43add29b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-313690b5-a035-4ec6-88a9-c044a0f6a717,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-49166c28-0bd4-4e26-b114-151d58d40fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-a6044c51-ac7b-456c-a8ba-ae977b0d5f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-38d93b77-f0f6-4fba-863a-83a8fc4d44d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-778a8566-427d-4f42-b354-fde44b4a9c66,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-18b67840-3551-4989-a451-0e2dda9f032b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1558536285-172.17.0.7-1597527441468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45711,DS-29b050a5-1d26-44c4-92c4-1aaf4fe30c53,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-65e43c5b-7bdc-41cf-bff6-e1324f05e5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-2875b414-219f-43aa-a833-6918ad7018f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-f9759465-542b-4200-b45c-1c200858a0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:32999,DS-d70b11be-dff1-4181-b57a-f6fd774b0b93,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-dd8bc4b2-c58e-47cb-b9eb-34553f804a65,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-414cc04a-3281-486a-bba1-95ff794b3aca,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-64ac25e3-266d-488e-9e9c-cbbb48af872a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1558536285-172.17.0.7-1597527441468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45711,DS-29b050a5-1d26-44c4-92c4-1aaf4fe30c53,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-65e43c5b-7bdc-41cf-bff6-e1324f05e5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-2875b414-219f-43aa-a833-6918ad7018f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-f9759465-542b-4200-b45c-1c200858a0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:32999,DS-d70b11be-dff1-4181-b57a-f6fd774b0b93,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-dd8bc4b2-c58e-47cb-b9eb-34553f804a65,DISK], DatanodeInfoWithStorage[127.0.0.1:38193,DS-414cc04a-3281-486a-bba1-95ff794b3aca,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-64ac25e3-266d-488e-9e9c-cbbb48af872a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-841866487-172.17.0.7-1597528139984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41100,DS-f082f441-061a-48ad-aa32-5cc9fe195089,DISK], DatanodeInfoWithStorage[127.0.0.1:42713,DS-93aaf150-56ae-49b3-a2ce-cb76954da446,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-a4415a7a-30b4-4ba6-b7c5-16c4818ad657,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-1bf41e7e-1227-47a7-a737-46196a3711f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-0155874c-435b-4c93-8a09-e588270c3db0,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-f3cbd298-9842-47c9-a362-863735e98ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-f8c571ad-c201-4647-adca-73d8ecd6104a,DISK], DatanodeInfoWithStorage[127.0.0.1:45198,DS-783c8d69-c5c8-43db-aa10-aba94e7faf56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-841866487-172.17.0.7-1597528139984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41100,DS-f082f441-061a-48ad-aa32-5cc9fe195089,DISK], DatanodeInfoWithStorage[127.0.0.1:42713,DS-93aaf150-56ae-49b3-a2ce-cb76954da446,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-a4415a7a-30b4-4ba6-b7c5-16c4818ad657,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-1bf41e7e-1227-47a7-a737-46196a3711f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36351,DS-0155874c-435b-4c93-8a09-e588270c3db0,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-f3cbd298-9842-47c9-a362-863735e98ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-f8c571ad-c201-4647-adca-73d8ecd6104a,DISK], DatanodeInfoWithStorage[127.0.0.1:45198,DS-783c8d69-c5c8-43db-aa10-aba94e7faf56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1898745925-172.17.0.7-1597528267006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35667,DS-271d21fc-7a45-4d02-a50d-fd66e9ac7c72,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-f8049273-4fae-49d8-a07d-b01960b92fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-d43e8acd-dbda-4a95-a8b3-1121855a45e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-b0a0fe67-a938-4e66-a077-b089c8e18d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-b7798fa8-fdbe-466b-9d64-7864c5322e35,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-6dc327b5-befd-4502-83bb-1f52a8d4292c,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-950b045c-4ee0-490b-a928-13055253ce36,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-ec7c40e4-093f-4ed0-996d-8340fea6f7fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1898745925-172.17.0.7-1597528267006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35667,DS-271d21fc-7a45-4d02-a50d-fd66e9ac7c72,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-f8049273-4fae-49d8-a07d-b01960b92fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-d43e8acd-dbda-4a95-a8b3-1121855a45e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-b0a0fe67-a938-4e66-a077-b089c8e18d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-b7798fa8-fdbe-466b-9d64-7864c5322e35,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-6dc327b5-befd-4502-83bb-1f52a8d4292c,DISK], DatanodeInfoWithStorage[127.0.0.1:35230,DS-950b045c-4ee0-490b-a928-13055253ce36,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-ec7c40e4-093f-4ed0-996d-8340fea6f7fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-224690110-172.17.0.7-1597528538130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37273,DS-4132a15f-83dd-471b-9f49-af52325d12df,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-5213f4a7-6950-458f-ba6b-8d3f3ecfe714,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-8df19c56-f4b9-4cb9-a783-5dc3401e567d,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-9dc61a18-f6d8-4a1a-baa0-654337c3d14f,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-acd4b734-db7f-4107-9d4b-ef3b7a29a612,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-b4713c37-ba35-4c24-b94e-ba2ea15f9481,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-f2dc0979-db33-4cf2-a3d4-6a7ce27ea4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-89419530-ca2a-4052-88f3-09482b7da4d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-224690110-172.17.0.7-1597528538130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37273,DS-4132a15f-83dd-471b-9f49-af52325d12df,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-5213f4a7-6950-458f-ba6b-8d3f3ecfe714,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-8df19c56-f4b9-4cb9-a783-5dc3401e567d,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-9dc61a18-f6d8-4a1a-baa0-654337c3d14f,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-acd4b734-db7f-4107-9d4b-ef3b7a29a612,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-b4713c37-ba35-4c24-b94e-ba2ea15f9481,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-f2dc0979-db33-4cf2-a3d4-6a7ce27ea4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-89419530-ca2a-4052-88f3-09482b7da4d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21916173-172.17.0.7-1597528576963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34832,DS-fbc21ef6-9f5e-4109-b0b7-252a97049db9,DISK], DatanodeInfoWithStorage[127.0.0.1:33283,DS-fdcd9d4e-51d4-49de-a830-a52e4ab6462a,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-8265c167-9cc9-4bbf-b10d-b162b19bbe7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-a41bf4fc-e5c5-4fc9-86dd-40ea8e436237,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-f122091a-4c27-47c4-993b-e571a7ae03ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-4334ee99-ef52-4275-a2ff-b635331b0e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-96abbbad-31b3-477a-8078-f57e1d065a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-d8aa93fa-e254-40fa-ae5a-e554c41b4f96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21916173-172.17.0.7-1597528576963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34832,DS-fbc21ef6-9f5e-4109-b0b7-252a97049db9,DISK], DatanodeInfoWithStorage[127.0.0.1:33283,DS-fdcd9d4e-51d4-49de-a830-a52e4ab6462a,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-8265c167-9cc9-4bbf-b10d-b162b19bbe7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-a41bf4fc-e5c5-4fc9-86dd-40ea8e436237,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-f122091a-4c27-47c4-993b-e571a7ae03ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-4334ee99-ef52-4275-a2ff-b635331b0e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-96abbbad-31b3-477a-8078-f57e1d065a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-d8aa93fa-e254-40fa-ae5a-e554c41b4f96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-354147349-172.17.0.7-1597528660607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46829,DS-29b3afba-fa62-4dc6-aa50-7c39f984dc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-6e9b8fa3-732f-44e1-a1b5-9ffa15825316,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-1317b833-aec8-4208-af15-5dd808ae5554,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-9a603c88-fa2d-45f0-8629-9bc67708d9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-03e01e7e-ea44-4582-bad9-f02d7f4b75fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-6cfabfb7-79ef-4416-bd33-6cb166c34c46,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-4cdf250d-f9e4-477c-a032-e1ec831fbca3,DISK], DatanodeInfoWithStorage[127.0.0.1:45198,DS-617bc7e9-6d05-4328-a8db-34be8194508f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-354147349-172.17.0.7-1597528660607:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46829,DS-29b3afba-fa62-4dc6-aa50-7c39f984dc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-6e9b8fa3-732f-44e1-a1b5-9ffa15825316,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-1317b833-aec8-4208-af15-5dd808ae5554,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-9a603c88-fa2d-45f0-8629-9bc67708d9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-03e01e7e-ea44-4582-bad9-f02d7f4b75fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-6cfabfb7-79ef-4416-bd33-6cb166c34c46,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-4cdf250d-f9e4-477c-a032-e1ec831fbca3,DISK], DatanodeInfoWithStorage[127.0.0.1:45198,DS-617bc7e9-6d05-4328-a8db-34be8194508f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1940950441-172.17.0.7-1597528863174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41553,DS-64c7a8f6-2e64-4c7e-8743-fe9589aea5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-e61d585e-4f29-4d94-997f-b0767fb8e494,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-0250e259-608e-4b62-947c-86baf13f32b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-19d2e0b5-0aca-4dd4-9030-b3e556c433fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-4557a760-7bca-4cca-a96e-48de58bc206a,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-c6e45a19-1c75-4145-bd82-41f86481c5af,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-dadb95b9-8977-42b3-9d1c-c29555a25357,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-dc58edf0-f7b3-4b15-8683-27adcc34b5ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1940950441-172.17.0.7-1597528863174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41553,DS-64c7a8f6-2e64-4c7e-8743-fe9589aea5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-e61d585e-4f29-4d94-997f-b0767fb8e494,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-0250e259-608e-4b62-947c-86baf13f32b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-19d2e0b5-0aca-4dd4-9030-b3e556c433fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-4557a760-7bca-4cca-a96e-48de58bc206a,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-c6e45a19-1c75-4145-bd82-41f86481c5af,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-dadb95b9-8977-42b3-9d1c-c29555a25357,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-dc58edf0-f7b3-4b15-8683-27adcc34b5ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5596
