reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3600
v2: 3ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3600
v2: 3ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1714925708-172.17.0.13-1597499528948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33921,DS-c0af72ac-ae2d-4bdc-804c-df927e2473e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-f9eec6dd-63d1-40a5-96af-068621b10011,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-cf2d6893-ada1-46fe-8d56-c51ca9bb05dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-bd43e87f-9f16-439b-a823-fa7889b925aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-88a9ddfa-b847-4d23-a9a7-d28e6b539afb,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-ee6d595f-d37a-480f-b824-2419368c158c,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-e28895e1-2808-4ef4-af9f-86789506c386,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-b3db4862-97ad-4352-8495-9491c55af78b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1714925708-172.17.0.13-1597499528948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33921,DS-c0af72ac-ae2d-4bdc-804c-df927e2473e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-f9eec6dd-63d1-40a5-96af-068621b10011,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-cf2d6893-ada1-46fe-8d56-c51ca9bb05dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-bd43e87f-9f16-439b-a823-fa7889b925aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-88a9ddfa-b847-4d23-a9a7-d28e6b539afb,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-ee6d595f-d37a-480f-b824-2419368c158c,DISK], DatanodeInfoWithStorage[127.0.0.1:32856,DS-e28895e1-2808-4ef4-af9f-86789506c386,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-b3db4862-97ad-4352-8495-9491c55af78b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3600
v2: 3ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1720523747-172.17.0.13-1597499625483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33733,DS-9a73d6a1-0c63-4f3f-8486-6d4214a63d36,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-0c6f5694-a7e1-4bd3-881d-6979d297aed7,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-6d9cea0d-cb89-4e4c-8280-4eca676322f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-84df8335-304a-4f31-8b2f-ab5aaf58e4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-41061a0e-6d1a-4a55-b4c1-e1d6f7b4d36c,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-812729c5-bc01-4fc2-8e31-7e152c9e79df,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-84116b93-7807-4ec4-a7e0-0da70b050e46,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-8e547611-b8a3-47ce-af7e-945e3081aca4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1720523747-172.17.0.13-1597499625483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33733,DS-9a73d6a1-0c63-4f3f-8486-6d4214a63d36,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-0c6f5694-a7e1-4bd3-881d-6979d297aed7,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-6d9cea0d-cb89-4e4c-8280-4eca676322f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-84df8335-304a-4f31-8b2f-ab5aaf58e4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38167,DS-41061a0e-6d1a-4a55-b4c1-e1d6f7b4d36c,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-812729c5-bc01-4fc2-8e31-7e152c9e79df,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-84116b93-7807-4ec4-a7e0-0da70b050e46,DISK], DatanodeInfoWithStorage[127.0.0.1:35401,DS-8e547611-b8a3-47ce-af7e-945e3081aca4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3600
v2: 3ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1259442758-172.17.0.13-1597500271853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46536,DS-87a168dc-3229-49d0-9067-bcd787425707,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-72ede30a-602b-41ae-8f11-824780f37412,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-c04f8ba4-c5f9-4475-ad0c-be1d1c90df9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-b286a35b-b932-435e-a43b-9043f46e7422,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-13992c93-c45d-48c6-8182-3c1fd751e707,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-7d43c79c-83bb-4e2f-9fe7-7e1af0049b92,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-a19d317e-f7c3-4546-a3e9-80d1f0b7e086,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-b7954c2b-fac4-4c26-8670-507a085f2ff8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1259442758-172.17.0.13-1597500271853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46536,DS-87a168dc-3229-49d0-9067-bcd787425707,DISK], DatanodeInfoWithStorage[127.0.0.1:32829,DS-72ede30a-602b-41ae-8f11-824780f37412,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-c04f8ba4-c5f9-4475-ad0c-be1d1c90df9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-b286a35b-b932-435e-a43b-9043f46e7422,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-13992c93-c45d-48c6-8182-3c1fd751e707,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-7d43c79c-83bb-4e2f-9fe7-7e1af0049b92,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-a19d317e-f7c3-4546-a3e9-80d1f0b7e086,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-b7954c2b-fac4-4c26-8670-507a085f2ff8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3600
v2: 3ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1504357642-172.17.0.13-1597501116503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36983,DS-ff958375-33b0-4802-a9d8-fe2b17baf522,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-20080328-14c8-4056-b178-3418473af6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-c74faf93-a34e-41e7-9151-ed61f8494fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-cb0d5a60-592f-4c08-9f2d-d71266236f74,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-b4a3865e-6f77-4bfb-aad1-5d5ba7e79455,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-22674365-2959-4d71-982c-88937cb34a59,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-e0302d59-dcb7-4fdc-89fd-ec85301a6293,DISK], DatanodeInfoWithStorage[127.0.0.1:35219,DS-480e7b09-71b2-4234-a644-f5427edd3d65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1504357642-172.17.0.13-1597501116503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36983,DS-ff958375-33b0-4802-a9d8-fe2b17baf522,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-20080328-14c8-4056-b178-3418473af6a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-c74faf93-a34e-41e7-9151-ed61f8494fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-cb0d5a60-592f-4c08-9f2d-d71266236f74,DISK], DatanodeInfoWithStorage[127.0.0.1:42290,DS-b4a3865e-6f77-4bfb-aad1-5d5ba7e79455,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-22674365-2959-4d71-982c-88937cb34a59,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-e0302d59-dcb7-4fdc-89fd-ec85301a6293,DISK], DatanodeInfoWithStorage[127.0.0.1:35219,DS-480e7b09-71b2-4234-a644-f5427edd3d65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3600
v2: 3ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-798441496-172.17.0.13-1597501260574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43452,DS-9b36dd22-774a-4667-8c2b-be875756a147,DISK], DatanodeInfoWithStorage[127.0.0.1:45924,DS-84302b1e-6fd1-42c2-930d-9eb4119a3b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-3b56eb05-5ed7-4dc8-a60b-dff1ca79f560,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-3790a0b0-adb5-49a0-9772-b495175ceabd,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-d52eafd3-e2dc-463d-8e5c-130895b28561,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-1e370539-7421-4f1a-9d20-f85872817614,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-2e95114f-da41-4886-a1c2-8964cb194afd,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-772471d3-c72b-4025-8e3b-c6eb58566ccb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-798441496-172.17.0.13-1597501260574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43452,DS-9b36dd22-774a-4667-8c2b-be875756a147,DISK], DatanodeInfoWithStorage[127.0.0.1:45924,DS-84302b1e-6fd1-42c2-930d-9eb4119a3b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-3b56eb05-5ed7-4dc8-a60b-dff1ca79f560,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-3790a0b0-adb5-49a0-9772-b495175ceabd,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-d52eafd3-e2dc-463d-8e5c-130895b28561,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-1e370539-7421-4f1a-9d20-f85872817614,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-2e95114f-da41-4886-a1c2-8964cb194afd,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-772471d3-c72b-4025-8e3b-c6eb58566ccb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3600
v2: 3ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891605438-172.17.0.13-1597501801895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45669,DS-706f17d9-f4f6-438a-8ec7-d9cfc0fdc242,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-9cc31b8c-e16b-4d56-a64a-89bb5f06fb47,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-74c9f25b-5716-46fd-99f7-0d3a125e0945,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-31611111-6868-4e1b-afc8-feea64c347d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-ba295fe1-955d-4e10-aa48-37f6b28f9060,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-602f62fd-3ef5-47c4-b316-9d3377a1083f,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-2d35a2ec-844b-4cae-a4bf-5096542fc8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-45b9c285-a2f0-4f4e-86f4-d5a478cf1959,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891605438-172.17.0.13-1597501801895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45669,DS-706f17d9-f4f6-438a-8ec7-d9cfc0fdc242,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-9cc31b8c-e16b-4d56-a64a-89bb5f06fb47,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-74c9f25b-5716-46fd-99f7-0d3a125e0945,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-31611111-6868-4e1b-afc8-feea64c347d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-ba295fe1-955d-4e10-aa48-37f6b28f9060,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-602f62fd-3ef5-47c4-b316-9d3377a1083f,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-2d35a2ec-844b-4cae-a4bf-5096542fc8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33791,DS-45b9c285-a2f0-4f4e-86f4-d5a478cf1959,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3600
v2: 3ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933198616-172.17.0.13-1597502292432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44569,DS-4748238a-04a2-4ed2-817c-68774f8a21cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-8942c443-752b-4c7d-8316-e1c1f03bf72b,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-66208bc9-bcd0-416f-84cd-fe9df73813df,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-59b7458b-e783-492f-a1d4-1a2f55111363,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-b1ad9029-a23e-4db5-8a7a-ac856c96c4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-0fd502b2-1431-46f8-9106-dd98fc355f72,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-2c367bb6-c607-496f-8dda-8169f2628f02,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-637ee9f9-2d6f-4028-a103-c5d98a7a4544,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933198616-172.17.0.13-1597502292432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44569,DS-4748238a-04a2-4ed2-817c-68774f8a21cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-8942c443-752b-4c7d-8316-e1c1f03bf72b,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-66208bc9-bcd0-416f-84cd-fe9df73813df,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-59b7458b-e783-492f-a1d4-1a2f55111363,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-b1ad9029-a23e-4db5-8a7a-ac856c96c4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-0fd502b2-1431-46f8-9106-dd98fc355f72,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-2c367bb6-c607-496f-8dda-8169f2628f02,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-637ee9f9-2d6f-4028-a103-c5d98a7a4544,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3600
v2: 3ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-409864509-172.17.0.13-1597502507067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37455,DS-ff99e3ee-682a-4267-8990-a21d03c0fccf,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-28fa2f1e-b56e-4d91-b69f-201affdafde8,DISK], DatanodeInfoWithStorage[127.0.0.1:37473,DS-81cf47ed-8321-4067-8450-53a716ef8de6,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-11c17e76-92ba-4f3c-8f70-ef71cf1bfce2,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-7ddb1af5-8738-4fbf-953f-ab9cbaea4574,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-5f35e9e5-53f7-4704-a30b-13fe00497664,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-47d6f16d-3d53-4c17-89f7-530f0d0039ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-435891e9-0d3b-4810-bf39-21162faeba64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-409864509-172.17.0.13-1597502507067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37455,DS-ff99e3ee-682a-4267-8990-a21d03c0fccf,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-28fa2f1e-b56e-4d91-b69f-201affdafde8,DISK], DatanodeInfoWithStorage[127.0.0.1:37473,DS-81cf47ed-8321-4067-8450-53a716ef8de6,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-11c17e76-92ba-4f3c-8f70-ef71cf1bfce2,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-7ddb1af5-8738-4fbf-953f-ab9cbaea4574,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-5f35e9e5-53f7-4704-a30b-13fe00497664,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-47d6f16d-3d53-4c17-89f7-530f0d0039ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-435891e9-0d3b-4810-bf39-21162faeba64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3600
v2: 3ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011851895-172.17.0.13-1597503711349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44626,DS-992740c6-04b3-413b-b5c6-a59bc4745af2,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-1c07e3dc-ab89-4f54-af8e-488ccd63d7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-7ebfe434-7f43-4349-85ff-7101b3e9e52d,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-a84d49fe-0c55-41ed-8b3b-ea99103fb401,DISK], DatanodeInfoWithStorage[127.0.0.1:33185,DS-cf341448-e838-4f32-8563-79695026d34e,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-32736789-04df-49d3-8948-70151ccd490f,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-bf41bef0-9931-48cf-ad28-eb50d1830c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-70a52571-0006-4114-8cb3-85e9a4a6c8c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011851895-172.17.0.13-1597503711349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44626,DS-992740c6-04b3-413b-b5c6-a59bc4745af2,DISK], DatanodeInfoWithStorage[127.0.0.1:35323,DS-1c07e3dc-ab89-4f54-af8e-488ccd63d7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-7ebfe434-7f43-4349-85ff-7101b3e9e52d,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-a84d49fe-0c55-41ed-8b3b-ea99103fb401,DISK], DatanodeInfoWithStorage[127.0.0.1:33185,DS-cf341448-e838-4f32-8563-79695026d34e,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-32736789-04df-49d3-8948-70151ccd490f,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-bf41bef0-9931-48cf-ad28-eb50d1830c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-70a52571-0006-4114-8cb3-85e9a4a6c8c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3600
v2: 3ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-389879722-172.17.0.13-1597503855277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36483,DS-ecc57d10-e7b0-4d02-9959-5defc76d5dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-2ae11978-3437-4355-aefc-06b4cbe73861,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-b10dc6e5-fe81-4810-8683-8efdead47022,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-7d9a50ee-4675-47f8-bca0-2473b88f1cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-a3ba5809-7d5d-4da5-9d0b-e63bf910e5de,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-ce1bf387-e93f-4435-a189-5492b74977a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-e5a0404e-98bf-4d9b-92ef-e7e15672930e,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-964482e8-c4fa-4257-933a-09153d3fcd33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-389879722-172.17.0.13-1597503855277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36483,DS-ecc57d10-e7b0-4d02-9959-5defc76d5dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-2ae11978-3437-4355-aefc-06b4cbe73861,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-b10dc6e5-fe81-4810-8683-8efdead47022,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-7d9a50ee-4675-47f8-bca0-2473b88f1cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-a3ba5809-7d5d-4da5-9d0b-e63bf910e5de,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-ce1bf387-e93f-4435-a189-5492b74977a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-e5a0404e-98bf-4d9b-92ef-e7e15672930e,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-964482e8-c4fa-4257-933a-09153d3fcd33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3600
v2: 3ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089593878-172.17.0.13-1597503889183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39232,DS-2ff3578b-bee2-4d34-8182-82bbf7a547cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-800b55a3-d038-4deb-bb1f-c0fdb54d92ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-f8e39216-8679-4f88-bd7d-364387d12f93,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-d073008d-a414-4e02-a359-acd7c3f8bf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-311c5343-669b-4d3f-89c5-6117e72c41cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-d1f6529b-e7f5-4e69-91e8-1b490f4f0916,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-32380f76-df2f-43a8-aa41-b6d40e15e0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-42259b45-8d02-463e-b360-8ae2e0f75965,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089593878-172.17.0.13-1597503889183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39232,DS-2ff3578b-bee2-4d34-8182-82bbf7a547cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44979,DS-800b55a3-d038-4deb-bb1f-c0fdb54d92ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-f8e39216-8679-4f88-bd7d-364387d12f93,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-d073008d-a414-4e02-a359-acd7c3f8bf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-311c5343-669b-4d3f-89c5-6117e72c41cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-d1f6529b-e7f5-4e69-91e8-1b490f4f0916,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-32380f76-df2f-43a8-aa41-b6d40e15e0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-42259b45-8d02-463e-b360-8ae2e0f75965,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3600
v2: 3ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1505200771-172.17.0.13-1597504480885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44739,DS-5dab4583-746d-4745-b5ad-5d666c881822,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-763bf9bc-a1bb-4b52-b81f-7c211d8a01ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-548adb3f-ff35-44bd-8642-a994846a1816,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-b9e84e1b-6124-4e08-9eae-e4606551c33d,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-e990f854-663b-42f5-b644-f4b6098557b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-306c7579-4430-4ccb-a5bc-95cc15c5d065,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-48f6122f-7a62-49b2-9e46-2fa2687a0876,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-998803d8-27da-40b4-b972-81c86df96537,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1505200771-172.17.0.13-1597504480885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44739,DS-5dab4583-746d-4745-b5ad-5d666c881822,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-763bf9bc-a1bb-4b52-b81f-7c211d8a01ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43364,DS-548adb3f-ff35-44bd-8642-a994846a1816,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-b9e84e1b-6124-4e08-9eae-e4606551c33d,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-e990f854-663b-42f5-b644-f4b6098557b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-306c7579-4430-4ccb-a5bc-95cc15c5d065,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-48f6122f-7a62-49b2-9e46-2fa2687a0876,DISK], DatanodeInfoWithStorage[127.0.0.1:45565,DS-998803d8-27da-40b4-b972-81c86df96537,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.period
component: hdfs:NameNode
v1: 3600
v2: 3ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-44675440-172.17.0.13-1597504644728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42956,DS-aa5a071b-7bdd-4bd5-a101-2c5f86502106,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-bd586ea2-8f98-4377-93cf-db799b1f1913,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-5cac29b4-6a6b-47f3-a864-ae345ea2e228,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-c02297d4-34c9-4722-a8d7-2a23fc83bb31,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-1e9aa0e4-9bc8-4601-b1b2-b20dfadae31b,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-7d4e3a89-8fb7-40f9-8283-1e338ecf7ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-53790548-44fb-4062-ba12-923894b5af9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-ea5c152c-82de-47f8-9053-dc3834e7a9e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-44675440-172.17.0.13-1597504644728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42956,DS-aa5a071b-7bdd-4bd5-a101-2c5f86502106,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-bd586ea2-8f98-4377-93cf-db799b1f1913,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-5cac29b4-6a6b-47f3-a864-ae345ea2e228,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-c02297d4-34c9-4722-a8d7-2a23fc83bb31,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-1e9aa0e4-9bc8-4601-b1b2-b20dfadae31b,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-7d4e3a89-8fb7-40f9-8283-1e338ecf7ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-53790548-44fb-4062-ba12-923894b5af9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-ea5c152c-82de-47f8-9053-dc3834e7a9e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5667
