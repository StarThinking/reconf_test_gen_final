reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1452075237-172.17.0.12-1597399873983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41135,DS-60340d5f-a5f1-4c0e-b16e-cdd7f7307cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-fffd1117-dbc3-4888-b066-1a25a8943915,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-56aaa5f3-93f6-4bd0-881d-fec8c1465401,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-bf82c942-b51d-4c6b-9e0d-75dc659ccf5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-e8d3a141-29ef-427b-9e8e-3ec131ac81f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-c4fc330f-293b-4680-97a6-41650d93235e,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-500129e6-1f09-4f66-a216-3fbb62be7d10,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-bcb8fad3-02c1-42fd-b822-910d38b3dcbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1452075237-172.17.0.12-1597399873983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41135,DS-60340d5f-a5f1-4c0e-b16e-cdd7f7307cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-fffd1117-dbc3-4888-b066-1a25a8943915,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-56aaa5f3-93f6-4bd0-881d-fec8c1465401,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-bf82c942-b51d-4c6b-9e0d-75dc659ccf5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-e8d3a141-29ef-427b-9e8e-3ec131ac81f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-c4fc330f-293b-4680-97a6-41650d93235e,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-500129e6-1f09-4f66-a216-3fbb62be7d10,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-bcb8fad3-02c1-42fd-b822-910d38b3dcbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1798379610-172.17.0.12-1597400693933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38830,DS-9361e82f-df6e-477a-8c12-4d572eadbb63,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-ddf27688-7eff-4db6-86d5-34ac31082756,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-3c3b6df8-01d7-472e-8bc9-bece4aedf0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-10030f06-c157-4714-98f4-71f19f386caf,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-3936310a-d7f5-4ad6-9a7d-8eab531f50f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-061ef570-a27f-4344-9108-6c67b710d056,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-8f3f6656-c302-4cfc-8998-218e14d08cec,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-a828a803-0d89-472c-8220-3e7ab7c97624,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1798379610-172.17.0.12-1597400693933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38830,DS-9361e82f-df6e-477a-8c12-4d572eadbb63,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-ddf27688-7eff-4db6-86d5-34ac31082756,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-3c3b6df8-01d7-472e-8bc9-bece4aedf0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-10030f06-c157-4714-98f4-71f19f386caf,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-3936310a-d7f5-4ad6-9a7d-8eab531f50f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38258,DS-061ef570-a27f-4344-9108-6c67b710d056,DISK], DatanodeInfoWithStorage[127.0.0.1:45939,DS-8f3f6656-c302-4cfc-8998-218e14d08cec,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-a828a803-0d89-472c-8220-3e7ab7c97624,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-672360837-172.17.0.12-1597401406904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43983,DS-bace62a2-d644-45c8-96e8-1f9d86c86b16,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-b44fbf24-b8bd-4224-b033-529da02b1fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-88f5d016-5e02-4b8b-a257-a57c8ba4ef2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-731d87ba-ea14-4c92-ab18-2790409c2e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-21a75801-4396-4531-b17b-36910e77c0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-5c82ac04-10ca-4b2f-b275-ec283a5de1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-962526e9-3d7b-455b-a93a-b77eb5912ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-ef9c772e-31be-45c3-90c9-5f92e03194a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-672360837-172.17.0.12-1597401406904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43983,DS-bace62a2-d644-45c8-96e8-1f9d86c86b16,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-b44fbf24-b8bd-4224-b033-529da02b1fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-88f5d016-5e02-4b8b-a257-a57c8ba4ef2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-731d87ba-ea14-4c92-ab18-2790409c2e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40718,DS-21a75801-4396-4531-b17b-36910e77c0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-5c82ac04-10ca-4b2f-b275-ec283a5de1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-962526e9-3d7b-455b-a93a-b77eb5912ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:44789,DS-ef9c772e-31be-45c3-90c9-5f92e03194a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1915606782-172.17.0.12-1597401450779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43158,DS-850ee109-4a0b-4e76-829e-340d06de6e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-7c8c3052-f62e-447f-96e5-33cd3dfc689b,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-3c6a197f-553d-4eb5-905b-233c27bbdfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-13c4d52d-cb00-4201-814f-43aca58cbc74,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-8dddcf37-f6f5-4c3e-bcad-f12ac16c32ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-875b5f53-72d4-437e-b582-af7964ae3563,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-a79e3a4a-eb27-4b6c-93d8-dcc497eb0745,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-a350f4fb-eb23-4e4a-b98a-16128d257f6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1915606782-172.17.0.12-1597401450779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43158,DS-850ee109-4a0b-4e76-829e-340d06de6e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-7c8c3052-f62e-447f-96e5-33cd3dfc689b,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-3c6a197f-553d-4eb5-905b-233c27bbdfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-13c4d52d-cb00-4201-814f-43aca58cbc74,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-8dddcf37-f6f5-4c3e-bcad-f12ac16c32ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-875b5f53-72d4-437e-b582-af7964ae3563,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-a79e3a4a-eb27-4b6c-93d8-dcc497eb0745,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-a350f4fb-eb23-4e4a-b98a-16128d257f6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1128745938-172.17.0.12-1597401676643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36216,DS-85976108-9a2b-40e2-8f00-2cebb4ffbbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-f1d75d66-416d-4763-a75f-91833dc7beba,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-b983bc7b-e725-4361-aab5-77ee08fe33af,DISK], DatanodeInfoWithStorage[127.0.0.1:42835,DS-d4ce677c-6454-4da2-9775-9f00b66b6481,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-64d8b75e-26c0-4349-9b39-b2f68f3ff903,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-bdc4e9e6-0494-49ea-a97d-72a10e18a362,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-ac79e883-d39d-4a12-a40a-eb20cc6cd582,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-318e28af-a302-45bd-b824-91d220fd7666,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1128745938-172.17.0.12-1597401676643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36216,DS-85976108-9a2b-40e2-8f00-2cebb4ffbbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-f1d75d66-416d-4763-a75f-91833dc7beba,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-b983bc7b-e725-4361-aab5-77ee08fe33af,DISK], DatanodeInfoWithStorage[127.0.0.1:42835,DS-d4ce677c-6454-4da2-9775-9f00b66b6481,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-64d8b75e-26c0-4349-9b39-b2f68f3ff903,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-bdc4e9e6-0494-49ea-a97d-72a10e18a362,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-ac79e883-d39d-4a12-a40a-eb20cc6cd582,DISK], DatanodeInfoWithStorage[127.0.0.1:38569,DS-318e28af-a302-45bd-b824-91d220fd7666,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1814505272-172.17.0.12-1597402354273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41621,DS-1ce6aa46-687d-4e7e-befe-e77b88a739e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-cd0a4167-479f-453d-95af-c6be605142c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-841d0b44-1955-4b5c-a0bf-d6673ed4192c,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-d15491ff-8a88-4802-a14c-a05c69c9ef9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-ced9f251-8335-4804-9bfd-1449a26a8e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-8ff83896-0ff4-450f-a17b-8ececa30d21e,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-cbdeebd7-fac1-43fe-a96d-d4bdfea75949,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-b312bcd0-70be-4c94-8ba0-793bf4501ffd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1814505272-172.17.0.12-1597402354273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41621,DS-1ce6aa46-687d-4e7e-befe-e77b88a739e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-cd0a4167-479f-453d-95af-c6be605142c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-841d0b44-1955-4b5c-a0bf-d6673ed4192c,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-d15491ff-8a88-4802-a14c-a05c69c9ef9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-ced9f251-8335-4804-9bfd-1449a26a8e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-8ff83896-0ff4-450f-a17b-8ececa30d21e,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-cbdeebd7-fac1-43fe-a96d-d4bdfea75949,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-b312bcd0-70be-4c94-8ba0-793bf4501ffd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961690774-172.17.0.12-1597402442042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34295,DS-44f33ca5-42d6-4d17-928d-5b89019d2902,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-01867610-c585-4db7-ab11-dcc7cdd485e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-ca0ff676-b694-4a78-af64-0341fdb80143,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-4c8ced17-1170-40ad-9986-398b86a12e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-2c53d952-f28d-461e-b9f3-0d84cfce7c16,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-f786ff51-3a2b-4fb7-ab71-7f9f7a44c0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-6b8f3818-5118-4e65-ad11-3c00821b9aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-00f24589-b540-47b1-ad95-644c6f64be4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961690774-172.17.0.12-1597402442042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34295,DS-44f33ca5-42d6-4d17-928d-5b89019d2902,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-01867610-c585-4db7-ab11-dcc7cdd485e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33043,DS-ca0ff676-b694-4a78-af64-0341fdb80143,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-4c8ced17-1170-40ad-9986-398b86a12e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42946,DS-2c53d952-f28d-461e-b9f3-0d84cfce7c16,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-f786ff51-3a2b-4fb7-ab71-7f9f7a44c0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-6b8f3818-5118-4e65-ad11-3c00821b9aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-00f24589-b540-47b1-ad95-644c6f64be4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-259908035-172.17.0.12-1597403277015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45064,DS-27970a2d-01c2-459c-abac-728f3257b4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-1fc7c890-c645-4cb6-8709-a8e5af0dae7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-f88bb7fc-2afe-4054-b282-307222780cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-5b7bf7e4-3ac3-41c0-9e18-cb96f50ecd26,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-926720b8-f266-4906-bd7e-21834302551d,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-efea604d-2465-4e6f-b9e7-1f9d23ef7278,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-91d74c48-65cc-4a76-b23f-19bf9d148348,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-5970b7d7-e2f9-477c-9375-58d8f99a4286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-259908035-172.17.0.12-1597403277015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45064,DS-27970a2d-01c2-459c-abac-728f3257b4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43435,DS-1fc7c890-c645-4cb6-8709-a8e5af0dae7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-f88bb7fc-2afe-4054-b282-307222780cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-5b7bf7e4-3ac3-41c0-9e18-cb96f50ecd26,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-926720b8-f266-4906-bd7e-21834302551d,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-efea604d-2465-4e6f-b9e7-1f9d23ef7278,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-91d74c48-65cc-4a76-b23f-19bf9d148348,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-5970b7d7-e2f9-477c-9375-58d8f99a4286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-592354173-172.17.0.12-1597403537222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33879,DS-88201a1f-2038-4abf-acd0-a1a1baab2c72,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-6318649c-06bf-4ec2-9df3-831d46d342a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-d4618c07-a2fa-4a94-bf4e-32f05f878e64,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-22953bf2-9562-41c7-a2cc-8ce0ffe0784d,DISK], DatanodeInfoWithStorage[127.0.0.1:40551,DS-bce51a2a-22c5-4e66-8778-900e225d96fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-44e681b8-067d-4f45-ab84-3d5a471b991a,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-613af28e-df74-4c14-9d90-cf75e903c9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-2d5c5ed5-d809-47b8-90bc-fe51cc56be69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-592354173-172.17.0.12-1597403537222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33879,DS-88201a1f-2038-4abf-acd0-a1a1baab2c72,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-6318649c-06bf-4ec2-9df3-831d46d342a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-d4618c07-a2fa-4a94-bf4e-32f05f878e64,DISK], DatanodeInfoWithStorage[127.0.0.1:41578,DS-22953bf2-9562-41c7-a2cc-8ce0ffe0784d,DISK], DatanodeInfoWithStorage[127.0.0.1:40551,DS-bce51a2a-22c5-4e66-8778-900e225d96fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-44e681b8-067d-4f45-ab84-3d5a471b991a,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-613af28e-df74-4c14-9d90-cf75e903c9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-2d5c5ed5-d809-47b8-90bc-fe51cc56be69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1211074117-172.17.0.12-1597403623425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44370,DS-b610c979-5508-45f3-97d7-e3276d3702e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-f0d203ce-08f4-4739-a554-d33cc3f421fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-86694323-1507-4b91-a8f9-ecd88d8da133,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-1e25e422-b0ce-4b43-9906-594df44ef7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42427,DS-a3e0c667-d32c-4553-8880-f73bc27f6f59,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-aa74c1d0-2255-4cf0-9ccf-3c3e67e23de4,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-6b83afb5-2964-490b-a63d-f84e37cbd7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-479e98d6-1780-43d5-9dd8-4cba4f193700,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1211074117-172.17.0.12-1597403623425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44370,DS-b610c979-5508-45f3-97d7-e3276d3702e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-f0d203ce-08f4-4739-a554-d33cc3f421fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-86694323-1507-4b91-a8f9-ecd88d8da133,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-1e25e422-b0ce-4b43-9906-594df44ef7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42427,DS-a3e0c667-d32c-4553-8880-f73bc27f6f59,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-aa74c1d0-2255-4cf0-9ccf-3c3e67e23de4,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-6b83afb5-2964-490b-a63d-f84e37cbd7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-479e98d6-1780-43d5-9dd8-4cba4f193700,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1679565557-172.17.0.12-1597403713680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45178,DS-253bfae6-863f-41bb-99a5-d28be79b7127,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-e46d8e2e-f461-4834-a33e-41578b60ce9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-4c678a55-87db-4352-a86e-8a94f29b8844,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-f12dd6be-6e7b-40d1-b8a1-e936d4940d95,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-64ee1749-36cd-4c62-bde7-5633050e9621,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-db70fc93-e321-47fe-b22f-b9c2478c7902,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-c55376b4-914a-40e5-b831-011b1f3c75e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-2f5e0963-26f0-4383-852d-4d6432c65807,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1679565557-172.17.0.12-1597403713680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45178,DS-253bfae6-863f-41bb-99a5-d28be79b7127,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-e46d8e2e-f461-4834-a33e-41578b60ce9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43942,DS-4c678a55-87db-4352-a86e-8a94f29b8844,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-f12dd6be-6e7b-40d1-b8a1-e936d4940d95,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-64ee1749-36cd-4c62-bde7-5633050e9621,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-db70fc93-e321-47fe-b22f-b9c2478c7902,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-c55376b4-914a-40e5-b831-011b1f3c75e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-2f5e0963-26f0-4383-852d-4d6432c65807,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1127619848-172.17.0.12-1597404170496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43211,DS-971b0000-14f4-4649-9d8e-19bb6588fac2,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-e28d8220-9b55-4c46-b060-04d5235d5392,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-9cd3564e-eec3-42a6-bf04-22361e35e16f,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-abe755f2-1ae8-493c-8fe9-c3ea1df68c90,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-c30dc31b-f46b-4402-a83a-51bbde366989,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-96e85454-6f36-4bf4-816c-927553ee26d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-94d8821c-11f4-45d6-9094-c7db62cb4540,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-3b3e63d0-abe1-4a38-a6b0-85f3cfe04af5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1127619848-172.17.0.12-1597404170496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43211,DS-971b0000-14f4-4649-9d8e-19bb6588fac2,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-e28d8220-9b55-4c46-b060-04d5235d5392,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-9cd3564e-eec3-42a6-bf04-22361e35e16f,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-abe755f2-1ae8-493c-8fe9-c3ea1df68c90,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-c30dc31b-f46b-4402-a83a-51bbde366989,DISK], DatanodeInfoWithStorage[127.0.0.1:40593,DS-96e85454-6f36-4bf4-816c-927553ee26d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46813,DS-94d8821c-11f4-45d6-9094-c7db62cb4540,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-3b3e63d0-abe1-4a38-a6b0-85f3cfe04af5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1412374605-172.17.0.12-1597404221966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33182,DS-329ace56-846a-4a88-8fbe-d5877b44092b,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-2e8e48ed-7933-4110-9bf1-324ee655c978,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-ce1725ff-54df-4794-9c7e-b6042405aead,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-3684b5ac-04a1-4403-881b-8ba54e6daa36,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-b8bb12f1-5f8b-4eb3-b6c9-b213720d74cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-da1dec05-100f-4328-90d0-d212ae5fc9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-c607690f-811c-48e1-afd6-86d1f736b8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-61c2b4a3-8b34-43da-818b-7e580221e0c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1412374605-172.17.0.12-1597404221966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33182,DS-329ace56-846a-4a88-8fbe-d5877b44092b,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-2e8e48ed-7933-4110-9bf1-324ee655c978,DISK], DatanodeInfoWithStorage[127.0.0.1:40111,DS-ce1725ff-54df-4794-9c7e-b6042405aead,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-3684b5ac-04a1-4403-881b-8ba54e6daa36,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-b8bb12f1-5f8b-4eb3-b6c9-b213720d74cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-da1dec05-100f-4328-90d0-d212ae5fc9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-c607690f-811c-48e1-afd6-86d1f736b8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-61c2b4a3-8b34-43da-818b-7e580221e0c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405363343-172.17.0.12-1597404681046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45936,DS-21d2e5d8-4937-4686-88d6-d4de7d151d72,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-f33e4b8f-e104-45ae-9495-5a6d6dda50b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-8bda9ca8-a14e-4a3a-a435-60b6671dae58,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-cafbd25c-9f89-4647-b97a-dd0abc2b76e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-500ba79e-eb6b-42b2-887c-36881f883684,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-469b1bd3-9f79-4d56-9127-2c2dbde141bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-496cd55b-7cc9-470d-a2d9-ac5dc5c45caf,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-3198fb36-fea2-4abc-9b72-c04164474b65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405363343-172.17.0.12-1597404681046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45936,DS-21d2e5d8-4937-4686-88d6-d4de7d151d72,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-f33e4b8f-e104-45ae-9495-5a6d6dda50b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-8bda9ca8-a14e-4a3a-a435-60b6671dae58,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-cafbd25c-9f89-4647-b97a-dd0abc2b76e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-500ba79e-eb6b-42b2-887c-36881f883684,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-469b1bd3-9f79-4d56-9127-2c2dbde141bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-496cd55b-7cc9-470d-a2d9-ac5dc5c45caf,DISK], DatanodeInfoWithStorage[127.0.0.1:39264,DS-3198fb36-fea2-4abc-9b72-c04164474b65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-478974334-172.17.0.12-1597405635844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33391,DS-5465dcdf-0e2d-4dee-88bb-861576a3a7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-fd3551f6-5ac2-4846-a80b-b39cf98f1b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-36f94c25-0dba-4f10-8b5f-badada644209,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-50567cc2-6145-4d3d-ae21-348a6996f1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-7f8676e3-b5a1-4487-80d6-296bd7216c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-36c1d9d0-db1a-4003-bf3f-ebc038823554,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-40a0b702-064d-4a5f-aec2-a451159671da,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-3f76730b-928f-4e6b-bdfc-dff2aaf42a63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-478974334-172.17.0.12-1597405635844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33391,DS-5465dcdf-0e2d-4dee-88bb-861576a3a7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-fd3551f6-5ac2-4846-a80b-b39cf98f1b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-36f94c25-0dba-4f10-8b5f-badada644209,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-50567cc2-6145-4d3d-ae21-348a6996f1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-7f8676e3-b5a1-4487-80d6-296bd7216c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-36c1d9d0-db1a-4003-bf3f-ebc038823554,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-40a0b702-064d-4a5f-aec2-a451159671da,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-3f76730b-928f-4e6b-bdfc-dff2aaf42a63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1248469064-172.17.0.12-1597405880701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37531,DS-57a33c31-0feb-45f8-8622-bb7b372f9cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-dc5e4811-3394-4a46-885d-a590c17fae3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-c2856423-cdc1-4e8e-afb1-a3e2c1efd25a,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-a66d9e50-a8f7-4725-874f-27a90cae8e86,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-3a264482-4870-4fb8-91dd-933b99bf6b40,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-2fe074c0-cef2-4a44-875c-6bbd7f6dd765,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-3241bd39-2a56-4c9c-9c64-80f4ffc8e752,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-a1a67396-ddc2-4824-b236-b9083a127a7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1248469064-172.17.0.12-1597405880701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37531,DS-57a33c31-0feb-45f8-8622-bb7b372f9cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-dc5e4811-3394-4a46-885d-a590c17fae3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-c2856423-cdc1-4e8e-afb1-a3e2c1efd25a,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-a66d9e50-a8f7-4725-874f-27a90cae8e86,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-3a264482-4870-4fb8-91dd-933b99bf6b40,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-2fe074c0-cef2-4a44-875c-6bbd7f6dd765,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-3241bd39-2a56-4c9c-9c64-80f4ffc8e752,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-a1a67396-ddc2-4824-b236-b9083a127a7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1652413007-172.17.0.12-1597406234943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39681,DS-2a23884f-f24b-4f7b-9f91-8f2c8df62afa,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-f61dc3cd-a173-47f0-ace9-4be6b7f6f9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-b3293444-1a10-41d8-83f9-cdc16581144b,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-6b652473-8141-4c86-b366-a8fa46cb3605,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-bb18159e-5d93-4851-a4af-6977590f16a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-b337005a-095c-4c44-adb4-1d5a87506b02,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-780f8c96-6f16-49c8-a893-5221bbccbea4,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-dbcff6ad-8e47-43bd-86b6-96670f95e3b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1652413007-172.17.0.12-1597406234943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39681,DS-2a23884f-f24b-4f7b-9f91-8f2c8df62afa,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-f61dc3cd-a173-47f0-ace9-4be6b7f6f9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40892,DS-b3293444-1a10-41d8-83f9-cdc16581144b,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-6b652473-8141-4c86-b366-a8fa46cb3605,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-bb18159e-5d93-4851-a4af-6977590f16a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-b337005a-095c-4c44-adb4-1d5a87506b02,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-780f8c96-6f16-49c8-a893-5221bbccbea4,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-dbcff6ad-8e47-43bd-86b6-96670f95e3b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6822
