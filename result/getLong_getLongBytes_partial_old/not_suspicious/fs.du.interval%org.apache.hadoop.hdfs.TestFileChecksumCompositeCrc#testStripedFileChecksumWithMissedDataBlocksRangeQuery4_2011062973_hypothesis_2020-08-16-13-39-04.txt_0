reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-813990314-172.17.0.7-1597585421262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40213,DS-458a2f68-f302-48c6-85fd-c1ba8059a60e,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-f81ba505-e615-4b96-b011-0c1773b22c72,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-725fff49-2182-46bb-a19b-4a991a629245,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-9719ab5f-ad8b-49a5-9dee-05bce9c63e22,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-59b038c3-93fb-480f-9acb-1bc6e9632298,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-f4fdc0fb-299b-4bc6-b5ca-9692d1cf8858,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-10fcc397-d395-450f-bef3-a5ad48237560,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-d86ae05d-97be-4ecd-9dc7-f97b1585af5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-813990314-172.17.0.7-1597585421262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40213,DS-458a2f68-f302-48c6-85fd-c1ba8059a60e,DISK], DatanodeInfoWithStorage[127.0.0.1:33188,DS-f81ba505-e615-4b96-b011-0c1773b22c72,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-725fff49-2182-46bb-a19b-4a991a629245,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-9719ab5f-ad8b-49a5-9dee-05bce9c63e22,DISK], DatanodeInfoWithStorage[127.0.0.1:35639,DS-59b038c3-93fb-480f-9acb-1bc6e9632298,DISK], DatanodeInfoWithStorage[127.0.0.1:44967,DS-f4fdc0fb-299b-4bc6-b5ca-9692d1cf8858,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-10fcc397-d395-450f-bef3-a5ad48237560,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-d86ae05d-97be-4ecd-9dc7-f97b1585af5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-318249649-172.17.0.7-1597586063879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36511,DS-7a256f20-bf2a-4de1-8858-126d5c8b42bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-222612bd-8344-4c55-bada-f958d85baab0,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-59f4f695-b2da-4197-88e5-7811fa796568,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-d75b7d8c-3c3c-402d-8fe0-253512d8a911,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-bfa24d1b-017b-48ce-aacf-b51ceccb6c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-3648b31a-e6d6-44e5-bb29-92ca2034636d,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-96f8df4d-77c3-4c74-933f-361d5922873c,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-68ca1675-d930-4414-8ab8-a7abb513638b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-318249649-172.17.0.7-1597586063879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36511,DS-7a256f20-bf2a-4de1-8858-126d5c8b42bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39684,DS-222612bd-8344-4c55-bada-f958d85baab0,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-59f4f695-b2da-4197-88e5-7811fa796568,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-d75b7d8c-3c3c-402d-8fe0-253512d8a911,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-bfa24d1b-017b-48ce-aacf-b51ceccb6c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-3648b31a-e6d6-44e5-bb29-92ca2034636d,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-96f8df4d-77c3-4c74-933f-361d5922873c,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-68ca1675-d930-4414-8ab8-a7abb513638b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-481310045-172.17.0.7-1597586923894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43295,DS-72a4e6ec-45d4-4c88-9fec-4dd10289e892,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-272047c5-19a5-48cd-8467-ec49bd9c126b,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-bd4f319d-bb43-49e1-b5ea-83c34b3a2641,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-ccc7e88d-ebaa-4937-8676-d078a1d0fef3,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-841f157c-e98f-4787-897d-0c701667ca76,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-9a23dccd-160d-4585-98b5-274c3065879d,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-749dcd0a-e2a8-4633-8dd6-6f9b1970a5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-e4456a1c-9d0f-4b8f-adb5-fafe3167b00b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-481310045-172.17.0.7-1597586923894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43295,DS-72a4e6ec-45d4-4c88-9fec-4dd10289e892,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-272047c5-19a5-48cd-8467-ec49bd9c126b,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-bd4f319d-bb43-49e1-b5ea-83c34b3a2641,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-ccc7e88d-ebaa-4937-8676-d078a1d0fef3,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-841f157c-e98f-4787-897d-0c701667ca76,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-9a23dccd-160d-4585-98b5-274c3065879d,DISK], DatanodeInfoWithStorage[127.0.0.1:44831,DS-749dcd0a-e2a8-4633-8dd6-6f9b1970a5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-e4456a1c-9d0f-4b8f-adb5-fafe3167b00b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-631531073-172.17.0.7-1597587108562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36189,DS-966ac0e0-f1bd-4e25-80b2-eb25b9f427ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-ebfe763b-ecb1-409d-a964-65b3843b6ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-1e8578bb-7a73-4168-93d2-6dd6f907d14d,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-d8c078ef-ca6e-4c16-9df4-79975f89b976,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-f4c6dfbc-ec34-47ee-8ea6-49c604a05d88,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-c7b5cabc-9053-4802-a739-5e746f7e7666,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-4aa5e8b0-3ca4-4bfa-b896-11f672601f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-480b8a1d-452f-49f0-989c-1f518cfcb3e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-631531073-172.17.0.7-1597587108562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36189,DS-966ac0e0-f1bd-4e25-80b2-eb25b9f427ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-ebfe763b-ecb1-409d-a964-65b3843b6ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-1e8578bb-7a73-4168-93d2-6dd6f907d14d,DISK], DatanodeInfoWithStorage[127.0.0.1:38450,DS-d8c078ef-ca6e-4c16-9df4-79975f89b976,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-f4c6dfbc-ec34-47ee-8ea6-49c604a05d88,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-c7b5cabc-9053-4802-a739-5e746f7e7666,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-4aa5e8b0-3ca4-4bfa-b896-11f672601f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-480b8a1d-452f-49f0-989c-1f518cfcb3e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1904622861-172.17.0.7-1597587989248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41278,DS-c559d0a3-4c32-48f2-a84b-95d7e9662e63,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-e40f1d5c-3825-4df9-aa70-291a9cd5285d,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-e5fdbc9e-1546-43cb-9b4d-21069b6fe3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-3af5b135-42b9-4e92-be57-33145dd8c8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-b3bb75e5-cd4a-4971-b1af-984debcd02bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-97500ed1-f600-4939-9ba3-d71dbae914e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-09dad642-1e71-4341-83a1-fbc92610acf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-222616e3-ea8c-4999-9ba8-98632a66f92a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1904622861-172.17.0.7-1597587989248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41278,DS-c559d0a3-4c32-48f2-a84b-95d7e9662e63,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-e40f1d5c-3825-4df9-aa70-291a9cd5285d,DISK], DatanodeInfoWithStorage[127.0.0.1:33006,DS-e5fdbc9e-1546-43cb-9b4d-21069b6fe3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-3af5b135-42b9-4e92-be57-33145dd8c8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-b3bb75e5-cd4a-4971-b1af-984debcd02bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-97500ed1-f600-4939-9ba3-d71dbae914e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-09dad642-1e71-4341-83a1-fbc92610acf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-222616e3-ea8c-4999-9ba8-98632a66f92a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1552983640-172.17.0.7-1597588043545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35374,DS-1e7063cf-9ce2-47e8-951c-744a9d23f8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-380cabfa-0326-4a6f-831f-dfe7d14765b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-fb0dd3e6-fc1f-496d-9173-8d79a17f0611,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-65fa66e3-2abc-40a2-a4d3-c5b254576a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-e00ccc78-4735-4bf6-be0f-af64c7c25e47,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-1e31f5ba-7601-4121-a3b2-ed7352113bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-8a67fd74-fb95-48a3-b619-1a85144d10bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-fd2f2cff-2b0e-497b-a5dc-15fc888f3e1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1552983640-172.17.0.7-1597588043545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35374,DS-1e7063cf-9ce2-47e8-951c-744a9d23f8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-380cabfa-0326-4a6f-831f-dfe7d14765b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-fb0dd3e6-fc1f-496d-9173-8d79a17f0611,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-65fa66e3-2abc-40a2-a4d3-c5b254576a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-e00ccc78-4735-4bf6-be0f-af64c7c25e47,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-1e31f5ba-7601-4121-a3b2-ed7352113bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-8a67fd74-fb95-48a3-b619-1a85144d10bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-fd2f2cff-2b0e-497b-a5dc-15fc888f3e1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293660292-172.17.0.7-1597588560773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43399,DS-eac95001-c542-4087-b7de-32a9836a5141,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-582b21e7-a0d6-409a-8274-746e6b1b20da,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-997132d7-69c1-4d0a-923a-89823e1db5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-09ce6966-fbb4-4fc3-ac80-ee9920007f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-45b6599f-6dc6-4191-b7ef-dc8d5b209c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-6c100130-180c-4a76-a888-1f83d1f50e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-3c6f7f07-7372-44c6-aab3-51cce84002d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-6a34196a-3c4e-4021-9767-4d077c8d9b0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293660292-172.17.0.7-1597588560773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43399,DS-eac95001-c542-4087-b7de-32a9836a5141,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-582b21e7-a0d6-409a-8274-746e6b1b20da,DISK], DatanodeInfoWithStorage[127.0.0.1:39740,DS-997132d7-69c1-4d0a-923a-89823e1db5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46209,DS-09ce6966-fbb4-4fc3-ac80-ee9920007f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-45b6599f-6dc6-4191-b7ef-dc8d5b209c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44244,DS-6c100130-180c-4a76-a888-1f83d1f50e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-3c6f7f07-7372-44c6-aab3-51cce84002d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-6a34196a-3c4e-4021-9767-4d077c8d9b0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050905849-172.17.0.7-1597589257361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40892,DS-669278c1-22a3-45af-9299-cd90d5753150,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-0fe4ea61-6789-46e2-95d2-c53d9c7ef94a,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-acb520d3-6b9d-44ba-9830-78134dee7c73,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-2e0140bc-c77a-4392-987f-03f7635f88ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-9df2228f-43d2-4b88-b1e3-6498f98ead7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-e13ef732-d665-4606-8fb3-b023b6de22ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-0f32d7bd-f757-4c28-b4e3-c841734d54f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-f63906f5-9aab-4dab-a954-930f06704cf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050905849-172.17.0.7-1597589257361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40892,DS-669278c1-22a3-45af-9299-cd90d5753150,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-0fe4ea61-6789-46e2-95d2-c53d9c7ef94a,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-acb520d3-6b9d-44ba-9830-78134dee7c73,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-2e0140bc-c77a-4392-987f-03f7635f88ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-9df2228f-43d2-4b88-b1e3-6498f98ead7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-e13ef732-d665-4606-8fb3-b023b6de22ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-0f32d7bd-f757-4c28-b4e3-c841734d54f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-f63906f5-9aab-4dab-a954-930f06704cf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999598664-172.17.0.7-1597589659046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37243,DS-33be7d6e-a132-4ae8-b49e-6eedd34bd078,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-633a4532-1f2f-4535-81ba-e11b9245cbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-19fc0705-deae-4a6a-8264-db4d5a2f15db,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-761e36e1-2234-4901-87d0-9287b344f6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-0b10c0e3-e4b1-4293-8bf6-f8b9dd7d38ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-424b720a-d4ed-42a9-bdf9-a86221731989,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-f073a65f-4ca1-4b5a-b3f1-b27923776e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-880b7351-2935-42ac-9a1f-204ea1a4981e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999598664-172.17.0.7-1597589659046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37243,DS-33be7d6e-a132-4ae8-b49e-6eedd34bd078,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-633a4532-1f2f-4535-81ba-e11b9245cbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-19fc0705-deae-4a6a-8264-db4d5a2f15db,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-761e36e1-2234-4901-87d0-9287b344f6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-0b10c0e3-e4b1-4293-8bf6-f8b9dd7d38ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-424b720a-d4ed-42a9-bdf9-a86221731989,DISK], DatanodeInfoWithStorage[127.0.0.1:42122,DS-f073a65f-4ca1-4b5a-b3f1-b27923776e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-880b7351-2935-42ac-9a1f-204ea1a4981e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-136291630-172.17.0.7-1597589944799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38284,DS-a7c10bdd-d3eb-4769-8776-c1b1190084f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-a00bdc61-32a1-429a-8a34-80824b4cecd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-1a98304a-cdf7-4ac9-9cf7-7ffde2843e68,DISK], DatanodeInfoWithStorage[127.0.0.1:34291,DS-cdde1bb4-17a8-4a28-bf64-15efce8b3649,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-f54eebba-8ae9-4449-be67-cc85359b7e08,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-65121c74-c2e2-428c-b70c-d7946c416a77,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-21e7536e-b3a6-40e9-8f4b-f6d20da37bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-d0b56be3-ad20-4957-8094-ef1fbdd1e4fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-136291630-172.17.0.7-1597589944799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38284,DS-a7c10bdd-d3eb-4769-8776-c1b1190084f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-a00bdc61-32a1-429a-8a34-80824b4cecd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-1a98304a-cdf7-4ac9-9cf7-7ffde2843e68,DISK], DatanodeInfoWithStorage[127.0.0.1:34291,DS-cdde1bb4-17a8-4a28-bf64-15efce8b3649,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-f54eebba-8ae9-4449-be67-cc85359b7e08,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-65121c74-c2e2-428c-b70c-d7946c416a77,DISK], DatanodeInfoWithStorage[127.0.0.1:37564,DS-21e7536e-b3a6-40e9-8f4b-f6d20da37bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-d0b56be3-ad20-4957-8094-ef1fbdd1e4fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1580244280-172.17.0.7-1597590035370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40087,DS-aba2afb2-4f08-4aac-9138-d8dd5da0a8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-1ec7a57b-e815-415e-80dc-749af9411df8,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-f4cd8640-30d1-4197-adc5-7c361d1e4fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-2ce6fbe7-1e47-4642-9219-c6bb6ff57418,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-5cdd4869-bdbc-4de1-ba43-99f2de27b5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-8f8f3a9c-2761-409e-ab62-b2618f632bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-5e4cd653-e44f-408c-94dc-97d1f5944be7,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-ca9f7b79-df52-41e6-9b51-f3823a8d28a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1580244280-172.17.0.7-1597590035370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40087,DS-aba2afb2-4f08-4aac-9138-d8dd5da0a8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-1ec7a57b-e815-415e-80dc-749af9411df8,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-f4cd8640-30d1-4197-adc5-7c361d1e4fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-2ce6fbe7-1e47-4642-9219-c6bb6ff57418,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-5cdd4869-bdbc-4de1-ba43-99f2de27b5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-8f8f3a9c-2761-409e-ab62-b2618f632bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-5e4cd653-e44f-408c-94dc-97d1f5944be7,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-ca9f7b79-df52-41e6-9b51-f3823a8d28a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056119965-172.17.0.7-1597590080394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45996,DS-63d3a051-5c92-46e0-8f62-e270d5ef01ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-64e2967d-da5c-4c81-b32a-c0688cec3393,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-fa6bf186-3296-4924-ac72-3d4446576c83,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-2787e070-388c-4098-af4f-b90cd7a4fc52,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-ceb04155-75a6-405c-951d-8ae9b64d0b20,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-b5427639-6d15-4c52-91fc-66faf65d14c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-bf9226de-74ae-4fb9-8b41-94435ec5c4db,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-8dfe2b40-b51d-495a-bbf1-9cdae5bbf4c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056119965-172.17.0.7-1597590080394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45996,DS-63d3a051-5c92-46e0-8f62-e270d5ef01ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-64e2967d-da5c-4c81-b32a-c0688cec3393,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-fa6bf186-3296-4924-ac72-3d4446576c83,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-2787e070-388c-4098-af4f-b90cd7a4fc52,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-ceb04155-75a6-405c-951d-8ae9b64d0b20,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-b5427639-6d15-4c52-91fc-66faf65d14c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-bf9226de-74ae-4fb9-8b41-94435ec5c4db,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-8dfe2b40-b51d-495a-bbf1-9cdae5bbf4c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1409969221-172.17.0.7-1597590407854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45271,DS-7ecc83e0-622c-4bb4-8ce5-afaea92de8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-5a1ce366-dad2-4050-804a-8e2c31edf0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-b3612c10-23e2-4d80-b109-7b9975e4c508,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-3ab053f8-d142-40c2-82a5-796eb0f078ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-9e3cfb7d-6365-4a88-bd40-6730e456600e,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-a36ffbbb-4ae0-49f8-81c0-ef5e34fef325,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-12344959-9e31-4a9a-ac8f-b4927e1c7238,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-d3c7eb20-0574-473b-9e93-b22940b4d797,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1409969221-172.17.0.7-1597590407854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45271,DS-7ecc83e0-622c-4bb4-8ce5-afaea92de8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-5a1ce366-dad2-4050-804a-8e2c31edf0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-b3612c10-23e2-4d80-b109-7b9975e4c508,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-3ab053f8-d142-40c2-82a5-796eb0f078ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-9e3cfb7d-6365-4a88-bd40-6730e456600e,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-a36ffbbb-4ae0-49f8-81c0-ef5e34fef325,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-12344959-9e31-4a9a-ac8f-b4927e1c7238,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-d3c7eb20-0574-473b-9e93-b22940b4d797,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-110801865-172.17.0.7-1597591101787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45951,DS-340102fa-4455-4515-a5da-39c6403b68f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-6123378d-72d6-435d-83e9-0159602108ac,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-13e717df-6924-4237-8669-4a31ae7b0977,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-df2fbf7d-b61b-4d84-a96e-7fec177af8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-4342ae99-4e82-414b-9507-484b7e95434f,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-5e563a39-caf9-4116-998b-42377ff940ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-b59fc5fa-2074-42dc-b176-da869ee58f01,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-e5d4e1ee-ca1d-4b38-81f9-e44a5d1a5915,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-110801865-172.17.0.7-1597591101787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45951,DS-340102fa-4455-4515-a5da-39c6403b68f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-6123378d-72d6-435d-83e9-0159602108ac,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-13e717df-6924-4237-8669-4a31ae7b0977,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-df2fbf7d-b61b-4d84-a96e-7fec177af8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33048,DS-4342ae99-4e82-414b-9507-484b7e95434f,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-5e563a39-caf9-4116-998b-42377ff940ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-b59fc5fa-2074-42dc-b176-da869ee58f01,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-e5d4e1ee-ca1d-4b38-81f9-e44a5d1a5915,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1201592667-172.17.0.7-1597591780879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34675,DS-26ddd2e1-39bc-41a9-a8e0-7cdd35f32e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-d697a20d-ea08-4431-9a28-fdf2eefb47da,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-77e4affc-543a-44e6-94c0-b2b17028a55e,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-656a317a-d34a-48f7-88c9-767e2c1fc955,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-424f8c8f-6afd-448a-8f72-8e91b4044d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-7f096b47-e764-4475-affc-49b65b8ff6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-90940a4c-c707-494a-97e7-ea840a5d5250,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-b1f0dc26-b8da-44b1-ad78-29902f701ca5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1201592667-172.17.0.7-1597591780879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34675,DS-26ddd2e1-39bc-41a9-a8e0-7cdd35f32e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-d697a20d-ea08-4431-9a28-fdf2eefb47da,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-77e4affc-543a-44e6-94c0-b2b17028a55e,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-656a317a-d34a-48f7-88c9-767e2c1fc955,DISK], DatanodeInfoWithStorage[127.0.0.1:43560,DS-424f8c8f-6afd-448a-8f72-8e91b4044d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-7f096b47-e764-4475-affc-49b65b8ff6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-90940a4c-c707-494a-97e7-ea840a5d5250,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-b1f0dc26-b8da-44b1-ad78-29902f701ca5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1161264500-172.17.0.7-1597592090378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45508,DS-407cc78b-1e39-494d-9bfa-615dc21248e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-65303dc4-51c1-4566-a7a0-1062a4d60b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-3a4ab82c-4da9-4903-8ce8-6266f92a46dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-ae461901-773c-4401-869d-0bd860667e44,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-eb4642f8-7350-408a-bd37-dd7f10661fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-e5fb9b58-39c4-4107-b082-221c2aa5917a,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-1284caa0-3c94-44bb-a7e9-bdb82ccf5b44,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-f0ff8716-bb21-46d4-ad89-abfea2e19708,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1161264500-172.17.0.7-1597592090378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45508,DS-407cc78b-1e39-494d-9bfa-615dc21248e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-65303dc4-51c1-4566-a7a0-1062a4d60b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-3a4ab82c-4da9-4903-8ce8-6266f92a46dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-ae461901-773c-4401-869d-0bd860667e44,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-eb4642f8-7350-408a-bd37-dd7f10661fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-e5fb9b58-39c4-4107-b082-221c2aa5917a,DISK], DatanodeInfoWithStorage[127.0.0.1:42686,DS-1284caa0-3c94-44bb-a7e9-bdb82ccf5b44,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-f0ff8716-bb21-46d4-ad89-abfea2e19708,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 7216
