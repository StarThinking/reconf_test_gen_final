reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 16384
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 16384
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693682884-172.17.0.2-1597538857186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40832,DS-7a7884aa-eb9a-4f4e-8255-36994dbeb01d,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-31022fad-1eab-4662-a2cf-1deaf757d86e,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-dcdaee6f-affe-47c9-bbe0-0d40effc5091,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-50aff6a4-569e-486b-bcb0-f7c3a86264f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-802adb9d-7bfe-4b18-81f8-40ad4853954b,DISK], DatanodeInfoWithStorage[127.0.0.1:46025,DS-de6bbdf4-15c8-413c-8dca-4fb340197bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-5452b7fd-4f12-42a0-ac0a-6ea500d18968,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-ce16d119-8e62-4321-989e-647b5593b828,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693682884-172.17.0.2-1597538857186:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40832,DS-7a7884aa-eb9a-4f4e-8255-36994dbeb01d,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-31022fad-1eab-4662-a2cf-1deaf757d86e,DISK], DatanodeInfoWithStorage[127.0.0.1:35281,DS-dcdaee6f-affe-47c9-bbe0-0d40effc5091,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-50aff6a4-569e-486b-bcb0-f7c3a86264f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-802adb9d-7bfe-4b18-81f8-40ad4853954b,DISK], DatanodeInfoWithStorage[127.0.0.1:46025,DS-de6bbdf4-15c8-413c-8dca-4fb340197bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-5452b7fd-4f12-42a0-ac0a-6ea500d18968,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-ce16d119-8e62-4321-989e-647b5593b828,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 16384
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1322417974-172.17.0.2-1597539201424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41520,DS-267153fa-f51f-474e-8af9-d3393a2dd3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-c7900570-47c4-41b8-968e-c6a9f9f0fe7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-9af927cb-db66-4e78-bdc9-e7318d025b79,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-22de90d8-f40a-46cc-a81d-4451e83063fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-44faf581-df02-4db0-b17d-ef2a9bab9e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-d9eccbaa-5da7-4f39-87b3-d3676f242cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-81bb387d-3a0e-49de-bd71-24ec9e264441,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-38503e60-6308-49f1-b2fc-2e87d4069074,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1322417974-172.17.0.2-1597539201424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41520,DS-267153fa-f51f-474e-8af9-d3393a2dd3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-c7900570-47c4-41b8-968e-c6a9f9f0fe7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-9af927cb-db66-4e78-bdc9-e7318d025b79,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-22de90d8-f40a-46cc-a81d-4451e83063fc,DISK], DatanodeInfoWithStorage[127.0.0.1:32781,DS-44faf581-df02-4db0-b17d-ef2a9bab9e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-d9eccbaa-5da7-4f39-87b3-d3676f242cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-81bb387d-3a0e-49de-bd71-24ec9e264441,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-38503e60-6308-49f1-b2fc-2e87d4069074,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 16384
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-538165156-172.17.0.2-1597540699980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39382,DS-454984a6-1e93-447b-9a63-77a1c23f1e18,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-5fd295c4-1748-4f4b-b678-75297a837345,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-3e93e801-955c-401d-9005-f87ed988aa8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-56db0096-859a-447f-82c3-3e586961ea03,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-4040646a-ecf3-4b44-a31b-5e976fa1e5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-0b826740-8e08-4a01-8818-93e9ad9f8f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-fff3503b-e63a-4f89-8a76-9a259c341c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-c931ce66-a088-4766-8ad6-b7d956100c06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-538165156-172.17.0.2-1597540699980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39382,DS-454984a6-1e93-447b-9a63-77a1c23f1e18,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-5fd295c4-1748-4f4b-b678-75297a837345,DISK], DatanodeInfoWithStorage[127.0.0.1:43470,DS-3e93e801-955c-401d-9005-f87ed988aa8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-56db0096-859a-447f-82c3-3e586961ea03,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-4040646a-ecf3-4b44-a31b-5e976fa1e5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-0b826740-8e08-4a01-8818-93e9ad9f8f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-fff3503b-e63a-4f89-8a76-9a259c341c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39364,DS-c931ce66-a088-4766-8ad6-b7d956100c06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 16384
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1948710000-172.17.0.2-1597540854579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39928,DS-7ea47d78-69bf-49bf-806f-d014ee04a747,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-10cf5aed-28ce-4a84-b866-1c2f7881b08e,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-35536cc3-c9fe-4b89-9b25-7a7bd1bb9e61,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-90d1aaaf-f194-4bc0-9dd4-6894b28c8801,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-87ea2cbb-f2ce-4056-b370-123d03569647,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-dabd266f-a361-4a59-8501-a4de4c6d5231,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-d011e668-8c25-41c2-898c-c06265800aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-ca06b65b-594f-4e8c-9bd8-63d1f20e8d19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1948710000-172.17.0.2-1597540854579:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39928,DS-7ea47d78-69bf-49bf-806f-d014ee04a747,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-10cf5aed-28ce-4a84-b866-1c2f7881b08e,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-35536cc3-c9fe-4b89-9b25-7a7bd1bb9e61,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-90d1aaaf-f194-4bc0-9dd4-6894b28c8801,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-87ea2cbb-f2ce-4056-b370-123d03569647,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-dabd266f-a361-4a59-8501-a4de4c6d5231,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-d011e668-8c25-41c2-898c-c06265800aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-ca06b65b-594f-4e8c-9bd8-63d1f20e8d19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 16384
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-120217264-172.17.0.2-1597541286706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32803,DS-fa1450f2-be4b-4b75-9349-525aa4ed35bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-e7672310-bcc6-42cf-b930-9754de0f1d18,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-5dc542c2-f4a9-451a-aa22-03d9fd634c49,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-fdb16a2e-fbc3-4c3f-9c7b-2494d88aee8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-bc8dd526-cc75-4e6a-93b7-b2125fac7ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-3836a3bc-c44b-48a1-a4db-9010ac4dd41e,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-309c4464-e42b-4962-946d-6d04e7774481,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-f6a11791-788a-40cd-a75d-00fba4d10d49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-120217264-172.17.0.2-1597541286706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32803,DS-fa1450f2-be4b-4b75-9349-525aa4ed35bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-e7672310-bcc6-42cf-b930-9754de0f1d18,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-5dc542c2-f4a9-451a-aa22-03d9fd634c49,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-fdb16a2e-fbc3-4c3f-9c7b-2494d88aee8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-bc8dd526-cc75-4e6a-93b7-b2125fac7ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:35366,DS-3836a3bc-c44b-48a1-a4db-9010ac4dd41e,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-309c4464-e42b-4962-946d-6d04e7774481,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-f6a11791-788a-40cd-a75d-00fba4d10d49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 16384
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2105021663-172.17.0.2-1597541514974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37471,DS-0126a8d3-8fe3-4c13-9cda-4e8342349306,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-8c99f386-bcee-42b1-9e82-cc0b918d8baa,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-db95c87d-499e-43d6-a165-5cb10cc3512b,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-0868a915-6cca-4c5d-bbe6-2a883ed11ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-e7816aeb-3146-4e13-92a3-c791d67a13e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-cde4f282-e0b6-495b-96d2-5a496917da8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-cbda28de-3140-40b4-b86c-c690c61ad391,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-21e29296-2fda-4be8-92b8-f94a188818ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2105021663-172.17.0.2-1597541514974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37471,DS-0126a8d3-8fe3-4c13-9cda-4e8342349306,DISK], DatanodeInfoWithStorage[127.0.0.1:36530,DS-8c99f386-bcee-42b1-9e82-cc0b918d8baa,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-db95c87d-499e-43d6-a165-5cb10cc3512b,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-0868a915-6cca-4c5d-bbe6-2a883ed11ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-e7816aeb-3146-4e13-92a3-c791d67a13e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-cde4f282-e0b6-495b-96d2-5a496917da8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-cbda28de-3140-40b4-b86c-c690c61ad391,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-21e29296-2fda-4be8-92b8-f94a188818ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 16384
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-639993372-172.17.0.2-1597541837149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40773,DS-7d5fab37-8cc5-4034-a664-f0d93216178c,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-c2c57700-9bfa-4e93-9ced-07c40fdf330d,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-25d12334-c9ee-430c-8b0a-64811c13c6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-e384f24b-d6d2-4f9f-84a9-57108b36aed9,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-eb6cd0e8-248d-47f1-aa4e-cce404c56d78,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-22ecc70c-f6f0-428d-a643-cdeff982dfdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-6c152b97-4aa2-46b5-a346-20f068261be6,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-e40044dd-cf82-4864-aa31-02d0270bdbd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-639993372-172.17.0.2-1597541837149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40773,DS-7d5fab37-8cc5-4034-a664-f0d93216178c,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-c2c57700-9bfa-4e93-9ced-07c40fdf330d,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-25d12334-c9ee-430c-8b0a-64811c13c6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-e384f24b-d6d2-4f9f-84a9-57108b36aed9,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-eb6cd0e8-248d-47f1-aa4e-cce404c56d78,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-22ecc70c-f6f0-428d-a643-cdeff982dfdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-6c152b97-4aa2-46b5-a346-20f068261be6,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-e40044dd-cf82-4864-aa31-02d0270bdbd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 16384
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1362188524-172.17.0.2-1597541993287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37852,DS-28a7ed3b-40e0-43a1-b20d-2c7f340dc3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-12223cbe-b31b-4560-b044-6361fefde450,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-64a42719-1e57-4f5a-9aa0-b53fa6c4d09b,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-91b9d03f-f305-4c01-827f-46d9b9793f82,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-06fc28df-3ebf-414f-9c89-090267e3236e,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-451bb46f-0417-4a73-8e97-570e660f22c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-72c459d8-9032-454c-9b17-e6dafb73ddff,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-f99ad480-9872-4634-9382-90e4f851f486,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1362188524-172.17.0.2-1597541993287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37852,DS-28a7ed3b-40e0-43a1-b20d-2c7f340dc3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-12223cbe-b31b-4560-b044-6361fefde450,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-64a42719-1e57-4f5a-9aa0-b53fa6c4d09b,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-91b9d03f-f305-4c01-827f-46d9b9793f82,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-06fc28df-3ebf-414f-9c89-090267e3236e,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-451bb46f-0417-4a73-8e97-570e660f22c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-72c459d8-9032-454c-9b17-e6dafb73ddff,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-f99ad480-9872-4634-9382-90e4f851f486,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 16384
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-862485483-172.17.0.2-1597542459122:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38342,DS-3e885f0f-2817-491c-a838-27a4f32da254,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-8d2a704e-5949-4485-a029-e4abb0660de6,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-e095a1dc-462e-4979-a019-fc0a7ccf445c,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-a9d4b124-3d66-4838-855e-bfa15b177ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-eeac74f9-f8d6-403b-af29-ce705c408c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-252ef436-72f9-4a5a-a825-f728b36a3ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-2e1585ba-b242-4958-9d13-8a2defd7acd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-71830e89-f700-4cf8-9e13-a5bf9af8ae6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-862485483-172.17.0.2-1597542459122:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38342,DS-3e885f0f-2817-491c-a838-27a4f32da254,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-8d2a704e-5949-4485-a029-e4abb0660de6,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-e095a1dc-462e-4979-a019-fc0a7ccf445c,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-a9d4b124-3d66-4838-855e-bfa15b177ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-eeac74f9-f8d6-403b-af29-ce705c408c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-252ef436-72f9-4a5a-a825-f728b36a3ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-2e1585ba-b242-4958-9d13-8a2defd7acd7,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-71830e89-f700-4cf8-9e13-a5bf9af8ae6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 16384
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-444228565-172.17.0.2-1597542534630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40234,DS-2198951b-bc33-429e-83f9-9e646d7f2bef,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-cf0ff4fb-6b31-4a3f-9aab-1a03c3ca28b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-43b07a61-204f-4b7b-baf1-438ba4796216,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-4701bff6-3d2f-4503-83cb-86125d4109b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-24233212-de92-49d4-a74a-54721319c28a,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-1bfb65f6-7ed2-414d-a48a-140d7a0f23d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-c6c7e35d-ac8c-4824-9241-b8166bf2c6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-db7481d4-1ed7-400c-8470-5b573f7b03fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-444228565-172.17.0.2-1597542534630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40234,DS-2198951b-bc33-429e-83f9-9e646d7f2bef,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-cf0ff4fb-6b31-4a3f-9aab-1a03c3ca28b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-43b07a61-204f-4b7b-baf1-438ba4796216,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-4701bff6-3d2f-4503-83cb-86125d4109b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-24233212-de92-49d4-a74a-54721319c28a,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-1bfb65f6-7ed2-414d-a48a-140d7a0f23d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-c6c7e35d-ac8c-4824-9241-b8166bf2c6a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-db7481d4-1ed7-400c-8470-5b573f7b03fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 16384
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1348960949-172.17.0.2-1597542832593:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41580,DS-186648ce-ff50-4619-a5eb-b2a3ed26b473,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-b73f350c-205a-4f90-b8ad-c95dfd46363a,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-269b464c-4331-459f-b52f-1f955aec28a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-9dc11cf7-9d0b-4eff-9755-364ea434da64,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-29fd7f2d-52ea-4ad5-815c-9007d422c60d,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-f17ad26f-f1d6-4728-9c35-32de54728975,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-3597098f-7066-4b65-9af0-9439c5a2f981,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-54f9004b-8c8d-4eac-b579-ccd4a0fabeb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1348960949-172.17.0.2-1597542832593:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41580,DS-186648ce-ff50-4619-a5eb-b2a3ed26b473,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-b73f350c-205a-4f90-b8ad-c95dfd46363a,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-269b464c-4331-459f-b52f-1f955aec28a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-9dc11cf7-9d0b-4eff-9755-364ea434da64,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-29fd7f2d-52ea-4ad5-815c-9007d422c60d,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-f17ad26f-f1d6-4728-9c35-32de54728975,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-3597098f-7066-4b65-9af0-9439c5a2f981,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-54f9004b-8c8d-4eac-b579-ccd4a0fabeb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 16384
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-53363921-172.17.0.2-1597542905814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39378,DS-ef886afb-8740-435d-a4c4-fd66065665f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-23301061-035e-45ab-a9a1-678363db2098,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-1518a3ac-c6ab-4ab1-b71f-c35eac1a21c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-2dab42b1-042f-4b4d-83ac-09a2ac6c7b72,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-d0e35730-ac7c-42b9-acc5-4fc53a10bba3,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-10179ef2-28d9-4f7f-b1cd-03ee9d047727,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-9e6bc073-41d2-4789-b8c2-30fca2d7952f,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-011335fe-aaea-4959-ba22-812302ee580f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-53363921-172.17.0.2-1597542905814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39378,DS-ef886afb-8740-435d-a4c4-fd66065665f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-23301061-035e-45ab-a9a1-678363db2098,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-1518a3ac-c6ab-4ab1-b71f-c35eac1a21c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-2dab42b1-042f-4b4d-83ac-09a2ac6c7b72,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-d0e35730-ac7c-42b9-acc5-4fc53a10bba3,DISK], DatanodeInfoWithStorage[127.0.0.1:42017,DS-10179ef2-28d9-4f7f-b1cd-03ee9d047727,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-9e6bc073-41d2-4789-b8c2-30fca2d7952f,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-011335fe-aaea-4959-ba22-812302ee580f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 16384
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-304681061-172.17.0.2-1597543218372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36332,DS-52d77b22-d7b8-4bb3-bc57-e04de9101223,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-7311c796-a117-4af3-90a3-78ffc5564211,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-c8e50a87-2f3f-49e7-8dfc-34512a685f65,DISK], DatanodeInfoWithStorage[127.0.0.1:40851,DS-a67b6a73-18eb-4bf4-9fe7-0e1ab9538e17,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-ad3710a5-79c5-4c5c-bce0-1b487a2ddc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-ebb84ab0-6c7b-448d-a203-d787166ed53d,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-aa0ca7c5-2241-4277-b1eb-c96f07f7d3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-212e7008-add9-4914-85bc-79e398e4bf9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-304681061-172.17.0.2-1597543218372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36332,DS-52d77b22-d7b8-4bb3-bc57-e04de9101223,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-7311c796-a117-4af3-90a3-78ffc5564211,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-c8e50a87-2f3f-49e7-8dfc-34512a685f65,DISK], DatanodeInfoWithStorage[127.0.0.1:40851,DS-a67b6a73-18eb-4bf4-9fe7-0e1ab9538e17,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-ad3710a5-79c5-4c5c-bce0-1b487a2ddc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-ebb84ab0-6c7b-448d-a203-d787166ed53d,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-aa0ca7c5-2241-4277-b1eb-c96f07f7d3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-212e7008-add9-4914-85bc-79e398e4bf9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 16384
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1288732773-172.17.0.2-1597543549559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35507,DS-9be8829e-6440-484a-9143-f4089da9af21,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-c82afea6-3d9d-4ad7-a07d-5f9385209d36,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-0f0e440b-02b9-4c47-a80c-434e12b244fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-e7a0577a-1521-42c2-90ef-1248c293e56f,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-57ac9228-6981-4847-8b44-d6674b2046fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-030f4e5d-b45e-48d2-964d-fc027c4b7647,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-43a2e9b3-1353-4680-a032-eeda97cff44f,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-1730bc15-1187-4f94-9539-56ca4238dbf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1288732773-172.17.0.2-1597543549559:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35507,DS-9be8829e-6440-484a-9143-f4089da9af21,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-c82afea6-3d9d-4ad7-a07d-5f9385209d36,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-0f0e440b-02b9-4c47-a80c-434e12b244fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-e7a0577a-1521-42c2-90ef-1248c293e56f,DISK], DatanodeInfoWithStorage[127.0.0.1:34421,DS-57ac9228-6981-4847-8b44-d6674b2046fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-030f4e5d-b45e-48d2-964d-fc027c4b7647,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-43a2e9b3-1353-4680-a032-eeda97cff44f,DISK], DatanodeInfoWithStorage[127.0.0.1:46223,DS-1730bc15-1187-4f94-9539-56ca4238dbf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.prefetch.size
component: hdfs:NameNode
v1: 16384
v2: 62914560
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-424216064-172.17.0.2-1597544096986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43038,DS-1bfaf4a8-7723-41c1-bf8e-218142fa5278,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-fd37ee3a-44e8-4666-b853-3c85132e857d,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-92f97f0b-3675-4c93-95a7-c82e61f6ee2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-7ab53d03-678a-4c96-9fb8-4d16f2bbaa12,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-24178298-1ced-4e53-8ced-8c92d3974913,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-a53e6f05-ee6a-4eae-86d2-c3505fec7a10,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-0f8a9ce7-e2b3-4f17-a328-48b2b8ec4111,DISK], DatanodeInfoWithStorage[127.0.0.1:37239,DS-103c971f-6ba5-48de-aedd-42c6e3e64e0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-424216064-172.17.0.2-1597544096986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43038,DS-1bfaf4a8-7723-41c1-bf8e-218142fa5278,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-fd37ee3a-44e8-4666-b853-3c85132e857d,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-92f97f0b-3675-4c93-95a7-c82e61f6ee2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-7ab53d03-678a-4c96-9fb8-4d16f2bbaa12,DISK], DatanodeInfoWithStorage[127.0.0.1:37371,DS-24178298-1ced-4e53-8ced-8c92d3974913,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-a53e6f05-ee6a-4eae-86d2-c3505fec7a10,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-0f8a9ce7-e2b3-4f17-a328-48b2b8ec4111,DISK], DatanodeInfoWithStorage[127.0.0.1:37239,DS-103c971f-6ba5-48de-aedd-42c6e3e64e0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5399
