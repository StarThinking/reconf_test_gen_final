reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421840159-172.17.0.10-1597317857470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39001,DS-230ded17-d2e5-4c31-814c-500ef08f4981,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-bab68be8-a95c-4c7d-99f8-42648a46ffa9,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-3e9eafa4-32a9-4ed2-8e93-4d2e28889302,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-bae1337f-9f1b-49ab-a332-a4ec0932c368,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-5ff9d2ae-f475-41cb-a430-3c4f690dc5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-064579f4-91cc-4444-af7b-d05497c83e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-abe970a3-1992-4c7e-af33-5de2882cc01f,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-b3ceb3ce-dbe2-4878-81c4-2d242f61e00c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421840159-172.17.0.10-1597317857470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39001,DS-230ded17-d2e5-4c31-814c-500ef08f4981,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-bab68be8-a95c-4c7d-99f8-42648a46ffa9,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-3e9eafa4-32a9-4ed2-8e93-4d2e28889302,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-bae1337f-9f1b-49ab-a332-a4ec0932c368,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-5ff9d2ae-f475-41cb-a430-3c4f690dc5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-064579f4-91cc-4444-af7b-d05497c83e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-abe970a3-1992-4c7e-af33-5de2882cc01f,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-b3ceb3ce-dbe2-4878-81c4-2d242f61e00c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509441285-172.17.0.10-1597318447615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45195,DS-629ed21d-28be-44be-a3e6-13304fc9514a,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-62cd83e4-82e6-41c5-8050-8aaf0f60184c,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-54ea9335-f26d-499c-a995-718c3ddac682,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-db5b718b-15a7-4a8a-8933-67e0c2003ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-7ec6bede-b559-4a08-ba0b-8cefd2fd9cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-65f051ac-6c2e-470a-9f90-88585513e2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-c932aa4f-d4d5-4c28-8a93-267bbe6a7174,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-b331b75d-39ff-476a-9ab8-3cec770062e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509441285-172.17.0.10-1597318447615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45195,DS-629ed21d-28be-44be-a3e6-13304fc9514a,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-62cd83e4-82e6-41c5-8050-8aaf0f60184c,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-54ea9335-f26d-499c-a995-718c3ddac682,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-db5b718b-15a7-4a8a-8933-67e0c2003ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-7ec6bede-b559-4a08-ba0b-8cefd2fd9cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-65f051ac-6c2e-470a-9f90-88585513e2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-c932aa4f-d4d5-4c28-8a93-267bbe6a7174,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-b331b75d-39ff-476a-9ab8-3cec770062e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-818388183-172.17.0.10-1597318786912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41537,DS-56827cfa-185a-4e7c-9daf-68880e04ac33,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-19d7166b-c3f4-49c3-9bbb-c29092e5d51f,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-35e282df-b744-482f-9475-158172ec7f71,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-74831b80-efa0-43cf-896d-4bd2a21e37a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-a6a65771-b400-4357-9dfb-397a754496b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-251f430f-1b32-4b40-a83a-6ca0c67b79b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-b03a8a9f-724e-4a68-89d0-2b21bc025781,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-ed77603e-a11c-493b-90e4-e8f76ea68e6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-818388183-172.17.0.10-1597318786912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41537,DS-56827cfa-185a-4e7c-9daf-68880e04ac33,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-19d7166b-c3f4-49c3-9bbb-c29092e5d51f,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-35e282df-b744-482f-9475-158172ec7f71,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-74831b80-efa0-43cf-896d-4bd2a21e37a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-a6a65771-b400-4357-9dfb-397a754496b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-251f430f-1b32-4b40-a83a-6ca0c67b79b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-b03a8a9f-724e-4a68-89d0-2b21bc025781,DISK], DatanodeInfoWithStorage[127.0.0.1:43678,DS-ed77603e-a11c-493b-90e4-e8f76ea68e6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1838428688-172.17.0.10-1597319256443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33253,DS-c3a4046b-709b-471c-845c-708b20542926,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-bb45f3dc-952d-4968-bcf7-bb9a62cefa34,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-98002dc3-82c5-43d9-ade3-982ed5cff7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-1de353b5-6d1a-4592-9fa8-f91718239f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-68192fcb-979a-483c-903e-b1fb38a0f520,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-21a9f5ed-c000-49d2-9fe7-430fcf0d2fca,DISK], DatanodeInfoWithStorage[127.0.0.1:41780,DS-70c16104-a011-4d7d-923e-30a0d3e493c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-7b09ebbb-6b8a-43c7-9088-7977501842ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1838428688-172.17.0.10-1597319256443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33253,DS-c3a4046b-709b-471c-845c-708b20542926,DISK], DatanodeInfoWithStorage[127.0.0.1:38848,DS-bb45f3dc-952d-4968-bcf7-bb9a62cefa34,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-98002dc3-82c5-43d9-ade3-982ed5cff7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-1de353b5-6d1a-4592-9fa8-f91718239f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-68192fcb-979a-483c-903e-b1fb38a0f520,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-21a9f5ed-c000-49d2-9fe7-430fcf0d2fca,DISK], DatanodeInfoWithStorage[127.0.0.1:41780,DS-70c16104-a011-4d7d-923e-30a0d3e493c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-7b09ebbb-6b8a-43c7-9088-7977501842ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-783221223-172.17.0.10-1597319854256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40119,DS-39acf693-767f-4ffd-9b11-9f3f000101f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-36e85ae2-6264-4845-8961-df018e1e7e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-07248bf1-e6c1-4ad0-936a-8d22b49e3156,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-f736aca0-6ad3-4632-bad4-7fc4467baea9,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-2a117aec-a3dc-40a2-aca6-21a05c4a79f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-8b6d3ca4-0ffc-47ab-9604-e5ffbb108034,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-e96e934c-3cc8-42d7-83ad-4fc190dc98cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-1bdd49fc-2be0-495a-ae5c-7db1c4caf5cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-783221223-172.17.0.10-1597319854256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40119,DS-39acf693-767f-4ffd-9b11-9f3f000101f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-36e85ae2-6264-4845-8961-df018e1e7e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-07248bf1-e6c1-4ad0-936a-8d22b49e3156,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-f736aca0-6ad3-4632-bad4-7fc4467baea9,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-2a117aec-a3dc-40a2-aca6-21a05c4a79f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46018,DS-8b6d3ca4-0ffc-47ab-9604-e5ffbb108034,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-e96e934c-3cc8-42d7-83ad-4fc190dc98cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42533,DS-1bdd49fc-2be0-495a-ae5c-7db1c4caf5cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982940990-172.17.0.10-1597320088785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40046,DS-59438653-541c-4015-8b11-aa61541c9a23,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-27e58ed1-a971-4a86-a36f-477515a90e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-bf1e7eb5-1d1d-4c07-9501-5f253e6ac5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-26f3d58d-3aec-4b7c-88d5-74e972880fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-6e24f340-235a-4753-a087-8ccbf9aa62b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-98e96ede-a807-4ed5-8a7a-04ec8a64f6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-15e989a5-38f0-4dbb-b938-0fc2b9f02fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-f9b2dea7-7df4-4155-a072-9822c84edeea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982940990-172.17.0.10-1597320088785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40046,DS-59438653-541c-4015-8b11-aa61541c9a23,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-27e58ed1-a971-4a86-a36f-477515a90e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-bf1e7eb5-1d1d-4c07-9501-5f253e6ac5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-26f3d58d-3aec-4b7c-88d5-74e972880fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-6e24f340-235a-4753-a087-8ccbf9aa62b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38711,DS-98e96ede-a807-4ed5-8a7a-04ec8a64f6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-15e989a5-38f0-4dbb-b938-0fc2b9f02fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-f9b2dea7-7df4-4155-a072-9822c84edeea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969983547-172.17.0.10-1597320169370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35786,DS-8c9b6ddb-1b8f-4eed-8b96-05698f3807d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-bc80cbb0-1e94-4bf8-8d9e-b03a300a61cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-e53f5cc6-3dd7-431d-8923-67947bce1ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-2d914552-d63d-4fb8-978b-cf3a8afa0db4,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-5e6260ba-dd7f-427a-9a62-de5cd0f3a079,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-cc9f6720-50f1-497a-89bc-60020891c31b,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-beb0b3ae-8958-45f6-b0a7-908aba8e35c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-27403210-0eeb-4c8c-8e4a-999ac7cebda0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-969983547-172.17.0.10-1597320169370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35786,DS-8c9b6ddb-1b8f-4eed-8b96-05698f3807d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-bc80cbb0-1e94-4bf8-8d9e-b03a300a61cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-e53f5cc6-3dd7-431d-8923-67947bce1ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-2d914552-d63d-4fb8-978b-cf3a8afa0db4,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-5e6260ba-dd7f-427a-9a62-de5cd0f3a079,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-cc9f6720-50f1-497a-89bc-60020891c31b,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-beb0b3ae-8958-45f6-b0a7-908aba8e35c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-27403210-0eeb-4c8c-8e4a-999ac7cebda0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369449404-172.17.0.10-1597320497379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45367,DS-25ae59a8-1d59-4a40-bfe0-4a7c705fb85d,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-02389bb9-65b1-4607-8101-860556b79657,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-46b6c5d8-2ecf-4e3a-aba8-14d426bc41b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-75c21a9a-7334-4bd4-b3b7-28631f5cc40e,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-578c595a-389b-4df2-a68b-c18ca81434ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45415,DS-8f332564-fbb6-41b5-be89-8231d8d1c96b,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-e1f3cf31-c712-45a6-894f-e79d9192c941,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-c2b691c2-ace6-491c-ad82-11ad8ca4c151,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369449404-172.17.0.10-1597320497379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45367,DS-25ae59a8-1d59-4a40-bfe0-4a7c705fb85d,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-02389bb9-65b1-4607-8101-860556b79657,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-46b6c5d8-2ecf-4e3a-aba8-14d426bc41b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-75c21a9a-7334-4bd4-b3b7-28631f5cc40e,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-578c595a-389b-4df2-a68b-c18ca81434ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45415,DS-8f332564-fbb6-41b5-be89-8231d8d1c96b,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-e1f3cf31-c712-45a6-894f-e79d9192c941,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-c2b691c2-ace6-491c-ad82-11ad8ca4c151,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542380070-172.17.0.10-1597321158048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33629,DS-ff5546cf-089a-4a36-b050-583eb10d974b,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-372100b2-fe5e-4163-9c55-97e2dfd69b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-495b1987-34c8-4f9a-82b6-56da94a16981,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-8457e028-1e7c-412c-88c4-3b1f62b70d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-a1adebc0-be08-4bb5-8969-a57315f545d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-e79577af-77bc-46a9-9580-ac1a826235bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-d85637b0-c40e-490d-92fb-00a34ffc327c,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-c5246f6d-cb93-4257-b939-97d1ca2e666c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542380070-172.17.0.10-1597321158048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33629,DS-ff5546cf-089a-4a36-b050-583eb10d974b,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-372100b2-fe5e-4163-9c55-97e2dfd69b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-495b1987-34c8-4f9a-82b6-56da94a16981,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-8457e028-1e7c-412c-88c4-3b1f62b70d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-a1adebc0-be08-4bb5-8969-a57315f545d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-e79577af-77bc-46a9-9580-ac1a826235bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-d85637b0-c40e-490d-92fb-00a34ffc327c,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-c5246f6d-cb93-4257-b939-97d1ca2e666c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2072581283-172.17.0.10-1597321396400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37403,DS-814a9289-f134-485c-bcb8-0e198816cc12,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-1382886c-32ad-462a-a748-1d0684f116ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-3bad38e5-c97e-4028-a21b-24bcad370073,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-ee1b1ff2-dd2f-445f-b0ba-75aecc16fa8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-cf5d25d7-7319-4565-9d0d-ca351edf0f97,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-9baf4595-6552-4254-8a44-cd15454393ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-3e7437e3-7bcc-4ceb-b707-7a8ae2fb48c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-6d678a57-4888-47c8-8a91-5fd4e24de5e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2072581283-172.17.0.10-1597321396400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37403,DS-814a9289-f134-485c-bcb8-0e198816cc12,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-1382886c-32ad-462a-a748-1d0684f116ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-3bad38e5-c97e-4028-a21b-24bcad370073,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-ee1b1ff2-dd2f-445f-b0ba-75aecc16fa8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37755,DS-cf5d25d7-7319-4565-9d0d-ca351edf0f97,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-9baf4595-6552-4254-8a44-cd15454393ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-3e7437e3-7bcc-4ceb-b707-7a8ae2fb48c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-6d678a57-4888-47c8-8a91-5fd4e24de5e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-7540165-172.17.0.10-1597321544728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43049,DS-1dea43b0-a206-407f-b229-b639cdd18d10,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-dd8bcc63-73a7-490e-a0f6-ffd769377c67,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-63f94328-dad2-405c-a80a-3074ee1e1bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-2641c1ea-4585-492c-956d-89a7e9acb91a,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-5eb021d9-a011-418a-ab22-6f6498e9c2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-fef80e41-3c14-49f8-b299-d3545a1e145e,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-0beeb684-3e31-432c-8c2d-cec1611fb517,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-c7843498-0094-4380-a3e9-f338c44f180b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-7540165-172.17.0.10-1597321544728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43049,DS-1dea43b0-a206-407f-b229-b639cdd18d10,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-dd8bcc63-73a7-490e-a0f6-ffd769377c67,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-63f94328-dad2-405c-a80a-3074ee1e1bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-2641c1ea-4585-492c-956d-89a7e9acb91a,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-5eb021d9-a011-418a-ab22-6f6498e9c2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-fef80e41-3c14-49f8-b299-d3545a1e145e,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-0beeb684-3e31-432c-8c2d-cec1611fb517,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-c7843498-0094-4380-a3e9-f338c44f180b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2039602013-172.17.0.10-1597321663127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38502,DS-52318342-1b2d-4635-9b2a-b15416f4b817,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-e2933579-0403-4397-9923-69dce429c2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-ef807bf7-87d0-45d1-af1d-5ea848b9bf27,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-d623b2cb-02ed-4593-8bf2-a757b5dee919,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-e2ff9642-c582-4c2c-8d70-b93d704d695f,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-c6df8b6d-1b7e-481e-be4f-92f47af76bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37390,DS-398f7c08-5f4d-4b67-ab12-0c66baa94e77,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-892d061e-7e5a-41e3-939b-ba95b429dc03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2039602013-172.17.0.10-1597321663127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38502,DS-52318342-1b2d-4635-9b2a-b15416f4b817,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-e2933579-0403-4397-9923-69dce429c2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-ef807bf7-87d0-45d1-af1d-5ea848b9bf27,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-d623b2cb-02ed-4593-8bf2-a757b5dee919,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-e2ff9642-c582-4c2c-8d70-b93d704d695f,DISK], DatanodeInfoWithStorage[127.0.0.1:38459,DS-c6df8b6d-1b7e-481e-be4f-92f47af76bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37390,DS-398f7c08-5f4d-4b67-ab12-0c66baa94e77,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-892d061e-7e5a-41e3-939b-ba95b429dc03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-979076820-172.17.0.10-1597322219635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35691,DS-32df74ed-f101-4ac4-a9e3-d2cc81b5f572,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-bdb038b1-4fb5-4fdf-833e-2202cc2817da,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-ab4a4c17-f7ea-4512-83a8-f5b036fe9dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-d3fa9105-cf56-491d-965e-c2f163cc9a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-e4f8543f-478f-4adf-9cec-6f3b4559a501,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-e3aa6392-a6c6-4474-a75e-1a387c190325,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-a37e7bfe-fa8f-45dc-b932-85d5da013e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-7f0e5141-9d6f-416c-9ba1-cd2921acd2a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-979076820-172.17.0.10-1597322219635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35691,DS-32df74ed-f101-4ac4-a9e3-d2cc81b5f572,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-bdb038b1-4fb5-4fdf-833e-2202cc2817da,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-ab4a4c17-f7ea-4512-83a8-f5b036fe9dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-d3fa9105-cf56-491d-965e-c2f163cc9a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38002,DS-e4f8543f-478f-4adf-9cec-6f3b4559a501,DISK], DatanodeInfoWithStorage[127.0.0.1:39672,DS-e3aa6392-a6c6-4474-a75e-1a387c190325,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-a37e7bfe-fa8f-45dc-b932-85d5da013e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-7f0e5141-9d6f-416c-9ba1-cd2921acd2a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045838276-172.17.0.10-1597322740362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37243,DS-64c2429a-a5e0-465f-9e33-3abbfa8e9d72,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-cc7fbafd-5335-47b1-82ab-8dc2c09c0baa,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-f28e441c-1f57-4df7-a8f7-426db7c6dbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-1056c5df-efc1-4c5d-b231-0e0536c9953a,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-b13ccd5f-dc6c-4af4-bb4e-acd44a3c2920,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-89f42308-7f90-4fbf-a4e9-6130085aef82,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-fb536914-44df-4d40-a587-f7b32d75c9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-7d6c73d1-e0ac-4ea2-b863-24b4ab543edb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1045838276-172.17.0.10-1597322740362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37243,DS-64c2429a-a5e0-465f-9e33-3abbfa8e9d72,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-cc7fbafd-5335-47b1-82ab-8dc2c09c0baa,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-f28e441c-1f57-4df7-a8f7-426db7c6dbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-1056c5df-efc1-4c5d-b231-0e0536c9953a,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-b13ccd5f-dc6c-4af4-bb4e-acd44a3c2920,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-89f42308-7f90-4fbf-a4e9-6130085aef82,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-fb536914-44df-4d40-a587-f7b32d75c9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-7d6c73d1-e0ac-4ea2-b863-24b4ab543edb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-471874719-172.17.0.10-1597322780150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42041,DS-8eb79410-7c76-4667-9647-17409fe73b66,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-ce3efbb8-35bc-4d21-8ffa-d3e5f2cc4e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-074119a3-419a-48e2-b85f-0c48283d0b41,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-c34be0ba-1b07-40d5-a100-67c910c27eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-e07ab8b2-7e6d-46cf-bbf7-43af6ae9edbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-34d95561-cac1-4314-be00-9ab1434a7efe,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-d666d134-92a8-4178-9454-4ba7b7e108be,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-6ad8c193-c7a4-4af1-a044-0a06d1ffa650,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-471874719-172.17.0.10-1597322780150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42041,DS-8eb79410-7c76-4667-9647-17409fe73b66,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-ce3efbb8-35bc-4d21-8ffa-d3e5f2cc4e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-074119a3-419a-48e2-b85f-0c48283d0b41,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-c34be0ba-1b07-40d5-a100-67c910c27eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-e07ab8b2-7e6d-46cf-bbf7-43af6ae9edbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-34d95561-cac1-4314-be00-9ab1434a7efe,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-d666d134-92a8-4178-9454-4ba7b7e108be,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-6ad8c193-c7a4-4af1-a044-0a06d1ffa650,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567460089-172.17.0.10-1597323139666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38277,DS-87ba6676-b4ca-4262-931f-f19f9ed2e1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-8ef2fc65-72cd-4f7f-9d92-b40a01534e52,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-3eb1b456-1019-4acb-8966-5598e6e23d40,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-b08e43ed-76d8-40f6-8941-259a9040b484,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-19b4b3b0-7e01-458b-b88f-d2fd525cfc75,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-7380bb54-280d-4fd8-b0bc-91856e7334aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-99f845fa-3fa2-4b5e-8723-8d847c3f0001,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-4ded1155-9fec-49ca-aa6d-e8dbfa36685e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567460089-172.17.0.10-1597323139666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38277,DS-87ba6676-b4ca-4262-931f-f19f9ed2e1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-8ef2fc65-72cd-4f7f-9d92-b40a01534e52,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-3eb1b456-1019-4acb-8966-5598e6e23d40,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-b08e43ed-76d8-40f6-8941-259a9040b484,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-19b4b3b0-7e01-458b-b88f-d2fd525cfc75,DISK], DatanodeInfoWithStorage[127.0.0.1:43334,DS-7380bb54-280d-4fd8-b0bc-91856e7334aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-99f845fa-3fa2-4b5e-8723-8d847c3f0001,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-4ded1155-9fec-49ca-aa6d-e8dbfa36685e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5846
