reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-740214577-172.17.0.15-1597514077350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35157,DS-3b250d76-7864-4383-a199-1e3fe7a81b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-40a949d5-d3ad-464c-9213-16859b71595e,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-40fd9e53-fa82-4dcc-baf9-60152c95dbca,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-7001f943-870f-49b7-a6fe-a3540dd7a533,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-d25b774d-ca40-4fbe-8c58-826c7f17db3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-9568ab0c-026e-436d-bca5-20523090d743,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-cf224162-c523-4615-8ef8-391ceae81084,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-82a84fe7-97c3-42aa-83b8-26835b4e7231,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-740214577-172.17.0.15-1597514077350:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35157,DS-3b250d76-7864-4383-a199-1e3fe7a81b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-40a949d5-d3ad-464c-9213-16859b71595e,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-40fd9e53-fa82-4dcc-baf9-60152c95dbca,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-7001f943-870f-49b7-a6fe-a3540dd7a533,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-d25b774d-ca40-4fbe-8c58-826c7f17db3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-9568ab0c-026e-436d-bca5-20523090d743,DISK], DatanodeInfoWithStorage[127.0.0.1:36667,DS-cf224162-c523-4615-8ef8-391ceae81084,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-82a84fe7-97c3-42aa-83b8-26835b4e7231,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1775333305-172.17.0.15-1597514415692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33345,DS-bcc903b4-c76c-43c9-b718-1574be6d731e,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-f702fdc8-cfc3-40d2-a672-552fd2d443b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-08b611fe-07b2-4fab-aa65-d80461ff0257,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-fbaa3b56-52c5-4b0a-a4c6-199730a32726,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-ad683fef-5b17-4fc2-a535-63c6a152babe,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-d5db44bf-7fb6-40fb-8b19-10860c3f0232,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-7c6f364d-45da-4627-9897-216e96465a15,DISK], DatanodeInfoWithStorage[127.0.0.1:39716,DS-b31f0baa-2829-4db5-9737-9e42715549ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1775333305-172.17.0.15-1597514415692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33345,DS-bcc903b4-c76c-43c9-b718-1574be6d731e,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-f702fdc8-cfc3-40d2-a672-552fd2d443b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-08b611fe-07b2-4fab-aa65-d80461ff0257,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-fbaa3b56-52c5-4b0a-a4c6-199730a32726,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-ad683fef-5b17-4fc2-a535-63c6a152babe,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-d5db44bf-7fb6-40fb-8b19-10860c3f0232,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-7c6f364d-45da-4627-9897-216e96465a15,DISK], DatanodeInfoWithStorage[127.0.0.1:39716,DS-b31f0baa-2829-4db5-9737-9e42715549ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1787199160-172.17.0.15-1597515161803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46800,DS-0bb9b0de-b417-449f-97e4-346041caf725,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-256f31ef-3392-480e-9e1d-955051c3c835,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-aaf894cf-8a82-458b-9712-65f7c79a3f97,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-5ed49316-c81c-4147-87fb-6814f5ce490c,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-644a0943-b4d4-4f7c-b780-69f09c93c039,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-c96f0202-c11f-473b-b9e9-e5d474bfc311,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-7c3ad4db-c944-4c6f-9844-6332569e074b,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-9d157ada-d0e6-44c0-80f0-bfc2f21b07aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1787199160-172.17.0.15-1597515161803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46800,DS-0bb9b0de-b417-449f-97e4-346041caf725,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-256f31ef-3392-480e-9e1d-955051c3c835,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-aaf894cf-8a82-458b-9712-65f7c79a3f97,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-5ed49316-c81c-4147-87fb-6814f5ce490c,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-644a0943-b4d4-4f7c-b780-69f09c93c039,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-c96f0202-c11f-473b-b9e9-e5d474bfc311,DISK], DatanodeInfoWithStorage[127.0.0.1:45859,DS-7c3ad4db-c944-4c6f-9844-6332569e074b,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-9d157ada-d0e6-44c0-80f0-bfc2f21b07aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1064236239-172.17.0.15-1597515461345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35303,DS-ca0d72e4-664f-4269-a1c7-be6dc0e9dff4,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-ce7902f1-4438-4061-b1d2-7d7b48faf98e,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-402eafba-16d0-4ecc-b976-f3418010c7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-97689f4b-8847-44dd-aec3-9584dc6f3daa,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-b93ad7b9-d52d-4e5a-b874-03ed0932d4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-e109bd48-0d16-40f1-91f6-64495111fe0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-9f38fe38-91e4-4fde-828e-1c2be1f9e877,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-2bd2e4aa-2354-48f6-adf7-1fae0a1e7bab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1064236239-172.17.0.15-1597515461345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35303,DS-ca0d72e4-664f-4269-a1c7-be6dc0e9dff4,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-ce7902f1-4438-4061-b1d2-7d7b48faf98e,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-402eafba-16d0-4ecc-b976-f3418010c7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-97689f4b-8847-44dd-aec3-9584dc6f3daa,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-b93ad7b9-d52d-4e5a-b874-03ed0932d4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-e109bd48-0d16-40f1-91f6-64495111fe0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-9f38fe38-91e4-4fde-828e-1c2be1f9e877,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-2bd2e4aa-2354-48f6-adf7-1fae0a1e7bab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1283982343-172.17.0.15-1597515656992:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45820,DS-a8733f26-f625-4ca3-9e0a-9f3c41285637,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-fe40bf15-a1f2-4aab-b480-6aa60908c676,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-81cb4900-a873-4233-94d6-e2010ad2e883,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-7e1e2c77-5e56-4664-8ea2-1534bc074515,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-d44a70a3-6c6f-4eb7-bfc6-e51ca1e4ba21,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-164b44da-8ee8-4a3a-9d8c-244a23db50c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-e2674098-f12d-432a-b247-88305594d062,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-c9218060-80cc-4d33-9747-d28683a0d150,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1283982343-172.17.0.15-1597515656992:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45820,DS-a8733f26-f625-4ca3-9e0a-9f3c41285637,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-fe40bf15-a1f2-4aab-b480-6aa60908c676,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-81cb4900-a873-4233-94d6-e2010ad2e883,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-7e1e2c77-5e56-4664-8ea2-1534bc074515,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-d44a70a3-6c6f-4eb7-bfc6-e51ca1e4ba21,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-164b44da-8ee8-4a3a-9d8c-244a23db50c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-e2674098-f12d-432a-b247-88305594d062,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-c9218060-80cc-4d33-9747-d28683a0d150,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1806622624-172.17.0.15-1597515846603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37581,DS-acd1f361-a395-44b8-bcd4-ecf576beff9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-948870fa-7cf6-496a-beee-c2ad114a872d,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-90ccc702-e406-4753-a83e-76207308aa77,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-8ee7c18c-53c6-4925-805e-690ecb313c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-ee32cfdc-1574-4538-b3a8-1a46d554a2db,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-79db760f-4ced-405f-988a-d89d48746f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-e3dfed49-d8c5-4804-a739-c76548a40df3,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-a7ebcd47-9c1d-4658-ba34-c906b024bedb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1806622624-172.17.0.15-1597515846603:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37581,DS-acd1f361-a395-44b8-bcd4-ecf576beff9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-948870fa-7cf6-496a-beee-c2ad114a872d,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-90ccc702-e406-4753-a83e-76207308aa77,DISK], DatanodeInfoWithStorage[127.0.0.1:36331,DS-8ee7c18c-53c6-4925-805e-690ecb313c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40429,DS-ee32cfdc-1574-4538-b3a8-1a46d554a2db,DISK], DatanodeInfoWithStorage[127.0.0.1:40888,DS-79db760f-4ced-405f-988a-d89d48746f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-e3dfed49-d8c5-4804-a739-c76548a40df3,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-a7ebcd47-9c1d-4658-ba34-c906b024bedb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1063724612-172.17.0.15-1597517612426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35694,DS-348c2a3b-6309-4459-8991-16c3a4962513,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-d1a30fb3-15e5-4924-81d3-82d4531e6e23,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-0ad3853d-2743-48c9-9ea9-51bf67c37499,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-b8f4e2c3-fc29-48c3-894a-0e91eea5d61c,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-29a30e43-fe03-4ae0-8b3f-248bc9090954,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-7e8403ef-4a56-4d50-bb4d-b09cd421782b,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-aa1acc7c-81a2-44ed-84bb-8ea64f1814fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-947d38b3-c982-46db-870a-4d591d0e0299,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1063724612-172.17.0.15-1597517612426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35694,DS-348c2a3b-6309-4459-8991-16c3a4962513,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-d1a30fb3-15e5-4924-81d3-82d4531e6e23,DISK], DatanodeInfoWithStorage[127.0.0.1:38110,DS-0ad3853d-2743-48c9-9ea9-51bf67c37499,DISK], DatanodeInfoWithStorage[127.0.0.1:44502,DS-b8f4e2c3-fc29-48c3-894a-0e91eea5d61c,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-29a30e43-fe03-4ae0-8b3f-248bc9090954,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-7e8403ef-4a56-4d50-bb4d-b09cd421782b,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-aa1acc7c-81a2-44ed-84bb-8ea64f1814fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-947d38b3-c982-46db-870a-4d591d0e0299,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-298963425-172.17.0.15-1597517873113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34061,DS-51048f69-b1ed-4862-a567-43c6678ededa,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-2b7e51c2-58f6-4c2c-8c98-4df9c2c0282b,DISK], DatanodeInfoWithStorage[127.0.0.1:35581,DS-418d8313-3ab3-42eb-a1b8-8c0e20001138,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-59fd3bd0-5229-40b5-899c-34a24a238727,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-2d321cf9-644e-4caa-8252-875ab97528bf,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-c702172c-cd67-4829-8f47-8f5e4fc61929,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-af45be32-5849-4802-90f8-42c2d1a9587d,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-95d723ba-e05e-4fac-81a4-6ca24e474461,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-298963425-172.17.0.15-1597517873113:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34061,DS-51048f69-b1ed-4862-a567-43c6678ededa,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-2b7e51c2-58f6-4c2c-8c98-4df9c2c0282b,DISK], DatanodeInfoWithStorage[127.0.0.1:35581,DS-418d8313-3ab3-42eb-a1b8-8c0e20001138,DISK], DatanodeInfoWithStorage[127.0.0.1:45860,DS-59fd3bd0-5229-40b5-899c-34a24a238727,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-2d321cf9-644e-4caa-8252-875ab97528bf,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-c702172c-cd67-4829-8f47-8f5e4fc61929,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-af45be32-5849-4802-90f8-42c2d1a9587d,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-95d723ba-e05e-4fac-81a4-6ca24e474461,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-401003245-172.17.0.15-1597518124317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44911,DS-2d88d8b7-0444-4ec0-b91b-13f043d666f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-b3cf19c9-4921-41b7-856f-fb32f5f8ed7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-b5e08e9d-02b7-468f-8791-e157b7196189,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-7a11e4d8-93cc-4bbd-a62b-84c937f3d831,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-0d773d7b-da7b-4d91-88a4-4bdaea883df0,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-3d39f69b-d0bc-4252-beff-f7ce99d92e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-23af6660-cf8b-415d-825e-c77b0e6fe37c,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-ccfd3894-15e8-4e4e-9488-524a3975a9d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-401003245-172.17.0.15-1597518124317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44911,DS-2d88d8b7-0444-4ec0-b91b-13f043d666f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-b3cf19c9-4921-41b7-856f-fb32f5f8ed7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-b5e08e9d-02b7-468f-8791-e157b7196189,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-7a11e4d8-93cc-4bbd-a62b-84c937f3d831,DISK], DatanodeInfoWithStorage[127.0.0.1:34061,DS-0d773d7b-da7b-4d91-88a4-4bdaea883df0,DISK], DatanodeInfoWithStorage[127.0.0.1:40580,DS-3d39f69b-d0bc-4252-beff-f7ce99d92e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-23af6660-cf8b-415d-825e-c77b0e6fe37c,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-ccfd3894-15e8-4e4e-9488-524a3975a9d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-976891270-172.17.0.15-1597518437080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33445,DS-f9ccec11-28c6-4e34-9fd4-e1f05176dc8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-4cb1afcd-1ba1-49d4-b60f-d1dfd1128978,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-8c591088-5c58-44c8-a185-f86a17fb4c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-a842e10b-259d-47d7-89d4-01abe87fa48a,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-4f7e20d7-e12f-4b0e-b230-c5b7a221d924,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-69ea15d1-3187-4727-8b30-fef5518b998b,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-2c6a8dff-7ef6-4b32-9e8c-6ed0fd12ec7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-d2634571-624b-411f-b049-4fd989885053,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-976891270-172.17.0.15-1597518437080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33445,DS-f9ccec11-28c6-4e34-9fd4-e1f05176dc8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-4cb1afcd-1ba1-49d4-b60f-d1dfd1128978,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-8c591088-5c58-44c8-a185-f86a17fb4c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-a842e10b-259d-47d7-89d4-01abe87fa48a,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-4f7e20d7-e12f-4b0e-b230-c5b7a221d924,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-69ea15d1-3187-4727-8b30-fef5518b998b,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-2c6a8dff-7ef6-4b32-9e8c-6ed0fd12ec7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-d2634571-624b-411f-b049-4fd989885053,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-523073660-172.17.0.15-1597518476047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42370,DS-d06f193c-4cdf-457c-960c-06545ad7bcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-e4c1621f-d060-44bc-8817-4a66d5765856,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-232dc7c4-c38e-40c0-92d3-bc2ef591a0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-3763de4d-8a66-409a-8728-dd91c4d15415,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-c5caf12b-de18-4226-bcd7-ab0193695ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-94ae5183-548f-4e9b-b220-aa0f7aa6300d,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-c8ff91d8-057e-4c1b-9af4-d6a0b787e764,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-e55a8f94-ad3a-4b53-a6ab-03e4dc1fd8aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-523073660-172.17.0.15-1597518476047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42370,DS-d06f193c-4cdf-457c-960c-06545ad7bcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43688,DS-e4c1621f-d060-44bc-8817-4a66d5765856,DISK], DatanodeInfoWithStorage[127.0.0.1:41110,DS-232dc7c4-c38e-40c0-92d3-bc2ef591a0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-3763de4d-8a66-409a-8728-dd91c4d15415,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-c5caf12b-de18-4226-bcd7-ab0193695ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-94ae5183-548f-4e9b-b220-aa0f7aa6300d,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-c8ff91d8-057e-4c1b-9af4-d6a0b787e764,DISK], DatanodeInfoWithStorage[127.0.0.1:39386,DS-e55a8f94-ad3a-4b53-a6ab-03e4dc1fd8aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-568302816-172.17.0.15-1597518802798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38952,DS-9a864483-0df0-4ef0-8c05-a3fbee914557,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-41443e8b-b29e-48a8-b096-ed401287acfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-6b210094-2422-484a-8fd2-9593b01f20de,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-7662d9bb-b8ab-47ff-868b-8ce7c3400b63,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-858d6057-07e8-42ee-b359-0d626ece359b,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-4d74e56f-ae6b-42b9-9f72-6737975bc758,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-a727ded2-9d5a-4ab0-8288-2e8a5f758980,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-2d99d033-deac-48a8-8c0f-fcbd192cfdc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-568302816-172.17.0.15-1597518802798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38952,DS-9a864483-0df0-4ef0-8c05-a3fbee914557,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-41443e8b-b29e-48a8-b096-ed401287acfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45265,DS-6b210094-2422-484a-8fd2-9593b01f20de,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-7662d9bb-b8ab-47ff-868b-8ce7c3400b63,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-858d6057-07e8-42ee-b359-0d626ece359b,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-4d74e56f-ae6b-42b9-9f72-6737975bc758,DISK], DatanodeInfoWithStorage[127.0.0.1:35641,DS-a727ded2-9d5a-4ab0-8288-2e8a5f758980,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-2d99d033-deac-48a8-8c0f-fcbd192cfdc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lease-recheck-interval-ms
component: hdfs:NameNode
v1: 2000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1184187713-172.17.0.15-1597518949376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38672,DS-2a1aeb7c-9eb9-4288-80e8-3f326fde2cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-1b150b96-8280-4062-8b9c-d6ec49edd74b,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-833e5d60-8c6e-498e-95f9-708518031d99,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-be6740bd-ba06-4610-b5ba-07785873665b,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-c80e8eae-8012-4417-9bbe-32e6e3753947,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-1bc0763e-0a4d-43c8-9210-201d5df0c460,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-e4ee51f1-6e93-4596-a26c-8fb9472ae880,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-4aa51cbf-57b7-489f-873d-6da89af97933,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1184187713-172.17.0.15-1597518949376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38672,DS-2a1aeb7c-9eb9-4288-80e8-3f326fde2cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-1b150b96-8280-4062-8b9c-d6ec49edd74b,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-833e5d60-8c6e-498e-95f9-708518031d99,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-be6740bd-ba06-4610-b5ba-07785873665b,DISK], DatanodeInfoWithStorage[127.0.0.1:35979,DS-c80e8eae-8012-4417-9bbe-32e6e3753947,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-1bc0763e-0a4d-43c8-9210-201d5df0c460,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-e4ee51f1-6e93-4596-a26c-8fb9472ae880,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-4aa51cbf-57b7-489f-873d-6da89af97933,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5535
