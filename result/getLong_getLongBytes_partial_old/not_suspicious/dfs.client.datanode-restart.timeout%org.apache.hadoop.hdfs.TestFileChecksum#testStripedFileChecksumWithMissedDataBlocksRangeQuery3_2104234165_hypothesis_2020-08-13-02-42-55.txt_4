reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-894429768-172.17.0.16-1597286589242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43509,DS-f9346677-8886-4c4f-a8ed-687926424cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-56dc4db5-9e1d-4117-9402-1fb4b6c7b6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-8a8b999a-210a-49ff-845e-4f1873a8cef3,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-81c37a2c-68d7-40ce-b300-e17973e45109,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-a4df48d9-110c-4981-83ed-942d152406a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-392d2c0a-8877-4a44-b7fe-85e9fd1dfd99,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-21fd13dd-5ba4-475f-99af-12204cc076c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-2f730c60-0b55-4a11-a955-1aba50eb42cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-894429768-172.17.0.16-1597286589242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43509,DS-f9346677-8886-4c4f-a8ed-687926424cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-56dc4db5-9e1d-4117-9402-1fb4b6c7b6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-8a8b999a-210a-49ff-845e-4f1873a8cef3,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-81c37a2c-68d7-40ce-b300-e17973e45109,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-a4df48d9-110c-4981-83ed-942d152406a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35225,DS-392d2c0a-8877-4a44-b7fe-85e9fd1dfd99,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-21fd13dd-5ba4-475f-99af-12204cc076c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-2f730c60-0b55-4a11-a955-1aba50eb42cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1385261459-172.17.0.16-1597287101174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46208,DS-34290619-f976-4e69-8355-d6888266630d,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-41ca723f-e575-489c-8680-997f01375d76,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-9fe64424-3c30-4813-b532-3dbffa92a2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-2bd4eeed-953e-4ca6-a01b-f1bd02a0095a,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-753f2180-41de-41ed-acf8-8469e1dd1491,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-28bbc2c3-cafe-4149-b308-828360e18400,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-53ab4d4a-6f7f-4ffa-b8af-2c870adc280c,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-b0416b6a-5cc3-4f07-9d3d-1438ba679e51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1385261459-172.17.0.16-1597287101174:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46208,DS-34290619-f976-4e69-8355-d6888266630d,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-41ca723f-e575-489c-8680-997f01375d76,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-9fe64424-3c30-4813-b532-3dbffa92a2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-2bd4eeed-953e-4ca6-a01b-f1bd02a0095a,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-753f2180-41de-41ed-acf8-8469e1dd1491,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-28bbc2c3-cafe-4149-b308-828360e18400,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-53ab4d4a-6f7f-4ffa-b8af-2c870adc280c,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-b0416b6a-5cc3-4f07-9d3d-1438ba679e51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-908009675-172.17.0.16-1597287506347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34412,DS-012716eb-09c4-4b30-a703-d89a22eeb692,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-f3cf5a65-cd23-48d3-932a-1d8fdb100756,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-212355fa-3828-4bfc-abcd-b08cd2d945fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-5af61075-3ef2-4031-8879-9da5c0945413,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-93947a1d-75e9-448d-9b8b-0c4a53668c37,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-71a7f763-9408-49dd-8907-e2b1c50471ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-0b37e27a-e394-4c54-9c77-5490005182e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-ef19d90a-dd0f-41c5-b4d8-aaf54a31eaf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-908009675-172.17.0.16-1597287506347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34412,DS-012716eb-09c4-4b30-a703-d89a22eeb692,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-f3cf5a65-cd23-48d3-932a-1d8fdb100756,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-212355fa-3828-4bfc-abcd-b08cd2d945fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-5af61075-3ef2-4031-8879-9da5c0945413,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-93947a1d-75e9-448d-9b8b-0c4a53668c37,DISK], DatanodeInfoWithStorage[127.0.0.1:42398,DS-71a7f763-9408-49dd-8907-e2b1c50471ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-0b37e27a-e394-4c54-9c77-5490005182e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-ef19d90a-dd0f-41c5-b4d8-aaf54a31eaf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1785293912-172.17.0.16-1597288114356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39096,DS-c80b7408-ebde-4e28-a644-c13fc79c1fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-cd1826a0-55e8-4814-aa4d-b42dc1273183,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-b822058d-e8ef-4ba9-8c32-eef1eaa432a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-bcfad70c-7677-4636-a414-0c9da83c67e1,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-f9c6bd76-99db-4cc2-8921-bda0575b8e18,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-e5fd93b8-79af-46ff-92d3-2d346c44b96a,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-058b1233-1374-4513-99f8-d670917a9f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-cd9b7f23-dc14-4a7b-a2d8-c2fb8d455cb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1785293912-172.17.0.16-1597288114356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39096,DS-c80b7408-ebde-4e28-a644-c13fc79c1fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-cd1826a0-55e8-4814-aa4d-b42dc1273183,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-b822058d-e8ef-4ba9-8c32-eef1eaa432a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-bcfad70c-7677-4636-a414-0c9da83c67e1,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-f9c6bd76-99db-4cc2-8921-bda0575b8e18,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-e5fd93b8-79af-46ff-92d3-2d346c44b96a,DISK], DatanodeInfoWithStorage[127.0.0.1:40771,DS-058b1233-1374-4513-99f8-d670917a9f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-cd9b7f23-dc14-4a7b-a2d8-c2fb8d455cb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957060996-172.17.0.16-1597288153065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34612,DS-8e837c49-71d8-4bf7-85c2-91b2a182a6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-998ccf99-8edb-40bd-9f77-ae084d64fafd,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-fb18eabe-62ee-40b4-8e56-40ac3c819900,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-cd19901e-b21b-4f83-badc-bde4a1652bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-bae1251f-d0db-48c9-82ec-46df9d93ee1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-d88c882b-58d0-4f65-829b-1f2b1b5d2e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-f6fbeb98-c1fb-4ae9-a2ba-450343cdeca0,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-f5582489-9a9e-4d4a-b6dd-96ff8d4ff64e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957060996-172.17.0.16-1597288153065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34612,DS-8e837c49-71d8-4bf7-85c2-91b2a182a6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-998ccf99-8edb-40bd-9f77-ae084d64fafd,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-fb18eabe-62ee-40b4-8e56-40ac3c819900,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-cd19901e-b21b-4f83-badc-bde4a1652bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-bae1251f-d0db-48c9-82ec-46df9d93ee1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-d88c882b-58d0-4f65-829b-1f2b1b5d2e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-f6fbeb98-c1fb-4ae9-a2ba-450343cdeca0,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-f5582489-9a9e-4d4a-b6dd-96ff8d4ff64e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-328120573-172.17.0.16-1597288231153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44013,DS-a895bde8-2ecf-4559-857f-40d4d4a88464,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-0521115d-360c-4f88-8645-08d52e99eac0,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-051acb25-e536-43bc-8715-d0b7bd5dc5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-59467068-a2e7-4857-b372-02355163763f,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-e72d1515-8378-4d3c-bc51-0e018f9e7e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-1e327f3f-c887-4596-b70d-aaec9e16a929,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-615d7759-74bc-4e5b-9898-e4b77a418628,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-3e9b5ff2-e5b8-488b-9a7b-12bcb80e2344,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-328120573-172.17.0.16-1597288231153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44013,DS-a895bde8-2ecf-4559-857f-40d4d4a88464,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-0521115d-360c-4f88-8645-08d52e99eac0,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-051acb25-e536-43bc-8715-d0b7bd5dc5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-59467068-a2e7-4857-b372-02355163763f,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-e72d1515-8378-4d3c-bc51-0e018f9e7e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-1e327f3f-c887-4596-b70d-aaec9e16a929,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-615d7759-74bc-4e5b-9898-e4b77a418628,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-3e9b5ff2-e5b8-488b-9a7b-12bcb80e2344,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943031908-172.17.0.16-1597288427927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33683,DS-e4f03019-dad6-424c-9b43-9ae305e49bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-e65b5bcd-2079-484a-87f5-bbd5fd8d059f,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-2d5ff86a-e967-4585-b6d0-19da19084399,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-2c5f61f5-b7d6-4245-ac4f-0e2a51ee7419,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-7b829165-b0c0-4c87-8130-e89b7f6faef2,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-1d011969-17d4-42b2-afae-d7b1c3310949,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-52d1ce43-30b9-4561-a2a6-3a63a238c618,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-5af01c31-4da7-4956-8aec-76284149bec9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943031908-172.17.0.16-1597288427927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33683,DS-e4f03019-dad6-424c-9b43-9ae305e49bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-e65b5bcd-2079-484a-87f5-bbd5fd8d059f,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-2d5ff86a-e967-4585-b6d0-19da19084399,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-2c5f61f5-b7d6-4245-ac4f-0e2a51ee7419,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-7b829165-b0c0-4c87-8130-e89b7f6faef2,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-1d011969-17d4-42b2-afae-d7b1c3310949,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-52d1ce43-30b9-4561-a2a6-3a63a238c618,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-5af01c31-4da7-4956-8aec-76284149bec9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2030858181-172.17.0.16-1597288552457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35043,DS-8f678673-0fda-4725-a7d3-20852159ea63,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-70317574-884b-4ff6-8b7b-f23490080026,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-99e88d9c-05ef-47df-8885-3c20264aad0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-702d209a-067b-4e59-8953-6d8fe0857680,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-2d5964ed-1874-4671-ba13-322979480132,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-4ea84d61-9719-4d18-b631-2603d47b73d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-2253dabb-6b2e-41e3-ba72-a58558d6c7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-fd947410-a0ef-4518-b052-8718a9e964ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2030858181-172.17.0.16-1597288552457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35043,DS-8f678673-0fda-4725-a7d3-20852159ea63,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-70317574-884b-4ff6-8b7b-f23490080026,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-99e88d9c-05ef-47df-8885-3c20264aad0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-702d209a-067b-4e59-8953-6d8fe0857680,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-2d5964ed-1874-4671-ba13-322979480132,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-4ea84d61-9719-4d18-b631-2603d47b73d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-2253dabb-6b2e-41e3-ba72-a58558d6c7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-fd947410-a0ef-4518-b052-8718a9e964ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663288192-172.17.0.16-1597289418322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45593,DS-66511224-09ee-407e-bba5-3f066b3e3ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-30a9ab4e-3778-4684-8f14-3de29db07c07,DISK], DatanodeInfoWithStorage[127.0.0.1:38986,DS-2eac9785-c86e-4876-83ba-11e501e754d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-a90400e2-9595-4620-9ddf-0baa27b37eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44306,DS-f90ea8dd-749d-4f80-beca-fb0b549794f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-f03ef16b-b8d2-4a13-ae5f-af375a8c3208,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-59a145ba-e708-4f59-831b-b403db63dd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-679cef16-59ab-47f6-9072-561148e3125c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663288192-172.17.0.16-1597289418322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45593,DS-66511224-09ee-407e-bba5-3f066b3e3ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-30a9ab4e-3778-4684-8f14-3de29db07c07,DISK], DatanodeInfoWithStorage[127.0.0.1:38986,DS-2eac9785-c86e-4876-83ba-11e501e754d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-a90400e2-9595-4620-9ddf-0baa27b37eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44306,DS-f90ea8dd-749d-4f80-beca-fb0b549794f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-f03ef16b-b8d2-4a13-ae5f-af375a8c3208,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-59a145ba-e708-4f59-831b-b403db63dd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36425,DS-679cef16-59ab-47f6-9072-561148e3125c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-518152748-172.17.0.16-1597289614115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43873,DS-3dec87d9-3449-4e9e-b634-5600a3b3677a,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-cc2d12f0-e5ac-48ce-9f67-ef460d36f41a,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-b52f972a-ccc1-4d60-a251-41421064760d,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-8e0597d0-d839-4dd9-bf5f-42a1a48238ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-9fba5a99-a541-44e0-9794-ccca6babb45b,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-b2c2cdeb-3932-4b0b-a1d2-b1da6c0f3244,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-d2d1d2bc-fe91-48a5-b7d0-b89113935dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-b2dc5b8d-ecb4-4974-83e0-1a7084ba2ed0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-518152748-172.17.0.16-1597289614115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43873,DS-3dec87d9-3449-4e9e-b634-5600a3b3677a,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-cc2d12f0-e5ac-48ce-9f67-ef460d36f41a,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-b52f972a-ccc1-4d60-a251-41421064760d,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-8e0597d0-d839-4dd9-bf5f-42a1a48238ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-9fba5a99-a541-44e0-9794-ccca6babb45b,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-b2c2cdeb-3932-4b0b-a1d2-b1da6c0f3244,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-d2d1d2bc-fe91-48a5-b7d0-b89113935dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-b2dc5b8d-ecb4-4974-83e0-1a7084ba2ed0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161845140-172.17.0.16-1597289848144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33985,DS-34f277a2-baf2-4687-bd2a-9285d42650ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-6827baae-6103-41f0-ad52-bf8c16157735,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-1d632b6a-e34e-450b-9ede-be158b775321,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-c65386a9-4b99-493c-be1d-e4bf90acf1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-e7527a23-df27-4a68-816f-6c9db962897e,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-aee2c2e2-1955-4586-b2e0-0afae99b96aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-db512a5f-e0f3-4315-8314-d349244c4267,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-c33e2c4d-55ff-474f-898b-744b7fa7c300,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161845140-172.17.0.16-1597289848144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33985,DS-34f277a2-baf2-4687-bd2a-9285d42650ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-6827baae-6103-41f0-ad52-bf8c16157735,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-1d632b6a-e34e-450b-9ede-be158b775321,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-c65386a9-4b99-493c-be1d-e4bf90acf1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-e7527a23-df27-4a68-816f-6c9db962897e,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-aee2c2e2-1955-4586-b2e0-0afae99b96aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-db512a5f-e0f3-4315-8314-d349244c4267,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-c33e2c4d-55ff-474f-898b-744b7fa7c300,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1990553958-172.17.0.16-1597289933253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34995,DS-21cd1b2d-0409-49c1-a12a-cda2a83b3175,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-3a104964-db69-4bb2-9c1f-4a55d59ef36b,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-32e69d06-4d22-4832-b213-50a01d1469a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-653b6228-e75c-4d48-be6f-8bddf8c3bf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-51e578ae-a6a0-4b96-bed2-fe043b73b9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-d99ab7d2-807f-4237-9139-3099d5f05d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-1b425aa0-dab2-41d8-a0d4-515b161e44e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-8b083206-e947-4d5f-ace2-3b386d82228a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1990553958-172.17.0.16-1597289933253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34995,DS-21cd1b2d-0409-49c1-a12a-cda2a83b3175,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-3a104964-db69-4bb2-9c1f-4a55d59ef36b,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-32e69d06-4d22-4832-b213-50a01d1469a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-653b6228-e75c-4d48-be6f-8bddf8c3bf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-51e578ae-a6a0-4b96-bed2-fe043b73b9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-d99ab7d2-807f-4237-9139-3099d5f05d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-1b425aa0-dab2-41d8-a0d4-515b161e44e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-8b083206-e947-4d5f-ace2-3b386d82228a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1626481998-172.17.0.16-1597290791423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32812,DS-c4a5efc0-4705-4a46-839f-1fb9b3fdd314,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-1f7d45a7-ce55-4100-9d4a-990add543fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-0b5b8823-e7e2-47c6-92dd-62da6880b60a,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-79b09a49-9847-4b46-8211-c040c69aaef6,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-c3e34c68-89ee-4406-976b-c591a6406c58,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-3d3d6ad8-72fc-4de4-b12e-750d8cbc18b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-1a010e22-cd92-419d-a9a9-be6d4aca75f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-a7fa478f-5cee-4270-a409-081adb50c867,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1626481998-172.17.0.16-1597290791423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32812,DS-c4a5efc0-4705-4a46-839f-1fb9b3fdd314,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-1f7d45a7-ce55-4100-9d4a-990add543fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-0b5b8823-e7e2-47c6-92dd-62da6880b60a,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-79b09a49-9847-4b46-8211-c040c69aaef6,DISK], DatanodeInfoWithStorage[127.0.0.1:35092,DS-c3e34c68-89ee-4406-976b-c591a6406c58,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-3d3d6ad8-72fc-4de4-b12e-750d8cbc18b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-1a010e22-cd92-419d-a9a9-be6d4aca75f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-a7fa478f-5cee-4270-a409-081adb50c867,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1134498459-172.17.0.16-1597291049627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42432,DS-ed9ed6bf-dd7e-4a33-9398-c502e8d9013a,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-a1082bb2-96c1-40e0-a236-ec15275ae2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-f9007e39-9e51-422b-9d3c-237ad83ff93a,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-3058d271-0dc5-4578-8459-9cf6829b51cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-6f249731-39a4-4bbe-8858-b8cb126b6233,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-f40a95b3-9028-475d-814d-5417cb337b23,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-46c15359-e269-46b7-8f8e-bf46a876ed6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-954dcbde-71fa-476a-9248-23339a85ee0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1134498459-172.17.0.16-1597291049627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42432,DS-ed9ed6bf-dd7e-4a33-9398-c502e8d9013a,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-a1082bb2-96c1-40e0-a236-ec15275ae2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-f9007e39-9e51-422b-9d3c-237ad83ff93a,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-3058d271-0dc5-4578-8459-9cf6829b51cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45267,DS-6f249731-39a4-4bbe-8858-b8cb126b6233,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-f40a95b3-9028-475d-814d-5417cb337b23,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-46c15359-e269-46b7-8f8e-bf46a876ed6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43754,DS-954dcbde-71fa-476a-9248-23339a85ee0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.datanode-restart.timeout
component: hdfs:NameNode
v1: 30s
v2: 30000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1190022888-172.17.0.16-1597292307995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46222,DS-b9e63998-8b6a-46fa-a0cf-9e39fdeab3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-2ee00595-8cbd-4ef5-af65-4d11d88408c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-1b36e3c4-92aa-4253-9f33-bda43a05fc85,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-97d5feca-3747-43aa-9fea-b3437b11a662,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-ad767d9d-ce1e-4fdf-8fb4-292d1c0e0cff,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-f7a756f0-92b9-432c-bb8a-8c34fd41d185,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-086343da-2901-45fc-9fe9-d6e1677fc5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-a719b4fd-f834-40d7-a553-95aad9308a2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1190022888-172.17.0.16-1597292307995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46222,DS-b9e63998-8b6a-46fa-a0cf-9e39fdeab3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-2ee00595-8cbd-4ef5-af65-4d11d88408c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-1b36e3c4-92aa-4253-9f33-bda43a05fc85,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-97d5feca-3747-43aa-9fea-b3437b11a662,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-ad767d9d-ce1e-4fdf-8fb4-292d1c0e0cff,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-f7a756f0-92b9-432c-bb8a-8c34fd41d185,DISK], DatanodeInfoWithStorage[127.0.0.1:43802,DS-086343da-2901-45fc-9fe9-d6e1677fc5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-a719b4fd-f834-40d7-a553-95aad9308a2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5753
