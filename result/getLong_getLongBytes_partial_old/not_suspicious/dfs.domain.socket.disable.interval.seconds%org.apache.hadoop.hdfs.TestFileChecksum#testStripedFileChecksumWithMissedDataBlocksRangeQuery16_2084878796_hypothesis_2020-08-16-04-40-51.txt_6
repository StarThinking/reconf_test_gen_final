reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1647151096-172.17.0.7-1597553424916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37415,DS-ed59a909-7e9c-4795-8d09-3579bc9ee191,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-4dbe54ea-88b1-4ff7-bbf1-656283ae92ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-a39cc9dd-996b-4a12-8e94-9b0f0a811b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-bb5ab290-6f3c-45b5-8c9e-4ef17de2747f,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-8bc6170a-f3b9-4255-bdd4-9793019512ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-866082af-5cdc-43c1-a169-ec97b1f94a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-a28d9b89-5d21-4a58-9348-d84f4ed87771,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-6d874cef-958f-4d9e-b619-8b0e7fe52cc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1647151096-172.17.0.7-1597553424916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37415,DS-ed59a909-7e9c-4795-8d09-3579bc9ee191,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-4dbe54ea-88b1-4ff7-bbf1-656283ae92ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-a39cc9dd-996b-4a12-8e94-9b0f0a811b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-bb5ab290-6f3c-45b5-8c9e-4ef17de2747f,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-8bc6170a-f3b9-4255-bdd4-9793019512ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-866082af-5cdc-43c1-a169-ec97b1f94a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-a28d9b89-5d21-4a58-9348-d84f4ed87771,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-6d874cef-958f-4d9e-b619-8b0e7fe52cc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1934077419-172.17.0.7-1597553698635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35119,DS-0a493255-0ce8-40da-ad7a-fc62c0fadb13,DISK], DatanodeInfoWithStorage[127.0.0.1:44774,DS-ccf732a2-bd2f-4a27-9860-b1d9f6152169,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-57527c5d-0137-4d06-9a71-b354a217e1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-e2806070-419e-46e7-8568-b9e336b24c76,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-c12f1ac9-570e-444a-aaef-5e78c6f9a22b,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-481954ab-f578-42a9-b5c3-d9b4df4617c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-75a682f4-3e67-4db2-9a96-e03ec0a447e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-6a471bc0-3a91-41b4-96bb-5cd9d02031e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1934077419-172.17.0.7-1597553698635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35119,DS-0a493255-0ce8-40da-ad7a-fc62c0fadb13,DISK], DatanodeInfoWithStorage[127.0.0.1:44774,DS-ccf732a2-bd2f-4a27-9860-b1d9f6152169,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-57527c5d-0137-4d06-9a71-b354a217e1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-e2806070-419e-46e7-8568-b9e336b24c76,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-c12f1ac9-570e-444a-aaef-5e78c6f9a22b,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-481954ab-f578-42a9-b5c3-d9b4df4617c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-75a682f4-3e67-4db2-9a96-e03ec0a447e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-6a471bc0-3a91-41b4-96bb-5cd9d02031e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1197755093-172.17.0.7-1597554876271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38071,DS-d774d24b-b7f1-4300-af30-e02641b13fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-df1b7c29-90b7-4e6f-9f5a-2fa0fc04a7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-5258508b-cafc-4fcf-b154-89b4f0124c28,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-ba098a64-972b-453e-b24c-efde1b84735e,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-38be2e0a-f4fb-48ef-b5e6-01714ffc8a99,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-d0e8df2f-7e74-4c4c-b490-ebbffddbb9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-33be77a3-19a2-4a6d-92ea-59d3c08d9a38,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-e4a334d4-6bfa-4520-96cb-cf9cd49309b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1197755093-172.17.0.7-1597554876271:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38071,DS-d774d24b-b7f1-4300-af30-e02641b13fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-df1b7c29-90b7-4e6f-9f5a-2fa0fc04a7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33143,DS-5258508b-cafc-4fcf-b154-89b4f0124c28,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-ba098a64-972b-453e-b24c-efde1b84735e,DISK], DatanodeInfoWithStorage[127.0.0.1:41941,DS-38be2e0a-f4fb-48ef-b5e6-01714ffc8a99,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-d0e8df2f-7e74-4c4c-b490-ebbffddbb9e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-33be77a3-19a2-4a6d-92ea-59d3c08d9a38,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-e4a334d4-6bfa-4520-96cb-cf9cd49309b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-869264002-172.17.0.7-1597554946023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43600,DS-2215714c-de59-4abf-bf38-ac068ab281ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-64c17e26-c8f4-453d-97d1-c8fec5f0ad7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-609ff322-4433-40d0-8f38-f6e74556bd09,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-5be93d05-94dd-4c76-8192-ad6405128301,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-ef229785-7c4e-4b9c-b5ef-f155a9a7e944,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-52b79926-b840-4929-a01f-6ce81ec24af9,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-4a32aa87-4be4-49b8-809e-e6642dbbcdab,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-a7dd8570-ced6-4875-8720-4fb74922d5e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-869264002-172.17.0.7-1597554946023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43600,DS-2215714c-de59-4abf-bf38-ac068ab281ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-64c17e26-c8f4-453d-97d1-c8fec5f0ad7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-609ff322-4433-40d0-8f38-f6e74556bd09,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-5be93d05-94dd-4c76-8192-ad6405128301,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-ef229785-7c4e-4b9c-b5ef-f155a9a7e944,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-52b79926-b840-4929-a01f-6ce81ec24af9,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-4a32aa87-4be4-49b8-809e-e6642dbbcdab,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-a7dd8570-ced6-4875-8720-4fb74922d5e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1429656330-172.17.0.7-1597555614591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36674,DS-62e1026a-f6d1-44f9-a6d8-7a0b238fa553,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-6270feb9-eb52-483a-8282-21e91c10b6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-1e28f46e-e147-4623-b226-db9bc4d66d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-d35fd7de-7106-49f0-ad18-b9fbce4ee5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-2409230a-066b-497b-b86f-253297bb8bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-7345e952-d49a-4c0f-8915-bb854b887658,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-2e490053-3937-48d4-927f-ae4f9cad314a,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-2c37fba3-9f62-4705-b488-5e4190f85b5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1429656330-172.17.0.7-1597555614591:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36674,DS-62e1026a-f6d1-44f9-a6d8-7a0b238fa553,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-6270feb9-eb52-483a-8282-21e91c10b6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-1e28f46e-e147-4623-b226-db9bc4d66d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-d35fd7de-7106-49f0-ad18-b9fbce4ee5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-2409230a-066b-497b-b86f-253297bb8bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-7345e952-d49a-4c0f-8915-bb854b887658,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-2e490053-3937-48d4-927f-ae4f9cad314a,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-2c37fba3-9f62-4705-b488-5e4190f85b5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-143153569-172.17.0.7-1597555761410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43812,DS-c9cabac2-1b60-483f-8f56-2352f313bc46,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-8db5a94e-de86-4a19-a232-d1e94409a281,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-f8821145-746d-425d-8f2e-5eb38319bf4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-f653eef2-8ac9-4b73-8e48-6307ddc0ea5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-02c88656-9272-463e-86d2-251952afdb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-c65d6ff2-8bfc-4fe2-a846-039589d56b28,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-25c1c154-9640-4af2-a071-3a6486e7b786,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-b3f6b559-d1cc-40f7-aef0-6a559eae7d9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-143153569-172.17.0.7-1597555761410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43812,DS-c9cabac2-1b60-483f-8f56-2352f313bc46,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-8db5a94e-de86-4a19-a232-d1e94409a281,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-f8821145-746d-425d-8f2e-5eb38319bf4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-f653eef2-8ac9-4b73-8e48-6307ddc0ea5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-02c88656-9272-463e-86d2-251952afdb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-c65d6ff2-8bfc-4fe2-a846-039589d56b28,DISK], DatanodeInfoWithStorage[127.0.0.1:36721,DS-25c1c154-9640-4af2-a071-3a6486e7b786,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-b3f6b559-d1cc-40f7-aef0-6a559eae7d9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1839553112-172.17.0.7-1597555795884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44203,DS-260f81ac-eec8-4979-9db8-9aef38b4d24d,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-72e6a93c-987d-425e-a1e0-d00d4970cc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-659119ed-8814-40f3-bdff-f1507ab5a5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-9c83a15b-8706-4402-908b-b10800bf5ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-b3de5b4d-14a0-4da5-82b7-d5e520c4cc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-4e1b3b63-ffd1-4689-9dd6-d2e8916149fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-cb60c047-5187-4fa0-bf03-8241a66ba286,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-c974e417-e84a-4ab8-baee-8d9a9a5b1e4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1839553112-172.17.0.7-1597555795884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44203,DS-260f81ac-eec8-4979-9db8-9aef38b4d24d,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-72e6a93c-987d-425e-a1e0-d00d4970cc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-659119ed-8814-40f3-bdff-f1507ab5a5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41270,DS-9c83a15b-8706-4402-908b-b10800bf5ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:42819,DS-b3de5b4d-14a0-4da5-82b7-d5e520c4cc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-4e1b3b63-ffd1-4689-9dd6-d2e8916149fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-cb60c047-5187-4fa0-bf03-8241a66ba286,DISK], DatanodeInfoWithStorage[127.0.0.1:46298,DS-c974e417-e84a-4ab8-baee-8d9a9a5b1e4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-592336096-172.17.0.7-1597555974223:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35554,DS-1b25ab8a-5253-47b2-9a93-86892d058fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-033006b9-a17b-4b6e-84ce-5bdadb23db68,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-c49dbea5-4e86-4115-bf7a-64758cd17468,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-bf522831-eacc-45e2-9e98-af7117795869,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-8ab136e0-8912-42eb-8376-1621f890d655,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-4d89523c-fcd4-4279-8305-5aedbce85e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-aa7f249a-9251-4e3c-b4be-129d33e51da4,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-c200f9a0-cce9-48c7-818b-17b865938682,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-592336096-172.17.0.7-1597555974223:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35554,DS-1b25ab8a-5253-47b2-9a93-86892d058fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-033006b9-a17b-4b6e-84ce-5bdadb23db68,DISK], DatanodeInfoWithStorage[127.0.0.1:43173,DS-c49dbea5-4e86-4115-bf7a-64758cd17468,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-bf522831-eacc-45e2-9e98-af7117795869,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-8ab136e0-8912-42eb-8376-1621f890d655,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-4d89523c-fcd4-4279-8305-5aedbce85e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-aa7f249a-9251-4e3c-b4be-129d33e51da4,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-c200f9a0-cce9-48c7-818b-17b865938682,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1979743427-172.17.0.7-1597556173105:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41316,DS-02ac10f6-8e2d-4c7d-9930-5cba7506a8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-dc7d6f8e-2781-4ba0-accc-a8c107a6aa64,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-b32b7103-fdaf-4fdb-a7a4-b1bc3eb3ee7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-7a64a621-a34e-4e69-9fd3-19558fb6156a,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-6f470d6e-6410-4c46-97be-fd96a6b198ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-6d228750-440d-4756-8506-2d3974499174,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-63151750-6043-495d-a5bc-b0f942a83c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-de1c61dc-faae-44e8-8752-cb7b62f58369,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1979743427-172.17.0.7-1597556173105:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41316,DS-02ac10f6-8e2d-4c7d-9930-5cba7506a8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-dc7d6f8e-2781-4ba0-accc-a8c107a6aa64,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-b32b7103-fdaf-4fdb-a7a4-b1bc3eb3ee7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-7a64a621-a34e-4e69-9fd3-19558fb6156a,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-6f470d6e-6410-4c46-97be-fd96a6b198ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-6d228750-440d-4756-8506-2d3974499174,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-63151750-6043-495d-a5bc-b0f942a83c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-de1c61dc-faae-44e8-8752-cb7b62f58369,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1349521208-172.17.0.7-1597556287927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34079,DS-54845923-45eb-466a-a61e-77ae372905d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-f1345df1-be80-42fd-8bb8-e26f722c7cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-0e6c57a4-b51a-4926-b6f1-fd8dfa69b698,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-a8f790c8-c0ad-4449-acaf-61bedc7a9ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-869c50df-c6cb-4e6a-9efc-6a17e9784421,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-44d859d0-bbaa-4236-a4f7-829cec51b5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-62dd9e84-fbdd-4f7e-bc1a-39d81d7a9f26,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-b8ec8284-8d0f-4bbe-8df3-67ba0e620b51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1349521208-172.17.0.7-1597556287927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34079,DS-54845923-45eb-466a-a61e-77ae372905d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-f1345df1-be80-42fd-8bb8-e26f722c7cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-0e6c57a4-b51a-4926-b6f1-fd8dfa69b698,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-a8f790c8-c0ad-4449-acaf-61bedc7a9ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-869c50df-c6cb-4e6a-9efc-6a17e9784421,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-44d859d0-bbaa-4236-a4f7-829cec51b5f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-62dd9e84-fbdd-4f7e-bc1a-39d81d7a9f26,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-b8ec8284-8d0f-4bbe-8df3-67ba0e620b51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-279785666-172.17.0.7-1597556700421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37639,DS-d3517b9d-5851-48a7-b26f-8cf30024c76d,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-818809d7-bf16-45b5-9bfd-ea19e5d76bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-9dc503de-490a-41d4-9ab1-e8f64a4cbf5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-f78467c3-1c57-4b16-95bd-3af0995df365,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-f617e195-3569-46b9-b390-be633fa20e39,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-a984ce57-1cef-4642-9df8-60a69bd4cb23,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-1c39447c-b714-4628-8e87-a70b018e783e,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-fdcc0dd6-c60b-4d1d-b968-514defe80745,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-279785666-172.17.0.7-1597556700421:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37639,DS-d3517b9d-5851-48a7-b26f-8cf30024c76d,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-818809d7-bf16-45b5-9bfd-ea19e5d76bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-9dc503de-490a-41d4-9ab1-e8f64a4cbf5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-f78467c3-1c57-4b16-95bd-3af0995df365,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-f617e195-3569-46b9-b390-be633fa20e39,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-a984ce57-1cef-4642-9df8-60a69bd4cb23,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-1c39447c-b714-4628-8e87-a70b018e783e,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-fdcc0dd6-c60b-4d1d-b968-514defe80745,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1416560178-172.17.0.7-1597557460592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44647,DS-d4f9d017-631b-46e4-80d5-4302ece09f33,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-5b85b136-a2c2-431a-bea5-d54512580e93,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-17b2a547-8fec-4365-a5eb-f9c98fb35dae,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-9c6ac567-ed52-4cbb-9202-5f59dca3cf83,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-ef5c3a03-6a43-4047-b8a1-7827a0f1a99b,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-c98e75ef-aecf-4433-bc10-687bc5708fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-526d1685-5cfb-43d3-b88d-bca65a4710c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-c9512c1c-0ada-4dc2-9725-263ee0749f16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1416560178-172.17.0.7-1597557460592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44647,DS-d4f9d017-631b-46e4-80d5-4302ece09f33,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-5b85b136-a2c2-431a-bea5-d54512580e93,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-17b2a547-8fec-4365-a5eb-f9c98fb35dae,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-9c6ac567-ed52-4cbb-9202-5f59dca3cf83,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-ef5c3a03-6a43-4047-b8a1-7827a0f1a99b,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-c98e75ef-aecf-4433-bc10-687bc5708fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-526d1685-5cfb-43d3-b88d-bca65a4710c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-c9512c1c-0ada-4dc2-9725-263ee0749f16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 700
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-162211532-172.17.0.7-1597557715811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35014,DS-66fba4a6-d8ec-4389-97de-1e6472ac985d,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-54c1f83c-326b-435f-b3a1-29d7232cdcac,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-42315057-69a1-4099-acbe-c341412d70b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-8f79927d-d4d1-465c-9b4d-1963c85fa07e,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-fcabe66a-f47c-4731-9b14-ce1c0494de35,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-d65b7791-d8aa-45c2-8c31-bdcc83ac30c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-848d8536-6159-4a10-9129-d54dda1eed99,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-bfb6a4e2-2227-42ed-81f3-d367755d7680,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-162211532-172.17.0.7-1597557715811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35014,DS-66fba4a6-d8ec-4389-97de-1e6472ac985d,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-54c1f83c-326b-435f-b3a1-29d7232cdcac,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-42315057-69a1-4099-acbe-c341412d70b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-8f79927d-d4d1-465c-9b4d-1963c85fa07e,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-fcabe66a-f47c-4731-9b14-ce1c0494de35,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-d65b7791-d8aa-45c2-8c31-bdcc83ac30c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-848d8536-6159-4a10-9129-d54dda1eed99,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-bfb6a4e2-2227-42ed-81f3-d367755d7680,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5562
