reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80124183-172.17.0.5-1597289447383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36371,DS-0be5675a-98e3-432e-800a-52a8752d86dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-77aa0350-871d-4386-bf65-d85b54f96dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-6cb119af-fff7-43cd-9e02-7099dec0c8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-9fc15f75-7aee-40b2-bbff-0c7ec00d8c19,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-7f0346ed-99f3-4ece-9c70-44cbf571dfff,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-30d17166-48e8-4daa-a5cb-98ff56f7fbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-08517fd8-7513-461d-abaa-a4f3ce2347ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41017,DS-9a34116b-e414-4023-88cb-759ca8bd73ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-80124183-172.17.0.5-1597289447383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36371,DS-0be5675a-98e3-432e-800a-52a8752d86dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-77aa0350-871d-4386-bf65-d85b54f96dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-6cb119af-fff7-43cd-9e02-7099dec0c8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46282,DS-9fc15f75-7aee-40b2-bbff-0c7ec00d8c19,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-7f0346ed-99f3-4ece-9c70-44cbf571dfff,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-30d17166-48e8-4daa-a5cb-98ff56f7fbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-08517fd8-7513-461d-abaa-a4f3ce2347ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41017,DS-9a34116b-e414-4023-88cb-759ca8bd73ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235779987-172.17.0.5-1597289486046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39795,DS-62631da5-6d41-4d28-b770-f04c588ffedb,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-ed440b42-e5c0-4b71-a2e7-66e598d82130,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-c062641a-7c27-4c83-a0bc-9f656aa447b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-37a5dbf5-19df-4741-88ab-580bb82b92ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-6061339e-22d5-4f3a-a207-72d9771e2d88,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-1431684a-4647-4768-bc54-d4fbe02e1c60,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-afb26a99-d0bf-4503-a1ef-f295c8353706,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-27b3070c-c999-4496-b5a1-82ec81841366,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1235779987-172.17.0.5-1597289486046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39795,DS-62631da5-6d41-4d28-b770-f04c588ffedb,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-ed440b42-e5c0-4b71-a2e7-66e598d82130,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-c062641a-7c27-4c83-a0bc-9f656aa447b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-37a5dbf5-19df-4741-88ab-580bb82b92ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-6061339e-22d5-4f3a-a207-72d9771e2d88,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-1431684a-4647-4768-bc54-d4fbe02e1c60,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-afb26a99-d0bf-4503-a1ef-f295c8353706,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-27b3070c-c999-4496-b5a1-82ec81841366,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1300438933-172.17.0.5-1597289528591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44094,DS-1fcd56c9-7f89-4cae-890a-5b14fe468ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-7dd2f9d2-bf0c-47a7-87bc-63dc6ce9fd41,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-9d036e28-dd79-4ed2-b2e4-ca8e12ac4900,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-351faaf7-cf51-4894-8533-35a08983180c,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-586d5ee6-3ccb-4b97-adde-e7e2e154f1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-4b418b23-ec8e-4570-a3cb-d4363da9f1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-233e21de-3039-42d2-bd91-cf2c720f2827,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-57f5cd28-6437-4b18-9bb5-252223ca4636,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1300438933-172.17.0.5-1597289528591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44094,DS-1fcd56c9-7f89-4cae-890a-5b14fe468ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-7dd2f9d2-bf0c-47a7-87bc-63dc6ce9fd41,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-9d036e28-dd79-4ed2-b2e4-ca8e12ac4900,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-351faaf7-cf51-4894-8533-35a08983180c,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-586d5ee6-3ccb-4b97-adde-e7e2e154f1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-4b418b23-ec8e-4570-a3cb-d4363da9f1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-233e21de-3039-42d2-bd91-cf2c720f2827,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-57f5cd28-6437-4b18-9bb5-252223ca4636,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1228976129-172.17.0.5-1597289572136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38923,DS-851b3dab-e1b4-46ca-887e-7b6e03514ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-3ace9785-11f5-4c5a-91c7-9bc1b83818f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-c884383c-2df5-4d70-bc44-80dd434527ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-a0b99c2f-944b-4c7e-98ad-aa06e6bf324d,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-62a1d154-d0f5-41e4-9dcf-7d2d69eee685,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-d037813e-a016-4270-8ed2-476a0e5944f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-dc85fc37-561e-40b9-86b1-55ee63ce99a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-7ecf73f2-c210-4606-8ee1-c0dff5055093,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1228976129-172.17.0.5-1597289572136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38923,DS-851b3dab-e1b4-46ca-887e-7b6e03514ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-3ace9785-11f5-4c5a-91c7-9bc1b83818f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-c884383c-2df5-4d70-bc44-80dd434527ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-a0b99c2f-944b-4c7e-98ad-aa06e6bf324d,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-62a1d154-d0f5-41e4-9dcf-7d2d69eee685,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-d037813e-a016-4270-8ed2-476a0e5944f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-dc85fc37-561e-40b9-86b1-55ee63ce99a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-7ecf73f2-c210-4606-8ee1-c0dff5055093,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-244022687-172.17.0.5-1597289683794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43959,DS-d13a6bf8-59f2-4626-8258-305c6aad7c49,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-16aab49b-c9bc-48ed-8289-915f928d1950,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-e6b9f0c4-42f2-4789-b755-c0c21b65691f,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-603fc510-54c1-4f1f-9830-b20ee48f6438,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-0427423b-2f44-4ede-95b3-cba4d3d64727,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-067da0dd-bfee-4064-a2be-4c4e661e2e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-eb32ea9a-01c0-4552-93c0-02fa4f263095,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-e41bd39e-f507-4941-a3f5-425debc1c249,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-244022687-172.17.0.5-1597289683794:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43959,DS-d13a6bf8-59f2-4626-8258-305c6aad7c49,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-16aab49b-c9bc-48ed-8289-915f928d1950,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-e6b9f0c4-42f2-4789-b755-c0c21b65691f,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-603fc510-54c1-4f1f-9830-b20ee48f6438,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-0427423b-2f44-4ede-95b3-cba4d3d64727,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-067da0dd-bfee-4064-a2be-4c4e661e2e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35986,DS-eb32ea9a-01c0-4552-93c0-02fa4f263095,DISK], DatanodeInfoWithStorage[127.0.0.1:37009,DS-e41bd39e-f507-4941-a3f5-425debc1c249,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-807437569-172.17.0.5-1597289722070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43806,DS-9d74d331-a0be-4fe5-8fba-81296ae1ea93,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-2db9eba1-1278-44d3-a46e-e9c1d2bc8523,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-3c727209-eca8-47c7-b7d1-17efa0655c37,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-1b00693f-a7b1-4e75-bc96-0a1ee7903a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-518ff8d6-90ee-4d6a-8762-ff88b13e280e,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-9af932d8-42dd-438a-92e9-d4ec1602acb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45804,DS-e38f0fab-df38-490e-b327-5610163cba48,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-f32c0eb5-33d3-424b-b6eb-e4b5553aa199,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-807437569-172.17.0.5-1597289722070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43806,DS-9d74d331-a0be-4fe5-8fba-81296ae1ea93,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-2db9eba1-1278-44d3-a46e-e9c1d2bc8523,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-3c727209-eca8-47c7-b7d1-17efa0655c37,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-1b00693f-a7b1-4e75-bc96-0a1ee7903a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-518ff8d6-90ee-4d6a-8762-ff88b13e280e,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-9af932d8-42dd-438a-92e9-d4ec1602acb8,DISK], DatanodeInfoWithStorage[127.0.0.1:45804,DS-e38f0fab-df38-490e-b327-5610163cba48,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-f32c0eb5-33d3-424b-b6eb-e4b5553aa199,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1967246112-172.17.0.5-1597289875173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35779,DS-3a0cebd7-2a3e-402a-8a07-d5ee8ce03daf,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-7861a435-2b91-4034-bc43-73f8185f5913,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-386cccb6-22f2-45e1-a846-96ebe5e6ac5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-034571d3-8c43-44df-896c-ac605161109c,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-f0bfb094-4024-44b8-a528-b505fd2b16eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-cb0a7360-b4a3-40d5-8b30-c02d1bfe6055,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-7770e21d-8c0f-4726-9ee7-c5a44440b201,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-924edade-c7fe-47f7-8b07-c5c8b1e6c1ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1967246112-172.17.0.5-1597289875173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35779,DS-3a0cebd7-2a3e-402a-8a07-d5ee8ce03daf,DISK], DatanodeInfoWithStorage[127.0.0.1:39565,DS-7861a435-2b91-4034-bc43-73f8185f5913,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-386cccb6-22f2-45e1-a846-96ebe5e6ac5b,DISK], DatanodeInfoWithStorage[127.0.0.1:40464,DS-034571d3-8c43-44df-896c-ac605161109c,DISK], DatanodeInfoWithStorage[127.0.0.1:34886,DS-f0bfb094-4024-44b8-a528-b505fd2b16eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-cb0a7360-b4a3-40d5-8b30-c02d1bfe6055,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-7770e21d-8c0f-4726-9ee7-c5a44440b201,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-924edade-c7fe-47f7-8b07-c5c8b1e6c1ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1379002016-172.17.0.5-1597289954110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44496,DS-78ef8f82-ff7e-4e81-abfb-cd0d8948f9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-79253e4d-1aa0-4631-98e3-834b33882dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-1dcd11fc-e688-48f4-a24f-764dc413c6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-80657c51-04e4-406c-a44d-a1ab4c88abed,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-323f051e-aa0d-4107-83dd-3cfb050b4711,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-9acdc6c5-f974-4bd5-941d-27f8b25a15ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-e0989858-5a64-476c-8177-bf8df11cb471,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-1ce6fbed-59c5-4350-bf00-b3698e720898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1379002016-172.17.0.5-1597289954110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44496,DS-78ef8f82-ff7e-4e81-abfb-cd0d8948f9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33395,DS-79253e4d-1aa0-4631-98e3-834b33882dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:42374,DS-1dcd11fc-e688-48f4-a24f-764dc413c6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-80657c51-04e4-406c-a44d-a1ab4c88abed,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-323f051e-aa0d-4107-83dd-3cfb050b4711,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-9acdc6c5-f974-4bd5-941d-27f8b25a15ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-e0989858-5a64-476c-8177-bf8df11cb471,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-1ce6fbed-59c5-4350-bf00-b3698e720898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-779142899-172.17.0.5-1597290483890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35732,DS-60af8539-a775-4035-9380-d5a73d2876a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32882,DS-0267ea3c-924d-487a-b9d5-127ab694b5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-195d0c2f-df55-46c2-a643-a6f560456c68,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-ec332405-0831-432e-b045-232ef9b26bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-a7c34a45-1503-44b8-b529-68a0f9a49938,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-31aaedc8-59e3-4e9f-a22e-cc35c66f3288,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-6dff31c8-0111-4ec1-ab7f-eb7df5eead5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-53a11009-3a04-4fbf-a1aa-295d3aea88ae,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-779142899-172.17.0.5-1597290483890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35732,DS-60af8539-a775-4035-9380-d5a73d2876a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32882,DS-0267ea3c-924d-487a-b9d5-127ab694b5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-195d0c2f-df55-46c2-a643-a6f560456c68,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-ec332405-0831-432e-b045-232ef9b26bc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-a7c34a45-1503-44b8-b529-68a0f9a49938,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-31aaedc8-59e3-4e9f-a22e-cc35c66f3288,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-6dff31c8-0111-4ec1-ab7f-eb7df5eead5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38504,DS-53a11009-3a04-4fbf-a1aa-295d3aea88ae,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811028693-172.17.0.5-1597290525396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43619,DS-4b6bfec1-e2ca-4fc4-b604-b94a61bbb633,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-5657d79c-9288-4dda-a4b1-db397a7c85a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-e2729faa-2183-43e1-a0ad-3f097495e0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-87eecffc-d2d2-46e3-a159-6c56f5f089f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-9fb2d105-dfd3-4fc6-bbef-047140b2e474,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-b93b167b-4ffd-43a3-ada1-2e3ae503f24a,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-81452a32-c395-432d-a3ee-025e4043d080,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-20d4b5c0-89e6-4a92-8a5c-880e5711da7a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811028693-172.17.0.5-1597290525396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43619,DS-4b6bfec1-e2ca-4fc4-b604-b94a61bbb633,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-5657d79c-9288-4dda-a4b1-db397a7c85a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-e2729faa-2183-43e1-a0ad-3f097495e0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-87eecffc-d2d2-46e3-a159-6c56f5f089f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-9fb2d105-dfd3-4fc6-bbef-047140b2e474,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-b93b167b-4ffd-43a3-ada1-2e3ae503f24a,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-81452a32-c395-432d-a3ee-025e4043d080,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-20d4b5c0-89e6-4a92-8a5c-880e5711da7a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1496248969-172.17.0.5-1597290637175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40698,DS-70c7e156-eb61-4b7b-940a-0538ecdfc46b,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-ca454627-9532-433d-bd0e-828843a44403,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-699012e3-b20e-4779-a32b-2d979798ebef,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-50b37a0f-1ced-4b72-af08-f1f39f1e8630,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-e99c481b-cf95-49f4-b5ed-ed7c87e1fc02,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-474612be-6c1a-4227-a453-00e3bd922295,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-1143e2bf-87f6-41a3-aa81-d37493ae903e,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-801328df-7423-479e-96d7-5d9456ef25ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1496248969-172.17.0.5-1597290637175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40698,DS-70c7e156-eb61-4b7b-940a-0538ecdfc46b,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-ca454627-9532-433d-bd0e-828843a44403,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-699012e3-b20e-4779-a32b-2d979798ebef,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-50b37a0f-1ced-4b72-af08-f1f39f1e8630,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-e99c481b-cf95-49f4-b5ed-ed7c87e1fc02,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-474612be-6c1a-4227-a453-00e3bd922295,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-1143e2bf-87f6-41a3-aa81-d37493ae903e,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-801328df-7423-479e-96d7-5d9456ef25ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1106587050-172.17.0.5-1597290675514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46394,DS-f2ec41be-9ffb-49f1-8a00-dc29afe592d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-008c3a3d-59f6-4170-a35a-be05bdb3cc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-56ca7d83-7cb4-4d6c-b62e-114b2a0e1bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-e9c1b80e-ebe6-49e5-929e-896579710e14,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-78ed6af4-31a0-4f9a-8779-14bbe80672e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-18dfe497-e841-447e-bce7-3e23f1bd680e,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-2501a0c8-932f-4f23-ba38-4ac1530d3631,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-903ff966-5b66-4364-801e-996c0243ff22,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1106587050-172.17.0.5-1597290675514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46394,DS-f2ec41be-9ffb-49f1-8a00-dc29afe592d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-008c3a3d-59f6-4170-a35a-be05bdb3cc4b,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-56ca7d83-7cb4-4d6c-b62e-114b2a0e1bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-e9c1b80e-ebe6-49e5-929e-896579710e14,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-78ed6af4-31a0-4f9a-8779-14bbe80672e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-18dfe497-e841-447e-bce7-3e23f1bd680e,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-2501a0c8-932f-4f23-ba38-4ac1530d3631,DISK], DatanodeInfoWithStorage[127.0.0.1:46174,DS-903ff966-5b66-4364-801e-996c0243ff22,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-695061358-172.17.0.5-1597290872408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41565,DS-11efbf84-ab88-471b-a1fd-8b0d6fa20b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-a40b4c5e-53b3-44e1-8590-324249c7aeb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-222b48d7-7760-452a-9de6-cc22e5e63b68,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-efc1b588-71c5-4e71-b06d-01cd12aaa743,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-bdd0d024-73ae-4dc6-8c29-d415ce423395,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-5459fd3e-012f-47a1-a66a-0891e3e5ebc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-0f12558c-64ed-4ff5-9d11-1a233c5ba6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-678547a1-162e-447f-9b1e-301e02cdff0a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-695061358-172.17.0.5-1597290872408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41565,DS-11efbf84-ab88-471b-a1fd-8b0d6fa20b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-a40b4c5e-53b3-44e1-8590-324249c7aeb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-222b48d7-7760-452a-9de6-cc22e5e63b68,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-efc1b588-71c5-4e71-b06d-01cd12aaa743,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-bdd0d024-73ae-4dc6-8c29-d415ce423395,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-5459fd3e-012f-47a1-a66a-0891e3e5ebc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-0f12558c-64ed-4ff5-9d11-1a233c5ba6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-678547a1-162e-447f-9b1e-301e02cdff0a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1311084908-172.17.0.5-1597291536301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33103,DS-69021566-cbfe-409e-8f51-10e5e8e59aec,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-4b0f7ddd-a233-42ec-b174-aedf8038d0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-92ab61ee-9564-4a8c-84b0-815cc5e1cb7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-4e29baed-b5aa-4a8b-90c5-f96d60fc9dda,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-46d36c37-fcc3-4d76-bacb-831cde2f244d,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-518dd3f7-6e09-487b-bd4d-4ac9242efb10,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-55bca229-3340-49a0-b6ea-83da607589c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-e1b2f33a-5d45-48b6-9f33-8e8f6ce87793,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1311084908-172.17.0.5-1597291536301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33103,DS-69021566-cbfe-409e-8f51-10e5e8e59aec,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-4b0f7ddd-a233-42ec-b174-aedf8038d0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-92ab61ee-9564-4a8c-84b0-815cc5e1cb7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34724,DS-4e29baed-b5aa-4a8b-90c5-f96d60fc9dda,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-46d36c37-fcc3-4d76-bacb-831cde2f244d,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-518dd3f7-6e09-487b-bd4d-4ac9242efb10,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-55bca229-3340-49a0-b6ea-83da607589c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-e1b2f33a-5d45-48b6-9f33-8e8f6ce87793,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-786548026-172.17.0.5-1597291616736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35147,DS-364fb80e-d80c-4d75-bb5b-416986d393e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-2de7a229-36f7-48b4-8424-175197edfce7,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-9feffc68-58a9-40cc-97b8-342fd92713e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-e19498ca-5306-4707-9d43-42eae5443791,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-41194c4c-a45d-406f-b010-3e110463d0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-f09c2652-52c9-417c-b295-979bd86b8f06,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-85ad1e29-0ec3-44d4-84ea-d9911521f295,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-3d3fbf1e-3606-46a5-bf44-d92c0b8b6ec9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-786548026-172.17.0.5-1597291616736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35147,DS-364fb80e-d80c-4d75-bb5b-416986d393e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-2de7a229-36f7-48b4-8424-175197edfce7,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-9feffc68-58a9-40cc-97b8-342fd92713e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-e19498ca-5306-4707-9d43-42eae5443791,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-41194c4c-a45d-406f-b010-3e110463d0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-f09c2652-52c9-417c-b295-979bd86b8f06,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-85ad1e29-0ec3-44d4-84ea-d9911521f295,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-3d3fbf1e-3606-46a5-bf44-d92c0b8b6ec9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902452299-172.17.0.5-1597291909592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35556,DS-b42f69f5-d5e3-40dd-90fa-41ad7405af8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-0252a1d8-610a-42f9-9cc3-2ab92427515d,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-bdb1b7bf-0272-46dd-b487-b5779d98b975,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-a2b77dd6-b308-418a-b276-634b2d4b2d83,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-507074eb-9492-49ba-8282-836a3ca08114,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-34b04948-bbde-4fa2-82dd-08077927f40c,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-d315db31-555d-4c7e-ae4e-e765152a7603,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-ff630357-a0d9-4117-bab0-0dcd549a0760,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902452299-172.17.0.5-1597291909592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35556,DS-b42f69f5-d5e3-40dd-90fa-41ad7405af8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-0252a1d8-610a-42f9-9cc3-2ab92427515d,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-bdb1b7bf-0272-46dd-b487-b5779d98b975,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-a2b77dd6-b308-418a-b276-634b2d4b2d83,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-507074eb-9492-49ba-8282-836a3ca08114,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-34b04948-bbde-4fa2-82dd-08077927f40c,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-d315db31-555d-4c7e-ae4e-e765152a7603,DISK], DatanodeInfoWithStorage[127.0.0.1:42841,DS-ff630357-a0d9-4117-bab0-0dcd549a0760,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417156504-172.17.0.5-1597292065381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46507,DS-fe007635-b32b-43e8-9146-bfaa9bdbbc94,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-742a0a05-e27b-4b29-8adf-757fb2c11e02,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-89561ef1-c4ea-4d0b-9734-565a72ecbcce,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-1eb8485e-81d7-4320-8407-fb70c132ab57,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-65a13485-87b2-4c3c-a097-a88c5bdb5a04,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-b63aa99f-6448-4c9e-96fa-153db0359bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-6f1b1298-692b-496a-8187-1d6908758f71,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-27966d4d-cfc3-4366-95cc-e27b1bedc76f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417156504-172.17.0.5-1597292065381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46507,DS-fe007635-b32b-43e8-9146-bfaa9bdbbc94,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-742a0a05-e27b-4b29-8adf-757fb2c11e02,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-89561ef1-c4ea-4d0b-9734-565a72ecbcce,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-1eb8485e-81d7-4320-8407-fb70c132ab57,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-65a13485-87b2-4c3c-a097-a88c5bdb5a04,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-b63aa99f-6448-4c9e-96fa-153db0359bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-6f1b1298-692b-496a-8187-1d6908758f71,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-27966d4d-cfc3-4366-95cc-e27b1bedc76f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1844703771-172.17.0.5-1597292386165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46831,DS-f18e02a1-2ab0-49b7-90a2-20f95eb2126c,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-9ee40777-485c-4d2b-974f-a04f1dce6ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-45255cbb-0cbf-40b3-99c1-439b546da845,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-59f84f93-cf22-4b5d-8c28-5e5d602932b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-67de667e-b350-455b-9e8a-e753da3347c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-f7aa1cfa-ca11-4999-b0c9-e3d16e8f2466,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-bb23c07f-8502-4613-93e8-f6766f9f3136,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-4576c933-c2d0-4f9c-8067-0b0ae8976d03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1844703771-172.17.0.5-1597292386165:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46831,DS-f18e02a1-2ab0-49b7-90a2-20f95eb2126c,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-9ee40777-485c-4d2b-974f-a04f1dce6ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-45255cbb-0cbf-40b3-99c1-439b546da845,DISK], DatanodeInfoWithStorage[127.0.0.1:38631,DS-59f84f93-cf22-4b5d-8c28-5e5d602932b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-67de667e-b350-455b-9e8a-e753da3347c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-f7aa1cfa-ca11-4999-b0c9-e3d16e8f2466,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-bb23c07f-8502-4613-93e8-f6766f9f3136,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-4576c933-c2d0-4f9c-8067-0b0ae8976d03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-166094715-172.17.0.5-1597292511408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36464,DS-db7fcb7d-9585-4428-99c2-aed9b87bc550,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-c2ef4277-b21a-4d24-bacd-afa05226612e,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-cf104de3-8a88-4b35-a364-b76a2b0cd348,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-ccadd7e3-2057-4327-b245-d03ecc0697e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-bca4d9bf-2f65-4528-bbe3-9b06e6a781f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-be570b64-7727-4387-a925-c258da5e765c,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-a486c4e3-9d34-46dc-9fff-a22faf868749,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-cc8f5afa-d1a7-42d5-be5c-6ac9b0b64634,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-166094715-172.17.0.5-1597292511408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36464,DS-db7fcb7d-9585-4428-99c2-aed9b87bc550,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-c2ef4277-b21a-4d24-bacd-afa05226612e,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-cf104de3-8a88-4b35-a364-b76a2b0cd348,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-ccadd7e3-2057-4327-b245-d03ecc0697e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-bca4d9bf-2f65-4528-bbe3-9b06e6a781f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-be570b64-7727-4387-a925-c258da5e765c,DISK], DatanodeInfoWithStorage[127.0.0.1:39254,DS-a486c4e3-9d34-46dc-9fff-a22faf868749,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-cc8f5afa-d1a7-42d5-be5c-6ac9b0b64634,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1326343657-172.17.0.5-1597292545398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45006,DS-35327c93-b806-453c-9350-6ee78f23a004,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-6eadc609-ff41-426c-8d08-a84c53c22966,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-5eaff8f0-8a72-4063-84a2-a95b4439abdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-87ab9677-d58c-4c0a-97c9-d47169ec61ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-02dd2bcf-2d44-4505-9085-eea1c6fe6bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-c89d7840-ff68-441c-aeb1-e3bd0ba6d340,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-40606aae-8d32-4edb-8c67-b4d6a464064e,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-98b3e0a5-5abb-4728-94eb-260f6868eaf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1326343657-172.17.0.5-1597292545398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45006,DS-35327c93-b806-453c-9350-6ee78f23a004,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-6eadc609-ff41-426c-8d08-a84c53c22966,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-5eaff8f0-8a72-4063-84a2-a95b4439abdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-87ab9677-d58c-4c0a-97c9-d47169ec61ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-02dd2bcf-2d44-4505-9085-eea1c6fe6bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-c89d7840-ff68-441c-aeb1-e3bd0ba6d340,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-40606aae-8d32-4edb-8c67-b4d6a464064e,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-98b3e0a5-5abb-4728-94eb-260f6868eaf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-290602158-172.17.0.5-1597292638955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46692,DS-d137d59a-4d79-46e5-8b8e-8280b8ffb516,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-36b40b33-a48b-4af0-9671-ffc429abc996,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-619b14c6-f19a-42ef-9af4-47b9993863bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-b6137c39-51dd-4967-ac09-48059a4689ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-716734c5-44d2-477e-a6be-6737fed1bc65,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-9f929821-b601-494e-a8a2-118b35c7f25a,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-7a23f332-5234-4e61-8864-39cf7c6c3a91,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-c00037f7-15ad-41a5-9153-5a034afe434a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-290602158-172.17.0.5-1597292638955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46692,DS-d137d59a-4d79-46e5-8b8e-8280b8ffb516,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-36b40b33-a48b-4af0-9671-ffc429abc996,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-619b14c6-f19a-42ef-9af4-47b9993863bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41041,DS-b6137c39-51dd-4967-ac09-48059a4689ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-716734c5-44d2-477e-a6be-6737fed1bc65,DISK], DatanodeInfoWithStorage[127.0.0.1:45171,DS-9f929821-b601-494e-a8a2-118b35c7f25a,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-7a23f332-5234-4e61-8864-39cf7c6c3a91,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-c00037f7-15ad-41a5-9153-5a034afe434a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-207459608-172.17.0.5-1597292807599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34847,DS-7c81badb-cadf-4f06-b171-e5a129ea93f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-16cabd5c-fcb1-4c59-a6b1-519d794df006,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-e7901384-8aaa-46a2-96e1-caa48c6aedc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-067bc0d2-bd42-4476-9714-0fb9dd9f6282,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-b01ba4e7-fb0b-4bf9-88f4-61a7203917c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-02111061-da78-4d39-8eee-f3ecf2dfa1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-aca65240-3374-4a1e-917d-be6b6ff21c87,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-df3b914d-1c0b-489d-8230-bce7b851a771,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-207459608-172.17.0.5-1597292807599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34847,DS-7c81badb-cadf-4f06-b171-e5a129ea93f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37036,DS-16cabd5c-fcb1-4c59-a6b1-519d794df006,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-e7901384-8aaa-46a2-96e1-caa48c6aedc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-067bc0d2-bd42-4476-9714-0fb9dd9f6282,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-b01ba4e7-fb0b-4bf9-88f4-61a7203917c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33495,DS-02111061-da78-4d39-8eee-f3ecf2dfa1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-aca65240-3374-4a1e-917d-be6b6ff21c87,DISK], DatanodeInfoWithStorage[127.0.0.1:40359,DS-df3b914d-1c0b-489d-8230-bce7b851a771,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-496270955-172.17.0.5-1597292852817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35605,DS-b063d1fe-8d96-41f3-923d-7cf4cd8cd686,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-0ab2e621-04d5-44ed-aab6-fc0462713bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-8b9d148a-395b-4115-93cf-56d888df551b,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-581e84d3-6ecc-489e-b5ae-c92cb9604f13,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-d0abc692-7215-4e95-b1c2-295251853488,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-0cb6b8c4-7a37-470b-bdce-81473786c84b,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-b96f5e6f-ea47-451d-99b6-44bfd2d2f4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-9f1e858a-17f4-4569-8749-0982b19002a7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-496270955-172.17.0.5-1597292852817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35605,DS-b063d1fe-8d96-41f3-923d-7cf4cd8cd686,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-0ab2e621-04d5-44ed-aab6-fc0462713bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-8b9d148a-395b-4115-93cf-56d888df551b,DISK], DatanodeInfoWithStorage[127.0.0.1:40701,DS-581e84d3-6ecc-489e-b5ae-c92cb9604f13,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-d0abc692-7215-4e95-b1c2-295251853488,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-0cb6b8c4-7a37-470b-bdce-81473786c84b,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-b96f5e6f-ea47-451d-99b6-44bfd2d2f4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-9f1e858a-17f4-4569-8749-0982b19002a7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450972715-172.17.0.5-1597293047573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41841,DS-2d9160e8-02c2-4e07-b260-242e586ced09,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-47cdd0af-043b-41e4-92e6-f15e7f5a1782,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-0cd37344-8803-4c0d-b65a-ababac17753b,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-f1c6c48d-c912-4df9-9a9a-ca9017294acb,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-96a7ba54-e8d9-4597-ac75-3eb7f71cfac9,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-0c7f005b-0b60-4923-a519-e53e96f32586,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-0f8ead68-eb3f-494b-b717-6c82721af340,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-eda769f0-7e0a-4c2c-b51b-13e7ad7f2b63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450972715-172.17.0.5-1597293047573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41841,DS-2d9160e8-02c2-4e07-b260-242e586ced09,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-47cdd0af-043b-41e4-92e6-f15e7f5a1782,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-0cd37344-8803-4c0d-b65a-ababac17753b,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-f1c6c48d-c912-4df9-9a9a-ca9017294acb,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-96a7ba54-e8d9-4597-ac75-3eb7f71cfac9,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-0c7f005b-0b60-4923-a519-e53e96f32586,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-0f8ead68-eb3f-494b-b717-6c82721af340,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-eda769f0-7e0a-4c2c-b51b-13e7ad7f2b63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2072991710-172.17.0.5-1597293477479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37933,DS-72d2cb8e-05b4-4403-a3a7-b5f7a553e3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-f3bb2a75-54a9-4bf4-aa13-7f4eca2863e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39215,DS-e33288c1-ed3e-495a-9b26-954609ed99c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-972dfd28-baa7-4c73-967b-6ebf49f69b11,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-b6d47483-ce7a-41a0-88d3-ae31766e9e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-e98adf2a-c15c-4a10-958d-9d6e391a58a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-d66c9d15-dd45-46c1-88b6-eb73065b3a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38244,DS-9f72c819-5f38-4657-b014-a8ac489a7ceb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2072991710-172.17.0.5-1597293477479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37933,DS-72d2cb8e-05b4-4403-a3a7-b5f7a553e3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-f3bb2a75-54a9-4bf4-aa13-7f4eca2863e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39215,DS-e33288c1-ed3e-495a-9b26-954609ed99c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-972dfd28-baa7-4c73-967b-6ebf49f69b11,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-b6d47483-ce7a-41a0-88d3-ae31766e9e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:43872,DS-e98adf2a-c15c-4a10-958d-9d6e391a58a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-d66c9d15-dd45-46c1-88b6-eb73065b3a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38244,DS-9f72c819-5f38-4657-b014-a8ac489a7ceb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-147238946-172.17.0.5-1597293669687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38519,DS-1df818ca-a7c6-47de-8ea7-b8f5b46a6cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-0273baa0-e0c9-4633-bc16-4f2bd7ccfdd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-3c04dcf7-34c5-45c2-b8c1-0ab14844108c,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-c9ec40c5-efeb-4e70-92f7-a06fe02c71eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-2ab36a8f-472f-4d89-95d7-ae7ae8079aba,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-abf47f61-a1c1-49fd-9482-2879ab3c263e,DISK], DatanodeInfoWithStorage[127.0.0.1:41735,DS-16b398be-a199-4151-9248-4cb2838aa2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-d0c4f553-85ad-4af7-8928-77a8b5b63241,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-147238946-172.17.0.5-1597293669687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38519,DS-1df818ca-a7c6-47de-8ea7-b8f5b46a6cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-0273baa0-e0c9-4633-bc16-4f2bd7ccfdd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-3c04dcf7-34c5-45c2-b8c1-0ab14844108c,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-c9ec40c5-efeb-4e70-92f7-a06fe02c71eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-2ab36a8f-472f-4d89-95d7-ae7ae8079aba,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-abf47f61-a1c1-49fd-9482-2879ab3c263e,DISK], DatanodeInfoWithStorage[127.0.0.1:41735,DS-16b398be-a199-4151-9248-4cb2838aa2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-d0c4f553-85ad-4af7-8928-77a8b5b63241,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1556996225-172.17.0.5-1597294069211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37465,DS-baf1cf64-248f-4b4c-9ab5-3728438c689a,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-86b4534e-8281-4b9c-89f0-05762c22bb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-160e5433-5ebd-4a4b-b6f7-ca5f17ffcb89,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-7559fd06-5663-4d7b-a237-608cba70a363,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-99aaaaca-51ba-4120-acd0-b71218323906,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-d8542d60-a71c-48ad-886a-b79bfdde32ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-1db2f4f3-aac0-495f-9ed2-7fccc17c659b,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-f6ebb36f-ec93-4c97-b8a1-de33ccf95437,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1556996225-172.17.0.5-1597294069211:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37465,DS-baf1cf64-248f-4b4c-9ab5-3728438c689a,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-86b4534e-8281-4b9c-89f0-05762c22bb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-160e5433-5ebd-4a4b-b6f7-ca5f17ffcb89,DISK], DatanodeInfoWithStorage[127.0.0.1:40282,DS-7559fd06-5663-4d7b-a237-608cba70a363,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-99aaaaca-51ba-4120-acd0-b71218323906,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-d8542d60-a71c-48ad-886a-b79bfdde32ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-1db2f4f3-aac0-495f-9ed2-7fccc17c659b,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-f6ebb36f-ec93-4c97-b8a1-de33ccf95437,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167605551-172.17.0.5-1597294182489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39455,DS-e6af8cce-fac1-4d7f-ac48-0b45f1ea9fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-2291b15b-f3a9-4b8f-b73c-9bafee2cd90c,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-cf2210bb-dc20-4e70-86ef-72358168fbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40560,DS-303849eb-d29c-4b78-aeb6-952db8af6060,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-a2f11f27-e3ca-4900-99cb-fc1aea6baa00,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-86895838-4a5a-44dd-84fc-b7a3a8add974,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-8b987367-1c34-41a7-b628-4a858859d81b,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-b55ddc01-aa11-45b6-a295-2ebec3c64e4d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167605551-172.17.0.5-1597294182489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39455,DS-e6af8cce-fac1-4d7f-ac48-0b45f1ea9fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-2291b15b-f3a9-4b8f-b73c-9bafee2cd90c,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-cf2210bb-dc20-4e70-86ef-72358168fbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40560,DS-303849eb-d29c-4b78-aeb6-952db8af6060,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-a2f11f27-e3ca-4900-99cb-fc1aea6baa00,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-86895838-4a5a-44dd-84fc-b7a3a8add974,DISK], DatanodeInfoWithStorage[127.0.0.1:41370,DS-8b987367-1c34-41a7-b628-4a858859d81b,DISK], DatanodeInfoWithStorage[127.0.0.1:42271,DS-b55ddc01-aa11-45b6-a295-2ebec3c64e4d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-400579620-172.17.0.5-1597294285752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43332,DS-a95e79d4-7ae2-4d79-882b-2b9973a5aec3,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-195637db-3a03-4e84-8b3d-76d70f9e9e82,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-bd68acd1-ffbd-4c45-a0ff-14d27f010d34,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-e0aa508d-76b2-4e80-9c9d-da2b5cd21528,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-6b269622-98a4-4fb4-b40e-ef07f5887ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-fbf4c824-217a-4951-bbc6-120d23840c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-e0755aca-6b72-41c4-8b0a-8c3cec06033f,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-0ad271f1-b5f4-4353-aaa4-6eed2a60e01a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-400579620-172.17.0.5-1597294285752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43332,DS-a95e79d4-7ae2-4d79-882b-2b9973a5aec3,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-195637db-3a03-4e84-8b3d-76d70f9e9e82,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-bd68acd1-ffbd-4c45-a0ff-14d27f010d34,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-e0aa508d-76b2-4e80-9c9d-da2b5cd21528,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-6b269622-98a4-4fb4-b40e-ef07f5887ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:37249,DS-fbf4c824-217a-4951-bbc6-120d23840c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-e0755aca-6b72-41c4-8b0a-8c3cec06033f,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-0ad271f1-b5f4-4353-aaa4-6eed2a60e01a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786217038-172.17.0.5-1597294404768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39872,DS-3d513883-a17b-42cb-a205-902937035f16,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-d0fe3f45-f0f0-4387-93d2-7d206019bb29,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-f0d5d8ab-5476-4a68-a5be-c49a20d693ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-06722ea2-4137-44d6-8b47-ef011f54c142,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-0c2970cd-05ff-4dba-b0f8-3e0e254a74b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-68f1bad5-cce8-4a18-b130-572f46771733,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-f6d1bc05-26dd-406f-a38c-d23681482c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-73cc0929-97b0-4a2e-a81d-1b34d65e3a20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786217038-172.17.0.5-1597294404768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39872,DS-3d513883-a17b-42cb-a205-902937035f16,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-d0fe3f45-f0f0-4387-93d2-7d206019bb29,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-f0d5d8ab-5476-4a68-a5be-c49a20d693ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-06722ea2-4137-44d6-8b47-ef011f54c142,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-0c2970cd-05ff-4dba-b0f8-3e0e254a74b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-68f1bad5-cce8-4a18-b130-572f46771733,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-f6d1bc05-26dd-406f-a38c-d23681482c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-73cc0929-97b0-4a2e-a81d-1b34d65e3a20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869035347-172.17.0.5-1597294574412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43756,DS-5a97b87b-7b3c-4ec1-b697-fe0814cc5863,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-7b575ac2-3a0e-4189-8bc1-beb06063eabe,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-cad11424-db38-42d4-965a-981f93725388,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-12f97fee-c4c4-4f7e-a7d6-85795563663d,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-bc6a505d-3e20-4436-9126-9f1be06f6e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-3691e602-834d-43c5-a481-34a097d5a70f,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-f0aa8c8d-48f8-481c-9a7c-dac014468119,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-daf54e47-eea8-4fec-9770-fefd19df2981,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869035347-172.17.0.5-1597294574412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43756,DS-5a97b87b-7b3c-4ec1-b697-fe0814cc5863,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-7b575ac2-3a0e-4189-8bc1-beb06063eabe,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-cad11424-db38-42d4-965a-981f93725388,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-12f97fee-c4c4-4f7e-a7d6-85795563663d,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-bc6a505d-3e20-4436-9126-9f1be06f6e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-3691e602-834d-43c5-a481-34a097d5a70f,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-f0aa8c8d-48f8-481c-9a7c-dac014468119,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-daf54e47-eea8-4fec-9770-fefd19df2981,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-645264910-172.17.0.5-1597294936289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40494,DS-0f81c916-c0b2-4f65-9f63-8612f7c9928b,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-4ee2fbcf-bc3c-4028-b9d4-f6ab37efa816,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-4f4495f0-a749-45a3-ba94-9c2e7ec856d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-129aaff4-81e5-461a-83be-3cd6414b8418,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-597bc9cc-2a2f-4c3c-bd1c-35b137b3191c,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-7ac8b700-ed74-495f-b6de-7533f88419c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-71e98680-7f62-4c00-8d29-15eb8c4bc280,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-8d09ca93-49c5-43b9-a941-9a595d2a7c52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-645264910-172.17.0.5-1597294936289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40494,DS-0f81c916-c0b2-4f65-9f63-8612f7c9928b,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-4ee2fbcf-bc3c-4028-b9d4-f6ab37efa816,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-4f4495f0-a749-45a3-ba94-9c2e7ec856d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41357,DS-129aaff4-81e5-461a-83be-3cd6414b8418,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-597bc9cc-2a2f-4c3c-bd1c-35b137b3191c,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-7ac8b700-ed74-495f-b6de-7533f88419c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-71e98680-7f62-4c00-8d29-15eb8c4bc280,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-8d09ca93-49c5-43b9-a941-9a595d2a7c52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352561070-172.17.0.5-1597295014103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38687,DS-a3018ed0-ac82-49ae-a657-c30d5f4f82c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-338dd173-c541-4b34-8dcc-13beeb80809d,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-ee07187e-46b0-4d3d-abda-b171d106497b,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-62e63c62-8623-4d52-86c8-a07158375134,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-05a4669a-f97d-4b7e-aec2-7dc8eeffb52a,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-3391832d-c1b1-48f4-bfd9-767f059f10aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-7ce98d6b-1d91-42c1-93f3-15138ac56f35,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-39c0cf03-f82c-4c6f-b74d-b382a15e8cc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352561070-172.17.0.5-1597295014103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38687,DS-a3018ed0-ac82-49ae-a657-c30d5f4f82c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-338dd173-c541-4b34-8dcc-13beeb80809d,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-ee07187e-46b0-4d3d-abda-b171d106497b,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-62e63c62-8623-4d52-86c8-a07158375134,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-05a4669a-f97d-4b7e-aec2-7dc8eeffb52a,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-3391832d-c1b1-48f4-bfd9-767f059f10aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-7ce98d6b-1d91-42c1-93f3-15138ac56f35,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-39c0cf03-f82c-4c6f-b74d-b382a15e8cc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183560348-172.17.0.5-1597295201771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42996,DS-4013fd78-8f7b-4649-8e09-e0fdfec9336f,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-ec473021-9539-4f46-9ddc-4a964c731f86,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-ae6b7118-7d1f-452b-8e4f-ad0feedc62e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-e33db386-0363-44ee-8858-388248020b16,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-eb01f396-831a-40ab-931b-9554f561b8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-93803044-338a-4250-a7de-b827e9380449,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-3e0f19ba-cea3-4f93-904a-7b53211a872c,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-919dfc9b-6b0e-4dee-aaf5-1f97a43f441b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183560348-172.17.0.5-1597295201771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42996,DS-4013fd78-8f7b-4649-8e09-e0fdfec9336f,DISK], DatanodeInfoWithStorage[127.0.0.1:42769,DS-ec473021-9539-4f46-9ddc-4a964c731f86,DISK], DatanodeInfoWithStorage[127.0.0.1:33333,DS-ae6b7118-7d1f-452b-8e4f-ad0feedc62e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-e33db386-0363-44ee-8858-388248020b16,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-eb01f396-831a-40ab-931b-9554f561b8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-93803044-338a-4250-a7de-b827e9380449,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-3e0f19ba-cea3-4f93-904a-7b53211a872c,DISK], DatanodeInfoWithStorage[127.0.0.1:39619,DS-919dfc9b-6b0e-4dee-aaf5-1f97a43f441b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203769498-172.17.0.5-1597295275215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43031,DS-1904d841-2042-486c-a524-c0ea7e94b860,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-aac00e04-7f84-43d0-8ead-a7b6299c970b,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-a9211c25-44b8-4aa7-ac9c-5461e7e07f50,DISK], DatanodeInfoWithStorage[127.0.0.1:44663,DS-45917907-9bd0-42d9-aec7-bb7a652bfbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-6c5e4280-6d6c-4a23-9797-ec3e887a41ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-eb39b9d7-ff55-4adf-94cd-9e6ad7c9d1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-ab5c1d44-3e2f-4366-a3c6-1e63c318558c,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-9a026be4-d1a6-4b92-ad27-e3d943169a4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1203769498-172.17.0.5-1597295275215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43031,DS-1904d841-2042-486c-a524-c0ea7e94b860,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-aac00e04-7f84-43d0-8ead-a7b6299c970b,DISK], DatanodeInfoWithStorage[127.0.0.1:43718,DS-a9211c25-44b8-4aa7-ac9c-5461e7e07f50,DISK], DatanodeInfoWithStorage[127.0.0.1:44663,DS-45917907-9bd0-42d9-aec7-bb7a652bfbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-6c5e4280-6d6c-4a23-9797-ec3e887a41ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-eb39b9d7-ff55-4adf-94cd-9e6ad7c9d1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37025,DS-ab5c1d44-3e2f-4366-a3c6-1e63c318558c,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-9a026be4-d1a6-4b92-ad27-e3d943169a4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 15 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5998
