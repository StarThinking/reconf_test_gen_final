reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1945096764-172.17.0.6-1597287447778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45692,DS-dda84c5d-5fbc-4fc0-afda-1802b96612df,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-272a943b-d43d-4ab9-96d8-f3cad30a1872,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-7d0f0fff-d3c2-4758-a066-529d7a61255e,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-20cfbfaa-0685-4813-aa49-dd95d2d17804,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-6cb875f8-10e3-4058-bd0d-7c052200f942,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-c8602eea-b4d8-44b9-a1b2-a4768e50fcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-7847270a-8276-4928-891b-384e02671d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-9ae791a6-99ac-4357-bce8-66eb983073d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1945096764-172.17.0.6-1597287447778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45692,DS-dda84c5d-5fbc-4fc0-afda-1802b96612df,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-272a943b-d43d-4ab9-96d8-f3cad30a1872,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-7d0f0fff-d3c2-4758-a066-529d7a61255e,DISK], DatanodeInfoWithStorage[127.0.0.1:37042,DS-20cfbfaa-0685-4813-aa49-dd95d2d17804,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-6cb875f8-10e3-4058-bd0d-7c052200f942,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-c8602eea-b4d8-44b9-a1b2-a4768e50fcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-7847270a-8276-4928-891b-384e02671d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-9ae791a6-99ac-4357-bce8-66eb983073d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-256571023-172.17.0.6-1597287576198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35475,DS-3ec7215b-f5af-44c9-b649-9bd97f9efb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-40683377-abfc-48e3-b6a1-319dc1a00119,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-c18f5d81-0608-44c2-a700-93879aaa5bed,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-607cfd29-79ca-48fc-8624-0c4296b89d10,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-e319096e-8f90-4e0c-aa26-9d8b3479f0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-01732e83-f4a9-48d0-bd5e-6cb8c4acca6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-6a981bd5-acbc-4617-b366-656f7364e178,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-f7e03ec0-bec3-4799-ad0f-73f0ebabef73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-256571023-172.17.0.6-1597287576198:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35475,DS-3ec7215b-f5af-44c9-b649-9bd97f9efb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-40683377-abfc-48e3-b6a1-319dc1a00119,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-c18f5d81-0608-44c2-a700-93879aaa5bed,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-607cfd29-79ca-48fc-8624-0c4296b89d10,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-e319096e-8f90-4e0c-aa26-9d8b3479f0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-01732e83-f4a9-48d0-bd5e-6cb8c4acca6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36315,DS-6a981bd5-acbc-4617-b366-656f7364e178,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-f7e03ec0-bec3-4799-ad0f-73f0ebabef73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1380656930-172.17.0.6-1597287734094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37845,DS-537c6566-1cf2-4c0e-8f0e-4c8e6e2200de,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-3117763a-b389-4edc-8d89-a0ba431cf657,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-13413bf3-2fdd-4b82-ab9c-31c32e93a974,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-f4cc1b27-b4f5-4b0b-a3db-a702b4e90b57,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-51ff114c-5dbb-4ee2-bef7-a4ab126db880,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-e52774a5-ec59-406d-89e0-2a33df9f2453,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-47bdea29-a536-491b-9f67-4fad006e18b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-895dd8a2-4656-441a-a7a0-c8342c4a9f2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1380656930-172.17.0.6-1597287734094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37845,DS-537c6566-1cf2-4c0e-8f0e-4c8e6e2200de,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-3117763a-b389-4edc-8d89-a0ba431cf657,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-13413bf3-2fdd-4b82-ab9c-31c32e93a974,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-f4cc1b27-b4f5-4b0b-a3db-a702b4e90b57,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-51ff114c-5dbb-4ee2-bef7-a4ab126db880,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-e52774a5-ec59-406d-89e0-2a33df9f2453,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-47bdea29-a536-491b-9f67-4fad006e18b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-895dd8a2-4656-441a-a7a0-c8342c4a9f2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-152962185-172.17.0.6-1597287862832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37405,DS-b4b9ccd6-b733-4020-a1d5-01cb4a4beff9,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-1de2e61b-ca4c-40b7-94df-05005b34f69a,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-60f24b89-7b0e-4c9a-86d1-4bcdceec7a71,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-4db28fa4-8360-4841-816e-1e9305f5c9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-4010bb2d-be5d-4cfa-a6a5-3e6c720bc3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-db22cd87-975e-4d2a-8b8f-541982745e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-bbb120e6-8529-4244-bfc7-b7ff33796635,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-e58ea16e-5c9c-4ccd-b53e-08839cb4e3b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-152962185-172.17.0.6-1597287862832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37405,DS-b4b9ccd6-b733-4020-a1d5-01cb4a4beff9,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-1de2e61b-ca4c-40b7-94df-05005b34f69a,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-60f24b89-7b0e-4c9a-86d1-4bcdceec7a71,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-4db28fa4-8360-4841-816e-1e9305f5c9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-4010bb2d-be5d-4cfa-a6a5-3e6c720bc3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-db22cd87-975e-4d2a-8b8f-541982745e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36127,DS-bbb120e6-8529-4244-bfc7-b7ff33796635,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-e58ea16e-5c9c-4ccd-b53e-08839cb4e3b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-583549906-172.17.0.6-1597287949749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45310,DS-e4b08594-bec8-4773-8d30-41b29f33d1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-a864cfc1-77d3-41c5-bce8-e4b5470f2f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-a462b698-6270-4c6c-a1bd-5c27ea2e54d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-b357b605-f04d-42d2-9044-233511fea00c,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-68dcd4e4-f869-4735-8f08-de42b00d46aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-b937105f-c2e8-4e9f-9748-1b090b6a7cad,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-66fda624-aad4-4139-ad7f-586a2b9bd484,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-57e53e2a-642f-4d39-8c58-2bff7ecee14e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-583549906-172.17.0.6-1597287949749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45310,DS-e4b08594-bec8-4773-8d30-41b29f33d1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-a864cfc1-77d3-41c5-bce8-e4b5470f2f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36320,DS-a462b698-6270-4c6c-a1bd-5c27ea2e54d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-b357b605-f04d-42d2-9044-233511fea00c,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-68dcd4e4-f869-4735-8f08-de42b00d46aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-b937105f-c2e8-4e9f-9748-1b090b6a7cad,DISK], DatanodeInfoWithStorage[127.0.0.1:41904,DS-66fda624-aad4-4139-ad7f-586a2b9bd484,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-57e53e2a-642f-4d39-8c58-2bff7ecee14e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006830848-172.17.0.6-1597288150548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38810,DS-0fb5bfae-1ffb-4b9a-80dd-74affe7f8ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-03d57569-708e-41ef-a369-a176dfbcc62e,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-bb96522e-8668-4795-bb9e-1ca46740cfab,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-3094973f-7049-4be7-8cdb-defcf1fdbffd,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-ff631765-804a-49ee-adeb-6112be90aeda,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-440ab177-e11d-4e01-9793-5840e264e87a,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-240ccc2b-f983-4a90-b14a-9c829dc11537,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-24b27e8d-7019-4605-be28-583872e21c40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006830848-172.17.0.6-1597288150548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38810,DS-0fb5bfae-1ffb-4b9a-80dd-74affe7f8ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-03d57569-708e-41ef-a369-a176dfbcc62e,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-bb96522e-8668-4795-bb9e-1ca46740cfab,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-3094973f-7049-4be7-8cdb-defcf1fdbffd,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-ff631765-804a-49ee-adeb-6112be90aeda,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-440ab177-e11d-4e01-9793-5840e264e87a,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-240ccc2b-f983-4a90-b14a-9c829dc11537,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-24b27e8d-7019-4605-be28-583872e21c40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1586055412-172.17.0.6-1597288588498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44272,DS-e14ca95d-0871-4121-baef-850ff3ac6f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-a1f01379-afdf-4926-9e16-fba57c5e745c,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-d22b7212-90f0-460e-b383-9caaca4b481a,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-3651ce7b-e685-4014-8572-dc77f70ea205,DISK], DatanodeInfoWithStorage[127.0.0.1:45005,DS-3553ac0e-3552-454f-b82c-94fc62bf7513,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-2741610e-5e3f-47ae-83bb-2b9dd9ffabe7,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-4db21ba7-4d90-416c-a5ef-5a4f94313379,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-3722c249-1495-4f93-89e2-dd84f0b068e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1586055412-172.17.0.6-1597288588498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44272,DS-e14ca95d-0871-4121-baef-850ff3ac6f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-a1f01379-afdf-4926-9e16-fba57c5e745c,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-d22b7212-90f0-460e-b383-9caaca4b481a,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-3651ce7b-e685-4014-8572-dc77f70ea205,DISK], DatanodeInfoWithStorage[127.0.0.1:45005,DS-3553ac0e-3552-454f-b82c-94fc62bf7513,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-2741610e-5e3f-47ae-83bb-2b9dd9ffabe7,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-4db21ba7-4d90-416c-a5ef-5a4f94313379,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-3722c249-1495-4f93-89e2-dd84f0b068e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1617973727-172.17.0.6-1597288831230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33998,DS-1ae0c34e-b5f2-4c99-8c32-8cfc148c3e59,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-4059c95a-7e31-46c9-b41b-250905074424,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-041c7a5b-c74e-4072-a164-6efc58bbf59c,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-7c05d460-15e0-41d6-bc7e-96e1aa007e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-3974e1fe-f4aa-4a60-a470-227caefdd228,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-48b022e5-af1f-415e-bbce-3e4ed629fb30,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-8b02579a-9a6a-4054-b1f5-2db432ecc673,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-1494f0a5-09ab-4dfe-b078-1a540b3376ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1617973727-172.17.0.6-1597288831230:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33998,DS-1ae0c34e-b5f2-4c99-8c32-8cfc148c3e59,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-4059c95a-7e31-46c9-b41b-250905074424,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-041c7a5b-c74e-4072-a164-6efc58bbf59c,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-7c05d460-15e0-41d6-bc7e-96e1aa007e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-3974e1fe-f4aa-4a60-a470-227caefdd228,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-48b022e5-af1f-415e-bbce-3e4ed629fb30,DISK], DatanodeInfoWithStorage[127.0.0.1:40634,DS-8b02579a-9a6a-4054-b1f5-2db432ecc673,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-1494f0a5-09ab-4dfe-b078-1a540b3376ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-548983181-172.17.0.6-1597288985043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46498,DS-b33d2a29-bc8c-4de9-8bfb-c8a05a9655b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-2d33b5fe-db9e-4110-8bfe-25578b77ca37,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-d450b015-b374-4b65-8a55-743a9cbdc97e,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-eb5b8a8d-b5bf-41e0-ad63-6ef4a4d55ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-d43afbc3-a017-4d3e-8af5-78418c50a9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-db860caa-2fc2-46ea-8ae7-3ae8cc9abf67,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-b5ea2545-9f6e-44c6-810c-966744e23bce,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-5c279513-8944-4bac-859d-6787822ba099,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-548983181-172.17.0.6-1597288985043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46498,DS-b33d2a29-bc8c-4de9-8bfb-c8a05a9655b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-2d33b5fe-db9e-4110-8bfe-25578b77ca37,DISK], DatanodeInfoWithStorage[127.0.0.1:44529,DS-d450b015-b374-4b65-8a55-743a9cbdc97e,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-eb5b8a8d-b5bf-41e0-ad63-6ef4a4d55ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-d43afbc3-a017-4d3e-8af5-78418c50a9a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-db860caa-2fc2-46ea-8ae7-3ae8cc9abf67,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-b5ea2545-9f6e-44c6-810c-966744e23bce,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-5c279513-8944-4bac-859d-6787822ba099,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-218064051-172.17.0.6-1597289150175:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46536,DS-998caafe-ba1c-4bbe-9f77-7f9188c6a533,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-70657a99-e9a3-4877-8545-1212c0b6e14a,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-f4f1a64c-81a7-444e-9a8a-0a35b4757c34,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-c4580ab4-710a-4dc7-b750-e1322b6bb209,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-81c8d7ec-03bb-46e5-9b1a-b13b4d0b1b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-1de2210d-089a-406a-a285-e9cfd35a01f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-d790d5d6-083b-4ad8-be54-7dc3cb82fb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-3acc9f01-a69d-4394-9f86-499bde9cf611,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-218064051-172.17.0.6-1597289150175:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46536,DS-998caafe-ba1c-4bbe-9f77-7f9188c6a533,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-70657a99-e9a3-4877-8545-1212c0b6e14a,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-f4f1a64c-81a7-444e-9a8a-0a35b4757c34,DISK], DatanodeInfoWithStorage[127.0.0.1:38963,DS-c4580ab4-710a-4dc7-b750-e1322b6bb209,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-81c8d7ec-03bb-46e5-9b1a-b13b4d0b1b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-1de2210d-089a-406a-a285-e9cfd35a01f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-d790d5d6-083b-4ad8-be54-7dc3cb82fb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-3acc9f01-a69d-4394-9f86-499bde9cf611,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-208457589-172.17.0.6-1597289187813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34433,DS-8a593ba8-2dfa-4c28-b95c-e361abf6dde6,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-683de6de-d08a-419a-867f-785695e3f6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-9a7c9ee1-baa0-40b8-b0d8-9a9d462163f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-c3761c80-ba45-4dde-a68d-ac730c51f8be,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-a42b76ce-1d37-40d0-bd7a-bd521d26da7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-3336ef85-4d0b-4dcf-9a15-8c59373f67a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-01e18613-1ff2-428a-8818-356ee32854ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-a1011c92-980a-4a5d-9559-a5bd3f6ed6b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-208457589-172.17.0.6-1597289187813:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34433,DS-8a593ba8-2dfa-4c28-b95c-e361abf6dde6,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-683de6de-d08a-419a-867f-785695e3f6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-9a7c9ee1-baa0-40b8-b0d8-9a9d462163f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-c3761c80-ba45-4dde-a68d-ac730c51f8be,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-a42b76ce-1d37-40d0-bd7a-bd521d26da7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-3336ef85-4d0b-4dcf-9a15-8c59373f67a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-01e18613-1ff2-428a-8818-356ee32854ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-a1011c92-980a-4a5d-9559-a5bd3f6ed6b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-269460529-172.17.0.6-1597289802114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33590,DS-a3269506-fb54-478b-adc9-aef2e721e06e,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-b00c25e9-f9e5-4432-8020-b6a2873fb22a,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-de4097f9-ecc8-4180-9f22-c13c356252f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-83b731fb-1025-4313-bfc4-3bbd8b98fbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-da3ca90a-7768-4efc-9ab6-978a21246457,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-f5880cb8-28d3-4871-99ba-5dd398ce6bce,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-07bd0af2-1320-4ddb-a2bd-8f22faf01442,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-7e794b26-cd92-43cf-8ae4-4d10111a5977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-269460529-172.17.0.6-1597289802114:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33590,DS-a3269506-fb54-478b-adc9-aef2e721e06e,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-b00c25e9-f9e5-4432-8020-b6a2873fb22a,DISK], DatanodeInfoWithStorage[127.0.0.1:38585,DS-de4097f9-ecc8-4180-9f22-c13c356252f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-83b731fb-1025-4313-bfc4-3bbd8b98fbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-da3ca90a-7768-4efc-9ab6-978a21246457,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-f5880cb8-28d3-4871-99ba-5dd398ce6bce,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-07bd0af2-1320-4ddb-a2bd-8f22faf01442,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-7e794b26-cd92-43cf-8ae4-4d10111a5977,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1539238806-172.17.0.6-1597289841877:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37403,DS-d7bf2206-fb54-4598-9e99-5d99db177d21,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-4d4acd87-c44d-4bde-b1f6-da26ef8dd107,DISK], DatanodeInfoWithStorage[127.0.0.1:34944,DS-ffc66027-2121-4bae-b559-7e74dcd1ede1,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-9135df47-427d-433f-b9d8-4f38a1535124,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-7601adda-8d28-4745-b860-df5c848202e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-e67790bb-ec9e-4a20-b7ce-3a09b0f3715c,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-59dd4c26-8899-4bc5-be3e-2dc6cede78c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-83972fbd-30d1-4c76-b97e-b40c2bdd2c3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1539238806-172.17.0.6-1597289841877:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37403,DS-d7bf2206-fb54-4598-9e99-5d99db177d21,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-4d4acd87-c44d-4bde-b1f6-da26ef8dd107,DISK], DatanodeInfoWithStorage[127.0.0.1:34944,DS-ffc66027-2121-4bae-b559-7e74dcd1ede1,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-9135df47-427d-433f-b9d8-4f38a1535124,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-7601adda-8d28-4745-b860-df5c848202e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37643,DS-e67790bb-ec9e-4a20-b7ce-3a09b0f3715c,DISK], DatanodeInfoWithStorage[127.0.0.1:42878,DS-59dd4c26-8899-4bc5-be3e-2dc6cede78c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-83972fbd-30d1-4c76-b97e-b40c2bdd2c3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1767117142-172.17.0.6-1597290318498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43122,DS-be13ba96-f40f-499f-b4e3-ae35f8dd4b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-406d214f-04ff-499a-b24f-3ef34dda6a04,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-512beaaf-b66e-405d-9d8d-18ba190a6369,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-15783f26-50d0-4360-ba10-8834ed646639,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-bd0ca574-bced-46bb-8b14-44a6cd7353df,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-9537c367-79b6-43ff-ae66-3559bead7f70,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-e6e2c400-1613-4f83-b90c-3e283b366c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-abf1eb42-f450-4b65-a98f-5d46d3746561,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1767117142-172.17.0.6-1597290318498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43122,DS-be13ba96-f40f-499f-b4e3-ae35f8dd4b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-406d214f-04ff-499a-b24f-3ef34dda6a04,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-512beaaf-b66e-405d-9d8d-18ba190a6369,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-15783f26-50d0-4360-ba10-8834ed646639,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-bd0ca574-bced-46bb-8b14-44a6cd7353df,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-9537c367-79b6-43ff-ae66-3559bead7f70,DISK], DatanodeInfoWithStorage[127.0.0.1:38397,DS-e6e2c400-1613-4f83-b90c-3e283b366c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-abf1eb42-f450-4b65-a98f-5d46d3746561,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-536226445-172.17.0.6-1597290435115:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41089,DS-9e5e34d2-4b88-44f1-9db5-c1c7497bf089,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-a3f385ff-e4de-4328-87e0-69e41d3b7579,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-7cff0d35-6b12-4c2e-bec2-278731aa1420,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-27754adc-fdc3-4242-8fae-8a20a26c5d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-d99d2223-7e10-4fef-94ad-72a32d2c1b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-02980527-e5aa-4c2d-ab08-80a99a61a16d,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-fb439f6c-80a6-462d-8149-fca5353d8151,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-7c799ced-19ed-4ffb-aacd-8f9140d50410,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-536226445-172.17.0.6-1597290435115:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41089,DS-9e5e34d2-4b88-44f1-9db5-c1c7497bf089,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-a3f385ff-e4de-4328-87e0-69e41d3b7579,DISK], DatanodeInfoWithStorage[127.0.0.1:45276,DS-7cff0d35-6b12-4c2e-bec2-278731aa1420,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-27754adc-fdc3-4242-8fae-8a20a26c5d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-d99d2223-7e10-4fef-94ad-72a32d2c1b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-02980527-e5aa-4c2d-ab08-80a99a61a16d,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-fb439f6c-80a6-462d-8149-fca5353d8151,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-7c799ced-19ed-4ffb-aacd-8f9140d50410,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1102948657-172.17.0.6-1597290552036:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44051,DS-dfa485b4-8a92-440b-82c8-ed727e69176a,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-aaf3acb2-75eb-49ce-8974-40ac911f4cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-afceafb3-f74f-478c-af18-78d4d9d07c23,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-f46fe5ab-91bc-4d8d-aa93-61dd5043b300,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-d0bf9298-4d02-4f28-a277-eb718eac6ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-2cd44b50-7c72-4ac8-b42a-121f0dea6e19,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-32a11fde-cf18-4c5a-8717-05dedda3fb13,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-7f2de579-c45d-4c06-b9fb-557505406222,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1102948657-172.17.0.6-1597290552036:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44051,DS-dfa485b4-8a92-440b-82c8-ed727e69176a,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-aaf3acb2-75eb-49ce-8974-40ac911f4cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-afceafb3-f74f-478c-af18-78d4d9d07c23,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-f46fe5ab-91bc-4d8d-aa93-61dd5043b300,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-d0bf9298-4d02-4f28-a277-eb718eac6ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-2cd44b50-7c72-4ac8-b42a-121f0dea6e19,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-32a11fde-cf18-4c5a-8717-05dedda3fb13,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-7f2de579-c45d-4c06-b9fb-557505406222,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1059617193-172.17.0.6-1597290711232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33764,DS-8b86b012-745b-4a0b-a6db-378e25575cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-59dfa37f-1c7a-449e-8de0-1dc999adc48e,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-974ca5c2-153a-42b3-8a1c-65c6041a45a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-ff53507e-13b2-41a7-b4b5-61daf8e58f11,DISK], DatanodeInfoWithStorage[127.0.0.1:43641,DS-db3b97ad-4ab0-4f65-b40f-8e4732ee7378,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-b726701e-52c0-4f4d-b8a4-29ac2f9f4be1,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-ce4bf141-5d0a-4b8f-9e62-76a4bd534ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-2b146201-b37e-45c5-8af2-1b56ec3ddfff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1059617193-172.17.0.6-1597290711232:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33764,DS-8b86b012-745b-4a0b-a6db-378e25575cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-59dfa37f-1c7a-449e-8de0-1dc999adc48e,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-974ca5c2-153a-42b3-8a1c-65c6041a45a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-ff53507e-13b2-41a7-b4b5-61daf8e58f11,DISK], DatanodeInfoWithStorage[127.0.0.1:43641,DS-db3b97ad-4ab0-4f65-b40f-8e4732ee7378,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-b726701e-52c0-4f4d-b8a4-29ac2f9f4be1,DISK], DatanodeInfoWithStorage[127.0.0.1:42800,DS-ce4bf141-5d0a-4b8f-9e62-76a4bd534ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-2b146201-b37e-45c5-8af2-1b56ec3ddfff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1100066068-172.17.0.6-1597290987701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36247,DS-1afe5762-253f-4a97-8574-16182217f40b,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-bfa83aeb-8274-40bd-abc5-89ba822b356a,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-7e611d8b-fafb-4c2b-bdd7-cf2460d1eb88,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-abe8e68d-4a83-4606-ab75-c029f2f2043f,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-5db6fbbc-6ba9-4af7-994e-04cbe91ec831,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-93c059f3-e0f1-4d9d-b30a-93fbd765ce50,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-f696f232-54df-4917-8a56-858a60ea5141,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-c07a4295-7d2f-443d-8fda-2fbea7fd03f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1100066068-172.17.0.6-1597290987701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36247,DS-1afe5762-253f-4a97-8574-16182217f40b,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-bfa83aeb-8274-40bd-abc5-89ba822b356a,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-7e611d8b-fafb-4c2b-bdd7-cf2460d1eb88,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-abe8e68d-4a83-4606-ab75-c029f2f2043f,DISK], DatanodeInfoWithStorage[127.0.0.1:37685,DS-5db6fbbc-6ba9-4af7-994e-04cbe91ec831,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-93c059f3-e0f1-4d9d-b30a-93fbd765ce50,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-f696f232-54df-4917-8a56-858a60ea5141,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-c07a4295-7d2f-443d-8fda-2fbea7fd03f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1788851979-172.17.0.6-1597292382826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46421,DS-bb16d6c6-c8f3-4ac8-96e6-2a3c9c310412,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-e80ac888-675b-4f68-ac86-6b38d7d8f61c,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-3cbad074-6b3d-4c1a-87fd-ca6df2c641ca,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-7df55e2b-83f8-4488-b5a0-5b100cdbbe40,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-acde03ed-f852-469f-b72c-4b42d0de094c,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-6685fee3-6827-4da9-a1d6-dd799b1430c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-5335bd37-62a6-4e45-9918-6467578b304d,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-b7725390-e107-4406-afce-1c9599fbb2de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1788851979-172.17.0.6-1597292382826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46421,DS-bb16d6c6-c8f3-4ac8-96e6-2a3c9c310412,DISK], DatanodeInfoWithStorage[127.0.0.1:40350,DS-e80ac888-675b-4f68-ac86-6b38d7d8f61c,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-3cbad074-6b3d-4c1a-87fd-ca6df2c641ca,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-7df55e2b-83f8-4488-b5a0-5b100cdbbe40,DISK], DatanodeInfoWithStorage[127.0.0.1:42410,DS-acde03ed-f852-469f-b72c-4b42d0de094c,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-6685fee3-6827-4da9-a1d6-dd799b1430c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-5335bd37-62a6-4e45-9918-6467578b304d,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-b7725390-e107-4406-afce-1c9599fbb2de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1081336836-172.17.0.6-1597292504868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38628,DS-1942108d-745f-4eb1-bb2a-fad1a0f7bcbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-bf2b4f2d-38a9-4835-90ef-a20ed327c59e,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-2e8cb809-addb-4446-bbd3-172d28d24d01,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-eb077595-423c-46a6-96a7-3fdae96687b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-8b216c5f-3c36-4eee-868b-3ef6cd50c4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-c7051d5d-9d3d-433b-9aac-0b9fbc1b5246,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-feec8ad7-6c73-4c53-bb3c-788fc2471e75,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-e2fb8b75-c887-49db-b407-dd0d6236ef15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1081336836-172.17.0.6-1597292504868:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38628,DS-1942108d-745f-4eb1-bb2a-fad1a0f7bcbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-bf2b4f2d-38a9-4835-90ef-a20ed327c59e,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-2e8cb809-addb-4446-bbd3-172d28d24d01,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-eb077595-423c-46a6-96a7-3fdae96687b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39066,DS-8b216c5f-3c36-4eee-868b-3ef6cd50c4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-c7051d5d-9d3d-433b-9aac-0b9fbc1b5246,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-feec8ad7-6c73-4c53-bb3c-788fc2471e75,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-e2fb8b75-c887-49db-b407-dd0d6236ef15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5934
