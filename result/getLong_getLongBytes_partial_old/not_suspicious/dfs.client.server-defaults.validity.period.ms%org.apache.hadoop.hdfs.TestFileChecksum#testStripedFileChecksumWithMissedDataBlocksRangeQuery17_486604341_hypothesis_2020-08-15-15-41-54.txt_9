reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-313049133-172.17.0.6-1597506277284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42503,DS-c424f718-f6d4-4d54-b5a5-f50b654b87b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-10d2e9d5-8316-4118-9448-b39f1e6a8603,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-89a44322-b9ab-4c61-bb99-0b64a23436c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-d5cffa24-a94e-4c9a-8660-dc04e7f20efe,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-10a1aa53-03e5-4b00-9a1a-934cea5979a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-f5c385ff-641d-4323-9a9a-ab6138de6f43,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-4858bc0b-6792-4bf5-b36d-9f8be0fd7528,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-5081ed10-cbba-41b7-b8d7-da5bc79d8b4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-313049133-172.17.0.6-1597506277284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42503,DS-c424f718-f6d4-4d54-b5a5-f50b654b87b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-10d2e9d5-8316-4118-9448-b39f1e6a8603,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-89a44322-b9ab-4c61-bb99-0b64a23436c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-d5cffa24-a94e-4c9a-8660-dc04e7f20efe,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-10a1aa53-03e5-4b00-9a1a-934cea5979a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-f5c385ff-641d-4323-9a9a-ab6138de6f43,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-4858bc0b-6792-4bf5-b36d-9f8be0fd7528,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-5081ed10-cbba-41b7-b8d7-da5bc79d8b4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1181060639-172.17.0.6-1597506549505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43876,DS-a03d0230-1215-44ec-98b4-a9a60a24a486,DISK], DatanodeInfoWithStorage[127.0.0.1:35127,DS-2a7a1a7b-9a05-4d7c-a9cb-18d2bd328adb,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-63080101-9998-4bc3-af40-e73a4d6d37a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-bdf2c693-27d9-45ec-b83d-5f4e6ddb119f,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-c732f40b-06bc-4a44-8028-5b0c7ce0a03c,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-48667144-7a16-47c8-8dc9-6fb58f07942e,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-9624d451-67fa-40cc-954d-d1282348dd78,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-7b84151e-cf14-414f-b1ec-9ce926de859e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1181060639-172.17.0.6-1597506549505:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43876,DS-a03d0230-1215-44ec-98b4-a9a60a24a486,DISK], DatanodeInfoWithStorage[127.0.0.1:35127,DS-2a7a1a7b-9a05-4d7c-a9cb-18d2bd328adb,DISK], DatanodeInfoWithStorage[127.0.0.1:33973,DS-63080101-9998-4bc3-af40-e73a4d6d37a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-bdf2c693-27d9-45ec-b83d-5f4e6ddb119f,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-c732f40b-06bc-4a44-8028-5b0c7ce0a03c,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-48667144-7a16-47c8-8dc9-6fb58f07942e,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-9624d451-67fa-40cc-954d-d1282348dd78,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-7b84151e-cf14-414f-b1ec-9ce926de859e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1716518858-172.17.0.6-1597507450375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34585,DS-8ff8dad8-dfbb-4353-b2c3-97ebdf630805,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-e7084179-18db-449d-87ec-f802bb53e475,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-367fcd48-084d-4fa5-b210-12010d05cdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-b8dcd530-60db-4440-8acb-8c68c06f86cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-d015111a-ee4e-4e36-b79e-9c439f11d0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-64146214-5f0c-4ac2-9400-d384a4ef99ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-bb4e6923-cc8b-4e88-927d-c9935141f4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-9277a00e-5aa5-4955-bdd2-b95bc50b73fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1716518858-172.17.0.6-1597507450375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34585,DS-8ff8dad8-dfbb-4353-b2c3-97ebdf630805,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-e7084179-18db-449d-87ec-f802bb53e475,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-367fcd48-084d-4fa5-b210-12010d05cdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-b8dcd530-60db-4440-8acb-8c68c06f86cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-d015111a-ee4e-4e36-b79e-9c439f11d0e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-64146214-5f0c-4ac2-9400-d384a4ef99ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-bb4e6923-cc8b-4e88-927d-c9935141f4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-9277a00e-5aa5-4955-bdd2-b95bc50b73fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-23259402-172.17.0.6-1597507819634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43297,DS-33dae4c7-46ed-4599-b4e4-0f1449a65ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-46bf7555-e416-440b-8fa7-bf6b19cd9c61,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-b0977e7a-a636-407a-a7f8-f7305a09ac14,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-9f9e46e2-f00d-4dc9-9182-fcfd6af7e7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-a7bc5977-61a3-47f4-ab7f-996c5b90c1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45112,DS-dc9200de-335d-4608-9c53-1cb83f4adacf,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-29fa0f58-2a3d-4740-b212-a9567b02df15,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-8e284b4b-5726-453c-8975-3a44e26443d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-23259402-172.17.0.6-1597507819634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43297,DS-33dae4c7-46ed-4599-b4e4-0f1449a65ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-46bf7555-e416-440b-8fa7-bf6b19cd9c61,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-b0977e7a-a636-407a-a7f8-f7305a09ac14,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-9f9e46e2-f00d-4dc9-9182-fcfd6af7e7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-a7bc5977-61a3-47f4-ab7f-996c5b90c1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45112,DS-dc9200de-335d-4608-9c53-1cb83f4adacf,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-29fa0f58-2a3d-4740-b212-a9567b02df15,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-8e284b4b-5726-453c-8975-3a44e26443d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-342643411-172.17.0.6-1597508399952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34033,DS-268d2e51-b0a2-4b13-b79e-b002f75ec32b,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-d824d4e3-5f23-4e70-b6e1-ed016000cc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-cdac984b-c8fb-479b-9b1b-89817a76d6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-92d63017-0098-4e9c-b473-c5d3a63b62a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-43ea739e-f850-45b4-a2e1-f9e34c66263e,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-011530d0-fcf9-482a-8c00-1c8a56f1ee22,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-4c19c2e8-c7b5-4165-a2c4-c8598b318490,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-68ebcba4-27a6-41ab-b994-de3f0eca8a5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-342643411-172.17.0.6-1597508399952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34033,DS-268d2e51-b0a2-4b13-b79e-b002f75ec32b,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-d824d4e3-5f23-4e70-b6e1-ed016000cc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-cdac984b-c8fb-479b-9b1b-89817a76d6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-92d63017-0098-4e9c-b473-c5d3a63b62a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-43ea739e-f850-45b4-a2e1-f9e34c66263e,DISK], DatanodeInfoWithStorage[127.0.0.1:37522,DS-011530d0-fcf9-482a-8c00-1c8a56f1ee22,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-4c19c2e8-c7b5-4165-a2c4-c8598b318490,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-68ebcba4-27a6-41ab-b994-de3f0eca8a5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-877966476-172.17.0.6-1597508753334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40966,DS-6bfd3029-00fa-4487-9fd4-a5e378fccd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-5b4bda58-55df-458a-87eb-0cfe5511d790,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-ca2621ea-4665-444f-bb6c-4c1d4b1c3984,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-dcfa6eb3-4237-4b29-9961-bdd9ba63c8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-3269908a-dfe5-44dc-a1ae-07389112ec1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-aef9f887-e6ef-48d2-80e6-962368aa57cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-c6fe564a-d8f3-4a38-98bf-7c5f2dcff99f,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-27569796-59ce-454c-a6f0-384e623adc4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-877966476-172.17.0.6-1597508753334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40966,DS-6bfd3029-00fa-4487-9fd4-a5e378fccd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-5b4bda58-55df-458a-87eb-0cfe5511d790,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-ca2621ea-4665-444f-bb6c-4c1d4b1c3984,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-dcfa6eb3-4237-4b29-9961-bdd9ba63c8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-3269908a-dfe5-44dc-a1ae-07389112ec1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-aef9f887-e6ef-48d2-80e6-962368aa57cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-c6fe564a-d8f3-4a38-98bf-7c5f2dcff99f,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-27569796-59ce-454c-a6f0-384e623adc4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1981078885-172.17.0.6-1597508868456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41352,DS-29837b18-ad1e-4344-9e65-783b351d7e88,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-2e237557-0b78-483d-a738-64bfcf7421a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-5dbf604b-cbe2-44d7-bf9b-1176ed5ff95d,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-6ec75494-255a-497c-9ba5-150e89776580,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-712f1cba-00c5-481b-8d10-2e66e5c43eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-72975488-6b7d-4ea4-ab7a-3c231fd21eee,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-1f25c9d4-f3ef-4975-8175-0f287613c6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-be1fa3a1-1106-46ee-b983-efa8db0ee653,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1981078885-172.17.0.6-1597508868456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41352,DS-29837b18-ad1e-4344-9e65-783b351d7e88,DISK], DatanodeInfoWithStorage[127.0.0.1:32817,DS-2e237557-0b78-483d-a738-64bfcf7421a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-5dbf604b-cbe2-44d7-bf9b-1176ed5ff95d,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-6ec75494-255a-497c-9ba5-150e89776580,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-712f1cba-00c5-481b-8d10-2e66e5c43eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-72975488-6b7d-4ea4-ab7a-3c231fd21eee,DISK], DatanodeInfoWithStorage[127.0.0.1:43812,DS-1f25c9d4-f3ef-4975-8175-0f287613c6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-be1fa3a1-1106-46ee-b983-efa8db0ee653,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-216095735-172.17.0.6-1597508933333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35366,DS-1c890e05-3191-4ac2-bed1-e21ea10ec161,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-c5316876-17d9-4a73-96be-10f2c0e9d0a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-680ed6a4-1a37-4e4c-8bcd-40dd23b893d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-fcd092d5-2293-4311-b6b3-b3e1a6676e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-3985de4f-f9d3-438b-8352-efee639f9033,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-58058bac-5078-4d4a-94f0-91ab81a49d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-c4470b36-3001-4462-a299-b5b48093c1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-48a4d3d1-ca90-46b5-9015-dfbc25f1cd94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-216095735-172.17.0.6-1597508933333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35366,DS-1c890e05-3191-4ac2-bed1-e21ea10ec161,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-c5316876-17d9-4a73-96be-10f2c0e9d0a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-680ed6a4-1a37-4e4c-8bcd-40dd23b893d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-fcd092d5-2293-4311-b6b3-b3e1a6676e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-3985de4f-f9d3-438b-8352-efee639f9033,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-58058bac-5078-4d4a-94f0-91ab81a49d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46509,DS-c4470b36-3001-4462-a299-b5b48093c1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-48a4d3d1-ca90-46b5-9015-dfbc25f1cd94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1843926216-172.17.0.6-1597509114256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41986,DS-66869d35-efd6-472e-8978-5187b3cd96f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-0a1aca8c-22c9-49d7-8564-65dd6d32d752,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-ff4cd831-ff2f-4e70-8cd8-550fe7691736,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-8d81bea7-c1c3-4fc1-b644-6bfd482d2bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-5695156e-e2d7-4293-839e-220d8a05ff3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-e9b58258-b66b-4c41-b468-b220118ec76b,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-34af1239-e0d5-4dfc-8353-752eb6757f48,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-8b7519e3-4576-46bf-a3e7-3925d340721a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1843926216-172.17.0.6-1597509114256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41986,DS-66869d35-efd6-472e-8978-5187b3cd96f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-0a1aca8c-22c9-49d7-8564-65dd6d32d752,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-ff4cd831-ff2f-4e70-8cd8-550fe7691736,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-8d81bea7-c1c3-4fc1-b644-6bfd482d2bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-5695156e-e2d7-4293-839e-220d8a05ff3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-e9b58258-b66b-4c41-b468-b220118ec76b,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-34af1239-e0d5-4dfc-8353-752eb6757f48,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-8b7519e3-4576-46bf-a3e7-3925d340721a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1164111080-172.17.0.6-1597509502608:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43180,DS-15b58c45-76cb-4d3e-a70b-d58efdd45516,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-39586ce5-e955-4abd-b093-0502ff56e1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-80364f72-441c-466d-9f13-15722fe2c64b,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-09ee12c4-1db8-470d-a4e6-046cedd085b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-87913e50-ae49-4550-ae41-9e36e36f00ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-300ffb1d-3af3-4ba4-8e1d-0423dd5e1d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-1fee8299-6c85-422a-a1df-2a12d9b01f78,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-7578a545-6b3a-4630-953f-8c6100cd9898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1164111080-172.17.0.6-1597509502608:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43180,DS-15b58c45-76cb-4d3e-a70b-d58efdd45516,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-39586ce5-e955-4abd-b093-0502ff56e1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42641,DS-80364f72-441c-466d-9f13-15722fe2c64b,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-09ee12c4-1db8-470d-a4e6-046cedd085b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-87913e50-ae49-4550-ae41-9e36e36f00ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-300ffb1d-3af3-4ba4-8e1d-0423dd5e1d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-1fee8299-6c85-422a-a1df-2a12d9b01f78,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-7578a545-6b3a-4630-953f-8c6100cd9898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2086596169-172.17.0.6-1597509655348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37823,DS-f2915cda-69cb-4229-94f6-85967c48c0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-5e20305f-439c-4cb9-ac06-b55292a31c95,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-7a3cec40-eec6-4ea6-a73e-3ecc22d5b093,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-ee4f26c5-e09c-40fb-9a0c-bed2bad1c97c,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-84992558-7f08-49d9-a010-dd0d88d8285b,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-e4e42421-103d-4ffc-889d-e690d8ff9334,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-587ee50c-8199-4750-b30f-397b188092f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-c0e12fbf-a40e-4bf2-b8fe-45c0aaa1a7e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2086596169-172.17.0.6-1597509655348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37823,DS-f2915cda-69cb-4229-94f6-85967c48c0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-5e20305f-439c-4cb9-ac06-b55292a31c95,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-7a3cec40-eec6-4ea6-a73e-3ecc22d5b093,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-ee4f26c5-e09c-40fb-9a0c-bed2bad1c97c,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-84992558-7f08-49d9-a010-dd0d88d8285b,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-e4e42421-103d-4ffc-889d-e690d8ff9334,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-587ee50c-8199-4750-b30f-397b188092f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42674,DS-c0e12fbf-a40e-4bf2-b8fe-45c0aaa1a7e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-313866317-172.17.0.6-1597510339525:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39002,DS-572b1260-f7f9-4104-8db6-79a95d3cbb62,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-8d28bf2e-d562-4d29-82ea-0c75befba1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-87c39fff-9ad1-4a93-90bd-73665f5170e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-594befe0-e823-4e7f-8149-624f8cc46690,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-4dbe4649-4164-458d-b378-1fd7f9f52f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-1166421f-2ddb-4964-a1bd-a615cd336106,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-b1ed908c-76f5-45cf-b3d9-2dcaaed7e8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-175b0348-bcfe-4320-b100-8b3b972c1546,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-313866317-172.17.0.6-1597510339525:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39002,DS-572b1260-f7f9-4104-8db6-79a95d3cbb62,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-8d28bf2e-d562-4d29-82ea-0c75befba1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-87c39fff-9ad1-4a93-90bd-73665f5170e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-594befe0-e823-4e7f-8149-624f8cc46690,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-4dbe4649-4164-458d-b378-1fd7f9f52f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-1166421f-2ddb-4964-a1bd-a615cd336106,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-b1ed908c-76f5-45cf-b3d9-2dcaaed7e8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-175b0348-bcfe-4320-b100-8b3b972c1546,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1333356192-172.17.0.6-1597510707807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42913,DS-4d469a60-d6eb-436d-b76b-97e6b20ce1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-0f8a3a9b-707a-4e4d-83f2-ff4fea6cc170,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-b8355167-1251-4b15-b6bb-dbd5ffaded8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-99fd6744-a27a-48df-a936-2b829610ef57,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-cc814ab3-1949-4b68-95f7-fcfa8e1014ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-4f5324ad-3609-4221-9751-8ef22e8d9ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-ae7febc3-03ee-488d-869c-4ee0c626c2be,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-6c25599b-91fd-4276-8ba4-29d9d6c916c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1333356192-172.17.0.6-1597510707807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42913,DS-4d469a60-d6eb-436d-b76b-97e6b20ce1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32871,DS-0f8a3a9b-707a-4e4d-83f2-ff4fea6cc170,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-b8355167-1251-4b15-b6bb-dbd5ffaded8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-99fd6744-a27a-48df-a936-2b829610ef57,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-cc814ab3-1949-4b68-95f7-fcfa8e1014ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-4f5324ad-3609-4221-9751-8ef22e8d9ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-ae7febc3-03ee-488d-869c-4ee0c626c2be,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-6c25599b-91fd-4276-8ba4-29d9d6c916c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-74477475-172.17.0.6-1597510785416:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35086,DS-66082f4b-030a-40a7-af1a-f58188f3567e,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-a4f3f633-34e6-4f6b-911f-304b643576ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-6ff7e132-32fd-4a92-90ec-908e03c43e43,DISK], DatanodeInfoWithStorage[127.0.0.1:33788,DS-a79ca0f1-7ee9-4058-9546-d934984ec44e,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-b6b38599-6fd0-4def-8b8f-c2751ce11fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-d8347f42-661f-4a69-8cd6-dc26e0523587,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-f4e27f23-5952-47c2-89d8-a21a89e999c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-8c5ebea9-00de-4c94-8611-57d3e5007800,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-74477475-172.17.0.6-1597510785416:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35086,DS-66082f4b-030a-40a7-af1a-f58188f3567e,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-a4f3f633-34e6-4f6b-911f-304b643576ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38570,DS-6ff7e132-32fd-4a92-90ec-908e03c43e43,DISK], DatanodeInfoWithStorage[127.0.0.1:33788,DS-a79ca0f1-7ee9-4058-9546-d934984ec44e,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-b6b38599-6fd0-4def-8b8f-c2751ce11fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41508,DS-d8347f42-661f-4a69-8cd6-dc26e0523587,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-f4e27f23-5952-47c2-89d8-a21a89e999c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-8c5ebea9-00de-4c94-8611-57d3e5007800,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.server-defaults.validity.period.ms
component: hdfs:NameNode
v1: 3600000
v2: 360
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-561350453-172.17.0.6-1597511278581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34462,DS-ddfde33c-6619-4b54-9840-74f50819f47b,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-e379fc62-c499-4174-b7cf-36aa20187e82,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-f88b960b-b260-4439-a07e-8937a3f924f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-2726db25-d2ae-40c0-a652-c41772b8cac0,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-12f69af6-9b3e-431f-9415-93901a6ff718,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-846fa3c7-1f52-4239-a12c-8e8abf7ce584,DISK], DatanodeInfoWithStorage[127.0.0.1:42455,DS-1b06df57-a521-40be-9b68-d461d408c0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-aa4ff121-c481-4882-bd4f-62ec7ea75914,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-561350453-172.17.0.6-1597511278581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34462,DS-ddfde33c-6619-4b54-9840-74f50819f47b,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-e379fc62-c499-4174-b7cf-36aa20187e82,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-f88b960b-b260-4439-a07e-8937a3f924f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-2726db25-d2ae-40c0-a652-c41772b8cac0,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-12f69af6-9b3e-431f-9415-93901a6ff718,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-846fa3c7-1f52-4239-a12c-8e8abf7ce584,DISK], DatanodeInfoWithStorage[127.0.0.1:42455,DS-1b06df57-a521-40be-9b68-d461d408c0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-aa4ff121-c481-4882-bd4f-62ec7ea75914,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5564
