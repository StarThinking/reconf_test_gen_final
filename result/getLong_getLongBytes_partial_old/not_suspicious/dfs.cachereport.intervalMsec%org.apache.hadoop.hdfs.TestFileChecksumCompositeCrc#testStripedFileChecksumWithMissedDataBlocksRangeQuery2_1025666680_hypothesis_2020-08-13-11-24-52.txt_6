reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1191048562-172.17.0.15-1597317948861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34021,DS-68a9c9a6-74b1-46a6-97e0-ac7fc5930b34,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-eab1222d-3088-45d0-a363-51fc72aab205,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-fb6802e9-31b3-449a-b7bc-d5ec3c66254c,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-9c8ea9b0-3ce9-446a-9a32-53560b30c234,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-a3493f66-460b-44e4-a7e6-b6480beae797,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-26d0aa81-a343-4af6-a886-733957b6f588,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-96fda5d4-dcaa-42d0-8f90-641e1ca4488d,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-c40c582c-fe96-492a-8baa-831be36d789a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1191048562-172.17.0.15-1597317948861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34021,DS-68a9c9a6-74b1-46a6-97e0-ac7fc5930b34,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-eab1222d-3088-45d0-a363-51fc72aab205,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-fb6802e9-31b3-449a-b7bc-d5ec3c66254c,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-9c8ea9b0-3ce9-446a-9a32-53560b30c234,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-a3493f66-460b-44e4-a7e6-b6480beae797,DISK], DatanodeInfoWithStorage[127.0.0.1:36366,DS-26d0aa81-a343-4af6-a886-733957b6f588,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-96fda5d4-dcaa-42d0-8f90-641e1ca4488d,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-c40c582c-fe96-492a-8baa-831be36d789a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1546365214-172.17.0.15-1597318589980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33903,DS-f47048ea-fcd6-4aa1-b560-afcfe6ed4ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-0c3d2aeb-b880-4642-ab11-c367ae581b02,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-de18b483-635c-4632-b197-4a76bf7196e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-be03dde9-419b-445c-965f-070076e6590f,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-c6db7437-e213-463f-b394-c684a94235b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-bc77a64a-92d4-4f37-a192-3e660b32cf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-60ce9041-f3ea-4ec1-89d1-f8066eda8998,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-ee9727c2-8f9c-4e1f-b924-15e2d92a1fc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1546365214-172.17.0.15-1597318589980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33903,DS-f47048ea-fcd6-4aa1-b560-afcfe6ed4ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-0c3d2aeb-b880-4642-ab11-c367ae581b02,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-de18b483-635c-4632-b197-4a76bf7196e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45963,DS-be03dde9-419b-445c-965f-070076e6590f,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-c6db7437-e213-463f-b394-c684a94235b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-bc77a64a-92d4-4f37-a192-3e660b32cf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-60ce9041-f3ea-4ec1-89d1-f8066eda8998,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-ee9727c2-8f9c-4e1f-b924-15e2d92a1fc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1676144884-172.17.0.15-1597319682962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41633,DS-1e778b04-25e2-44df-9d40-666db70ae042,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-c3102c69-efc1-4cb1-baca-598df1746e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-780dc236-9334-4760-8853-a2fb2ea902e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-9eb824d7-61e6-4ca9-8e16-a724c73eb40b,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-31ccf4ea-cfaa-48ae-9488-a967bac0ff77,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-64115fdf-2930-4730-ae14-8aad037152ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-e6185d6f-49c8-4c2f-bf47-6f4c2e474152,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-cd549fa5-f1db-42ee-aff9-5edf604a3ca9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1676144884-172.17.0.15-1597319682962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41633,DS-1e778b04-25e2-44df-9d40-666db70ae042,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-c3102c69-efc1-4cb1-baca-598df1746e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-780dc236-9334-4760-8853-a2fb2ea902e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40817,DS-9eb824d7-61e6-4ca9-8e16-a724c73eb40b,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-31ccf4ea-cfaa-48ae-9488-a967bac0ff77,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-64115fdf-2930-4730-ae14-8aad037152ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41202,DS-e6185d6f-49c8-4c2f-bf47-6f4c2e474152,DISK], DatanodeInfoWithStorage[127.0.0.1:42001,DS-cd549fa5-f1db-42ee-aff9-5edf604a3ca9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-285847024-172.17.0.15-1597320139237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41389,DS-f76908c6-dc95-4afa-b8b2-602cc5e93c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-fac9640d-de7b-4b73-a7d9-3ca60aba672d,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-fbde06c0-fce0-4c27-9921-b68c8b61b651,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-59d433cf-77a5-45d3-aa0d-5477aa77ab67,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-5eed0f54-1e13-460b-a9be-18ce487273e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-7a83c1e0-8798-412d-a819-dc0a3fdf6ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-90b459eb-2225-44fc-8592-61ac6fc92e83,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-fb76052c-abe1-4964-a70c-d9ec7ee318f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-285847024-172.17.0.15-1597320139237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41389,DS-f76908c6-dc95-4afa-b8b2-602cc5e93c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-fac9640d-de7b-4b73-a7d9-3ca60aba672d,DISK], DatanodeInfoWithStorage[127.0.0.1:35598,DS-fbde06c0-fce0-4c27-9921-b68c8b61b651,DISK], DatanodeInfoWithStorage[127.0.0.1:45517,DS-59d433cf-77a5-45d3-aa0d-5477aa77ab67,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-5eed0f54-1e13-460b-a9be-18ce487273e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33699,DS-7a83c1e0-8798-412d-a819-dc0a3fdf6ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:46129,DS-90b459eb-2225-44fc-8592-61ac6fc92e83,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-fb76052c-abe1-4964-a70c-d9ec7ee318f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047082702-172.17.0.15-1597320493006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37457,DS-034707c7-6b53-469b-b105-af1a31bfcbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-68f13c22-92ac-431e-9778-8eee703534f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-56f06d33-4af4-4b6a-af94-eda7c587d9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-acb2ecb7-c94d-4c0b-8e3e-ff30384c5f91,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-1e60a531-cf9d-4fdd-813e-48fc69caef7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-810127a5-8d3a-41cb-a2b7-32fb1108a79b,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-7eb95e54-8d02-4cb6-ae47-f32eeb1d6ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-8ab85e9c-6408-4f5c-9d41-4f6298fb4ed6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1047082702-172.17.0.15-1597320493006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37457,DS-034707c7-6b53-469b-b105-af1a31bfcbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-68f13c22-92ac-431e-9778-8eee703534f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-56f06d33-4af4-4b6a-af94-eda7c587d9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-acb2ecb7-c94d-4c0b-8e3e-ff30384c5f91,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-1e60a531-cf9d-4fdd-813e-48fc69caef7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-810127a5-8d3a-41cb-a2b7-32fb1108a79b,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-7eb95e54-8d02-4cb6-ae47-f32eeb1d6ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:40596,DS-8ab85e9c-6408-4f5c-9d41-4f6298fb4ed6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1380181456-172.17.0.15-1597320531614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42024,DS-ed90b4a5-2c98-45f4-b398-300063ae0105,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-6a40af6e-172e-4a5b-84ed-47b155591276,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-9633c131-b474-439b-b72b-1a0e25d08870,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-ffd72c03-61de-4934-a060-157dfe4f0af9,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-edb48873-e331-4353-baf3-5ac7091bf882,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-08222858-3279-47ad-89ea-94d024a75a99,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-2c0ffe4a-7083-4547-adb2-c6af80183475,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-4f46f489-9082-4296-a24a-c71063539cd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1380181456-172.17.0.15-1597320531614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42024,DS-ed90b4a5-2c98-45f4-b398-300063ae0105,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-6a40af6e-172e-4a5b-84ed-47b155591276,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-9633c131-b474-439b-b72b-1a0e25d08870,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-ffd72c03-61de-4934-a060-157dfe4f0af9,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-edb48873-e331-4353-baf3-5ac7091bf882,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-08222858-3279-47ad-89ea-94d024a75a99,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-2c0ffe4a-7083-4547-adb2-c6af80183475,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-4f46f489-9082-4296-a24a-c71063539cd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2065907740-172.17.0.15-1597320602152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39150,DS-710253c4-b89a-4ba7-9333-bbd6dc3ec3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-1e190b2b-f8b8-4c63-aed0-e4e5dab506a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-d7d6b268-cff1-4112-97f6-998655b598dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-5df69ca5-5646-4aff-bccf-1fb0b7383d22,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-0d218fe3-1938-4154-9b76-44f2f0361c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-85ff566a-2172-4d42-a250-88f375f7f9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-87f31345-a98c-475b-a96f-3a6e6dd3276e,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-277b888f-ccf2-4a13-821a-9da3a0ec2d90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2065907740-172.17.0.15-1597320602152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39150,DS-710253c4-b89a-4ba7-9333-bbd6dc3ec3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-1e190b2b-f8b8-4c63-aed0-e4e5dab506a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42202,DS-d7d6b268-cff1-4112-97f6-998655b598dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-5df69ca5-5646-4aff-bccf-1fb0b7383d22,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-0d218fe3-1938-4154-9b76-44f2f0361c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-85ff566a-2172-4d42-a250-88f375f7f9b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-87f31345-a98c-475b-a96f-3a6e6dd3276e,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-277b888f-ccf2-4a13-821a-9da3a0ec2d90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650927126-172.17.0.15-1597321117409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43453,DS-03b19eb5-1868-4080-b51f-a22f8e854ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-db2b6ad7-4ddc-4964-9646-da0461c3c5af,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-27153dd7-2de3-4bc5-b306-a671778e5b42,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-731f8eb9-90b0-421c-9890-b804445f08ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-f76ad843-2be6-464a-8d69-d5a7903e9fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-fcd148f9-01a1-4785-90d9-65a9120691dc,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-fefbc855-4138-4fc5-a129-a0d15ddb07bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-fdcd701c-0f3a-4320-90cd-5f1b06308cb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650927126-172.17.0.15-1597321117409:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43453,DS-03b19eb5-1868-4080-b51f-a22f8e854ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:40920,DS-db2b6ad7-4ddc-4964-9646-da0461c3c5af,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-27153dd7-2de3-4bc5-b306-a671778e5b42,DISK], DatanodeInfoWithStorage[127.0.0.1:38572,DS-731f8eb9-90b0-421c-9890-b804445f08ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-f76ad843-2be6-464a-8d69-d5a7903e9fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-fcd148f9-01a1-4785-90d9-65a9120691dc,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-fefbc855-4138-4fc5-a129-a0d15ddb07bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-fdcd701c-0f3a-4320-90cd-5f1b06308cb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1292480897-172.17.0.15-1597321158807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40324,DS-5418bd14-6f69-4bc2-91c1-6e454286f99e,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-47617fef-dafe-4bce-90af-c94241c2af8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-ec0f1ade-ce1e-4e03-a9cd-4e92fd5db712,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-a54a49d3-39e8-4747-83a1-7cdf2032848a,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-a7878469-c35f-4f12-a658-46a2de38c502,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-794a393a-cb48-44b9-9429-c318769526b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-70d33a1f-ec73-4da5-b040-71b69feef4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-944a509d-e7e6-4f99-8c5c-fbc2c5291bac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1292480897-172.17.0.15-1597321158807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40324,DS-5418bd14-6f69-4bc2-91c1-6e454286f99e,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-47617fef-dafe-4bce-90af-c94241c2af8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-ec0f1ade-ce1e-4e03-a9cd-4e92fd5db712,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-a54a49d3-39e8-4747-83a1-7cdf2032848a,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-a7878469-c35f-4f12-a658-46a2de38c502,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-794a393a-cb48-44b9-9429-c318769526b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-70d33a1f-ec73-4da5-b040-71b69feef4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-944a509d-e7e6-4f99-8c5c-fbc2c5291bac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1304357798-172.17.0.15-1597321711355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33027,DS-150ccf49-ed4e-4cca-be7a-73e45cfe45ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-cb284ae5-ce0f-4899-9ef2-4392e4f4d99a,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-80572870-3ec5-42f3-aa1e-a429329d9677,DISK], DatanodeInfoWithStorage[127.0.0.1:39053,DS-6bd792a8-bcb8-4e71-94b9-1197bd222e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-bebfc05a-c0ba-4fbd-ac0e-0e3d476e2434,DISK], DatanodeInfoWithStorage[127.0.0.1:46106,DS-d485a366-b997-49af-a35e-367f19e12254,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-01f4d319-d224-4191-bb8b-f207af6ff2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-27a99159-43f1-45a0-b80a-dce94dd61398,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1304357798-172.17.0.15-1597321711355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33027,DS-150ccf49-ed4e-4cca-be7a-73e45cfe45ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-cb284ae5-ce0f-4899-9ef2-4392e4f4d99a,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-80572870-3ec5-42f3-aa1e-a429329d9677,DISK], DatanodeInfoWithStorage[127.0.0.1:39053,DS-6bd792a8-bcb8-4e71-94b9-1197bd222e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41342,DS-bebfc05a-c0ba-4fbd-ac0e-0e3d476e2434,DISK], DatanodeInfoWithStorage[127.0.0.1:46106,DS-d485a366-b997-49af-a35e-367f19e12254,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-01f4d319-d224-4191-bb8b-f207af6ff2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-27a99159-43f1-45a0-b80a-dce94dd61398,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1327121848-172.17.0.15-1597321906256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44731,DS-d7ce712b-4617-4e00-898f-fee341a8d1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-c323714a-f559-4104-80cf-854c47eacce9,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-4e3e4b36-262d-42df-8c23-093060277a74,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-5ba89900-8276-4989-86cb-55360e66c103,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-4843952f-fe31-404e-acf1-e5c4bb40ca01,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-3fbb9369-3334-43e8-a507-e4759540a71c,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-a05acb3f-6c6c-4ad0-a20b-de107139c477,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-72c2c9ec-a3e0-48d1-95c4-18c16579ad17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1327121848-172.17.0.15-1597321906256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44731,DS-d7ce712b-4617-4e00-898f-fee341a8d1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-c323714a-f559-4104-80cf-854c47eacce9,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-4e3e4b36-262d-42df-8c23-093060277a74,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-5ba89900-8276-4989-86cb-55360e66c103,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-4843952f-fe31-404e-acf1-e5c4bb40ca01,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-3fbb9369-3334-43e8-a507-e4759540a71c,DISK], DatanodeInfoWithStorage[127.0.0.1:38265,DS-a05acb3f-6c6c-4ad0-a20b-de107139c477,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-72c2c9ec-a3e0-48d1-95c4-18c16579ad17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1923764613-172.17.0.15-1597322149221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33211,DS-3d8a983e-6e5b-4ea2-a3ce-68913a49c194,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-540974a6-48d5-482d-b782-e0800f7caccf,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-2255d9c9-b01d-45b3-8ff8-b461d7cea10c,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-ff1015e9-08b9-4681-b522-d430a62b8596,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-5101a37d-5b9c-4f4b-82c1-5a80dbde3847,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-9c69462d-194d-47dc-95ee-82f06972dd28,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-890afb2c-e494-4bea-87b3-f402f7f463cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-04a0888c-1b78-4bc5-b01c-6fc60e23305d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1923764613-172.17.0.15-1597322149221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33211,DS-3d8a983e-6e5b-4ea2-a3ce-68913a49c194,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-540974a6-48d5-482d-b782-e0800f7caccf,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-2255d9c9-b01d-45b3-8ff8-b461d7cea10c,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-ff1015e9-08b9-4681-b522-d430a62b8596,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-5101a37d-5b9c-4f4b-82c1-5a80dbde3847,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-9c69462d-194d-47dc-95ee-82f06972dd28,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-890afb2c-e494-4bea-87b3-f402f7f463cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-04a0888c-1b78-4bc5-b01c-6fc60e23305d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547456078-172.17.0.15-1597322582655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38306,DS-4842c168-f43b-41e9-ab7f-a360e230bf9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-9b3c3d6e-d15c-44d9-8b4a-f2fa769bc5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-9162db84-119d-4150-846b-bee17d9891df,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-0d17c57d-d4b1-4035-a0fa-e4a4d5114840,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-6822ca65-99dd-43b4-bf12-886c615a4d87,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-2af2d6ee-a514-42af-932e-d6189aae4c74,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-47fbb43e-8d89-468e-a362-fc21e165f9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-788f7b8c-bb7e-4076-951e-0ca8965c8eaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-547456078-172.17.0.15-1597322582655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38306,DS-4842c168-f43b-41e9-ab7f-a360e230bf9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40739,DS-9b3c3d6e-d15c-44d9-8b4a-f2fa769bc5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33917,DS-9162db84-119d-4150-846b-bee17d9891df,DISK], DatanodeInfoWithStorage[127.0.0.1:46491,DS-0d17c57d-d4b1-4035-a0fa-e4a4d5114840,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-6822ca65-99dd-43b4-bf12-886c615a4d87,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-2af2d6ee-a514-42af-932e-d6189aae4c74,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-47fbb43e-8d89-468e-a362-fc21e165f9d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-788f7b8c-bb7e-4076-951e-0ca8965c8eaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-715619599-172.17.0.15-1597323075017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46270,DS-f372878f-2567-4aa6-9f8e-192b26f33673,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-ee128da2-5c79-4e1c-aae1-90c4c00c98e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-d4c7b63f-51e1-4b1d-9c61-0ff59ff55bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-57973bff-4f17-4ee8-a62e-7ff0230afd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-ee6e5efc-b0f5-4352-a074-7e98b93b8d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-d6cea43a-b8df-4215-b128-014d3dad18be,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-aa212746-e475-4e09-958c-29363da1daa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-471774ba-33a3-4076-9f12-b48fe279567c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-715619599-172.17.0.15-1597323075017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46270,DS-f372878f-2567-4aa6-9f8e-192b26f33673,DISK], DatanodeInfoWithStorage[127.0.0.1:46197,DS-ee128da2-5c79-4e1c-aae1-90c4c00c98e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-d4c7b63f-51e1-4b1d-9c61-0ff59ff55bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40052,DS-57973bff-4f17-4ee8-a62e-7ff0230afd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-ee6e5efc-b0f5-4352-a074-7e98b93b8d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-d6cea43a-b8df-4215-b128-014d3dad18be,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-aa212746-e475-4e09-958c-29363da1daa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36380,DS-471774ba-33a3-4076-9f12-b48fe279567c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2093484523-172.17.0.15-1597323386918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36574,DS-8ab1496b-67b2-4da0-83f6-c9eb829e7f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-c56d04bd-e5ae-461b-9109-5b66bfa31acf,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-ddd530e3-6fea-4123-b8c5-3edc17e4f433,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-64f45c37-3451-4084-90ba-eab788e2e863,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-51dfd53b-0a84-4515-ab67-3ff18cd1805a,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-8caace00-691b-4cd9-a53c-fa7f11ca565b,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-7c430b24-0b58-452b-abb9-847fa09f0ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-b61d4aa3-af1e-4058-b025-5d842b0de715,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2093484523-172.17.0.15-1597323386918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36574,DS-8ab1496b-67b2-4da0-83f6-c9eb829e7f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-c56d04bd-e5ae-461b-9109-5b66bfa31acf,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-ddd530e3-6fea-4123-b8c5-3edc17e4f433,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-64f45c37-3451-4084-90ba-eab788e2e863,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-51dfd53b-0a84-4515-ab67-3ff18cd1805a,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-8caace00-691b-4cd9-a53c-fa7f11ca565b,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-7c430b24-0b58-452b-abb9-847fa09f0ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-b61d4aa3-af1e-4058-b025-5d842b0de715,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5819
