reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029241114-172.17.0.12-1597460173256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44139,DS-3762d180-87fc-44e5-b2c1-975fcf0b9865,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-640af412-a45e-421d-89ba-da6c7aae3109,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-554d0162-161f-4e59-b04f-523a5ff63b76,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-ee519636-c8fc-40fa-8719-7ea67c8ec0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-ddb0b1d3-a593-4958-8e9e-f0838f32b99e,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-cd7241d2-bc4b-4c0d-a312-d95223b9e141,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-ace0bebb-f1dd-4248-bb20-ac59f69307dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-ccf7fb76-f20e-4ca0-9896-d8216677e46b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029241114-172.17.0.12-1597460173256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44139,DS-3762d180-87fc-44e5-b2c1-975fcf0b9865,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-640af412-a45e-421d-89ba-da6c7aae3109,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-554d0162-161f-4e59-b04f-523a5ff63b76,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-ee519636-c8fc-40fa-8719-7ea67c8ec0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-ddb0b1d3-a593-4958-8e9e-f0838f32b99e,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-cd7241d2-bc4b-4c0d-a312-d95223b9e141,DISK], DatanodeInfoWithStorage[127.0.0.1:34729,DS-ace0bebb-f1dd-4248-bb20-ac59f69307dc,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-ccf7fb76-f20e-4ca0-9896-d8216677e46b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1920367395-172.17.0.12-1597460213535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37349,DS-afee1b74-1908-4589-b70b-d68bdd423bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-cc5a21ef-b62f-4705-b0f5-776132725114,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-9e07e131-3730-4c9f-ab78-8342d70add74,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-dba3efc3-8e42-4ba0-a6cb-88038dee9c11,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-9e2b0627-e7e0-457a-8d6a-8b7c1fd4bbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-eeb16a08-00bf-4b64-9c67-266e9b94dde9,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-f42659ee-2e3c-4fd4-b91b-56db93ddbb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-46eba7a4-4cd3-436f-9f4c-0eaa4596c51f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1920367395-172.17.0.12-1597460213535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37349,DS-afee1b74-1908-4589-b70b-d68bdd423bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-cc5a21ef-b62f-4705-b0f5-776132725114,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-9e07e131-3730-4c9f-ab78-8342d70add74,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-dba3efc3-8e42-4ba0-a6cb-88038dee9c11,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-9e2b0627-e7e0-457a-8d6a-8b7c1fd4bbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:36007,DS-eeb16a08-00bf-4b64-9c67-266e9b94dde9,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-f42659ee-2e3c-4fd4-b91b-56db93ddbb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-46eba7a4-4cd3-436f-9f4c-0eaa4596c51f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1690973480-172.17.0.12-1597460440535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33355,DS-a72c8be1-5f5b-4e39-b0b4-2341f64522cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-9f857ff3-f031-4ebc-935f-70260f95d2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-4177bcfa-527e-4020-8bfb-c4db8be3e16f,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-a0774c04-6f27-43a1-aea2-9fcfaf641ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-264770a6-0af7-4af7-9c36-fde3226d7261,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-2d2fac70-8d3c-4415-88f3-39e0aef1844a,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-ff112637-beee-472b-bb0c-01f9a91c0f19,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-e6416d05-1557-400b-8950-1b3fc450f5e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1690973480-172.17.0.12-1597460440535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33355,DS-a72c8be1-5f5b-4e39-b0b4-2341f64522cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-9f857ff3-f031-4ebc-935f-70260f95d2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-4177bcfa-527e-4020-8bfb-c4db8be3e16f,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-a0774c04-6f27-43a1-aea2-9fcfaf641ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-264770a6-0af7-4af7-9c36-fde3226d7261,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-2d2fac70-8d3c-4415-88f3-39e0aef1844a,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-ff112637-beee-472b-bb0c-01f9a91c0f19,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-e6416d05-1557-400b-8950-1b3fc450f5e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-827932495-172.17.0.12-1597460486680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44485,DS-45219fdd-cb7c-4bf4-adfa-e370bff687f6,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-e016a131-6f6b-49e4-8867-fa45c0a0968e,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-568a6a17-450b-47b8-9c75-53007caaac42,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-95a340c4-c893-466e-aa9a-07c5d43e48d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-756451c9-1718-4c1c-9c9f-0d8303a64670,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-8f2dc8f2-3429-4e7d-8c78-809f51b3556c,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-a5580e79-5d35-4610-83ef-b3497ceed58e,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-7420a4a6-8e29-4adc-b900-b6d12cfc3d4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-827932495-172.17.0.12-1597460486680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44485,DS-45219fdd-cb7c-4bf4-adfa-e370bff687f6,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-e016a131-6f6b-49e4-8867-fa45c0a0968e,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-568a6a17-450b-47b8-9c75-53007caaac42,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-95a340c4-c893-466e-aa9a-07c5d43e48d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-756451c9-1718-4c1c-9c9f-0d8303a64670,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-8f2dc8f2-3429-4e7d-8c78-809f51b3556c,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-a5580e79-5d35-4610-83ef-b3497ceed58e,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-7420a4a6-8e29-4adc-b900-b6d12cfc3d4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582104206-172.17.0.12-1597460566949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46250,DS-ff32724b-1062-47e0-8e99-5309be4e2cab,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-fa985714-bdb4-42db-a3a9-1bd8718ab6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-e94bac43-f890-4829-a411-9eb9106ede03,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-25568552-a954-4b56-a9db-1f28cec1757f,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-5696beca-0ec8-4b66-961e-bab24aefab6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-b83c28cb-3ac4-4f9e-a373-13361a626c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-ac35dc02-9ab9-4466-9cba-2c9d7d78b7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-dce5fe6e-90c1-4f13-a517-a97fb0fa78c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1582104206-172.17.0.12-1597460566949:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46250,DS-ff32724b-1062-47e0-8e99-5309be4e2cab,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-fa985714-bdb4-42db-a3a9-1bd8718ab6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-e94bac43-f890-4829-a411-9eb9106ede03,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-25568552-a954-4b56-a9db-1f28cec1757f,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-5696beca-0ec8-4b66-961e-bab24aefab6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34730,DS-b83c28cb-3ac4-4f9e-a373-13361a626c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-ac35dc02-9ab9-4466-9cba-2c9d7d78b7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-dce5fe6e-90c1-4f13-a517-a97fb0fa78c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325564013-172.17.0.12-1597460767691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46208,DS-ba3b8d6f-d9f9-4f2a-bdff-104f17928d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-daa4e086-5acf-45bf-a43c-082d89c7c184,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-d9533a5a-e0cb-4f7c-a80d-57dbc32acb77,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-12a33649-9ea5-48a7-95c0-a4a7ab40c331,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-f424f883-637e-4bc8-bbcb-201d60e2f6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-e1619601-72b4-41f2-9ae9-469b768e3519,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-209ab875-77c5-48fd-aeec-df7fa4f51567,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-f85e3adf-a23e-4683-85a8-f1e53caad102,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1325564013-172.17.0.12-1597460767691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46208,DS-ba3b8d6f-d9f9-4f2a-bdff-104f17928d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-daa4e086-5acf-45bf-a43c-082d89c7c184,DISK], DatanodeInfoWithStorage[127.0.0.1:36293,DS-d9533a5a-e0cb-4f7c-a80d-57dbc32acb77,DISK], DatanodeInfoWithStorage[127.0.0.1:44628,DS-12a33649-9ea5-48a7-95c0-a4a7ab40c331,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-f424f883-637e-4bc8-bbcb-201d60e2f6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-e1619601-72b4-41f2-9ae9-469b768e3519,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-209ab875-77c5-48fd-aeec-df7fa4f51567,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-f85e3adf-a23e-4683-85a8-f1e53caad102,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1447986901-172.17.0.12-1597460836100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42104,DS-641d1c45-7f5b-431f-94ee-38a2e8d384b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-ff6e388c-3b48-41d5-8fb8-e368f02d0cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-1af60207-d646-45be-ac14-c1ef2b43934c,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-aeea00e4-a7d7-4c35-9b82-4a375111c260,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-cfb27cee-1476-4423-a63b-f97e18d8d95f,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-a8f4a3b1-6ed2-4378-a587-27ebb2ea377a,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-bfbde533-03a4-40cb-8850-478bf9e00df0,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-fefe1e16-6d24-413b-ba1b-d51d99d26e1d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1447986901-172.17.0.12-1597460836100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42104,DS-641d1c45-7f5b-431f-94ee-38a2e8d384b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-ff6e388c-3b48-41d5-8fb8-e368f02d0cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42422,DS-1af60207-d646-45be-ac14-c1ef2b43934c,DISK], DatanodeInfoWithStorage[127.0.0.1:39969,DS-aeea00e4-a7d7-4c35-9b82-4a375111c260,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-cfb27cee-1476-4423-a63b-f97e18d8d95f,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-a8f4a3b1-6ed2-4378-a587-27ebb2ea377a,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-bfbde533-03a4-40cb-8850-478bf9e00df0,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-fefe1e16-6d24-413b-ba1b-d51d99d26e1d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2073982048-172.17.0.12-1597460912804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36371,DS-4a5da641-371f-4c98-92f9-ca86910870e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-6d38cd4e-770d-431d-b33e-40e2befa41db,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-f5c3f83f-73ee-4fd0-a610-93174c624d12,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-86cc3e53-ad7b-4380-beab-9430526ad12e,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-8bf94c54-1971-41f9-9ea7-5b1be55cb539,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-1984697e-4ec5-4e95-b327-453d40b7c7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-61b88710-4c06-463e-ab77-0d80e3964ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-32b37f25-fcdd-47a5-9560-740768248ba8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2073982048-172.17.0.12-1597460912804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36371,DS-4a5da641-371f-4c98-92f9-ca86910870e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-6d38cd4e-770d-431d-b33e-40e2befa41db,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-f5c3f83f-73ee-4fd0-a610-93174c624d12,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-86cc3e53-ad7b-4380-beab-9430526ad12e,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-8bf94c54-1971-41f9-9ea7-5b1be55cb539,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-1984697e-4ec5-4e95-b327-453d40b7c7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-61b88710-4c06-463e-ab77-0d80e3964ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-32b37f25-fcdd-47a5-9560-740768248ba8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1078123525-172.17.0.12-1597461139720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40976,DS-f801a713-dbd3-4912-9ea3-90e173c62025,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-7b329a4f-8a9d-4380-92ea-3862a12581a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-27f79232-cf8e-4245-a75e-440b14a8b49b,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-5e60e3ab-6985-43d2-95fc-5cfe13967788,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-4025140e-3f8e-47f1-97ac-de2c1f5eaa9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-1dc4c6eb-2dbf-4ae7-9a8d-88cbfc1925c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-8db1fa79-f15d-4b45-b3fa-3bf93cc9633f,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-9f3ce025-6d7a-4dcf-bf8e-b3f4dec5513c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1078123525-172.17.0.12-1597461139720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40976,DS-f801a713-dbd3-4912-9ea3-90e173c62025,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-7b329a4f-8a9d-4380-92ea-3862a12581a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-27f79232-cf8e-4245-a75e-440b14a8b49b,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-5e60e3ab-6985-43d2-95fc-5cfe13967788,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-4025140e-3f8e-47f1-97ac-de2c1f5eaa9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-1dc4c6eb-2dbf-4ae7-9a8d-88cbfc1925c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-8db1fa79-f15d-4b45-b3fa-3bf93cc9633f,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-9f3ce025-6d7a-4dcf-bf8e-b3f4dec5513c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-510169701-172.17.0.12-1597461254528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33266,DS-fc87f25a-bb49-4d55-8267-56f2751dabb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-d524da43-9073-45f3-aa8c-4b188b690cea,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-751e67ab-0666-4e71-a372-7eb56434906a,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-55f1b941-f251-4b29-9fa2-74b60ee1b7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-c9e60802-9828-4492-85a0-0d0ac636639d,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-efc1d406-8731-45d7-8495-0b23b564e442,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-178be410-391e-4c07-9a9d-cff7815820e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-cb45f2fc-5987-4d9b-87b5-ed3bb4cd43fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-510169701-172.17.0.12-1597461254528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33266,DS-fc87f25a-bb49-4d55-8267-56f2751dabb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-d524da43-9073-45f3-aa8c-4b188b690cea,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-751e67ab-0666-4e71-a372-7eb56434906a,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-55f1b941-f251-4b29-9fa2-74b60ee1b7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-c9e60802-9828-4492-85a0-0d0ac636639d,DISK], DatanodeInfoWithStorage[127.0.0.1:45501,DS-efc1d406-8731-45d7-8495-0b23b564e442,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-178be410-391e-4c07-9a9d-cff7815820e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-cb45f2fc-5987-4d9b-87b5-ed3bb4cd43fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-918021153-172.17.0.12-1597461328365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34301,DS-d9bda523-fc5d-4f01-8bad-21510349db2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-543f1379-2eda-44f2-9cf5-a4c4266bdfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-9f6ccd7e-b1ec-4c15-8679-8ac3ae7f312b,DISK], DatanodeInfoWithStorage[127.0.0.1:46350,DS-101f20d9-fc17-4cf3-9907-55c0bdf464b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-7c6e7510-9b16-4b49-ae5a-1d03b1cc90b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-1d70d319-35bf-4b5c-b4e4-fb0c6d99a77d,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-2d63b36e-76e5-462d-bfe8-9872d18c2d73,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-72b5ca6e-7089-481b-bc9c-793c1f238ad8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-918021153-172.17.0.12-1597461328365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34301,DS-d9bda523-fc5d-4f01-8bad-21510349db2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-543f1379-2eda-44f2-9cf5-a4c4266bdfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-9f6ccd7e-b1ec-4c15-8679-8ac3ae7f312b,DISK], DatanodeInfoWithStorage[127.0.0.1:46350,DS-101f20d9-fc17-4cf3-9907-55c0bdf464b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-7c6e7510-9b16-4b49-ae5a-1d03b1cc90b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-1d70d319-35bf-4b5c-b4e4-fb0c6d99a77d,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-2d63b36e-76e5-462d-bfe8-9872d18c2d73,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-72b5ca6e-7089-481b-bc9c-793c1f238ad8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-571086668-172.17.0.12-1597461374247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42460,DS-6a4bcefb-c128-495b-b927-2b2326372069,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-643fad6f-a1ec-489e-b6e5-dc30bc42de1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-f9a595ee-3b31-4d4c-8b8e-74083d91b81c,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-91ea9948-9255-4b2a-9bac-410b7afd1d26,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-f02a57da-fce2-4e7d-a126-110c0c49596f,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-707c2a39-6949-43d1-86da-6c04ece7162e,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-6487f1c0-9e54-488b-b2d2-c616652b145c,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-ea0874be-6122-485c-b891-43be58f8183f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-571086668-172.17.0.12-1597461374247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42460,DS-6a4bcefb-c128-495b-b927-2b2326372069,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-643fad6f-a1ec-489e-b6e5-dc30bc42de1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-f9a595ee-3b31-4d4c-8b8e-74083d91b81c,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-91ea9948-9255-4b2a-9bac-410b7afd1d26,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-f02a57da-fce2-4e7d-a126-110c0c49596f,DISK], DatanodeInfoWithStorage[127.0.0.1:33548,DS-707c2a39-6949-43d1-86da-6c04ece7162e,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-6487f1c0-9e54-488b-b2d2-c616652b145c,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-ea0874be-6122-485c-b891-43be58f8183f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382434417-172.17.0.12-1597461447817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35689,DS-1a321d0c-bf82-4789-b2a8-f065bec397f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-c68df207-d215-4bf7-8337-70ea65fa5e36,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-b4a985ad-9de7-4888-9acd-7d580e99563f,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-e2f76c6e-f806-49e8-af1a-6fed4c71c624,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-41e614f0-f6f5-47e6-beb3-7ae2aefdc76f,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-83eb7471-2a5b-4867-bcad-bb43f6da4e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-f0140308-0957-47e9-8dc0-8af62889d06b,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-a0915fa1-2abf-4a68-9e15-37b0b49670c5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382434417-172.17.0.12-1597461447817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35689,DS-1a321d0c-bf82-4789-b2a8-f065bec397f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35797,DS-c68df207-d215-4bf7-8337-70ea65fa5e36,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-b4a985ad-9de7-4888-9acd-7d580e99563f,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-e2f76c6e-f806-49e8-af1a-6fed4c71c624,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-41e614f0-f6f5-47e6-beb3-7ae2aefdc76f,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-83eb7471-2a5b-4867-bcad-bb43f6da4e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-f0140308-0957-47e9-8dc0-8af62889d06b,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-a0915fa1-2abf-4a68-9e15-37b0b49670c5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-50237679-172.17.0.12-1597461629583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32896,DS-83431dd3-3c60-4e0d-9853-353f9c164f57,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-95565587-4db8-44d3-a8db-81c9af734e74,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-2ed065ae-e6e1-4913-8fd0-1cb171e909ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-8bf023b6-9b5d-46ce-b7c6-c261acfc50b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-0ae8c6dc-f1ca-4c58-9d87-8c01e6c90b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-9ef61eac-d92f-49f7-93e2-d01a9d1bccaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-ada080dc-bbc7-4bed-9f88-03454cbcbb94,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-92a24190-1204-4ff8-873d-f075fa21a3ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-50237679-172.17.0.12-1597461629583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32896,DS-83431dd3-3c60-4e0d-9853-353f9c164f57,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-95565587-4db8-44d3-a8db-81c9af734e74,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-2ed065ae-e6e1-4913-8fd0-1cb171e909ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-8bf023b6-9b5d-46ce-b7c6-c261acfc50b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38547,DS-0ae8c6dc-f1ca-4c58-9d87-8c01e6c90b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-9ef61eac-d92f-49f7-93e2-d01a9d1bccaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36764,DS-ada080dc-bbc7-4bed-9f88-03454cbcbb94,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-92a24190-1204-4ff8-873d-f075fa21a3ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-743025390-172.17.0.12-1597461672342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35741,DS-1817139e-6495-4b92-ade8-54e3b7efd7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-609071ce-a379-4428-85cb-113ef1faa88b,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-037085c3-ab4c-426e-81a0-bbac60f99772,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-5defd349-6b6c-4905-9fe8-3d8b32c54861,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-6c1ea076-ac14-4732-943a-8d14bb1365df,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-aee719db-a872-4fc4-9442-406ce9d7d34c,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-1b7d6c06-dccc-460d-a875-a3d155a24904,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-de0581ba-86a8-4b1e-94c7-a7bbdbdf1d62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-743025390-172.17.0.12-1597461672342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35741,DS-1817139e-6495-4b92-ade8-54e3b7efd7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-609071ce-a379-4428-85cb-113ef1faa88b,DISK], DatanodeInfoWithStorage[127.0.0.1:44760,DS-037085c3-ab4c-426e-81a0-bbac60f99772,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-5defd349-6b6c-4905-9fe8-3d8b32c54861,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-6c1ea076-ac14-4732-943a-8d14bb1365df,DISK], DatanodeInfoWithStorage[127.0.0.1:39423,DS-aee719db-a872-4fc4-9442-406ce9d7d34c,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-1b7d6c06-dccc-460d-a875-a3d155a24904,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-de0581ba-86a8-4b1e-94c7-a7bbdbdf1d62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1827396069-172.17.0.12-1597462039537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43614,DS-0e784627-d306-47df-9a55-de0214720254,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-2b3bb526-4ad8-4ba1-b8d0-0f530eb1c81a,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-a2ccba85-2d0d-40a6-abc0-185405d4eeff,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-664706f1-2dd7-46a0-b326-59a710e5e680,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-9abe38fb-7ddc-4210-bd36-c080079fa08e,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-9334d429-4607-4491-9ee9-35306aa95b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-33b54568-7b84-4be2-8e87-81da73c103d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-a17d280b-cc9e-4de5-bccc-71d40061995b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1827396069-172.17.0.12-1597462039537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43614,DS-0e784627-d306-47df-9a55-de0214720254,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-2b3bb526-4ad8-4ba1-b8d0-0f530eb1c81a,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-a2ccba85-2d0d-40a6-abc0-185405d4eeff,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-664706f1-2dd7-46a0-b326-59a710e5e680,DISK], DatanodeInfoWithStorage[127.0.0.1:45753,DS-9abe38fb-7ddc-4210-bd36-c080079fa08e,DISK], DatanodeInfoWithStorage[127.0.0.1:43879,DS-9334d429-4607-4491-9ee9-35306aa95b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44279,DS-33b54568-7b84-4be2-8e87-81da73c103d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-a17d280b-cc9e-4de5-bccc-71d40061995b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933103218-172.17.0.12-1597462124306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46537,DS-03d80fb0-2e74-417f-97e4-f630cf5d1422,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-65cff785-da09-49d6-9395-5d0ca480f130,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-848a4c9d-591b-42a7-af37-914eb8e10d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-2ebf0573-7495-410d-87e7-b8323988b359,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-6d6817f5-1854-41c2-90f8-48c853067e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-a8d0b883-2ca9-437a-90a2-bff9ec5ca465,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-e0215f03-e290-4d28-a29d-50acd763fac8,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-adb0e7e9-7457-4b18-b9d7-3ab4127c5ff5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933103218-172.17.0.12-1597462124306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46537,DS-03d80fb0-2e74-417f-97e4-f630cf5d1422,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-65cff785-da09-49d6-9395-5d0ca480f130,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-848a4c9d-591b-42a7-af37-914eb8e10d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-2ebf0573-7495-410d-87e7-b8323988b359,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-6d6817f5-1854-41c2-90f8-48c853067e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-a8d0b883-2ca9-437a-90a2-bff9ec5ca465,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-e0215f03-e290-4d28-a29d-50acd763fac8,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-adb0e7e9-7457-4b18-b9d7-3ab4127c5ff5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-977304694-172.17.0.12-1597462699223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35308,DS-4f51771b-c98e-4f0a-b64c-d77a03f5cf06,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-8e83f436-25ae-4f2d-8793-dd5c5a3e880b,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-6e4083cc-d0dd-4ac4-ace6-dad8bc948535,DISK], DatanodeInfoWithStorage[127.0.0.1:46731,DS-f12da6b1-9020-4382-b78e-c87e1b27ab00,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-b4a09c6a-85eb-45c7-a392-ad080f3b23b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-d4bc9b98-9e16-43a8-85ba-11d68b191488,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-6176f5a0-0fab-4eba-8118-a77ed0417a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-fb2b9588-867f-4b10-8eb1-89872370179b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-977304694-172.17.0.12-1597462699223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35308,DS-4f51771b-c98e-4f0a-b64c-d77a03f5cf06,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-8e83f436-25ae-4f2d-8793-dd5c5a3e880b,DISK], DatanodeInfoWithStorage[127.0.0.1:33164,DS-6e4083cc-d0dd-4ac4-ace6-dad8bc948535,DISK], DatanodeInfoWithStorage[127.0.0.1:46731,DS-f12da6b1-9020-4382-b78e-c87e1b27ab00,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-b4a09c6a-85eb-45c7-a392-ad080f3b23b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-d4bc9b98-9e16-43a8-85ba-11d68b191488,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-6176f5a0-0fab-4eba-8118-a77ed0417a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-fb2b9588-867f-4b10-8eb1-89872370179b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598050864-172.17.0.12-1597462851896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38747,DS-0437efb3-9289-40ee-9acc-bec380917f00,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-d99a6753-8084-4373-a534-64ec83943b34,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-52a9d6f6-288c-4e02-b060-62e0a93672cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-d06f4efe-04a2-4a96-be7d-05689f77586a,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-fde64c01-83b6-4484-a023-81bb3e36654b,DISK], DatanodeInfoWithStorage[127.0.0.1:42373,DS-d91f9e6a-176d-40cc-8b95-aed4ffad62d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-4818c1c1-d060-4135-9957-486911ee81ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-4997ea44-41b2-4d3d-af84-7c034b607ed1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598050864-172.17.0.12-1597462851896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38747,DS-0437efb3-9289-40ee-9acc-bec380917f00,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-d99a6753-8084-4373-a534-64ec83943b34,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-52a9d6f6-288c-4e02-b060-62e0a93672cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36418,DS-d06f4efe-04a2-4a96-be7d-05689f77586a,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-fde64c01-83b6-4484-a023-81bb3e36654b,DISK], DatanodeInfoWithStorage[127.0.0.1:42373,DS-d91f9e6a-176d-40cc-8b95-aed4ffad62d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-4818c1c1-d060-4135-9957-486911ee81ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-4997ea44-41b2-4d3d-af84-7c034b607ed1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396712989-172.17.0.12-1597462890537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45307,DS-697a4e34-ffd1-4429-b70e-f6c125754cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-93a9fd55-dc9d-4cef-ad3f-786114ba8076,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-fa778700-db7b-4245-b0b1-b46d7e54e5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40388,DS-23488023-4657-4133-8fc2-4cdedfb2a35c,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-9b14ab93-6da8-430a-96f5-7711b8bc8bef,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-48dc5ad7-7fcd-4cbb-a650-30df53ca84ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-df016470-e102-4a50-bd76-9af9dcc5c5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-407bcfcd-ef42-414f-9705-af179d95ea8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396712989-172.17.0.12-1597462890537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45307,DS-697a4e34-ffd1-4429-b70e-f6c125754cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-93a9fd55-dc9d-4cef-ad3f-786114ba8076,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-fa778700-db7b-4245-b0b1-b46d7e54e5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40388,DS-23488023-4657-4133-8fc2-4cdedfb2a35c,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-9b14ab93-6da8-430a-96f5-7711b8bc8bef,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-48dc5ad7-7fcd-4cbb-a650-30df53ca84ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-df016470-e102-4a50-bd76-9af9dcc5c5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-407bcfcd-ef42-414f-9705-af179d95ea8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109442658-172.17.0.12-1597463539545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43555,DS-3ad2e67a-de83-4067-a6f6-6a4b456f8e32,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-b656e991-daff-4e43-8488-25fb626cf1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-a305a372-f36a-42e4-8aa6-702144963f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-1d5e9d53-fbfe-4f68-9c03-42de1ed4e9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-4156f536-b267-4b3f-b33a-dd1f82580560,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-255e9737-e56b-4ec2-856e-c6567f1c4619,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-ab834ad1-f31e-4a90-a878-a8ccbd537927,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-fb2959fd-9da4-4de1-8cf1-992c0a2c0d8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109442658-172.17.0.12-1597463539545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43555,DS-3ad2e67a-de83-4067-a6f6-6a4b456f8e32,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-b656e991-daff-4e43-8488-25fb626cf1d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-a305a372-f36a-42e4-8aa6-702144963f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-1d5e9d53-fbfe-4f68-9c03-42de1ed4e9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-4156f536-b267-4b3f-b33a-dd1f82580560,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-255e9737-e56b-4ec2-856e-c6567f1c4619,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-ab834ad1-f31e-4a90-a878-a8ccbd537927,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-fb2959fd-9da4-4de1-8cf1-992c0a2c0d8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260392646-172.17.0.12-1597463687746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45230,DS-58a3b500-f787-446b-b26e-2e516588880a,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-c7d04b0c-6f5b-434c-b10e-f872cbcc89e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-b9d5d77b-a81e-410e-9917-26d83b8dfbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-88c86bd2-3423-4947-b9a6-0532fca2466c,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-8c037319-a964-48e3-b726-55f133429a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-069f15c2-080d-446c-9b31-6713a535198a,DISK], DatanodeInfoWithStorage[127.0.0.1:36616,DS-4d156574-568b-41be-9cff-070484715eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-e26b7f88-3d44-4a88-9eb6-b3afbc5d0a7b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260392646-172.17.0.12-1597463687746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45230,DS-58a3b500-f787-446b-b26e-2e516588880a,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-c7d04b0c-6f5b-434c-b10e-f872cbcc89e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-b9d5d77b-a81e-410e-9917-26d83b8dfbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:43244,DS-88c86bd2-3423-4947-b9a6-0532fca2466c,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-8c037319-a964-48e3-b726-55f133429a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-069f15c2-080d-446c-9b31-6713a535198a,DISK], DatanodeInfoWithStorage[127.0.0.1:36616,DS-4d156574-568b-41be-9cff-070484715eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-e26b7f88-3d44-4a88-9eb6-b3afbc5d0a7b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088834577-172.17.0.12-1597463762280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45379,DS-3c93c2f9-a80d-4e3f-adfb-0d29467cd983,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-91111d49-eb12-42c3-8435-590c3accd3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-3ad36839-8223-401c-8df1-fbf756537ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:39518,DS-12e8551f-88dd-4737-96e0-04a3a81832e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-da46d61a-8936-4063-97e3-b0d3f36bdf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-1925b9e8-2f0d-4461-91bb-1f5b0dc97870,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-568c0620-2329-49eb-93ee-f73dfe4127e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-1f15d8d9-4f68-4ea1-88b2-b0fbe1a493e7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1088834577-172.17.0.12-1597463762280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45379,DS-3c93c2f9-a80d-4e3f-adfb-0d29467cd983,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-91111d49-eb12-42c3-8435-590c3accd3fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-3ad36839-8223-401c-8df1-fbf756537ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:39518,DS-12e8551f-88dd-4737-96e0-04a3a81832e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-da46d61a-8936-4063-97e3-b0d3f36bdf9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-1925b9e8-2f0d-4461-91bb-1f5b0dc97870,DISK], DatanodeInfoWithStorage[127.0.0.1:37130,DS-568c0620-2329-49eb-93ee-f73dfe4127e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-1f15d8d9-4f68-4ea1-88b2-b0fbe1a493e7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257540368-172.17.0.12-1597463995000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45789,DS-ae3e8d66-aa24-4984-9bd1-a7610e09f5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-5ed8b6c7-05ee-45ff-8f4f-8bb5848d91bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-5c5c773b-f056-4f71-86a8-6cf3cfb18443,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-8d417f34-7f7a-4958-82df-b8fbb743c746,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-0c8ce507-0519-428e-a1ad-82bcc9a76356,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-a9c1ede9-bc9e-4eea-845d-bbf01824ff5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-263fa419-95e8-4a6a-ba52-5093a1625676,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-72b3c356-27b3-4df6-99d0-ce438d7a203c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257540368-172.17.0.12-1597463995000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45789,DS-ae3e8d66-aa24-4984-9bd1-a7610e09f5ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-5ed8b6c7-05ee-45ff-8f4f-8bb5848d91bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33389,DS-5c5c773b-f056-4f71-86a8-6cf3cfb18443,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-8d417f34-7f7a-4958-82df-b8fbb743c746,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-0c8ce507-0519-428e-a1ad-82bcc9a76356,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-a9c1ede9-bc9e-4eea-845d-bbf01824ff5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35399,DS-263fa419-95e8-4a6a-ba52-5093a1625676,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-72b3c356-27b3-4df6-99d0-ce438d7a203c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654986974-172.17.0.12-1597464184631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36821,DS-51b023cd-dca2-451e-b09e-bbde8639977f,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-0df29ef8-e83d-4204-9d5d-4e96743f1fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-22eca8f1-ec15-453d-b568-ef3461f28f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-4965f51a-aa25-4d59-9cf9-8fdd990e238b,DISK], DatanodeInfoWithStorage[127.0.0.1:33046,DS-a110e575-0914-4656-a7e4-44cb2c365c86,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-2792396e-90c5-4bb2-a948-bd79a722aa90,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-7d5ed9c1-4d1e-4a9f-9248-02ed6a224abc,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-90dec719-41ae-4cfc-ab0d-103390081a1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654986974-172.17.0.12-1597464184631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36821,DS-51b023cd-dca2-451e-b09e-bbde8639977f,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-0df29ef8-e83d-4204-9d5d-4e96743f1fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-22eca8f1-ec15-453d-b568-ef3461f28f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-4965f51a-aa25-4d59-9cf9-8fdd990e238b,DISK], DatanodeInfoWithStorage[127.0.0.1:33046,DS-a110e575-0914-4656-a7e4-44cb2c365c86,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-2792396e-90c5-4bb2-a948-bd79a722aa90,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-7d5ed9c1-4d1e-4a9f-9248-02ed6a224abc,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-90dec719-41ae-4cfc-ab0d-103390081a1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1086181073-172.17.0.12-1597464298817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44855,DS-27f9c848-c441-4360-bf2e-45d4e633d536,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-8cafe2da-473b-4ec8-b009-b7fef937e961,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-8b280e26-4789-47c4-be66-b6c5c64ea421,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-137694a5-1dfc-4420-ac19-31a044fecaab,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-9151d42c-2f7a-41a0-a2d5-282cc10dad08,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-53eb89ad-c403-4993-9ea2-f05dc389d9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-fe7f3bf2-0e57-43cd-aace-195728b118e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-d1960642-bc74-4c3c-9e75-3911ad6d3ffc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1086181073-172.17.0.12-1597464298817:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44855,DS-27f9c848-c441-4360-bf2e-45d4e633d536,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-8cafe2da-473b-4ec8-b009-b7fef937e961,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-8b280e26-4789-47c4-be66-b6c5c64ea421,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-137694a5-1dfc-4420-ac19-31a044fecaab,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-9151d42c-2f7a-41a0-a2d5-282cc10dad08,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-53eb89ad-c403-4993-9ea2-f05dc389d9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-fe7f3bf2-0e57-43cd-aace-195728b118e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-d1960642-bc74-4c3c-9e75-3911ad6d3ffc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029122617-172.17.0.12-1597464618683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34447,DS-8956265d-c3b2-4b88-aeee-9deeb62fccdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-d9b7253a-b7a2-408f-ac19-463b8adc4c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-8d6a4ba6-f3e9-4f54-9373-622a45fa955e,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-04bb2bd9-d62f-4182-bb46-6ae071c40261,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-916b75ad-419b-4f8e-aac3-e9114df4d656,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-3ab1de48-5765-4fb8-877d-0a1345bc06ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-0d5ef7ba-b6da-4a48-9b03-7f09415be27d,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-325b74c8-52f5-4065-b386-26f7c456efff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2029122617-172.17.0.12-1597464618683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34447,DS-8956265d-c3b2-4b88-aeee-9deeb62fccdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-d9b7253a-b7a2-408f-ac19-463b8adc4c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-8d6a4ba6-f3e9-4f54-9373-622a45fa955e,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-04bb2bd9-d62f-4182-bb46-6ae071c40261,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-916b75ad-419b-4f8e-aac3-e9114df4d656,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-3ab1de48-5765-4fb8-877d-0a1345bc06ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-0d5ef7ba-b6da-4a48-9b03-7f09415be27d,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-325b74c8-52f5-4065-b386-26f7c456efff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367507844-172.17.0.12-1597464983430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37332,DS-08b72092-2820-434c-9fbd-bbba6670ad6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-889789ea-5a24-4323-bb68-5f5c0142c348,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-16c112df-926d-4d68-a31e-d5018e6160d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-5bd52af7-9bdb-431b-b5af-49ceb6b31f16,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-794562a4-5145-475a-bf17-77d2b44dd849,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-584654cc-2e9f-46b2-b9ae-c0f58ac45e99,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-f6142afb-c153-4b15-9951-382ae433ac9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-17220d42-3fb7-47e6-a364-406904224b98,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367507844-172.17.0.12-1597464983430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37332,DS-08b72092-2820-434c-9fbd-bbba6670ad6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41459,DS-889789ea-5a24-4323-bb68-5f5c0142c348,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-16c112df-926d-4d68-a31e-d5018e6160d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-5bd52af7-9bdb-431b-b5af-49ceb6b31f16,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-794562a4-5145-475a-bf17-77d2b44dd849,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-584654cc-2e9f-46b2-b9ae-c0f58ac45e99,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-f6142afb-c153-4b15-9951-382ae433ac9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-17220d42-3fb7-47e6-a364-406904224b98,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2134255595-172.17.0.12-1597465176509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37390,DS-ef5ad30b-14fc-406f-899a-112129f2a678,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-42e305af-d7b4-45f5-a766-2fa3f0a62196,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-901af9c4-8483-455d-8160-44d6bfa2bfe3,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-606ec219-aa36-40a5-83b6-6de0add951b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-6b9769bc-5258-4abe-955f-2125afc6962a,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-7eb1c59e-df0f-45a9-8136-523693300b66,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-97cdfc90-47c8-4f03-8118-85804e273f59,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-39c017af-09cb-47c6-872d-18d3711bec77,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2134255595-172.17.0.12-1597465176509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37390,DS-ef5ad30b-14fc-406f-899a-112129f2a678,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-42e305af-d7b4-45f5-a766-2fa3f0a62196,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-901af9c4-8483-455d-8160-44d6bfa2bfe3,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-606ec219-aa36-40a5-83b6-6de0add951b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-6b9769bc-5258-4abe-955f-2125afc6962a,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-7eb1c59e-df0f-45a9-8136-523693300b66,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-97cdfc90-47c8-4f03-8118-85804e273f59,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-39c017af-09cb-47c6-872d-18d3711bec77,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1044201230-172.17.0.12-1597465220118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43999,DS-b8c93aac-c9e3-4ded-95d3-238653b88dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-ac0d867f-a60c-4395-b3ad-0c67ec48e44b,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-239d9243-3cb2-4fe7-91f2-b020a7c8594c,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-020e6898-2ae4-440f-ab6c-5cdae0e3f9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-585e11f5-ab94-400c-b8b2-18edb1b726fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-766d1282-5862-4c7e-bcef-27134b663b90,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-8f22ae4b-852a-49f4-a5d7-1d634b3f20de,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-5c5da457-a2b1-4af1-ae9c-d1e917ddee35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1044201230-172.17.0.12-1597465220118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43999,DS-b8c93aac-c9e3-4ded-95d3-238653b88dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-ac0d867f-a60c-4395-b3ad-0c67ec48e44b,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-239d9243-3cb2-4fe7-91f2-b020a7c8594c,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-020e6898-2ae4-440f-ab6c-5cdae0e3f9cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33037,DS-585e11f5-ab94-400c-b8b2-18edb1b726fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-766d1282-5862-4c7e-bcef-27134b663b90,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-8f22ae4b-852a-49f4-a5d7-1d634b3f20de,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-5c5da457-a2b1-4af1-ae9c-d1e917ddee35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-335041900-172.17.0.12-1597465419002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45257,DS-b66f9cde-ea01-49fa-a4f0-09f0ede74eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-a384e8d0-8aea-4947-89f8-4637fa9b0254,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-b3084d8a-df11-45f8-992d-63febc4f5278,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-17847cc3-f2e5-47b5-b74f-4ea794255e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-bafa147c-f03d-49ba-91d0-3512979a12eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-7fdea4c5-7e73-47d5-bed9-519519aa5220,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-9d79b4ee-ffe3-4925-b995-26468931d331,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-260eda12-9fa5-466c-a577-830027c8d6ee,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-335041900-172.17.0.12-1597465419002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45257,DS-b66f9cde-ea01-49fa-a4f0-09f0ede74eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-a384e8d0-8aea-4947-89f8-4637fa9b0254,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-b3084d8a-df11-45f8-992d-63febc4f5278,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-17847cc3-f2e5-47b5-b74f-4ea794255e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-bafa147c-f03d-49ba-91d0-3512979a12eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35958,DS-7fdea4c5-7e73-47d5-bed9-519519aa5220,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-9d79b4ee-ffe3-4925-b995-26468931d331,DISK], DatanodeInfoWithStorage[127.0.0.1:41403,DS-260eda12-9fa5-466c-a577-830027c8d6ee,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1593442923-172.17.0.12-1597465537103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40129,DS-7b8966b4-519e-4d3e-8117-c2fd39f79619,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-985e2e2f-cd7a-401e-9536-044fde888844,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-4e65eb6f-095c-421a-bfaa-75718edd6a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-2951dba5-d6e6-494e-b0d6-361f72c0e6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-2459a5b3-d973-40da-ab96-095e344cf7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-9d8062ae-995e-40a7-98b1-43822bcb1cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-35973a46-1fcd-4fb1-9141-2836f8ad918c,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-ced7ff3b-0254-4123-a11e-e31f026ab980,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1593442923-172.17.0.12-1597465537103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40129,DS-7b8966b4-519e-4d3e-8117-c2fd39f79619,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-985e2e2f-cd7a-401e-9536-044fde888844,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-4e65eb6f-095c-421a-bfaa-75718edd6a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-2951dba5-d6e6-494e-b0d6-361f72c0e6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-2459a5b3-d973-40da-ab96-095e344cf7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-9d8062ae-995e-40a7-98b1-43822bcb1cbf,DISK], DatanodeInfoWithStorage[127.0.0.1:40402,DS-35973a46-1fcd-4fb1-9141-2836f8ad918c,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-ced7ff3b-0254-4123-a11e-e31f026ab980,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-880637576-172.17.0.12-1597465763968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44401,DS-f1726fc8-97a7-48e1-8877-43fc3d13172d,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-fad661db-af45-4113-819f-62970bae0027,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-0d836749-f88b-45eb-917b-cec9d835b5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-31b0c4e8-f999-4598-92de-29ab1eb1e8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-8ce8dcfb-ee69-4e46-ac90-2d4a56ae5920,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-17d55b01-60b3-46be-a843-57b328bbb3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-c34decec-30a9-468f-91b4-c7ef361c817f,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-89da57ff-3659-4de3-88cb-9602202efb14,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-880637576-172.17.0.12-1597465763968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44401,DS-f1726fc8-97a7-48e1-8877-43fc3d13172d,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-fad661db-af45-4113-819f-62970bae0027,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-0d836749-f88b-45eb-917b-cec9d835b5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-31b0c4e8-f999-4598-92de-29ab1eb1e8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-8ce8dcfb-ee69-4e46-ac90-2d4a56ae5920,DISK], DatanodeInfoWithStorage[127.0.0.1:44768,DS-17d55b01-60b3-46be-a843-57b328bbb3f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-c34decec-30a9-468f-91b4-c7ef361c817f,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-89da57ff-3659-4de3-88cb-9602202efb14,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058423640-172.17.0.12-1597465834158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43081,DS-08d2bee4-f827-441b-8ec7-7df19c9f2cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-4a89f199-3f22-40c3-b527-cefb36208c73,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-91e8a7f6-321f-4049-95d5-7a9ebb151114,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-3d837908-f5be-4f65-8174-db642d76ff35,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-1e6773e1-6c55-40b7-ba43-b97be75b46a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-e850462a-4c8b-4fba-9346-0f5fa830598d,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-b23409b1-45c5-40ad-b49d-5c32d6a1e492,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-de509dbc-0c07-4f65-8bb1-d5187af0f9a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2058423640-172.17.0.12-1597465834158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43081,DS-08d2bee4-f827-441b-8ec7-7df19c9f2cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-4a89f199-3f22-40c3-b527-cefb36208c73,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-91e8a7f6-321f-4049-95d5-7a9ebb151114,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-3d837908-f5be-4f65-8174-db642d76ff35,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-1e6773e1-6c55-40b7-ba43-b97be75b46a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-e850462a-4c8b-4fba-9346-0f5fa830598d,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-b23409b1-45c5-40ad-b49d-5c32d6a1e492,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-de509dbc-0c07-4f65-8bb1-d5187af0f9a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 22 out of 50
result: false positive !!!
Total execution time in seconds : 5834
