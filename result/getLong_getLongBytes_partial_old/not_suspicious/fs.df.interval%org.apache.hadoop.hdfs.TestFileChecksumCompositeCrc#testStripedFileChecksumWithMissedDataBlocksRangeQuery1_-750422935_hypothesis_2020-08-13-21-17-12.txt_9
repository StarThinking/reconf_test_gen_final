reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-678638347-172.17.0.4-1597353721656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33144,DS-3fbc0536-647c-45ac-91ff-25b6f5e8a7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-c1fd8aed-5043-45c0-a188-731624889dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-c6572de6-07ee-4d29-b1dc-1486283d0dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-4d8bba93-3fb3-4a22-bf4f-4689dadac8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-f4f52c0a-1477-4505-bccb-c5b9e6d8aac1,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-0d52399b-18e4-4a1b-909b-6dc714b644bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-14d16fb9-ff7b-4731-adef-9e59c3b5b67d,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-eb9ece64-89a4-4cfb-a3c9-2ba0cd05db64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-678638347-172.17.0.4-1597353721656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33144,DS-3fbc0536-647c-45ac-91ff-25b6f5e8a7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-c1fd8aed-5043-45c0-a188-731624889dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-c6572de6-07ee-4d29-b1dc-1486283d0dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-4d8bba93-3fb3-4a22-bf4f-4689dadac8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38686,DS-f4f52c0a-1477-4505-bccb-c5b9e6d8aac1,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-0d52399b-18e4-4a1b-909b-6dc714b644bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-14d16fb9-ff7b-4731-adef-9e59c3b5b67d,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-eb9ece64-89a4-4cfb-a3c9-2ba0cd05db64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1610677633-172.17.0.4-1597353795872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35207,DS-127ace69-a77d-49fe-939a-1cab76609259,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-3aa1f8e0-49a9-44c4-be8b-a9bfc571e590,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-cfd508fc-2f4a-418f-955b-b423b3761d28,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-062f6414-139f-49d1-b5a8-f15d50e111a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-0429c7eb-4700-4b0d-8d23-11ad3993d65f,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-7d56a44f-bc96-4007-86b3-5a4f2305cc03,DISK], DatanodeInfoWithStorage[127.0.0.1:35980,DS-d9f4db9f-5c0c-47e5-a5d4-1bd12560777a,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-4244e91b-ffbb-42ba-a7f2-7d262125f403,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1610677633-172.17.0.4-1597353795872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35207,DS-127ace69-a77d-49fe-939a-1cab76609259,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-3aa1f8e0-49a9-44c4-be8b-a9bfc571e590,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-cfd508fc-2f4a-418f-955b-b423b3761d28,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-062f6414-139f-49d1-b5a8-f15d50e111a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-0429c7eb-4700-4b0d-8d23-11ad3993d65f,DISK], DatanodeInfoWithStorage[127.0.0.1:45291,DS-7d56a44f-bc96-4007-86b3-5a4f2305cc03,DISK], DatanodeInfoWithStorage[127.0.0.1:35980,DS-d9f4db9f-5c0c-47e5-a5d4-1bd12560777a,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-4244e91b-ffbb-42ba-a7f2-7d262125f403,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-253970097-172.17.0.4-1597354102288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36727,DS-6ecaee20-03ea-458d-9e71-e81edd2bc968,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-d64d6dae-1d81-4b4e-a7fc-13b6614a2da3,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-251d4ae1-e0e3-4f1b-824c-c0455b606e31,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-f8cbbbef-769a-4892-b47b-dae9fbb4f2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-82a200a8-dcaa-40d6-b65e-2c37019f9b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-6be9538a-a8fe-4c79-9dcf-10fd73ceffa8,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-ba77f42d-2a52-497d-a215-917fe5ce3346,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-707fbdaa-53a8-4cd0-8264-4f784fc57762,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-253970097-172.17.0.4-1597354102288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36727,DS-6ecaee20-03ea-458d-9e71-e81edd2bc968,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-d64d6dae-1d81-4b4e-a7fc-13b6614a2da3,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-251d4ae1-e0e3-4f1b-824c-c0455b606e31,DISK], DatanodeInfoWithStorage[127.0.0.1:44561,DS-f8cbbbef-769a-4892-b47b-dae9fbb4f2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-82a200a8-dcaa-40d6-b65e-2c37019f9b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-6be9538a-a8fe-4c79-9dcf-10fd73ceffa8,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-ba77f42d-2a52-497d-a215-917fe5ce3346,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-707fbdaa-53a8-4cd0-8264-4f784fc57762,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553271375-172.17.0.4-1597354799547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42118,DS-f93879ac-966d-40a0-a753-1b0e4c5623a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-204b75e3-2c9d-4acf-ba1e-94a72244b196,DISK], DatanodeInfoWithStorage[127.0.0.1:46761,DS-a44c8335-3f5c-49f0-9bd1-698dd1995ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-67575e5b-0c21-4c88-b3ce-f359dcbe075f,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-6283bcaf-d8da-4157-9031-b4b13a62d09a,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-72d9860f-2099-4313-8356-edcc921a8cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-8017ea8d-1f28-42a1-8323-46c242240c25,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-69b30e1d-9519-4712-8579-d7d00495ac18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553271375-172.17.0.4-1597354799547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42118,DS-f93879ac-966d-40a0-a753-1b0e4c5623a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-204b75e3-2c9d-4acf-ba1e-94a72244b196,DISK], DatanodeInfoWithStorage[127.0.0.1:46761,DS-a44c8335-3f5c-49f0-9bd1-698dd1995ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-67575e5b-0c21-4c88-b3ce-f359dcbe075f,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-6283bcaf-d8da-4157-9031-b4b13a62d09a,DISK], DatanodeInfoWithStorage[127.0.0.1:41638,DS-72d9860f-2099-4313-8356-edcc921a8cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-8017ea8d-1f28-42a1-8323-46c242240c25,DISK], DatanodeInfoWithStorage[127.0.0.1:39175,DS-69b30e1d-9519-4712-8579-d7d00495ac18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-440210132-172.17.0.4-1597355017226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33119,DS-36c1b9f6-9219-4842-bfe5-2ae522f2026c,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-02a94f2f-9cca-412e-bdcd-7021ce941735,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-1c7ecf61-8893-451d-a3f0-18a1f71f818f,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-94475d24-0e04-4f74-8fd1-8eaebacf0745,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-0a56cd9f-bc46-4ed8-87ac-409695b5092f,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-5787f77c-ac7f-428a-ba7d-1c905be90fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-35b2a09c-de75-4169-97f3-a028b0516f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-2d87845c-80c8-4177-8d2d-a96ea4c161bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-440210132-172.17.0.4-1597355017226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33119,DS-36c1b9f6-9219-4842-bfe5-2ae522f2026c,DISK], DatanodeInfoWithStorage[127.0.0.1:34401,DS-02a94f2f-9cca-412e-bdcd-7021ce941735,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-1c7ecf61-8893-451d-a3f0-18a1f71f818f,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-94475d24-0e04-4f74-8fd1-8eaebacf0745,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-0a56cd9f-bc46-4ed8-87ac-409695b5092f,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-5787f77c-ac7f-428a-ba7d-1c905be90fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-35b2a09c-de75-4169-97f3-a028b0516f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-2d87845c-80c8-4177-8d2d-a96ea4c161bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-996457960-172.17.0.4-1597355115501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38009,DS-16aa65a5-dd96-4502-ae4c-59a99e4e779c,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-7bd20164-4ff1-4a2e-b879-97cd1f5c4bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-0fd5db57-c2e6-4aa1-bb40-c0309bccc5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-961b4566-96f2-42b1-87d7-f7f1d7d08de2,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-4a6be66d-f0c6-4a09-8067-adc78c3626d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-7f4fee9f-4fa6-4871-98f1-2e63f0abdabc,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-631879f9-ac40-4ca2-8968-e01cdd8006d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-6ee26210-60a7-4adc-ad70-e8de62788c2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-996457960-172.17.0.4-1597355115501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38009,DS-16aa65a5-dd96-4502-ae4c-59a99e4e779c,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-7bd20164-4ff1-4a2e-b879-97cd1f5c4bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-0fd5db57-c2e6-4aa1-bb40-c0309bccc5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-961b4566-96f2-42b1-87d7-f7f1d7d08de2,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-4a6be66d-f0c6-4a09-8067-adc78c3626d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-7f4fee9f-4fa6-4871-98f1-2e63f0abdabc,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-631879f9-ac40-4ca2-8968-e01cdd8006d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41685,DS-6ee26210-60a7-4adc-ad70-e8de62788c2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-46399968-172.17.0.4-1597355144489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37061,DS-23114370-d51c-487b-a72c-33e52ee1168a,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-6d8d99d0-b5ad-4282-a73b-0c1da4f0d0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-702ab276-1447-4ed3-86b7-f49f80fb9128,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-66cb769f-0c28-4364-9fa4-bbafb721b92d,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-be12d77a-7569-4153-873c-cca1237255d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-61086ac5-47bd-4b98-80fa-c9857ae8bf1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-77571589-f4c5-40db-9dca-42e1cae98aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-40907fd5-5ed1-442a-b181-13af13f139b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-46399968-172.17.0.4-1597355144489:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37061,DS-23114370-d51c-487b-a72c-33e52ee1168a,DISK], DatanodeInfoWithStorage[127.0.0.1:34637,DS-6d8d99d0-b5ad-4282-a73b-0c1da4f0d0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-702ab276-1447-4ed3-86b7-f49f80fb9128,DISK], DatanodeInfoWithStorage[127.0.0.1:45161,DS-66cb769f-0c28-4364-9fa4-bbafb721b92d,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-be12d77a-7569-4153-873c-cca1237255d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-61086ac5-47bd-4b98-80fa-c9857ae8bf1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-77571589-f4c5-40db-9dca-42e1cae98aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:32893,DS-40907fd5-5ed1-442a-b181-13af13f139b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-502329187-172.17.0.4-1597355411622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38967,DS-60d547b1-cf7b-4571-add4-9f59a0ad5a33,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-363ca835-4bf9-479b-91d3-639f10790cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-6795eb92-1b65-4e14-a5a6-cf446ab79686,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-3f0642f2-5940-4301-994a-95e4468f732d,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-321e5030-5759-4c0a-bcb7-8eeaca59eb64,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-219310b3-7449-4c04-b9b4-178dc1a8cbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-a24aa0c3-ce8f-45e9-a046-27e89026dba7,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-9df3a068-d010-4359-96a6-fd0cd67803f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-502329187-172.17.0.4-1597355411622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38967,DS-60d547b1-cf7b-4571-add4-9f59a0ad5a33,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-363ca835-4bf9-479b-91d3-639f10790cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35101,DS-6795eb92-1b65-4e14-a5a6-cf446ab79686,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-3f0642f2-5940-4301-994a-95e4468f732d,DISK], DatanodeInfoWithStorage[127.0.0.1:37652,DS-321e5030-5759-4c0a-bcb7-8eeaca59eb64,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-219310b3-7449-4c04-b9b4-178dc1a8cbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-a24aa0c3-ce8f-45e9-a046-27e89026dba7,DISK], DatanodeInfoWithStorage[127.0.0.1:43617,DS-9df3a068-d010-4359-96a6-fd0cd67803f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1093107129-172.17.0.4-1597355524376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32946,DS-6dc7ddcd-5447-4d01-8ed0-9f355fb0754c,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-eb3a8093-e705-40b1-b7b4-b51ed3e510a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-89456dad-b09e-4e52-99ee-0099b965926d,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-2229342c-f55e-4403-b2dc-1e6cadb9c7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-4c85702f-a7da-480e-bb0d-9bc35bd2dc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-86e5b3d4-f63b-4f79-a506-803644e2dedc,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-7e77d737-8be5-4379-a930-9d919eb65af4,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-33d9de79-4831-4cc0-b94b-edb81aea8923,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1093107129-172.17.0.4-1597355524376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32946,DS-6dc7ddcd-5447-4d01-8ed0-9f355fb0754c,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-eb3a8093-e705-40b1-b7b4-b51ed3e510a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-89456dad-b09e-4e52-99ee-0099b965926d,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-2229342c-f55e-4403-b2dc-1e6cadb9c7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-4c85702f-a7da-480e-bb0d-9bc35bd2dc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-86e5b3d4-f63b-4f79-a506-803644e2dedc,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-7e77d737-8be5-4379-a930-9d919eb65af4,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-33d9de79-4831-4cc0-b94b-edb81aea8923,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-729093695-172.17.0.4-1597355737865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42361,DS-b9a3ac46-a797-4bc1-8d0d-b8f194b53697,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-adcb8a6c-ac47-4071-9a66-7f5b1d4fc02c,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-0d967fd6-7b90-449c-9c6f-d08cfe3d777b,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-aebd0a4d-beff-46ae-9e4a-a0e766fd3009,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-a38b98b6-af1f-40d1-9653-ef5fb2c87e89,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-e475717c-5a9d-4714-83a0-9891cb983313,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-39abc82c-363e-4ed2-931a-4d1671a162dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-b2b4ec71-8914-4c24-9334-1d636370abdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-729093695-172.17.0.4-1597355737865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42361,DS-b9a3ac46-a797-4bc1-8d0d-b8f194b53697,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-adcb8a6c-ac47-4071-9a66-7f5b1d4fc02c,DISK], DatanodeInfoWithStorage[127.0.0.1:38779,DS-0d967fd6-7b90-449c-9c6f-d08cfe3d777b,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-aebd0a4d-beff-46ae-9e4a-a0e766fd3009,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-a38b98b6-af1f-40d1-9653-ef5fb2c87e89,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-e475717c-5a9d-4714-83a0-9891cb983313,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-39abc82c-363e-4ed2-931a-4d1671a162dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-b2b4ec71-8914-4c24-9334-1d636370abdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1390496723-172.17.0.4-1597356160403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46803,DS-1c187f34-12a1-4ae5-9c7c-5718f33afedb,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-c6d44b1b-24eb-4792-ad8f-597c32af3876,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-b9b05a9f-f0dc-4a1c-a445-d8bf6e578ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-0d2ac490-08e3-4779-ac5b-1f3a34b0659e,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-7fbe222e-a5eb-4407-83f8-3f46b1c57858,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-a97e58af-a5ae-4dd2-9af6-776d55acc7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-ae7255b2-f1c9-43c7-bccd-c491c88915b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-0ac89e4e-cfba-4dc6-8dab-cd607aed59fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1390496723-172.17.0.4-1597356160403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46803,DS-1c187f34-12a1-4ae5-9c7c-5718f33afedb,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-c6d44b1b-24eb-4792-ad8f-597c32af3876,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-b9b05a9f-f0dc-4a1c-a445-d8bf6e578ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-0d2ac490-08e3-4779-ac5b-1f3a34b0659e,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-7fbe222e-a5eb-4407-83f8-3f46b1c57858,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-a97e58af-a5ae-4dd2-9af6-776d55acc7eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-ae7255b2-f1c9-43c7-bccd-c491c88915b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39198,DS-0ac89e4e-cfba-4dc6-8dab-cd607aed59fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356786000-172.17.0.4-1597356543253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38974,DS-290625ad-c152-4c0c-8d7d-77274fb978eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-cea062f8-cc91-442c-9c03-1042b4703607,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-3fdbe92e-c626-46bb-8be2-d8ee5aac559c,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-128de4dc-2ef8-4489-97e2-28275e2813c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-7022c6a6-e44d-4e58-abe1-fed6b35a127e,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-6b56c730-d6ec-491d-98f6-09eb78477f43,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-31d96c33-f3e1-4953-9c04-6c867f3ed4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-1d680aeb-f847-4c95-b270-ca2528415e32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356786000-172.17.0.4-1597356543253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38974,DS-290625ad-c152-4c0c-8d7d-77274fb978eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42863,DS-cea062f8-cc91-442c-9c03-1042b4703607,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-3fdbe92e-c626-46bb-8be2-d8ee5aac559c,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-128de4dc-2ef8-4489-97e2-28275e2813c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-7022c6a6-e44d-4e58-abe1-fed6b35a127e,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-6b56c730-d6ec-491d-98f6-09eb78477f43,DISK], DatanodeInfoWithStorage[127.0.0.1:34088,DS-31d96c33-f3e1-4953-9c04-6c867f3ed4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-1d680aeb-f847-4c95-b270-ca2528415e32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343795695-172.17.0.4-1597357202758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44328,DS-5ccaf436-be24-49c7-b366-2db3b49360b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39487,DS-9eb59c38-57bb-4425-881a-1a34fda6136e,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-59086b3b-0c6b-49f8-b92c-6db460e4311b,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-01e2d517-b088-4bac-814b-d943a4a76534,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-8161a11b-a518-4534-8b72-a9f0ac80d01c,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-fc7c36f9-20ee-4308-8f7f-10fd454447e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-8c442e8a-360f-4507-aa03-dd5d077b11ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-24821030-dc51-4113-99d2-5c8e512714fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-343795695-172.17.0.4-1597357202758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44328,DS-5ccaf436-be24-49c7-b366-2db3b49360b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39487,DS-9eb59c38-57bb-4425-881a-1a34fda6136e,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-59086b3b-0c6b-49f8-b92c-6db460e4311b,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-01e2d517-b088-4bac-814b-d943a4a76534,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-8161a11b-a518-4534-8b72-a9f0ac80d01c,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-fc7c36f9-20ee-4308-8f7f-10fd454447e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-8c442e8a-360f-4507-aa03-dd5d077b11ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-24821030-dc51-4113-99d2-5c8e512714fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117114042-172.17.0.4-1597357393185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33207,DS-9f9ef668-bd2a-4e9c-86b9-b7efa3be3241,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-bf9e4847-a3c2-4269-94bf-1ae67b5ca246,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-385ca74a-cbbc-4a80-9c9f-bb297b754b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-99898fe0-ef9d-4993-adcf-3047439e4a04,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-d793461c-8d3b-4fbb-94c6-8d4b24422921,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-03c6eaf7-9f8d-4334-9e16-fad09357efd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-0c5f9034-eae1-4143-b22e-5f82d5a8dcc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-af860cc5-d65a-406b-bcd8-07d181dff5ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117114042-172.17.0.4-1597357393185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33207,DS-9f9ef668-bd2a-4e9c-86b9-b7efa3be3241,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-bf9e4847-a3c2-4269-94bf-1ae67b5ca246,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-385ca74a-cbbc-4a80-9c9f-bb297b754b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-99898fe0-ef9d-4993-adcf-3047439e4a04,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-d793461c-8d3b-4fbb-94c6-8d4b24422921,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-03c6eaf7-9f8d-4334-9e16-fad09357efd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-0c5f9034-eae1-4143-b22e-5f82d5a8dcc3,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-af860cc5-d65a-406b-bcd8-07d181dff5ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-525052420-172.17.0.4-1597357885324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42273,DS-da63f406-e6fc-41c9-be03-41cd7d3f2bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-65b4419b-e93d-41ec-9f1b-ce65aa53a2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-454fc26d-202f-4d03-92ba-5967ada78ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-4678d51d-ff0a-44e2-911e-20af3b9b2869,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-9a6b5fc5-929d-4462-9730-076c2bc78682,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-deb74730-511e-43f0-a832-765fda173079,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-bce8d021-7c5a-407c-b156-cdb505d7b8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-8290ba64-6e05-4d8f-be39-0906f1ea6388,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-525052420-172.17.0.4-1597357885324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42273,DS-da63f406-e6fc-41c9-be03-41cd7d3f2bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-65b4419b-e93d-41ec-9f1b-ce65aa53a2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-454fc26d-202f-4d03-92ba-5967ada78ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-4678d51d-ff0a-44e2-911e-20af3b9b2869,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-9a6b5fc5-929d-4462-9730-076c2bc78682,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-deb74730-511e-43f0-a832-765fda173079,DISK], DatanodeInfoWithStorage[127.0.0.1:38334,DS-bce8d021-7c5a-407c-b156-cdb505d7b8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-8290ba64-6e05-4d8f-be39-0906f1ea6388,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1784627860-172.17.0.4-1597358325565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44546,DS-60dc1822-db68-4cfc-98eb-7eea5bacdabb,DISK], DatanodeInfoWithStorage[127.0.0.1:46313,DS-0e68398c-52c0-4341-aa03-dca722868f92,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-307eed6f-5c4e-4774-95a2-ab9f50f5e5de,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-2d7bee7f-21b8-493c-97f3-e75715c57cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-73d290b1-310a-4b43-be59-bf5cce4e464f,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-a9da0174-5952-4bed-922b-8a84f35efd92,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-d09515a5-9fa2-4a9a-966c-994f64d16ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-518dc398-e97a-455b-b8a6-2170da0c93b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1784627860-172.17.0.4-1597358325565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44546,DS-60dc1822-db68-4cfc-98eb-7eea5bacdabb,DISK], DatanodeInfoWithStorage[127.0.0.1:46313,DS-0e68398c-52c0-4341-aa03-dca722868f92,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-307eed6f-5c4e-4774-95a2-ab9f50f5e5de,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-2d7bee7f-21b8-493c-97f3-e75715c57cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-73d290b1-310a-4b43-be59-bf5cce4e464f,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-a9da0174-5952-4bed-922b-8a84f35efd92,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-d09515a5-9fa2-4a9a-966c-994f64d16ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-518dc398-e97a-455b-b8a6-2170da0c93b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-137187049-172.17.0.4-1597358445577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37774,DS-f985d2ea-699c-46ab-8b78-614a32da8d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-e14dc6f0-82ff-4b50-a01f-657556c63192,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-c95a4bd2-265e-416e-9d26-0b5567a1e1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-f1a32b42-514e-49f4-9ffe-4d759a4001d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-8e4908fe-e0ad-4635-b846-efa1dd13b4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-19f2a0ef-8b08-4448-a429-5b4d197a380f,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-9b3e7aee-c5b8-48d4-b9bc-56247889035e,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-c24e2a7b-aa09-4bc2-ae08-2b4c18079602,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-137187049-172.17.0.4-1597358445577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37774,DS-f985d2ea-699c-46ab-8b78-614a32da8d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43538,DS-e14dc6f0-82ff-4b50-a01f-657556c63192,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-c95a4bd2-265e-416e-9d26-0b5567a1e1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-f1a32b42-514e-49f4-9ffe-4d759a4001d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-8e4908fe-e0ad-4635-b846-efa1dd13b4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-19f2a0ef-8b08-4448-a429-5b4d197a380f,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-9b3e7aee-c5b8-48d4-b9bc-56247889035e,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-c24e2a7b-aa09-4bc2-ae08-2b4c18079602,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315964906-172.17.0.4-1597358630642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41717,DS-52f2e695-d68f-453b-815d-28eee3c3a410,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-c2c826ef-7739-4992-9162-62c72c36de32,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-9f1e327e-1915-45cf-9610-3384fe6fb7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-93292d12-b20f-47c0-8ced-9715d4185dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-13878108-4457-4487-b9a4-62044dcb71c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-758c02b7-90de-4ec7-9417-89ab5442f78d,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-1a38b0dc-b07b-4346-a323-8df10bf97907,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-dbe32385-98b4-4b69-b899-80303a146c29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-315964906-172.17.0.4-1597358630642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41717,DS-52f2e695-d68f-453b-815d-28eee3c3a410,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-c2c826ef-7739-4992-9162-62c72c36de32,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-9f1e327e-1915-45cf-9610-3384fe6fb7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-93292d12-b20f-47c0-8ced-9715d4185dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-13878108-4457-4487-b9a4-62044dcb71c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-758c02b7-90de-4ec7-9417-89ab5442f78d,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-1a38b0dc-b07b-4346-a323-8df10bf97907,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-dbe32385-98b4-4b69-b899-80303a146c29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1867650565-172.17.0.4-1597358662846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43760,DS-93c92728-92b4-446e-a938-d33df0ea07e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-c551136a-63ef-4c27-afc4-31905c35ed1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-3429ecdb-f9ef-4df4-9ea2-b51cc7aa29b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-7a819b31-3fd3-4548-82ae-56d5e6fb634d,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-994589c6-6360-4a7e-ae37-82fde91a0a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-4e332959-e3d3-4fa8-b2b3-9dee6b334acf,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-7fc1a138-9203-4557-9668-37dbf528a56a,DISK], DatanodeInfoWithStorage[127.0.0.1:40005,DS-bae60ad9-410a-446b-88cb-299d5e55ff8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1867650565-172.17.0.4-1597358662846:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43760,DS-93c92728-92b4-446e-a938-d33df0ea07e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-c551136a-63ef-4c27-afc4-31905c35ed1d,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-3429ecdb-f9ef-4df4-9ea2-b51cc7aa29b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-7a819b31-3fd3-4548-82ae-56d5e6fb634d,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-994589c6-6360-4a7e-ae37-82fde91a0a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-4e332959-e3d3-4fa8-b2b3-9dee6b334acf,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-7fc1a138-9203-4557-9668-37dbf528a56a,DISK], DatanodeInfoWithStorage[127.0.0.1:40005,DS-bae60ad9-410a-446b-88cb-299d5e55ff8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-77580922-172.17.0.4-1597358695492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46538,DS-c5afaea1-b72b-4464-8809-acc6abdb7c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-f980f3ce-2e7c-4e3a-91c7-111c6b4b7435,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-2cde5641-321a-4287-a3b1-4f92b0fc06c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-3d938e41-218e-4d93-805f-204b9c595591,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-b88b1217-bafc-4817-850e-e617a80543e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-d2787ac7-2c07-4c0b-8943-cc5ad6f22d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-57624bbd-790a-4c19-8d41-3b48279df098,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-01ee6e8f-21ce-462b-9098-a61c82fc125f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-77580922-172.17.0.4-1597358695492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46538,DS-c5afaea1-b72b-4464-8809-acc6abdb7c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35120,DS-f980f3ce-2e7c-4e3a-91c7-111c6b4b7435,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-2cde5641-321a-4287-a3b1-4f92b0fc06c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-3d938e41-218e-4d93-805f-204b9c595591,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-b88b1217-bafc-4817-850e-e617a80543e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42257,DS-d2787ac7-2c07-4c0b-8943-cc5ad6f22d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-57624bbd-790a-4c19-8d41-3b48279df098,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-01ee6e8f-21ce-462b-9098-a61c82fc125f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5627
