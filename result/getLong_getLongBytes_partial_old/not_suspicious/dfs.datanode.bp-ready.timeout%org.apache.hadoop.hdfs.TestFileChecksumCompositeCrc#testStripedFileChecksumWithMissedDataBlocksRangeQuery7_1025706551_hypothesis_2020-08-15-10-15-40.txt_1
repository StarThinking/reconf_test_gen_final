reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1080871889-172.17.0.5-1597486559172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43910,DS-92d278ad-bf77-4183-9c74-b2487701df82,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-0def87a5-0aa5-4212-bd80-dd6a8c24be0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-e9a5ec64-8222-4672-a576-ab11006a843a,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-78a528da-66e3-415a-b6e2-7e253c865ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-6326e96b-f5ed-4038-bde9-09de7b1a2e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-6aceb5ae-33f9-4c58-bce8-ff1df72ece65,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-0a85d399-0501-4515-9f41-1eac6c56b58c,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-1b82afd6-dccc-4400-a5d9-2efa0a729baf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1080871889-172.17.0.5-1597486559172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43910,DS-92d278ad-bf77-4183-9c74-b2487701df82,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-0def87a5-0aa5-4212-bd80-dd6a8c24be0e,DISK], DatanodeInfoWithStorage[127.0.0.1:39343,DS-e9a5ec64-8222-4672-a576-ab11006a843a,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-78a528da-66e3-415a-b6e2-7e253c865ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-6326e96b-f5ed-4038-bde9-09de7b1a2e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-6aceb5ae-33f9-4c58-bce8-ff1df72ece65,DISK], DatanodeInfoWithStorage[127.0.0.1:39564,DS-0a85d399-0501-4515-9f41-1eac6c56b58c,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-1b82afd6-dccc-4400-a5d9-2efa0a729baf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-175224046-172.17.0.5-1597486597485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40327,DS-b8287963-fda5-42fc-a20f-e889d0d4a1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-4e2d2e9c-5bd2-468a-a5d5-95b32bbe9397,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-0b4f3f7e-c514-4c66-9544-81c893533367,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-ad5a6a94-4df9-4b3d-bd33-d73b09911a99,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-af87f379-da99-4b85-a644-48f5e7562283,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-27d2d921-5793-4752-9818-07fb11a86bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-19a63964-8477-4668-92b1-b784b82ca05a,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-f2187df7-75f7-4c52-8eb1-47635f1a94ce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-175224046-172.17.0.5-1597486597485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40327,DS-b8287963-fda5-42fc-a20f-e889d0d4a1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45646,DS-4e2d2e9c-5bd2-468a-a5d5-95b32bbe9397,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-0b4f3f7e-c514-4c66-9544-81c893533367,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-ad5a6a94-4df9-4b3d-bd33-d73b09911a99,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-af87f379-da99-4b85-a644-48f5e7562283,DISK], DatanodeInfoWithStorage[127.0.0.1:38442,DS-27d2d921-5793-4752-9818-07fb11a86bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39876,DS-19a63964-8477-4668-92b1-b784b82ca05a,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-f2187df7-75f7-4c52-8eb1-47635f1a94ce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2002273856-172.17.0.5-1597486754373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36069,DS-52bab7d8-0874-4e96-b499-a2c8200db2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-b4cccf2d-56dc-49ad-ab50-da2ce65df608,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-6a9f8615-46f2-4da4-b674-8310baac78bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-d573a4af-e960-42e1-8d30-e9f10abc326e,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-122f9561-f65f-4017-857f-76707359d846,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-be7c6c09-89ff-4df2-9e0c-de2a736ec005,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-0166a0ee-7155-4861-9a95-71271cfcbe45,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-fe35560f-f795-4ee4-9715-fbc77d8aa159,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2002273856-172.17.0.5-1597486754373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36069,DS-52bab7d8-0874-4e96-b499-a2c8200db2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-b4cccf2d-56dc-49ad-ab50-da2ce65df608,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-6a9f8615-46f2-4da4-b674-8310baac78bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-d573a4af-e960-42e1-8d30-e9f10abc326e,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-122f9561-f65f-4017-857f-76707359d846,DISK], DatanodeInfoWithStorage[127.0.0.1:38799,DS-be7c6c09-89ff-4df2-9e0c-de2a736ec005,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-0166a0ee-7155-4861-9a95-71271cfcbe45,DISK], DatanodeInfoWithStorage[127.0.0.1:39046,DS-fe35560f-f795-4ee4-9715-fbc77d8aa159,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443672494-172.17.0.5-1597486835773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45226,DS-0a0b4bb3-1128-48ee-957f-82880c19e738,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-f1797276-0692-4e5a-a45d-e42c59d6a9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-ddde4947-ed96-44aa-98f9-c7b18cac988f,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-4fd53353-d5c1-4d4a-b080-a6821d90dc12,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-34077173-d71e-4f30-ab8f-00cff29795f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-4e81e4a2-e079-4013-aa36-0bfac8b1117a,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-26d4d1b6-1720-4cdb-a86a-c769e817836b,DISK], DatanodeInfoWithStorage[127.0.0.1:35127,DS-6573fd41-1265-440b-8f0e-4788ecfadbd4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443672494-172.17.0.5-1597486835773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45226,DS-0a0b4bb3-1128-48ee-957f-82880c19e738,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-f1797276-0692-4e5a-a45d-e42c59d6a9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-ddde4947-ed96-44aa-98f9-c7b18cac988f,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-4fd53353-d5c1-4d4a-b080-a6821d90dc12,DISK], DatanodeInfoWithStorage[127.0.0.1:46271,DS-34077173-d71e-4f30-ab8f-00cff29795f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-4e81e4a2-e079-4013-aa36-0bfac8b1117a,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-26d4d1b6-1720-4cdb-a86a-c769e817836b,DISK], DatanodeInfoWithStorage[127.0.0.1:35127,DS-6573fd41-1265-440b-8f0e-4788ecfadbd4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-279629432-172.17.0.5-1597486986665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45916,DS-e9dfc630-f32c-4319-b65d-3a9acabbe895,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-f571c0fe-cf6b-4935-bdc7-62d44b199af8,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-83807e0c-faba-4c77-8a59-2b898eeb2082,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-146bdde3-4d10-4fe2-8a57-4aa5af95710a,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-e9f6ade6-89e0-4bbf-9c63-c2d749fa848a,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-599c86e4-d218-4fec-8b13-b89a6ccca484,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-db84d04e-549b-489a-895a-f5e52c24df17,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-95ec1bb6-c5ca-4870-9815-a1b7d00d9e0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-279629432-172.17.0.5-1597486986665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45916,DS-e9dfc630-f32c-4319-b65d-3a9acabbe895,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-f571c0fe-cf6b-4935-bdc7-62d44b199af8,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-83807e0c-faba-4c77-8a59-2b898eeb2082,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-146bdde3-4d10-4fe2-8a57-4aa5af95710a,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-e9f6ade6-89e0-4bbf-9c63-c2d749fa848a,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-599c86e4-d218-4fec-8b13-b89a6ccca484,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-db84d04e-549b-489a-895a-f5e52c24df17,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-95ec1bb6-c5ca-4870-9815-a1b7d00d9e0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1419843575-172.17.0.5-1597487213330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41218,DS-95e30bba-739d-4538-a1ba-077ff844508e,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-79690e82-98ba-4a7c-840f-6ea97ea5cd66,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-130e62da-e410-43cf-91f4-c2334672c297,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-5525da66-34dd-4afb-b90f-33d13d2a9b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:32977,DS-6a8092f6-95e2-4216-8bb9-d62a504241a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-54d3f836-372d-4454-be46-68b99357ceca,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-5bdc3164-73fb-48e0-bbd2-6ac2690908e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-883ef35e-0525-4766-953c-0f792db815d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1419843575-172.17.0.5-1597487213330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41218,DS-95e30bba-739d-4538-a1ba-077ff844508e,DISK], DatanodeInfoWithStorage[127.0.0.1:36674,DS-79690e82-98ba-4a7c-840f-6ea97ea5cd66,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-130e62da-e410-43cf-91f4-c2334672c297,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-5525da66-34dd-4afb-b90f-33d13d2a9b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:32977,DS-6a8092f6-95e2-4216-8bb9-d62a504241a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-54d3f836-372d-4454-be46-68b99357ceca,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-5bdc3164-73fb-48e0-bbd2-6ac2690908e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-883ef35e-0525-4766-953c-0f792db815d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-79948715-172.17.0.5-1597487299004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44106,DS-be4f50b3-2eba-458c-98cb-3c89c99f2842,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-2260a128-b149-41df-9fab-0eb2815ad518,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-3a57f351-faeb-461e-ae4f-56b38a9d8d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-f6637dac-44ba-4644-be62-74d5aeb06418,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-ffc5b35e-6f87-45f1-8ea0-c9ae060324fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-09513890-940f-4dc4-880a-134a8894010c,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-859de398-92f7-40d1-ba2a-c17154a69547,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-1e40ff41-8afd-4cb9-9928-9f62f4ef1ee6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-79948715-172.17.0.5-1597487299004:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44106,DS-be4f50b3-2eba-458c-98cb-3c89c99f2842,DISK], DatanodeInfoWithStorage[127.0.0.1:42590,DS-2260a128-b149-41df-9fab-0eb2815ad518,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-3a57f351-faeb-461e-ae4f-56b38a9d8d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-f6637dac-44ba-4644-be62-74d5aeb06418,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-ffc5b35e-6f87-45f1-8ea0-c9ae060324fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-09513890-940f-4dc4-880a-134a8894010c,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-859de398-92f7-40d1-ba2a-c17154a69547,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-1e40ff41-8afd-4cb9-9928-9f62f4ef1ee6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1828827451-172.17.0.5-1597487337966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40306,DS-c9f09aa5-0ec0-445b-8238-2f9428d0cc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-7467b348-fdc6-4407-b250-6d1b735f67ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-d0b87ce1-8019-4fa7-ba08-4b6ea316f0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-22a8303c-25a6-40cf-8e7b-6206f9989eae,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-dbaec311-1e99-46da-ad6b-ebc401f64282,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-0cbfc249-b3a4-4161-a988-81f11fb57d60,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-987a1f5f-b74d-4b4b-a469-8adf5690c5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-9f02799e-f226-4a10-bb60-07dc4d6bd813,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1828827451-172.17.0.5-1597487337966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40306,DS-c9f09aa5-0ec0-445b-8238-2f9428d0cc5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-7467b348-fdc6-4407-b250-6d1b735f67ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-d0b87ce1-8019-4fa7-ba08-4b6ea316f0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-22a8303c-25a6-40cf-8e7b-6206f9989eae,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-dbaec311-1e99-46da-ad6b-ebc401f64282,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-0cbfc249-b3a4-4161-a988-81f11fb57d60,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-987a1f5f-b74d-4b4b-a469-8adf5690c5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-9f02799e-f226-4a10-bb60-07dc4d6bd813,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484024187-172.17.0.5-1597487417317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39913,DS-9c542c2a-e280-401b-bc0e-1502a32f3da5,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-4caf4c4a-718c-4460-b436-f9368ad43777,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-3460d9d4-ea2b-423f-8eeb-5f08cd173e85,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-504989b3-27b8-4376-949a-4756739f91a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-15ad14b5-9b04-42be-a374-fb5c4ca21ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-9c6408d6-f6a7-475c-bed5-495a70d73cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-9f46689b-985d-4833-b856-2db66e4affbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-8afb98d9-0d0f-4638-aa57-7e0943f19706,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484024187-172.17.0.5-1597487417317:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39913,DS-9c542c2a-e280-401b-bc0e-1502a32f3da5,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-4caf4c4a-718c-4460-b436-f9368ad43777,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-3460d9d4-ea2b-423f-8eeb-5f08cd173e85,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-504989b3-27b8-4376-949a-4756739f91a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-15ad14b5-9b04-42be-a374-fb5c4ca21ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-9c6408d6-f6a7-475c-bed5-495a70d73cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-9f46689b-985d-4833-b856-2db66e4affbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-8afb98d9-0d0f-4638-aa57-7e0943f19706,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1382122596-172.17.0.5-1597487500815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46047,DS-ac5a1e12-2d54-40b5-9e2b-51ddcc52e761,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-6e638ecc-3c25-4777-b246-e9b889bca277,DISK], DatanodeInfoWithStorage[127.0.0.1:42713,DS-57fa4193-a40d-4391-9359-92c39d12bb11,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-bf6a3bc0-709a-4b4a-97f2-0bd84f57db42,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-25e0a93f-3c78-42ed-b8f2-a37b896acdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-5e3eb2a5-6719-4df9-8d29-c926f405942e,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-56c0525b-6c5c-428d-8139-aa543c726f04,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-2f9608d7-91e1-418b-b5d7-bffd108c6f03,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1382122596-172.17.0.5-1597487500815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46047,DS-ac5a1e12-2d54-40b5-9e2b-51ddcc52e761,DISK], DatanodeInfoWithStorage[127.0.0.1:38627,DS-6e638ecc-3c25-4777-b246-e9b889bca277,DISK], DatanodeInfoWithStorage[127.0.0.1:42713,DS-57fa4193-a40d-4391-9359-92c39d12bb11,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-bf6a3bc0-709a-4b4a-97f2-0bd84f57db42,DISK], DatanodeInfoWithStorage[127.0.0.1:43800,DS-25e0a93f-3c78-42ed-b8f2-a37b896acdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-5e3eb2a5-6719-4df9-8d29-c926f405942e,DISK], DatanodeInfoWithStorage[127.0.0.1:45295,DS-56c0525b-6c5c-428d-8139-aa543c726f04,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-2f9608d7-91e1-418b-b5d7-bffd108c6f03,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1014722469-172.17.0.5-1597487614040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39542,DS-d635e5ed-cd0b-4660-9a3d-6d4d1456b02f,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-6f8e4c97-d04b-49ba-b0cd-9205ae2d9300,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-8c69c808-9e46-476f-ba67-1f4c0a6b65cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-87ca2adb-024f-47e4-a27d-85c4ed6d5339,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-9e7a657a-bf5f-4dca-b0c3-bdcde027078b,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-53c59b58-34a6-492d-9cf8-f68cd09344be,DISK], DatanodeInfoWithStorage[127.0.0.1:32978,DS-015a12b4-c758-4607-b7c3-727ecbb94804,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-5f927230-176b-4ca4-9eb6-1e7083327650,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1014722469-172.17.0.5-1597487614040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39542,DS-d635e5ed-cd0b-4660-9a3d-6d4d1456b02f,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-6f8e4c97-d04b-49ba-b0cd-9205ae2d9300,DISK], DatanodeInfoWithStorage[127.0.0.1:43407,DS-8c69c808-9e46-476f-ba67-1f4c0a6b65cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-87ca2adb-024f-47e4-a27d-85c4ed6d5339,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-9e7a657a-bf5f-4dca-b0c3-bdcde027078b,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-53c59b58-34a6-492d-9cf8-f68cd09344be,DISK], DatanodeInfoWithStorage[127.0.0.1:32978,DS-015a12b4-c758-4607-b7c3-727ecbb94804,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-5f927230-176b-4ca4-9eb6-1e7083327650,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914958011-172.17.0.5-1597487701016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34461,DS-7ccbf068-8965-44d2-acfd-5e39c02bae3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-52015d50-0254-4784-bee3-4fb26f7d11a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-3b010710-55b5-4d6a-9481-2bada5868195,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-6d6b13d7-4b64-4b08-9da5-c0af95a5f40e,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-26e5d711-2cdf-4126-b2ac-324723d9fbee,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-9e2ee5db-91ff-4626-8afc-8967340b89f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-ca989439-4962-4c11-acab-0c545d69c1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-44d8e462-20dc-4122-82ae-0131504a110b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914958011-172.17.0.5-1597487701016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34461,DS-7ccbf068-8965-44d2-acfd-5e39c02bae3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-52015d50-0254-4784-bee3-4fb26f7d11a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-3b010710-55b5-4d6a-9481-2bada5868195,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-6d6b13d7-4b64-4b08-9da5-c0af95a5f40e,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-26e5d711-2cdf-4126-b2ac-324723d9fbee,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-9e2ee5db-91ff-4626-8afc-8967340b89f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-ca989439-4962-4c11-acab-0c545d69c1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40099,DS-44d8e462-20dc-4122-82ae-0131504a110b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1520389747-172.17.0.5-1597487849427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39571,DS-0a1329be-9ed9-4efc-8b6d-0d51b1962f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-654c8b22-313f-4c55-a72a-6f5980b24079,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-a537dda6-083b-428a-8994-c40a229ad8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36565,DS-8cc4c1ac-bd01-4d8d-be91-fa5aed655f75,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-5e2354df-fd10-4895-a3d3-a12209a4f610,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-4ad9d277-6611-4327-96ef-57915c3c191f,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-3a39b67d-6fe4-4d12-9ef5-86a1ad5ed43a,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-522bbad5-71fe-4ceb-b6b7-e9ccbab4a3f2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1520389747-172.17.0.5-1597487849427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39571,DS-0a1329be-9ed9-4efc-8b6d-0d51b1962f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-654c8b22-313f-4c55-a72a-6f5980b24079,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-a537dda6-083b-428a-8994-c40a229ad8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36565,DS-8cc4c1ac-bd01-4d8d-be91-fa5aed655f75,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-5e2354df-fd10-4895-a3d3-a12209a4f610,DISK], DatanodeInfoWithStorage[127.0.0.1:33768,DS-4ad9d277-6611-4327-96ef-57915c3c191f,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-3a39b67d-6fe4-4d12-9ef5-86a1ad5ed43a,DISK], DatanodeInfoWithStorage[127.0.0.1:38152,DS-522bbad5-71fe-4ceb-b6b7-e9ccbab4a3f2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-125752911-172.17.0.5-1597488048399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41391,DS-08e1454b-9d2a-4806-bfd1-3bdd3c723aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-c53e760a-8da9-4591-b77e-3234dddb1f49,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-32ae5f02-b7c3-46cd-8466-b4ff584fdd13,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-01741aea-c5b5-4618-8ac4-a0bd10836a69,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-e93870e7-1615-4632-81a6-0a0f3f19f81f,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-8078629b-6691-4d96-ba09-5c2a4dd7c1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-9e7dd010-e24c-4882-b5e1-9a580ad8d5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-0f64b852-2102-4efe-91af-dfff34a743b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-125752911-172.17.0.5-1597488048399:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41391,DS-08e1454b-9d2a-4806-bfd1-3bdd3c723aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-c53e760a-8da9-4591-b77e-3234dddb1f49,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-32ae5f02-b7c3-46cd-8466-b4ff584fdd13,DISK], DatanodeInfoWithStorage[127.0.0.1:45727,DS-01741aea-c5b5-4618-8ac4-a0bd10836a69,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-e93870e7-1615-4632-81a6-0a0f3f19f81f,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-8078629b-6691-4d96-ba09-5c2a4dd7c1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-9e7dd010-e24c-4882-b5e1-9a580ad8d5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-0f64b852-2102-4efe-91af-dfff34a743b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1948512629-172.17.0.5-1597488091730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38439,DS-26c43e3a-d52f-4ebf-b0e1-71d587ea02a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-691a15d2-80b3-4da5-b921-657da95bbdc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-bc4b72b3-fbff-4a18-8cba-3ece295ba511,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-1e55ad9a-5148-4ed2-a79f-c3100591b08c,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-c3cca221-66dd-49c0-9f8d-64dc91bc9b03,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-7bba0e85-0ecc-4315-b485-c10a7ecc8cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-311afeef-398b-4f22-925a-8fcc01281312,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-c13301a6-6cc2-4d84-bf7f-b062f768b631,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1948512629-172.17.0.5-1597488091730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38439,DS-26c43e3a-d52f-4ebf-b0e1-71d587ea02a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37173,DS-691a15d2-80b3-4da5-b921-657da95bbdc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-bc4b72b3-fbff-4a18-8cba-3ece295ba511,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-1e55ad9a-5148-4ed2-a79f-c3100591b08c,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-c3cca221-66dd-49c0-9f8d-64dc91bc9b03,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-7bba0e85-0ecc-4315-b485-c10a7ecc8cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-311afeef-398b-4f22-925a-8fcc01281312,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-c13301a6-6cc2-4d84-bf7f-b062f768b631,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-944166928-172.17.0.5-1597488217966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38510,DS-31072001-e19d-4b30-a475-8b43223049de,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-8d719a8f-fefe-4413-b776-16698cc05b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-a8771fc8-91e5-4ae0-abb0-bb62dddcfd35,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-148795a5-38fd-4047-92d8-67e3ea169093,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-578f4884-d92c-4b7f-ae25-3f66d19d6b39,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-d158ee2c-8986-45db-8dd1-ae5c2769390a,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-df73212c-c2bb-4af1-b571-784905a19e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-bec892a9-e494-4b59-8de7-5a4d8efaa49d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-944166928-172.17.0.5-1597488217966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38510,DS-31072001-e19d-4b30-a475-8b43223049de,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-8d719a8f-fefe-4413-b776-16698cc05b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-a8771fc8-91e5-4ae0-abb0-bb62dddcfd35,DISK], DatanodeInfoWithStorage[127.0.0.1:41679,DS-148795a5-38fd-4047-92d8-67e3ea169093,DISK], DatanodeInfoWithStorage[127.0.0.1:38058,DS-578f4884-d92c-4b7f-ae25-3f66d19d6b39,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-d158ee2c-8986-45db-8dd1-ae5c2769390a,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-df73212c-c2bb-4af1-b571-784905a19e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34887,DS-bec892a9-e494-4b59-8de7-5a4d8efaa49d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-129542462-172.17.0.5-1597488262594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36874,DS-0a66aedc-e0b9-4e52-9fb2-0d2e4a197dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-572a0e15-cd71-4fab-a3cb-e8c367fef87b,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-52332ea8-ebf2-474c-a88c-d80192fa7e97,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-769fae6f-73b9-402f-8df5-6c9f1d5549d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-dd9017fb-57c6-413a-a5ef-c0b6691a341d,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-495332dc-adec-4528-b356-71eda1b74b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-60b31c6e-7bc4-4c8c-a302-48e43dba4c93,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-770f1cae-995f-4f61-a2e4-927e7deab857,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-129542462-172.17.0.5-1597488262594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36874,DS-0a66aedc-e0b9-4e52-9fb2-0d2e4a197dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-572a0e15-cd71-4fab-a3cb-e8c367fef87b,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-52332ea8-ebf2-474c-a88c-d80192fa7e97,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-769fae6f-73b9-402f-8df5-6c9f1d5549d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45619,DS-dd9017fb-57c6-413a-a5ef-c0b6691a341d,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-495332dc-adec-4528-b356-71eda1b74b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-60b31c6e-7bc4-4c8c-a302-48e43dba4c93,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-770f1cae-995f-4f61-a2e4-927e7deab857,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223633348-172.17.0.5-1597488297565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43550,DS-3263b13f-480a-48b0-b140-8492718b184e,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-9e6c6058-099c-4c64-8547-4bb31e849ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-781e23d1-544a-42e9-9a55-a23eb5e949ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-8fc8ac9a-a437-44bc-943a-87b49adfb39d,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-a98108c5-a6d2-44d7-89b2-83edaab22a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-aab7d9c7-7aab-4af9-b4d6-091caa69726a,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-ef994eff-2ff4-4fa7-8b10-168a0bad75b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-8edd5cca-c792-4a6e-af1f-1e1c5ec680ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223633348-172.17.0.5-1597488297565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43550,DS-3263b13f-480a-48b0-b140-8492718b184e,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-9e6c6058-099c-4c64-8547-4bb31e849ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-781e23d1-544a-42e9-9a55-a23eb5e949ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-8fc8ac9a-a437-44bc-943a-87b49adfb39d,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-a98108c5-a6d2-44d7-89b2-83edaab22a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-aab7d9c7-7aab-4af9-b4d6-091caa69726a,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-ef994eff-2ff4-4fa7-8b10-168a0bad75b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-8edd5cca-c792-4a6e-af1f-1e1c5ec680ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442290240-172.17.0.5-1597488408622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38883,DS-0eef90da-e56b-46d2-bc95-63816603475c,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-485de16b-216f-4b7b-8a89-6981e2a8157a,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-d8a68f9b-a93e-4451-b431-d405803bfbca,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-64396010-2d58-4c2f-89b9-8c9dbd17930a,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-9139fc6e-3ba9-4771-ae96-74bba7a3da77,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-a7994ba0-8e3f-498b-a88e-29d1999bd2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-9d709752-d726-426b-9821-2737e5c11045,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-849bd894-0f6d-45b8-82d2-302a3ff81b20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442290240-172.17.0.5-1597488408622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38883,DS-0eef90da-e56b-46d2-bc95-63816603475c,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-485de16b-216f-4b7b-8a89-6981e2a8157a,DISK], DatanodeInfoWithStorage[127.0.0.1:34759,DS-d8a68f9b-a93e-4451-b431-d405803bfbca,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-64396010-2d58-4c2f-89b9-8c9dbd17930a,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-9139fc6e-3ba9-4771-ae96-74bba7a3da77,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-a7994ba0-8e3f-498b-a88e-29d1999bd2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-9d709752-d726-426b-9821-2737e5c11045,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-849bd894-0f6d-45b8-82d2-302a3ff81b20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-925602943-172.17.0.5-1597488524305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41774,DS-480ead1a-3063-49c7-aa2d-8084171d1e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-98642d76-efc4-47eb-ac3d-3beaa615b3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-c37f62e8-b7af-43ab-96e6-0d493eb24aac,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-903014fd-9bf2-414c-b5f8-84162d18128a,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-c3ddadf3-38ed-42bf-bb1a-e5ce7cb11113,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-4a41e66d-5db0-4bcb-91b4-d18c758e8613,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-fc34d11b-eabd-43c3-bccf-24b6cd97d7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-3043e473-4395-4564-bccf-97af3c470287,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-925602943-172.17.0.5-1597488524305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41774,DS-480ead1a-3063-49c7-aa2d-8084171d1e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-98642d76-efc4-47eb-ac3d-3beaa615b3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-c37f62e8-b7af-43ab-96e6-0d493eb24aac,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-903014fd-9bf2-414c-b5f8-84162d18128a,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-c3ddadf3-38ed-42bf-bb1a-e5ce7cb11113,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-4a41e66d-5db0-4bcb-91b4-d18c758e8613,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-fc34d11b-eabd-43c3-bccf-24b6cd97d7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-3043e473-4395-4564-bccf-97af3c470287,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691506076-172.17.0.5-1597488605960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35968,DS-fda4ba4b-e092-4d07-8e97-68aad6b7053b,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-14e6d235-d9b1-4094-9d39-0b7c438b2343,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-6eabab61-5f41-46d8-a071-dedf4671a59c,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-c97478f4-f571-49ed-bc98-4fa40fc27cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-191918aa-8f0e-4f41-9825-8c7134f627a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-7e3e7ca9-9aa1-4541-96de-d4c3be39a502,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-eb84d2fd-e78f-4581-bb2a-c40b685cb2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40909,DS-134e78ae-3fa7-4c6e-ad24-76bbdee5296b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691506076-172.17.0.5-1597488605960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35968,DS-fda4ba4b-e092-4d07-8e97-68aad6b7053b,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-14e6d235-d9b1-4094-9d39-0b7c438b2343,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-6eabab61-5f41-46d8-a071-dedf4671a59c,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-c97478f4-f571-49ed-bc98-4fa40fc27cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-191918aa-8f0e-4f41-9825-8c7134f627a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-7e3e7ca9-9aa1-4541-96de-d4c3be39a502,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-eb84d2fd-e78f-4581-bb2a-c40b685cb2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40909,DS-134e78ae-3fa7-4c6e-ad24-76bbdee5296b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1264127055-172.17.0.5-1597488754170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36476,DS-aec66ccd-10eb-4b7e-9260-3919d242cd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-876a3c52-73f6-46ff-ae3f-f9c949e7919f,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-4c4502c6-17a3-40b1-b6cf-a20d5da673b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-18da97b4-82fb-4796-90cb-6260799e9bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-e23f77bf-7f32-43b3-9cfa-c3fa7406ab1c,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-7cbf3d3c-90b6-486f-937c-dcb952db94e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-b8bb7aaf-02cf-475b-b96f-bed312ae77d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-acf49799-8932-4a8a-8a7b-ec1c8b158a0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1264127055-172.17.0.5-1597488754170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36476,DS-aec66ccd-10eb-4b7e-9260-3919d242cd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-876a3c52-73f6-46ff-ae3f-f9c949e7919f,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-4c4502c6-17a3-40b1-b6cf-a20d5da673b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-18da97b4-82fb-4796-90cb-6260799e9bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-e23f77bf-7f32-43b3-9cfa-c3fa7406ab1c,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-7cbf3d3c-90b6-486f-937c-dcb952db94e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-b8bb7aaf-02cf-475b-b96f-bed312ae77d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-acf49799-8932-4a8a-8a7b-ec1c8b158a0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376064274-172.17.0.5-1597488787598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41134,DS-d0b57065-11ce-4a61-856f-206591fac403,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-d910cd58-7866-4120-abcd-538766b50f45,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-21eccbe4-3820-418c-b5ae-424fda789519,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-9d53e59c-d5ae-4fda-b657-a579ee454cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-76378072-85b0-4141-b7d2-144fd05ed197,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-93cb6243-71d5-456a-9e2c-a96a1ab9e1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-86123780-763e-4231-a3eb-141129601ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-6f126504-437e-4d58-8b40-ce367d10d382,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1376064274-172.17.0.5-1597488787598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41134,DS-d0b57065-11ce-4a61-856f-206591fac403,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-d910cd58-7866-4120-abcd-538766b50f45,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-21eccbe4-3820-418c-b5ae-424fda789519,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-9d53e59c-d5ae-4fda-b657-a579ee454cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-76378072-85b0-4141-b7d2-144fd05ed197,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-93cb6243-71d5-456a-9e2c-a96a1ab9e1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-86123780-763e-4231-a3eb-141129601ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-6f126504-437e-4d58-8b40-ce367d10d382,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-32511669-172.17.0.5-1597488968218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37530,DS-421a0eee-e4aa-498b-8550-2de39eef8f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-02f7be28-787c-44df-a6d3-ea3d5d822420,DISK], DatanodeInfoWithStorage[127.0.0.1:46799,DS-7051097f-800f-4b8b-8c50-92e5ddf55bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-2f995ffe-c849-415e-b880-0c531713d1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-cd37a2d4-60bb-4e3f-87bc-45069fd72337,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-aea73e63-1e48-4116-90d5-f5ce58920a37,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-ab297626-2912-4c2f-8459-328addbdf2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-d86ba411-b9ab-45d6-a59d-a8f5a158910a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-32511669-172.17.0.5-1597488968218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37530,DS-421a0eee-e4aa-498b-8550-2de39eef8f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-02f7be28-787c-44df-a6d3-ea3d5d822420,DISK], DatanodeInfoWithStorage[127.0.0.1:46799,DS-7051097f-800f-4b8b-8c50-92e5ddf55bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36132,DS-2f995ffe-c849-415e-b880-0c531713d1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-cd37a2d4-60bb-4e3f-87bc-45069fd72337,DISK], DatanodeInfoWithStorage[127.0.0.1:45028,DS-aea73e63-1e48-4116-90d5-f5ce58920a37,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-ab297626-2912-4c2f-8459-328addbdf2f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-d86ba411-b9ab-45d6-a59d-a8f5a158910a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-34285776-172.17.0.5-1597489190837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42370,DS-79dbede5-94c8-4710-ac4c-b71793951049,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-c20a3f91-0d28-4d9f-a20d-f81f911aff1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-354be0a0-9487-4c81-aa51-9c58acb4ca3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-efeabc7d-c21f-48ad-9563-f582f82ca8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34256,DS-14559206-6c71-497b-8e35-11abfeb93982,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-2a596477-4f59-4822-8a1d-750fe9275e11,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-e02b8a11-552b-4de0-85b2-1b110ca3e21c,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-db4e40fd-43cd-44e9-b39d-86ac41d37861,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-34285776-172.17.0.5-1597489190837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42370,DS-79dbede5-94c8-4710-ac4c-b71793951049,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-c20a3f91-0d28-4d9f-a20d-f81f911aff1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-354be0a0-9487-4c81-aa51-9c58acb4ca3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-efeabc7d-c21f-48ad-9563-f582f82ca8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34256,DS-14559206-6c71-497b-8e35-11abfeb93982,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-2a596477-4f59-4822-8a1d-750fe9275e11,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-e02b8a11-552b-4de0-85b2-1b110ca3e21c,DISK], DatanodeInfoWithStorage[127.0.0.1:33800,DS-db4e40fd-43cd-44e9-b39d-86ac41d37861,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-335122217-172.17.0.5-1597489274981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34298,DS-fab7d58c-e6bd-49ea-a18d-ce089f2caca7,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-90eb3bde-7519-4ab7-a394-ab723c252bef,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-3a2557b4-f9cc-4586-9a64-572848857287,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-2b2b515f-7aa6-4f0d-97fc-597344ec7b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-f4c5eb96-0add-4f0d-9eda-35734db8bfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-8e4232bb-2520-4641-bdb2-62ab27760cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-45d42ed7-4da1-4c59-b707-d28cc378658a,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-4274d290-2055-48b7-bd6e-3c806f82207c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-335122217-172.17.0.5-1597489274981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34298,DS-fab7d58c-e6bd-49ea-a18d-ce089f2caca7,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-90eb3bde-7519-4ab7-a394-ab723c252bef,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-3a2557b4-f9cc-4586-9a64-572848857287,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-2b2b515f-7aa6-4f0d-97fc-597344ec7b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-f4c5eb96-0add-4f0d-9eda-35734db8bfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-8e4232bb-2520-4641-bdb2-62ab27760cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-45d42ed7-4da1-4c59-b707-d28cc378658a,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-4274d290-2055-48b7-bd6e-3c806f82207c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1534077690-172.17.0.5-1597489449516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43287,DS-9bbde86f-6396-4a99-b178-749b2c17bb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-4e634805-cc99-4733-9b74-10129803b12f,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-d1aa891c-d824-4435-872a-c54b34c9564c,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-7b362ed5-15c3-48e1-b007-5e3746acf748,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-b624a5d0-3941-4063-90e4-43feaa16d9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-de813b7f-4530-4abf-80b8-77c860eb404d,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-a7c0f8af-018b-457b-9d8c-f2ebe721edae,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-af28138b-9d11-4033-b114-cf4a9b66895a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1534077690-172.17.0.5-1597489449516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43287,DS-9bbde86f-6396-4a99-b178-749b2c17bb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-4e634805-cc99-4733-9b74-10129803b12f,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-d1aa891c-d824-4435-872a-c54b34c9564c,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-7b362ed5-15c3-48e1-b007-5e3746acf748,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-b624a5d0-3941-4063-90e4-43feaa16d9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-de813b7f-4530-4abf-80b8-77c860eb404d,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-a7c0f8af-018b-457b-9d8c-f2ebe721edae,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-af28138b-9d11-4033-b114-cf4a9b66895a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1966003113-172.17.0.5-1597489489520:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41800,DS-29c99d88-efcb-4872-9d16-12f1d69bdd05,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-6b9e1f7a-a69e-4e71-8066-c5e133d87f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-4603112c-4e98-4ff6-874e-48c2adce8edc,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-2c690d7e-1661-4eb7-9c17-a1bfbd689083,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-f4d4f06d-164c-46ad-8f4e-728265e28b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-2ef8b074-58db-4642-8a78-1bb7b92fcf5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-538d33ec-0b91-495e-80c8-d629c4d2e320,DISK], DatanodeInfoWithStorage[127.0.0.1:45754,DS-63ffcd35-b0e9-4dd4-b466-cc17a40f062e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1966003113-172.17.0.5-1597489489520:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41800,DS-29c99d88-efcb-4872-9d16-12f1d69bdd05,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-6b9e1f7a-a69e-4e71-8066-c5e133d87f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-4603112c-4e98-4ff6-874e-48c2adce8edc,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-2c690d7e-1661-4eb7-9c17-a1bfbd689083,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-f4d4f06d-164c-46ad-8f4e-728265e28b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-2ef8b074-58db-4642-8a78-1bb7b92fcf5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-538d33ec-0b91-495e-80c8-d629c4d2e320,DISK], DatanodeInfoWithStorage[127.0.0.1:45754,DS-63ffcd35-b0e9-4dd4-b466-cc17a40f062e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1416098131-172.17.0.5-1597489642672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40396,DS-b064aeaa-f2d0-4846-a21d-1cf02b9bb679,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-95a751df-3881-4d6f-85ab-aa2f37b7d05e,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-0194a059-415c-4c01-b4af-38099d2e1619,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-7cd22e86-e633-48e9-a7d4-d5a03e63801e,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-d0e89211-5dcd-49a0-b139-ca1da761e10b,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-49ac1528-593f-402c-9104-b55a10af0ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-76d14120-edd7-42d1-8202-658088f0288b,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-19a57e18-10a9-4123-957c-85cc88461587,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1416098131-172.17.0.5-1597489642672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40396,DS-b064aeaa-f2d0-4846-a21d-1cf02b9bb679,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-95a751df-3881-4d6f-85ab-aa2f37b7d05e,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-0194a059-415c-4c01-b4af-38099d2e1619,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-7cd22e86-e633-48e9-a7d4-d5a03e63801e,DISK], DatanodeInfoWithStorage[127.0.0.1:41248,DS-d0e89211-5dcd-49a0-b139-ca1da761e10b,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-49ac1528-593f-402c-9104-b55a10af0ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-76d14120-edd7-42d1-8202-658088f0288b,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-19a57e18-10a9-4123-957c-85cc88461587,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-33186953-172.17.0.5-1597490002356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37799,DS-50c2e5a6-0216-4e95-a61e-770b01ec309d,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-710a4453-6a32-4d0e-be6d-ebeed8ae6f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-2378b4c9-39d1-40c6-86cf-c2e931e6839e,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-b1d183a4-88cb-4122-9ee8-ffa01603e77d,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-8ccc4338-a687-45e6-a588-2337208d6e43,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-5bc84955-2647-4b34-8d31-017660d73048,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-92b26c51-5e36-443a-914b-9183fcfd5379,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-91c15b02-25a9-4c98-9acd-ee850fec7f60,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-33186953-172.17.0.5-1597490002356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37799,DS-50c2e5a6-0216-4e95-a61e-770b01ec309d,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-710a4453-6a32-4d0e-be6d-ebeed8ae6f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39835,DS-2378b4c9-39d1-40c6-86cf-c2e931e6839e,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-b1d183a4-88cb-4122-9ee8-ffa01603e77d,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-8ccc4338-a687-45e6-a588-2337208d6e43,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-5bc84955-2647-4b34-8d31-017660d73048,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-92b26c51-5e36-443a-914b-9183fcfd5379,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-91c15b02-25a9-4c98-9acd-ee850fec7f60,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454692396-172.17.0.5-1597490071653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43372,DS-b609742b-1b9e-4bf2-a160-bf7ac8c4be4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-73f387b0-3939-4956-8a5e-5829aa2e8ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-70a199b2-a2f0-4ff9-81e9-e6a76e5267f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-4a72edcb-9281-4815-843d-7b873e3d13b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-84f65549-5f62-447b-aec5-70a5dceea000,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-a7f94e62-4b98-4ef8-80a8-0cbe197b2a39,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-f286fad1-3323-42ca-9dda-bec32b5dad48,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-d9f482f6-43d9-460a-b294-e17d2bd091f2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454692396-172.17.0.5-1597490071653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43372,DS-b609742b-1b9e-4bf2-a160-bf7ac8c4be4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-73f387b0-3939-4956-8a5e-5829aa2e8ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-70a199b2-a2f0-4ff9-81e9-e6a76e5267f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-4a72edcb-9281-4815-843d-7b873e3d13b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-84f65549-5f62-447b-aec5-70a5dceea000,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-a7f94e62-4b98-4ef8-80a8-0cbe197b2a39,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-f286fad1-3323-42ca-9dda-bec32b5dad48,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-d9f482f6-43d9-460a-b294-e17d2bd091f2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-644081169-172.17.0.5-1597490615874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38412,DS-74a8db20-d375-4d0a-8c4f-7fe63b1c2e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-9b55618d-dc5d-4990-a961-35cf5d6dc4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-01ce9315-311a-46ca-aefb-c883fe3383bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-9131a221-8992-4f0b-9b20-c00da77bcea5,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-d5ec1e59-d1e5-4045-858e-097e0f0a479e,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-e1ce6d3b-958b-4f7f-8979-e1dad08580c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-aac7742b-e34b-4152-9e1f-f6be0f4200f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-958296f3-4378-45fb-812b-00bbf80d824d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-644081169-172.17.0.5-1597490615874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38412,DS-74a8db20-d375-4d0a-8c4f-7fe63b1c2e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-9b55618d-dc5d-4990-a961-35cf5d6dc4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-01ce9315-311a-46ca-aefb-c883fe3383bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-9131a221-8992-4f0b-9b20-c00da77bcea5,DISK], DatanodeInfoWithStorage[127.0.0.1:38894,DS-d5ec1e59-d1e5-4045-858e-097e0f0a479e,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-e1ce6d3b-958b-4f7f-8979-e1dad08580c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-aac7742b-e34b-4152-9e1f-f6be0f4200f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41821,DS-958296f3-4378-45fb-812b-00bbf80d824d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1100069679-172.17.0.5-1597490770866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45469,DS-37f696bf-10d7-4352-878c-11376e571fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-2b024628-1c5e-4dd1-b3c3-39bdc5ef45df,DISK], DatanodeInfoWithStorage[127.0.0.1:39278,DS-25d5d488-20ef-4ee7-ae77-963928e69957,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-cb227c1e-74df-4e6a-9ba9-dceedb67aa96,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-62a3d4ee-bfd0-494a-97a3-dc87b60f09a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-6e652cfc-bf21-426a-8eee-b43167c08374,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-c2cb9a5c-4f61-4659-b144-92e37e08d2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-72b19729-dacc-4338-8156-1656ac18556a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1100069679-172.17.0.5-1597490770866:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45469,DS-37f696bf-10d7-4352-878c-11376e571fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-2b024628-1c5e-4dd1-b3c3-39bdc5ef45df,DISK], DatanodeInfoWithStorage[127.0.0.1:39278,DS-25d5d488-20ef-4ee7-ae77-963928e69957,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-cb227c1e-74df-4e6a-9ba9-dceedb67aa96,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-62a3d4ee-bfd0-494a-97a3-dc87b60f09a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-6e652cfc-bf21-426a-8eee-b43167c08374,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-c2cb9a5c-4f61-4659-b144-92e37e08d2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-72b19729-dacc-4338-8156-1656ac18556a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-431382514-172.17.0.5-1597490885393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46444,DS-d9295e92-2e21-4eb1-a67b-c8e4c54db905,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-ac4f491d-e70f-480e-9d13-7381232867bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-840d0e22-ead5-4de9-b9f7-68e18798ab08,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-50fddb88-52af-405c-8cfc-c85af5901aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-df9232a2-5e7d-4d50-870e-3013955d4588,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-0516a02d-78a1-4fa5-95f6-e433bc50d499,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-727fd964-efc8-4898-b39d-c24953cabb81,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-42d7d188-348c-4dff-a489-dc1369d1df6d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-431382514-172.17.0.5-1597490885393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46444,DS-d9295e92-2e21-4eb1-a67b-c8e4c54db905,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-ac4f491d-e70f-480e-9d13-7381232867bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-840d0e22-ead5-4de9-b9f7-68e18798ab08,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-50fddb88-52af-405c-8cfc-c85af5901aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:44401,DS-df9232a2-5e7d-4d50-870e-3013955d4588,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-0516a02d-78a1-4fa5-95f6-e433bc50d499,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-727fd964-efc8-4898-b39d-c24953cabb81,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-42d7d188-348c-4dff-a489-dc1369d1df6d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498592020-172.17.0.5-1597490923475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43886,DS-0361aa3f-3bab-4532-ae26-53cf467a7f05,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-e84fe8c9-d951-4aa7-b331-01baf5747bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-1994f9b6-b42f-41e0-9dd8-35bbe9da05ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-f3f1ca1e-c500-43f8-93fd-4bbeb9c19ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-f9cf19cf-0c34-4061-9331-19862ebc4fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-2bbc5ee2-dfae-491b-9f4d-c12105c1c6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-aa365362-6d99-48d8-8c2d-01560a1c5233,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-9b280247-8b96-47c0-8b11-0ebfe8b5a097,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498592020-172.17.0.5-1597490923475:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43886,DS-0361aa3f-3bab-4532-ae26-53cf467a7f05,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-e84fe8c9-d951-4aa7-b331-01baf5747bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-1994f9b6-b42f-41e0-9dd8-35bbe9da05ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-f3f1ca1e-c500-43f8-93fd-4bbeb9c19ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-f9cf19cf-0c34-4061-9331-19862ebc4fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-2bbc5ee2-dfae-491b-9f4d-c12105c1c6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-aa365362-6d99-48d8-8c2d-01560a1c5233,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-9b280247-8b96-47c0-8b11-0ebfe8b5a097,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780213426-172.17.0.5-1597491254479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38706,DS-a48a1cb2-35f8-4e0d-8cd0-7dee8c612cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-d21474f2-7b01-4e5d-a0d5-849c5415e3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-aa60cd43-c81c-448d-a8ca-cd108a0e82b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-15a75b96-811f-493e-9c9a-ae4b97d7c445,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-fb51a84a-2515-41e5-8bee-d3bef7a19730,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-2a4c885d-2751-47ab-b1f9-c4db59526119,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-b6b7df47-84c8-45fb-8567-84215df18a11,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-3cc0156d-1faf-4664-8d68-24334bfa8bb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780213426-172.17.0.5-1597491254479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38706,DS-a48a1cb2-35f8-4e0d-8cd0-7dee8c612cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45357,DS-d21474f2-7b01-4e5d-a0d5-849c5415e3e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-aa60cd43-c81c-448d-a8ca-cd108a0e82b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-15a75b96-811f-493e-9c9a-ae4b97d7c445,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-fb51a84a-2515-41e5-8bee-d3bef7a19730,DISK], DatanodeInfoWithStorage[127.0.0.1:46195,DS-2a4c885d-2751-47ab-b1f9-c4db59526119,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-b6b7df47-84c8-45fb-8567-84215df18a11,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-3cc0156d-1faf-4664-8d68-24334bfa8bb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1839336245-172.17.0.5-1597491424096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36467,DS-5ae8926e-44c6-4ae3-9cdf-8bf9063585a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-dcfbff2b-85c9-42cd-922c-729e3d417400,DISK], DatanodeInfoWithStorage[127.0.0.1:40604,DS-d78ee1a9-9829-475a-a5c9-86c16a60fd21,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-03288d9d-a6c6-487b-9168-e5d3628fdfef,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-1629f5bb-bdfe-411f-b5f9-972dfd9deaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-b03a04c2-3bdb-4ff3-bd9b-66d05e7d9d99,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-1df9a355-0617-4a3d-8adc-714302e83c00,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-c019083b-c48d-4675-af20-ac9fd13857ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1839336245-172.17.0.5-1597491424096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36467,DS-5ae8926e-44c6-4ae3-9cdf-8bf9063585a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-dcfbff2b-85c9-42cd-922c-729e3d417400,DISK], DatanodeInfoWithStorage[127.0.0.1:40604,DS-d78ee1a9-9829-475a-a5c9-86c16a60fd21,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-03288d9d-a6c6-487b-9168-e5d3628fdfef,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-1629f5bb-bdfe-411f-b5f9-972dfd9deaf7,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-b03a04c2-3bdb-4ff3-bd9b-66d05e7d9d99,DISK], DatanodeInfoWithStorage[127.0.0.1:41528,DS-1df9a355-0617-4a3d-8adc-714302e83c00,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-c019083b-c48d-4675-af20-ac9fd13857ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-391396179-172.17.0.5-1597491529908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42455,DS-8e2f0735-7c8b-46ec-8296-629747c9109d,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-4b8caf8a-d16a-4325-abc2-4fafb6788c57,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-6bec9ed3-fcb4-408a-a509-60e64486027c,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-e0ccdf79-e9c1-4a8b-b530-c14724a31e42,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-d1157cc4-2ea0-43ce-85f8-d50355f63829,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-7ec05c55-f30c-40bc-8817-e1df4c1c19cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-369c5ca4-ef73-419b-9ad6-3c6d99daa56b,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-360e9959-0e12-4f79-b9de-929dabfa6c46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-391396179-172.17.0.5-1597491529908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42455,DS-8e2f0735-7c8b-46ec-8296-629747c9109d,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-4b8caf8a-d16a-4325-abc2-4fafb6788c57,DISK], DatanodeInfoWithStorage[127.0.0.1:34822,DS-6bec9ed3-fcb4-408a-a509-60e64486027c,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-e0ccdf79-e9c1-4a8b-b530-c14724a31e42,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-d1157cc4-2ea0-43ce-85f8-d50355f63829,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-7ec05c55-f30c-40bc-8817-e1df4c1c19cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-369c5ca4-ef73-419b-9ad6-3c6d99daa56b,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-360e9959-0e12-4f79-b9de-929dabfa6c46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879670861-172.17.0.5-1597491751085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33142,DS-a020bd33-7487-41dc-ade5-f611f52b8641,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-d46ac4c2-a71d-4b3e-8bbd-84f03be63eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-f349df03-45dc-4d9b-ae56-96f55b4965f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-cff13f65-4fc2-46d0-bf03-96764cf3d28e,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-f8b90d1f-f6b9-4509-9ff7-801d8ccefaee,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-8823b643-1148-406b-b9de-88aeda19937a,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-178a7552-dec9-4aa6-b72d-10a86d256ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:36053,DS-269b42f1-d5a1-46a8-96f2-c6dc551c5ff8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879670861-172.17.0.5-1597491751085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33142,DS-a020bd33-7487-41dc-ade5-f611f52b8641,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-d46ac4c2-a71d-4b3e-8bbd-84f03be63eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-f349df03-45dc-4d9b-ae56-96f55b4965f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-cff13f65-4fc2-46d0-bf03-96764cf3d28e,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-f8b90d1f-f6b9-4509-9ff7-801d8ccefaee,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-8823b643-1148-406b-b9de-88aeda19937a,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-178a7552-dec9-4aa6-b72d-10a86d256ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:36053,DS-269b42f1-d5a1-46a8-96f2-c6dc551c5ff8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1756483251-172.17.0.5-1597491823341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36792,DS-c272f277-2d2c-4f1c-acfd-1cc529662491,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-0a30e557-e47f-4705-90fd-1100d68c58ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-0f29877b-9d13-4525-96e2-6a1fe275c830,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-4977bee8-6310-488e-9ea4-b30e69b235fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-ceef7c17-fe0b-40d3-8b1b-dbd5896fe12f,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-8d56389b-3f65-40e4-a813-73c728a970a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-c8a6ff0c-0972-4bc9-a5b6-fc7e0022df4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-654c6024-7a1f-49bb-901e-096ead0925b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1756483251-172.17.0.5-1597491823341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36792,DS-c272f277-2d2c-4f1c-acfd-1cc529662491,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-0a30e557-e47f-4705-90fd-1100d68c58ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-0f29877b-9d13-4525-96e2-6a1fe275c830,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-4977bee8-6310-488e-9ea4-b30e69b235fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-ceef7c17-fe0b-40d3-8b1b-dbd5896fe12f,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-8d56389b-3f65-40e4-a813-73c728a970a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-c8a6ff0c-0972-4bc9-a5b6-fc7e0022df4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-654c6024-7a1f-49bb-901e-096ead0925b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403198455-172.17.0.5-1597492051739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34768,DS-cf895e51-e354-41ac-aba4-1f68951f28d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-7ce1f352-2768-4bb8-9694-b262e065f934,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-53efd815-01a4-4956-9e17-e842a97db76d,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-12a78fde-ae20-4241-9f3c-39d60bdf958b,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-c3b862d7-f5ef-49ce-844b-00e3512b155f,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-aa21c39c-a930-41da-b358-58af579631ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-fcd829e8-77b6-44bf-8544-00e28ded26d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-831148b6-b12a-4923-95f9-a520013e4ffc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403198455-172.17.0.5-1597492051739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34768,DS-cf895e51-e354-41ac-aba4-1f68951f28d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-7ce1f352-2768-4bb8-9694-b262e065f934,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-53efd815-01a4-4956-9e17-e842a97db76d,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-12a78fde-ae20-4241-9f3c-39d60bdf958b,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-c3b862d7-f5ef-49ce-844b-00e3512b155f,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-aa21c39c-a930-41da-b358-58af579631ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-fcd829e8-77b6-44bf-8544-00e28ded26d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-831148b6-b12a-4923-95f9-a520013e4ffc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 1000m
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-474211247-172.17.0.5-1597492090871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36928,DS-20552fb5-5551-413a-8399-78acaab57e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-33c3d7ba-9aa4-4f8b-9710-87d4746fe30b,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-eb61215b-069c-45f6-ac32-958c8c0ec27e,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-85ae4ea3-8b38-4911-8e0e-f49c9a739f16,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-15067cdb-a607-4abe-91bd-b14c34409f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-49e17c17-751a-41ee-a56a-de567e62a52e,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-22341ca0-cd79-4338-8a62-c5a849bcf3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-6ad895dc-5762-47c6-8936-1666373efaf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-474211247-172.17.0.5-1597492090871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36928,DS-20552fb5-5551-413a-8399-78acaab57e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-33c3d7ba-9aa4-4f8b-9710-87d4746fe30b,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-eb61215b-069c-45f6-ac32-958c8c0ec27e,DISK], DatanodeInfoWithStorage[127.0.0.1:37571,DS-85ae4ea3-8b38-4911-8e0e-f49c9a739f16,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-15067cdb-a607-4abe-91bd-b14c34409f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-49e17c17-751a-41ee-a56a-de567e62a52e,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-22341ca0-cd79-4338-8a62-c5a849bcf3d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-6ad895dc-5762-47c6-8936-1666373efaf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 28 out of 50
result: false positive !!!
Total execution time in seconds : 5683
