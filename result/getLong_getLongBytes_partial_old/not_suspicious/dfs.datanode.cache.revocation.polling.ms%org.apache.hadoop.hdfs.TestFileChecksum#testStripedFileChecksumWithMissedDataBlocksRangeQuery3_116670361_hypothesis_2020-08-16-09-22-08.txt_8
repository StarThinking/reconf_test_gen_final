reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-537940633-172.17.0.3-1597570182428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43170,DS-ca22186a-d7db-4edf-b9e3-16668c13bcae,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-d4352265-5aac-4b79-91bc-bccfadf49c98,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-3a5c4179-dcbc-438a-b1dc-47331a1395db,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-c34c8534-d8fa-45df-9ce2-7e98479778ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-d2190533-3c08-4e4d-b7dc-9ed93f4ffd61,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-767a347a-25af-470d-a1be-6dee71ebac60,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-c825ee32-753c-460e-971d-ab7376e78eff,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-22db13d4-bdca-44c4-9839-a959ef5f6c2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-537940633-172.17.0.3-1597570182428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43170,DS-ca22186a-d7db-4edf-b9e3-16668c13bcae,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-d4352265-5aac-4b79-91bc-bccfadf49c98,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-3a5c4179-dcbc-438a-b1dc-47331a1395db,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-c34c8534-d8fa-45df-9ce2-7e98479778ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-d2190533-3c08-4e4d-b7dc-9ed93f4ffd61,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-767a347a-25af-470d-a1be-6dee71ebac60,DISK], DatanodeInfoWithStorage[127.0.0.1:42648,DS-c825ee32-753c-460e-971d-ab7376e78eff,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-22db13d4-bdca-44c4-9839-a959ef5f6c2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-532488084-172.17.0.3-1597570523429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35129,DS-a4605537-d8bc-484f-a85f-445ffbc6c3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-dd3fa4e1-3c64-47f3-9f54-bc64b7cf57a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-14ad2ba7-fb12-49a6-a407-b198fd43f3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-15d99cab-cecc-4fd0-b689-92618a0bd140,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-0dc881b3-5c39-481c-92df-9e665ecf79fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-0c40d822-5717-46fa-aaf5-f0b9a30d14fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-e1cfb3ad-c955-4e48-903d-8f4e51ae3986,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-38745957-a867-4ca1-a65b-4e044e2eddb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-532488084-172.17.0.3-1597570523429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35129,DS-a4605537-d8bc-484f-a85f-445ffbc6c3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-dd3fa4e1-3c64-47f3-9f54-bc64b7cf57a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-14ad2ba7-fb12-49a6-a407-b198fd43f3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-15d99cab-cecc-4fd0-b689-92618a0bd140,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-0dc881b3-5c39-481c-92df-9e665ecf79fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-0c40d822-5717-46fa-aaf5-f0b9a30d14fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-e1cfb3ad-c955-4e48-903d-8f4e51ae3986,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-38745957-a867-4ca1-a65b-4e044e2eddb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896687188-172.17.0.3-1597570676331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34828,DS-2a1431f1-f812-4aef-a345-f2b0e39ed916,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-25c08825-5ff7-4bf4-9f3c-b47eb46493ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-d41e39b5-723c-4973-b048-3d0984c13248,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-c77b221a-37ce-4146-8961-838d08104163,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-7ec08c7d-f863-46e1-b7dd-be9c6081a488,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-88c6471b-630a-4d84-8227-ff9be2c2cd30,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-75edbd0d-fced-4e1d-936a-80d8ccfdfe22,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-aff15110-f772-4342-b88f-dc1b2d513779,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896687188-172.17.0.3-1597570676331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34828,DS-2a1431f1-f812-4aef-a345-f2b0e39ed916,DISK], DatanodeInfoWithStorage[127.0.0.1:45156,DS-25c08825-5ff7-4bf4-9f3c-b47eb46493ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-d41e39b5-723c-4973-b048-3d0984c13248,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-c77b221a-37ce-4146-8961-838d08104163,DISK], DatanodeInfoWithStorage[127.0.0.1:34832,DS-7ec08c7d-f863-46e1-b7dd-be9c6081a488,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-88c6471b-630a-4d84-8227-ff9be2c2cd30,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-75edbd0d-fced-4e1d-936a-80d8ccfdfe22,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-aff15110-f772-4342-b88f-dc1b2d513779,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1004594737-172.17.0.3-1597570718295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32952,DS-af8ca1de-7b83-43fc-b7c8-dd738ae6f8df,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-0c190cfe-ae3f-4bfc-9357-eaad5652a4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-55e4eebd-a011-41af-86a8-4dff268d66c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-d4bf3884-b49b-4ff5-9001-7c4e731366c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-d1a19230-564a-4b81-90f1-8fa494e522e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-e59e3bf5-67a6-498b-8201-58696db7a67c,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-1129d2a7-e4e7-4106-9898-2b0a94f7ef87,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-0261146a-0967-452d-b82e-9af41863ce8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1004594737-172.17.0.3-1597570718295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32952,DS-af8ca1de-7b83-43fc-b7c8-dd738ae6f8df,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-0c190cfe-ae3f-4bfc-9357-eaad5652a4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-55e4eebd-a011-41af-86a8-4dff268d66c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-d4bf3884-b49b-4ff5-9001-7c4e731366c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-d1a19230-564a-4b81-90f1-8fa494e522e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-e59e3bf5-67a6-498b-8201-58696db7a67c,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-1129d2a7-e4e7-4106-9898-2b0a94f7ef87,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-0261146a-0967-452d-b82e-9af41863ce8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319743223-172.17.0.3-1597570911014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40150,DS-20c2d73b-afeb-41fa-9bc1-b0cfab36d1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-e9aaa6f8-3077-4ff0-bb5a-ea24eacb9549,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-15a72b17-3ce5-4418-a3e1-534192e42241,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-f8300856-1669-4428-8732-e694713fe75c,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-191593d2-b1d2-43b6-aeec-3e7f07ad937c,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-492b7257-666e-46b7-8d7c-f09c1f961f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34824,DS-4ea643be-0d9d-4efc-82c9-d3dc1ec3d78e,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-f9a73d15-0f51-4050-a33a-54d5f64419fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319743223-172.17.0.3-1597570911014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40150,DS-20c2d73b-afeb-41fa-9bc1-b0cfab36d1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-e9aaa6f8-3077-4ff0-bb5a-ea24eacb9549,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-15a72b17-3ce5-4418-a3e1-534192e42241,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-f8300856-1669-4428-8732-e694713fe75c,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-191593d2-b1d2-43b6-aeec-3e7f07ad937c,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-492b7257-666e-46b7-8d7c-f09c1f961f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34824,DS-4ea643be-0d9d-4efc-82c9-d3dc1ec3d78e,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-f9a73d15-0f51-4050-a33a-54d5f64419fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930412182-172.17.0.3-1597571152442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42635,DS-90e6cf93-cc5d-4e19-bd2d-c90a52714875,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-37348248-2633-476c-930a-d15c1573cdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-cd683a8a-d63a-4f28-94c1-3ed04129a336,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-d1fd9356-ae66-4ea5-821b-8e1f610d1678,DISK], DatanodeInfoWithStorage[127.0.0.1:37324,DS-99ae64a0-e737-4c9e-9e5c-3bb4ec611bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-9bed068d-635e-4b86-af92-ba11d65577f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-51c4da59-4d7b-4cb9-aec6-1b2856c5d067,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-2e69b6c1-52eb-4f36-89b3-e1321924f033,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930412182-172.17.0.3-1597571152442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42635,DS-90e6cf93-cc5d-4e19-bd2d-c90a52714875,DISK], DatanodeInfoWithStorage[127.0.0.1:39808,DS-37348248-2633-476c-930a-d15c1573cdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-cd683a8a-d63a-4f28-94c1-3ed04129a336,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-d1fd9356-ae66-4ea5-821b-8e1f610d1678,DISK], DatanodeInfoWithStorage[127.0.0.1:37324,DS-99ae64a0-e737-4c9e-9e5c-3bb4ec611bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-9bed068d-635e-4b86-af92-ba11d65577f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45275,DS-51c4da59-4d7b-4cb9-aec6-1b2856c5d067,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-2e69b6c1-52eb-4f36-89b3-e1321924f033,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1577957727-172.17.0.3-1597571305790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39599,DS-92aa0e36-6ee6-4028-a4bd-3afe60ba468b,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-dc470677-9dc0-4a58-b247-5ec8c8c8aa78,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-3fc25434-2473-4e80-9557-20d8ff79bd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-0ecafb0f-a4db-4fd0-88ce-28622e815df1,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-b85cc40c-a9c4-46b9-9578-8b0922ae9089,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-2262b4be-8d7b-4b48-aced-23e4e7f86f51,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-63b74141-70e3-420d-8988-e7f9464df98b,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-ecadaa44-4c2a-414d-b8c9-468d160d19c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1577957727-172.17.0.3-1597571305790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39599,DS-92aa0e36-6ee6-4028-a4bd-3afe60ba468b,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-dc470677-9dc0-4a58-b247-5ec8c8c8aa78,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-3fc25434-2473-4e80-9557-20d8ff79bd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-0ecafb0f-a4db-4fd0-88ce-28622e815df1,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-b85cc40c-a9c4-46b9-9578-8b0922ae9089,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-2262b4be-8d7b-4b48-aced-23e4e7f86f51,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-63b74141-70e3-420d-8988-e7f9464df98b,DISK], DatanodeInfoWithStorage[127.0.0.1:41337,DS-ecadaa44-4c2a-414d-b8c9-468d160d19c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134369312-172.17.0.3-1597571677194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45633,DS-87280689-7680-4a70-8c4c-6e29b2c2d51a,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-e731c3f8-9d54-491a-9bf7-8ff6e13fdf72,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-60603fa0-da5e-4a49-acbd-365ae26d22d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-a7cb3aef-32e1-4cf2-bb49-77dd97501305,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-d8899d0c-7b7e-45de-9d15-fb0c82aa1a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-33dfcdf2-38b8-49df-aac1-c9b57c28b30e,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-be172829-8666-475e-830a-3e0f7317f6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-7e1831e1-3a9d-4644-bc7a-871d74a176bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134369312-172.17.0.3-1597571677194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45633,DS-87280689-7680-4a70-8c4c-6e29b2c2d51a,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-e731c3f8-9d54-491a-9bf7-8ff6e13fdf72,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-60603fa0-da5e-4a49-acbd-365ae26d22d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-a7cb3aef-32e1-4cf2-bb49-77dd97501305,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-d8899d0c-7b7e-45de-9d15-fb0c82aa1a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-33dfcdf2-38b8-49df-aac1-c9b57c28b30e,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-be172829-8666-475e-830a-3e0f7317f6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-7e1831e1-3a9d-4644-bc7a-871d74a176bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1714102609-172.17.0.3-1597572016398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43142,DS-53ec4d05-b3ca-4714-822f-0b33c6c682a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-e81acedd-3e29-49eb-ab63-97ec8132775e,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-4625ca85-36dd-4b63-a733-4d8814b3e016,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-0399aef0-403f-4234-9911-3bf5ea743cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-f76adc63-3417-4339-bbef-08727c4255ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-251e3e31-4141-4bda-91ee-d5bbc214eb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-12672814-8af0-4578-b333-bac965599fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-faf581fd-675d-4c4f-ac97-47c874aa270b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1714102609-172.17.0.3-1597572016398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43142,DS-53ec4d05-b3ca-4714-822f-0b33c6c682a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45023,DS-e81acedd-3e29-49eb-ab63-97ec8132775e,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-4625ca85-36dd-4b63-a733-4d8814b3e016,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-0399aef0-403f-4234-9911-3bf5ea743cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-f76adc63-3417-4339-bbef-08727c4255ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43174,DS-251e3e31-4141-4bda-91ee-d5bbc214eb2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-12672814-8af0-4578-b333-bac965599fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-faf581fd-675d-4c4f-ac97-47c874aa270b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041672789-172.17.0.3-1597572126239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34786,DS-657651e9-5cd0-44ee-bf66-30005486ee4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-febb4343-6edb-47b0-95c2-148167f2c208,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-4efa2446-2528-4c79-b4da-33d80bc41d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-abe478af-4168-47e8-973d-43ad0b43f9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-0937683a-8543-474f-bfcc-34cfa289f2df,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-630880fd-f087-4766-8deb-ae11e33338e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-a6bb9f4b-7b0b-4d5d-9031-79fe375f5e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-e1da8fc9-eb38-4196-8d03-28e029c2ad8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041672789-172.17.0.3-1597572126239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34786,DS-657651e9-5cd0-44ee-bf66-30005486ee4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-febb4343-6edb-47b0-95c2-148167f2c208,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-4efa2446-2528-4c79-b4da-33d80bc41d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-abe478af-4168-47e8-973d-43ad0b43f9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-0937683a-8543-474f-bfcc-34cfa289f2df,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-630880fd-f087-4766-8deb-ae11e33338e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-a6bb9f4b-7b0b-4d5d-9031-79fe375f5e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-e1da8fc9-eb38-4196-8d03-28e029c2ad8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-641691043-172.17.0.3-1597572242334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36465,DS-4901f436-665d-4621-97f0-809d4c8ba8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-86952fb7-69b4-4117-9f20-2f4c5df4e541,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-f851de05-b6f5-48ae-8fc2-5445ef5ac378,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-3ee55fc2-8934-4aa8-b197-e85f1eb5bb99,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-bb661aab-57b1-43a4-aee4-6ee0b4a8c37a,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-8b770bcb-0b65-4e8c-bd38-8e289613bc84,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-4ca9b430-5178-4a0e-925c-14042cd71064,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-827f8b04-3572-4cb6-96d8-b946ed77f799,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-641691043-172.17.0.3-1597572242334:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36465,DS-4901f436-665d-4621-97f0-809d4c8ba8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-86952fb7-69b4-4117-9f20-2f4c5df4e541,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-f851de05-b6f5-48ae-8fc2-5445ef5ac378,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-3ee55fc2-8934-4aa8-b197-e85f1eb5bb99,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-bb661aab-57b1-43a4-aee4-6ee0b4a8c37a,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-8b770bcb-0b65-4e8c-bd38-8e289613bc84,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-4ca9b430-5178-4a0e-925c-14042cd71064,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-827f8b04-3572-4cb6-96d8-b946ed77f799,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1856396670-172.17.0.3-1597572420390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36423,DS-0c766faf-2b6b-4379-b29a-69d06ce36300,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-37a4f6f7-a2e3-47a9-8f6c-67245433b07a,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-9b90bde6-8e21-4f4e-a8d6-af05e522865a,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-a03b7d72-e6a8-477a-a598-8c7f0cd5b541,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-b4c6b052-fee7-4654-968f-bdb9b041643e,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-df3181cb-d19f-4b9e-a1a0-df3703316ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-b4f82c06-abfd-4ced-b49d-1d0a8fd8890a,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-5c2b6234-2b47-41f6-b480-0c1d28bb438a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1856396670-172.17.0.3-1597572420390:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36423,DS-0c766faf-2b6b-4379-b29a-69d06ce36300,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-37a4f6f7-a2e3-47a9-8f6c-67245433b07a,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-9b90bde6-8e21-4f4e-a8d6-af05e522865a,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-a03b7d72-e6a8-477a-a598-8c7f0cd5b541,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-b4c6b052-fee7-4654-968f-bdb9b041643e,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-df3181cb-d19f-4b9e-a1a0-df3703316ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:42060,DS-b4f82c06-abfd-4ced-b49d-1d0a8fd8890a,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-5c2b6234-2b47-41f6-b480-0c1d28bb438a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2131439657-172.17.0.3-1597572535397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33994,DS-22fe3569-8a10-4441-94da-3b8dfde9c084,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-036d7be8-d5e9-43b0-a10b-a5f11f8321d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-7d487280-3789-4ecb-8631-9b58cb31f40b,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-cc82438a-5319-4567-8ba1-3a1fd7da098a,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-21ce91d6-685b-4bcc-83a4-2bae9ba79bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-350969d9-71a6-43f3-9ca4-91a717cdddb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-29ae4f62-981c-49ef-9452-fea5d6338072,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-c4840ed9-aae7-44c0-b374-5ec53b4d694f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2131439657-172.17.0.3-1597572535397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33994,DS-22fe3569-8a10-4441-94da-3b8dfde9c084,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-036d7be8-d5e9-43b0-a10b-a5f11f8321d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39223,DS-7d487280-3789-4ecb-8631-9b58cb31f40b,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-cc82438a-5319-4567-8ba1-3a1fd7da098a,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-21ce91d6-685b-4bcc-83a4-2bae9ba79bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-350969d9-71a6-43f3-9ca4-91a717cdddb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-29ae4f62-981c-49ef-9452-fea5d6338072,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-c4840ed9-aae7-44c0-b374-5ec53b4d694f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933375266-172.17.0.3-1597572883736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38694,DS-f0146554-0618-451a-a55c-5e76cf710bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-29f3c02f-a280-47ea-b32f-9e07582c9ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-07a30d18-097c-4c9f-a775-0aced21334d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-5e0647df-b1d7-41fb-b034-75382fb6f966,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-38200c02-28da-4ca3-a087-d218b9765780,DISK], DatanodeInfoWithStorage[127.0.0.1:44524,DS-0ec042a6-4004-482b-b648-62dac060e52a,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-03af543a-a143-42e3-8185-4effa0a0c784,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-8fa3cf2a-e576-4d35-96cd-4232042719c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933375266-172.17.0.3-1597572883736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38694,DS-f0146554-0618-451a-a55c-5e76cf710bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46873,DS-29f3c02f-a280-47ea-b32f-9e07582c9ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-07a30d18-097c-4c9f-a775-0aced21334d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42382,DS-5e0647df-b1d7-41fb-b034-75382fb6f966,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-38200c02-28da-4ca3-a087-d218b9765780,DISK], DatanodeInfoWithStorage[127.0.0.1:44524,DS-0ec042a6-4004-482b-b648-62dac060e52a,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-03af543a-a143-42e3-8185-4effa0a0c784,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-8fa3cf2a-e576-4d35-96cd-4232042719c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2031216134-172.17.0.3-1597574162104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33194,DS-d2ec5304-9aa4-4ae2-b6cd-3db532fa24be,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-568e93d3-dc36-4873-9cf7-302634da44df,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-2353f01c-45bd-4cc6-8e3e-32b49acb0e87,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-d2bcd34d-24c3-4117-a6c9-517a53b76eae,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-31a698a3-9994-4610-b8a8-799262be2d41,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-b4bac4e7-00d2-4aaa-b29b-94be12733fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-6bb55e66-4cce-4c3c-9768-c1d7378107e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-6dc91c3b-507d-4619-80d2-2bc6af7f9291,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2031216134-172.17.0.3-1597574162104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33194,DS-d2ec5304-9aa4-4ae2-b6cd-3db532fa24be,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-568e93d3-dc36-4873-9cf7-302634da44df,DISK], DatanodeInfoWithStorage[127.0.0.1:40000,DS-2353f01c-45bd-4cc6-8e3e-32b49acb0e87,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-d2bcd34d-24c3-4117-a6c9-517a53b76eae,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-31a698a3-9994-4610-b8a8-799262be2d41,DISK], DatanodeInfoWithStorage[127.0.0.1:33603,DS-b4bac4e7-00d2-4aaa-b29b-94be12733fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-6bb55e66-4cce-4c3c-9768-c1d7378107e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-6dc91c3b-507d-4619-80d2-2bc6af7f9291,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614640065-172.17.0.3-1597574784525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45241,DS-13dd3246-132c-49da-848f-9a56b2f701fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-eb5acbd7-3761-4a1f-84bb-a2ddc0306de9,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-1d12d1a4-b9b8-4e64-80f2-76d971fc33bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-7ec1d80d-d285-4c17-98c3-03e3665725d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-b9d1bdbe-053a-4d13-8daa-491d376db531,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-9bc97b2c-c0d6-47bf-8aee-911fb4ea6fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-414fecbb-2588-4b09-b86e-4a1236f10090,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-a5e9c346-bf5e-46c5-9409-507e6fbe7c5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614640065-172.17.0.3-1597574784525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45241,DS-13dd3246-132c-49da-848f-9a56b2f701fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-eb5acbd7-3761-4a1f-84bb-a2ddc0306de9,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-1d12d1a4-b9b8-4e64-80f2-76d971fc33bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-7ec1d80d-d285-4c17-98c3-03e3665725d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-b9d1bdbe-053a-4d13-8daa-491d376db531,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-9bc97b2c-c0d6-47bf-8aee-911fb4ea6fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-414fecbb-2588-4b09-b86e-4a1236f10090,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-a5e9c346-bf5e-46c5-9409-507e6fbe7c5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-252147454-172.17.0.3-1597575233401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46136,DS-edef8b25-f0e5-4e20-877e-f98d6d7eecf2,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-3ca178d7-d091-47f8-be4d-5abe6fdfe552,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-94edadcc-49ec-4fc6-9894-b52c54276cea,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-aa1ebc7d-e5de-442a-8fde-f10942863ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-ba2edee0-3903-4e07-a351-6e09833b1c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-7ffcb461-2b43-46e0-85c9-863bdf3cdac1,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-25763986-41df-489f-93c2-db571ef33978,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-0979d33d-d20d-4c7e-a225-9d6f55bd1523,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-252147454-172.17.0.3-1597575233401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46136,DS-edef8b25-f0e5-4e20-877e-f98d6d7eecf2,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-3ca178d7-d091-47f8-be4d-5abe6fdfe552,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-94edadcc-49ec-4fc6-9894-b52c54276cea,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-aa1ebc7d-e5de-442a-8fde-f10942863ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-ba2edee0-3903-4e07-a351-6e09833b1c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-7ffcb461-2b43-46e0-85c9-863bdf3cdac1,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-25763986-41df-489f-93c2-db571ef33978,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-0979d33d-d20d-4c7e-a225-9d6f55bd1523,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5644
