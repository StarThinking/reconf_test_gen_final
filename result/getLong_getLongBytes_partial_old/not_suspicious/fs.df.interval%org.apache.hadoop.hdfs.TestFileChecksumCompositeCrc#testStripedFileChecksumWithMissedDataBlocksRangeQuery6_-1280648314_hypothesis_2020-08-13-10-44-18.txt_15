reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-627537543-172.17.0.8-1597315677359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33438,DS-181b83a5-73f5-463a-89b3-68f36a949530,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-56aa16d3-d308-446c-b23d-54fa42bc77fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-62fbb3e0-919b-4cbb-b594-9afdf58879c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-b4b75174-53fc-4813-bd85-e7447cf49ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:44159,DS-78ace4a3-2f58-48b8-933a-0fd1299db2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-37ab25d3-5e28-4f98-880d-b6bec99500e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-8ff0b3ae-b510-4b79-b48c-0cb7391c7108,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-a1f2b648-33b3-4f79-a481-f98a2ec3eaf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-627537543-172.17.0.8-1597315677359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33438,DS-181b83a5-73f5-463a-89b3-68f36a949530,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-56aa16d3-d308-446c-b23d-54fa42bc77fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-62fbb3e0-919b-4cbb-b594-9afdf58879c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-b4b75174-53fc-4813-bd85-e7447cf49ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:44159,DS-78ace4a3-2f58-48b8-933a-0fd1299db2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-37ab25d3-5e28-4f98-880d-b6bec99500e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-8ff0b3ae-b510-4b79-b48c-0cb7391c7108,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-a1f2b648-33b3-4f79-a481-f98a2ec3eaf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1157090082-172.17.0.8-1597315877903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46329,DS-4d92c282-1063-45c7-82c4-f476e9c8256f,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-4d7f1880-e32d-41d9-b43b-3db631dbe991,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-f620b150-e622-4761-93ab-45d69ad6a976,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-4638dfc8-4111-4beb-8b23-3df8e34ace97,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-2752e384-3be2-42c1-98e0-aeb45b36be6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-85ababa3-1b47-408d-a3a3-640efc5e53e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-124c93ee-11cd-4af7-8541-a55eb9061c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-bfcf3d58-6bc0-4b26-b8ae-dc842a57d2ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1157090082-172.17.0.8-1597315877903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46329,DS-4d92c282-1063-45c7-82c4-f476e9c8256f,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-4d7f1880-e32d-41d9-b43b-3db631dbe991,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-f620b150-e622-4761-93ab-45d69ad6a976,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-4638dfc8-4111-4beb-8b23-3df8e34ace97,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-2752e384-3be2-42c1-98e0-aeb45b36be6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-85ababa3-1b47-408d-a3a3-640efc5e53e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-124c93ee-11cd-4af7-8541-a55eb9061c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-bfcf3d58-6bc0-4b26-b8ae-dc842a57d2ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1365564887-172.17.0.8-1597316080957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34093,DS-375de489-5dc5-4504-8ffe-0b2815b0ea95,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-e8b4c9aa-d2c7-46f8-ab56-b7366e33836e,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-be77fc62-951b-4f13-ab8f-3c414df9ed7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-7ff073bc-3578-4605-b452-ea7accb3fade,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-e9e420b9-8952-4894-969d-ff20eae98b56,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-27fbc47b-123f-41ca-a8f5-81bdaf7fc8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-bf9e52a6-1207-4775-96d3-49ebe9ed097d,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-062a5a4f-acb2-41cf-878d-f3a085ebc8f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1365564887-172.17.0.8-1597316080957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34093,DS-375de489-5dc5-4504-8ffe-0b2815b0ea95,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-e8b4c9aa-d2c7-46f8-ab56-b7366e33836e,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-be77fc62-951b-4f13-ab8f-3c414df9ed7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-7ff073bc-3578-4605-b452-ea7accb3fade,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-e9e420b9-8952-4894-969d-ff20eae98b56,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-27fbc47b-123f-41ca-a8f5-81bdaf7fc8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-bf9e52a6-1207-4775-96d3-49ebe9ed097d,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-062a5a4f-acb2-41cf-878d-f3a085ebc8f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2147191857-172.17.0.8-1597316208135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45578,DS-ef678f8d-3325-41ee-a812-0729337faeaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-a095d5d7-4fbb-4f6f-b07e-5d67eb34c239,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-600d4e08-60df-4a5c-87e4-53e008ab46b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-7d8d1bf7-13e8-416d-892b-0683396fffa5,DISK], DatanodeInfoWithStorage[127.0.0.1:40395,DS-1a04b74b-0c7e-4828-ad76-2522d8d69a32,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-704a2124-7103-46a6-a4b7-8bed3fe40a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-1db7a79f-d8af-489b-8fa5-85ca15f18089,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-145a3bd8-5df1-4f99-8d25-2a6aa483350c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2147191857-172.17.0.8-1597316208135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45578,DS-ef678f8d-3325-41ee-a812-0729337faeaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-a095d5d7-4fbb-4f6f-b07e-5d67eb34c239,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-600d4e08-60df-4a5c-87e4-53e008ab46b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-7d8d1bf7-13e8-416d-892b-0683396fffa5,DISK], DatanodeInfoWithStorage[127.0.0.1:40395,DS-1a04b74b-0c7e-4828-ad76-2522d8d69a32,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-704a2124-7103-46a6-a4b7-8bed3fe40a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-1db7a79f-d8af-489b-8fa5-85ca15f18089,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-145a3bd8-5df1-4f99-8d25-2a6aa483350c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850022596-172.17.0.8-1597316320796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37501,DS-0232edf6-2c3a-4b33-ac2d-60cb3bba86bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-341f0d43-3dd7-4990-b33c-0b217a76c652,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-fc2e4adf-f3cc-4d8c-9550-1443bb37a285,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-6a080273-ad13-45e5-87e5-88a4459482b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-a96db86e-6620-4db9-9d69-95860aeb3aea,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-db92d971-a154-4dfe-b38d-4337450167eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-be2e276f-fd15-43cb-9e1e-c927fd3b3c83,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-63dc085a-04e6-4046-9fa7-0fede8790bcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850022596-172.17.0.8-1597316320796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37501,DS-0232edf6-2c3a-4b33-ac2d-60cb3bba86bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-341f0d43-3dd7-4990-b33c-0b217a76c652,DISK], DatanodeInfoWithStorage[127.0.0.1:32961,DS-fc2e4adf-f3cc-4d8c-9550-1443bb37a285,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-6a080273-ad13-45e5-87e5-88a4459482b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-a96db86e-6620-4db9-9d69-95860aeb3aea,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-db92d971-a154-4dfe-b38d-4337450167eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-be2e276f-fd15-43cb-9e1e-c927fd3b3c83,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-63dc085a-04e6-4046-9fa7-0fede8790bcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2007919570-172.17.0.8-1597316359352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42102,DS-8c315706-93a8-4979-b914-a52b5865ec3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-62e156c8-765c-49ca-ba76-0fd46a7568c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-90a76d4e-f8d7-4fe5-8aea-47c1057d5804,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-5c746415-38a1-4ea2-86ce-a788639fd8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-1c241c79-e436-4d7c-a4d0-9be2aac22148,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-b0f9f1f8-24e5-4715-b5de-fa200b4c79dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-032effde-8ccc-407a-ada1-88a067b9c390,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-a6d14cc1-df0b-465c-8dc5-99410a4c0b70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2007919570-172.17.0.8-1597316359352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42102,DS-8c315706-93a8-4979-b914-a52b5865ec3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-62e156c8-765c-49ca-ba76-0fd46a7568c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-90a76d4e-f8d7-4fe5-8aea-47c1057d5804,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-5c746415-38a1-4ea2-86ce-a788639fd8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-1c241c79-e436-4d7c-a4d0-9be2aac22148,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-b0f9f1f8-24e5-4715-b5de-fa200b4c79dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-032effde-8ccc-407a-ada1-88a067b9c390,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-a6d14cc1-df0b-465c-8dc5-99410a4c0b70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026332565-172.17.0.8-1597316696007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40598,DS-f02c16e8-be27-4968-a19e-0e76c22526c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-6f52a8d7-6dc4-4a41-ae12-b46497c41d04,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-e25f1c00-6d64-46e7-aac7-f9fb59b48f86,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-a8228260-e7af-4c2b-a1fc-a8e6f62f661c,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-5c6e0cd3-5b87-4e75-a115-f3ed096665c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-8deab1ae-304e-4f06-9b9e-ac320693eda8,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-db44d72e-ec5a-4a35-bc60-5f05b83aebc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-aac06003-de69-42e0-9b9d-6740ffe9c0f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026332565-172.17.0.8-1597316696007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40598,DS-f02c16e8-be27-4968-a19e-0e76c22526c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-6f52a8d7-6dc4-4a41-ae12-b46497c41d04,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-e25f1c00-6d64-46e7-aac7-f9fb59b48f86,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-a8228260-e7af-4c2b-a1fc-a8e6f62f661c,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-5c6e0cd3-5b87-4e75-a115-f3ed096665c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43934,DS-8deab1ae-304e-4f06-9b9e-ac320693eda8,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-db44d72e-ec5a-4a35-bc60-5f05b83aebc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45394,DS-aac06003-de69-42e0-9b9d-6740ffe9c0f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1750121501-172.17.0.8-1597316775189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43171,DS-12924fbe-470d-4bbc-90cf-466aa53f350a,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-b980704a-9e7a-4610-a2b8-940e0516da26,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-a3f4e87f-9711-49ee-aaa5-d7f6c36b8d62,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-b0521711-1f4d-4f79-b165-82b3810c457e,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-95db01f5-0cf8-403e-9800-e448155b4fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-c0891ba6-8c8f-451a-ab44-09a2f23d5a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-672ba3de-18ba-42a4-af23-a1239520c2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-88fa1342-2094-4f30-a46e-7705eb6a6fa9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1750121501-172.17.0.8-1597316775189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43171,DS-12924fbe-470d-4bbc-90cf-466aa53f350a,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-b980704a-9e7a-4610-a2b8-940e0516da26,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-a3f4e87f-9711-49ee-aaa5-d7f6c36b8d62,DISK], DatanodeInfoWithStorage[127.0.0.1:40179,DS-b0521711-1f4d-4f79-b165-82b3810c457e,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-95db01f5-0cf8-403e-9800-e448155b4fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-c0891ba6-8c8f-451a-ab44-09a2f23d5a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-672ba3de-18ba-42a4-af23-a1239520c2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-88fa1342-2094-4f30-a46e-7705eb6a6fa9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1539840565-172.17.0.8-1597317074566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39490,DS-5fbd7ce3-d315-4d23-be04-b0331d0f4b79,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-73884d06-2a46-4d18-8821-446d43f23b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-401ab37a-d8d8-47fd-9037-3fc475657bec,DISK], DatanodeInfoWithStorage[127.0.0.1:44131,DS-2dbaf243-4fb2-45ff-b0c1-a564f2caf17a,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-cb8df469-93a6-463a-a817-d0d9615f5515,DISK], DatanodeInfoWithStorage[127.0.0.1:41485,DS-c3a7ac20-c26a-47d5-90f9-e5d61ae0b5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-bab4c5cb-fbd4-40e4-9480-4d1a305ba31b,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-e47abdca-3d81-468c-a31f-677c226a1a5c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1539840565-172.17.0.8-1597317074566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39490,DS-5fbd7ce3-d315-4d23-be04-b0331d0f4b79,DISK], DatanodeInfoWithStorage[127.0.0.1:45966,DS-73884d06-2a46-4d18-8821-446d43f23b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-401ab37a-d8d8-47fd-9037-3fc475657bec,DISK], DatanodeInfoWithStorage[127.0.0.1:44131,DS-2dbaf243-4fb2-45ff-b0c1-a564f2caf17a,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-cb8df469-93a6-463a-a817-d0d9615f5515,DISK], DatanodeInfoWithStorage[127.0.0.1:41485,DS-c3a7ac20-c26a-47d5-90f9-e5d61ae0b5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-bab4c5cb-fbd4-40e4-9480-4d1a305ba31b,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-e47abdca-3d81-468c-a31f-677c226a1a5c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1271719644-172.17.0.8-1597317193987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32948,DS-059b72e6-904f-4b4f-b0f3-c29993361686,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-8a7a5e07-6e9d-4280-b16f-37ec7a59762d,DISK], DatanodeInfoWithStorage[127.0.0.1:34365,DS-682502f3-2e3d-4c5d-adf2-981a4c82857c,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-3eafc845-f379-43aa-acf5-45d22f096d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-dd666ac9-0c55-4f22-b6aa-358d5186dc3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-f6bd1c95-a7a1-4ae5-bf1d-563e2c979b51,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-24f4aa73-773f-47f8-83b2-5a3726cbd045,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-84eb3671-93f5-476f-bfdf-fd7d541f16cc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1271719644-172.17.0.8-1597317193987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32948,DS-059b72e6-904f-4b4f-b0f3-c29993361686,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-8a7a5e07-6e9d-4280-b16f-37ec7a59762d,DISK], DatanodeInfoWithStorage[127.0.0.1:34365,DS-682502f3-2e3d-4c5d-adf2-981a4c82857c,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-3eafc845-f379-43aa-acf5-45d22f096d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-dd666ac9-0c55-4f22-b6aa-358d5186dc3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-f6bd1c95-a7a1-4ae5-bf1d-563e2c979b51,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-24f4aa73-773f-47f8-83b2-5a3726cbd045,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-84eb3671-93f5-476f-bfdf-fd7d541f16cc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1201704275-172.17.0.8-1597317231617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34078,DS-2e18a3d3-77ca-4ab7-959b-6bb436309ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-43b223c9-4b11-4830-8a51-42e454d3197a,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-d31cb614-48b8-46e1-8ba3-ffb8cc946066,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-5d8ea55c-8d75-471f-be99-8afdf29f642c,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-42899248-2524-4bf0-a138-c3d684e941f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-8fe64c5f-2e30-4175-b8b6-abe7d5777343,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-7f0c6bdb-30a8-4d7b-8ef3-829a36213ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-9139ca66-5bc6-4e1c-90fb-9b4dc8a025b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1201704275-172.17.0.8-1597317231617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34078,DS-2e18a3d3-77ca-4ab7-959b-6bb436309ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-43b223c9-4b11-4830-8a51-42e454d3197a,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-d31cb614-48b8-46e1-8ba3-ffb8cc946066,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-5d8ea55c-8d75-471f-be99-8afdf29f642c,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-42899248-2524-4bf0-a138-c3d684e941f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-8fe64c5f-2e30-4175-b8b6-abe7d5777343,DISK], DatanodeInfoWithStorage[127.0.0.1:34171,DS-7f0c6bdb-30a8-4d7b-8ef3-829a36213ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-9139ca66-5bc6-4e1c-90fb-9b4dc8a025b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-680881533-172.17.0.8-1597317314262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37237,DS-159203f9-3464-4abb-a6f9-475bb0fff54e,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-e7f31603-50f3-456c-8b79-60f408147e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-5e3f99c0-1c76-4aba-9df9-c88d0269a548,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-2b245b24-281b-423a-b7ce-6e8b41a29e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-83585250-e005-4a66-906f-b9b1efe83ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-0218232e-4a0c-475d-bc82-8f855b76834e,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-eae593e7-a17f-41ab-aa06-e35cfa80d2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-6cbabdc1-0e28-42b6-89df-f172f48bd452,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-680881533-172.17.0.8-1597317314262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37237,DS-159203f9-3464-4abb-a6f9-475bb0fff54e,DISK], DatanodeInfoWithStorage[127.0.0.1:37499,DS-e7f31603-50f3-456c-8b79-60f408147e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-5e3f99c0-1c76-4aba-9df9-c88d0269a548,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-2b245b24-281b-423a-b7ce-6e8b41a29e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43602,DS-83585250-e005-4a66-906f-b9b1efe83ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-0218232e-4a0c-475d-bc82-8f855b76834e,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-eae593e7-a17f-41ab-aa06-e35cfa80d2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-6cbabdc1-0e28-42b6-89df-f172f48bd452,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1416169318-172.17.0.8-1597317386089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41588,DS-7c76f5bb-53fd-4c28-95d6-2b787e79c231,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-8972d2e7-5b9d-4f5a-9dfe-69b6b9fc255f,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-db5b6e55-4416-4dcb-a13a-299fc39d2026,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-abfa6410-b0ba-4e9e-8781-355f2247993c,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-d3bc9f1d-fb92-45d5-9e5b-8ff2546a79ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-e8abf1c7-a8ec-4682-9513-c8ce336a9e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-653ead26-5d7b-4d1e-a5a2-219c59e418c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-11dd21e7-6f16-40f4-ac3d-44fb873502a9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1416169318-172.17.0.8-1597317386089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41588,DS-7c76f5bb-53fd-4c28-95d6-2b787e79c231,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-8972d2e7-5b9d-4f5a-9dfe-69b6b9fc255f,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-db5b6e55-4416-4dcb-a13a-299fc39d2026,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-abfa6410-b0ba-4e9e-8781-355f2247993c,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-d3bc9f1d-fb92-45d5-9e5b-8ff2546a79ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-e8abf1c7-a8ec-4682-9513-c8ce336a9e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-653ead26-5d7b-4d1e-a5a2-219c59e418c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-11dd21e7-6f16-40f4-ac3d-44fb873502a9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-657552808-172.17.0.8-1597317566384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41239,DS-6af46445-3b00-43d6-8037-e495f1081ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-ca795d39-9647-46bc-9e99-1b4ced10724f,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-20d47c81-8184-44e2-9516-e2045b023536,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-54e6d873-500d-4cb0-b564-83a007b83749,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-c729c62c-6d51-462a-87d4-7824344cf226,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-58043667-633a-4cf7-af65-9e676d7db6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-942c16bf-0c46-4543-8418-d01aad99b73b,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-a30052ae-efd0-48e7-bf97-7a981e7fc395,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-657552808-172.17.0.8-1597317566384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41239,DS-6af46445-3b00-43d6-8037-e495f1081ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-ca795d39-9647-46bc-9e99-1b4ced10724f,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-20d47c81-8184-44e2-9516-e2045b023536,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-54e6d873-500d-4cb0-b564-83a007b83749,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-c729c62c-6d51-462a-87d4-7824344cf226,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-58043667-633a-4cf7-af65-9e676d7db6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-942c16bf-0c46-4543-8418-d01aad99b73b,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-a30052ae-efd0-48e7-bf97-7a981e7fc395,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-431048824-172.17.0.8-1597317636389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41527,DS-197c439f-863b-44c4-9c05-9f52c1d44167,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-abe8adf3-de5d-4b32-a795-e533f57e460c,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-7a035925-c691-4e91-92d6-216881d44637,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-e3ea35c0-cd45-4796-9f15-02c5c7682490,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-7e4d2463-67c0-4a54-98c3-057c1b7a6886,DISK], DatanodeInfoWithStorage[127.0.0.1:43347,DS-caf34103-a585-4e29-9f56-f4e0bef611c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-72c1ff11-55c2-46a1-9e2b-92c98726deb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-f70cd1f7-87fb-4d57-93b1-f5671092af18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-431048824-172.17.0.8-1597317636389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41527,DS-197c439f-863b-44c4-9c05-9f52c1d44167,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-abe8adf3-de5d-4b32-a795-e533f57e460c,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-7a035925-c691-4e91-92d6-216881d44637,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-e3ea35c0-cd45-4796-9f15-02c5c7682490,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-7e4d2463-67c0-4a54-98c3-057c1b7a6886,DISK], DatanodeInfoWithStorage[127.0.0.1:43347,DS-caf34103-a585-4e29-9f56-f4e0bef611c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-72c1ff11-55c2-46a1-9e2b-92c98726deb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-f70cd1f7-87fb-4d57-93b1-f5671092af18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145295554-172.17.0.8-1597317714509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37536,DS-4d57c917-487d-448b-9638-eae0bb788896,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-b71a7a18-616b-4f67-ad43-1b80644c92dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-8b70927b-c6e3-40bf-9f15-4b2d1a3d2e79,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-b4c91cfe-b35a-40ee-9c3e-5142a7e83669,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-fb56a0c8-623a-42fe-bcb9-ab51637e59e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-ef07f40e-ade9-41c5-9cba-5f467c225853,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-53c936ef-2497-445c-aef9-2c30d0fb3ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-69fd3274-f258-4e0c-9a53-e14a0a0eadd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1145295554-172.17.0.8-1597317714509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37536,DS-4d57c917-487d-448b-9638-eae0bb788896,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-b71a7a18-616b-4f67-ad43-1b80644c92dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-8b70927b-c6e3-40bf-9f15-4b2d1a3d2e79,DISK], DatanodeInfoWithStorage[127.0.0.1:45429,DS-b4c91cfe-b35a-40ee-9c3e-5142a7e83669,DISK], DatanodeInfoWithStorage[127.0.0.1:34443,DS-fb56a0c8-623a-42fe-bcb9-ab51637e59e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-ef07f40e-ade9-41c5-9cba-5f467c225853,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-53c936ef-2497-445c-aef9-2c30d0fb3ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-69fd3274-f258-4e0c-9a53-e14a0a0eadd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1611249669-172.17.0.8-1597317793007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40817,DS-14cddc30-36fd-4a22-aa99-9072f5f2d65a,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-01bda753-6c8c-48bf-8238-13dfd5b06385,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-d372aee7-9a11-46fb-be92-afc7d703f660,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-9fa67568-cf8f-418b-a25f-6fc35faaf841,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-2c501c70-0f28-41ed-952a-b03385a0f325,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-e24c78b3-c6aa-4db1-9a6a-0dcf8f03bf26,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-627531ef-c209-46ed-8962-ef5ba7886eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-87be75cd-0aae-4736-bf42-febe7a854503,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1611249669-172.17.0.8-1597317793007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40817,DS-14cddc30-36fd-4a22-aa99-9072f5f2d65a,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-01bda753-6c8c-48bf-8238-13dfd5b06385,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-d372aee7-9a11-46fb-be92-afc7d703f660,DISK], DatanodeInfoWithStorage[127.0.0.1:34543,DS-9fa67568-cf8f-418b-a25f-6fc35faaf841,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-2c501c70-0f28-41ed-952a-b03385a0f325,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-e24c78b3-c6aa-4db1-9a6a-0dcf8f03bf26,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-627531ef-c209-46ed-8962-ef5ba7886eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-87be75cd-0aae-4736-bf42-febe7a854503,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654571367-172.17.0.8-1597318250626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39986,DS-d930e4de-84a9-4752-ad81-803f8e1bc5de,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-957ea12a-5cfc-4614-9852-5339804edddc,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-4c6882ca-e21d-4f2e-93c1-3e05c4465cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-b2a65caa-e248-4296-b7b2-6a597d49be4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-424e3ae9-3a67-44e7-b1f6-7c2173391bce,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-807fb403-7ef2-483f-a898-852d3160e06c,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-cf517acd-27aa-4780-81b4-91d6a78e6df0,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-4f912226-2a49-40bc-93dd-2467afb80a7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654571367-172.17.0.8-1597318250626:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39986,DS-d930e4de-84a9-4752-ad81-803f8e1bc5de,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-957ea12a-5cfc-4614-9852-5339804edddc,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-4c6882ca-e21d-4f2e-93c1-3e05c4465cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41288,DS-b2a65caa-e248-4296-b7b2-6a597d49be4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-424e3ae9-3a67-44e7-b1f6-7c2173391bce,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-807fb403-7ef2-483f-a898-852d3160e06c,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-cf517acd-27aa-4780-81b4-91d6a78e6df0,DISK], DatanodeInfoWithStorage[127.0.0.1:34578,DS-4f912226-2a49-40bc-93dd-2467afb80a7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204355173-172.17.0.8-1597318446036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43781,DS-e2238052-db43-4135-8871-747bc1352ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-d813b898-449d-41bd-ab0e-e8012ea12afb,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-3bc28614-736b-48c2-bcb4-db73a6f63b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-76ec476f-f1e0-40bd-9a2d-f06513fe7642,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-e14e00ff-0b22-4c58-98b3-ac2836844842,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-38ccce91-f687-4525-91bc-dd36e0e87e63,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-1ddd48f7-e9de-425b-ba7e-9e04a9742f49,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-89a492cd-c76c-48e5-9aeb-3d98592b16ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204355173-172.17.0.8-1597318446036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43781,DS-e2238052-db43-4135-8871-747bc1352ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-d813b898-449d-41bd-ab0e-e8012ea12afb,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-3bc28614-736b-48c2-bcb4-db73a6f63b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-76ec476f-f1e0-40bd-9a2d-f06513fe7642,DISK], DatanodeInfoWithStorage[127.0.0.1:33753,DS-e14e00ff-0b22-4c58-98b3-ac2836844842,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-38ccce91-f687-4525-91bc-dd36e0e87e63,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-1ddd48f7-e9de-425b-ba7e-9e04a9742f49,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-89a492cd-c76c-48e5-9aeb-3d98592b16ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951967535-172.17.0.8-1597318556234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33759,DS-f0773d76-9a9f-4333-ba13-7cc16b5ce5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-ae8cd139-6ef8-4ef4-9d52-3076d1f83af2,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-7e9714cd-c7dd-4a96-be26-96be4f44793e,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-cf509107-5d2d-4923-980a-30a39aaa9186,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-b5a60472-53ac-439f-a694-7ba38ac1d9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-af1e4dc0-dd79-4e3a-a57a-3520710a207e,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-d545dfce-919c-4495-a8ba-a32910984ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-c119c28d-a85e-497d-ab0e-eb0445a929a8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951967535-172.17.0.8-1597318556234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33759,DS-f0773d76-9a9f-4333-ba13-7cc16b5ce5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44033,DS-ae8cd139-6ef8-4ef4-9d52-3076d1f83af2,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-7e9714cd-c7dd-4a96-be26-96be4f44793e,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-cf509107-5d2d-4923-980a-30a39aaa9186,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-b5a60472-53ac-439f-a694-7ba38ac1d9ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-af1e4dc0-dd79-4e3a-a57a-3520710a207e,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-d545dfce-919c-4495-a8ba-a32910984ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-c119c28d-a85e-497d-ab0e-eb0445a929a8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1374385703-172.17.0.8-1597319012048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32920,DS-bbfd2ae4-a358-4b41-b3e2-4f6791328a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-a042ba60-3c7d-4b7f-9159-cb848dbf9f89,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-b27a52e0-f957-4d0c-9b8c-1a9982fa8cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-586cc2ea-a0de-4be1-a814-e49d90f03570,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-132ed774-8dcd-4e78-a1db-56147fcb5a74,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-dda597ff-6471-4119-9a6a-47fd5f2bdae3,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-8703dfb8-0115-467a-b680-2c9051588bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-b27b1978-9151-44b4-b9d0-e924be6c1f55,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1374385703-172.17.0.8-1597319012048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32920,DS-bbfd2ae4-a358-4b41-b3e2-4f6791328a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:32924,DS-a042ba60-3c7d-4b7f-9159-cb848dbf9f89,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-b27a52e0-f957-4d0c-9b8c-1a9982fa8cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-586cc2ea-a0de-4be1-a814-e49d90f03570,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-132ed774-8dcd-4e78-a1db-56147fcb5a74,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-dda597ff-6471-4119-9a6a-47fd5f2bdae3,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-8703dfb8-0115-467a-b680-2c9051588bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-b27b1978-9151-44b4-b9d0-e924be6c1f55,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299969566-172.17.0.8-1597319109688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43927,DS-f5572b2f-7e74-4c35-91c5-e27cbad5a94d,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-0dd70746-fc9e-43c9-b13f-b8ecdf36a5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-4de97826-20c0-417e-a941-4a7206504734,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-eb18baff-475d-4b32-8a6f-1a2d6f734188,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-6272aa74-fc6f-40d5-b0ee-90b3d5b3f469,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-d45ebf98-1251-443a-b22c-f247635b12fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-fec536aa-b3ad-4f71-ba12-c959589baee0,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-9dff0878-b610-4b6a-a9f5-f77c99e3b434,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299969566-172.17.0.8-1597319109688:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43927,DS-f5572b2f-7e74-4c35-91c5-e27cbad5a94d,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-0dd70746-fc9e-43c9-b13f-b8ecdf36a5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-4de97826-20c0-417e-a941-4a7206504734,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-eb18baff-475d-4b32-8a6f-1a2d6f734188,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-6272aa74-fc6f-40d5-b0ee-90b3d5b3f469,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-d45ebf98-1251-443a-b22c-f247635b12fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-fec536aa-b3ad-4f71-ba12-c959589baee0,DISK], DatanodeInfoWithStorage[127.0.0.1:45582,DS-9dff0878-b610-4b6a-a9f5-f77c99e3b434,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896144063-172.17.0.8-1597319247654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46089,DS-10fc59bc-ef6f-4da1-8228-485837e92889,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-9100549d-6a15-4894-a2d2-a7c7b4d7548f,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-50b61325-5234-4e50-9e7a-1ae76ea98a93,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-5fdb25f8-0702-4c3e-b696-55cc01d09e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-c2f13fc5-8ad3-448f-a955-382b1e421a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-a7474327-7176-4236-aab7-b7c446967245,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-1868daf5-f408-40c8-bdfc-5529ce761591,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-a0d55a05-ea11-4502-b051-bf9a6ef5e93a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-896144063-172.17.0.8-1597319247654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46089,DS-10fc59bc-ef6f-4da1-8228-485837e92889,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-9100549d-6a15-4894-a2d2-a7c7b4d7548f,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-50b61325-5234-4e50-9e7a-1ae76ea98a93,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-5fdb25f8-0702-4c3e-b696-55cc01d09e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-c2f13fc5-8ad3-448f-a955-382b1e421a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-a7474327-7176-4236-aab7-b7c446967245,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-1868daf5-f408-40c8-bdfc-5529ce761591,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-a0d55a05-ea11-4502-b051-bf9a6ef5e93a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165875720-172.17.0.8-1597319313589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42147,DS-d11504b2-b8a9-400d-bda1-a9f1728a2faa,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-795b8cdc-f09a-49ca-a305-1e8b30b2e58d,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-1f71c177-3ac6-40d5-99ba-32e7e3b8ca86,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-75120463-a751-4526-b105-edafbc82d7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-e7543ab7-c792-401e-9c3d-5d0138269780,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-df413f7a-47a9-409a-b98d-bd2c5ae4de7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-3a9019f9-e5a3-43c5-ae97-6271013c0165,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-eed2aeec-31e7-4b44-b758-dc8d154c9942,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165875720-172.17.0.8-1597319313589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42147,DS-d11504b2-b8a9-400d-bda1-a9f1728a2faa,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-795b8cdc-f09a-49ca-a305-1e8b30b2e58d,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-1f71c177-3ac6-40d5-99ba-32e7e3b8ca86,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-75120463-a751-4526-b105-edafbc82d7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-e7543ab7-c792-401e-9c3d-5d0138269780,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-df413f7a-47a9-409a-b98d-bd2c5ae4de7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-3a9019f9-e5a3-43c5-ae97-6271013c0165,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-eed2aeec-31e7-4b44-b758-dc8d154c9942,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1714592759-172.17.0.8-1597319345857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39731,DS-f42d2fbc-b821-4f1b-9d52-7120299dd7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-4a45a2d3-c3f8-48f6-a798-4a3716a68abe,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-92c53625-874f-4325-ab1c-15b542e081f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-19a3f0be-ea80-4390-b945-20af6abaabb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-8ee4bd9b-ee36-48c5-8a6c-5c699fa7dc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-315082df-93a7-4d2c-9033-ed2a19a7855e,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-68176578-4a8d-4c0e-9358-6fd4b9aec683,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-76fb9c8a-fe35-492b-bb12-e5d6f0b948cd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1714592759-172.17.0.8-1597319345857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39731,DS-f42d2fbc-b821-4f1b-9d52-7120299dd7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-4a45a2d3-c3f8-48f6-a798-4a3716a68abe,DISK], DatanodeInfoWithStorage[127.0.0.1:34324,DS-92c53625-874f-4325-ab1c-15b542e081f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-19a3f0be-ea80-4390-b945-20af6abaabb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-8ee4bd9b-ee36-48c5-8a6c-5c699fa7dc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-315082df-93a7-4d2c-9033-ed2a19a7855e,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-68176578-4a8d-4c0e-9358-6fd4b9aec683,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-76fb9c8a-fe35-492b-bb12-e5d6f0b948cd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-434604935-172.17.0.8-1597319474067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43579,DS-eac29b61-c9b8-4954-b61e-34b68dc5dab9,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-b59f544a-ecfd-4d84-a843-af949f729c88,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-dda5cc56-1930-4422-ad2b-affbf53f3509,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-58fa0502-3f7a-40e1-bc0d-7827a41f96c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-67fd0eb5-171d-438c-a71c-2001e96567c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-5a53d096-8977-4680-b239-77d8a09d374d,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-fa313c91-300d-44ba-8586-bba65e1d7b46,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-de45d086-e28c-4ae3-96f4-561993317461,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-434604935-172.17.0.8-1597319474067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43579,DS-eac29b61-c9b8-4954-b61e-34b68dc5dab9,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-b59f544a-ecfd-4d84-a843-af949f729c88,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-dda5cc56-1930-4422-ad2b-affbf53f3509,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-58fa0502-3f7a-40e1-bc0d-7827a41f96c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-67fd0eb5-171d-438c-a71c-2001e96567c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-5a53d096-8977-4680-b239-77d8a09d374d,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-fa313c91-300d-44ba-8586-bba65e1d7b46,DISK], DatanodeInfoWithStorage[127.0.0.1:42246,DS-de45d086-e28c-4ae3-96f4-561993317461,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1191740557-172.17.0.8-1597319508490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41792,DS-689dfefd-f6e0-4252-91de-e227540d9720,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-72b05809-5bd9-4c66-9472-b7d427c617ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-cc70de96-a7fa-44c0-a3d8-f594d6acdd07,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-5a5059e3-f19a-4f89-af17-90175207a165,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-f318a4d9-819a-48f2-9c26-2c754ed3e15f,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-066dd6cf-9378-4f65-af92-bc0da1826133,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-7b7ec8a3-ef43-4a5a-9828-c0007435c053,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-6b2d6623-68d6-429e-90c5-816b36f196ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1191740557-172.17.0.8-1597319508490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41792,DS-689dfefd-f6e0-4252-91de-e227540d9720,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-72b05809-5bd9-4c66-9472-b7d427c617ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-cc70de96-a7fa-44c0-a3d8-f594d6acdd07,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-5a5059e3-f19a-4f89-af17-90175207a165,DISK], DatanodeInfoWithStorage[127.0.0.1:36799,DS-f318a4d9-819a-48f2-9c26-2c754ed3e15f,DISK], DatanodeInfoWithStorage[127.0.0.1:43752,DS-066dd6cf-9378-4f65-af92-bc0da1826133,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-7b7ec8a3-ef43-4a5a-9828-c0007435c053,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-6b2d6623-68d6-429e-90c5-816b36f196ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154490845-172.17.0.8-1597319593044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36521,DS-ba68c492-08ab-4523-a724-63b9adb97c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-edbbe43a-f81b-4469-984a-9aaef500801a,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-eccc411c-1c9e-4792-8994-a6e1a309c001,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-842f4b38-2916-4040-a3e8-26a3b7867558,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-d2b8d602-fbab-4843-a1ac-54ff920aba6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-5f335a43-cc54-4f4e-ad32-6b910888311e,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-beb49c0c-8828-4930-82b7-a4a1a3c51503,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-57ca0c34-f43d-423c-a9c6-e2e3c3c92137,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1154490845-172.17.0.8-1597319593044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36521,DS-ba68c492-08ab-4523-a724-63b9adb97c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-edbbe43a-f81b-4469-984a-9aaef500801a,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-eccc411c-1c9e-4792-8994-a6e1a309c001,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-842f4b38-2916-4040-a3e8-26a3b7867558,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-d2b8d602-fbab-4843-a1ac-54ff920aba6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-5f335a43-cc54-4f4e-ad32-6b910888311e,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-beb49c0c-8828-4930-82b7-a4a1a3c51503,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-57ca0c34-f43d-423c-a9c6-e2e3c3c92137,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-362590621-172.17.0.8-1597319807998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40401,DS-1af89fc6-0d45-4365-ae2a-3879e8735040,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-45dc7970-e4d6-4def-892a-eedab7aa7e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-ad064227-fe16-407f-a255-f09aeec952a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-2e6603e6-2cb2-4205-b16b-83f32ec012c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-8efa5a9f-7f37-4e77-9c19-1ccf7634f1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-3ec6bd4d-2944-420b-bd3d-23eea3c83083,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-b57a915e-7251-4621-9d93-f7d562899a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-da3311e8-74e0-4187-b1e7-b0d84164e919,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-362590621-172.17.0.8-1597319807998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40401,DS-1af89fc6-0d45-4365-ae2a-3879e8735040,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-45dc7970-e4d6-4def-892a-eedab7aa7e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-ad064227-fe16-407f-a255-f09aeec952a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-2e6603e6-2cb2-4205-b16b-83f32ec012c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-8efa5a9f-7f37-4e77-9c19-1ccf7634f1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-3ec6bd4d-2944-420b-bd3d-23eea3c83083,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-b57a915e-7251-4621-9d93-f7d562899a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-da3311e8-74e0-4187-b1e7-b0d84164e919,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-427094335-172.17.0.8-1597320282282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46858,DS-eff8b192-b101-4b0c-a70c-b8a2c28f95e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-f3045495-c176-42d1-b720-517cc990abba,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-4d3fe4f7-d78e-4380-b841-6d3fafb7281b,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-14bd219c-6e04-4376-beba-863955a5b333,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-efe35911-8019-4c9d-808f-e5c864987708,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-c45020b0-e60c-4125-8378-de1e3fbcd0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-8484a6b9-3fb4-404f-8d7c-0f181846326c,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-c56b86bb-e590-4e2c-96b2-81b5af82c33b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-427094335-172.17.0.8-1597320282282:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46858,DS-eff8b192-b101-4b0c-a70c-b8a2c28f95e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-f3045495-c176-42d1-b720-517cc990abba,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-4d3fe4f7-d78e-4380-b841-6d3fafb7281b,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-14bd219c-6e04-4376-beba-863955a5b333,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-efe35911-8019-4c9d-808f-e5c864987708,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-c45020b0-e60c-4125-8378-de1e3fbcd0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-8484a6b9-3fb4-404f-8d7c-0f181846326c,DISK], DatanodeInfoWithStorage[127.0.0.1:44323,DS-c56b86bb-e590-4e2c-96b2-81b5af82c33b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-29006701-172.17.0.8-1597320324539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33059,DS-c9b3e946-7521-4789-b977-2f1d317edb40,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-af033fd6-7010-4525-9c64-5f2ee76ccdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-bdd650ff-0fc3-468f-8041-c81bd8bb5437,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-8cbef3f4-36ca-4f53-8504-ecc499e301c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-9336e885-4721-42fb-8d6d-6da5fd385490,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-baf55b50-ebdc-43ca-aee3-f9847d781409,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-0d65df1e-00fe-4901-afad-c825f9333fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-a8a19b79-7a10-47a9-a5c3-c1fec23f6bc5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-29006701-172.17.0.8-1597320324539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33059,DS-c9b3e946-7521-4789-b977-2f1d317edb40,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-af033fd6-7010-4525-9c64-5f2ee76ccdeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43033,DS-bdd650ff-0fc3-468f-8041-c81bd8bb5437,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-8cbef3f4-36ca-4f53-8504-ecc499e301c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-9336e885-4721-42fb-8d6d-6da5fd385490,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-baf55b50-ebdc-43ca-aee3-f9847d781409,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-0d65df1e-00fe-4901-afad-c825f9333fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-a8a19b79-7a10-47a9-a5c3-c1fec23f6bc5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-564381625-172.17.0.8-1597320595850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33317,DS-4b039b52-4af4-47b9-bb84-509e1c6724b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-90dd6882-ecf3-4859-a41d-e4e3534187aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-c9637c33-ffff-4602-b6f3-93dd0d113af7,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-f6d62097-e154-4e66-ae37-9dbd9799aa58,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-9db3f373-0b5a-4402-80bc-ad00d0693c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-7dbdd331-8046-4a14-b0c1-f48d8f10c552,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-455ad627-35db-4c8f-8ed8-a41366c72850,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-53b9f94e-402b-4c41-9324-e473aefc1714,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-564381625-172.17.0.8-1597320595850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33317,DS-4b039b52-4af4-47b9-bb84-509e1c6724b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-90dd6882-ecf3-4859-a41d-e4e3534187aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-c9637c33-ffff-4602-b6f3-93dd0d113af7,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-f6d62097-e154-4e66-ae37-9dbd9799aa58,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-9db3f373-0b5a-4402-80bc-ad00d0693c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-7dbdd331-8046-4a14-b0c1-f48d8f10c552,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-455ad627-35db-4c8f-8ed8-a41366c72850,DISK], DatanodeInfoWithStorage[127.0.0.1:38677,DS-53b9f94e-402b-4c41-9324-e473aefc1714,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-741845536-172.17.0.8-1597320775113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37372,DS-26e3f64f-da39-47dd-a1dd-46ae0addb735,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-5648e770-328a-4908-9b13-39c1b884f1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-f65dc849-36b2-47b8-9445-221ee4b7bd12,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-d642e5ca-39d6-4589-acfa-9537d69739e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-99108311-143b-4f19-a618-c6a6e3f4ce75,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-3837ebbd-8acb-4eab-9670-39fa3500d006,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-fd4a5b5d-46c5-4322-a2ee-b4b183460b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-a936abcf-eb1f-43c2-ba64-994065b2d8bf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-741845536-172.17.0.8-1597320775113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37372,DS-26e3f64f-da39-47dd-a1dd-46ae0addb735,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-5648e770-328a-4908-9b13-39c1b884f1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-f65dc849-36b2-47b8-9445-221ee4b7bd12,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-d642e5ca-39d6-4589-acfa-9537d69739e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-99108311-143b-4f19-a618-c6a6e3f4ce75,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-3837ebbd-8acb-4eab-9670-39fa3500d006,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-fd4a5b5d-46c5-4322-a2ee-b4b183460b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34712,DS-a936abcf-eb1f-43c2-ba64-994065b2d8bf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-352372244-172.17.0.8-1597321085425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46862,DS-8818135a-8a25-4f7c-b0a2-ebbb20e881db,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-a9d15239-7864-4429-b397-a6b9e9f77306,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-cd608c37-bb22-4c6a-b0f6-8b0d2611d314,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-ed778dd9-7f2a-438c-9a19-268cb5c871ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-a3a36b96-4f60-4b4d-bdb9-ded90cc12a46,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-bfa7df09-082e-4d3e-a8b6-16adaee9f39e,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-db724d90-6a57-4444-8d8c-1efd2b98c904,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-cd02e225-3258-45db-8cda-35d2ef1ffd48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-352372244-172.17.0.8-1597321085425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46862,DS-8818135a-8a25-4f7c-b0a2-ebbb20e881db,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-a9d15239-7864-4429-b397-a6b9e9f77306,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-cd608c37-bb22-4c6a-b0f6-8b0d2611d314,DISK], DatanodeInfoWithStorage[127.0.0.1:40281,DS-ed778dd9-7f2a-438c-9a19-268cb5c871ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46289,DS-a3a36b96-4f60-4b4d-bdb9-ded90cc12a46,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-bfa7df09-082e-4d3e-a8b6-16adaee9f39e,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-db724d90-6a57-4444-8d8c-1efd2b98c904,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-cd02e225-3258-45db-8cda-35d2ef1ffd48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 22 out of 50
result: false positive !!!
Total execution time in seconds : 5651
