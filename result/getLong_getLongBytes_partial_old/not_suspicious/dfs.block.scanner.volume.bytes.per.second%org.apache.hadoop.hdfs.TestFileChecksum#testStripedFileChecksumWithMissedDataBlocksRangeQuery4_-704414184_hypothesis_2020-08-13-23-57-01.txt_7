reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2120116229-172.17.0.4-1597363070819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42533,DS-129fa6f7-b0ed-46cb-a81b-5c5ee14e5f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-eff7b0f1-9aa6-44a1-9728-d30d3d653405,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-d6672f31-2af8-41e6-8927-ad7661a23492,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-09054076-5ff8-4f4c-9889-19ca9681f289,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-87e79bdf-b814-40df-b01e-4ca253c51b16,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-1895e76f-a68e-49f8-8da6-e1a645f293dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-8dbeae8b-770f-4e93-a6d6-b9e3e9543309,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-94993e43-b268-4055-af4d-39427df79dd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2120116229-172.17.0.4-1597363070819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42533,DS-129fa6f7-b0ed-46cb-a81b-5c5ee14e5f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-eff7b0f1-9aa6-44a1-9728-d30d3d653405,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-d6672f31-2af8-41e6-8927-ad7661a23492,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-09054076-5ff8-4f4c-9889-19ca9681f289,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-87e79bdf-b814-40df-b01e-4ca253c51b16,DISK], DatanodeInfoWithStorage[127.0.0.1:33738,DS-1895e76f-a68e-49f8-8da6-e1a645f293dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-8dbeae8b-770f-4e93-a6d6-b9e3e9543309,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-94993e43-b268-4055-af4d-39427df79dd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1166654971-172.17.0.4-1597363278299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43225,DS-148375e2-cb9e-4dfc-9e93-fd6fe0ee2cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-883e6338-b6dd-4c48-a68f-2a427d2e8e85,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-cdbb2f2f-be48-487b-a4eb-f9a174b65542,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-8cc8e629-8c6b-4f01-a5f5-ee2b7d21719e,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-001f7aa7-50e9-4370-bbb1-ac0dfc89ab05,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-f17f6d07-261f-46e2-9da2-7d6b7fbaa595,DISK], DatanodeInfoWithStorage[127.0.0.1:34771,DS-d05e66db-a29e-4fff-9f2d-f0d22f2f2977,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-d220b2e6-fcae-410e-b6be-b6ed64e37b41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1166654971-172.17.0.4-1597363278299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43225,DS-148375e2-cb9e-4dfc-9e93-fd6fe0ee2cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-883e6338-b6dd-4c48-a68f-2a427d2e8e85,DISK], DatanodeInfoWithStorage[127.0.0.1:46070,DS-cdbb2f2f-be48-487b-a4eb-f9a174b65542,DISK], DatanodeInfoWithStorage[127.0.0.1:35824,DS-8cc8e629-8c6b-4f01-a5f5-ee2b7d21719e,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-001f7aa7-50e9-4370-bbb1-ac0dfc89ab05,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-f17f6d07-261f-46e2-9da2-7d6b7fbaa595,DISK], DatanodeInfoWithStorage[127.0.0.1:34771,DS-d05e66db-a29e-4fff-9f2d-f0d22f2f2977,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-d220b2e6-fcae-410e-b6be-b6ed64e37b41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-679090895-172.17.0.4-1597363490250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36552,DS-d20124fd-719a-4be2-ad11-d2dbc6bdc5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-023b746c-5062-45eb-960b-c7a5f6ce48b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-58c15586-4a35-42d8-8e6e-646c6dd43121,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-783a5f34-544c-4caa-8288-0fade90712df,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-05f4c26f-30ae-4c4b-ad47-7730982f399c,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-aa36f27f-0c39-458d-af7b-64ab06cc24a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-f62ae5dd-2835-4621-a771-c85b03f2664e,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-0c2010cc-ad58-4cb7-bafe-d59ec49538a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-679090895-172.17.0.4-1597363490250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36552,DS-d20124fd-719a-4be2-ad11-d2dbc6bdc5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-023b746c-5062-45eb-960b-c7a5f6ce48b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-58c15586-4a35-42d8-8e6e-646c6dd43121,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-783a5f34-544c-4caa-8288-0fade90712df,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-05f4c26f-30ae-4c4b-ad47-7730982f399c,DISK], DatanodeInfoWithStorage[127.0.0.1:37238,DS-aa36f27f-0c39-458d-af7b-64ab06cc24a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-f62ae5dd-2835-4621-a771-c85b03f2664e,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-0c2010cc-ad58-4cb7-bafe-d59ec49538a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-129388949-172.17.0.4-1597363560518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39524,DS-48c7f467-33a2-4ad0-bf6c-595a52206353,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-6193c26f-e0a4-4523-8a6a-a67a463e1dca,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-faf2e5be-3e86-41e9-88f2-c005d57978e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-5fe58c9d-b2cf-47d0-bf40-e332f7fb0214,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-64e569a7-5aeb-4659-9d2c-e3f07fff23ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-96346712-c91f-4ea8-be17-653d1f859287,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-9109a0ef-f427-499c-b754-2939477eb4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-1d513429-e8fa-4d59-96d2-94dece2f7efe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-129388949-172.17.0.4-1597363560518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39524,DS-48c7f467-33a2-4ad0-bf6c-595a52206353,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-6193c26f-e0a4-4523-8a6a-a67a463e1dca,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-faf2e5be-3e86-41e9-88f2-c005d57978e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-5fe58c9d-b2cf-47d0-bf40-e332f7fb0214,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-64e569a7-5aeb-4659-9d2c-e3f07fff23ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-96346712-c91f-4ea8-be17-653d1f859287,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-9109a0ef-f427-499c-b754-2939477eb4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42024,DS-1d513429-e8fa-4d59-96d2-94dece2f7efe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1816086939-172.17.0.4-1597363780953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38229,DS-fe865799-04ab-43a0-87d0-ce05213a4d32,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-9199ba4d-c98f-4d05-959e-810ec7195bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-c717f6a2-d58a-419e-b3fe-324ffbc0d316,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-0dce5ef5-c594-47c6-b261-fefed83cdc60,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-2e0c5ecd-7604-435d-98c2-6f502b6b8758,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-48923d17-da2b-4b97-8743-379668e46b84,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-7543400c-72b7-4285-90b1-e1b997330870,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-b5e51cc9-90f3-480d-923f-e3c12e3c0277,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1816086939-172.17.0.4-1597363780953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38229,DS-fe865799-04ab-43a0-87d0-ce05213a4d32,DISK], DatanodeInfoWithStorage[127.0.0.1:37542,DS-9199ba4d-c98f-4d05-959e-810ec7195bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:34745,DS-c717f6a2-d58a-419e-b3fe-324ffbc0d316,DISK], DatanodeInfoWithStorage[127.0.0.1:34433,DS-0dce5ef5-c594-47c6-b261-fefed83cdc60,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-2e0c5ecd-7604-435d-98c2-6f502b6b8758,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-48923d17-da2b-4b97-8743-379668e46b84,DISK], DatanodeInfoWithStorage[127.0.0.1:42696,DS-7543400c-72b7-4285-90b1-e1b997330870,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-b5e51cc9-90f3-480d-923f-e3c12e3c0277,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077044258-172.17.0.4-1597363814974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37444,DS-8218cb4e-75cf-4531-9221-e8ac348e735a,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-4a8159d8-8975-4150-88ea-93423616daa0,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-e7f5b03c-aed9-42f4-9b70-2a30ca4b7d57,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-ab0797b0-6f1d-4bb0-85a3-20233df4330d,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-1774dd0d-03b0-42a2-abab-8fcb5e6a0645,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-d568f9cf-f526-4933-8743-4743572ac6d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-44d7d118-066a-452f-8146-79031d41271c,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-d2356fd2-bb67-4fde-957a-d9a0b41a8efa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2077044258-172.17.0.4-1597363814974:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37444,DS-8218cb4e-75cf-4531-9221-e8ac348e735a,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-4a8159d8-8975-4150-88ea-93423616daa0,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-e7f5b03c-aed9-42f4-9b70-2a30ca4b7d57,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-ab0797b0-6f1d-4bb0-85a3-20233df4330d,DISK], DatanodeInfoWithStorage[127.0.0.1:33980,DS-1774dd0d-03b0-42a2-abab-8fcb5e6a0645,DISK], DatanodeInfoWithStorage[127.0.0.1:33424,DS-d568f9cf-f526-4933-8743-4743572ac6d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-44d7d118-066a-452f-8146-79031d41271c,DISK], DatanodeInfoWithStorage[127.0.0.1:37469,DS-d2356fd2-bb67-4fde-957a-d9a0b41a8efa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-332888176-172.17.0.4-1597363908095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40562,DS-b98e8bcc-78c5-4e01-946d-2ac9307c92a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-10fdcc2d-30eb-483f-ad10-23b1068fb002,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-80dcae56-c79b-487f-9789-52eba42df40d,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-c8cb632c-2993-4431-8a9a-40b44c44f96f,DISK], DatanodeInfoWithStorage[127.0.0.1:43148,DS-b21a1dc1-c4f6-40ce-bafa-6f304550e1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-04cef042-08d9-4901-b054-982c0e4df763,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-e6b8d2d4-7d00-4516-9575-5916949aecfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-09a4e327-c25f-45b8-a192-87f788f72d00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-332888176-172.17.0.4-1597363908095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40562,DS-b98e8bcc-78c5-4e01-946d-2ac9307c92a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44487,DS-10fdcc2d-30eb-483f-ad10-23b1068fb002,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-80dcae56-c79b-487f-9789-52eba42df40d,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-c8cb632c-2993-4431-8a9a-40b44c44f96f,DISK], DatanodeInfoWithStorage[127.0.0.1:43148,DS-b21a1dc1-c4f6-40ce-bafa-6f304550e1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-04cef042-08d9-4901-b054-982c0e4df763,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-e6b8d2d4-7d00-4516-9575-5916949aecfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-09a4e327-c25f-45b8-a192-87f788f72d00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2031040337-172.17.0.4-1597364073860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38681,DS-6547cb2c-337d-4d20-90e7-9459fa060a36,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-e53980d0-747a-4955-a77a-fedb0faf8dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-8b73dcd3-ee24-4c74-8bdd-e537a6a0efb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34870,DS-3562c11c-86bc-48d5-8cc0-315c43a2db73,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-6650fe6b-7568-4e30-a8fc-c16c9065d04b,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-a07ac9e1-fe60-427c-b978-2d210edbc70e,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-6cdd6d92-6a83-4b37-882d-157369c58108,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-97a98c58-dea6-4237-9b6f-f7d9a888114a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2031040337-172.17.0.4-1597364073860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38681,DS-6547cb2c-337d-4d20-90e7-9459fa060a36,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-e53980d0-747a-4955-a77a-fedb0faf8dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-8b73dcd3-ee24-4c74-8bdd-e537a6a0efb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34870,DS-3562c11c-86bc-48d5-8cc0-315c43a2db73,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-6650fe6b-7568-4e30-a8fc-c16c9065d04b,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-a07ac9e1-fe60-427c-b978-2d210edbc70e,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-6cdd6d92-6a83-4b37-882d-157369c58108,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-97a98c58-dea6-4237-9b6f-f7d9a888114a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-140127336-172.17.0.4-1597364505674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40011,DS-6ad314cb-723f-4b99-8912-dbccd1bc072b,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-a15440ce-b86e-4d31-8101-293fafaca137,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-b1c73a75-e7ed-430f-83f3-79a5663036a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-316e1f85-0edf-4099-9c75-b4d671ac9da9,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-f39be986-5cdb-4231-b5b9-43d6ea9fe445,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-1405f7d1-3ab4-4cb9-a7c0-5af511ce10b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-926b6218-8f6f-4ea6-bf77-12b3561339b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-81ab1a8a-51e3-40d3-98d5-daed167eea3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-140127336-172.17.0.4-1597364505674:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40011,DS-6ad314cb-723f-4b99-8912-dbccd1bc072b,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-a15440ce-b86e-4d31-8101-293fafaca137,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-b1c73a75-e7ed-430f-83f3-79a5663036a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41538,DS-316e1f85-0edf-4099-9c75-b4d671ac9da9,DISK], DatanodeInfoWithStorage[127.0.0.1:43355,DS-f39be986-5cdb-4231-b5b9-43d6ea9fe445,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-1405f7d1-3ab4-4cb9-a7c0-5af511ce10b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-926b6218-8f6f-4ea6-bf77-12b3561339b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-81ab1a8a-51e3-40d3-98d5-daed167eea3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1446409012-172.17.0.4-1597364882813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34772,DS-a6b0362f-67af-4cc4-a801-8c40f66585f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-f5cf6f9b-8683-4c29-a417-69b6e50219bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-7b995ce9-805f-4a73-b193-4ed9cfc9e225,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-748e0d96-33f8-4adf-879b-0aa3eea7099b,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-b164c1bb-d22b-42e9-937b-36b520179d44,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-48518482-c3b7-4666-b79e-cd687c8fbaec,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-3f255644-54ab-49f6-93f0-1770d29617a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-a22393f6-f30f-4c9d-9ffd-dd754e69d307,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1446409012-172.17.0.4-1597364882813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34772,DS-a6b0362f-67af-4cc4-a801-8c40f66585f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-f5cf6f9b-8683-4c29-a417-69b6e50219bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-7b995ce9-805f-4a73-b193-4ed9cfc9e225,DISK], DatanodeInfoWithStorage[127.0.0.1:33742,DS-748e0d96-33f8-4adf-879b-0aa3eea7099b,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-b164c1bb-d22b-42e9-937b-36b520179d44,DISK], DatanodeInfoWithStorage[127.0.0.1:33320,DS-48518482-c3b7-4666-b79e-cd687c8fbaec,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-3f255644-54ab-49f6-93f0-1770d29617a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-a22393f6-f30f-4c9d-9ffd-dd754e69d307,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-615478547-172.17.0.4-1597364996433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35861,DS-1e937bd3-e46b-4146-bca3-a1ca2577f556,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-670c78e2-0c94-4ecd-8d62-8de2696d68d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-a6aac204-7ba3-4e68-82cd-ddc51a3e6880,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-f22d8882-91ea-42b0-9d2f-434c9522bd45,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-dbb611cd-f54c-4f91-8092-910f77629ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-9025fc32-e90d-4db2-83bb-61a73573bc8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-b1dee2ee-6ff6-4834-8b85-3b973de6f7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-23517346-7db5-45da-aba2-5368b5be912f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-615478547-172.17.0.4-1597364996433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35861,DS-1e937bd3-e46b-4146-bca3-a1ca2577f556,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-670c78e2-0c94-4ecd-8d62-8de2696d68d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45065,DS-a6aac204-7ba3-4e68-82cd-ddc51a3e6880,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-f22d8882-91ea-42b0-9d2f-434c9522bd45,DISK], DatanodeInfoWithStorage[127.0.0.1:42037,DS-dbb611cd-f54c-4f91-8092-910f77629ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-9025fc32-e90d-4db2-83bb-61a73573bc8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34143,DS-b1dee2ee-6ff6-4834-8b85-3b973de6f7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43103,DS-23517346-7db5-45da-aba2-5368b5be912f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-345658735-172.17.0.4-1597365101822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43222,DS-8c8f39ac-f0ae-49af-9c99-3f568dffbddf,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-2c168ebc-cdf5-4f03-9537-b8bb39740717,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-c447def2-665a-4ee7-a248-a5ff3760b268,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-715ee890-6e66-4c1b-9c73-e741f4c86274,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-07b0bb98-3bf5-4aba-8942-f179564aca71,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-4a4ee6d4-7810-4d19-807f-97f7e89a5570,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-7df1fc56-5c09-4283-accf-0adf9118257c,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-f94c13fd-6126-48b9-9e0f-12f6749ba15e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-345658735-172.17.0.4-1597365101822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43222,DS-8c8f39ac-f0ae-49af-9c99-3f568dffbddf,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-2c168ebc-cdf5-4f03-9537-b8bb39740717,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-c447def2-665a-4ee7-a248-a5ff3760b268,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-715ee890-6e66-4c1b-9c73-e741f4c86274,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-07b0bb98-3bf5-4aba-8942-f179564aca71,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-4a4ee6d4-7810-4d19-807f-97f7e89a5570,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-7df1fc56-5c09-4283-accf-0adf9118257c,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-f94c13fd-6126-48b9-9e0f-12f6749ba15e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648708140-172.17.0.4-1597365211163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36267,DS-2934c8c5-c3ba-408d-8aa7-740c3dc874c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-724f1eaa-d283-4d02-9913-d9728017d215,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-42d07de7-7021-4c89-b806-1becb8eacce7,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-0dc0e290-829c-4f6a-83b1-4d32a9b2b0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-c582ceda-4822-4868-9603-bbfe495f9ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-ba07714b-f371-4ab6-b79f-9e86247415c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-b622f07c-fea1-4b9d-91ee-56243ecdaf69,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-77ee983d-469e-47c0-b4ce-201a2538dde3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648708140-172.17.0.4-1597365211163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36267,DS-2934c8c5-c3ba-408d-8aa7-740c3dc874c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-724f1eaa-d283-4d02-9913-d9728017d215,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-42d07de7-7021-4c89-b806-1becb8eacce7,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-0dc0e290-829c-4f6a-83b1-4d32a9b2b0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-c582ceda-4822-4868-9603-bbfe495f9ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-ba07714b-f371-4ab6-b79f-9e86247415c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-b622f07c-fea1-4b9d-91ee-56243ecdaf69,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-77ee983d-469e-47c0-b4ce-201a2538dde3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614291299-172.17.0.4-1597366146948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37924,DS-be992b5e-fb03-44b4-8013-f5aa62d053fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-328bd898-af97-45ca-9b7a-5565bc036baa,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-8799d3d3-a605-4099-87ee-3aa4d9a72c83,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-92fc7bb5-0caa-4964-92d3-009ed699f664,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-03d9e05b-ef7a-478b-ac5d-47c0a07aca7b,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-7288bd1c-e2aa-446d-993a-35f8f1f71eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-12525d80-7263-4273-90fd-bb771cdd1bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-03797a0a-dcde-4021-a313-2f1fbe58a89e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614291299-172.17.0.4-1597366146948:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37924,DS-be992b5e-fb03-44b4-8013-f5aa62d053fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-328bd898-af97-45ca-9b7a-5565bc036baa,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-8799d3d3-a605-4099-87ee-3aa4d9a72c83,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-92fc7bb5-0caa-4964-92d3-009ed699f664,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-03d9e05b-ef7a-478b-ac5d-47c0a07aca7b,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-7288bd1c-e2aa-446d-993a-35f8f1f71eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-12525d80-7263-4273-90fd-bb771cdd1bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-03797a0a-dcde-4021-a313-2f1fbe58a89e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1751996481-172.17.0.4-1597366184091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46471,DS-7555d796-7301-40f1-aee8-fa95015cb151,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-ee83fb7c-1a9f-49c8-8f9f-bd07b6594a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-9ef3db59-a5a4-4406-8c8a-c8beb5e1beb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-b5dde51d-354c-4fa6-9936-e5bc5676f683,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-1fd79f5d-4fa5-481a-87ba-29c9c5112ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-53f0772b-8aea-45bc-b331-190c596cb287,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-7e4d8768-71a6-41b0-9d4f-4f9ca7017783,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-d10b72b7-2a80-48ae-b6f8-31be747448a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1751996481-172.17.0.4-1597366184091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46471,DS-7555d796-7301-40f1-aee8-fa95015cb151,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-ee83fb7c-1a9f-49c8-8f9f-bd07b6594a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-9ef3db59-a5a4-4406-8c8a-c8beb5e1beb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-b5dde51d-354c-4fa6-9936-e5bc5676f683,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-1fd79f5d-4fa5-481a-87ba-29c9c5112ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-53f0772b-8aea-45bc-b331-190c596cb287,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-7e4d8768-71a6-41b0-9d4f-4f9ca7017783,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-d10b72b7-2a80-48ae-b6f8-31be747448a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-808486042-172.17.0.4-1597366332299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34178,DS-c83459b9-ffe2-4084-9d9e-feca8f884323,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-04385ed8-789e-4f77-a628-d4ce8e262228,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-a4f43a38-0be1-426c-a7a0-83be4175932e,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-6d1d91e4-04c6-4801-8573-261cb565022d,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-44e97aeb-2966-4457-80f8-fd769c853533,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-b12420cc-de39-4d1b-a27d-772ea2fc0fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-e2e946cb-9e70-41db-a5e4-c019422f5013,DISK], DatanodeInfoWithStorage[127.0.0.1:37626,DS-c5637dcc-7b86-4ea0-b70d-cad6b1531c47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-808486042-172.17.0.4-1597366332299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34178,DS-c83459b9-ffe2-4084-9d9e-feca8f884323,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-04385ed8-789e-4f77-a628-d4ce8e262228,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-a4f43a38-0be1-426c-a7a0-83be4175932e,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-6d1d91e4-04c6-4801-8573-261cb565022d,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-44e97aeb-2966-4457-80f8-fd769c853533,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-b12420cc-de39-4d1b-a27d-772ea2fc0fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-e2e946cb-9e70-41db-a5e4-c019422f5013,DISK], DatanodeInfoWithStorage[127.0.0.1:37626,DS-c5637dcc-7b86-4ea0-b70d-cad6b1531c47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1446558096-172.17.0.4-1597367333854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36036,DS-8c193034-ad1c-4a8d-9faf-51fec8e34d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-8fd05303-183e-451e-a282-1cd25c7da580,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-5ba55c02-30ba-4ea4-a471-0eca8477d878,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-e7d77b2f-83b5-471b-baee-c33af0fe1a03,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-67b2a73c-c052-4ffc-813c-cc8fcbf9d7af,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-1deb53f6-e6ba-4f27-9440-dd41da119d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-f852415a-859b-48bc-a1ac-7dd6859985fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-82406068-57c1-419a-85db-0265ffc866a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1446558096-172.17.0.4-1597367333854:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36036,DS-8c193034-ad1c-4a8d-9faf-51fec8e34d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-8fd05303-183e-451e-a282-1cd25c7da580,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-5ba55c02-30ba-4ea4-a471-0eca8477d878,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-e7d77b2f-83b5-471b-baee-c33af0fe1a03,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-67b2a73c-c052-4ffc-813c-cc8fcbf9d7af,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-1deb53f6-e6ba-4f27-9440-dd41da119d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-f852415a-859b-48bc-a1ac-7dd6859985fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-82406068-57c1-419a-85db-0265ffc866a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1067958106-172.17.0.4-1597367695337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36659,DS-119a8ce3-0316-4001-be71-e7d32eff91de,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-87cf0200-63df-4a05-b6fc-c952cbe22bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-cf844e61-1f76-4ca3-b136-16d6ea5b1236,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-c2719595-52ab-4099-83ec-d357c46d06d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-f5b3db5b-be58-454a-86cb-2edb23a4fcfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-e80109ec-22b3-4ff2-8258-13ca5cb2c68a,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-be55a299-4ff6-4f20-a7e0-20546afa9633,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-1f323f8d-484e-4930-a141-a268a662297f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1067958106-172.17.0.4-1597367695337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36659,DS-119a8ce3-0316-4001-be71-e7d32eff91de,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-87cf0200-63df-4a05-b6fc-c952cbe22bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39669,DS-cf844e61-1f76-4ca3-b136-16d6ea5b1236,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-c2719595-52ab-4099-83ec-d357c46d06d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45231,DS-f5b3db5b-be58-454a-86cb-2edb23a4fcfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-e80109ec-22b3-4ff2-8258-13ca5cb2c68a,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-be55a299-4ff6-4f20-a7e0-20546afa9633,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-1f323f8d-484e-4930-a141-a268a662297f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1024
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1103913983-172.17.0.4-1597368254937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42783,DS-f0879deb-7552-4b18-8964-7ff2fc9760cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-bc764087-d884-43b6-983c-52cd4047b1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-633685b1-494b-4751-b948-d68201fd9c07,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-e12dfc0d-3914-4c93-8da8-59af3b66c426,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-5abd183a-614c-4b83-9c79-3a9fd1c8c17c,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-d28a816e-20d0-4d35-be3a-d37efa0aded7,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-25cbdb6c-9341-419b-bc33-667956d39a43,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-110999de-b332-4ac3-a071-b404ef015140,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1103913983-172.17.0.4-1597368254937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42783,DS-f0879deb-7552-4b18-8964-7ff2fc9760cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-bc764087-d884-43b6-983c-52cd4047b1d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-633685b1-494b-4751-b948-d68201fd9c07,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-e12dfc0d-3914-4c93-8da8-59af3b66c426,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-5abd183a-614c-4b83-9c79-3a9fd1c8c17c,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-d28a816e-20d0-4d35-be3a-d37efa0aded7,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-25cbdb6c-9341-419b-bc33-667956d39a43,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-110999de-b332-4ac3-a071-b404ef015140,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5444
