reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-97606856-172.17.0.8-1597298862466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38746,DS-921bc619-996f-4bdf-93b7-aaa3bc6f1813,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-acbd6137-292f-428e-b5ec-6e888193a7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-f8edb52d-5e3c-4b85-9826-360b48f6509d,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-003b5b4c-25ae-4bbe-82a4-fe8463a1c427,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-98bfe316-d527-4af5-ae34-dd8718a26b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-5776090a-1c37-429b-8329-d40a14b0c657,DISK], DatanodeInfoWithStorage[127.0.0.1:39716,DS-48dafa60-e5a7-4f57-948e-c83abdb78ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-fdddc9cd-5a91-4680-8acb-4746aeaba6da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-97606856-172.17.0.8-1597298862466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38746,DS-921bc619-996f-4bdf-93b7-aaa3bc6f1813,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-acbd6137-292f-428e-b5ec-6e888193a7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42027,DS-f8edb52d-5e3c-4b85-9826-360b48f6509d,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-003b5b4c-25ae-4bbe-82a4-fe8463a1c427,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-98bfe316-d527-4af5-ae34-dd8718a26b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:40521,DS-5776090a-1c37-429b-8329-d40a14b0c657,DISK], DatanodeInfoWithStorage[127.0.0.1:39716,DS-48dafa60-e5a7-4f57-948e-c83abdb78ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-fdddc9cd-5a91-4680-8acb-4746aeaba6da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1272167311-172.17.0.8-1597298932464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46114,DS-20a8f6f2-f7ac-4416-9804-cda4a050822f,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-0bf2ed99-22dd-4205-87e0-ac76b5ff5f13,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-39e90fd2-c8c8-498b-996a-c84a9c837f99,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-34bac4e1-eefe-423e-b1ee-8c91399e05df,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-5d62ddb7-0a29-4496-80ac-81f5d551b8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-a8cac6c4-71ce-4438-b01d-b66fb29dfdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-c8d6da54-cc15-40fb-b213-53706524d727,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-e083e10f-ee79-42f3-b075-bc88942b883d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1272167311-172.17.0.8-1597298932464:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46114,DS-20a8f6f2-f7ac-4416-9804-cda4a050822f,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-0bf2ed99-22dd-4205-87e0-ac76b5ff5f13,DISK], DatanodeInfoWithStorage[127.0.0.1:35753,DS-39e90fd2-c8c8-498b-996a-c84a9c837f99,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-34bac4e1-eefe-423e-b1ee-8c91399e05df,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-5d62ddb7-0a29-4496-80ac-81f5d551b8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-a8cac6c4-71ce-4438-b01d-b66fb29dfdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-c8d6da54-cc15-40fb-b213-53706524d727,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-e083e10f-ee79-42f3-b075-bc88942b883d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2014893158-172.17.0.8-1597299329031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37944,DS-6d824b74-9a53-4406-9c1e-9370428c6741,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-07d29f5d-3590-42db-a96a-e55cff531ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-21ac650c-3ad9-49de-99bb-f57b28ddebb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35883,DS-454767d2-2223-4ae6-8490-2e44ba9e5414,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-f3ecb6ae-5665-489d-82a2-ac1c8bb4c853,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-2bf8d8b9-fdfe-4773-94c3-223e112d952d,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-af8c16c8-fa8f-4ecb-8584-a775c8ea4d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-c1169d87-3926-4f13-90fa-0b3d66cace51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2014893158-172.17.0.8-1597299329031:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37944,DS-6d824b74-9a53-4406-9c1e-9370428c6741,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-07d29f5d-3590-42db-a96a-e55cff531ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-21ac650c-3ad9-49de-99bb-f57b28ddebb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35883,DS-454767d2-2223-4ae6-8490-2e44ba9e5414,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-f3ecb6ae-5665-489d-82a2-ac1c8bb4c853,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-2bf8d8b9-fdfe-4773-94c3-223e112d952d,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-af8c16c8-fa8f-4ecb-8584-a775c8ea4d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45272,DS-c1169d87-3926-4f13-90fa-0b3d66cace51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1553063125-172.17.0.8-1597299482728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38779,DS-25c106b4-b129-4bee-be7e-068d4bc74b00,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-e96d52a9-9cad-4153-8493-4b242ddc0051,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-424d8e03-d509-419f-9a0f-1c83d04dffaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-52bcf477-6272-40b0-985e-fa87c463d43b,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-e1cd87b2-ca7d-4a6f-a44a-96f8cef91fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-1931fad0-2d48-44e4-aa6a-e751a532bded,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-425a1197-4f3b-4cf0-abde-087cba04ed5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-9c618904-5dad-44b2-b363-c13de96929b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1553063125-172.17.0.8-1597299482728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38779,DS-25c106b4-b129-4bee-be7e-068d4bc74b00,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-e96d52a9-9cad-4153-8493-4b242ddc0051,DISK], DatanodeInfoWithStorage[127.0.0.1:35668,DS-424d8e03-d509-419f-9a0f-1c83d04dffaf,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-52bcf477-6272-40b0-985e-fa87c463d43b,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-e1cd87b2-ca7d-4a6f-a44a-96f8cef91fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-1931fad0-2d48-44e4-aa6a-e751a532bded,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-425a1197-4f3b-4cf0-abde-087cba04ed5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-9c618904-5dad-44b2-b363-c13de96929b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1348583067-172.17.0.8-1597299973818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45858,DS-e143de20-3645-4f94-8ea3-8fa5cc75f954,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-61884242-02b1-448c-9fcb-281ac9f56aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-8f9cc98f-672c-4ae5-9482-5b1fe4b9fc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-afcdf979-714f-495a-ad04-1677cd46f848,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-14bc4f53-b45c-4c1c-badb-fc3e149e5ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-7200adba-9a18-4685-a46d-6ee7d77c0a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-7fa8bf7e-7748-4b5a-a706-94b27aaa80f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-4831030c-b008-431f-b9c4-621e16771dd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1348583067-172.17.0.8-1597299973818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45858,DS-e143de20-3645-4f94-8ea3-8fa5cc75f954,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-61884242-02b1-448c-9fcb-281ac9f56aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-8f9cc98f-672c-4ae5-9482-5b1fe4b9fc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42438,DS-afcdf979-714f-495a-ad04-1677cd46f848,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-14bc4f53-b45c-4c1c-badb-fc3e149e5ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:40373,DS-7200adba-9a18-4685-a46d-6ee7d77c0a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-7fa8bf7e-7748-4b5a-a706-94b27aaa80f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-4831030c-b008-431f-b9c4-621e16771dd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-581189968-172.17.0.8-1597300090001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46370,DS-c0a5f668-4b62-45d9-84e7-00b842ec0a89,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-07994f01-5196-4f43-aba4-7456a1f3dfb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-85e7b912-b9d3-455d-b0a0-f12188a6e17d,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-9dbe2243-032f-4cad-9717-28ec44aae5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-075c5bcc-f217-4808-8f42-b1a32ea6431b,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-12211ad9-dc9c-4983-a985-4b74ed51ec3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-d86a7c47-31cd-4826-9758-4c59f15fa00c,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-7c1cd2f5-ac08-417d-8e31-e19a5ebfc46f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-581189968-172.17.0.8-1597300090001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46370,DS-c0a5f668-4b62-45d9-84e7-00b842ec0a89,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-07994f01-5196-4f43-aba4-7456a1f3dfb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43788,DS-85e7b912-b9d3-455d-b0a0-f12188a6e17d,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-9dbe2243-032f-4cad-9717-28ec44aae5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-075c5bcc-f217-4808-8f42-b1a32ea6431b,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-12211ad9-dc9c-4983-a985-4b74ed51ec3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35909,DS-d86a7c47-31cd-4826-9758-4c59f15fa00c,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-7c1cd2f5-ac08-417d-8e31-e19a5ebfc46f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1721749120-172.17.0.8-1597300166090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37072,DS-6e84e09c-a315-42b2-9adb-962fece08968,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-9174b0b1-b3b3-4ecb-a6c2-c96581d9debb,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-801c5449-c477-4e8b-a328-4380e873efb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-144abcdf-5b19-4486-8ffd-51aa50deaf1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-dfc861a2-85d3-4e64-834c-bb9049b0634d,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-6392d7ab-96e3-4434-906f-4cba920699b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-936d928e-67f2-4d30-839e-2de671a1a99e,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-ecdd2936-3bf2-4179-b152-56c1da5d0a42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1721749120-172.17.0.8-1597300166090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37072,DS-6e84e09c-a315-42b2-9adb-962fece08968,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-9174b0b1-b3b3-4ecb-a6c2-c96581d9debb,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-801c5449-c477-4e8b-a328-4380e873efb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-144abcdf-5b19-4486-8ffd-51aa50deaf1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34984,DS-dfc861a2-85d3-4e64-834c-bb9049b0634d,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-6392d7ab-96e3-4434-906f-4cba920699b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-936d928e-67f2-4d30-839e-2de671a1a99e,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-ecdd2936-3bf2-4179-b152-56c1da5d0a42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-726128665-172.17.0.8-1597300203027:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40653,DS-037272af-828a-4636-b29c-bc6fd0f1624d,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-d76e6fc6-a7db-492d-82b6-87f2ac1921b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-e77ca617-2b99-403b-8569-6412c2eaab37,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-9b314d85-1643-4fa2-bf4c-dee1b66a5c35,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-176cd57a-3027-48fd-8523-986e4b18930f,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-1f55b3ff-c89a-4e4b-a36f-de00546d5a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-62d21766-5063-49b8-9004-92bb0cdef065,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-15798f80-db25-42b1-87ff-6776709bfc52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-726128665-172.17.0.8-1597300203027:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40653,DS-037272af-828a-4636-b29c-bc6fd0f1624d,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-d76e6fc6-a7db-492d-82b6-87f2ac1921b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-e77ca617-2b99-403b-8569-6412c2eaab37,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-9b314d85-1643-4fa2-bf4c-dee1b66a5c35,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-176cd57a-3027-48fd-8523-986e4b18930f,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-1f55b3ff-c89a-4e4b-a36f-de00546d5a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-62d21766-5063-49b8-9004-92bb0cdef065,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-15798f80-db25-42b1-87ff-6776709bfc52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1821521073-172.17.0.8-1597300275137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38823,DS-2bd5c47e-ba0b-46b3-8647-252d4d1a517c,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-891d6e9f-ccc4-4ef1-8283-5568ec7eefb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43352,DS-c3348275-6dd1-4127-8e54-1560956cc3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40077,DS-7ed25d19-dd78-403e-9755-a519302e3397,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-bcb043cb-c1d1-4fee-9c5d-b85b564f540a,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-b7943022-bfdc-4967-8629-909c0928afc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-e404c934-4677-46e2-98c2-52672565e457,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-96e51414-c09b-4164-bf29-0728237f23fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1821521073-172.17.0.8-1597300275137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38823,DS-2bd5c47e-ba0b-46b3-8647-252d4d1a517c,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-891d6e9f-ccc4-4ef1-8283-5568ec7eefb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43352,DS-c3348275-6dd1-4127-8e54-1560956cc3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40077,DS-7ed25d19-dd78-403e-9755-a519302e3397,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-bcb043cb-c1d1-4fee-9c5d-b85b564f540a,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-b7943022-bfdc-4967-8629-909c0928afc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-e404c934-4677-46e2-98c2-52672565e457,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-96e51414-c09b-4164-bf29-0728237f23fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-430091003-172.17.0.8-1597300716645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32965,DS-1571c87c-019a-4f92-a00e-b49ec9831f43,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-616bd807-0036-4c62-9cdc-bc30ac4cc812,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-6aaa92f3-0fc0-4a9a-af5e-fbbdc36df956,DISK], DatanodeInfoWithStorage[127.0.0.1:40388,DS-d37306c2-4044-4776-9a9f-59d5c2d0e264,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-c787c085-b9e1-49b5-b754-fa0147c29a05,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-18c3adb5-7fd9-4158-9192-b8fd2e652aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-4d87776e-2c46-4e43-a107-e4576cc88c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-82ddd4c4-205a-4349-899e-d8cdfa44b9d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-430091003-172.17.0.8-1597300716645:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32965,DS-1571c87c-019a-4f92-a00e-b49ec9831f43,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-616bd807-0036-4c62-9cdc-bc30ac4cc812,DISK], DatanodeInfoWithStorage[127.0.0.1:35367,DS-6aaa92f3-0fc0-4a9a-af5e-fbbdc36df956,DISK], DatanodeInfoWithStorage[127.0.0.1:40388,DS-d37306c2-4044-4776-9a9f-59d5c2d0e264,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-c787c085-b9e1-49b5-b754-fa0147c29a05,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-18c3adb5-7fd9-4158-9192-b8fd2e652aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-4d87776e-2c46-4e43-a107-e4576cc88c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-82ddd4c4-205a-4349-899e-d8cdfa44b9d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1281204480-172.17.0.8-1597301625439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45985,DS-fc452fca-56c0-4521-9710-dc86c8009db4,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-addc8e54-aea2-4681-ab1c-81d2e47d0f03,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-2d45770f-5774-47e9-a0c7-734be819390e,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-ff2f5c99-2b9c-4609-b210-03bf67e48e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-f46148cb-c07b-439e-a7e2-ccdbbaddbdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-c8e90b63-4d8d-4dc6-96d8-023a904cb0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-0711385f-8566-4504-8ede-bdd200e2c6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-f21a9f59-ed67-49a9-9703-15a9b8380400,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1281204480-172.17.0.8-1597301625439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45985,DS-fc452fca-56c0-4521-9710-dc86c8009db4,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-addc8e54-aea2-4681-ab1c-81d2e47d0f03,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-2d45770f-5774-47e9-a0c7-734be819390e,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-ff2f5c99-2b9c-4609-b210-03bf67e48e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-f46148cb-c07b-439e-a7e2-ccdbbaddbdd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38395,DS-c8e90b63-4d8d-4dc6-96d8-023a904cb0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-0711385f-8566-4504-8ede-bdd200e2c6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39354,DS-f21a9f59-ed67-49a9-9703-15a9b8380400,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2064316519-172.17.0.8-1597302995331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41130,DS-8aef7d01-5d28-4b12-9fb2-b3cf62c82704,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-696d3b50-a6cd-4313-9e85-0e9131b4baf3,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-c959e71a-5138-4f79-8ca0-09202ea64366,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-5c093b6c-b71a-4af1-b027-e49f7cfd8c13,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-7902e06d-3b98-4f05-9175-46a30b61ff48,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-b63f8b7b-a863-4343-be6c-ad1a46c68e14,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-753f7400-8870-468d-97ac-927cb3326d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-c8ac6c62-ac2b-4a10-9831-89cc97b63574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2064316519-172.17.0.8-1597302995331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41130,DS-8aef7d01-5d28-4b12-9fb2-b3cf62c82704,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-696d3b50-a6cd-4313-9e85-0e9131b4baf3,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-c959e71a-5138-4f79-8ca0-09202ea64366,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-5c093b6c-b71a-4af1-b027-e49f7cfd8c13,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-7902e06d-3b98-4f05-9175-46a30b61ff48,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-b63f8b7b-a863-4343-be6c-ad1a46c68e14,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-753f7400-8870-468d-97ac-927cb3326d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-c8ac6c62-ac2b-4a10-9831-89cc97b63574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2019647193-172.17.0.8-1597303031085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43386,DS-1d01ba82-b54a-4fdc-b4de-f4cb64b61c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-e780b1e5-75d2-402d-81a6-1797a33a985b,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-98cca0bd-12ff-4b8d-8415-228518683b25,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-0176fdab-c517-4c76-9ae0-9851f104c0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-18bcaee3-52b2-40fd-87ad-0ae402e0dbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43671,DS-d077315c-173f-4deb-832c-188e53b072a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-0ef4254f-83e2-480b-b589-524b7ea19d40,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-e3e4f057-13bd-4880-b93e-182ed198c663,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2019647193-172.17.0.8-1597303031085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43386,DS-1d01ba82-b54a-4fdc-b4de-f4cb64b61c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-e780b1e5-75d2-402d-81a6-1797a33a985b,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-98cca0bd-12ff-4b8d-8415-228518683b25,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-0176fdab-c517-4c76-9ae0-9851f104c0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-18bcaee3-52b2-40fd-87ad-0ae402e0dbd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43671,DS-d077315c-173f-4deb-832c-188e53b072a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-0ef4254f-83e2-480b-b589-524b7ea19d40,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-e3e4f057-13bd-4880-b93e-182ed198c663,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-787176436-172.17.0.8-1597303250458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45344,DS-28f4989f-2cf8-437c-8ee6-51e4ff82bf93,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-b1aa5628-2339-436f-b775-a1a630c25066,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-dd663b4f-de59-491c-a86d-cadd91b09ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-4d7244f3-6663-4129-b477-5b5fd2cf04e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-98147986-8bb7-4f5d-bc11-262a6f92bc31,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-9257be58-c5c2-4491-85fa-a2fd3002c8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-c08c1523-7998-4d5b-b461-f992d366a202,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-6652f173-2ad9-4fee-98c2-cbaebab06acc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-787176436-172.17.0.8-1597303250458:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45344,DS-28f4989f-2cf8-437c-8ee6-51e4ff82bf93,DISK], DatanodeInfoWithStorage[127.0.0.1:33163,DS-b1aa5628-2339-436f-b775-a1a630c25066,DISK], DatanodeInfoWithStorage[127.0.0.1:36677,DS-dd663b4f-de59-491c-a86d-cadd91b09ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-4d7244f3-6663-4129-b477-5b5fd2cf04e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-98147986-8bb7-4f5d-bc11-262a6f92bc31,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-9257be58-c5c2-4491-85fa-a2fd3002c8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-c08c1523-7998-4d5b-b461-f992d366a202,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-6652f173-2ad9-4fee-98c2-cbaebab06acc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1613224352-172.17.0.8-1597303580356:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40878,DS-d1ecf7e2-da20-4d59-bfc2-53fcefe68b65,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-661745bc-ee61-486d-8d15-e4d019d3f285,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-22e186fd-e5ea-4ae2-8cf4-2883aaa99815,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-efdcccb2-3c48-4924-ab79-cf26d83a7aea,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-92a629cc-68ca-4628-a340-f10d17267abb,DISK], DatanodeInfoWithStorage[127.0.0.1:43207,DS-ec82f0d1-8a2d-4860-bc87-a0577020a983,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-18655cce-2b48-44ce-89b7-ed9d217fda79,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-919682be-bf94-48a9-9aef-dfbe6f355cf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1613224352-172.17.0.8-1597303580356:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40878,DS-d1ecf7e2-da20-4d59-bfc2-53fcefe68b65,DISK], DatanodeInfoWithStorage[127.0.0.1:45168,DS-661745bc-ee61-486d-8d15-e4d019d3f285,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-22e186fd-e5ea-4ae2-8cf4-2883aaa99815,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-efdcccb2-3c48-4924-ab79-cf26d83a7aea,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-92a629cc-68ca-4628-a340-f10d17267abb,DISK], DatanodeInfoWithStorage[127.0.0.1:43207,DS-ec82f0d1-8a2d-4860-bc87-a0577020a983,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-18655cce-2b48-44ce-89b7-ed9d217fda79,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-919682be-bf94-48a9-9aef-dfbe6f355cf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2032842343-172.17.0.8-1597303702461:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39044,DS-741cf9de-5a56-4fc6-b016-8a75eb62e2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-cca8a300-88f6-4619-a3aa-9b78db59baf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-e28e4294-467a-4f06-9d4c-61bddd6f6da8,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-99fcf3e3-583d-4983-9628-e1afebce49f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-3661b233-9a79-4369-bdfc-6554ee4ce4be,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-134d54a7-46de-41c7-9068-551061535102,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-f2a5e9e2-cd20-4865-a0e1-d92e5a1bd7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-e699fc45-4984-4524-9dcd-67ec2aa60aa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2032842343-172.17.0.8-1597303702461:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39044,DS-741cf9de-5a56-4fc6-b016-8a75eb62e2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-cca8a300-88f6-4619-a3aa-9b78db59baf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-e28e4294-467a-4f06-9d4c-61bddd6f6da8,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-99fcf3e3-583d-4983-9628-e1afebce49f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-3661b233-9a79-4369-bdfc-6554ee4ce4be,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-134d54a7-46de-41c7-9068-551061535102,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-f2a5e9e2-cd20-4865-a0e1-d92e5a1bd7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-e699fc45-4984-4524-9dcd-67ec2aa60aa2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1761160522-172.17.0.8-1597303766449:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37533,DS-04dd4574-dec5-40ee-85e1-cff6449413f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-ff74cfb7-ecf1-4c9c-82bd-e4665dfdd07b,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-557ad4c8-b5fb-4136-b534-105ed0c09ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-b239dfeb-2878-40b3-9efb-d20cf440f969,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-2d7a2025-43b0-42d2-b553-30cccf818e52,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-42cd7392-8a65-4a85-a346-2013b5f43a22,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-bc263711-f168-474e-8881-6218a0f50cec,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-da891c38-b3ae-4dc2-a7a0-b57a2a572577,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1761160522-172.17.0.8-1597303766449:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37533,DS-04dd4574-dec5-40ee-85e1-cff6449413f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-ff74cfb7-ecf1-4c9c-82bd-e4665dfdd07b,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-557ad4c8-b5fb-4136-b534-105ed0c09ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-b239dfeb-2878-40b3-9efb-d20cf440f969,DISK], DatanodeInfoWithStorage[127.0.0.1:46757,DS-2d7a2025-43b0-42d2-b553-30cccf818e52,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-42cd7392-8a65-4a85-a346-2013b5f43a22,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-bc263711-f168-474e-8881-6218a0f50cec,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-da891c38-b3ae-4dc2-a7a0-b57a2a572577,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 1
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1774646314-172.17.0.8-1597304207703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38639,DS-71cbe33e-c941-4855-8c43-a4f70aca3bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-bc10bf7c-10dc-429d-b0aa-3dee1e453801,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-6e013d52-0172-471d-ac16-b03664775137,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-783f0ffb-9271-4ced-b196-3e450ff2b9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-d1232a57-ee0a-4066-91b9-c7b2cefc660a,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-532156d3-6a26-4aaf-9d1d-0068008a7c22,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-cbd2f903-6f68-4fa5-a823-656cae4c6770,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-94a73678-84df-4033-ac9f-d27c12df779d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1774646314-172.17.0.8-1597304207703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38639,DS-71cbe33e-c941-4855-8c43-a4f70aca3bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:38838,DS-bc10bf7c-10dc-429d-b0aa-3dee1e453801,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-6e013d52-0172-471d-ac16-b03664775137,DISK], DatanodeInfoWithStorage[127.0.0.1:45181,DS-783f0ffb-9271-4ced-b196-3e450ff2b9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-d1232a57-ee0a-4066-91b9-c7b2cefc660a,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-532156d3-6a26-4aaf-9d1d-0068008a7c22,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-cbd2f903-6f68-4fa5-a823-656cae4c6770,DISK], DatanodeInfoWithStorage[127.0.0.1:45046,DS-94a73678-84df-4033-ac9f-d27c12df779d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5600
