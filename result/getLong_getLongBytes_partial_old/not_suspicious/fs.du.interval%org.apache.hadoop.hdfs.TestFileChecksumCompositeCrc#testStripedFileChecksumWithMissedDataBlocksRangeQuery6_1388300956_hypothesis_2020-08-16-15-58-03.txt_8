reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1280795229-172.17.0.21-1597593615572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38921,DS-d2484d16-8ec0-4c2d-a53d-9c1beaf10d08,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-ac2fcee4-0e8a-4850-a51f-32ace4810219,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-3716372c-a048-4983-8d9e-e65f3d5b5afe,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-59d3aaca-3adf-4794-bc2d-ccbbfb54942d,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-ef99a4ac-cde1-4ae8-aeda-2aa0e8ffe05d,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-b1e6a035-143a-4bc6-a6e6-8a2674846ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-14393af4-476c-4d42-8817-2ca27ec45bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-46dafa82-2327-4501-93c6-d31b9357eff0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1280795229-172.17.0.21-1597593615572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38921,DS-d2484d16-8ec0-4c2d-a53d-9c1beaf10d08,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-ac2fcee4-0e8a-4850-a51f-32ace4810219,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-3716372c-a048-4983-8d9e-e65f3d5b5afe,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-59d3aaca-3adf-4794-bc2d-ccbbfb54942d,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-ef99a4ac-cde1-4ae8-aeda-2aa0e8ffe05d,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-b1e6a035-143a-4bc6-a6e6-8a2674846ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:33096,DS-14393af4-476c-4d42-8817-2ca27ec45bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-46dafa82-2327-4501-93c6-d31b9357eff0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1637389321-172.17.0.21-1597594026358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40599,DS-0b4346a2-eec2-4c97-bf4d-d2dd29f96ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-2bed2d03-383b-47fd-ae42-75fddee23a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-1cf30989-502b-437d-9487-fac14f93d932,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-a828c262-8401-4b4e-94ba-ec9b615aa9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-9b3f66d6-4e66-4fed-b0e1-303470442982,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-3e36ab1a-2f7a-4831-b4ba-d0c88539d5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-bcfc4090-4ba9-4285-b354-864c72d52ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-246b3ffe-de92-44e8-9138-7e66cbdc4976,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1637389321-172.17.0.21-1597594026358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40599,DS-0b4346a2-eec2-4c97-bf4d-d2dd29f96ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-2bed2d03-383b-47fd-ae42-75fddee23a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42136,DS-1cf30989-502b-437d-9487-fac14f93d932,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-a828c262-8401-4b4e-94ba-ec9b615aa9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-9b3f66d6-4e66-4fed-b0e1-303470442982,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-3e36ab1a-2f7a-4831-b4ba-d0c88539d5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-bcfc4090-4ba9-4285-b354-864c72d52ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:34789,DS-246b3ffe-de92-44e8-9138-7e66cbdc4976,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-739431359-172.17.0.21-1597594064783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37603,DS-2c702725-9848-46c2-8548-2f476e70989b,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-bab187da-fe5f-4061-b517-369ab3b56529,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-c99f8465-31e9-4c42-a59e-818acdb2b4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-c356d9b0-1e9c-4fe3-b7de-e994cfc96191,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-f9a95afd-aaae-4ffc-8e11-0399edcf93a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-cabd6b9a-b219-4e39-af71-310b50d54add,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-2fac2ac8-c4f5-4fc3-bfd0-c009929cb701,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-8e8ffc10-67db-4305-80dc-33bcc6782d04,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-739431359-172.17.0.21-1597594064783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37603,DS-2c702725-9848-46c2-8548-2f476e70989b,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-bab187da-fe5f-4061-b517-369ab3b56529,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-c99f8465-31e9-4c42-a59e-818acdb2b4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-c356d9b0-1e9c-4fe3-b7de-e994cfc96191,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-f9a95afd-aaae-4ffc-8e11-0399edcf93a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-cabd6b9a-b219-4e39-af71-310b50d54add,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-2fac2ac8-c4f5-4fc3-bfd0-c009929cb701,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-8e8ffc10-67db-4305-80dc-33bcc6782d04,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943934264-172.17.0.21-1597594270635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42260,DS-014211c4-dd24-4240-b7d8-e3414d12c9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-58f2252f-6025-4922-af32-fb0fdaf0d3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-bf5929a0-c873-4f31-a900-6b82b08b6f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-0ed65ed6-2cd2-4825-a70f-5fc2faaea4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-f0039fa9-e7bd-41fe-9bad-149893c9ba27,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-2645035d-f5e2-4775-9fb8-c0fe64eaa0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-2c68d8a3-8ff7-41c4-88cd-b282426f9ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-ce9f6400-ca4f-4279-8f52-2996152fd894,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943934264-172.17.0.21-1597594270635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42260,DS-014211c4-dd24-4240-b7d8-e3414d12c9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-58f2252f-6025-4922-af32-fb0fdaf0d3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39011,DS-bf5929a0-c873-4f31-a900-6b82b08b6f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-0ed65ed6-2cd2-4825-a70f-5fc2faaea4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-f0039fa9-e7bd-41fe-9bad-149893c9ba27,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-2645035d-f5e2-4775-9fb8-c0fe64eaa0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-2c68d8a3-8ff7-41c4-88cd-b282426f9ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-ce9f6400-ca4f-4279-8f52-2996152fd894,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633957773-172.17.0.21-1597594664068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43379,DS-46cab508-f8fa-46f7-8268-6f783e1570b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-964bf32d-f276-42f0-a094-4b395c0cf9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-a99ec7f4-a38f-4c82-92a4-e05e4e8cb9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-4de41a19-e45c-4a40-ab76-4742cab7ecd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-012e9054-65dd-4c29-9dac-aa22db38781d,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-8c9799a0-b6bd-4c03-9b84-2204484d707b,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-ac867750-761b-4573-bb37-aebe6f477da4,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-38eebe3b-3ca5-477a-ba6a-ffe5ba59f57b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633957773-172.17.0.21-1597594664068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43379,DS-46cab508-f8fa-46f7-8268-6f783e1570b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-964bf32d-f276-42f0-a094-4b395c0cf9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-a99ec7f4-a38f-4c82-92a4-e05e4e8cb9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-4de41a19-e45c-4a40-ab76-4742cab7ecd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-012e9054-65dd-4c29-9dac-aa22db38781d,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-8c9799a0-b6bd-4c03-9b84-2204484d707b,DISK], DatanodeInfoWithStorage[127.0.0.1:42080,DS-ac867750-761b-4573-bb37-aebe6f477da4,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-38eebe3b-3ca5-477a-ba6a-ffe5ba59f57b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1429371882-172.17.0.21-1597594708783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34335,DS-53819b46-9d73-4fed-b8ae-146cb6f33b96,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-e83cd713-e4ca-4e7c-8396-80ca4ebfb422,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-d903602e-1e87-43b9-83bb-3c2a71970b91,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-0062a7c4-9118-4713-b811-980b5d04aa8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-db460f6c-0cb6-4c57-a0ba-8d061935bae4,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-55908fa6-4cd9-42f7-a9df-0dc69dd2bc45,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-0eff69c7-6d8d-48b8-8cec-412a976bedc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-cc7ff054-a611-486d-abf1-13fa8f3304c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1429371882-172.17.0.21-1597594708783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34335,DS-53819b46-9d73-4fed-b8ae-146cb6f33b96,DISK], DatanodeInfoWithStorage[127.0.0.1:43499,DS-e83cd713-e4ca-4e7c-8396-80ca4ebfb422,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-d903602e-1e87-43b9-83bb-3c2a71970b91,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-0062a7c4-9118-4713-b811-980b5d04aa8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-db460f6c-0cb6-4c57-a0ba-8d061935bae4,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-55908fa6-4cd9-42f7-a9df-0dc69dd2bc45,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-0eff69c7-6d8d-48b8-8cec-412a976bedc2,DISK], DatanodeInfoWithStorage[127.0.0.1:39599,DS-cc7ff054-a611-486d-abf1-13fa8f3304c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-581031403-172.17.0.21-1597594772749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36428,DS-17fcad01-2fab-4fe0-8036-a1512db6bd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-c59fe4aa-bce0-4716-8cbb-beda54f82800,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-b1bb7790-c752-43d9-b948-2eba4c33c70d,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-c7874bc7-b1f3-4354-9430-2a8e66557fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-305546ae-b322-405a-8400-4ebe4d2e68bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-602791d0-ae47-47dc-85b8-5a2d3ea09f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-2bc2e029-f41e-4131-b7bb-8a0b8a599ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-d13ec779-2201-43f7-af31-c508cfdae14d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-581031403-172.17.0.21-1597594772749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36428,DS-17fcad01-2fab-4fe0-8036-a1512db6bd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-c59fe4aa-bce0-4716-8cbb-beda54f82800,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-b1bb7790-c752-43d9-b948-2eba4c33c70d,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-c7874bc7-b1f3-4354-9430-2a8e66557fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-305546ae-b322-405a-8400-4ebe4d2e68bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-602791d0-ae47-47dc-85b8-5a2d3ea09f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-2bc2e029-f41e-4131-b7bb-8a0b8a599ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-d13ec779-2201-43f7-af31-c508cfdae14d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-808749306-172.17.0.21-1597594816939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33815,DS-851c78f8-ca58-4210-82c9-71e992903aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-6ab8a799-1195-4b21-93a9-f6c5b3523d25,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-733f21ae-fe53-43a4-96e1-6650b0c93552,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-f13da0a7-46b4-4b9e-af34-61eb9833a19a,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-189be4be-8b68-47cf-a283-062b2d566139,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-69fee475-f389-4aee-9dae-40c8fb48164d,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-48793fe9-0675-49ff-bd91-17e32abf0da5,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-5ff15286-00fd-4e5c-bddb-3e9653f7b18f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-808749306-172.17.0.21-1597594816939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33815,DS-851c78f8-ca58-4210-82c9-71e992903aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-6ab8a799-1195-4b21-93a9-f6c5b3523d25,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-733f21ae-fe53-43a4-96e1-6650b0c93552,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-f13da0a7-46b4-4b9e-af34-61eb9833a19a,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-189be4be-8b68-47cf-a283-062b2d566139,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-69fee475-f389-4aee-9dae-40c8fb48164d,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-48793fe9-0675-49ff-bd91-17e32abf0da5,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-5ff15286-00fd-4e5c-bddb-3e9653f7b18f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-607601347-172.17.0.21-1597594996435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38096,DS-7fb79b5f-1ee4-47c4-8e53-4043b23c5e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-f4fb0c21-99fe-4fc5-883b-81cc4d84f9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-d7aad3bb-2406-421c-b464-f7e2016d81bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-0963c54a-10c9-4470-99e0-5178b85e5376,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-f552d422-07d2-4e34-8934-1caaf05421dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-f44f074e-7541-4631-be79-8e81e929a4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-229eabed-d092-4191-881c-381838af4ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-32b2ec35-a2a3-41cb-a595-294ba9e94b0d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-607601347-172.17.0.21-1597594996435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38096,DS-7fb79b5f-1ee4-47c4-8e53-4043b23c5e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-f4fb0c21-99fe-4fc5-883b-81cc4d84f9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-d7aad3bb-2406-421c-b464-f7e2016d81bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40435,DS-0963c54a-10c9-4470-99e0-5178b85e5376,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-f552d422-07d2-4e34-8934-1caaf05421dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-f44f074e-7541-4631-be79-8e81e929a4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-229eabed-d092-4191-881c-381838af4ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-32b2ec35-a2a3-41cb-a595-294ba9e94b0d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178404942-172.17.0.21-1597595017151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35399,DS-fcb7e18f-cc66-44f6-8afc-cf2a44e612a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-a7dab5b6-41fa-4ba2-add7-690f5eb5171e,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-3e734843-ec3d-451c-b22b-291a0e7e244c,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-05769f56-dde8-4c15-811e-70bccf5c81c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-3e24c520-bb43-4676-83d0-53db3bb4a6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-12cbcd15-deb2-4884-a311-57ada6e1491a,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-edbd4540-94ee-476b-8860-2aefa68a7673,DISK], DatanodeInfoWithStorage[127.0.0.1:36898,DS-e6e6e487-428d-43e2-93cb-b63bc636c6c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-178404942-172.17.0.21-1597595017151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35399,DS-fcb7e18f-cc66-44f6-8afc-cf2a44e612a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-a7dab5b6-41fa-4ba2-add7-690f5eb5171e,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-3e734843-ec3d-451c-b22b-291a0e7e244c,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-05769f56-dde8-4c15-811e-70bccf5c81c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46860,DS-3e24c520-bb43-4676-83d0-53db3bb4a6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-12cbcd15-deb2-4884-a311-57ada6e1491a,DISK], DatanodeInfoWithStorage[127.0.0.1:42489,DS-edbd4540-94ee-476b-8860-2aefa68a7673,DISK], DatanodeInfoWithStorage[127.0.0.1:36898,DS-e6e6e487-428d-43e2-93cb-b63bc636c6c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1661400517-172.17.0.21-1597595076990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34446,DS-4938e23c-2d8a-479c-a152-d62c15ecb5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-ff067ca6-db6d-4377-a46a-55be66148005,DISK], DatanodeInfoWithStorage[127.0.0.1:44008,DS-e393eb3a-c5ec-4f1e-bfd6-6e7531113107,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-a2ed5861-76ab-4b94-9d36-62b88364c114,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-13575d94-6bbf-4b83-bd0d-eee8418d5ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-29e22ccc-eb3b-4d1d-994a-8a57b73bd509,DISK], DatanodeInfoWithStorage[127.0.0.1:44013,DS-2e4edfa3-f79d-46bd-bd0b-adee535055cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-7b6f2644-62cf-4e35-8e35-b73b3bf428d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1661400517-172.17.0.21-1597595076990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34446,DS-4938e23c-2d8a-479c-a152-d62c15ecb5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-ff067ca6-db6d-4377-a46a-55be66148005,DISK], DatanodeInfoWithStorage[127.0.0.1:44008,DS-e393eb3a-c5ec-4f1e-bfd6-6e7531113107,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-a2ed5861-76ab-4b94-9d36-62b88364c114,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-13575d94-6bbf-4b83-bd0d-eee8418d5ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:41880,DS-29e22ccc-eb3b-4d1d-994a-8a57b73bd509,DISK], DatanodeInfoWithStorage[127.0.0.1:44013,DS-2e4edfa3-f79d-46bd-bd0b-adee535055cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-7b6f2644-62cf-4e35-8e35-b73b3bf428d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2135556486-172.17.0.21-1597595272018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32859,DS-04982390-79c9-42f4-9f5f-b51a4a505989,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-967a33d1-1c46-49b4-85a0-9010b73a9c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-8c3352dd-83e1-40ae-ba71-83b3b8e3996e,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-73834ba2-7c78-4981-9b2a-211f4e9b162e,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-8a475d32-bd8a-41e3-87d0-4aa252ba16ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-42978ed9-514b-438c-a161-53d4bb2439f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-4a2c802d-a7b8-4059-93e2-463faa59e79f,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-40190422-749a-45b4-9697-561eb8291c80,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2135556486-172.17.0.21-1597595272018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32859,DS-04982390-79c9-42f4-9f5f-b51a4a505989,DISK], DatanodeInfoWithStorage[127.0.0.1:35901,DS-967a33d1-1c46-49b4-85a0-9010b73a9c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-8c3352dd-83e1-40ae-ba71-83b3b8e3996e,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-73834ba2-7c78-4981-9b2a-211f4e9b162e,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-8a475d32-bd8a-41e3-87d0-4aa252ba16ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-42978ed9-514b-438c-a161-53d4bb2439f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-4a2c802d-a7b8-4059-93e2-463faa59e79f,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-40190422-749a-45b4-9697-561eb8291c80,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-982838111-172.17.0.21-1597595369895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34042,DS-7c2d7805-56f6-4911-bbbe-80fcda283824,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-3b13d5fd-94ac-4d46-a282-2fee213d2462,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-939e4d40-ed4a-4890-8390-1ba3d80093f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-2eef2308-37b1-499a-a8c9-afed17274ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-170c7737-9f4a-41c8-9480-c5eb2d80269f,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-53af0122-9e73-4c10-82cb-1bc21923caac,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-fb4c2d94-7862-45b1-9817-f992f798851e,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-c486f2c0-da80-4db8-80d8-ba50419a1711,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-982838111-172.17.0.21-1597595369895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34042,DS-7c2d7805-56f6-4911-bbbe-80fcda283824,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-3b13d5fd-94ac-4d46-a282-2fee213d2462,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-939e4d40-ed4a-4890-8390-1ba3d80093f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-2eef2308-37b1-499a-a8c9-afed17274ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:46623,DS-170c7737-9f4a-41c8-9480-c5eb2d80269f,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-53af0122-9e73-4c10-82cb-1bc21923caac,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-fb4c2d94-7862-45b1-9817-f992f798851e,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-c486f2c0-da80-4db8-80d8-ba50419a1711,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1511581274-172.17.0.21-1597595429138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41907,DS-b5bfb276-a03f-4823-85dc-73957b94adac,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-af8cffb5-dcf1-41fa-b03d-85b3861726f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-3862e02f-a0ed-4420-a877-69a080de1216,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-e5cb23bb-7c61-4e1c-a3e8-71dfb1532c76,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-6de9b146-881b-45b1-9c3a-670e6d86b6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-d2b5026d-21c7-431a-a4a1-394669279392,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-04e8cecf-99f0-48f4-8b72-0c56839cbdfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-2376a376-ab4d-450c-b21e-63ce6a06cb37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1511581274-172.17.0.21-1597595429138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41907,DS-b5bfb276-a03f-4823-85dc-73957b94adac,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-af8cffb5-dcf1-41fa-b03d-85b3861726f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-3862e02f-a0ed-4420-a877-69a080de1216,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-e5cb23bb-7c61-4e1c-a3e8-71dfb1532c76,DISK], DatanodeInfoWithStorage[127.0.0.1:34583,DS-6de9b146-881b-45b1-9c3a-670e6d86b6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-d2b5026d-21c7-431a-a4a1-394669279392,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-04e8cecf-99f0-48f4-8b72-0c56839cbdfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-2376a376-ab4d-450c-b21e-63ce6a06cb37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156951153-172.17.0.21-1597595627567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40860,DS-5067a0da-837a-41be-9031-22d709813678,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-b21c556b-1245-4bf2-af2c-d594045142ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-eb99a89b-55ad-4d6c-b52b-cdf72758feff,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-8efab518-4ca8-4fda-8eb7-1f335be082d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-f36fcca8-87a5-42c0-8d1d-20ace38a8a30,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-0de2b79d-f843-42ce-824a-54d7c413f325,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-eeab60c8-c7ac-45f5-86b9-b64a3824096c,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-7a6992ea-5486-4c3b-8967-70ba182673e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156951153-172.17.0.21-1597595627567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40860,DS-5067a0da-837a-41be-9031-22d709813678,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-b21c556b-1245-4bf2-af2c-d594045142ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-eb99a89b-55ad-4d6c-b52b-cdf72758feff,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-8efab518-4ca8-4fda-8eb7-1f335be082d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43638,DS-f36fcca8-87a5-42c0-8d1d-20ace38a8a30,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-0de2b79d-f843-42ce-824a-54d7c413f325,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-eeab60c8-c7ac-45f5-86b9-b64a3824096c,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-7a6992ea-5486-4c3b-8967-70ba182673e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-151721384-172.17.0.21-1597595766501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46527,DS-45abb97a-ae5a-4f77-b0b3-b74ad33df4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-36b52666-be86-407b-b20c-c5e3969537e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-04f88b1d-042d-4bef-be9f-6a279d49fcf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-856811a4-832d-42d4-811f-bf8fba73d3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-161f94ed-9b96-440f-aef8-107c67e7c40c,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-afe3e302-b1a4-4cbe-9e72-8fd5332f1c87,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-4d6b179c-20a5-4a32-bbb5-bc2fa89ed519,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-075030d2-827d-44db-a420-e464e2de6354,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-151721384-172.17.0.21-1597595766501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46527,DS-45abb97a-ae5a-4f77-b0b3-b74ad33df4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-36b52666-be86-407b-b20c-c5e3969537e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-04f88b1d-042d-4bef-be9f-6a279d49fcf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-856811a4-832d-42d4-811f-bf8fba73d3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-161f94ed-9b96-440f-aef8-107c67e7c40c,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-afe3e302-b1a4-4cbe-9e72-8fd5332f1c87,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-4d6b179c-20a5-4a32-bbb5-bc2fa89ed519,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-075030d2-827d-44db-a420-e464e2de6354,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-270817929-172.17.0.21-1597596062078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34253,DS-2ffeec93-b7e1-4492-a558-432b6e4d6910,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-396db48e-df0d-46b1-b6e4-ddaf614902a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-dceea1e8-8674-487c-9b56-6ce635e328ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-bb28dc63-e035-4612-99a1-1eab3735fffa,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-d43f3a22-2e2d-4e71-9af2-28e8c6d4b724,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-42959f1f-d615-4668-b56a-045b08e4018b,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-44cef3a3-b343-45c2-a47d-6b0cf2ecc4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-8d865f97-eca8-4ff2-82bf-bedf5401590e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-270817929-172.17.0.21-1597596062078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34253,DS-2ffeec93-b7e1-4492-a558-432b6e4d6910,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-396db48e-df0d-46b1-b6e4-ddaf614902a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-dceea1e8-8674-487c-9b56-6ce635e328ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41225,DS-bb28dc63-e035-4612-99a1-1eab3735fffa,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-d43f3a22-2e2d-4e71-9af2-28e8c6d4b724,DISK], DatanodeInfoWithStorage[127.0.0.1:44226,DS-42959f1f-d615-4668-b56a-045b08e4018b,DISK], DatanodeInfoWithStorage[127.0.0.1:45840,DS-44cef3a3-b343-45c2-a47d-6b0cf2ecc4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-8d865f97-eca8-4ff2-82bf-bedf5401590e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-420163539-172.17.0.21-1597596193599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41116,DS-7b8d8c65-fd29-4e31-b99a-66ec17ab1905,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-927cb628-a385-4549-a3f0-a6b7c5f80b74,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-42e637a4-e588-41f7-a7e8-32554bd77eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-781993e5-b850-4520-bb0f-3c74aa5a0501,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-c15e2311-7f8d-49ed-a264-7a9d536ac875,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-af16749f-6235-40d7-ab4d-41701b44be7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-216306a0-7526-476a-a3c8-1f1b0122bd02,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-e2e8ecaa-58f1-4442-83b9-341baf66d041,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-420163539-172.17.0.21-1597596193599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41116,DS-7b8d8c65-fd29-4e31-b99a-66ec17ab1905,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-927cb628-a385-4549-a3f0-a6b7c5f80b74,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-42e637a4-e588-41f7-a7e8-32554bd77eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-781993e5-b850-4520-bb0f-3c74aa5a0501,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-c15e2311-7f8d-49ed-a264-7a9d536ac875,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-af16749f-6235-40d7-ab4d-41701b44be7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-216306a0-7526-476a-a3c8-1f1b0122bd02,DISK], DatanodeInfoWithStorage[127.0.0.1:42616,DS-e2e8ecaa-58f1-4442-83b9-341baf66d041,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2065921291-172.17.0.21-1597596272059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35974,DS-4d7241ef-3605-4425-9bf6-d70b7d80ab0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-e37e437b-99ce-4c9b-8933-825bdd35a8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-f5e99066-82a0-4598-b2f7-e95fc1f3bc97,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-3f3b5696-43da-48b4-9379-90b5727407d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-12b03b8f-0a61-450a-b7c0-04e692f6287e,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-e30005c8-aa7e-4cec-9e34-9fef9ba9e226,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-b6ddb329-9d8f-48ca-9c63-68b0163e068d,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-82df7ae6-0019-468c-aea2-8849bf194e02,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2065921291-172.17.0.21-1597596272059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35974,DS-4d7241ef-3605-4425-9bf6-d70b7d80ab0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-e37e437b-99ce-4c9b-8933-825bdd35a8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-f5e99066-82a0-4598-b2f7-e95fc1f3bc97,DISK], DatanodeInfoWithStorage[127.0.0.1:41996,DS-3f3b5696-43da-48b4-9379-90b5727407d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39503,DS-12b03b8f-0a61-450a-b7c0-04e692f6287e,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-e30005c8-aa7e-4cec-9e34-9fef9ba9e226,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-b6ddb329-9d8f-48ca-9c63-68b0163e068d,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-82df7ae6-0019-468c-aea2-8849bf194e02,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238908432-172.17.0.21-1597596290778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36310,DS-46d84225-8bf5-4116-b7b8-c411a5538757,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-bd8f61be-9c79-41c6-8eab-830e1a1d904c,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-f960b882-01cd-43d4-9ef9-f23956fd650e,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-ca353f2b-ea1a-4fa8-938e-40bcd64ea4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-5aec0c35-aaa8-4c44-a4dd-c3bca8e90239,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-40b6f4f2-eef6-4403-a2fb-7ba9b6ef7242,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-a95492f5-a466-4530-9d94-5e326fa4492e,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-d08be6db-b9d9-4596-8dc7-a1d36af9e952,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238908432-172.17.0.21-1597596290778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36310,DS-46d84225-8bf5-4116-b7b8-c411a5538757,DISK], DatanodeInfoWithStorage[127.0.0.1:37866,DS-bd8f61be-9c79-41c6-8eab-830e1a1d904c,DISK], DatanodeInfoWithStorage[127.0.0.1:41215,DS-f960b882-01cd-43d4-9ef9-f23956fd650e,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-ca353f2b-ea1a-4fa8-938e-40bcd64ea4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-5aec0c35-aaa8-4c44-a4dd-c3bca8e90239,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-40b6f4f2-eef6-4403-a2fb-7ba9b6ef7242,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-a95492f5-a466-4530-9d94-5e326fa4492e,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-d08be6db-b9d9-4596-8dc7-a1d36af9e952,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-656430687-172.17.0.21-1597596603878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38938,DS-dfca8a78-938d-40c7-9e82-a19d7581563e,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-c3928beb-6bb5-4062-8f8d-00a7cbc7a757,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-b9260a3c-b16b-44af-835f-9aceebd63c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-e17f6c15-de33-47bb-bfb1-669d544e2ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-d988e38d-b934-48d2-b348-bb4808308391,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-d153c64f-80ef-4db4-bcc3-40031ab3d8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-9982ad4a-269b-44db-a9ed-8ff16b2756b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-51a48c0e-5ad1-4d25-b077-66706540a247,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-656430687-172.17.0.21-1597596603878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38938,DS-dfca8a78-938d-40c7-9e82-a19d7581563e,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-c3928beb-6bb5-4062-8f8d-00a7cbc7a757,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-b9260a3c-b16b-44af-835f-9aceebd63c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-e17f6c15-de33-47bb-bfb1-669d544e2ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:42749,DS-d988e38d-b934-48d2-b348-bb4808308391,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-d153c64f-80ef-4db4-bcc3-40031ab3d8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-9982ad4a-269b-44db-a9ed-8ff16b2756b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46096,DS-51a48c0e-5ad1-4d25-b077-66706540a247,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-884483436-172.17.0.21-1597596722656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34364,DS-9912e947-22c3-41c7-a1c9-8079ef35092a,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-ce2c2762-7629-414d-9a50-ebdb390a8b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-8309bfc8-18e9-4d45-8ac4-5bacf24cafb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-f8c8014c-c16b-4c80-a644-59b5cc441057,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-b546968e-ec22-4f04-90f0-f17f7d26cb22,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-2bcc0ee0-2fea-41e6-8904-16630f724f84,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-85517f5c-a293-4c30-8f74-400faa40d58e,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-90de9cd8-0674-421e-8260-65ab815bd86a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-884483436-172.17.0.21-1597596722656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34364,DS-9912e947-22c3-41c7-a1c9-8079ef35092a,DISK], DatanodeInfoWithStorage[127.0.0.1:36823,DS-ce2c2762-7629-414d-9a50-ebdb390a8b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-8309bfc8-18e9-4d45-8ac4-5bacf24cafb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-f8c8014c-c16b-4c80-a644-59b5cc441057,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-b546968e-ec22-4f04-90f0-f17f7d26cb22,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-2bcc0ee0-2fea-41e6-8904-16630f724f84,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-85517f5c-a293-4c30-8f74-400faa40d58e,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-90de9cd8-0674-421e-8260-65ab815bd86a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86712389-172.17.0.21-1597596760251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44835,DS-42aee4c2-b9c0-4475-b7f7-8529fd31e22b,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-e5a1676f-b39b-4f5b-ae17-39f9c7fcffa6,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-dab6481f-8982-4e7f-b485-803dd177d8df,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-12478c67-7b6b-482a-ba3d-52554371d5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-fd3b5b10-3288-44ff-8a31-4c3dc8ca5e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-23c80635-b6f2-47a3-b3ae-6eba589e4e62,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-e6afc09a-1a05-46a2-980a-9d165906a616,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-7203957b-5fdc-4869-952b-5b4aff4c28e9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86712389-172.17.0.21-1597596760251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44835,DS-42aee4c2-b9c0-4475-b7f7-8529fd31e22b,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-e5a1676f-b39b-4f5b-ae17-39f9c7fcffa6,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-dab6481f-8982-4e7f-b485-803dd177d8df,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-12478c67-7b6b-482a-ba3d-52554371d5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-fd3b5b10-3288-44ff-8a31-4c3dc8ca5e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-23c80635-b6f2-47a3-b3ae-6eba589e4e62,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-e6afc09a-1a05-46a2-980a-9d165906a616,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-7203957b-5fdc-4869-952b-5b4aff4c28e9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002783261-172.17.0.21-1597596876264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35779,DS-15dfb5ab-3e9c-4f9b-8c19-2fab5c401fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-4acfff0d-cc8a-4f0f-b059-6ba47cb6e47c,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-d7c5719a-6ad9-4e9c-a1ac-b2b045fec697,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-13f917f6-7e59-4cb7-8a65-7d225ba434ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-dc1fefc2-388f-433c-9c93-5df2d656749c,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-20885ae9-624a-4264-bd26-4214d0811044,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-57f78d47-4d22-41b2-b6e4-7000793c5002,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-9c79f93a-33eb-4b24-b9a2-9b32c2072f1b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002783261-172.17.0.21-1597596876264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35779,DS-15dfb5ab-3e9c-4f9b-8c19-2fab5c401fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-4acfff0d-cc8a-4f0f-b059-6ba47cb6e47c,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-d7c5719a-6ad9-4e9c-a1ac-b2b045fec697,DISK], DatanodeInfoWithStorage[127.0.0.1:38763,DS-13f917f6-7e59-4cb7-8a65-7d225ba434ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-dc1fefc2-388f-433c-9c93-5df2d656749c,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-20885ae9-624a-4264-bd26-4214d0811044,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-57f78d47-4d22-41b2-b6e4-7000793c5002,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-9c79f93a-33eb-4b24-b9a2-9b32c2072f1b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-377433634-172.17.0.21-1597596896210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46161,DS-a19b3433-3539-4bca-8af6-27b8a0a423c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-a0e0edca-9c9d-49c6-9d6f-046d21e6097a,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-b0c264a9-1958-4a6e-8bc7-74f37e33ecaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-3a809e9e-7ab9-4504-bae6-0d06b59fa57f,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-43762fba-fba2-455b-b2bd-87c5b1210f17,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-5adb637a-c52d-4b1b-879e-cbb0db4b25f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-bed05cde-b38c-4452-a654-dc32b2cde81c,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-85bb9d8e-c7de-4895-89d6-d202746971e2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-377433634-172.17.0.21-1597596896210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46161,DS-a19b3433-3539-4bca-8af6-27b8a0a423c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-a0e0edca-9c9d-49c6-9d6f-046d21e6097a,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-b0c264a9-1958-4a6e-8bc7-74f37e33ecaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-3a809e9e-7ab9-4504-bae6-0d06b59fa57f,DISK], DatanodeInfoWithStorage[127.0.0.1:33051,DS-43762fba-fba2-455b-b2bd-87c5b1210f17,DISK], DatanodeInfoWithStorage[127.0.0.1:35871,DS-5adb637a-c52d-4b1b-879e-cbb0db4b25f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-bed05cde-b38c-4452-a654-dc32b2cde81c,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-85bb9d8e-c7de-4895-89d6-d202746971e2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 6000000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-96241106-172.17.0.21-1597596972547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33565,DS-4c95e4e8-ece3-48da-8158-732cd1ab055a,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-a9e5904c-bd75-4684-81ca-a5321363cc68,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-0a150e5f-324e-4263-88e9-9fec8fc2428c,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-fa7cea54-edb6-47bf-976f-2af22a61b876,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-4f723249-a44d-4d78-abe9-0fae543f4456,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-15f24486-e51f-4013-8b92-5793d91b87ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-ca23ad4f-1c1f-4d4a-a54e-58b6b40b25ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-8b54b168-1ac5-48ef-94b3-5d9d093d2ca1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-96241106-172.17.0.21-1597596972547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33565,DS-4c95e4e8-ece3-48da-8158-732cd1ab055a,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-a9e5904c-bd75-4684-81ca-a5321363cc68,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-0a150e5f-324e-4263-88e9-9fec8fc2428c,DISK], DatanodeInfoWithStorage[127.0.0.1:44447,DS-fa7cea54-edb6-47bf-976f-2af22a61b876,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-4f723249-a44d-4d78-abe9-0fae543f4456,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-15f24486-e51f-4013-8b92-5793d91b87ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-ca23ad4f-1c1f-4d4a-a54e-58b6b40b25ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-8b54b168-1ac5-48ef-94b3-5d9d093d2ca1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 3594
