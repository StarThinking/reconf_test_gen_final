reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-324404762-172.17.0.19-1597459580430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33059,DS-d9e2cf38-3446-40e8-b7bb-3e4b1c504062,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-8b36cec2-b53b-449f-a858-ba76c78dc746,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-b551f117-751b-4b38-bf05-870ce70db928,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-e5c1c3cc-776f-4b68-8216-a9ad0474fdac,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-bff714b0-07a6-417b-a9a9-6ffcb6d89b79,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-c479f924-fdc6-4aaf-9e7e-31c871a766aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-843d7170-a760-4899-9df4-f3d27352b284,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-3ea53146-8242-44d9-8044-450c1712ef43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-324404762-172.17.0.19-1597459580430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33059,DS-d9e2cf38-3446-40e8-b7bb-3e4b1c504062,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-8b36cec2-b53b-449f-a858-ba76c78dc746,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-b551f117-751b-4b38-bf05-870ce70db928,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-e5c1c3cc-776f-4b68-8216-a9ad0474fdac,DISK], DatanodeInfoWithStorage[127.0.0.1:46551,DS-bff714b0-07a6-417b-a9a9-6ffcb6d89b79,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-c479f924-fdc6-4aaf-9e7e-31c871a766aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-843d7170-a760-4899-9df4-f3d27352b284,DISK], DatanodeInfoWithStorage[127.0.0.1:44966,DS-3ea53146-8242-44d9-8044-450c1712ef43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1649351840-172.17.0.19-1597459614039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42975,DS-96ab5f2f-bbe4-4fd4-9ec9-e2d9ce1508e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-c50f40f5-8029-477f-95e6-f3cf0ff89745,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-be4d9702-81ec-4b91-b4f9-986ace4f2124,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-f38684e4-6f37-4f21-91c9-1f7295a6ac3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-ca418302-c621-40ce-b5cb-b5d5d9f34d78,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-62360d08-3db1-4f00-8dbb-cd33134ca446,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-241028f7-7564-4bac-a230-c3fc72a093b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-b582f5e8-a3b8-4849-8639-e4d545cc3f55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1649351840-172.17.0.19-1597459614039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42975,DS-96ab5f2f-bbe4-4fd4-9ec9-e2d9ce1508e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-c50f40f5-8029-477f-95e6-f3cf0ff89745,DISK], DatanodeInfoWithStorage[127.0.0.1:37590,DS-be4d9702-81ec-4b91-b4f9-986ace4f2124,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-f38684e4-6f37-4f21-91c9-1f7295a6ac3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-ca418302-c621-40ce-b5cb-b5d5d9f34d78,DISK], DatanodeInfoWithStorage[127.0.0.1:42171,DS-62360d08-3db1-4f00-8dbb-cd33134ca446,DISK], DatanodeInfoWithStorage[127.0.0.1:43400,DS-241028f7-7564-4bac-a230-c3fc72a093b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-b582f5e8-a3b8-4849-8639-e4d545cc3f55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-205509329-172.17.0.19-1597459653012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39455,DS-c1b3dd04-0f65-4fd4-8980-e609d6e5880c,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-1a95eac9-911e-48af-931f-65687ba123df,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-0667d7d4-b27f-4ce5-acac-be9d4ea5bfaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-bf0f7e8f-d7b3-4ea2-9ad0-1b1d051e47ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-c4bf3402-db7d-43e6-a259-1d0513a6d272,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-1783690a-c608-4ed5-a766-3a9156ffed9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-26852bff-bb5e-43c8-8c34-f703b6b4ae7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43100,DS-86fda3d0-bd2d-4981-a03d-739f2e0572aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-205509329-172.17.0.19-1597459653012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39455,DS-c1b3dd04-0f65-4fd4-8980-e609d6e5880c,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-1a95eac9-911e-48af-931f-65687ba123df,DISK], DatanodeInfoWithStorage[127.0.0.1:39454,DS-0667d7d4-b27f-4ce5-acac-be9d4ea5bfaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-bf0f7e8f-d7b3-4ea2-9ad0-1b1d051e47ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-c4bf3402-db7d-43e6-a259-1d0513a6d272,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-1783690a-c608-4ed5-a766-3a9156ffed9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-26852bff-bb5e-43c8-8c34-f703b6b4ae7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43100,DS-86fda3d0-bd2d-4981-a03d-739f2e0572aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1279580806-172.17.0.19-1597459809888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44994,DS-4c3e55cf-3413-4a21-ac7b-442f72f14f89,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-37400a3f-e6cf-4631-8cf6-a3cd25aabb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-3a713fd1-c83e-4c5d-85dc-492f59604fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-8a60760e-34f7-4203-ad70-710a11da89c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-c2f74761-d8d2-4703-976e-f48e8b331502,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-de4eee78-eda3-4874-bf7d-f803b57477a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-a5f054d8-3d32-447e-97b8-ebde9bb3aa1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-d93d7372-9ee1-4b92-90e4-346385960611,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1279580806-172.17.0.19-1597459809888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44994,DS-4c3e55cf-3413-4a21-ac7b-442f72f14f89,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-37400a3f-e6cf-4631-8cf6-a3cd25aabb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-3a713fd1-c83e-4c5d-85dc-492f59604fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-8a60760e-34f7-4203-ad70-710a11da89c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-c2f74761-d8d2-4703-976e-f48e8b331502,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-de4eee78-eda3-4874-bf7d-f803b57477a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-a5f054d8-3d32-447e-97b8-ebde9bb3aa1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-d93d7372-9ee1-4b92-90e4-346385960611,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1262432277-172.17.0.19-1597460546658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46182,DS-af400834-ade1-4e27-991b-91d50519d260,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-cd246b27-d4ea-4ab8-9f65-f78cb3e64157,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-d9ce0b34-5f2a-4a2d-bbd8-29bfd8f48c55,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-dbb768b3-b369-4882-a474-6a1defdf6c94,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-2fa1dece-e054-4912-af18-b13fbc3d769c,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-4149b75a-ab2e-4fc1-9914-bfc6d0a76bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-18bc4217-c937-429f-a08a-648c980f69c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-95ba28c6-003d-451a-a5be-125242c87417,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1262432277-172.17.0.19-1597460546658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46182,DS-af400834-ade1-4e27-991b-91d50519d260,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-cd246b27-d4ea-4ab8-9f65-f78cb3e64157,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-d9ce0b34-5f2a-4a2d-bbd8-29bfd8f48c55,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-dbb768b3-b369-4882-a474-6a1defdf6c94,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-2fa1dece-e054-4912-af18-b13fbc3d769c,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-4149b75a-ab2e-4fc1-9914-bfc6d0a76bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-18bc4217-c937-429f-a08a-648c980f69c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-95ba28c6-003d-451a-a5be-125242c87417,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1016190047-172.17.0.19-1597460930154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39253,DS-780d2216-56d2-46d3-896b-8fc79473b1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-e4d5db29-0350-441b-b729-76253785519f,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-004e374a-903a-47d6-bd92-ca07508418a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-fb3b1c11-ad60-4822-83fa-d2d9fa754bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-f897a980-9547-4cce-8a9c-9b5cffcd2086,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-94c66512-fe95-40d8-b27a-f3ddc168928f,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-29bdb417-7ec2-43a3-b695-19cca80835e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-66c8505e-b307-48c9-86d2-6f9ce841d19e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1016190047-172.17.0.19-1597460930154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39253,DS-780d2216-56d2-46d3-896b-8fc79473b1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-e4d5db29-0350-441b-b729-76253785519f,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-004e374a-903a-47d6-bd92-ca07508418a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-fb3b1c11-ad60-4822-83fa-d2d9fa754bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41543,DS-f897a980-9547-4cce-8a9c-9b5cffcd2086,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-94c66512-fe95-40d8-b27a-f3ddc168928f,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-29bdb417-7ec2-43a3-b695-19cca80835e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-66c8505e-b307-48c9-86d2-6f9ce841d19e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-232578172-172.17.0.19-1597461249467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36006,DS-080c3c74-1b09-431f-a2a5-f15b6d3b6ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:42223,DS-0e155660-daa9-4518-9c95-9efacd747bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-2d5ae8df-e291-4269-847f-3f496f1eda9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-49a35cdd-5ca3-4060-a731-b8189940c8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-d24efe7f-b4b6-4ffb-9f8d-f585e358383c,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-2d930dc4-1bd4-4cc9-8802-bf99391feaa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-bc284eef-4f71-47da-9c78-c0a3a624bcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-c049f03b-d325-4e10-823c-a5e4a7b2172b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-232578172-172.17.0.19-1597461249467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36006,DS-080c3c74-1b09-431f-a2a5-f15b6d3b6ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:42223,DS-0e155660-daa9-4518-9c95-9efacd747bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-2d5ae8df-e291-4269-847f-3f496f1eda9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-49a35cdd-5ca3-4060-a731-b8189940c8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-d24efe7f-b4b6-4ffb-9f8d-f585e358383c,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-2d930dc4-1bd4-4cc9-8802-bf99391feaa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-bc284eef-4f71-47da-9c78-c0a3a624bcf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-c049f03b-d325-4e10-823c-a5e4a7b2172b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1093239347-172.17.0.19-1597461366370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37544,DS-18cef535-ef72-4c9b-a720-0f8cbb0e5c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-2a42f3b8-73aa-4912-a337-826cdc565bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-0318553e-d07d-4bdd-b24f-abf9bac54a26,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-a17a2877-70b6-4b52-ae5b-e1152ee87c76,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-4b3d3218-1c8b-49f5-96c5-7484631d4cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-245c39ae-19a9-49fe-abd4-bf9caa6bf886,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-794f60cd-8d37-49f1-98fc-8dd1a3de9e02,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-673f6ef1-fda3-4a82-b8d6-ac142ee4ad95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1093239347-172.17.0.19-1597461366370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37544,DS-18cef535-ef72-4c9b-a720-0f8cbb0e5c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-2a42f3b8-73aa-4912-a337-826cdc565bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-0318553e-d07d-4bdd-b24f-abf9bac54a26,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-a17a2877-70b6-4b52-ae5b-e1152ee87c76,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-4b3d3218-1c8b-49f5-96c5-7484631d4cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-245c39ae-19a9-49fe-abd4-bf9caa6bf886,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-794f60cd-8d37-49f1-98fc-8dd1a3de9e02,DISK], DatanodeInfoWithStorage[127.0.0.1:46678,DS-673f6ef1-fda3-4a82-b8d6-ac142ee4ad95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-749375767-172.17.0.19-1597462207597:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41219,DS-b4fb49db-34b8-4294-bab9-92b3854dc9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-f6eec8e6-43f7-4f96-8267-f2db22486e01,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-9182fb56-f5e8-40ce-9a4b-f6b2b3df1201,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-bcf96282-61ac-4a91-b4b9-492cbe048941,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-fe6d002e-d80e-4763-b7f3-e973437ce964,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-6afcd613-3816-492c-ad09-cc31f31d0354,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-3c5cbe47-b217-4572-99de-9f7e10c695bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-5e860b7f-17d9-477a-a1b5-84d03debc94a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-749375767-172.17.0.19-1597462207597:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41219,DS-b4fb49db-34b8-4294-bab9-92b3854dc9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-f6eec8e6-43f7-4f96-8267-f2db22486e01,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-9182fb56-f5e8-40ce-9a4b-f6b2b3df1201,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-bcf96282-61ac-4a91-b4b9-492cbe048941,DISK], DatanodeInfoWithStorage[127.0.0.1:39787,DS-fe6d002e-d80e-4763-b7f3-e973437ce964,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-6afcd613-3816-492c-ad09-cc31f31d0354,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-3c5cbe47-b217-4572-99de-9f7e10c695bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-5e860b7f-17d9-477a-a1b5-84d03debc94a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-777500261-172.17.0.19-1597462372066:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40914,DS-bea5c54b-653e-4a23-b143-f0fdf79791ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-2a73ad11-85de-4bea-a948-098e42f20aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-6535aa2c-cbf5-4f78-8092-3d1a9f6e3336,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-d44cce38-d784-4405-92bb-70cadceafe71,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-2941a9a2-cde9-431f-b07c-b2fe5df04198,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-3b5463ac-fcd8-4958-93ca-134ef46ddc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-d7f3942d-0491-4347-9ffe-b0ad22ecc1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-d30e0bca-3c77-4014-9eac-e4d83d26693f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-777500261-172.17.0.19-1597462372066:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40914,DS-bea5c54b-653e-4a23-b143-f0fdf79791ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-2a73ad11-85de-4bea-a948-098e42f20aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:40165,DS-6535aa2c-cbf5-4f78-8092-3d1a9f6e3336,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-d44cce38-d784-4405-92bb-70cadceafe71,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-2941a9a2-cde9-431f-b07c-b2fe5df04198,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-3b5463ac-fcd8-4958-93ca-134ef46ddc0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-d7f3942d-0491-4347-9ffe-b0ad22ecc1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-d30e0bca-3c77-4014-9eac-e4d83d26693f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-735212547-172.17.0.19-1597462698646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34015,DS-eb4fda75-a1f3-43b2-8b88-2d972e01b41c,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-bde84be4-b32a-4277-bef7-9483029f857c,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-2d8db018-9430-4916-91fe-78d68cc9db81,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-9a6b16e6-d315-41cb-9e4d-cda8f97d9a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-957ee77f-3220-42f3-8219-906c7d1d6175,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-b7391030-70a7-4790-b043-d61d66fedc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-a54839ef-6f73-4afd-a7be-84379e57539a,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-ae97b81d-fc4b-4203-b8be-055b77f7fe62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-735212547-172.17.0.19-1597462698646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34015,DS-eb4fda75-a1f3-43b2-8b88-2d972e01b41c,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-bde84be4-b32a-4277-bef7-9483029f857c,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-2d8db018-9430-4916-91fe-78d68cc9db81,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-9a6b16e6-d315-41cb-9e4d-cda8f97d9a9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-957ee77f-3220-42f3-8219-906c7d1d6175,DISK], DatanodeInfoWithStorage[127.0.0.1:33147,DS-b7391030-70a7-4790-b043-d61d66fedc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36109,DS-a54839ef-6f73-4afd-a7be-84379e57539a,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-ae97b81d-fc4b-4203-b8be-055b77f7fe62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-735967913-172.17.0.19-1597462737455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45479,DS-c60a39bc-0df4-40e9-91f9-fa95c90ff1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-ef08592e-0493-4c85-8f1e-bd13fc6be9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-e558221b-0db2-44c8-b879-6f1cd38ef64b,DISK], DatanodeInfoWithStorage[127.0.0.1:46616,DS-d5befa67-12af-4b6e-9662-7e52b51ce9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-cc340c73-a830-4af4-9a44-5d4c68526219,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-0a618cf8-73bd-4933-ab01-2903c780edd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-e9a66772-73c5-4a55-a2d5-610ba9c04045,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-e9182494-074b-4cc7-95e2-af4f4d87b4f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-735967913-172.17.0.19-1597462737455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45479,DS-c60a39bc-0df4-40e9-91f9-fa95c90ff1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38447,DS-ef08592e-0493-4c85-8f1e-bd13fc6be9a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-e558221b-0db2-44c8-b879-6f1cd38ef64b,DISK], DatanodeInfoWithStorage[127.0.0.1:46616,DS-d5befa67-12af-4b6e-9662-7e52b51ce9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-cc340c73-a830-4af4-9a44-5d4c68526219,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-0a618cf8-73bd-4933-ab01-2903c780edd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44679,DS-e9a66772-73c5-4a55-a2d5-610ba9c04045,DISK], DatanodeInfoWithStorage[127.0.0.1:44231,DS-e9182494-074b-4cc7-95e2-af4f4d87b4f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169087890-172.17.0.19-1597462886956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44829,DS-56402075-57a1-4f32-8d5c-249c6395b59c,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-026fb08d-f0f0-4da0-b578-90fa3ebe7d22,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-005467e2-f220-438a-8677-4f50aa44ef21,DISK], DatanodeInfoWithStorage[127.0.0.1:38234,DS-17d55af8-7135-4ac7-a006-690f5b2bd0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-6edd9a85-1b05-4369-9948-7753bdb329a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-36371cec-a4b1-4485-b85a-9a4e9fcc073f,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-03d8fcf8-b2e6-44d0-9d3c-8c4c25d6e640,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-c1a3bad3-a920-49d9-a6e6-c4f94e0f6a42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1169087890-172.17.0.19-1597462886956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44829,DS-56402075-57a1-4f32-8d5c-249c6395b59c,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-026fb08d-f0f0-4da0-b578-90fa3ebe7d22,DISK], DatanodeInfoWithStorage[127.0.0.1:39734,DS-005467e2-f220-438a-8677-4f50aa44ef21,DISK], DatanodeInfoWithStorage[127.0.0.1:38234,DS-17d55af8-7135-4ac7-a006-690f5b2bd0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-6edd9a85-1b05-4369-9948-7753bdb329a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-36371cec-a4b1-4485-b85a-9a4e9fcc073f,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-03d8fcf8-b2e6-44d0-9d3c-8c4c25d6e640,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-c1a3bad3-a920-49d9-a6e6-c4f94e0f6a42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1689349209-172.17.0.19-1597462927462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41604,DS-989ff27a-371b-4059-bc70-476127d4b7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-894f76dd-f229-41d5-9b2b-e76b635d075b,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-ba5356d8-38a6-465f-b472-7bbd9ba1e91f,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-fd9785e6-045e-46f0-9f73-ad0c01900ada,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-77d540b5-fe19-4e5c-9d95-f435a93b41b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-a475ff45-61e4-48f2-8b55-6b8ebb02d29d,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-85eeb1c2-694b-4b70-a6f1-480f4ecc1364,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-bb6f795f-7ca8-46d4-b18d-0daefbcd4e9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1689349209-172.17.0.19-1597462927462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41604,DS-989ff27a-371b-4059-bc70-476127d4b7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-894f76dd-f229-41d5-9b2b-e76b635d075b,DISK], DatanodeInfoWithStorage[127.0.0.1:43187,DS-ba5356d8-38a6-465f-b472-7bbd9ba1e91f,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-fd9785e6-045e-46f0-9f73-ad0c01900ada,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-77d540b5-fe19-4e5c-9d95-f435a93b41b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-a475ff45-61e4-48f2-8b55-6b8ebb02d29d,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-85eeb1c2-694b-4b70-a6f1-480f4ecc1364,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-bb6f795f-7ca8-46d4-b18d-0daefbcd4e9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-173795494-172.17.0.19-1597463276620:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42548,DS-43375efe-bce4-4749-a338-a158254191a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-db19d3e3-9f8c-43dd-97da-5b3a57db4aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-be332c3f-ecca-495f-844f-e2e796e3baf2,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-c6c1cb64-81d0-46c8-b324-e7e70ee154da,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-453daaba-91c1-461a-8fbe-94ef7412c95e,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-6ee965dd-d44d-4f86-afe1-e3611cd52ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-301ac852-c74e-47fd-aa17-a927ddccbb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-6b852c02-3a25-4626-9e24-95140b88387d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-173795494-172.17.0.19-1597463276620:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42548,DS-43375efe-bce4-4749-a338-a158254191a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-db19d3e3-9f8c-43dd-97da-5b3a57db4aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-be332c3f-ecca-495f-844f-e2e796e3baf2,DISK], DatanodeInfoWithStorage[127.0.0.1:44259,DS-c6c1cb64-81d0-46c8-b324-e7e70ee154da,DISK], DatanodeInfoWithStorage[127.0.0.1:38989,DS-453daaba-91c1-461a-8fbe-94ef7412c95e,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-6ee965dd-d44d-4f86-afe1-e3611cd52ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-301ac852-c74e-47fd-aa17-a927ddccbb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-6b852c02-3a25-4626-9e24-95140b88387d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1204932302-172.17.0.19-1597463356701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45838,DS-5cbf3431-e905-45ce-baae-861c5853caf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-810f2c45-ec38-46a9-8bca-b7d90675c890,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-5c54b1ff-896a-4022-9d67-addbbe408b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-8d11e634-2cc2-45f5-b42d-6c2fcf58b36d,DISK], DatanodeInfoWithStorage[127.0.0.1:38008,DS-48bd4cda-39cb-4f31-b8fb-76a372971fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-5bc1014d-b65d-4d81-bbba-1f8ee95b4b69,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-ae38f24d-f5b0-4d93-95eb-55fa0b010a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-183a5319-e3d1-44fa-9189-ca556ff3d8a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1204932302-172.17.0.19-1597463356701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45838,DS-5cbf3431-e905-45ce-baae-861c5853caf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-810f2c45-ec38-46a9-8bca-b7d90675c890,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-5c54b1ff-896a-4022-9d67-addbbe408b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-8d11e634-2cc2-45f5-b42d-6c2fcf58b36d,DISK], DatanodeInfoWithStorage[127.0.0.1:38008,DS-48bd4cda-39cb-4f31-b8fb-76a372971fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-5bc1014d-b65d-4d81-bbba-1f8ee95b4b69,DISK], DatanodeInfoWithStorage[127.0.0.1:44195,DS-ae38f24d-f5b0-4d93-95eb-55fa0b010a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-183a5319-e3d1-44fa-9189-ca556ff3d8a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1391688830-172.17.0.19-1597463548210:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35514,DS-dca4c003-0be2-4e3a-8d43-32a6ab751b14,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-aaa516de-0793-4653-b214-ccd8e57355c7,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-cb088bb8-0021-4ed3-a57e-edfda6164a45,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-551ee02f-60a0-4535-a424-6d7e6a1daffd,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-41ff0d9c-02ee-4c68-b36c-e988cb3744c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-36b14e2a-ee8d-4840-a518-dcea472b4775,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-de4a9fec-7fbb-478e-97f6-99a349c16319,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-b086acfb-79a3-4fb3-9261-cc2102054b42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1391688830-172.17.0.19-1597463548210:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35514,DS-dca4c003-0be2-4e3a-8d43-32a6ab751b14,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-aaa516de-0793-4653-b214-ccd8e57355c7,DISK], DatanodeInfoWithStorage[127.0.0.1:32938,DS-cb088bb8-0021-4ed3-a57e-edfda6164a45,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-551ee02f-60a0-4535-a424-6d7e6a1daffd,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-41ff0d9c-02ee-4c68-b36c-e988cb3744c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-36b14e2a-ee8d-4840-a518-dcea472b4775,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-de4a9fec-7fbb-478e-97f6-99a349c16319,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-b086acfb-79a3-4fb3-9261-cc2102054b42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1159716093-172.17.0.19-1597463585882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46068,DS-3f78f3cf-abbe-4942-8564-2112f9ae48b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-3991bbfa-9578-4022-8171-afc996ef0e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-bcea3bf4-7c9a-403b-987c-fef50854389c,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-ead76bbe-1368-4976-a242-97c3839a37d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-fe692d41-a5f5-4fc9-9f1e-b6525c539a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-868c4731-9232-4eb0-93f6-b5c55c10beb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-0fbb4446-4438-44cb-a111-148d520abfd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-0e8dd5a8-a467-4c00-933d-9a1aa00b0106,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1159716093-172.17.0.19-1597463585882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46068,DS-3f78f3cf-abbe-4942-8564-2112f9ae48b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-3991bbfa-9578-4022-8171-afc996ef0e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-bcea3bf4-7c9a-403b-987c-fef50854389c,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-ead76bbe-1368-4976-a242-97c3839a37d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-fe692d41-a5f5-4fc9-9f1e-b6525c539a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-868c4731-9232-4eb0-93f6-b5c55c10beb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-0fbb4446-4438-44cb-a111-148d520abfd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-0e8dd5a8-a467-4c00-933d-9a1aa00b0106,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1209632573-172.17.0.19-1597463892457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44585,DS-c0dc849e-ff89-45c5-b551-2f04232bbc60,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-0711858f-3386-4bca-8e02-87e1ea2cf704,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-10f3e58e-71bf-4f9b-a310-4f24ec021708,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-c837e7e4-27b7-4c7f-9d81-3161ea0a7d32,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-672275eb-1344-4daa-972d-7011e8de3aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-30a32d5c-ff32-4778-8d88-38b41289299c,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-bcec70de-0669-460d-abf2-32cc88c78baf,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-c9ad9cfc-1d15-494d-9dae-004d93caa1b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1209632573-172.17.0.19-1597463892457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44585,DS-c0dc849e-ff89-45c5-b551-2f04232bbc60,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-0711858f-3386-4bca-8e02-87e1ea2cf704,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-10f3e58e-71bf-4f9b-a310-4f24ec021708,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-c837e7e4-27b7-4c7f-9d81-3161ea0a7d32,DISK], DatanodeInfoWithStorage[127.0.0.1:41592,DS-672275eb-1344-4daa-972d-7011e8de3aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-30a32d5c-ff32-4778-8d88-38b41289299c,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-bcec70de-0669-460d-abf2-32cc88c78baf,DISK], DatanodeInfoWithStorage[127.0.0.1:43295,DS-c9ad9cfc-1d15-494d-9dae-004d93caa1b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-786661234-172.17.0.19-1597463967596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35693,DS-c995cd2b-bf49-45f6-a0e3-8dc33034a7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-684ff167-8b92-46e6-883a-98545e56df79,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-5a3469d2-2070-473b-aad0-bed8182cbecf,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-1fb1c346-2093-4f0d-91ba-70d0b378a6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-3fc90277-1ec5-4959-84f9-3d8227d186a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-9e99c23c-1ad6-402f-a0d9-0eedf57834e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-c1626927-3189-4c7c-935e-1feaa8a3e89a,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-c447cfd3-b319-4bb8-8996-ffedc5804c58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-786661234-172.17.0.19-1597463967596:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35693,DS-c995cd2b-bf49-45f6-a0e3-8dc33034a7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-684ff167-8b92-46e6-883a-98545e56df79,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-5a3469d2-2070-473b-aad0-bed8182cbecf,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-1fb1c346-2093-4f0d-91ba-70d0b378a6ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-3fc90277-1ec5-4959-84f9-3d8227d186a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-9e99c23c-1ad6-402f-a0d9-0eedf57834e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40794,DS-c1626927-3189-4c7c-935e-1feaa8a3e89a,DISK], DatanodeInfoWithStorage[127.0.0.1:35014,DS-c447cfd3-b319-4bb8-8996-ffedc5804c58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1475195803-172.17.0.19-1597464122368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41691,DS-1463d5f1-8d60-4581-bbc1-60f087662768,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-9b93d78d-98e7-4747-94b3-d137d5cefd88,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-d195e729-214a-4548-8346-e5249a85051f,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-381c566a-622b-4df9-9c35-f0f90f5eb440,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-0d9f765d-079a-4899-8263-0a40541c3e24,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-04f941b7-2483-4bbd-a349-f6050d75e22c,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-ebbdb366-3b90-4843-970a-03a19997c625,DISK], DatanodeInfoWithStorage[127.0.0.1:43387,DS-9055d72c-d4e3-4a0b-abec-a087ab7aae42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1475195803-172.17.0.19-1597464122368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41691,DS-1463d5f1-8d60-4581-bbc1-60f087662768,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-9b93d78d-98e7-4747-94b3-d137d5cefd88,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-d195e729-214a-4548-8346-e5249a85051f,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-381c566a-622b-4df9-9c35-f0f90f5eb440,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-0d9f765d-079a-4899-8263-0a40541c3e24,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-04f941b7-2483-4bbd-a349-f6050d75e22c,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-ebbdb366-3b90-4843-970a-03a19997c625,DISK], DatanodeInfoWithStorage[127.0.0.1:43387,DS-9055d72c-d4e3-4a0b-abec-a087ab7aae42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-755979993-172.17.0.19-1597464285256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37670,DS-458dc498-ba6a-4dc5-be1b-201b1a5ad464,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-f7e1cbcf-185c-425a-a7fb-46671550d6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-a505f39c-8ddd-445f-8ed7-70c0a4831783,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-5a9b8408-3875-4d91-8981-fc183b09c232,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-fa0b2c42-665a-482f-9b60-0d53f0ec8177,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-047bbbbd-971e-46bd-ac52-996559048337,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-86d3170b-1da9-4e95-b083-75659f1a54cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-9f0fbd6a-8511-4fd4-b3a7-ad7cbd728cf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-755979993-172.17.0.19-1597464285256:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37670,DS-458dc498-ba6a-4dc5-be1b-201b1a5ad464,DISK], DatanodeInfoWithStorage[127.0.0.1:42824,DS-f7e1cbcf-185c-425a-a7fb-46671550d6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-a505f39c-8ddd-445f-8ed7-70c0a4831783,DISK], DatanodeInfoWithStorage[127.0.0.1:38575,DS-5a9b8408-3875-4d91-8981-fc183b09c232,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-fa0b2c42-665a-482f-9b60-0d53f0ec8177,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-047bbbbd-971e-46bd-ac52-996559048337,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-86d3170b-1da9-4e95-b083-75659f1a54cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-9f0fbd6a-8511-4fd4-b3a7-ad7cbd728cf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131900845-172.17.0.19-1597464361737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36220,DS-5ee5b0b5-c9b1-45b0-b657-685622e9d8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-843e4698-9a32-406f-9264-89dbce1576a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-0111736b-416a-462e-a7e4-4110395df904,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-2d536d63-d815-47bc-abf8-826c704bab74,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-bd78dbb0-b1af-4399-ab00-025d9d5e2714,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-deda56a5-e4b4-4134-bfa5-a9b9d7e12e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-869eed6f-9a4e-4fd6-bbf4-170a22561959,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-30f6d5ee-796e-4106-acab-b0371380170b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131900845-172.17.0.19-1597464361737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36220,DS-5ee5b0b5-c9b1-45b0-b657-685622e9d8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-843e4698-9a32-406f-9264-89dbce1576a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-0111736b-416a-462e-a7e4-4110395df904,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-2d536d63-d815-47bc-abf8-826c704bab74,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-bd78dbb0-b1af-4399-ab00-025d9d5e2714,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-deda56a5-e4b4-4134-bfa5-a9b9d7e12e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-869eed6f-9a4e-4fd6-bbf4-170a22561959,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-30f6d5ee-796e-4106-acab-b0371380170b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-327615637-172.17.0.19-1597464889565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44330,DS-50af46c2-82a9-4263-962a-cd97249da191,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-22911906-d2cb-46c4-8b1d-32885b5cabce,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-af59ca90-c360-4c7e-a6a1-50de18a3d339,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-38e2a7df-9dea-472c-8ec2-6176c6085df7,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-5e040efc-1e38-48b3-bc5a-2c10df142e44,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-3a5b9006-bc7d-494d-91c4-154d8640c3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-8e38852b-5b1a-47a1-a9a9-5d9836a6c41f,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-f829b073-78ac-4a8e-ba1c-ffa1857674f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-327615637-172.17.0.19-1597464889565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44330,DS-50af46c2-82a9-4263-962a-cd97249da191,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-22911906-d2cb-46c4-8b1d-32885b5cabce,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-af59ca90-c360-4c7e-a6a1-50de18a3d339,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-38e2a7df-9dea-472c-8ec2-6176c6085df7,DISK], DatanodeInfoWithStorage[127.0.0.1:42960,DS-5e040efc-1e38-48b3-bc5a-2c10df142e44,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-3a5b9006-bc7d-494d-91c4-154d8640c3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-8e38852b-5b1a-47a1-a9a9-5d9836a6c41f,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-f829b073-78ac-4a8e-ba1c-ffa1857674f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-923875831-172.17.0.19-1597464928121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35950,DS-98cda662-4b9a-445b-a278-3027ac359837,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-e5cad9d3-ff43-42f4-8ba0-70b8489e0473,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-bf4c3478-1eb7-4d06-916d-89d36487c0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-fd0ff17e-e8fa-4827-a9d6-ae95cb38deaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-bfb17c1e-5466-47f9-bfa5-fd616d6debff,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-55752cc4-e05a-400c-8628-3256adcdf697,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-48cc7fa3-05cf-48ca-acf6-133da887919c,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-67aa48c2-ed6a-4fc0-9453-6beadd5349d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-923875831-172.17.0.19-1597464928121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35950,DS-98cda662-4b9a-445b-a278-3027ac359837,DISK], DatanodeInfoWithStorage[127.0.0.1:40256,DS-e5cad9d3-ff43-42f4-8ba0-70b8489e0473,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-bf4c3478-1eb7-4d06-916d-89d36487c0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-fd0ff17e-e8fa-4827-a9d6-ae95cb38deaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40856,DS-bfb17c1e-5466-47f9-bfa5-fd616d6debff,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-55752cc4-e05a-400c-8628-3256adcdf697,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-48cc7fa3-05cf-48ca-acf6-133da887919c,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-67aa48c2-ed6a-4fc0-9453-6beadd5349d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.content-summary.sleep-microsec
component: hdfs:NameNode
v1: 500
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1905836770-172.17.0.19-1597464968331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43309,DS-3c595b86-09db-4455-903e-bff2e494b090,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-d4986691-0045-4547-9a06-e88c5090ea72,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-4dc27953-b684-45a0-9661-5b4741c8b1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-048ea5dd-faef-42a6-8db5-aa4c20aa2844,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-a83dea0c-ff5e-406c-a772-3ccb44974033,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-f2c033a9-03ba-41cd-82c2-bc2e45009b71,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-913ae160-bca4-4a7b-a0bd-0d08476f0405,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-a62146cb-6581-4aec-a778-74b13b507fbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1905836770-172.17.0.19-1597464968331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43309,DS-3c595b86-09db-4455-903e-bff2e494b090,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-d4986691-0045-4547-9a06-e88c5090ea72,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-4dc27953-b684-45a0-9661-5b4741c8b1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-048ea5dd-faef-42a6-8db5-aa4c20aa2844,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-a83dea0c-ff5e-406c-a772-3ccb44974033,DISK], DatanodeInfoWithStorage[127.0.0.1:40644,DS-f2c033a9-03ba-41cd-82c2-bc2e45009b71,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-913ae160-bca4-4a7b-a0bd-0d08476f0405,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-a62146cb-6581-4aec-a778-74b13b507fbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5762
