reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822976356-172.17.0.21-1597456232140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38379,DS-68761b66-9031-4e9f-897e-09737fa7e293,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-e2bcd6b4-96f5-4ba9-8a8d-58ed5cfb758d,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-33eedf10-4bac-4e57-9340-4d07a840bb31,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-232d0d3d-ac2c-4552-8908-243dc7343e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-aecb362d-5bdc-4bac-90f4-b6300d69f1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-f6211b77-f8ff-46b7-8556-502d3a4ea4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-d9150c23-ea30-43bc-a0fe-cc579135afa5,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-d8a76de8-6c28-4ea2-adce-cc22b20d2ce0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822976356-172.17.0.21-1597456232140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38379,DS-68761b66-9031-4e9f-897e-09737fa7e293,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-e2bcd6b4-96f5-4ba9-8a8d-58ed5cfb758d,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-33eedf10-4bac-4e57-9340-4d07a840bb31,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-232d0d3d-ac2c-4552-8908-243dc7343e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34001,DS-aecb362d-5bdc-4bac-90f4-b6300d69f1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-f6211b77-f8ff-46b7-8556-502d3a4ea4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-d9150c23-ea30-43bc-a0fe-cc579135afa5,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-d8a76de8-6c28-4ea2-adce-cc22b20d2ce0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630319593-172.17.0.21-1597456272937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37721,DS-b230f42b-6659-44fb-bdee-f6a621e315e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-59ff052e-709b-4383-98e0-c3541718f33a,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-275a5f11-1861-4bbd-9900-26a4ea631d30,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-59340b07-13dc-4f22-9454-744755c6c09c,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-b01f5438-30d6-4af4-a42d-37bdbb6b5bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-78a4ff14-8075-4c28-9355-f6d7bddfb387,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-e1f98ba8-09da-4c95-bb65-d8c6cd08ac32,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-51c234e1-ff00-40c6-95f3-a8dba313dc47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1630319593-172.17.0.21-1597456272937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37721,DS-b230f42b-6659-44fb-bdee-f6a621e315e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-59ff052e-709b-4383-98e0-c3541718f33a,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-275a5f11-1861-4bbd-9900-26a4ea631d30,DISK], DatanodeInfoWithStorage[127.0.0.1:44565,DS-59340b07-13dc-4f22-9454-744755c6c09c,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-b01f5438-30d6-4af4-a42d-37bdbb6b5bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-78a4ff14-8075-4c28-9355-f6d7bddfb387,DISK], DatanodeInfoWithStorage[127.0.0.1:45794,DS-e1f98ba8-09da-4c95-bb65-d8c6cd08ac32,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-51c234e1-ff00-40c6-95f3-a8dba313dc47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-916154056-172.17.0.21-1597456765920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46443,DS-650bc1cc-bb6e-4045-ae3d-6a4bf363a7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-9e7c4319-a0a0-4a2b-859c-f4dd4b2f892d,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-9937fc28-9814-4f96-a816-98eb166ade32,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-15581e67-f858-4173-9e74-1aefdaf16bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-f56d5a42-60d5-41e0-8ab4-cc35f116c2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-5de21d7b-d5fb-44ec-86ea-317014a3d2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-eabc3c42-7657-48c1-8080-082110f70e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-5befb90f-c2f6-47f7-a615-28249799d2c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-916154056-172.17.0.21-1597456765920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46443,DS-650bc1cc-bb6e-4045-ae3d-6a4bf363a7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-9e7c4319-a0a0-4a2b-859c-f4dd4b2f892d,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-9937fc28-9814-4f96-a816-98eb166ade32,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-15581e67-f858-4173-9e74-1aefdaf16bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-f56d5a42-60d5-41e0-8ab4-cc35f116c2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-5de21d7b-d5fb-44ec-86ea-317014a3d2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-eabc3c42-7657-48c1-8080-082110f70e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-5befb90f-c2f6-47f7-a615-28249799d2c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1064084198-172.17.0.21-1597456934649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39643,DS-482e44b6-069c-4ec2-a339-73d3e94d6dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-6431a54c-5292-40e3-a640-4a0d131144bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-c6b0c7c6-e4c0-488d-ad4d-086aa6fa1c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-cd6b5b82-ae36-443c-afdd-c400884b7bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-7436fdce-806b-4b09-86db-cc08e55e0e67,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-ea56c70b-e2a1-40a9-bc17-155db0983b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-ef9f75b3-0205-44d6-86b5-07f0f3bcd256,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-d319fa78-c6e5-4918-818e-737b15184e46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1064084198-172.17.0.21-1597456934649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39643,DS-482e44b6-069c-4ec2-a339-73d3e94d6dc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-6431a54c-5292-40e3-a640-4a0d131144bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-c6b0c7c6-e4c0-488d-ad4d-086aa6fa1c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-cd6b5b82-ae36-443c-afdd-c400884b7bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-7436fdce-806b-4b09-86db-cc08e55e0e67,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-ea56c70b-e2a1-40a9-bc17-155db0983b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-ef9f75b3-0205-44d6-86b5-07f0f3bcd256,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-d319fa78-c6e5-4918-818e-737b15184e46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642886326-172.17.0.21-1597457902979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42130,DS-7681d580-ff09-4bd7-b781-1e5bf9df9e24,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-f02bb5a5-05dc-46ce-a10f-047d950812d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-a836dd95-ea37-43dd-8d03-2f9fdecb9ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-76398339-6a37-4b6c-ae42-86d49df11912,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-c011e025-3ea1-494e-a640-7de519e3e73c,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-a1b6a353-afb3-48d2-9996-76d98c1072eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-a5e9684d-f581-48f6-bd48-b31a069eb248,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-dee69d65-3f2a-48d9-915e-349799495b49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-642886326-172.17.0.21-1597457902979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42130,DS-7681d580-ff09-4bd7-b781-1e5bf9df9e24,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-f02bb5a5-05dc-46ce-a10f-047d950812d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-a836dd95-ea37-43dd-8d03-2f9fdecb9ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-76398339-6a37-4b6c-ae42-86d49df11912,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-c011e025-3ea1-494e-a640-7de519e3e73c,DISK], DatanodeInfoWithStorage[127.0.0.1:41098,DS-a1b6a353-afb3-48d2-9996-76d98c1072eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-a5e9684d-f581-48f6-bd48-b31a069eb248,DISK], DatanodeInfoWithStorage[127.0.0.1:44668,DS-dee69d65-3f2a-48d9-915e-349799495b49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-675479931-172.17.0.21-1597458131786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34371,DS-7222902c-9d56-4876-9f56-f58d182f5455,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-92749e96-c326-4f12-9a0a-c9545ea46b84,DISK], DatanodeInfoWithStorage[127.0.0.1:40688,DS-23c29920-cbe3-4412-a920-3268876d165d,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-ffe5d91e-d6a5-4563-95f6-6c5f60c1ce36,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-fcd0608d-3820-4fb2-9f31-2dd6497c7a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-c95e343a-6601-4815-98d5-f50e4e24e1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-ab75c09e-5913-4fae-9083-565dcc5b3892,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-ed6c166e-c04c-4ebb-b240-bf45436254c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-675479931-172.17.0.21-1597458131786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34371,DS-7222902c-9d56-4876-9f56-f58d182f5455,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-92749e96-c326-4f12-9a0a-c9545ea46b84,DISK], DatanodeInfoWithStorage[127.0.0.1:40688,DS-23c29920-cbe3-4412-a920-3268876d165d,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-ffe5d91e-d6a5-4563-95f6-6c5f60c1ce36,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-fcd0608d-3820-4fb2-9f31-2dd6497c7a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-c95e343a-6601-4815-98d5-f50e4e24e1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-ab75c09e-5913-4fae-9083-565dcc5b3892,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-ed6c166e-c04c-4ebb-b240-bf45436254c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1871245726-172.17.0.21-1597458627302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43890,DS-059d30aa-56a6-4086-ba07-0c07d88cbdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-f893773d-10a2-43f6-a10c-ac31b315a93c,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-d9ef0113-1fa4-4a1b-8f8a-1cd618b1b545,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-cc80981d-b4e3-406a-bb28-0df19b38e2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-930a514f-b126-4784-9691-fd1991e6683c,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-ce80651b-9932-4079-99d4-7fedab7909f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-bfffa2d4-438b-4556-b95c-a03b73a1ae31,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-0c891856-7a35-432a-84c1-72b31075db5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1871245726-172.17.0.21-1597458627302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43890,DS-059d30aa-56a6-4086-ba07-0c07d88cbdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-f893773d-10a2-43f6-a10c-ac31b315a93c,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-d9ef0113-1fa4-4a1b-8f8a-1cd618b1b545,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-cc80981d-b4e3-406a-bb28-0df19b38e2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-930a514f-b126-4784-9691-fd1991e6683c,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-ce80651b-9932-4079-99d4-7fedab7909f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36980,DS-bfffa2d4-438b-4556-b95c-a03b73a1ae31,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-0c891856-7a35-432a-84c1-72b31075db5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-325782023-172.17.0.21-1597458670024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35158,DS-248625b2-1dbb-4622-b710-341697cd26b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-248027c0-527e-443f-88dc-278f9b74b48b,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-5f37c218-2fd6-45b9-9694-c3332e0c7602,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-8e2d473e-dd2e-4328-9a79-ab5cdee199e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-df95c9f0-f6bf-4d4b-a0c1-1e3ef8881c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-822c7b13-7628-4ade-b41b-3d415382c02d,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-2185fafc-03cb-46b4-9ae3-93b60df02461,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-a91d19f1-38e5-4464-8e1c-95031f07be78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-325782023-172.17.0.21-1597458670024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35158,DS-248625b2-1dbb-4622-b710-341697cd26b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-248027c0-527e-443f-88dc-278f9b74b48b,DISK], DatanodeInfoWithStorage[127.0.0.1:39498,DS-5f37c218-2fd6-45b9-9694-c3332e0c7602,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-8e2d473e-dd2e-4328-9a79-ab5cdee199e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-df95c9f0-f6bf-4d4b-a0c1-1e3ef8881c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-822c7b13-7628-4ade-b41b-3d415382c02d,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-2185fafc-03cb-46b4-9ae3-93b60df02461,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-a91d19f1-38e5-4464-8e1c-95031f07be78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156617207-172.17.0.21-1597458745985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44619,DS-6fb4e1cc-a774-4946-a3a6-6ebefce85ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-45599d55-1c5c-47cf-8582-3c7c31337d65,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-b9776433-1816-48fa-bfad-4485ec9aed9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-81376e21-bad0-4648-9e79-29be75c55fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-61a03a23-275c-49fc-a5b8-b4ab312f908a,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-f3d9eea8-796c-4dda-84da-84a8bda97c29,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-da8d4cda-a113-4e1b-bc6b-fbf13803cec1,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-12b7e17b-a3b6-4bbd-849e-5a5353c7f32e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156617207-172.17.0.21-1597458745985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44619,DS-6fb4e1cc-a774-4946-a3a6-6ebefce85ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-45599d55-1c5c-47cf-8582-3c7c31337d65,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-b9776433-1816-48fa-bfad-4485ec9aed9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-81376e21-bad0-4648-9e79-29be75c55fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:41154,DS-61a03a23-275c-49fc-a5b8-b4ab312f908a,DISK], DatanodeInfoWithStorage[127.0.0.1:35845,DS-f3d9eea8-796c-4dda-84da-84a8bda97c29,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-da8d4cda-a113-4e1b-bc6b-fbf13803cec1,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-12b7e17b-a3b6-4bbd-849e-5a5353c7f32e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1702072996-172.17.0.21-1597458818358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44338,DS-e9f02951-9d3f-45f2-b12b-6cf0870808be,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-cff0ab06-7cdb-42e7-80b0-2363bd6ba2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-0e00def3-3348-4d69-be65-be3546987e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-8993f74c-f235-4e98-921d-448a9a15e206,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-5ca83bca-31bc-49d4-8c4d-4ee277d67748,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-d00be379-9e34-42ba-965f-b30e25e7c6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-38ced881-3629-4784-85ed-d7b42677dd04,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-f9e62b99-8c02-4e4e-af8f-27022dce403f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1702072996-172.17.0.21-1597458818358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44338,DS-e9f02951-9d3f-45f2-b12b-6cf0870808be,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-cff0ab06-7cdb-42e7-80b0-2363bd6ba2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-0e00def3-3348-4d69-be65-be3546987e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-8993f74c-f235-4e98-921d-448a9a15e206,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-5ca83bca-31bc-49d4-8c4d-4ee277d67748,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-d00be379-9e34-42ba-965f-b30e25e7c6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-38ced881-3629-4784-85ed-d7b42677dd04,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-f9e62b99-8c02-4e4e-af8f-27022dce403f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-487027440-172.17.0.21-1597459078500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45734,DS-18247d16-c70b-44dd-b54e-62a3836cdd98,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-63ae9bc8-fb5f-4419-8120-c89802eb4d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-bd0997ae-b208-4d9e-9a1f-770b8c908320,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-b04dd503-5161-41dc-8362-a2158d4ca9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-6904a4fb-0675-44c3-a564-b0875d2dd358,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-c95ea8e9-6a49-4a5b-8936-e22ff2f22196,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-f7582d68-5586-41f4-8182-8ee9f0dbac46,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-60c4a582-2a00-4973-8505-df911055bab0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-487027440-172.17.0.21-1597459078500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45734,DS-18247d16-c70b-44dd-b54e-62a3836cdd98,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-63ae9bc8-fb5f-4419-8120-c89802eb4d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-bd0997ae-b208-4d9e-9a1f-770b8c908320,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-b04dd503-5161-41dc-8362-a2158d4ca9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-6904a4fb-0675-44c3-a564-b0875d2dd358,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-c95ea8e9-6a49-4a5b-8936-e22ff2f22196,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-f7582d68-5586-41f4-8182-8ee9f0dbac46,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-60c4a582-2a00-4973-8505-df911055bab0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846827406-172.17.0.21-1597459155707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44009,DS-6bd28f02-ff16-4269-8c72-d1e563bad064,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-58c8baea-0ca8-4b86-9103-911e18a28663,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-791ab027-749c-470d-9e4c-8ff0c4347077,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-18e76214-2a85-449d-bb2e-d674ad1a7a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-99cd206e-f419-4b79-8225-bd3f6a4c160a,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-49a89dc2-9eb5-4941-a4ed-d028ec340a98,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-33c39f6a-f0d3-46b4-8149-cf04c4338a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-059d0ef6-3f81-45bf-807e-73daafa7e27c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846827406-172.17.0.21-1597459155707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44009,DS-6bd28f02-ff16-4269-8c72-d1e563bad064,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-58c8baea-0ca8-4b86-9103-911e18a28663,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-791ab027-749c-470d-9e4c-8ff0c4347077,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-18e76214-2a85-449d-bb2e-d674ad1a7a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-99cd206e-f419-4b79-8225-bd3f6a4c160a,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-49a89dc2-9eb5-4941-a4ed-d028ec340a98,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-33c39f6a-f0d3-46b4-8149-cf04c4338a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-059d0ef6-3f81-45bf-807e-73daafa7e27c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-870911626-172.17.0.21-1597459234112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34239,DS-12d4e198-4b9e-4588-ac37-dc45a58b032a,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-029bd634-01e4-4b55-a251-029b9a1e801b,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-9ed3656a-3919-445d-ad25-0cafbdd27278,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-8038b907-4171-4bdf-967f-2b21ed886bde,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-6a2157f2-aaab-4f93-aac9-ea7613fb1714,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-9372876f-e4a0-4b02-9e7f-f84af5a12ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-f4c57f97-5949-4a70-8df7-bd0a5cad3a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-60161f19-0006-4d6f-8d22-83392f82349e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-870911626-172.17.0.21-1597459234112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34239,DS-12d4e198-4b9e-4588-ac37-dc45a58b032a,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-029bd634-01e4-4b55-a251-029b9a1e801b,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-9ed3656a-3919-445d-ad25-0cafbdd27278,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-8038b907-4171-4bdf-967f-2b21ed886bde,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-6a2157f2-aaab-4f93-aac9-ea7613fb1714,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-9372876f-e4a0-4b02-9e7f-f84af5a12ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-f4c57f97-5949-4a70-8df7-bd0a5cad3a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-60161f19-0006-4d6f-8d22-83392f82349e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455703859-172.17.0.21-1597459421257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45756,DS-e7e9e7ef-0c78-44aa-8bcc-a11fa63e7ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-bd545ced-2f5d-4bf2-a54a-60a256abe1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-02cb4d84-8fa7-45ca-b824-2fed3f17c257,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-2e4f2a68-0ddb-447d-a2d8-e0265691f4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-5bc0000e-35b6-4734-a734-253a86498362,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-3d538914-ee77-41cc-8d6d-07626b8746f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-d8429435-ec6f-4685-b770-b0b7c81eb428,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-625f4a81-c077-405b-af52-86537d96d485,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455703859-172.17.0.21-1597459421257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45756,DS-e7e9e7ef-0c78-44aa-8bcc-a11fa63e7ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:37591,DS-bd545ced-2f5d-4bf2-a54a-60a256abe1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-02cb4d84-8fa7-45ca-b824-2fed3f17c257,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-2e4f2a68-0ddb-447d-a2d8-e0265691f4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-5bc0000e-35b6-4734-a734-253a86498362,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-3d538914-ee77-41cc-8d6d-07626b8746f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-d8429435-ec6f-4685-b770-b0b7c81eb428,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-625f4a81-c077-405b-af52-86537d96d485,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926964585-172.17.0.21-1597459501952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44113,DS-6ddbe6ed-80fb-49e1-be79-619bcf732114,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-fc1e6b26-9f5b-46ac-8363-13dc6e7283be,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-b69dbca4-ee6c-4840-b14b-455713edcfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-a1845f87-3315-441d-98fb-f8c9a7377a52,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-d2f7a5d3-42f1-4269-ad13-f0737751d92d,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-c3e0b796-dbda-4601-aa65-ed1982ae6cec,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-deaa6771-f47b-44c4-a61d-0640c2965181,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-60d47b1e-b6cd-42f3-b7ec-191623523f21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926964585-172.17.0.21-1597459501952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44113,DS-6ddbe6ed-80fb-49e1-be79-619bcf732114,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-fc1e6b26-9f5b-46ac-8363-13dc6e7283be,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-b69dbca4-ee6c-4840-b14b-455713edcfe7,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-a1845f87-3315-441d-98fb-f8c9a7377a52,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-d2f7a5d3-42f1-4269-ad13-f0737751d92d,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-c3e0b796-dbda-4601-aa65-ed1982ae6cec,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-deaa6771-f47b-44c4-a61d-0640c2965181,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-60d47b1e-b6cd-42f3-b7ec-191623523f21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-786163951-172.17.0.21-1597459772802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39555,DS-ab5d6537-f355-45df-b973-20e271b3c6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-23f90335-e9c4-4430-9774-03d67276c6db,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-8b2d5364-91f1-4fab-8be4-51a9918b2144,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-1c288e3a-1519-4a54-a136-3b6d5913bf68,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-918cd292-021c-4a52-8f58-7a3622a6ab6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-b6d99dfb-f445-4a80-b61b-33555da01e50,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-c6896cb6-9093-413c-81a9-c6e427f83bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-aa09fecc-52f6-4bcf-965c-66edd7a6770c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-786163951-172.17.0.21-1597459772802:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39555,DS-ab5d6537-f355-45df-b973-20e271b3c6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-23f90335-e9c4-4430-9774-03d67276c6db,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-8b2d5364-91f1-4fab-8be4-51a9918b2144,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-1c288e3a-1519-4a54-a136-3b6d5913bf68,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-918cd292-021c-4a52-8f58-7a3622a6ab6c,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-b6d99dfb-f445-4a80-b61b-33555da01e50,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-c6896cb6-9093-413c-81a9-c6e427f83bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-aa09fecc-52f6-4bcf-965c-66edd7a6770c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1522082718-172.17.0.21-1597459847942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44057,DS-70b77b60-b25b-407e-9a95-497fe76d9ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-65d00a09-d2f5-46b6-94c8-fc577685fd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-c666990a-42b5-4e35-a632-6d636e61ceaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-104b3d45-da1b-40db-a0fa-24fc74a537f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-167892fb-f613-4bb1-8c4d-7f847e4b9e24,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-318c96c1-ce16-4d30-8abf-6ada0200abf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-2ef01f5f-7902-4b3c-a970-a202c7fde56b,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-6733f39f-59d9-4c35-9b2a-a4d7b67c29cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1522082718-172.17.0.21-1597459847942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44057,DS-70b77b60-b25b-407e-9a95-497fe76d9ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:36105,DS-65d00a09-d2f5-46b6-94c8-fc577685fd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-c666990a-42b5-4e35-a632-6d636e61ceaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35121,DS-104b3d45-da1b-40db-a0fa-24fc74a537f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-167892fb-f613-4bb1-8c4d-7f847e4b9e24,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-318c96c1-ce16-4d30-8abf-6ada0200abf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-2ef01f5f-7902-4b3c-a970-a202c7fde56b,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-6733f39f-59d9-4c35-9b2a-a4d7b67c29cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-390548687-172.17.0.21-1597460359016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42275,DS-2d108362-b5ea-4ba5-90f7-c8e06805513d,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-b0e884ed-a99a-43b9-9739-f26c8186245b,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-af5f7863-aae3-4c74-b9ec-f0ab6b608a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-e8db79fa-b15f-4549-8132-277ae264f00a,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-98a9cba2-cece-4130-ae70-d5e19863897b,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-64aed1f5-fb1a-4af2-956d-67b5717e0588,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-b594d0c5-b206-489e-bc6a-970f38711701,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-0a28beb5-1f2f-4d2e-a5ff-754db7867c63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-390548687-172.17.0.21-1597460359016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42275,DS-2d108362-b5ea-4ba5-90f7-c8e06805513d,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-b0e884ed-a99a-43b9-9739-f26c8186245b,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-af5f7863-aae3-4c74-b9ec-f0ab6b608a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46411,DS-e8db79fa-b15f-4549-8132-277ae264f00a,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-98a9cba2-cece-4130-ae70-d5e19863897b,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-64aed1f5-fb1a-4af2-956d-67b5717e0588,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-b594d0c5-b206-489e-bc6a-970f38711701,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-0a28beb5-1f2f-4d2e-a5ff-754db7867c63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235143038-172.17.0.21-1597460514530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39920,DS-37fe6679-b25a-486b-992f-9ebd3733bcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-37136142-850e-4d5b-9c5e-33ad875fca47,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-e3568fd2-4c71-418a-8338-341726aef69c,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-57b5f14d-5132-478c-8f61-b0a62950d5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-2b755b20-6873-4f90-b1d9-fc1b5637e8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-7903da4a-4853-4875-8af9-ceb834804388,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-5325ca11-c4b1-4623-9bda-39e67a6a3306,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-aca97329-42bc-4473-849a-7d3304c8658b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235143038-172.17.0.21-1597460514530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39920,DS-37fe6679-b25a-486b-992f-9ebd3733bcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-37136142-850e-4d5b-9c5e-33ad875fca47,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-e3568fd2-4c71-418a-8338-341726aef69c,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-57b5f14d-5132-478c-8f61-b0a62950d5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-2b755b20-6873-4f90-b1d9-fc1b5637e8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-7903da4a-4853-4875-8af9-ceb834804388,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-5325ca11-c4b1-4623-9bda-39e67a6a3306,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-aca97329-42bc-4473-849a-7d3304c8658b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-984437782-172.17.0.21-1597460605808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36180,DS-48b5b815-0f99-4c8a-9660-a8cb44e16784,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-aa64ecd8-a948-4164-b101-ec38697eb81a,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-926615ab-2431-45b8-812c-fc18d0a6d8be,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-12046422-88cf-4d82-a331-2ff4becd5420,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-84af1d27-6635-48e6-a53f-c42e5c97f8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-90a9238f-5d87-4dd6-86e2-87ca8da0da21,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-4f7c2ca0-0886-4bf8-9a9e-2dcb40380c83,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-f209b0a2-2181-49cd-8aae-387ada1e8565,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-984437782-172.17.0.21-1597460605808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36180,DS-48b5b815-0f99-4c8a-9660-a8cb44e16784,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-aa64ecd8-a948-4164-b101-ec38697eb81a,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-926615ab-2431-45b8-812c-fc18d0a6d8be,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-12046422-88cf-4d82-a331-2ff4becd5420,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-84af1d27-6635-48e6-a53f-c42e5c97f8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-90a9238f-5d87-4dd6-86e2-87ca8da0da21,DISK], DatanodeInfoWithStorage[127.0.0.1:38482,DS-4f7c2ca0-0886-4bf8-9a9e-2dcb40380c83,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-f209b0a2-2181-49cd-8aae-387ada1e8565,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560945090-172.17.0.21-1597460761113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41459,DS-b1452856-1b69-42ac-866f-e034c1e4e5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-983a13a1-00bf-4075-9b87-91651d3cb46c,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-a02b69b4-819f-4257-9f61-d518644ef712,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-bf785adf-293d-4014-bed9-dd8f7e16569d,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-b229d557-e9ce-468c-946a-a1507ee6ec71,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-9ada535e-dff8-4367-9939-d259e04daf24,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-c372e9f8-dd41-49a7-8b7c-1be2e2173c08,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-123aef4e-4564-4693-847f-88114a68c4f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-560945090-172.17.0.21-1597460761113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41459,DS-b1452856-1b69-42ac-866f-e034c1e4e5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-983a13a1-00bf-4075-9b87-91651d3cb46c,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-a02b69b4-819f-4257-9f61-d518644ef712,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-bf785adf-293d-4014-bed9-dd8f7e16569d,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-b229d557-e9ce-468c-946a-a1507ee6ec71,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-9ada535e-dff8-4367-9939-d259e04daf24,DISK], DatanodeInfoWithStorage[127.0.0.1:42744,DS-c372e9f8-dd41-49a7-8b7c-1be2e2173c08,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-123aef4e-4564-4693-847f-88114a68c4f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1687350263-172.17.0.21-1597460801254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35470,DS-02573fdb-2d09-4029-8500-18cd706d7413,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-447d9fd2-4826-4bc2-9c7c-49ce0c0cf376,DISK], DatanodeInfoWithStorage[127.0.0.1:41173,DS-a7d27777-1e66-47b7-9bd8-5264fea17c85,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-d5d01c19-0263-40f4-8721-bbb46571b11f,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-169ea39f-73f1-4ef2-b5e8-9e5a65599a03,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-8bb99e92-6a2a-4ed2-b68f-7a68d00e8ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-244a4cbc-a79e-4f34-8df9-8962b0b01597,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-43af3993-76af-4ed1-a6c7-4aeb69c332f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1687350263-172.17.0.21-1597460801254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35470,DS-02573fdb-2d09-4029-8500-18cd706d7413,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-447d9fd2-4826-4bc2-9c7c-49ce0c0cf376,DISK], DatanodeInfoWithStorage[127.0.0.1:41173,DS-a7d27777-1e66-47b7-9bd8-5264fea17c85,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-d5d01c19-0263-40f4-8721-bbb46571b11f,DISK], DatanodeInfoWithStorage[127.0.0.1:34997,DS-169ea39f-73f1-4ef2-b5e8-9e5a65599a03,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-8bb99e92-6a2a-4ed2-b68f-7a68d00e8ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:45343,DS-244a4cbc-a79e-4f34-8df9-8962b0b01597,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-43af3993-76af-4ed1-a6c7-4aeb69c332f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-937782533-172.17.0.21-1597461026982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36913,DS-1a49d0da-f09c-4ade-9105-8a8b223e52b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-24f30ba2-3bfb-44fd-9ba9-6c74f61086a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-0d3c1a7b-731c-4162-b132-d23ce8597980,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-4f16d153-98ac-441e-aa8e-80893b0f45fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-16a55fa9-826f-4ece-ba51-ba7f51760f60,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-f06b208d-28bd-403b-9198-483082e63f35,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-da882139-6dba-44d4-b57e-dd92d513f62f,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-79d791aa-3fc7-478a-bca3-99a0e1a00f66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-937782533-172.17.0.21-1597461026982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36913,DS-1a49d0da-f09c-4ade-9105-8a8b223e52b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-24f30ba2-3bfb-44fd-9ba9-6c74f61086a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-0d3c1a7b-731c-4162-b132-d23ce8597980,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-4f16d153-98ac-441e-aa8e-80893b0f45fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-16a55fa9-826f-4ece-ba51-ba7f51760f60,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-f06b208d-28bd-403b-9198-483082e63f35,DISK], DatanodeInfoWithStorage[127.0.0.1:39725,DS-da882139-6dba-44d4-b57e-dd92d513f62f,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-79d791aa-3fc7-478a-bca3-99a0e1a00f66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.resource.check.interval
component: hdfs:NameNode
v1: 50000
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-338374141-172.17.0.21-1597461178225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35934,DS-873f8bf9-aedc-4625-878d-efa5a4ac9af4,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-b088d27c-1810-40d8-9f1f-ef432e521ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-c55a1195-fcbf-43a9-90e2-57f4a9c9952f,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-f8c8c77f-5aa1-4381-9ef3-9d3d5bdc4835,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-f7550039-25f6-4b90-b263-c5920b90cbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-3cbb4356-4720-4960-948c-ccf06ec33fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-d13bfe7b-359d-478b-8997-d8cbb5af54c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-d1a9741a-f1a8-46ff-a6f1-fad115cd4da2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-338374141-172.17.0.21-1597461178225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35934,DS-873f8bf9-aedc-4625-878d-efa5a4ac9af4,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-b088d27c-1810-40d8-9f1f-ef432e521ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-c55a1195-fcbf-43a9-90e2-57f4a9c9952f,DISK], DatanodeInfoWithStorage[127.0.0.1:42737,DS-f8c8c77f-5aa1-4381-9ef3-9d3d5bdc4835,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-f7550039-25f6-4b90-b263-c5920b90cbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-3cbb4356-4720-4960-948c-ccf06ec33fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44636,DS-d13bfe7b-359d-478b-8997-d8cbb5af54c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-d1a9741a-f1a8-46ff-a6f1-fad115cd4da2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5771
