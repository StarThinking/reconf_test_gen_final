reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633298768-172.17.0.4-1597331485260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34896,DS-83f059a2-f05c-4175-96e4-d71a441c1d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-4240443b-c809-4bdb-8bd1-3dbc8e8cee36,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-df49827d-b96c-4439-b637-436db8063521,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-fda2e359-6673-4488-aefd-6f5a7893d24a,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-18f5e1c3-863a-4b5e-826f-2dec538838e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-5674e8c3-788b-443d-bfb3-facb918eadcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-32779eea-94ee-4e5e-8204-9fde9050cd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-46982cfe-c4c2-4165-af7c-2aed114f82d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633298768-172.17.0.4-1597331485260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34896,DS-83f059a2-f05c-4175-96e4-d71a441c1d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-4240443b-c809-4bdb-8bd1-3dbc8e8cee36,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-df49827d-b96c-4439-b637-436db8063521,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-fda2e359-6673-4488-aefd-6f5a7893d24a,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-18f5e1c3-863a-4b5e-826f-2dec538838e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-5674e8c3-788b-443d-bfb3-facb918eadcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-32779eea-94ee-4e5e-8204-9fde9050cd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-46982cfe-c4c2-4165-af7c-2aed114f82d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1499448931-172.17.0.4-1597331945752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34264,DS-21225987-22cb-4287-9c6c-33269314bab4,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-8432b444-22f4-469c-b3f8-32390cafb8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-47f28e75-02e6-40b0-9d4e-8089305c75b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-134e3996-a0ac-4e97-a561-6cdd6afee363,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-9b505ada-251b-4550-9730-d73fdde2047a,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-cd282bf2-8994-4cc1-bb22-b9ed7fd7fd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-730de595-0885-4367-994b-c225d4fe6fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-9a3dd929-19dc-49c3-a271-bc4974124deb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1499448931-172.17.0.4-1597331945752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34264,DS-21225987-22cb-4287-9c6c-33269314bab4,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-8432b444-22f4-469c-b3f8-32390cafb8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-47f28e75-02e6-40b0-9d4e-8089305c75b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-134e3996-a0ac-4e97-a561-6cdd6afee363,DISK], DatanodeInfoWithStorage[127.0.0.1:46481,DS-9b505ada-251b-4550-9730-d73fdde2047a,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-cd282bf2-8994-4cc1-bb22-b9ed7fd7fd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45602,DS-730de595-0885-4367-994b-c225d4fe6fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-9a3dd929-19dc-49c3-a271-bc4974124deb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1288868941-172.17.0.4-1597332020247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35341,DS-5187e28f-3246-468a-9793-f0f8a19b2e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-e33ba124-ada7-42b7-8456-b90dea9cf374,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-ef3f7a18-aae8-49e1-ba10-7ce960d107d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-870f0ea2-4656-4e01-aad4-7d3589cf79f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-b3d0a954-2a0b-40bd-8059-659a6db65e26,DISK], DatanodeInfoWithStorage[127.0.0.1:42223,DS-a1bd1285-28ec-4100-b075-3e312f7d5d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-9acdae65-78ac-41fe-b3e0-f26b4ee72c57,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-1352c2a3-0dad-4173-a84e-6b62b1b2bc73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1288868941-172.17.0.4-1597332020247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35341,DS-5187e28f-3246-468a-9793-f0f8a19b2e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-e33ba124-ada7-42b7-8456-b90dea9cf374,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-ef3f7a18-aae8-49e1-ba10-7ce960d107d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-870f0ea2-4656-4e01-aad4-7d3589cf79f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-b3d0a954-2a0b-40bd-8059-659a6db65e26,DISK], DatanodeInfoWithStorage[127.0.0.1:42223,DS-a1bd1285-28ec-4100-b075-3e312f7d5d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-9acdae65-78ac-41fe-b3e0-f26b4ee72c57,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-1352c2a3-0dad-4173-a84e-6b62b1b2bc73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-321716341-172.17.0.4-1597332195020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43598,DS-9bc13825-bccf-4adc-a2de-113b40cc792e,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-d349ffd9-9a81-41c1-b561-6288651d18e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-4478ac71-f297-4484-bfad-b70fe31653bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-d68af90f-db1d-47ae-b9d2-514dccabe138,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-c7b5dcdc-7041-4bb6-9bc9-120829d31429,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-ee6e6f44-3dbe-4aaf-9f05-85fdba1ff474,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-4a35cf04-b4c8-4d2c-8148-545ad6df5d67,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-770db579-71df-464b-98e6-323057c491ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-321716341-172.17.0.4-1597332195020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43598,DS-9bc13825-bccf-4adc-a2de-113b40cc792e,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-d349ffd9-9a81-41c1-b561-6288651d18e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-4478ac71-f297-4484-bfad-b70fe31653bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33409,DS-d68af90f-db1d-47ae-b9d2-514dccabe138,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-c7b5dcdc-7041-4bb6-9bc9-120829d31429,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-ee6e6f44-3dbe-4aaf-9f05-85fdba1ff474,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-4a35cf04-b4c8-4d2c-8148-545ad6df5d67,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-770db579-71df-464b-98e6-323057c491ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1666181095-172.17.0.4-1597332744479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37405,DS-1fa5cb8a-959d-4d1a-ad15-4ef55e1482b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-0197befe-9f20-47e3-9666-11cd03c1afbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-45d8c832-320a-4d30-9600-f417f5ae1c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-a2ac7a6f-6d9d-477c-8857-85540b3aca3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-c079ebed-cbec-44fa-bca4-6588ed890d54,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-bfacb0af-446a-420c-b472-fe2cc2f6579c,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-49abf2e0-7715-4d69-b4ab-2fc7b2eb1ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-e4c48e1d-efe4-4415-b4bb-ae73705f2c98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1666181095-172.17.0.4-1597332744479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37405,DS-1fa5cb8a-959d-4d1a-ad15-4ef55e1482b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-0197befe-9f20-47e3-9666-11cd03c1afbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-45d8c832-320a-4d30-9600-f417f5ae1c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-a2ac7a6f-6d9d-477c-8857-85540b3aca3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-c079ebed-cbec-44fa-bca4-6588ed890d54,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-bfacb0af-446a-420c-b472-fe2cc2f6579c,DISK], DatanodeInfoWithStorage[127.0.0.1:44734,DS-49abf2e0-7715-4d69-b4ab-2fc7b2eb1ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-e4c48e1d-efe4-4415-b4bb-ae73705f2c98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1531001172-172.17.0.4-1597332772313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36254,DS-7e1fac49-3bc1-4d04-b102-82c4792db5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-5db508db-9fcc-4c49-b6ce-288886ee7dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-ac4bac9a-0a47-4a4d-8aa9-cc05d4a5a867,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-8d2bebbb-a1ee-4ced-a765-f48865e8cd13,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-7a20c519-d6d6-440a-a743-9ab82a944897,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-73a3cc77-a9eb-4277-828a-ac5cf96cf930,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-1a47e2fb-fca1-417a-acd3-ac8172f9894a,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-1d4e4508-bd40-40e5-88c5-0ede15887921,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1531001172-172.17.0.4-1597332772313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36254,DS-7e1fac49-3bc1-4d04-b102-82c4792db5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-5db508db-9fcc-4c49-b6ce-288886ee7dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-ac4bac9a-0a47-4a4d-8aa9-cc05d4a5a867,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-8d2bebbb-a1ee-4ced-a765-f48865e8cd13,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-7a20c519-d6d6-440a-a743-9ab82a944897,DISK], DatanodeInfoWithStorage[127.0.0.1:37117,DS-73a3cc77-a9eb-4277-828a-ac5cf96cf930,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-1a47e2fb-fca1-417a-acd3-ac8172f9894a,DISK], DatanodeInfoWithStorage[127.0.0.1:39387,DS-1d4e4508-bd40-40e5-88c5-0ede15887921,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-115528749-172.17.0.4-1597332920107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44227,DS-8e373e60-a43d-4daf-99d3-db0aa55b05c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-ad9ea41a-d034-4acc-a43a-c7d353c47bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-96ad1429-5cd4-413c-a5bd-acdfaad19a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-0aad7dbb-0f62-4110-a63b-e9b8f8044f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-dd5ad43b-ad82-440d-8d34-5a241359eac6,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-9260ed60-fc3f-4a4d-84ef-b2cee368642f,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-8b4f49d4-fa53-4dbc-ae6b-c0dc471ac64c,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-8d077098-7ab8-47ac-8ca4-2de360936f47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-115528749-172.17.0.4-1597332920107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44227,DS-8e373e60-a43d-4daf-99d3-db0aa55b05c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35948,DS-ad9ea41a-d034-4acc-a43a-c7d353c47bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-96ad1429-5cd4-413c-a5bd-acdfaad19a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-0aad7dbb-0f62-4110-a63b-e9b8f8044f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-dd5ad43b-ad82-440d-8d34-5a241359eac6,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-9260ed60-fc3f-4a4d-84ef-b2cee368642f,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-8b4f49d4-fa53-4dbc-ae6b-c0dc471ac64c,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-8d077098-7ab8-47ac-8ca4-2de360936f47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1600462532-172.17.0.4-1597334012654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41571,DS-45aa1267-26f5-446d-a7f2-4226070f66d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-93eee239-2ee6-494b-ad5c-b877c2c8239f,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-d30073ec-247f-42b3-bc4a-d2824c21636e,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-8a95b8a1-0418-48dc-a8c5-124dfe148cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-2dfae057-2043-4731-8145-9c33e2c7fe73,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-c066c4af-3a34-4d4f-bbe4-0dd25d26253f,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-7e414031-6627-4082-83d8-d63e0296daf4,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-420d182f-5ed5-444e-b5a6-885f99c51c61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1600462532-172.17.0.4-1597334012654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41571,DS-45aa1267-26f5-446d-a7f2-4226070f66d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-93eee239-2ee6-494b-ad5c-b877c2c8239f,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-d30073ec-247f-42b3-bc4a-d2824c21636e,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-8a95b8a1-0418-48dc-a8c5-124dfe148cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33547,DS-2dfae057-2043-4731-8145-9c33e2c7fe73,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-c066c4af-3a34-4d4f-bbe4-0dd25d26253f,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-7e414031-6627-4082-83d8-d63e0296daf4,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-420d182f-5ed5-444e-b5a6-885f99c51c61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1191006437-172.17.0.4-1597334672186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41651,DS-ec42eb4e-70c2-4b93-9d59-3da473aaeff1,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-2d8332d9-3a78-43ff-ad9e-43033ee95768,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-d8a502bb-a472-453d-b5df-b42f9f352e35,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-3ac9b2e3-bd8b-4bba-ad2e-8e834a0a4299,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-e9a9f23f-7ebc-460f-9783-3240fd491a80,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-d985c036-4447-4ad7-a272-394632537cad,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-40d36bf6-3042-4605-9e7e-4bd0defca2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-edfca43a-eeb9-4b9d-bd7d-77b0ec96b9fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1191006437-172.17.0.4-1597334672186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41651,DS-ec42eb4e-70c2-4b93-9d59-3da473aaeff1,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-2d8332d9-3a78-43ff-ad9e-43033ee95768,DISK], DatanodeInfoWithStorage[127.0.0.1:44116,DS-d8a502bb-a472-453d-b5df-b42f9f352e35,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-3ac9b2e3-bd8b-4bba-ad2e-8e834a0a4299,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-e9a9f23f-7ebc-460f-9783-3240fd491a80,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-d985c036-4447-4ad7-a272-394632537cad,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-40d36bf6-3042-4605-9e7e-4bd0defca2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-edfca43a-eeb9-4b9d-bd7d-77b0ec96b9fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1342953826-172.17.0.4-1597334825636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40292,DS-84914a48-9dca-46dd-ac50-b19217fd9b45,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-63475c3c-5ca3-4c90-bd9d-3a8e5ba6a3af,DISK], DatanodeInfoWithStorage[127.0.0.1:42364,DS-c27d90b5-1681-47af-b6bb-3ce0435463a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-1409535a-48ea-41e9-8cfc-2135732938b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-3c6396af-81f3-4ff9-91dc-d769ce47b826,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-c9f29510-9fb8-4afb-ae0f-e05966c55803,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-a01a8edb-b73d-425e-b072-b04b3e1c6fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-cdd2f2b3-7ac9-42bf-bc1d-5154d7ead738,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1342953826-172.17.0.4-1597334825636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40292,DS-84914a48-9dca-46dd-ac50-b19217fd9b45,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-63475c3c-5ca3-4c90-bd9d-3a8e5ba6a3af,DISK], DatanodeInfoWithStorage[127.0.0.1:42364,DS-c27d90b5-1681-47af-b6bb-3ce0435463a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-1409535a-48ea-41e9-8cfc-2135732938b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-3c6396af-81f3-4ff9-91dc-d769ce47b826,DISK], DatanodeInfoWithStorage[127.0.0.1:42557,DS-c9f29510-9fb8-4afb-ae0f-e05966c55803,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-a01a8edb-b73d-425e-b072-b04b3e1c6fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-cdd2f2b3-7ac9-42bf-bc1d-5154d7ead738,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-241606486-172.17.0.4-1597335296116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46468,DS-861e351d-baf1-4aca-b8e7-285e36252705,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-c688435f-a7d6-4ce9-902f-f3404bf305d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-7885426e-a420-49fe-b1e8-4a523768c990,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-d7f9aa4c-2f4c-4785-bf0f-06785061bdce,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-a6ee5549-0c1e-4906-bed5-2fa8101bb9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-809f7dfe-bc89-4cb9-abfa-e935f675a135,DISK], DatanodeInfoWithStorage[127.0.0.1:45119,DS-882eb020-edb9-49d4-ba9b-e1820a76879c,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-db903a3e-52ba-458a-b78f-b8ea57225e8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-241606486-172.17.0.4-1597335296116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46468,DS-861e351d-baf1-4aca-b8e7-285e36252705,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-c688435f-a7d6-4ce9-902f-f3404bf305d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-7885426e-a420-49fe-b1e8-4a523768c990,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-d7f9aa4c-2f4c-4785-bf0f-06785061bdce,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-a6ee5549-0c1e-4906-bed5-2fa8101bb9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-809f7dfe-bc89-4cb9-abfa-e935f675a135,DISK], DatanodeInfoWithStorage[127.0.0.1:45119,DS-882eb020-edb9-49d4-ba9b-e1820a76879c,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-db903a3e-52ba-458a-b78f-b8ea57225e8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-400260496-172.17.0.4-1597335523640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35352,DS-f76221fc-04d5-4f0f-af83-03d8aa149a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-3de509c1-bf2d-4018-85a9-60adf3adb9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-71aebede-024b-439f-97c2-bb8c6c817b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-f352d0c3-746f-43f3-a904-22a64acf3652,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-fdfa3d7b-8196-4596-a870-bcec2429d764,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-f08bf0ea-f073-4070-a344-267289555584,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-b1d49d5d-8de8-4506-af55-0bdaa5b03a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-269ae5c0-037a-45e0-abe9-5ac48c83d2e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-400260496-172.17.0.4-1597335523640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35352,DS-f76221fc-04d5-4f0f-af83-03d8aa149a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-3de509c1-bf2d-4018-85a9-60adf3adb9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-71aebede-024b-439f-97c2-bb8c6c817b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34653,DS-f352d0c3-746f-43f3-a904-22a64acf3652,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-fdfa3d7b-8196-4596-a870-bcec2429d764,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-f08bf0ea-f073-4070-a344-267289555584,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-b1d49d5d-8de8-4506-af55-0bdaa5b03a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-269ae5c0-037a-45e0-abe9-5ac48c83d2e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5422
