reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1961855153-172.17.0.18-1597298264101:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39999,DS-ca97ccb0-16bb-4d57-9ff5-b7e3de9990a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-98541395-ce8a-4a71-a889-8eba09459b48,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-c685b4df-0db7-4af4-b918-5a420add4caa,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-d0a28d62-c0c4-4ae1-af7d-68f1393c14c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-e1bb92b5-577b-4eee-8fe0-5688c1ac191b,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-a394fdc6-f93c-4faf-8cfc-9c43a83e1dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-f5259032-a534-4430-bd16-75b5c650aa6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-63c04423-bc7e-4795-b786-9eced6ea238b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1961855153-172.17.0.18-1597298264101:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39999,DS-ca97ccb0-16bb-4d57-9ff5-b7e3de9990a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-98541395-ce8a-4a71-a889-8eba09459b48,DISK], DatanodeInfoWithStorage[127.0.0.1:38161,DS-c685b4df-0db7-4af4-b918-5a420add4caa,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-d0a28d62-c0c4-4ae1-af7d-68f1393c14c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-e1bb92b5-577b-4eee-8fe0-5688c1ac191b,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-a394fdc6-f93c-4faf-8cfc-9c43a83e1dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-f5259032-a534-4430-bd16-75b5c650aa6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-63c04423-bc7e-4795-b786-9eced6ea238b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-168317421-172.17.0.18-1597298305516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36056,DS-3352494b-aceb-4a07-988a-c3f81e66bac4,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-568cec14-3ef3-4b5f-ac6d-5c974d1ec0da,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-6f01343b-9ad3-417c-8346-35384781200d,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-b0dd8259-e886-4913-953a-116d7a934eac,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-658b32bc-ab3e-40c7-8555-6ad2b777042b,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-aafa4f86-c53d-4c36-97b5-0f4ffd74a58b,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-d967f2f2-a06d-4b14-85a1-e0c2a714319c,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-937738f1-fa5e-4295-8939-004a9fc8ef14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-168317421-172.17.0.18-1597298305516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36056,DS-3352494b-aceb-4a07-988a-c3f81e66bac4,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-568cec14-3ef3-4b5f-ac6d-5c974d1ec0da,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-6f01343b-9ad3-417c-8346-35384781200d,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-b0dd8259-e886-4913-953a-116d7a934eac,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-658b32bc-ab3e-40c7-8555-6ad2b777042b,DISK], DatanodeInfoWithStorage[127.0.0.1:40772,DS-aafa4f86-c53d-4c36-97b5-0f4ffd74a58b,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-d967f2f2-a06d-4b14-85a1-e0c2a714319c,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-937738f1-fa5e-4295-8939-004a9fc8ef14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1999511757-172.17.0.18-1597299149134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37874,DS-520a15ef-d848-4233-8b37-ab372379574f,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-dbdbae79-c6e8-48e7-9196-fd93245f632a,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-ee23e3fc-9f05-496e-b10b-738c0a924d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-3406cc7a-0d8b-4f8e-b34f-c3d39bce62e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-673caafe-b5ef-473b-8e33-4dc0f1aa9ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-41574e8f-cf16-431d-89d8-ba50df3e15a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-d07de861-a2a3-47ff-8296-b93583a3d8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-9b71eec6-f709-430b-a105-4e4de8f4fae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1999511757-172.17.0.18-1597299149134:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37874,DS-520a15ef-d848-4233-8b37-ab372379574f,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-dbdbae79-c6e8-48e7-9196-fd93245f632a,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-ee23e3fc-9f05-496e-b10b-738c0a924d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-3406cc7a-0d8b-4f8e-b34f-c3d39bce62e7,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-673caafe-b5ef-473b-8e33-4dc0f1aa9ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-41574e8f-cf16-431d-89d8-ba50df3e15a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-d07de861-a2a3-47ff-8296-b93583a3d8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-9b71eec6-f709-430b-a105-4e4de8f4fae8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1503677294-172.17.0.18-1597299416988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38000,DS-ef0b78d4-f0b4-429d-8985-3b34fa610b98,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-2e0b29c9-300c-4288-88cd-c4c087894c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-aeffae06-9d8d-42e1-b7b3-9abd79d6e906,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-4fd79850-0e72-4e58-b558-221bbbf4af2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-5e864f3e-1d95-4538-8fb6-f12c95354430,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-b9d10cfd-eef4-4654-93f1-cf4dfe1c3933,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-b220a3ac-84c7-4e11-89cf-556ab9ade65a,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-bcdd3303-5bcc-4ff5-b37a-eb55bcb5b078,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1503677294-172.17.0.18-1597299416988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38000,DS-ef0b78d4-f0b4-429d-8985-3b34fa610b98,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-2e0b29c9-300c-4288-88cd-c4c087894c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-aeffae06-9d8d-42e1-b7b3-9abd79d6e906,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-4fd79850-0e72-4e58-b558-221bbbf4af2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-5e864f3e-1d95-4538-8fb6-f12c95354430,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-b9d10cfd-eef4-4654-93f1-cf4dfe1c3933,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-b220a3ac-84c7-4e11-89cf-556ab9ade65a,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-bcdd3303-5bcc-4ff5-b37a-eb55bcb5b078,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-179752527-172.17.0.18-1597299519941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38824,DS-59f165e1-8f11-4c74-b463-4adb60f89e24,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-aadf13a6-7791-4a07-a151-566fa6f90035,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-e784860a-d0ca-48b4-827d-2616bf2db4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-17072a6c-5f45-4aa6-a9b5-9d7108339674,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-47b9b966-fc05-4a54-ae78-73c64c3f52e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-1c5676c9-223e-433b-9768-e0005074fbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-0239940d-79b7-4dee-8df3-12924bfd75e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-b99fe473-6a32-4559-95e8-bf8bf367bdc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-179752527-172.17.0.18-1597299519941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38824,DS-59f165e1-8f11-4c74-b463-4adb60f89e24,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-aadf13a6-7791-4a07-a151-566fa6f90035,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-e784860a-d0ca-48b4-827d-2616bf2db4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-17072a6c-5f45-4aa6-a9b5-9d7108339674,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-47b9b966-fc05-4a54-ae78-73c64c3f52e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38382,DS-1c5676c9-223e-433b-9768-e0005074fbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-0239940d-79b7-4dee-8df3-12924bfd75e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-b99fe473-6a32-4559-95e8-bf8bf367bdc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1989588782-172.17.0.18-1597300099287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36454,DS-9236f6cb-380d-428e-83b8-ebd3876a8490,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-dd147e4a-8340-43fc-841b-298b232d1d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-e1aa596a-e19a-4bfd-ae8d-97d969658a52,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-29b83d08-8dde-41ae-925e-77ebd0e9e1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-bd3cb735-1bf6-4b0e-940f-db1a3b05d976,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-f4a2b113-1c1a-4711-be68-63e317e93820,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-48e0beb1-46e1-400e-ad14-ee80a2c6e015,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-f33a342e-2ddb-47d7-8bce-3bdec083a806,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1989588782-172.17.0.18-1597300099287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36454,DS-9236f6cb-380d-428e-83b8-ebd3876a8490,DISK], DatanodeInfoWithStorage[127.0.0.1:38013,DS-dd147e4a-8340-43fc-841b-298b232d1d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-e1aa596a-e19a-4bfd-ae8d-97d969658a52,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-29b83d08-8dde-41ae-925e-77ebd0e9e1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-bd3cb735-1bf6-4b0e-940f-db1a3b05d976,DISK], DatanodeInfoWithStorage[127.0.0.1:40378,DS-f4a2b113-1c1a-4711-be68-63e317e93820,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-48e0beb1-46e1-400e-ad14-ee80a2c6e015,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-f33a342e-2ddb-47d7-8bce-3bdec083a806,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1595490371-172.17.0.18-1597300178021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39926,DS-2a058c92-8653-4448-a1d4-d81aef9166a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-da08d983-d72b-443a-a0f8-e4728292a395,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-9ec5cd77-5153-46c3-8b26-d339ff5e5002,DISK], DatanodeInfoWithStorage[127.0.0.1:36156,DS-313ee7a4-a92c-40dd-b250-dc5352d442e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-87625a27-1969-4351-a6d0-426830e02c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-c54e2906-9a12-4941-a30f-6bab30a44c31,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-f25e7661-9bf4-4c8e-93bc-6b1a9d3fc481,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-c789fe61-75c4-402e-9ab3-5c236b8a7a86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1595490371-172.17.0.18-1597300178021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39926,DS-2a058c92-8653-4448-a1d4-d81aef9166a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-da08d983-d72b-443a-a0f8-e4728292a395,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-9ec5cd77-5153-46c3-8b26-d339ff5e5002,DISK], DatanodeInfoWithStorage[127.0.0.1:36156,DS-313ee7a4-a92c-40dd-b250-dc5352d442e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-87625a27-1969-4351-a6d0-426830e02c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41835,DS-c54e2906-9a12-4941-a30f-6bab30a44c31,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-f25e7661-9bf4-4c8e-93bc-6b1a9d3fc481,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-c789fe61-75c4-402e-9ab3-5c236b8a7a86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1728885616-172.17.0.18-1597300323239:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41356,DS-cfaa8be3-76b7-4d73-9b42-7b5717ce2cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-30f19331-4d1d-47cf-b121-f63a53ae53f6,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-2b1733fb-b9df-4dc0-a479-8433441376eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-5c4605a5-b265-4f2d-bf11-9bd388193d83,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-03b38366-770d-4414-bdf3-363b79e4e346,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-f139e7d9-12cd-4c5b-ad0e-b0200f024c12,DISK], DatanodeInfoWithStorage[127.0.0.1:34253,DS-7d5ef565-a545-4c11-bc0e-84fcb899bdb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-611bfde8-b4a2-471b-8f5f-ea08ed40c9da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1728885616-172.17.0.18-1597300323239:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41356,DS-cfaa8be3-76b7-4d73-9b42-7b5717ce2cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37923,DS-30f19331-4d1d-47cf-b121-f63a53ae53f6,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-2b1733fb-b9df-4dc0-a479-8433441376eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39413,DS-5c4605a5-b265-4f2d-bf11-9bd388193d83,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-03b38366-770d-4414-bdf3-363b79e4e346,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-f139e7d9-12cd-4c5b-ad0e-b0200f024c12,DISK], DatanodeInfoWithStorage[127.0.0.1:34253,DS-7d5ef565-a545-4c11-bc0e-84fcb899bdb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-611bfde8-b4a2-471b-8f5f-ea08ed40c9da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1770952786-172.17.0.18-1597300473701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36670,DS-b3b13cb3-6a8c-43aa-8367-6a1bbc03fcb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-b9816a91-4a60-4a6f-bebd-f2fb57a60772,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-7f270b12-bf90-4537-9ccf-9f9c531ddc32,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-b7a0bdfd-a622-4719-8573-f9fbbdbb9f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-cf5ca66a-5ab3-4564-b862-9d7cea3c2530,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-e7139071-da8a-409a-a515-8e144a7535f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-a78ec6d0-0e56-45a5-91ac-5407260fb6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46502,DS-d752db8c-5900-4306-a03c-ae3474df3896,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1770952786-172.17.0.18-1597300473701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36670,DS-b3b13cb3-6a8c-43aa-8367-6a1bbc03fcb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-b9816a91-4a60-4a6f-bebd-f2fb57a60772,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-7f270b12-bf90-4537-9ccf-9f9c531ddc32,DISK], DatanodeInfoWithStorage[127.0.0.1:36951,DS-b7a0bdfd-a622-4719-8573-f9fbbdbb9f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-cf5ca66a-5ab3-4564-b862-9d7cea3c2530,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-e7139071-da8a-409a-a515-8e144a7535f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-a78ec6d0-0e56-45a5-91ac-5407260fb6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46502,DS-d752db8c-5900-4306-a03c-ae3474df3896,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1965333287-172.17.0.18-1597300515481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33469,DS-02364c52-ca2c-4c3b-9518-dd27221d368b,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-08440ed6-cfb0-408d-b3bc-f7e61ad1fe1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-87cf0034-87f1-47f9-9c5c-36e77da66e05,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-ac9af97d-b8cc-46a0-a1a1-7c8ca44d525d,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-e7637dcd-41ec-447a-8f66-7ab4d9d13dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-31078548-87c6-46fa-bba2-0b66caa13ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-041c41de-909b-48a0-b97d-6d7462ddf213,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-95b654ea-b3d1-43cc-81ae-47a687bf2e6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1965333287-172.17.0.18-1597300515481:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33469,DS-02364c52-ca2c-4c3b-9518-dd27221d368b,DISK], DatanodeInfoWithStorage[127.0.0.1:46624,DS-08440ed6-cfb0-408d-b3bc-f7e61ad1fe1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45151,DS-87cf0034-87f1-47f9-9c5c-36e77da66e05,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-ac9af97d-b8cc-46a0-a1a1-7c8ca44d525d,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-e7637dcd-41ec-447a-8f66-7ab4d9d13dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44776,DS-31078548-87c6-46fa-bba2-0b66caa13ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-041c41de-909b-48a0-b97d-6d7462ddf213,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-95b654ea-b3d1-43cc-81ae-47a687bf2e6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-307468450-172.17.0.18-1597300652906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39666,DS-a282efbe-c4a9-4965-82d8-31c50eeb0571,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-8464bb3b-9eb2-4df3-b5e7-c201480e75e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-00d66fe6-2ddf-45a5-bef1-816012d8b24f,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-64a9d925-62fa-41dc-a66c-ae74ce474628,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-51ee8336-1c3c-4e0e-909d-27b557649c34,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-5651de9d-aae2-4c9d-ad29-9cd4d6075aef,DISK], DatanodeInfoWithStorage[127.0.0.1:36890,DS-6640729d-a124-4029-8d3e-492daeb4498c,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-122fb01c-b45d-4223-96af-0c3c8c43a0ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-307468450-172.17.0.18-1597300652906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39666,DS-a282efbe-c4a9-4965-82d8-31c50eeb0571,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-8464bb3b-9eb2-4df3-b5e7-c201480e75e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-00d66fe6-2ddf-45a5-bef1-816012d8b24f,DISK], DatanodeInfoWithStorage[127.0.0.1:34145,DS-64a9d925-62fa-41dc-a66c-ae74ce474628,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-51ee8336-1c3c-4e0e-909d-27b557649c34,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-5651de9d-aae2-4c9d-ad29-9cd4d6075aef,DISK], DatanodeInfoWithStorage[127.0.0.1:36890,DS-6640729d-a124-4029-8d3e-492daeb4498c,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-122fb01c-b45d-4223-96af-0c3c8c43a0ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1132398644-172.17.0.18-1597300722123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41870,DS-54e0883b-dd55-4caa-be70-9628bdb4ac0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-4237d31e-7c13-42a7-8cc0-c1fd13250838,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-82b10924-383b-436a-93db-b424bd36f1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-e1cea54b-e31b-4e14-a42b-1d290023fa44,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-273309f6-c87e-459f-b1a1-53d99931fd99,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-3c0f18cb-b8fb-473c-be72-8ec97096fedc,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-1240dc86-4085-4014-a863-2ce353dbc838,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-e7513e14-0ae9-4ce5-83e9-d573cf8c4f30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1132398644-172.17.0.18-1597300722123:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41870,DS-54e0883b-dd55-4caa-be70-9628bdb4ac0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-4237d31e-7c13-42a7-8cc0-c1fd13250838,DISK], DatanodeInfoWithStorage[127.0.0.1:43599,DS-82b10924-383b-436a-93db-b424bd36f1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-e1cea54b-e31b-4e14-a42b-1d290023fa44,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-273309f6-c87e-459f-b1a1-53d99931fd99,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-3c0f18cb-b8fb-473c-be72-8ec97096fedc,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-1240dc86-4085-4014-a863-2ce353dbc838,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-e7513e14-0ae9-4ce5-83e9-d573cf8c4f30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-165602323-172.17.0.18-1597301114452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42165,DS-01446d7b-545d-4fbb-9bfa-fcd93d261863,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-3f2f953f-41bf-483a-96d8-b2c8637bb42a,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-3d206f79-62f2-4827-8ae0-e95e35719c56,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-7c41e971-979a-4ed8-9bc8-a2897a89be9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-f076b143-5b54-4c99-8948-4266be4fc621,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-ca64574e-c503-432e-abd8-548e953df6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-9f1ee7e6-37a1-4c78-9052-e87b67ace5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-bb02750d-f557-4482-b839-6391aa8e2c0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-165602323-172.17.0.18-1597301114452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42165,DS-01446d7b-545d-4fbb-9bfa-fcd93d261863,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-3f2f953f-41bf-483a-96d8-b2c8637bb42a,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-3d206f79-62f2-4827-8ae0-e95e35719c56,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-7c41e971-979a-4ed8-9bc8-a2897a89be9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-f076b143-5b54-4c99-8948-4266be4fc621,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-ca64574e-c503-432e-abd8-548e953df6ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-9f1ee7e6-37a1-4c78-9052-e87b67ace5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-bb02750d-f557-4482-b839-6391aa8e2c0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1311776013-172.17.0.18-1597301300312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46204,DS-8d36efcd-b094-449c-811d-1fd06444b9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-9dca3f0f-5e79-4e83-9419-538583f966f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-92c2c468-6735-40b4-b2dd-8b4c9d120ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-b0c6ba6d-d81c-4a60-b65d-7db71a0bb917,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-60e12e39-21c6-4ccb-a34f-a1affff30eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-c62fccc1-f344-4192-bf20-7aca24db7ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-d43ac47c-f567-4209-94d4-f88e8b97b29c,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-e3490e5d-a491-496d-95ed-1c169305cff1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1311776013-172.17.0.18-1597301300312:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46204,DS-8d36efcd-b094-449c-811d-1fd06444b9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40053,DS-9dca3f0f-5e79-4e83-9419-538583f966f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44096,DS-92c2c468-6735-40b4-b2dd-8b4c9d120ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-b0c6ba6d-d81c-4a60-b65d-7db71a0bb917,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-60e12e39-21c6-4ccb-a34f-a1affff30eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-c62fccc1-f344-4192-bf20-7aca24db7ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-d43ac47c-f567-4209-94d4-f88e8b97b29c,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-e3490e5d-a491-496d-95ed-1c169305cff1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1224907348-172.17.0.18-1597301446339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33651,DS-36192a12-52d4-497f-8240-c9ec267117e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-3d4e5a86-46d2-43b6-958a-899a20c23138,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-d6efd959-d5d3-4cee-9e8d-413b84a12cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-9589bec2-b64b-4abb-b7bd-7d36a17f3668,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-98e37abd-f31f-4503-bf44-2a013cb0cd1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-db58d5a3-ff3f-4f16-96fb-65cb37e4987e,DISK], DatanodeInfoWithStorage[127.0.0.1:38148,DS-4c3c1594-04b8-4bc7-b956-c59ee6b29bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-75866352-c926-4f36-8b1f-c49aeaf6e122,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1224907348-172.17.0.18-1597301446339:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33651,DS-36192a12-52d4-497f-8240-c9ec267117e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-3d4e5a86-46d2-43b6-958a-899a20c23138,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-d6efd959-d5d3-4cee-9e8d-413b84a12cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-9589bec2-b64b-4abb-b7bd-7d36a17f3668,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-98e37abd-f31f-4503-bf44-2a013cb0cd1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-db58d5a3-ff3f-4f16-96fb-65cb37e4987e,DISK], DatanodeInfoWithStorage[127.0.0.1:38148,DS-4c3c1594-04b8-4bc7-b956-c59ee6b29bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-75866352-c926-4f36-8b1f-c49aeaf6e122,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1227636763-172.17.0.18-1597301482672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35685,DS-5905e96f-17b9-4548-9a78-163153e3ecdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-47d05416-3177-44a5-8056-27b3109b186c,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-e08cc751-4a07-4b69-b6bc-f57f4ebb3643,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-492d0bad-b6fb-4803-a6df-54d46072bd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37649,DS-ff7e5c7a-8920-43dd-9d81-33bf9232e763,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-cddf45ad-c8a6-44d5-a524-b53ab78c6d46,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-8af44818-50f0-42a8-8248-9ebab0447453,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-f7742726-3503-4700-b84f-4c828573321f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1227636763-172.17.0.18-1597301482672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35685,DS-5905e96f-17b9-4548-9a78-163153e3ecdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43242,DS-47d05416-3177-44a5-8056-27b3109b186c,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-e08cc751-4a07-4b69-b6bc-f57f4ebb3643,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-492d0bad-b6fb-4803-a6df-54d46072bd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37649,DS-ff7e5c7a-8920-43dd-9d81-33bf9232e763,DISK], DatanodeInfoWithStorage[127.0.0.1:44190,DS-cddf45ad-c8a6-44d5-a524-b53ab78c6d46,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-8af44818-50f0-42a8-8248-9ebab0447453,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-f7742726-3503-4700-b84f-4c828573321f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1948000847-172.17.0.18-1597301666255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35995,DS-4609946e-7f82-4c49-a2b8-e91b6f80d77e,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-64e38d1d-2ad2-46a6-855a-1ac8738da425,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-a0ece2dc-1140-438d-83a4-d67f27259829,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-1a0751ac-667f-4310-a704-05d5104bb99b,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-3f6a9b39-3cb7-4b21-bb79-7538dcc3d737,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-51b2e477-12df-4c11-bb87-29aff7b291c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-8c5cecd3-2924-4e01-8f88-bbcc52cbc186,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-50d47f3b-8929-44e9-8a0d-8c5d07dd1e16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1948000847-172.17.0.18-1597301666255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35995,DS-4609946e-7f82-4c49-a2b8-e91b6f80d77e,DISK], DatanodeInfoWithStorage[127.0.0.1:42107,DS-64e38d1d-2ad2-46a6-855a-1ac8738da425,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-a0ece2dc-1140-438d-83a4-d67f27259829,DISK], DatanodeInfoWithStorage[127.0.0.1:38626,DS-1a0751ac-667f-4310-a704-05d5104bb99b,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-3f6a9b39-3cb7-4b21-bb79-7538dcc3d737,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-51b2e477-12df-4c11-bb87-29aff7b291c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-8c5cecd3-2924-4e01-8f88-bbcc52cbc186,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-50d47f3b-8929-44e9-8a0d-8c5d07dd1e16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-705145928-172.17.0.18-1597301699500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41678,DS-1420407c-9494-4f68-a184-27831fec1eed,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-c36de5c1-3d06-4d58-86ee-ebca25ae2b26,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-9669111a-3ed7-4c81-bf4a-3f4f608bb56b,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-2c46d19d-41a0-43b3-ba05-067ebe20d261,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-4fe2e2d8-33e0-49ef-b2a5-8acd4436f167,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-53d0027a-6ad2-452d-ad69-7cfefa8cd55b,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-155af858-a8c9-4f79-984d-ccc25f5b2c87,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-a01390f5-2ec2-4b2a-a9de-4618d0f2a1a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-705145928-172.17.0.18-1597301699500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41678,DS-1420407c-9494-4f68-a184-27831fec1eed,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-c36de5c1-3d06-4d58-86ee-ebca25ae2b26,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-9669111a-3ed7-4c81-bf4a-3f4f608bb56b,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-2c46d19d-41a0-43b3-ba05-067ebe20d261,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-4fe2e2d8-33e0-49ef-b2a5-8acd4436f167,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-53d0027a-6ad2-452d-ad69-7cfefa8cd55b,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-155af858-a8c9-4f79-984d-ccc25f5b2c87,DISK], DatanodeInfoWithStorage[127.0.0.1:46220,DS-a01390f5-2ec2-4b2a-a9de-4618d0f2a1a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1145219911-172.17.0.18-1597302477382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39732,DS-5218ac17-808f-4539-97e6-628e49d32f02,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-3f4974d7-9679-46cf-9e87-c2d1ec74e1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-5fb09100-dd9d-495b-91e7-36e73ef88b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39609,DS-cdfd1476-14fd-453c-846f-6284c3d94bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-2b94714d-d7cd-44f3-b533-fc1c1ce28244,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-4da4896e-8640-49f4-8277-fd45c22b6fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-7b4ff361-3fa8-404d-b640-c6fa2ef5632c,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-fe101fea-d709-42b1-90ae-8d7e861b0325,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1145219911-172.17.0.18-1597302477382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39732,DS-5218ac17-808f-4539-97e6-628e49d32f02,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-3f4974d7-9679-46cf-9e87-c2d1ec74e1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-5fb09100-dd9d-495b-91e7-36e73ef88b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:39609,DS-cdfd1476-14fd-453c-846f-6284c3d94bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-2b94714d-d7cd-44f3-b533-fc1c1ce28244,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-4da4896e-8640-49f4-8277-fd45c22b6fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-7b4ff361-3fa8-404d-b640-c6fa2ef5632c,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-fe101fea-d709-42b1-90ae-8d7e861b0325,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2015838514-172.17.0.18-1597302657369:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43607,DS-78fd0cdb-749e-454f-8c39-b387adb8ff35,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-11fc46fe-6873-40ab-95be-941f4b9bee81,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-8fe4e639-205f-472b-bb58-f7dd2f125e36,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-3c7c7697-367c-459b-bcf1-41a6fb5bbb84,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-d010895f-3171-4fdf-b224-ebac96b1518a,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-0ca4ab26-47ee-40a0-a3b8-fb3c0c7e4105,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-acc4e950-db98-40cc-90f1-0a07b6b0315e,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-8c53a735-592e-44c3-84f6-da956528125e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2015838514-172.17.0.18-1597302657369:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43607,DS-78fd0cdb-749e-454f-8c39-b387adb8ff35,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-11fc46fe-6873-40ab-95be-941f4b9bee81,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-8fe4e639-205f-472b-bb58-f7dd2f125e36,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-3c7c7697-367c-459b-bcf1-41a6fb5bbb84,DISK], DatanodeInfoWithStorage[127.0.0.1:46852,DS-d010895f-3171-4fdf-b224-ebac96b1518a,DISK], DatanodeInfoWithStorage[127.0.0.1:38798,DS-0ca4ab26-47ee-40a0-a3b8-fb3c0c7e4105,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-acc4e950-db98-40cc-90f1-0a07b6b0315e,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-8c53a735-592e-44c3-84f6-da956528125e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-621565610-172.17.0.18-1597302839025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36192,DS-5ed2b2bb-8695-4fbc-a3cb-ce29ce29de12,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-9a9cb17a-e5af-4bf4-9dcf-c435eaf10e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44272,DS-e1d97e69-5ef2-4f36-9b37-3b6c569db375,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-d2e5c7d8-2bec-4559-8aad-da2035dbb4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-03498c1f-21e5-4a6e-a790-6c5ba59f1041,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-9ba7e051-b028-4f16-867d-1762517f2513,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-048aadef-95a6-4879-b3d2-886159a30e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-0a9e9b7c-728a-4b18-a278-8bd198d3bb36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-621565610-172.17.0.18-1597302839025:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36192,DS-5ed2b2bb-8695-4fbc-a3cb-ce29ce29de12,DISK], DatanodeInfoWithStorage[127.0.0.1:44827,DS-9a9cb17a-e5af-4bf4-9dcf-c435eaf10e2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44272,DS-e1d97e69-5ef2-4f36-9b37-3b6c569db375,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-d2e5c7d8-2bec-4559-8aad-da2035dbb4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-03498c1f-21e5-4a6e-a790-6c5ba59f1041,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-9ba7e051-b028-4f16-867d-1762517f2513,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-048aadef-95a6-4879-b3d2-886159a30e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-0a9e9b7c-728a-4b18-a278-8bd198d3bb36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 2097152
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1442576946-172.17.0.18-1597303237511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36430,DS-b1268ea2-9d11-45f6-a2ce-e367c2e59e07,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-7fa358c2-ac37-4897-b152-65c7c184e63c,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-94c90400-5068-4948-8957-bd6d6d0c99b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-395fa13a-b888-4424-a1d9-f33dad555a57,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-e814e811-5769-4302-8ce8-c843262eb208,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-08f72a4c-2415-4670-b593-54ba9c128905,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-7a0c9220-c245-434d-a532-2ca3f7f13dda,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-1d7a2baf-8c9b-4b0a-9cc0-f018cac4906e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1442576946-172.17.0.18-1597303237511:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36430,DS-b1268ea2-9d11-45f6-a2ce-e367c2e59e07,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-7fa358c2-ac37-4897-b152-65c7c184e63c,DISK], DatanodeInfoWithStorage[127.0.0.1:38928,DS-94c90400-5068-4948-8957-bd6d6d0c99b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-395fa13a-b888-4424-a1d9-f33dad555a57,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-e814e811-5769-4302-8ce8-c843262eb208,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-08f72a4c-2415-4670-b593-54ba9c128905,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-7a0c9220-c245-434d-a532-2ca3f7f13dda,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-1d7a2baf-8c9b-4b0a-9cc0-f018cac4906e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5417
