reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954610791-172.17.0.13-1597281070726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44967,DS-ad83b88a-652d-45e6-8c53-85817957ed13,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-a2fe7ed3-3b6c-47f1-862e-567d04268e83,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-994d9730-58e7-4417-8940-3f3acc46fe07,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-c40c1834-f392-4d22-8c48-65372accc8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-913fc901-7a12-4898-9730-96bec7aa53c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-1c632352-11af-4531-a399-fab9b02f93ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-8fcdaabd-49fc-4984-885a-bc842dc32485,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-fd8b8f23-fe6f-4a7c-8003-6cdfd5b1a592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954610791-172.17.0.13-1597281070726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44967,DS-ad83b88a-652d-45e6-8c53-85817957ed13,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-a2fe7ed3-3b6c-47f1-862e-567d04268e83,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-994d9730-58e7-4417-8940-3f3acc46fe07,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-c40c1834-f392-4d22-8c48-65372accc8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-913fc901-7a12-4898-9730-96bec7aa53c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-1c632352-11af-4531-a399-fab9b02f93ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-8fcdaabd-49fc-4984-885a-bc842dc32485,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-fd8b8f23-fe6f-4a7c-8003-6cdfd5b1a592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-300198071-172.17.0.13-1597281112210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36217,DS-da40d25a-4979-4d95-88b6-3004adf95759,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-e99cf1ae-8f20-4635-a953-dcfc753823fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-9c6aaae3-88bc-4d47-9f79-4b76fea53ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-34b54e73-877c-4b6b-b4bf-fec1b840436f,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-77f618e0-8e86-4e87-8622-1a15e652682c,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-5b4d16d7-0e8a-48e1-8776-79aae804628d,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-f6298d64-6fcc-4f4f-9576-3c3f4033621a,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-4dc20ef6-f9c1-45ca-9f8e-588c49d310a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-300198071-172.17.0.13-1597281112210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36217,DS-da40d25a-4979-4d95-88b6-3004adf95759,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-e99cf1ae-8f20-4635-a953-dcfc753823fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-9c6aaae3-88bc-4d47-9f79-4b76fea53ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-34b54e73-877c-4b6b-b4bf-fec1b840436f,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-77f618e0-8e86-4e87-8622-1a15e652682c,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-5b4d16d7-0e8a-48e1-8776-79aae804628d,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-f6298d64-6fcc-4f4f-9576-3c3f4033621a,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-4dc20ef6-f9c1-45ca-9f8e-588c49d310a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455789557-172.17.0.13-1597281216321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33931,DS-9dd3d6d9-44fd-4b9c-a38b-0e09f535c22d,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-03fa9420-98ac-4bed-946f-2a64e67a8696,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-db70c49d-ebe5-46c1-aa00-53350525d786,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-dfd3c399-d172-4f3b-ab11-d4f472e88873,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-856d2b48-7bba-424f-88e6-0e628d4c9d91,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-721a52fb-1b90-4054-8fa4-0f3b57be4259,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-623bf5f6-ec02-4745-8100-71f709ce89fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-69c8e4a8-fb4d-4300-aeab-e25a89a20226,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455789557-172.17.0.13-1597281216321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33931,DS-9dd3d6d9-44fd-4b9c-a38b-0e09f535c22d,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-03fa9420-98ac-4bed-946f-2a64e67a8696,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-db70c49d-ebe5-46c1-aa00-53350525d786,DISK], DatanodeInfoWithStorage[127.0.0.1:46324,DS-dfd3c399-d172-4f3b-ab11-d4f472e88873,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-856d2b48-7bba-424f-88e6-0e628d4c9d91,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-721a52fb-1b90-4054-8fa4-0f3b57be4259,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-623bf5f6-ec02-4745-8100-71f709ce89fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-69c8e4a8-fb4d-4300-aeab-e25a89a20226,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1927179708-172.17.0.13-1597281357209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38696,DS-5eda91f3-9ff3-45f5-8ff0-89cececba8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43397,DS-bc2b4c89-c64e-4b32-9170-2a238329b5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-27db7d51-ec87-41d5-b002-e474f873bead,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-353eedc9-12ea-4762-8ba2-0b2e579aeea4,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-ac8ca675-4bcc-4994-8e53-cd77d867ff5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-ac66e3cb-7ac6-49bc-9873-3eabb52da613,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-5d1f0d02-1709-4610-b8a6-a7ff6e285c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-e6896501-9e5f-4637-b185-ffc9ce5ba18e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1927179708-172.17.0.13-1597281357209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38696,DS-5eda91f3-9ff3-45f5-8ff0-89cececba8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43397,DS-bc2b4c89-c64e-4b32-9170-2a238329b5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-27db7d51-ec87-41d5-b002-e474f873bead,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-353eedc9-12ea-4762-8ba2-0b2e579aeea4,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-ac8ca675-4bcc-4994-8e53-cd77d867ff5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-ac66e3cb-7ac6-49bc-9873-3eabb52da613,DISK], DatanodeInfoWithStorage[127.0.0.1:33372,DS-5d1f0d02-1709-4610-b8a6-a7ff6e285c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-e6896501-9e5f-4637-b185-ffc9ce5ba18e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056687418-172.17.0.13-1597281400656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37731,DS-0d3076de-c7cb-4b54-95a6-12e1645aface,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-b572a041-c66e-4422-a2c7-6fb23da56c99,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-f446eae8-df13-4382-91df-979248c89ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-289d7d32-95ff-44ce-abef-0eb024298d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-025a2b8a-ca92-4554-a120-7ad89648344b,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-12a7f265-5e31-420f-8421-b81be5142827,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-a2854990-2519-479c-a71d-fc72a891e441,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-205fb949-b0a8-4d02-8e7a-8a7bd62d75c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056687418-172.17.0.13-1597281400656:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37731,DS-0d3076de-c7cb-4b54-95a6-12e1645aface,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-b572a041-c66e-4422-a2c7-6fb23da56c99,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-f446eae8-df13-4382-91df-979248c89ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-289d7d32-95ff-44ce-abef-0eb024298d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-025a2b8a-ca92-4554-a120-7ad89648344b,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-12a7f265-5e31-420f-8421-b81be5142827,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-a2854990-2519-479c-a71d-fc72a891e441,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-205fb949-b0a8-4d02-8e7a-8a7bd62d75c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487460037-172.17.0.13-1597282395845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44786,DS-48491157-5de7-4ec4-a7f1-7b2d7e2af6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-bb0d6ac9-e149-453c-9fd3-f3cfcf3b593c,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-91c5b7dd-0f23-4021-9786-293182aaa8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-57b4bc04-dffb-4f82-9583-b21b32fad60a,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-60a96a87-8b1c-4539-a0ec-c066f04c01de,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-90b78aa9-9eeb-49d5-b30c-a2de09c6f9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-f4ed07c5-9776-4990-8077-3ac201768f24,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-1b0bf692-56f6-4cd7-8cac-155b5d8df9db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1487460037-172.17.0.13-1597282395845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44786,DS-48491157-5de7-4ec4-a7f1-7b2d7e2af6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-bb0d6ac9-e149-453c-9fd3-f3cfcf3b593c,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-91c5b7dd-0f23-4021-9786-293182aaa8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44886,DS-57b4bc04-dffb-4f82-9583-b21b32fad60a,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-60a96a87-8b1c-4539-a0ec-c066f04c01de,DISK], DatanodeInfoWithStorage[127.0.0.1:46535,DS-90b78aa9-9eeb-49d5-b30c-a2de09c6f9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-f4ed07c5-9776-4990-8077-3ac201768f24,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-1b0bf692-56f6-4cd7-8cac-155b5d8df9db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1994837996-172.17.0.13-1597283039677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38795,DS-d4bfa0f5-1b73-4db9-bfb5-9d86cd74ec29,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-6e8c4f35-5f51-45c3-a180-23bec0b061ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-f878ea76-01f0-46f0-aa2a-f6359a1b6a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-ac578eb1-a622-49a9-ae1f-7a028bb10cda,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-45f67b1b-c3f6-4434-9437-d41942d5ca48,DISK], DatanodeInfoWithStorage[127.0.0.1:32978,DS-4435bc85-492e-46e0-987a-bf00c86c2d23,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-842622ee-c638-4eb7-9761-e31603bb6518,DISK], DatanodeInfoWithStorage[127.0.0.1:39844,DS-7e92792a-5624-4fb1-a1e0-294a99b50016,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1994837996-172.17.0.13-1597283039677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38795,DS-d4bfa0f5-1b73-4db9-bfb5-9d86cd74ec29,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-6e8c4f35-5f51-45c3-a180-23bec0b061ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-f878ea76-01f0-46f0-aa2a-f6359a1b6a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-ac578eb1-a622-49a9-ae1f-7a028bb10cda,DISK], DatanodeInfoWithStorage[127.0.0.1:42268,DS-45f67b1b-c3f6-4434-9437-d41942d5ca48,DISK], DatanodeInfoWithStorage[127.0.0.1:32978,DS-4435bc85-492e-46e0-987a-bf00c86c2d23,DISK], DatanodeInfoWithStorage[127.0.0.1:42577,DS-842622ee-c638-4eb7-9761-e31603bb6518,DISK], DatanodeInfoWithStorage[127.0.0.1:39844,DS-7e92792a-5624-4fb1-a1e0-294a99b50016,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-51080269-172.17.0.13-1597283907909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45626,DS-af98ba8a-eb89-4c32-b2a2-827186357080,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-c026813a-3b48-4c71-812b-f1df4174e396,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-5ba9c1e0-86c9-4334-9054-5e95401ef33b,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-3157ec5f-5aea-4136-bf1f-41dc23660db0,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-d01e5697-001d-46d5-aa20-7da92050caa4,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-ff0daa24-568a-4365-8af2-1c07c9ed65c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-2a962204-bfbc-431b-833b-915dda6827b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-f3da854b-8aaf-4ff9-9c88-994618012c98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-51080269-172.17.0.13-1597283907909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45626,DS-af98ba8a-eb89-4c32-b2a2-827186357080,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-c026813a-3b48-4c71-812b-f1df4174e396,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-5ba9c1e0-86c9-4334-9054-5e95401ef33b,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-3157ec5f-5aea-4136-bf1f-41dc23660db0,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-d01e5697-001d-46d5-aa20-7da92050caa4,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-ff0daa24-568a-4365-8af2-1c07c9ed65c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-2a962204-bfbc-431b-833b-915dda6827b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-f3da854b-8aaf-4ff9-9c88-994618012c98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1850993977-172.17.0.13-1597284276370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45597,DS-fa5154df-d4d5-4b31-a468-9341db2e3946,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-2a25be0a-9de6-41c7-a6b0-a85d7a910912,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-c88d80fd-beee-42b0-8d46-8e838d26d622,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-d73dccfb-8cbf-44d9-aff5-2031641a3aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-7e0a5cc4-7547-471f-9ee4-49fa52eb66bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-13bf5436-ce64-4bff-a453-2570f2ff1ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:42591,DS-77864b04-746b-49ea-99aa-88f6bb770697,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-824ec4b6-f0f2-4d32-9d58-f609a18cb8d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1850993977-172.17.0.13-1597284276370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45597,DS-fa5154df-d4d5-4b31-a468-9341db2e3946,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-2a25be0a-9de6-41c7-a6b0-a85d7a910912,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-c88d80fd-beee-42b0-8d46-8e838d26d622,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-d73dccfb-8cbf-44d9-aff5-2031641a3aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-7e0a5cc4-7547-471f-9ee4-49fa52eb66bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-13bf5436-ce64-4bff-a453-2570f2ff1ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:42591,DS-77864b04-746b-49ea-99aa-88f6bb770697,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-824ec4b6-f0f2-4d32-9d58-f609a18cb8d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-96526561-172.17.0.13-1597284678967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43258,DS-d2eaff3d-deaa-421a-a420-4c7f951444fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-077b5ac6-07ed-4108-9253-11b08b2ca8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-1e70a10b-4d9f-4be7-9b3c-b7098adacbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43109,DS-b0bcea02-c2be-404e-a8e0-6594a6bd9737,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-888ab07c-2e82-4c48-8401-53edf1e6da0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-a0e02e6a-7386-4e9a-9d46-48d210afb538,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-941be112-b20a-4680-beb9-521a0b14557f,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-711457fd-b44e-4a3b-8d79-04012e3984c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-96526561-172.17.0.13-1597284678967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43258,DS-d2eaff3d-deaa-421a-a420-4c7f951444fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-077b5ac6-07ed-4108-9253-11b08b2ca8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-1e70a10b-4d9f-4be7-9b3c-b7098adacbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:43109,DS-b0bcea02-c2be-404e-a8e0-6594a6bd9737,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-888ab07c-2e82-4c48-8401-53edf1e6da0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-a0e02e6a-7386-4e9a-9d46-48d210afb538,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-941be112-b20a-4680-beb9-521a0b14557f,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-711457fd-b44e-4a3b-8d79-04012e3984c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553333075-172.17.0.13-1597285345782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46874,DS-e336ce31-66a4-424c-a695-7e36c836020f,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-12a292ac-85e6-4d81-a61e-bd2b2f75b0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-3579ff91-47ec-4eb0-af73-0282d3d1bac4,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-9565d600-a67f-460f-abb2-3a8c4f0f662e,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-74ecb781-af18-4742-a179-4a9080b29ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-8110fbaf-7eae-465d-b3d0-37e25a289da5,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-9b8b3c92-a5f1-4349-ba01-f5b1e7e43622,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-4412444d-f447-4621-a369-e299a1ce0dff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553333075-172.17.0.13-1597285345782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46874,DS-e336ce31-66a4-424c-a695-7e36c836020f,DISK], DatanodeInfoWithStorage[127.0.0.1:33666,DS-12a292ac-85e6-4d81-a61e-bd2b2f75b0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-3579ff91-47ec-4eb0-af73-0282d3d1bac4,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-9565d600-a67f-460f-abb2-3a8c4f0f662e,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-74ecb781-af18-4742-a179-4a9080b29ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-8110fbaf-7eae-465d-b3d0-37e25a289da5,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-9b8b3c92-a5f1-4349-ba01-f5b1e7e43622,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-4412444d-f447-4621-a369-e299a1ce0dff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1661289743-172.17.0.13-1597285786519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35727,DS-97b819b5-bfee-400a-870e-b416a0742fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-dcbea39b-7315-4a95-8eb2-0b66d46176ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-bd3c2dff-ab8b-4b8a-a6d4-869ae51c516b,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-a742e67f-b056-4b28-9630-98f8710d3680,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-148d851b-c067-428a-9ec4-fdf0dcb0acd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-69ad722a-f60a-427d-b447-05c3d594f48e,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-f2d71af9-c472-4856-9692-d2d7f1f852b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-8b6cb747-d485-4fab-b024-9623391e60c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1661289743-172.17.0.13-1597285786519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35727,DS-97b819b5-bfee-400a-870e-b416a0742fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-dcbea39b-7315-4a95-8eb2-0b66d46176ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-bd3c2dff-ab8b-4b8a-a6d4-869ae51c516b,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-a742e67f-b056-4b28-9630-98f8710d3680,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-148d851b-c067-428a-9ec4-fdf0dcb0acd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-69ad722a-f60a-427d-b447-05c3d594f48e,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-f2d71af9-c472-4856-9692-d2d7f1f852b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-8b6cb747-d485-4fab-b024-9623391e60c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889585443-172.17.0.13-1597285971702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43519,DS-748b01a6-eef9-44ca-aa0c-63b9773a7252,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-c1c42af2-d99f-43f7-8d4e-021834ceaafc,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-23208f46-dd92-4f76-a38e-70b51cc08c96,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-6859d166-f3ba-4b36-bb61-f44ab3aa292a,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-1cf60d66-bfb0-4304-b5de-7190bb10f095,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-7013a8fb-77de-43e9-b18b-feb685c7b0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-ee34890b-ce2c-4602-a619-986e5b12f17a,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-d36f8765-f4aa-42bf-bd14-1b2816eb2caf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889585443-172.17.0.13-1597285971702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43519,DS-748b01a6-eef9-44ca-aa0c-63b9773a7252,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-c1c42af2-d99f-43f7-8d4e-021834ceaafc,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-23208f46-dd92-4f76-a38e-70b51cc08c96,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-6859d166-f3ba-4b36-bb61-f44ab3aa292a,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-1cf60d66-bfb0-4304-b5de-7190bb10f095,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-7013a8fb-77de-43e9-b18b-feb685c7b0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33145,DS-ee34890b-ce2c-4602-a619-986e5b12f17a,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-d36f8765-f4aa-42bf-bd14-1b2816eb2caf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2033377914-172.17.0.13-1597286807197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45298,DS-324a905e-b4b8-4ae1-a5f8-58a959388563,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-112a0c16-1ba9-4d1e-b7ff-499c20507116,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-1ff17d5f-7245-4442-9391-552fc591d55e,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-cf0dda10-413e-4c0c-b44f-5c31e291ab0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-f664bb43-2e9b-4753-afc6-453c5f41989e,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-e5872c82-bc9e-4150-943f-ac91f8a3fb74,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-6cf0ba42-abe9-4bf6-8f3e-a610cfb8b722,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-e3564376-302a-4c53-bd37-82cb94529b68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2033377914-172.17.0.13-1597286807197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45298,DS-324a905e-b4b8-4ae1-a5f8-58a959388563,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-112a0c16-1ba9-4d1e-b7ff-499c20507116,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-1ff17d5f-7245-4442-9391-552fc591d55e,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-cf0dda10-413e-4c0c-b44f-5c31e291ab0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-f664bb43-2e9b-4753-afc6-453c5f41989e,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-e5872c82-bc9e-4150-943f-ac91f8a3fb74,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-6cf0ba42-abe9-4bf6-8f3e-a610cfb8b722,DISK], DatanodeInfoWithStorage[127.0.0.1:42541,DS-e3564376-302a-4c53-bd37-82cb94529b68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.lifeline.interval.seconds
component: hdfs:DataNode
v1: 9000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443871358-172.17.0.13-1597287784601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42943,DS-82a49dbf-d04e-4931-aeb5-717306a84f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-2f01e67f-87ac-42aa-8014-4fab199b870f,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-556eb31e-45bc-4fa5-bc4e-90d836a05cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-4657e913-b874-44be-8245-0d545918f0de,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-386422a0-1a90-42ab-b350-d4989267228a,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-3d0ec9bd-f894-4dd7-bef8-ad9b1b8c2e10,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-74e770e0-b4f3-4331-a384-1e03fb3a4f65,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-c8082518-0e5b-44bf-a24c-23dc290668c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443871358-172.17.0.13-1597287784601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42943,DS-82a49dbf-d04e-4931-aeb5-717306a84f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-2f01e67f-87ac-42aa-8014-4fab199b870f,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-556eb31e-45bc-4fa5-bc4e-90d836a05cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38103,DS-4657e913-b874-44be-8245-0d545918f0de,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-386422a0-1a90-42ab-b350-d4989267228a,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-3d0ec9bd-f894-4dd7-bef8-ad9b1b8c2e10,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-74e770e0-b4f3-4331-a384-1e03fb3a4f65,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-c8082518-0e5b-44bf-a24c-23dc290668c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6891
