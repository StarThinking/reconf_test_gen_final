reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-619648488-172.17.0.15-1597346860254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33943,DS-b04cd7ef-a8ab-4420-a63f-b9f3f3dabe79,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-2aefb09d-abe9-4f47-b3fd-231e2d350bce,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-5b29bd3d-2ee4-43a1-9d29-2eb15c00ed40,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-b8a3ed69-02b5-4724-86a0-932a3d76a343,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-9cd562f7-4a90-4d4e-95fb-78ca2445bf35,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-5b81186c-2b38-466b-8cb1-f45b164c9a53,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-e31f04f1-12e7-45fd-81a0-d0e71e38c9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-0eabeb15-0ef9-40f1-a18a-07b685d74bf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-619648488-172.17.0.15-1597346860254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33943,DS-b04cd7ef-a8ab-4420-a63f-b9f3f3dabe79,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-2aefb09d-abe9-4f47-b3fd-231e2d350bce,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-5b29bd3d-2ee4-43a1-9d29-2eb15c00ed40,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-b8a3ed69-02b5-4724-86a0-932a3d76a343,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-9cd562f7-4a90-4d4e-95fb-78ca2445bf35,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-5b81186c-2b38-466b-8cb1-f45b164c9a53,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-e31f04f1-12e7-45fd-81a0-d0e71e38c9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-0eabeb15-0ef9-40f1-a18a-07b685d74bf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1076159029-172.17.0.15-1597347266839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36118,DS-06119cb6-6954-48d1-99db-98882828413f,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-aea56f86-2e14-439e-930f-2764658d46e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-331d7414-bc9a-4406-b5d5-989f43b845a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-62236480-2df8-4556-849e-2a617500a25f,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-2ba1aaaa-0a03-4335-b430-7ea887d67029,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-bb757e1e-08ac-46a6-ac68-88f5e010a341,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-60685bef-49bb-41ae-ad1d-86c2a15f9d50,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-2d552e88-cdd3-4858-8b57-018a8e73139a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1076159029-172.17.0.15-1597347266839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36118,DS-06119cb6-6954-48d1-99db-98882828413f,DISK], DatanodeInfoWithStorage[127.0.0.1:33684,DS-aea56f86-2e14-439e-930f-2764658d46e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-331d7414-bc9a-4406-b5d5-989f43b845a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-62236480-2df8-4556-849e-2a617500a25f,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-2ba1aaaa-0a03-4335-b430-7ea887d67029,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-bb757e1e-08ac-46a6-ac68-88f5e010a341,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-60685bef-49bb-41ae-ad1d-86c2a15f9d50,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-2d552e88-cdd3-4858-8b57-018a8e73139a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-973579600-172.17.0.15-1597348174591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44756,DS-22ad233a-85ab-4fe1-acc2-56df1ac1f543,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-d8a5c5d0-cf57-42b3-988a-17b431705c90,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-ecaec870-338e-43a8-a591-fb74b0bdbea0,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-4d3389d0-4877-42c8-bd58-a05fa485e1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-4856aee0-b687-4988-852d-107744ee20f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-d3f28c02-3d85-4860-8856-973cc6672a39,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-91006ffb-15f2-4109-82f9-75ec9ec291e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-16c7d649-4152-4104-a071-74de2cf997a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-973579600-172.17.0.15-1597348174591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44756,DS-22ad233a-85ab-4fe1-acc2-56df1ac1f543,DISK], DatanodeInfoWithStorage[127.0.0.1:44811,DS-d8a5c5d0-cf57-42b3-988a-17b431705c90,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-ecaec870-338e-43a8-a591-fb74b0bdbea0,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-4d3389d0-4877-42c8-bd58-a05fa485e1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-4856aee0-b687-4988-852d-107744ee20f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-d3f28c02-3d85-4860-8856-973cc6672a39,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-91006ffb-15f2-4109-82f9-75ec9ec291e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-16c7d649-4152-4104-a071-74de2cf997a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1760659082-172.17.0.15-1597348612463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40919,DS-60a549e1-23ed-421b-9925-f3af22ad4969,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-1b2d2edc-636a-4d88-80fd-47c65948062c,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-39e336d0-dc41-413e-a929-a1287acc8286,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-5581efbb-e822-456a-bae2-ac83eee8599a,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-ef864256-224c-4d43-9e4a-40a62a3ebc2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-b2fc2a9e-fa8b-455c-a302-e64af629c410,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-c658ff97-988f-4ecd-b0bf-f9c0b684b1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-937bae15-c20b-4307-9ed4-9b55293c94b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1760659082-172.17.0.15-1597348612463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40919,DS-60a549e1-23ed-421b-9925-f3af22ad4969,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-1b2d2edc-636a-4d88-80fd-47c65948062c,DISK], DatanodeInfoWithStorage[127.0.0.1:32837,DS-39e336d0-dc41-413e-a929-a1287acc8286,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-5581efbb-e822-456a-bae2-ac83eee8599a,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-ef864256-224c-4d43-9e4a-40a62a3ebc2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-b2fc2a9e-fa8b-455c-a302-e64af629c410,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-c658ff97-988f-4ecd-b0bf-f9c0b684b1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-937bae15-c20b-4307-9ed4-9b55293c94b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-908561280-172.17.0.15-1597348744660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44249,DS-712a00e0-63f9-4cb4-ae3c-bc74a120e390,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-8844ab48-d9be-4a75-a429-2fc446a83c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-25253e4c-ba50-4450-b831-e9bc79f2eda4,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-b24477f8-fb22-4778-9339-620326556ede,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-d6494ae9-af2b-4abe-ad58-9d3d4900127d,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-d2580d41-4c1f-4753-942d-d04ee5b1aa14,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-949747ec-ff04-4d4e-a017-299ef91eddfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-22a1e556-abaa-460c-8035-841e781b9501,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-908561280-172.17.0.15-1597348744660:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44249,DS-712a00e0-63f9-4cb4-ae3c-bc74a120e390,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-8844ab48-d9be-4a75-a429-2fc446a83c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-25253e4c-ba50-4450-b831-e9bc79f2eda4,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-b24477f8-fb22-4778-9339-620326556ede,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-d6494ae9-af2b-4abe-ad58-9d3d4900127d,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-d2580d41-4c1f-4753-942d-d04ee5b1aa14,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-949747ec-ff04-4d4e-a017-299ef91eddfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-22a1e556-abaa-460c-8035-841e781b9501,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1527940091-172.17.0.15-1597348869299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44112,DS-0f6eda05-37f8-4367-a641-12dd98fbefd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-7cda3cd4-2cdf-47c6-87b3-71c817a6f8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-66c04eb9-5a61-4e49-9f11-14b7034fcbf4,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-d0a457c2-7a83-4aec-94a5-9da184c62411,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-a9d468e3-cca0-420b-aeb9-dfc295af3690,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-ff03c48d-5c24-47a9-a0a1-826d07f6e15b,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-03457dc5-d3b8-4c0e-b57b-aa076a677cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-2bcc3692-b6d7-4e87-ae2b-8474d9e620ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1527940091-172.17.0.15-1597348869299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44112,DS-0f6eda05-37f8-4367-a641-12dd98fbefd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-7cda3cd4-2cdf-47c6-87b3-71c817a6f8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-66c04eb9-5a61-4e49-9f11-14b7034fcbf4,DISK], DatanodeInfoWithStorage[127.0.0.1:33690,DS-d0a457c2-7a83-4aec-94a5-9da184c62411,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-a9d468e3-cca0-420b-aeb9-dfc295af3690,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-ff03c48d-5c24-47a9-a0a1-826d07f6e15b,DISK], DatanodeInfoWithStorage[127.0.0.1:37538,DS-03457dc5-d3b8-4c0e-b57b-aa076a677cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-2bcc3692-b6d7-4e87-ae2b-8474d9e620ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2053019438-172.17.0.15-1597348968821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43681,DS-4ae22730-398c-403c-b682-26055b9f8e65,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-7dcf76dc-05de-4488-b9d3-412aff8967e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-ab5144a6-80d0-43bc-9b73-9eb9ee7dac2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-34851a8f-ea6d-46b5-b723-ae614639c4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-3053d505-6391-4a0f-8bca-187b534b0dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-b4067f61-8111-47ff-8f13-799d4eaf9690,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-71d7d2df-119e-4b75-a1a4-36058a5272a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-e0444cce-44b5-46a1-b38f-2c1c9aed8581,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2053019438-172.17.0.15-1597348968821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43681,DS-4ae22730-398c-403c-b682-26055b9f8e65,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-7dcf76dc-05de-4488-b9d3-412aff8967e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-ab5144a6-80d0-43bc-9b73-9eb9ee7dac2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37599,DS-34851a8f-ea6d-46b5-b723-ae614639c4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-3053d505-6391-4a0f-8bca-187b534b0dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-b4067f61-8111-47ff-8f13-799d4eaf9690,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-71d7d2df-119e-4b75-a1a4-36058a5272a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41820,DS-e0444cce-44b5-46a1-b38f-2c1c9aed8581,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388541641-172.17.0.15-1597349289898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37380,DS-87af66af-916f-489c-b1a6-e748181dffc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-bff52f4c-ae81-44b1-a7c2-ead1dada9242,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-afff3770-903d-4f97-b2cc-662dfbc27d53,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-330602bf-c20c-464f-8768-16627fb30f62,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-940a05ea-1363-44dd-9dc9-72ab732de85d,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-bf7e6364-1196-4d63-9e80-8982106d5597,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-bfb667d5-531b-48dc-956e-016b73ccbdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-eeff39f4-30e8-4879-a9b2-50d296a931aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388541641-172.17.0.15-1597349289898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37380,DS-87af66af-916f-489c-b1a6-e748181dffc4,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-bff52f4c-ae81-44b1-a7c2-ead1dada9242,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-afff3770-903d-4f97-b2cc-662dfbc27d53,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-330602bf-c20c-464f-8768-16627fb30f62,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-940a05ea-1363-44dd-9dc9-72ab732de85d,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-bf7e6364-1196-4d63-9e80-8982106d5597,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-bfb667d5-531b-48dc-956e-016b73ccbdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-eeff39f4-30e8-4879-a9b2-50d296a931aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234152598-172.17.0.15-1597349533618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34338,DS-f2617f0f-c255-43e4-8369-74925f11e0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-3301cd23-a9dd-4221-964c-915bfaddcbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-e4adc50c-ba52-402c-b58e-8e537fc5524d,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-f7ce4d56-9e75-406a-9d6b-5b09a2a44766,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-a6dc2f32-0f7c-4d51-814c-e0516d16bc43,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-65a08b4c-2a3a-41f5-9aef-0998448fd028,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-cac103f6-f99d-436c-81de-50b7671e1748,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-f64820f0-b715-4726-b946-78ef387ab4e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234152598-172.17.0.15-1597349533618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34338,DS-f2617f0f-c255-43e4-8369-74925f11e0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-3301cd23-a9dd-4221-964c-915bfaddcbbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38744,DS-e4adc50c-ba52-402c-b58e-8e537fc5524d,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-f7ce4d56-9e75-406a-9d6b-5b09a2a44766,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-a6dc2f32-0f7c-4d51-814c-e0516d16bc43,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-65a08b4c-2a3a-41f5-9aef-0998448fd028,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-cac103f6-f99d-436c-81de-50b7671e1748,DISK], DatanodeInfoWithStorage[127.0.0.1:43239,DS-f64820f0-b715-4726-b946-78ef387ab4e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846518753-172.17.0.15-1597349837005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43587,DS-be3cd2f9-696b-4875-9e3b-caa0c07c1605,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-d43afdd2-9031-47b9-875c-a23f40dda0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-5330931c-7567-40ae-8def-55894ef08044,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-5df32ad6-d384-4400-9c3e-5b17d0716826,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-dea41ed4-c00a-42e4-ba21-516393b5c7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-eac5a127-af8c-4f9e-a331-59a61a8a70ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-2adb07a7-c65e-4f5c-8c5f-3984e185c378,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-2803879c-427f-4edd-a993-15db53936267,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846518753-172.17.0.15-1597349837005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43587,DS-be3cd2f9-696b-4875-9e3b-caa0c07c1605,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-d43afdd2-9031-47b9-875c-a23f40dda0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38081,DS-5330931c-7567-40ae-8def-55894ef08044,DISK], DatanodeInfoWithStorage[127.0.0.1:32931,DS-5df32ad6-d384-4400-9c3e-5b17d0716826,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-dea41ed4-c00a-42e4-ba21-516393b5c7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-eac5a127-af8c-4f9e-a331-59a61a8a70ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-2adb07a7-c65e-4f5c-8c5f-3984e185c378,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-2803879c-427f-4edd-a993-15db53936267,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1645730331-172.17.0.15-1597350858830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44524,DS-72c49035-6866-4ad6-8f4d-9f788407cea3,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-57e313f3-0830-4880-b17a-c177c3a59af8,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-d97f25fb-7d18-4934-926d-cd33558ac9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-deb488b4-3f9d-4d6d-b87a-24e28f419ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-45a5b6cf-bd7c-46bb-9e82-70f0c46eb714,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-14451498-7648-4ddc-8b60-2e9f5527da40,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-d828d44a-c3e5-48a6-b0b5-9738473fe5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46582,DS-d3147f2f-d0d7-4bd4-a5cd-ef0edb8e842e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1645730331-172.17.0.15-1597350858830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44524,DS-72c49035-6866-4ad6-8f4d-9f788407cea3,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-57e313f3-0830-4880-b17a-c177c3a59af8,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-d97f25fb-7d18-4934-926d-cd33558ac9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-deb488b4-3f9d-4d6d-b87a-24e28f419ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-45a5b6cf-bd7c-46bb-9e82-70f0c46eb714,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-14451498-7648-4ddc-8b60-2e9f5527da40,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-d828d44a-c3e5-48a6-b0b5-9738473fe5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46582,DS-d3147f2f-d0d7-4bd4-a5cd-ef0edb8e842e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994490733-172.17.0.15-1597351009735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39542,DS-5bbbee82-55c7-4655-8f40-a5bac7acee03,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-e6ff10b8-007e-4eaf-800d-d53f3406f6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-5f3469b2-af3c-4ba7-802d-fa6e87b34973,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-e87c9267-d319-46bb-b74f-0b9e184f5b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-bb8f132f-4baa-4d76-8928-947cc87d9ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-d37b35b6-21e5-4825-b519-c702acafe3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-235339a4-ebc5-499f-9d42-294c9fb86883,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-f7033613-8a26-4cda-ba83-9cb63a0dcb79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994490733-172.17.0.15-1597351009735:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39542,DS-5bbbee82-55c7-4655-8f40-a5bac7acee03,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-e6ff10b8-007e-4eaf-800d-d53f3406f6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-5f3469b2-af3c-4ba7-802d-fa6e87b34973,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-e87c9267-d319-46bb-b74f-0b9e184f5b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-bb8f132f-4baa-4d76-8928-947cc87d9ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-d37b35b6-21e5-4825-b519-c702acafe3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-235339a4-ebc5-499f-9d42-294c9fb86883,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-f7033613-8a26-4cda-ba83-9cb63a0dcb79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1206592387-172.17.0.15-1597351090325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42380,DS-93a0d8a0-d83e-4bb2-aa64-b2eb7b2d223d,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-cab26302-0db0-4327-bd01-37272951bbac,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-7c4bf264-68a2-467e-8ece-9531884c7b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-ca08cbb0-9c62-489c-a35c-1a61c6b9d2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-7d87b3d8-b874-4c04-918b-fef35d7d526e,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-851e6b19-dc3d-461b-a711-74c1efb55a78,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-a126bd2f-9996-48d8-ae1e-8c3cf0c5702c,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-2c8b72cf-3382-4549-a73b-5cf3162bc59f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1206592387-172.17.0.15-1597351090325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42380,DS-93a0d8a0-d83e-4bb2-aa64-b2eb7b2d223d,DISK], DatanodeInfoWithStorage[127.0.0.1:41167,DS-cab26302-0db0-4327-bd01-37272951bbac,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-7c4bf264-68a2-467e-8ece-9531884c7b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-ca08cbb0-9c62-489c-a35c-1a61c6b9d2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-7d87b3d8-b874-4c04-918b-fef35d7d526e,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-851e6b19-dc3d-461b-a711-74c1efb55a78,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-a126bd2f-9996-48d8-ae1e-8c3cf0c5702c,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-2c8b72cf-3382-4549-a73b-5cf3162bc59f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1708873449-172.17.0.15-1597351433162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44745,DS-3a89b00c-6854-4b03-995d-fd1cc38224e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-9cee19bb-4212-4f99-8535-d20e73ea5888,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-368b1729-ef10-4e96-9185-32c22ff81717,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-4cde128b-adf8-413d-9672-942587af8df7,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-a1e7cf97-0803-4577-b29c-4efa0a7d321d,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-6748d3b7-87e5-4019-b5d9-cc1a9d985ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-d653afbc-e797-4919-8ad5-ab4378312984,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-f2e43c38-23bc-4450-878a-8f685bc3f363,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1708873449-172.17.0.15-1597351433162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44745,DS-3a89b00c-6854-4b03-995d-fd1cc38224e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-9cee19bb-4212-4f99-8535-d20e73ea5888,DISK], DatanodeInfoWithStorage[127.0.0.1:36897,DS-368b1729-ef10-4e96-9185-32c22ff81717,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-4cde128b-adf8-413d-9672-942587af8df7,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-a1e7cf97-0803-4577-b29c-4efa0a7d321d,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-6748d3b7-87e5-4019-b5d9-cc1a9d985ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-d653afbc-e797-4919-8ad5-ab4378312984,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-f2e43c38-23bc-4450-878a-8f685bc3f363,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5205
