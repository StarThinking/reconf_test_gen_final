reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-660722978-172.17.0.17-1597528165887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38313,DS-298f21f0-d990-479d-b6c2-1764746d8775,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-36d12b70-f73b-4c96-bfe0-081e7ff94062,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-b2ae9b32-a561-4804-a5ed-29280dbd1484,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-8eb7957d-9812-4ee9-8e90-86b44fc9d4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-d81d1908-f322-4533-bf75-5a9b3eb17a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-54832c81-18a6-491e-a8f4-a8d3a1755c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-71ec56f2-d693-46dc-850f-0c7eb97ca5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-de989cb1-36a3-42a4-a4e5-d9b035631afd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-660722978-172.17.0.17-1597528165887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38313,DS-298f21f0-d990-479d-b6c2-1764746d8775,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-36d12b70-f73b-4c96-bfe0-081e7ff94062,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-b2ae9b32-a561-4804-a5ed-29280dbd1484,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-8eb7957d-9812-4ee9-8e90-86b44fc9d4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-d81d1908-f322-4533-bf75-5a9b3eb17a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-54832c81-18a6-491e-a8f4-a8d3a1755c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-71ec56f2-d693-46dc-850f-0c7eb97ca5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-de989cb1-36a3-42a4-a4e5-d9b035631afd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-112610834-172.17.0.17-1597528430959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36793,DS-264e6b3b-22ab-4491-8f24-1a7e6059c869,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-a624c831-b379-4251-ada0-b73d994f7724,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-61d81ba6-8de7-4803-8d08-7e4ef4f1c6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-86cf45d6-877f-4666-b59b-c958631fc4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-8584995a-ec6b-423b-ad04-a258aab4ba8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-15e6c60b-4cd9-4e3b-9356-29589a7c115a,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-34d75c60-08da-4b92-919a-d41964b16e74,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-e36dda32-b920-488d-9a5c-e4380c0c9a9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-112610834-172.17.0.17-1597528430959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36793,DS-264e6b3b-22ab-4491-8f24-1a7e6059c869,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-a624c831-b379-4251-ada0-b73d994f7724,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-61d81ba6-8de7-4803-8d08-7e4ef4f1c6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-86cf45d6-877f-4666-b59b-c958631fc4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-8584995a-ec6b-423b-ad04-a258aab4ba8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-15e6c60b-4cd9-4e3b-9356-29589a7c115a,DISK], DatanodeInfoWithStorage[127.0.0.1:39896,DS-34d75c60-08da-4b92-919a-d41964b16e74,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-e36dda32-b920-488d-9a5c-e4380c0c9a9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1874538353-172.17.0.17-1597528543647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36203,DS-77354631-c187-4e3e-a3d1-829717282cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-5b608616-a67c-43f8-ba52-01b1456310f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-90061a92-a914-4d61-9ce0-700a1b89bd12,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-3fbe451c-0844-4053-8ee7-80da23d89db0,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-aa0d944c-d60b-4784-be01-d4a8e871bd11,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-f08ee6ff-d5bf-4878-9e32-213079c90a16,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-2e027059-6850-4398-bf98-7aa7891f4ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-7567b082-ceca-48fb-bc8c-8d41ee067669,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1874538353-172.17.0.17-1597528543647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36203,DS-77354631-c187-4e3e-a3d1-829717282cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-5b608616-a67c-43f8-ba52-01b1456310f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-90061a92-a914-4d61-9ce0-700a1b89bd12,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-3fbe451c-0844-4053-8ee7-80da23d89db0,DISK], DatanodeInfoWithStorage[127.0.0.1:42179,DS-aa0d944c-d60b-4784-be01-d4a8e871bd11,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-f08ee6ff-d5bf-4878-9e32-213079c90a16,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-2e027059-6850-4398-bf98-7aa7891f4ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-7567b082-ceca-48fb-bc8c-8d41ee067669,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-522206286-172.17.0.17-1597528698463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37946,DS-6e432496-4899-434a-ba8a-89dc8e2e229b,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-e490268e-639f-405a-86a7-4239950ac306,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-7d118340-4d8e-49ce-b1b7-e895a0874988,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-5ab23f24-4c31-46fa-98fc-431099432679,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-6f438971-7b16-42a3-a7f7-8f8516768d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-93ad47f9-65a8-4ffa-b536-d44ecd593b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-99226b2a-d3b8-402c-9eb4-b82a6f66cc62,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-4728ac2a-2f1e-43cc-8e2a-f9ec4b334ee9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-522206286-172.17.0.17-1597528698463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37946,DS-6e432496-4899-434a-ba8a-89dc8e2e229b,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-e490268e-639f-405a-86a7-4239950ac306,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-7d118340-4d8e-49ce-b1b7-e895a0874988,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-5ab23f24-4c31-46fa-98fc-431099432679,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-6f438971-7b16-42a3-a7f7-8f8516768d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-93ad47f9-65a8-4ffa-b536-d44ecd593b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-99226b2a-d3b8-402c-9eb4-b82a6f66cc62,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-4728ac2a-2f1e-43cc-8e2a-f9ec4b334ee9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81005164-172.17.0.17-1597528949798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38772,DS-db59fbd8-d711-4e4f-90c0-0b1822a5c65d,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-8cc33a3f-43fd-45d8-a17b-eab43b94c5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-e9aa39bd-e83f-44e5-a0e7-869b6b069e08,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-ced23943-9c5d-4ef7-8518-f23addacfb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-bf1d511a-c44d-4014-9a7d-b08eb6a8004f,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-d1234378-8241-4072-b30b-f5dbc37c8411,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-2918d0be-6c7c-4dde-9349-d21b4701a654,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-a05d5229-9d79-492b-bc81-083b7a349804,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-81005164-172.17.0.17-1597528949798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38772,DS-db59fbd8-d711-4e4f-90c0-0b1822a5c65d,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-8cc33a3f-43fd-45d8-a17b-eab43b94c5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-e9aa39bd-e83f-44e5-a0e7-869b6b069e08,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-ced23943-9c5d-4ef7-8518-f23addacfb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-bf1d511a-c44d-4014-9a7d-b08eb6a8004f,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-d1234378-8241-4072-b30b-f5dbc37c8411,DISK], DatanodeInfoWithStorage[127.0.0.1:44809,DS-2918d0be-6c7c-4dde-9349-d21b4701a654,DISK], DatanodeInfoWithStorage[127.0.0.1:43401,DS-a05d5229-9d79-492b-bc81-083b7a349804,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097179882-172.17.0.17-1597529531265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44742,DS-0f274dff-451e-40d5-91da-a162e3ca6be1,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-127bf310-7b77-458b-a4dc-7f8ca2b74274,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-bb8de0ac-f69a-43c4-96f4-aa85fd6650a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-f0d9e636-e31b-43b7-a366-e3f094002056,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-a0205b30-2df1-4550-8386-78b68d6c5878,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-3f84b993-605b-4d77-aa28-870b8f8314e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-9ecfe62e-0e39-4edc-a71d-1441c08d5734,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-27b67618-b372-4e1c-bcec-dcad8ed4b2a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097179882-172.17.0.17-1597529531265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44742,DS-0f274dff-451e-40d5-91da-a162e3ca6be1,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-127bf310-7b77-458b-a4dc-7f8ca2b74274,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-bb8de0ac-f69a-43c4-96f4-aa85fd6650a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-f0d9e636-e31b-43b7-a366-e3f094002056,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-a0205b30-2df1-4550-8386-78b68d6c5878,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-3f84b993-605b-4d77-aa28-870b8f8314e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-9ecfe62e-0e39-4edc-a71d-1441c08d5734,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-27b67618-b372-4e1c-bcec-dcad8ed4b2a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454967216-172.17.0.17-1597529679304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34538,DS-53ca386c-0c99-4e61-bd18-7968c73d22a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-fc038c18-0695-45c3-a963-a6e5b07f6168,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-8da1d9f8-2b14-4dd1-b6e1-cef1b892b3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-7d488688-38d3-457c-9a59-09ef44052e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-9a08046b-cca7-4e0e-852d-1c90aa1c3b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-c263d9d1-6116-4b6c-a7cd-6a32647d1790,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-d216e6eb-fb23-451f-acf2-16fa1a01a1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-892411c6-4849-444e-96e2-b8698ac87388,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454967216-172.17.0.17-1597529679304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34538,DS-53ca386c-0c99-4e61-bd18-7968c73d22a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-fc038c18-0695-45c3-a963-a6e5b07f6168,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-8da1d9f8-2b14-4dd1-b6e1-cef1b892b3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-7d488688-38d3-457c-9a59-09ef44052e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-9a08046b-cca7-4e0e-852d-1c90aa1c3b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-c263d9d1-6116-4b6c-a7cd-6a32647d1790,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-d216e6eb-fb23-451f-acf2-16fa1a01a1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-892411c6-4849-444e-96e2-b8698ac87388,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-387200573-172.17.0.17-1597529950623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34517,DS-517e4744-aaaf-4d2f-98fe-529aa765fae5,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-541f62cc-45b8-452d-9ae1-f7940232b900,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-3c08dd87-c82b-4294-a321-8a10972cf5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-b869be8c-c609-427b-8887-c833983e3606,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-7abf2442-0a03-4034-b15b-ce83b64cf498,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-b8e632d2-c048-49a6-92ed-7f47e9ce6d72,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-ad166631-4c8f-4711-9e6c-4d3b6195ebb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-b2130baf-ccd5-403c-b047-c094cf5e647a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-387200573-172.17.0.17-1597529950623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34517,DS-517e4744-aaaf-4d2f-98fe-529aa765fae5,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-541f62cc-45b8-452d-9ae1-f7940232b900,DISK], DatanodeInfoWithStorage[127.0.0.1:35579,DS-3c08dd87-c82b-4294-a321-8a10972cf5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-b869be8c-c609-427b-8887-c833983e3606,DISK], DatanodeInfoWithStorage[127.0.0.1:37000,DS-7abf2442-0a03-4034-b15b-ce83b64cf498,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-b8e632d2-c048-49a6-92ed-7f47e9ce6d72,DISK], DatanodeInfoWithStorage[127.0.0.1:37466,DS-ad166631-4c8f-4711-9e6c-4d3b6195ebb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-b2130baf-ccd5-403c-b047-c094cf5e647a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396441059-172.17.0.17-1597530199046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36453,DS-629f4796-e98e-41ea-babf-26c2ece5c854,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-3c197f92-c76c-40ae-b74b-0a54e5cc3b59,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-64467f2d-2b0e-4014-a36f-2220b78c531d,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-3a549801-32cc-4e72-bd33-3c6f24dfd611,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-75736770-fbb0-4e49-880c-46614e0eb06f,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-569a3a1a-2d61-443c-a655-4097cc2805a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-584eaace-347f-48f8-a17d-6a25b40cf631,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-d8297e6e-d40b-4aa7-b73c-1fc078f06028,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396441059-172.17.0.17-1597530199046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36453,DS-629f4796-e98e-41ea-babf-26c2ece5c854,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-3c197f92-c76c-40ae-b74b-0a54e5cc3b59,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-64467f2d-2b0e-4014-a36f-2220b78c531d,DISK], DatanodeInfoWithStorage[127.0.0.1:40751,DS-3a549801-32cc-4e72-bd33-3c6f24dfd611,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-75736770-fbb0-4e49-880c-46614e0eb06f,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-569a3a1a-2d61-443c-a655-4097cc2805a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-584eaace-347f-48f8-a17d-6a25b40cf631,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-d8297e6e-d40b-4aa7-b73c-1fc078f06028,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1911245471-172.17.0.17-1597530428515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33061,DS-974e2162-38ee-4c6f-b5b9-5bb7e0480d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-6564d902-9fef-4460-93a3-bd4363544a50,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-105d1166-f772-432f-9c34-92221e329d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-59d2293e-8f11-4955-8497-46cb6b72a081,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-3aa971be-5c1a-4a37-92e0-387f5a2c6deb,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-cf5c1361-1b79-43a0-94f7-95af59561aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-8dd8ee18-3157-4e1b-a576-512255872a96,DISK], DatanodeInfoWithStorage[127.0.0.1:38446,DS-41f5e4bf-6539-43d1-8cd2-dcc6d43e2d01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1911245471-172.17.0.17-1597530428515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33061,DS-974e2162-38ee-4c6f-b5b9-5bb7e0480d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-6564d902-9fef-4460-93a3-bd4363544a50,DISK], DatanodeInfoWithStorage[127.0.0.1:33221,DS-105d1166-f772-432f-9c34-92221e329d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-59d2293e-8f11-4955-8497-46cb6b72a081,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-3aa971be-5c1a-4a37-92e0-387f5a2c6deb,DISK], DatanodeInfoWithStorage[127.0.0.1:39462,DS-cf5c1361-1b79-43a0-94f7-95af59561aa2,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-8dd8ee18-3157-4e1b-a576-512255872a96,DISK], DatanodeInfoWithStorage[127.0.0.1:38446,DS-41f5e4bf-6539-43d1-8cd2-dcc6d43e2d01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742516714-172.17.0.17-1597530701086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36284,DS-ac8d426f-7186-4436-9dca-45b1beba41ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-22183f52-e2da-4760-b52d-d72045eb1b74,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-87ee6ef2-7cad-4c59-bc8b-490c8164c811,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-7af22633-2bfc-4d98-8a31-9534ca9d4b68,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-1edbcd1d-ec99-4f74-bf78-beea0916c0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-f78b1088-9b90-4562-8e52-10bc6b0b0587,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-f50d9e48-2943-44f3-9d24-c766a2e5a990,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-ef65b24c-e90c-47a8-9a7d-cc82cdeb7122,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742516714-172.17.0.17-1597530701086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36284,DS-ac8d426f-7186-4436-9dca-45b1beba41ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-22183f52-e2da-4760-b52d-d72045eb1b74,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-87ee6ef2-7cad-4c59-bc8b-490c8164c811,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-7af22633-2bfc-4d98-8a31-9534ca9d4b68,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-1edbcd1d-ec99-4f74-bf78-beea0916c0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-f78b1088-9b90-4562-8e52-10bc6b0b0587,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-f50d9e48-2943-44f3-9d24-c766a2e5a990,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-ef65b24c-e90c-47a8-9a7d-cc82cdeb7122,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-970475073-172.17.0.17-1597530922359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39221,DS-a6fe70f9-e700-4fc6-aceb-d982af9e96c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-03606e00-25e7-4a30-9ff8-bdb64178dc07,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-8c447c8b-db5b-457a-a3cf-232db37153a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-dd49b1e4-08ac-4e1b-acea-1921b2c98628,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-ed0c7a10-21eb-414b-b547-99453c3f4fde,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-05619b5c-90a3-4033-b7df-9379412be797,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-82093d07-0981-4de5-9fa9-738b72e2e238,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-3f9ba45a-82a6-424d-8f78-873e12ad257e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-970475073-172.17.0.17-1597530922359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39221,DS-a6fe70f9-e700-4fc6-aceb-d982af9e96c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-03606e00-25e7-4a30-9ff8-bdb64178dc07,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-8c447c8b-db5b-457a-a3cf-232db37153a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44251,DS-dd49b1e4-08ac-4e1b-acea-1921b2c98628,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-ed0c7a10-21eb-414b-b547-99453c3f4fde,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-05619b5c-90a3-4033-b7df-9379412be797,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-82093d07-0981-4de5-9fa9-738b72e2e238,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-3f9ba45a-82a6-424d-8f78-873e12ad257e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-699402821-172.17.0.17-1597531403257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33456,DS-5f975ec3-0b01-466f-b975-3a90e76b3a06,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-454c4399-9ee5-40f0-8c19-89539c334bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-87327a5a-f8ab-4cea-9b5e-08cdd23e4ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-d75270c7-3548-43a2-85fb-19177490e7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-e9df4703-27dd-4c98-b771-b142588da294,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-aae2dcf4-a6f2-4b43-a296-a511ee0d8614,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-2d871875-b0c5-49de-8a99-ca436e6b5837,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-51abedd8-9d93-484d-a3a8-0828c999bf27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-699402821-172.17.0.17-1597531403257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33456,DS-5f975ec3-0b01-466f-b975-3a90e76b3a06,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-454c4399-9ee5-40f0-8c19-89539c334bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43461,DS-87327a5a-f8ab-4cea-9b5e-08cdd23e4ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-d75270c7-3548-43a2-85fb-19177490e7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-e9df4703-27dd-4c98-b771-b142588da294,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-aae2dcf4-a6f2-4b43-a296-a511ee0d8614,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-2d871875-b0c5-49de-8a99-ca436e6b5837,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-51abedd8-9d93-484d-a3a8-0828c999bf27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-577209652-172.17.0.17-1597531580933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36211,DS-79a2af0e-3a92-407f-ad5e-11fe7cad58a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-cb6b477d-5923-41a9-a83d-adf16741eb74,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-cf217ef6-162c-4bbc-a2d0-a5f8510725b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-9cbbd9dd-949a-4815-a651-6c0920b4fdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-debbabaf-09aa-4ac7-bd08-6f37f4bbfe88,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-469cebfa-dbb0-4084-8939-9ca5c47865a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-b8e932f6-2dab-4865-ae4e-830bda98fdca,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-0d220fde-7e24-46b8-b77c-bf5aff6f18e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-577209652-172.17.0.17-1597531580933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36211,DS-79a2af0e-3a92-407f-ad5e-11fe7cad58a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42094,DS-cb6b477d-5923-41a9-a83d-adf16741eb74,DISK], DatanodeInfoWithStorage[127.0.0.1:43046,DS-cf217ef6-162c-4bbc-a2d0-a5f8510725b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-9cbbd9dd-949a-4815-a651-6c0920b4fdb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-debbabaf-09aa-4ac7-bd08-6f37f4bbfe88,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-469cebfa-dbb0-4084-8939-9ca5c47865a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-b8e932f6-2dab-4865-ae4e-830bda98fdca,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-0d220fde-7e24-46b8-b77c-bf5aff6f18e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1933285944-172.17.0.17-1597531871116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37316,DS-ef4c9ea5-d8d6-4fa9-be74-e904fd0909f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-7df4d24b-976d-4ec4-961f-d0d6c18898a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-2cdd20b9-2f21-4857-ac8f-6f6b6cdcc3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39436,DS-876f8ee9-23db-4447-9e1a-7cf59ce58c22,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-9dbf2f8b-1ffe-4aa4-acd3-7428f2a002b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-6937ccb5-9938-4d0c-aec4-0bced72a49e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-c47e70b0-0ea3-4bfe-a73d-be4c3bd679ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-3b288f16-bb9e-4f0d-a92f-d4a9a0be7ea9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1933285944-172.17.0.17-1597531871116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37316,DS-ef4c9ea5-d8d6-4fa9-be74-e904fd0909f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-7df4d24b-976d-4ec4-961f-d0d6c18898a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-2cdd20b9-2f21-4857-ac8f-6f6b6cdcc3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39436,DS-876f8ee9-23db-4447-9e1a-7cf59ce58c22,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-9dbf2f8b-1ffe-4aa4-acd3-7428f2a002b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-6937ccb5-9938-4d0c-aec4-0bced72a49e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-c47e70b0-0ea3-4bfe-a73d-be4c3bd679ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-3b288f16-bb9e-4f0d-a92f-d4a9a0be7ea9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-590256222-172.17.0.17-1597532249602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44267,DS-b76d2e50-39f3-465d-a8b6-bc944a1ffd32,DISK], DatanodeInfoWithStorage[127.0.0.1:42427,DS-3b37d337-a121-4399-8e73-e2c894226839,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-8205967c-d705-436c-ad8d-6d36aa26fc50,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-a830d942-478c-465c-8356-3ee3131c5805,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-9c51a4d3-6764-4bff-a8b4-89f3e6438f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-8b1b695c-6b5f-4065-a75c-9eda548dc513,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-48ad6768-314c-47db-a45b-e873e4cd8011,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-3a7e1032-79bd-4adc-940a-6757ddc75e3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-590256222-172.17.0.17-1597532249602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44267,DS-b76d2e50-39f3-465d-a8b6-bc944a1ffd32,DISK], DatanodeInfoWithStorage[127.0.0.1:42427,DS-3b37d337-a121-4399-8e73-e2c894226839,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-8205967c-d705-436c-ad8d-6d36aa26fc50,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-a830d942-478c-465c-8356-3ee3131c5805,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-9c51a4d3-6764-4bff-a8b4-89f3e6438f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-8b1b695c-6b5f-4065-a75c-9eda548dc513,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-48ad6768-314c-47db-a45b-e873e4cd8011,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-3a7e1032-79bd-4adc-940a-6757ddc75e3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344926516-172.17.0.17-1597532500759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35215,DS-e4e8e9a3-59b1-4bf1-a252-ad82e7e91410,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-92609c32-d927-4ba4-b53b-7cc9378aa501,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-b4812860-f23e-4762-a822-fece168e82ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-8e5ede23-6e2b-4417-a1ba-d353b65404bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-f26e1137-ac15-4278-8cb5-11522917b863,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-af0bd2ab-1032-4f6d-a0c5-2eb6a1340546,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-3cd0bc97-bdc7-4905-bce4-57dc5bb408a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-1caf9a2d-3397-4487-95d2-5b9369bcc432,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344926516-172.17.0.17-1597532500759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35215,DS-e4e8e9a3-59b1-4bf1-a252-ad82e7e91410,DISK], DatanodeInfoWithStorage[127.0.0.1:38722,DS-92609c32-d927-4ba4-b53b-7cc9378aa501,DISK], DatanodeInfoWithStorage[127.0.0.1:45246,DS-b4812860-f23e-4762-a822-fece168e82ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-8e5ede23-6e2b-4417-a1ba-d353b65404bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-f26e1137-ac15-4278-8cb5-11522917b863,DISK], DatanodeInfoWithStorage[127.0.0.1:38016,DS-af0bd2ab-1032-4f6d-a0c5-2eb6a1340546,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-3cd0bc97-bdc7-4905-bce4-57dc5bb408a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-1caf9a2d-3397-4487-95d2-5b9369bcc432,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-563311413-172.17.0.17-1597532624079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34506,DS-03861377-f0cb-470d-ac4d-dfa23e237c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-6393bb6f-e218-468b-9e56-15fce71a28b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-fe84b36c-16ba-490c-a8a7-c557a17169ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-731aa4e6-9eae-493c-b561-7ec5eb30c4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-65727cc3-b94f-4956-a7bc-d8dd868745c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35739,DS-244644f0-9022-4258-8a3c-57376e61ec16,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-930bc020-54bd-4d97-98b8-00a14e5e5db9,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-77338f6c-7072-4f12-9c8a-0e03436e888b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-563311413-172.17.0.17-1597532624079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34506,DS-03861377-f0cb-470d-ac4d-dfa23e237c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:41083,DS-6393bb6f-e218-468b-9e56-15fce71a28b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-fe84b36c-16ba-490c-a8a7-c557a17169ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-731aa4e6-9eae-493c-b561-7ec5eb30c4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-65727cc3-b94f-4956-a7bc-d8dd868745c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35739,DS-244644f0-9022-4258-8a3c-57376e61ec16,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-930bc020-54bd-4d97-98b8-00a14e5e5db9,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-77338f6c-7072-4f12-9c8a-0e03436e888b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1491077881-172.17.0.17-1597532925532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43284,DS-77b78e62-dcaa-44db-80e7-9aa4885ea9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-6d3aa1e0-2260-46c6-b048-534f2415fb43,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-a5c97e61-49e8-47b0-befb-85ecba8ee051,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-c13b172b-e031-430c-80a6-ff6e059f6184,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-02c75a35-c958-42fd-bde3-789512b05013,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-d0df4ff7-d6ab-4808-ab73-d3301d23ac75,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-0b623a6d-b28b-4f04-a4e8-bcc297615cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-9b2f982e-f629-4165-8106-b169e9f5d3d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1491077881-172.17.0.17-1597532925532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43284,DS-77b78e62-dcaa-44db-80e7-9aa4885ea9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44904,DS-6d3aa1e0-2260-46c6-b048-534f2415fb43,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-a5c97e61-49e8-47b0-befb-85ecba8ee051,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-c13b172b-e031-430c-80a6-ff6e059f6184,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-02c75a35-c958-42fd-bde3-789512b05013,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-d0df4ff7-d6ab-4808-ab73-d3301d23ac75,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-0b623a6d-b28b-4f04-a4e8-bcc297615cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40914,DS-9b2f982e-f629-4165-8106-b169e9f5d3d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1577346810-172.17.0.17-1597533175682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43886,DS-6f625d29-4f65-455e-8021-d7a7152860d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-fdc3982e-c2c7-4c5f-bcfb-0e478f8f6703,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-8959e59d-0022-4a68-acf9-354b9f94d8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34591,DS-9c7a46e4-629d-46ec-84fa-4938b4e1ee3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-77ae3aff-8006-45c9-b344-52e9ecd2f983,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-7e6377a1-bfb3-4413-ba3d-c9e32d7228e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-c56d7b5b-8c26-45ce-b6e5-421bec410b88,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-4c3768b3-3492-40d3-a41b-c343cdf5d115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1577346810-172.17.0.17-1597533175682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43886,DS-6f625d29-4f65-455e-8021-d7a7152860d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-fdc3982e-c2c7-4c5f-bcfb-0e478f8f6703,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-8959e59d-0022-4a68-acf9-354b9f94d8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34591,DS-9c7a46e4-629d-46ec-84fa-4938b4e1ee3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33415,DS-77ae3aff-8006-45c9-b344-52e9ecd2f983,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-7e6377a1-bfb3-4413-ba3d-c9e32d7228e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-c56d7b5b-8c26-45ce-b6e5-421bec410b88,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-4c3768b3-3492-40d3-a41b-c343cdf5d115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-435295435-172.17.0.17-1597533208997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44830,DS-14cc2f51-3b3c-4858-8797-2c8c3c057de5,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-fa622406-1a9c-4406-8552-867b8edfe014,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-a65f125c-0f7a-4d93-adcd-dbef793fb0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-66dc18ca-d340-487f-9f19-2ae53c187bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-204c195b-f1a8-4e24-9527-0980c525311b,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-44548223-bfaf-4d75-ad8d-347c4647b129,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-2e2cb9b5-37c8-4639-afa9-31958c59c5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-3158b578-e784-4b0a-aa01-f28786e368c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-435295435-172.17.0.17-1597533208997:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44830,DS-14cc2f51-3b3c-4858-8797-2c8c3c057de5,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-fa622406-1a9c-4406-8552-867b8edfe014,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-a65f125c-0f7a-4d93-adcd-dbef793fb0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39907,DS-66dc18ca-d340-487f-9f19-2ae53c187bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:35959,DS-204c195b-f1a8-4e24-9527-0980c525311b,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-44548223-bfaf-4d75-ad8d-347c4647b129,DISK], DatanodeInfoWithStorage[127.0.0.1:32939,DS-2e2cb9b5-37c8-4639-afa9-31958c59c5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-3158b578-e784-4b0a-aa01-f28786e368c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1916203135-172.17.0.17-1597533333580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36698,DS-67241f01-b265-4d74-b74b-3997f54c7590,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-56c93ec5-b116-4a8a-8bdc-7c6d515d4c45,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-161992a7-c8d5-403a-91db-885db0516d62,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-93420286-519c-482a-82e4-e35f3abc9042,DISK], DatanodeInfoWithStorage[127.0.0.1:40065,DS-a490abba-b119-4995-a547-91345adc4ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-17928a74-fceb-4efd-8e8b-5dd7379110db,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-6197257d-294d-4a86-bb8a-efb05dd66d04,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-84ff8833-5d3d-41a7-b827-fafdab45d017,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1916203135-172.17.0.17-1597533333580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36698,DS-67241f01-b265-4d74-b74b-3997f54c7590,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-56c93ec5-b116-4a8a-8bdc-7c6d515d4c45,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-161992a7-c8d5-403a-91db-885db0516d62,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-93420286-519c-482a-82e4-e35f3abc9042,DISK], DatanodeInfoWithStorage[127.0.0.1:40065,DS-a490abba-b119-4995-a547-91345adc4ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-17928a74-fceb-4efd-8e8b-5dd7379110db,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-6197257d-294d-4a86-bb8a-efb05dd66d04,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-84ff8833-5d3d-41a7-b827-fafdab45d017,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5653
