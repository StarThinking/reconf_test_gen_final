reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049079998-172.17.0.5-1597376021994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44696,DS-db1e55c0-1712-47c9-ac6c-a8a958cb869d,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-89c6b941-bfaa-4077-9720-188dd73c6d24,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-fe54d1ab-f1fa-4371-ae8f-70e27ec0ff59,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-5cda3775-f692-4519-9308-af5635f07c48,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-403f0d41-a6be-4f04-8d2f-0364541127b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-73e53853-2b6a-4297-9071-34790b099aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-13aabc99-0f9e-48f5-b108-b30e35e6777d,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-faa4ee7f-2665-4e31-b329-33306ad8cfd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049079998-172.17.0.5-1597376021994:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44696,DS-db1e55c0-1712-47c9-ac6c-a8a958cb869d,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-89c6b941-bfaa-4077-9720-188dd73c6d24,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-fe54d1ab-f1fa-4371-ae8f-70e27ec0ff59,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-5cda3775-f692-4519-9308-af5635f07c48,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-403f0d41-a6be-4f04-8d2f-0364541127b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-73e53853-2b6a-4297-9071-34790b099aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-13aabc99-0f9e-48f5-b108-b30e35e6777d,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-faa4ee7f-2665-4e31-b329-33306ad8cfd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1114594790-172.17.0.5-1597376131804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42631,DS-2b2ed5a9-a8c4-4b3e-b8ca-2f3da992f336,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-cdf19ee8-602e-4864-869c-37d8220847e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-00aa5622-0fff-4378-a9bd-af7a5eb2f9be,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-6e9dce19-346e-4be7-9830-0d345b1dd2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-53c71254-9841-4fcf-81b4-2ed0ca048464,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-8094d8df-d3c6-475b-b7a3-206b5dcbe902,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-7447255f-92b1-48b0-a018-7f4f77ebd63b,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-ec219e9a-8303-454d-a753-1be5d3e235d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1114594790-172.17.0.5-1597376131804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42631,DS-2b2ed5a9-a8c4-4b3e-b8ca-2f3da992f336,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-cdf19ee8-602e-4864-869c-37d8220847e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46227,DS-00aa5622-0fff-4378-a9bd-af7a5eb2f9be,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-6e9dce19-346e-4be7-9830-0d345b1dd2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-53c71254-9841-4fcf-81b4-2ed0ca048464,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-8094d8df-d3c6-475b-b7a3-206b5dcbe902,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-7447255f-92b1-48b0-a018-7f4f77ebd63b,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-ec219e9a-8303-454d-a753-1be5d3e235d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-865871777-172.17.0.5-1597376522382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41339,DS-f2b1ba87-6bbe-408f-ae3c-26d571c6b554,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-fb56e38e-4ada-4883-a3db-6e4fb44048f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-cffa0373-e4a5-4802-be56-7b5b86ef04d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-87bfc370-de4a-4569-8624-31b7eb0674b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-42c8328e-1925-48c5-be6e-49c1dc56354b,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-c338ce16-dba1-4d79-b469-d652f2baed99,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-3f659f15-6e67-499a-b8ca-ff71ef6080d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-4d7fac6d-4804-4bc0-a936-b2daf68abfe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-865871777-172.17.0.5-1597376522382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41339,DS-f2b1ba87-6bbe-408f-ae3c-26d571c6b554,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-fb56e38e-4ada-4883-a3db-6e4fb44048f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-cffa0373-e4a5-4802-be56-7b5b86ef04d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-87bfc370-de4a-4569-8624-31b7eb0674b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-42c8328e-1925-48c5-be6e-49c1dc56354b,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-c338ce16-dba1-4d79-b469-d652f2baed99,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-3f659f15-6e67-499a-b8ca-ff71ef6080d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-4d7fac6d-4804-4bc0-a936-b2daf68abfe6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-775824436-172.17.0.5-1597376660327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45141,DS-29d26e0c-cbe0-4878-aee5-bc19f18702b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-ea5ceb09-5ecc-40f8-8ebb-a285d8b79a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-7a9a013d-48a4-4a50-84e7-69cb6db06d51,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-c08f1c29-91c7-4c14-81a9-cb020aeddc85,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-3e5520e1-217f-4d52-875b-1b66a60ef5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-f9d97ec7-f42c-436c-8981-ffb1f86fecbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-5fb98f89-598b-447c-8bc1-d4c7256c0792,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-6092ceac-92ff-45e1-b4d0-73d748c7e70f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-775824436-172.17.0.5-1597376660327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45141,DS-29d26e0c-cbe0-4878-aee5-bc19f18702b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-ea5ceb09-5ecc-40f8-8ebb-a285d8b79a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45037,DS-7a9a013d-48a4-4a50-84e7-69cb6db06d51,DISK], DatanodeInfoWithStorage[127.0.0.1:43927,DS-c08f1c29-91c7-4c14-81a9-cb020aeddc85,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-3e5520e1-217f-4d52-875b-1b66a60ef5e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-f9d97ec7-f42c-436c-8981-ffb1f86fecbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-5fb98f89-598b-447c-8bc1-d4c7256c0792,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-6092ceac-92ff-45e1-b4d0-73d748c7e70f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1574722625-172.17.0.5-1597376759092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42269,DS-94748623-bd1e-444c-8801-0e41f55230ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-f0e001ba-e108-4cfb-9189-176ec49ee374,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-1ebb6062-fe49-4043-8a69-f59180916d52,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-a6f4ee56-1d34-4c76-8cf0-35e7cc5e4b11,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-7ff71868-fcdf-4229-85e0-544b1578aabf,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-d24ee427-05c2-4470-88a4-579c6b47e0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-10a7b984-fe26-46ff-9598-e18a273993a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-9b47543f-5d4d-4b2a-9e62-34e18f7efba3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1574722625-172.17.0.5-1597376759092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42269,DS-94748623-bd1e-444c-8801-0e41f55230ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-f0e001ba-e108-4cfb-9189-176ec49ee374,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-1ebb6062-fe49-4043-8a69-f59180916d52,DISK], DatanodeInfoWithStorage[127.0.0.1:40051,DS-a6f4ee56-1d34-4c76-8cf0-35e7cc5e4b11,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-7ff71868-fcdf-4229-85e0-544b1578aabf,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-d24ee427-05c2-4470-88a4-579c6b47e0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-10a7b984-fe26-46ff-9598-e18a273993a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-9b47543f-5d4d-4b2a-9e62-34e18f7efba3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954481987-172.17.0.5-1597377016784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37619,DS-55fdabd7-e831-4387-b13d-f9efbedfae7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-596591cb-9815-4f72-a5f7-c3793b4f3ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-836cac4d-7ca6-425d-8e64-7e9b42239a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-76ec102d-8c53-4c61-b65c-b94a6d4ce795,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-f25c88c5-f7e2-4f97-9eac-59966cd51738,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-427d5943-01bf-4162-bad3-5a7250c5e085,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-5b27477a-1fbe-438f-be75-ffa2606fdd53,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-158d2ca8-8362-4043-8940-80ad44acb464,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954481987-172.17.0.5-1597377016784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37619,DS-55fdabd7-e831-4387-b13d-f9efbedfae7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-596591cb-9815-4f72-a5f7-c3793b4f3ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-836cac4d-7ca6-425d-8e64-7e9b42239a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-76ec102d-8c53-4c61-b65c-b94a6d4ce795,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-f25c88c5-f7e2-4f97-9eac-59966cd51738,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-427d5943-01bf-4162-bad3-5a7250c5e085,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-5b27477a-1fbe-438f-be75-ffa2606fdd53,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-158d2ca8-8362-4043-8940-80ad44acb464,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1897245604-172.17.0.5-1597377416719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46713,DS-b03b2780-65ff-4b3e-ad6e-6c8f245de5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-eb778d76-33c4-4618-aed4-9849a7355327,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-9923de48-7fa3-4680-809b-2db062889e86,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-897403c5-8710-4373-a935-1f289f01e30f,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-cf9dd722-bdea-45fd-baa1-f88aadc48d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-89822a5c-1675-4fb9-a621-9e835869cdb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-597cb936-6160-4962-a028-4fc4006d55b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-1ec373f4-9914-4d68-9c89-b1cacdd43b72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1897245604-172.17.0.5-1597377416719:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46713,DS-b03b2780-65ff-4b3e-ad6e-6c8f245de5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-eb778d76-33c4-4618-aed4-9849a7355327,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-9923de48-7fa3-4680-809b-2db062889e86,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-897403c5-8710-4373-a935-1f289f01e30f,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-cf9dd722-bdea-45fd-baa1-f88aadc48d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-89822a5c-1675-4fb9-a621-9e835869cdb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-597cb936-6160-4962-a028-4fc4006d55b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35215,DS-1ec373f4-9914-4d68-9c89-b1cacdd43b72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-240448751-172.17.0.5-1597377947123:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35002,DS-2ea5cb8f-3f8c-4119-80db-1b36c4bb78dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-1ec7e042-005e-4631-b015-9451e56499a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-faec8942-976e-4d32-a314-6b487a415804,DISK], DatanodeInfoWithStorage[127.0.0.1:45392,DS-84b37835-af6c-40f5-8e90-55ebdcb800ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-dffbbf6b-9562-4366-9fe0-6666a03f1f57,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-6ce991e9-73ea-4066-9d9c-403be876bbed,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-c6410dec-1775-4d79-8a32-696049b7b50f,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-911e2764-9314-4166-9065-516013ddcb7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-240448751-172.17.0.5-1597377947123:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35002,DS-2ea5cb8f-3f8c-4119-80db-1b36c4bb78dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-1ec7e042-005e-4631-b015-9451e56499a3,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-faec8942-976e-4d32-a314-6b487a415804,DISK], DatanodeInfoWithStorage[127.0.0.1:45392,DS-84b37835-af6c-40f5-8e90-55ebdcb800ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37679,DS-dffbbf6b-9562-4366-9fe0-6666a03f1f57,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-6ce991e9-73ea-4066-9d9c-403be876bbed,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-c6410dec-1775-4d79-8a32-696049b7b50f,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-911e2764-9314-4166-9065-516013ddcb7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1817146952-172.17.0.5-1597378972670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41852,DS-12f9bf90-862c-4bc6-a0d2-7957762443ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-132bfb52-8f6c-47d1-8637-3408711a94b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-0e7a0ad4-2943-4582-ab02-4d549e7ff30e,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-28b5be19-f165-4889-8a24-a83d753a8da4,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-a9df1d54-a61f-4ef3-9ecb-115b9d495d35,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-4cf40627-018a-4be7-9944-afbb35dccdc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36890,DS-4f9e4095-3b30-4bc7-a3a7-5d26f419dbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-9f3c606f-6d76-49b0-b872-237ca492f870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1817146952-172.17.0.5-1597378972670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41852,DS-12f9bf90-862c-4bc6-a0d2-7957762443ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-132bfb52-8f6c-47d1-8637-3408711a94b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41513,DS-0e7a0ad4-2943-4582-ab02-4d549e7ff30e,DISK], DatanodeInfoWithStorage[127.0.0.1:37785,DS-28b5be19-f165-4889-8a24-a83d753a8da4,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-a9df1d54-a61f-4ef3-9ecb-115b9d495d35,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-4cf40627-018a-4be7-9944-afbb35dccdc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36890,DS-4f9e4095-3b30-4bc7-a3a7-5d26f419dbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39510,DS-9f3c606f-6d76-49b0-b872-237ca492f870,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1742441732-172.17.0.5-1597379273337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46143,DS-b8833235-2648-41f0-b63f-d87dab702e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-adafce19-f2b4-4324-9e38-848981a1687f,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-3a7b7393-49f8-483d-b06b-a00c4e7ada06,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-e121a4e0-5838-49a4-830c-c1e3252da9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-e720d623-f265-4153-8969-67a4c5e3539f,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-6b217f66-d0f1-4e7d-949c-cf86bd730cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-6452e5e7-2c04-4604-8108-6215db76b84b,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-14eab081-6c8e-497d-9f48-554064826ac2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1742441732-172.17.0.5-1597379273337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46143,DS-b8833235-2648-41f0-b63f-d87dab702e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-adafce19-f2b4-4324-9e38-848981a1687f,DISK], DatanodeInfoWithStorage[127.0.0.1:44155,DS-3a7b7393-49f8-483d-b06b-a00c4e7ada06,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-e121a4e0-5838-49a4-830c-c1e3252da9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-e720d623-f265-4153-8969-67a4c5e3539f,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-6b217f66-d0f1-4e7d-949c-cf86bd730cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42631,DS-6452e5e7-2c04-4604-8108-6215db76b84b,DISK], DatanodeInfoWithStorage[127.0.0.1:34270,DS-14eab081-6c8e-497d-9f48-554064826ac2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739396043-172.17.0.5-1597380162277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43519,DS-1e88d1a9-e95c-43bf-9318-e1288b93af53,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-378993fd-8b98-4b92-931f-fc97e27d4761,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-3a7e9d0d-3f78-4ea7-9fdc-a15907074be7,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-ab16365e-ca2d-45cd-93cf-cfc49e537728,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-5a9deb7d-b2d3-4012-9598-213f1982fe21,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-00eac6f1-778a-418b-8780-51a313706886,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-dd0e9839-3bdb-4521-84bd-4560f48bbb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-6d77de3e-46dc-41ed-8bc0-aea9dd8b2419,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739396043-172.17.0.5-1597380162277:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43519,DS-1e88d1a9-e95c-43bf-9318-e1288b93af53,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-378993fd-8b98-4b92-931f-fc97e27d4761,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-3a7e9d0d-3f78-4ea7-9fdc-a15907074be7,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-ab16365e-ca2d-45cd-93cf-cfc49e537728,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-5a9deb7d-b2d3-4012-9598-213f1982fe21,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-00eac6f1-778a-418b-8780-51a313706886,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-dd0e9839-3bdb-4521-84bd-4560f48bbb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-6d77de3e-46dc-41ed-8bc0-aea9dd8b2419,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877225470-172.17.0.5-1597380406809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38675,DS-bc7209e9-8b9f-41bc-98c9-59a2f87ab638,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-093a01fa-6b8c-4eae-8706-83866a6d973c,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-b21f9bd0-9640-4b82-8eef-0f23a827c0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-14bc7f47-e1fc-4a63-a30d-c0c2145aac60,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-80e3bb13-ed50-4893-8a95-a8e8d90e571d,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-0658f71e-2e63-44b5-a6d1-96711ea5e0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-5fcddd5e-eb3d-4ca1-be0d-4d99857e68ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-b977ac16-62cf-45f5-9bd5-bc98841d5e28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1877225470-172.17.0.5-1597380406809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38675,DS-bc7209e9-8b9f-41bc-98c9-59a2f87ab638,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-093a01fa-6b8c-4eae-8706-83866a6d973c,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-b21f9bd0-9640-4b82-8eef-0f23a827c0c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-14bc7f47-e1fc-4a63-a30d-c0c2145aac60,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-80e3bb13-ed50-4893-8a95-a8e8d90e571d,DISK], DatanodeInfoWithStorage[127.0.0.1:38166,DS-0658f71e-2e63-44b5-a6d1-96711ea5e0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-5fcddd5e-eb3d-4ca1-be0d-4d99857e68ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-b977ac16-62cf-45f5-9bd5-bc98841d5e28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1368164718-172.17.0.5-1597380684393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42626,DS-267078df-8b5f-42cc-9227-df8d91402c19,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-4ea21099-a1b8-492c-abb0-08fe88edfc50,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-22ba7e9d-4e62-4574-9a13-381bf659ef61,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-7fac964c-2cae-4676-908e-1d2dc402cd03,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-d5c09089-41c6-448d-b984-4fd8a6f1978e,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-e440bf15-0399-40c8-a937-50b8022b67b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-f640db7c-8147-405e-a195-509898b3e6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-4e54a694-0134-41b5-8084-5a7eaca41c2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1368164718-172.17.0.5-1597380684393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42626,DS-267078df-8b5f-42cc-9227-df8d91402c19,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-4ea21099-a1b8-492c-abb0-08fe88edfc50,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-22ba7e9d-4e62-4574-9a13-381bf659ef61,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-7fac964c-2cae-4676-908e-1d2dc402cd03,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-d5c09089-41c6-448d-b984-4fd8a6f1978e,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-e440bf15-0399-40c8-a937-50b8022b67b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-f640db7c-8147-405e-a195-509898b3e6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-4e54a694-0134-41b5-8084-5a7eaca41c2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1753830433-172.17.0.5-1597381317981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33269,DS-dfd909cd-ca2d-466e-829c-4d750a7c9905,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-f8a28eaf-b70e-464c-8547-60ee36012067,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-7385431b-50c1-49dc-b956-2ba7c4e2f185,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-e08090b7-8e2d-4983-9df6-b50d7eb2efec,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-9b07d527-1fa6-499d-811e-1cd095c7c7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-a80edf65-b91e-4dbc-9e30-f08ec26cafd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-3d6667f2-3ff2-49c3-8237-c18be2f624c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-4cbe80f8-4e2c-4d54-bb1e-c94cda20fb69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1753830433-172.17.0.5-1597381317981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33269,DS-dfd909cd-ca2d-466e-829c-4d750a7c9905,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-f8a28eaf-b70e-464c-8547-60ee36012067,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-7385431b-50c1-49dc-b956-2ba7c4e2f185,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-e08090b7-8e2d-4983-9df6-b50d7eb2efec,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-9b07d527-1fa6-499d-811e-1cd095c7c7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33963,DS-a80edf65-b91e-4dbc-9e30-f08ec26cafd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-3d6667f2-3ff2-49c3-8237-c18be2f624c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-4cbe80f8-4e2c-4d54-bb1e-c94cda20fb69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5461
