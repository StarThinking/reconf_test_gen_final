reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1172188110-172.17.0.8-1597479142777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46811,DS-7884ae48-561c-47e2-95a6-a1e4ce5e09e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-71971e6a-8725-4072-b745-a4d6f2bf16fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-9a2a65e3-f5e6-45a0-aa52-0232d3a9d04b,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-9f2229e3-8371-47e3-8682-ce2d8d8df60b,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-0b080e10-ad13-44b6-b046-3c20183145fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-1acff0e5-6a67-430b-919b-ab3d54d12828,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-993b105b-758d-4493-ae0b-8cb3813acdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-cc8dab83-c380-4608-b497-7d2bbb8774b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1172188110-172.17.0.8-1597479142777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46811,DS-7884ae48-561c-47e2-95a6-a1e4ce5e09e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-71971e6a-8725-4072-b745-a4d6f2bf16fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-9a2a65e3-f5e6-45a0-aa52-0232d3a9d04b,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-9f2229e3-8371-47e3-8682-ce2d8d8df60b,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-0b080e10-ad13-44b6-b046-3c20183145fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-1acff0e5-6a67-430b-919b-ab3d54d12828,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-993b105b-758d-4493-ae0b-8cb3813acdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-cc8dab83-c380-4608-b497-7d2bbb8774b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-622083049-172.17.0.8-1597479194057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43820,DS-f3d7bab6-141d-423f-bacd-ce6174c51b38,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-9a9eb48b-c00d-42af-ba31-e1a6801d4126,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-c88c5142-20be-42d3-9c78-a1d0fb2b434b,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-4b1b7d8f-3b80-4df4-b832-a6db5080e1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-64a30406-9f93-43ee-98b7-13605a9efd32,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-07612a88-5119-4093-9ec9-9fce6345985f,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-05d12bdf-4ae4-4545-975c-bf5ae66e8cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-9d91a746-c1af-4f17-80b7-b32034c1648b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-622083049-172.17.0.8-1597479194057:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43820,DS-f3d7bab6-141d-423f-bacd-ce6174c51b38,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-9a9eb48b-c00d-42af-ba31-e1a6801d4126,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-c88c5142-20be-42d3-9c78-a1d0fb2b434b,DISK], DatanodeInfoWithStorage[127.0.0.1:34594,DS-4b1b7d8f-3b80-4df4-b832-a6db5080e1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-64a30406-9f93-43ee-98b7-13605a9efd32,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-07612a88-5119-4093-9ec9-9fce6345985f,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-05d12bdf-4ae4-4545-975c-bf5ae66e8cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:37884,DS-9d91a746-c1af-4f17-80b7-b32034c1648b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1142580365-172.17.0.8-1597479452898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40475,DS-393dde42-d5d9-4906-b31b-59782fbb3580,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-7f69eeb6-557b-4c03-b52c-4bcc13be0a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-fccb5f94-86f8-49ba-b46d-6d214d2b2029,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-e6c46c8d-2036-4c1f-9e20-fa1392284cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-801f3b29-0d38-48db-83ba-45667fb1f4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-62c6b7e4-b2a8-483a-ad77-febb432d224f,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-459d19c8-f25d-4d3e-94e1-f2e226c2b039,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-eee51238-3442-4120-a12d-3f1e012e9624,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1142580365-172.17.0.8-1597479452898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40475,DS-393dde42-d5d9-4906-b31b-59782fbb3580,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-7f69eeb6-557b-4c03-b52c-4bcc13be0a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-fccb5f94-86f8-49ba-b46d-6d214d2b2029,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-e6c46c8d-2036-4c1f-9e20-fa1392284cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-801f3b29-0d38-48db-83ba-45667fb1f4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-62c6b7e4-b2a8-483a-ad77-febb432d224f,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-459d19c8-f25d-4d3e-94e1-f2e226c2b039,DISK], DatanodeInfoWithStorage[127.0.0.1:45287,DS-eee51238-3442-4120-a12d-3f1e012e9624,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1998845301-172.17.0.8-1597479905403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42608,DS-7e09255d-cfd0-4c94-a372-8b67ab8065f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-dd297cf8-9366-466f-9e03-833bbfcd6016,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-2dc73a7e-bd43-40f2-9ff0-b02afcb0f4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-7d7876ab-eb4c-425e-b1e5-0f8802f9cbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-782cbdca-7ca7-4457-bd26-e63cbae9f551,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-16bea878-1fac-4641-867d-e660538a33e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-ba24cf41-d549-4768-8281-42f3883cbcec,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-1608d705-2d69-42f0-b4fe-fe48ac95da9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1998845301-172.17.0.8-1597479905403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42608,DS-7e09255d-cfd0-4c94-a372-8b67ab8065f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-dd297cf8-9366-466f-9e03-833bbfcd6016,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-2dc73a7e-bd43-40f2-9ff0-b02afcb0f4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-7d7876ab-eb4c-425e-b1e5-0f8802f9cbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-782cbdca-7ca7-4457-bd26-e63cbae9f551,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-16bea878-1fac-4641-867d-e660538a33e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-ba24cf41-d549-4768-8281-42f3883cbcec,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-1608d705-2d69-42f0-b4fe-fe48ac95da9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-151258232-172.17.0.8-1597479938914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45965,DS-2543ba47-97a4-4064-b032-8dcbca72243b,DISK], DatanodeInfoWithStorage[127.0.0.1:35823,DS-bb434a9c-4b80-459c-80cc-80162b1fa8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-1eb62896-ae94-4895-8e58-7c0a2e92e142,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-6c1db58a-51ef-40c3-8d1b-738a5fbe962d,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-06c9d4a3-f758-4207-b7fd-7d467565f386,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-d7f317d4-5cf6-4b30-9115-96d41fdb4785,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-edb14efa-290c-4f37-85c2-dde71dff931d,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-5abc46e2-700b-4bc0-8199-8aab65ed3630,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-151258232-172.17.0.8-1597479938914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45965,DS-2543ba47-97a4-4064-b032-8dcbca72243b,DISK], DatanodeInfoWithStorage[127.0.0.1:35823,DS-bb434a9c-4b80-459c-80cc-80162b1fa8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-1eb62896-ae94-4895-8e58-7c0a2e92e142,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-6c1db58a-51ef-40c3-8d1b-738a5fbe962d,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-06c9d4a3-f758-4207-b7fd-7d467565f386,DISK], DatanodeInfoWithStorage[127.0.0.1:41879,DS-d7f317d4-5cf6-4b30-9115-96d41fdb4785,DISK], DatanodeInfoWithStorage[127.0.0.1:45398,DS-edb14efa-290c-4f37-85c2-dde71dff931d,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-5abc46e2-700b-4bc0-8199-8aab65ed3630,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1695858438-172.17.0.8-1597480569892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35763,DS-d655723f-d814-47bc-a62e-edb293e996d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-0ddca1ab-ec5f-4017-a114-6753e7d41be8,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-53193c22-8641-400a-9ce1-d00a6e793de3,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-0ab24bbf-cbc9-4a78-8826-831a6a9ed0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-14aa2c62-78f5-46de-b578-d66aedf5e9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-b48b6aa6-6be4-44d5-a17d-22d63a5cc70d,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-be51f3e4-96a3-470a-abbd-e374eb4d4f13,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-a799629d-9124-4ef7-bffb-47592146c7ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1695858438-172.17.0.8-1597480569892:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35763,DS-d655723f-d814-47bc-a62e-edb293e996d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-0ddca1ab-ec5f-4017-a114-6753e7d41be8,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-53193c22-8641-400a-9ce1-d00a6e793de3,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-0ab24bbf-cbc9-4a78-8826-831a6a9ed0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-14aa2c62-78f5-46de-b578-d66aedf5e9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-b48b6aa6-6be4-44d5-a17d-22d63a5cc70d,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-be51f3e4-96a3-470a-abbd-e374eb4d4f13,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-a799629d-9124-4ef7-bffb-47592146c7ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-995734351-172.17.0.8-1597480833259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35334,DS-e7e36e44-291d-431e-8c3b-497dff7601de,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-4cd71e1b-e8d6-49be-8ec5-d6407c6cc8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-efbac66a-57ee-42ba-97a1-61408ee0837c,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-dab0c62f-18b3-41c2-94be-37ead639b62f,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-19e945a7-5082-4e0d-8f57-234b68980e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-437578df-ccc1-48dc-9875-79b96e113553,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-c2dce93e-d9f0-4f38-a819-62a9604d5fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-00e217b2-9492-4d24-a095-e3e3aad0c02d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-995734351-172.17.0.8-1597480833259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35334,DS-e7e36e44-291d-431e-8c3b-497dff7601de,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-4cd71e1b-e8d6-49be-8ec5-d6407c6cc8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-efbac66a-57ee-42ba-97a1-61408ee0837c,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-dab0c62f-18b3-41c2-94be-37ead639b62f,DISK], DatanodeInfoWithStorage[127.0.0.1:44536,DS-19e945a7-5082-4e0d-8f57-234b68980e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-437578df-ccc1-48dc-9875-79b96e113553,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-c2dce93e-d9f0-4f38-a819-62a9604d5fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-00e217b2-9492-4d24-a095-e3e3aad0c02d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1147757882-172.17.0.8-1597480904646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41837,DS-0fffd1cd-211d-4354-b367-3d82ad3dae66,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-c6ca933f-2559-415d-8a39-55b5acbe41f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-fe9b0d3d-260b-4297-8e74-2e4fcb2369c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-81799b06-86c7-42d6-ae4d-b1047ab465ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-948d2956-ec04-4509-80f3-51eabce65e06,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-401a67f0-5120-4dde-b1e5-76948c45e247,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-d726b350-751d-4a99-9b92-d3a27c569b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-7d663414-55ab-4483-877a-966e162d78ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1147757882-172.17.0.8-1597480904646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41837,DS-0fffd1cd-211d-4354-b367-3d82ad3dae66,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-c6ca933f-2559-415d-8a39-55b5acbe41f9,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-fe9b0d3d-260b-4297-8e74-2e4fcb2369c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-81799b06-86c7-42d6-ae4d-b1047ab465ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-948d2956-ec04-4509-80f3-51eabce65e06,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-401a67f0-5120-4dde-b1e5-76948c45e247,DISK], DatanodeInfoWithStorage[127.0.0.1:38879,DS-d726b350-751d-4a99-9b92-d3a27c569b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-7d663414-55ab-4483-877a-966e162d78ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951491945-172.17.0.8-1597480986135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45613,DS-5b01e4fb-8385-4022-95e8-5768fa68f004,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-d6354138-43d2-424b-bd73-50266dd047e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-62c71d45-17bb-4a1a-872a-8a58dba387ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-17af4926-311e-491c-8e96-d3ad968fd7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-495b5e70-8d60-4b99-a2fc-f27c23234377,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-8b715d9e-cd0f-4d6c-a893-cb34ecc0c72b,DISK], DatanodeInfoWithStorage[127.0.0.1:42723,DS-f1a6eb46-ae92-4007-8ccc-a01709757e07,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-6e84146f-95d7-4ea1-98a4-704f456f9271,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951491945-172.17.0.8-1597480986135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45613,DS-5b01e4fb-8385-4022-95e8-5768fa68f004,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-d6354138-43d2-424b-bd73-50266dd047e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-62c71d45-17bb-4a1a-872a-8a58dba387ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-17af4926-311e-491c-8e96-d3ad968fd7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-495b5e70-8d60-4b99-a2fc-f27c23234377,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-8b715d9e-cd0f-4d6c-a893-cb34ecc0c72b,DISK], DatanodeInfoWithStorage[127.0.0.1:42723,DS-f1a6eb46-ae92-4007-8ccc-a01709757e07,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-6e84146f-95d7-4ea1-98a4-704f456f9271,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-181206441-172.17.0.8-1597481253297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44629,DS-395d4b87-5e39-42a4-96ae-e4ba0607cd35,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-149de7df-0848-47b6-a434-925c1411b260,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-4ee2e58d-eda3-48b9-ae19-01aa219c674d,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-dce2a56d-8877-4ed7-9fd5-59d694967d05,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-1619379a-2cd0-4d6a-9850-34961e8ccb86,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-419f74d7-e75e-4bb3-a14b-ec98fbcd56ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-d1e95cfc-8788-45ce-8701-db19cb352feb,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-3fb2706e-8ab7-4858-be73-bc011c9be3d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-181206441-172.17.0.8-1597481253297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44629,DS-395d4b87-5e39-42a4-96ae-e4ba0607cd35,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-149de7df-0848-47b6-a434-925c1411b260,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-4ee2e58d-eda3-48b9-ae19-01aa219c674d,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-dce2a56d-8877-4ed7-9fd5-59d694967d05,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-1619379a-2cd0-4d6a-9850-34961e8ccb86,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-419f74d7-e75e-4bb3-a14b-ec98fbcd56ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-d1e95cfc-8788-45ce-8701-db19cb352feb,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-3fb2706e-8ab7-4858-be73-bc011c9be3d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-481125293-172.17.0.8-1597481694189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39672,DS-00ae0205-5e31-44bd-ad4e-b5367c77cedd,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-1b4c9e22-9ac7-4679-9564-f7e868774613,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-f904adf4-7930-49dd-8683-9fbe2a797f45,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-b3eb076e-c2a2-4dc1-84c1-7090cf3a5f77,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-34afa281-0907-4e84-b794-8c1633e7b526,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-c5ce3433-d2fb-4e5d-b482-4265b7bf1759,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-d24e2bbe-874f-45e7-91b7-77d0b4cb8ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-440f9989-55a6-46d1-b653-4ecbfb90691d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-481125293-172.17.0.8-1597481694189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39672,DS-00ae0205-5e31-44bd-ad4e-b5367c77cedd,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-1b4c9e22-9ac7-4679-9564-f7e868774613,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-f904adf4-7930-49dd-8683-9fbe2a797f45,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-b3eb076e-c2a2-4dc1-84c1-7090cf3a5f77,DISK], DatanodeInfoWithStorage[127.0.0.1:46085,DS-34afa281-0907-4e84-b794-8c1633e7b526,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-c5ce3433-d2fb-4e5d-b482-4265b7bf1759,DISK], DatanodeInfoWithStorage[127.0.0.1:45039,DS-d24e2bbe-874f-45e7-91b7-77d0b4cb8ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-440f9989-55a6-46d1-b653-4ecbfb90691d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1735110336-172.17.0.8-1597482041787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38305,DS-c947e080-1f4e-452d-b82e-45fae784f58b,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-331e87b1-553b-4591-881c-174f80523e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-02a6a9e6-8fe0-48b1-a440-3f34852be829,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-97b812f2-20e2-4111-960d-7d7a49f50afd,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-8a57382d-49ad-40dc-bca8-5ab268f285c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-5400d0a6-2334-44a2-a91f-082aafe478c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-cb1ed3f2-7c00-4ca8-b5bc-e1e2df8f387a,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-560cdf8d-00d4-47c2-bea4-e511cd74cf72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1735110336-172.17.0.8-1597482041787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38305,DS-c947e080-1f4e-452d-b82e-45fae784f58b,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-331e87b1-553b-4591-881c-174f80523e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-02a6a9e6-8fe0-48b1-a440-3f34852be829,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-97b812f2-20e2-4111-960d-7d7a49f50afd,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-8a57382d-49ad-40dc-bca8-5ab268f285c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44437,DS-5400d0a6-2334-44a2-a91f-082aafe478c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-cb1ed3f2-7c00-4ca8-b5bc-e1e2df8f387a,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-560cdf8d-00d4-47c2-bea4-e511cd74cf72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35912426-172.17.0.8-1597482158738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40386,DS-adfc35c3-c923-42a7-8f53-fac5a89edd51,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-c904e230-7885-45b5-8398-a1e3888bc9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-430e6ba7-1969-463c-8e95-28625af80df4,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-cf2d3ad1-a034-441c-a36c-57f6ce4b0987,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-1a8d4a8a-defb-435c-a44e-344463255389,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-3c2633de-083e-4d76-acd7-6a5360b60bec,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-93739a8c-13a3-4460-a41e-eaf7035d449f,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-c3e9235b-756d-4482-b279-b8e2ddaed5f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35912426-172.17.0.8-1597482158738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40386,DS-adfc35c3-c923-42a7-8f53-fac5a89edd51,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-c904e230-7885-45b5-8398-a1e3888bc9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-430e6ba7-1969-463c-8e95-28625af80df4,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-cf2d3ad1-a034-441c-a36c-57f6ce4b0987,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-1a8d4a8a-defb-435c-a44e-344463255389,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-3c2633de-083e-4d76-acd7-6a5360b60bec,DISK], DatanodeInfoWithStorage[127.0.0.1:41967,DS-93739a8c-13a3-4460-a41e-eaf7035d449f,DISK], DatanodeInfoWithStorage[127.0.0.1:33645,DS-c3e9235b-756d-4482-b279-b8e2ddaed5f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-317801066-172.17.0.8-1597482269771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44784,DS-c3862908-184d-4bba-8579-596f76426f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-809c9d5a-2212-4c24-be6b-cf7acce5fc59,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-67fc962a-f126-4825-9d72-5342fd5e5622,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-ff9306a6-7b88-46bf-a645-905b279533a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-6e57724d-ab65-4de1-9808-7dc95afb1516,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-f8587581-8047-44c2-b9f8-addf74decf07,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-4d445807-6379-42e0-ba5d-1b0a91f1a127,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-f1fa9ef5-10ce-4c9c-8c7f-07960c613a6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-317801066-172.17.0.8-1597482269771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44784,DS-c3862908-184d-4bba-8579-596f76426f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-809c9d5a-2212-4c24-be6b-cf7acce5fc59,DISK], DatanodeInfoWithStorage[127.0.0.1:35446,DS-67fc962a-f126-4825-9d72-5342fd5e5622,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-ff9306a6-7b88-46bf-a645-905b279533a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41628,DS-6e57724d-ab65-4de1-9808-7dc95afb1516,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-f8587581-8047-44c2-b9f8-addf74decf07,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-4d445807-6379-42e0-ba5d-1b0a91f1a127,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-f1fa9ef5-10ce-4c9c-8c7f-07960c613a6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1690453769-172.17.0.8-1597483350044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32815,DS-7f96dbb8-532a-43fe-b241-dcd43e338dda,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-d4865333-eec5-4e8e-a6fe-478d767db1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-d7587f07-724d-4cfb-a44d-049f18abf881,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-ed900a2c-2a79-41f0-8ef3-a23e88eda7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-ea0083ba-d75e-478d-8eaf-bf9a5397ef37,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-8e0e5e06-43c9-4ebb-a3d9-78901f128c17,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-67f998f0-6479-49eb-907e-04826e767f60,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-4a28a5e4-b7ac-453b-8c1f-7ef6659e2d6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1690453769-172.17.0.8-1597483350044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32815,DS-7f96dbb8-532a-43fe-b241-dcd43e338dda,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-d4865333-eec5-4e8e-a6fe-478d767db1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45514,DS-d7587f07-724d-4cfb-a44d-049f18abf881,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-ed900a2c-2a79-41f0-8ef3-a23e88eda7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-ea0083ba-d75e-478d-8eaf-bf9a5397ef37,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-8e0e5e06-43c9-4ebb-a3d9-78901f128c17,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-67f998f0-6479-49eb-907e-04826e767f60,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-4a28a5e4-b7ac-453b-8c1f-7ef6659e2d6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22753873-172.17.0.8-1597483461001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44837,DS-51f70d34-04bf-4795-b50d-3d1941906374,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-d65f5892-a758-4de7-86c6-9b95da116f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-91245d4f-90e8-4bd7-b724-065cbff11658,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-cabf276f-40a2-45e0-8fc7-58a1ca4f3fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-f3937bbd-33b2-41dc-a3cc-5ed78b7dfd02,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-c41de731-daab-4b9b-bc85-07892bffaa98,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-09247f33-d2a9-45e9-83d9-ecb6b2923dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-1a299d98-dfce-4a98-b607-6f14e4b05081,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22753873-172.17.0.8-1597483461001:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44837,DS-51f70d34-04bf-4795-b50d-3d1941906374,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-d65f5892-a758-4de7-86c6-9b95da116f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-91245d4f-90e8-4bd7-b724-065cbff11658,DISK], DatanodeInfoWithStorage[127.0.0.1:34082,DS-cabf276f-40a2-45e0-8fc7-58a1ca4f3fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-f3937bbd-33b2-41dc-a3cc-5ed78b7dfd02,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-c41de731-daab-4b9b-bc85-07892bffaa98,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-09247f33-d2a9-45e9-83d9-ecb6b2923dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-1a299d98-dfce-4a98-b607-6f14e4b05081,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5733
