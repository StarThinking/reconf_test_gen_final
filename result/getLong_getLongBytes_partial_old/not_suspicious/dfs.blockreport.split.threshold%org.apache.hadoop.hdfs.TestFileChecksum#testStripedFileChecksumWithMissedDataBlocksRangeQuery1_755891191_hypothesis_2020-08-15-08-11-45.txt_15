reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-659512303-172.17.0.20-1597479497176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44458,DS-42260d1e-a406-4129-8c33-abaa0f925dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-81c5264f-d214-4d4c-b4fa-e73f268d52f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-b79ee103-9331-4306-b517-ad679e455266,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-c951ff1a-fb12-402a-b798-d517e6d7d83a,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-9584c544-e133-4ad6-85a5-f764c05144eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-d6ec469f-80cc-4cee-ada9-a4033ea24bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-820d68a2-48d1-46fd-9141-1bfcfaaee594,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-0a988fc0-3b1e-43c3-956d-cc1356a2b2ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-659512303-172.17.0.20-1597479497176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44458,DS-42260d1e-a406-4129-8c33-abaa0f925dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-81c5264f-d214-4d4c-b4fa-e73f268d52f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42685,DS-b79ee103-9331-4306-b517-ad679e455266,DISK], DatanodeInfoWithStorage[127.0.0.1:33601,DS-c951ff1a-fb12-402a-b798-d517e6d7d83a,DISK], DatanodeInfoWithStorage[127.0.0.1:41888,DS-9584c544-e133-4ad6-85a5-f764c05144eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-d6ec469f-80cc-4cee-ada9-a4033ea24bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:40822,DS-820d68a2-48d1-46fd-9141-1bfcfaaee594,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-0a988fc0-3b1e-43c3-956d-cc1356a2b2ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085691998-172.17.0.20-1597479644552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34930,DS-873a28a2-2d05-435a-b555-24116f506de0,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-2693f66f-d538-4018-b357-a7488191a23e,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-4ebe18ff-a615-4a2b-b3c3-f9c50f6a0d86,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-2cba8d3e-43da-4f4a-b2a6-074f77ccea10,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-7ad96a07-5ada-48c2-8623-2e1548787569,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-709b35cc-0958-4fd7-ac68-c90748a35f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-177b6897-c60a-4082-a5c0-52555c5d60b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-03138637-5c63-46fb-bad5-f03be2057d70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085691998-172.17.0.20-1597479644552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34930,DS-873a28a2-2d05-435a-b555-24116f506de0,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-2693f66f-d538-4018-b357-a7488191a23e,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-4ebe18ff-a615-4a2b-b3c3-f9c50f6a0d86,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-2cba8d3e-43da-4f4a-b2a6-074f77ccea10,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-7ad96a07-5ada-48c2-8623-2e1548787569,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-709b35cc-0958-4fd7-ac68-c90748a35f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36470,DS-177b6897-c60a-4082-a5c0-52555c5d60b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-03138637-5c63-46fb-bad5-f03be2057d70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1898733914-172.17.0.20-1597480841111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43785,DS-ff6d02a1-5f71-4cda-b77b-22d6d1d1efe9,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-64c58976-8c71-406e-9578-d31c3f9698d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-debfea66-8279-49dd-b417-679548b77299,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-77e80ecb-418b-47bf-9dd9-0fc21fd65f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-c856b813-0185-4e90-8b91-dd3e733f01a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-3b32592f-6cc3-43ed-96e3-aa2ef96379d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-4b7ddf27-ba5f-4c55-ab15-e0bb63e1c9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-027e7268-3746-47b2-ad6b-69c08145293c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1898733914-172.17.0.20-1597480841111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43785,DS-ff6d02a1-5f71-4cda-b77b-22d6d1d1efe9,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-64c58976-8c71-406e-9578-d31c3f9698d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-debfea66-8279-49dd-b417-679548b77299,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-77e80ecb-418b-47bf-9dd9-0fc21fd65f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-c856b813-0185-4e90-8b91-dd3e733f01a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-3b32592f-6cc3-43ed-96e3-aa2ef96379d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-4b7ddf27-ba5f-4c55-ab15-e0bb63e1c9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-027e7268-3746-47b2-ad6b-69c08145293c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-681763034-172.17.0.20-1597481378160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36007,DS-5a89b043-eb91-41ad-a27c-0eb8c7c12fef,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-01b6d226-887d-477f-84f2-f992040b6b50,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-97c34932-8895-47f4-b66b-c28a6f1c9000,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-8d03f9f8-ef88-4975-8737-1beac5dbb531,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-9989ab0b-b5a7-4207-b0db-769826dbdac3,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-1f1877cd-a530-4ba7-91d0-da2a90b47c44,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-c69d8f03-9ccb-43d2-9bd0-6bec0824c638,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-16e5014b-7a79-4eb7-973e-6838e520f0e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-681763034-172.17.0.20-1597481378160:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36007,DS-5a89b043-eb91-41ad-a27c-0eb8c7c12fef,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-01b6d226-887d-477f-84f2-f992040b6b50,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-97c34932-8895-47f4-b66b-c28a6f1c9000,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-8d03f9f8-ef88-4975-8737-1beac5dbb531,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-9989ab0b-b5a7-4207-b0db-769826dbdac3,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-1f1877cd-a530-4ba7-91d0-da2a90b47c44,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-c69d8f03-9ccb-43d2-9bd0-6bec0824c638,DISK], DatanodeInfoWithStorage[127.0.0.1:36346,DS-16e5014b-7a79-4eb7-973e-6838e520f0e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1744805605-172.17.0.20-1597481691180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35383,DS-2e4f55c4-34b2-45de-acfe-3975dff041f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-6c9546ba-a68f-40ff-8450-9443e2aa3ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-84587d48-6a68-485f-8eae-f4cdeb78a23a,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-89957353-33da-4c36-932d-9d57f50c4564,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-7ec1ac79-8dca-400d-aa05-9b169a1a93e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-723f0d1c-4820-463b-acfa-86c2c0563997,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-62b29926-2814-4a99-b5cc-75fb224a4b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-6e07cb0b-b7ba-4a31-9995-65cd5999fb23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1744805605-172.17.0.20-1597481691180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35383,DS-2e4f55c4-34b2-45de-acfe-3975dff041f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-6c9546ba-a68f-40ff-8450-9443e2aa3ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:41244,DS-84587d48-6a68-485f-8eae-f4cdeb78a23a,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-89957353-33da-4c36-932d-9d57f50c4564,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-7ec1ac79-8dca-400d-aa05-9b169a1a93e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-723f0d1c-4820-463b-acfa-86c2c0563997,DISK], DatanodeInfoWithStorage[127.0.0.1:38517,DS-62b29926-2814-4a99-b5cc-75fb224a4b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-6e07cb0b-b7ba-4a31-9995-65cd5999fb23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589271135-172.17.0.20-1597482218413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40079,DS-4ee67cc8-10db-4434-9897-05c51cdbccb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-83791c13-a993-42c8-b99b-200680886179,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-e4b538eb-7866-4205-a532-bebba7c60d74,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-4a3bc612-44f0-4780-89cf-9b8374b0ea7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-221766cc-636f-4f4c-b410-2fbe9c9acc49,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-5fd6da30-c5c5-4510-8de0-f1edc0eb4e81,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-1f5be702-46df-429c-b19e-95a24f043dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-a4fe65ff-cad5-4a4f-995c-bb284e09f8cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-589271135-172.17.0.20-1597482218413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40079,DS-4ee67cc8-10db-4434-9897-05c51cdbccb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-83791c13-a993-42c8-b99b-200680886179,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-e4b538eb-7866-4205-a532-bebba7c60d74,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-4a3bc612-44f0-4780-89cf-9b8374b0ea7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-221766cc-636f-4f4c-b410-2fbe9c9acc49,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-5fd6da30-c5c5-4510-8de0-f1edc0eb4e81,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-1f5be702-46df-429c-b19e-95a24f043dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34642,DS-a4fe65ff-cad5-4a4f-995c-bb284e09f8cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238525462-172.17.0.20-1597482294769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38812,DS-9606f397-757a-42f3-9507-237041689c38,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-82b85ca3-2e52-4c1e-b7b1-16e16897002a,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-1cfa5b0b-7b2a-4fc3-9c63-832e758bde2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-25010079-2f7b-43d2-915c-6a3d3241257f,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-7bce6d63-7cbc-44bb-af96-bd14489d9290,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-fb7b1bb3-f497-49c5-9b17-fc75f52e704f,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-4e136401-18e9-40bc-94fd-a3312dde1213,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-d4a21f86-e8aa-44bd-8967-3db1fa6f2f26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238525462-172.17.0.20-1597482294769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38812,DS-9606f397-757a-42f3-9507-237041689c38,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-82b85ca3-2e52-4c1e-b7b1-16e16897002a,DISK], DatanodeInfoWithStorage[127.0.0.1:46013,DS-1cfa5b0b-7b2a-4fc3-9c63-832e758bde2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-25010079-2f7b-43d2-915c-6a3d3241257f,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-7bce6d63-7cbc-44bb-af96-bd14489d9290,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-fb7b1bb3-f497-49c5-9b17-fc75f52e704f,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-4e136401-18e9-40bc-94fd-a3312dde1213,DISK], DatanodeInfoWithStorage[127.0.0.1:35691,DS-d4a21f86-e8aa-44bd-8967-3db1fa6f2f26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-200528717-172.17.0.20-1597482534455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41670,DS-522aa5f9-eaf8-48b2-aad6-72d4ee76a496,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-a1b7b18b-5f41-48b5-86fd-43cbeaff2c05,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-3c0fac5a-d85c-4bad-abee-dd9ecd887d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-f2591d51-14d0-4a4f-b322-ea1a6d0f98d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-64f309d0-f377-4a7d-b213-441d346ed744,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-8f64f55c-4fe0-4c7d-b564-840617aa6d94,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-5db665d0-fd62-4d69-b8f7-a38fdab52f48,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-50fac532-95c5-4a08-8274-5bea5bb13888,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-200528717-172.17.0.20-1597482534455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41670,DS-522aa5f9-eaf8-48b2-aad6-72d4ee76a496,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-a1b7b18b-5f41-48b5-86fd-43cbeaff2c05,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-3c0fac5a-d85c-4bad-abee-dd9ecd887d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-f2591d51-14d0-4a4f-b322-ea1a6d0f98d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-64f309d0-f377-4a7d-b213-441d346ed744,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-8f64f55c-4fe0-4c7d-b564-840617aa6d94,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-5db665d0-fd62-4d69-b8f7-a38fdab52f48,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-50fac532-95c5-4a08-8274-5bea5bb13888,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-937359960-172.17.0.20-1597482617205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33405,DS-70fbbdee-c666-4c5c-b3c0-ec141efd0a95,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-227d217e-7007-4653-82a4-b78df5cefe07,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-1c0a6081-decf-4be5-9974-ef05dc56e4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-f8b27b02-6a3d-4a29-8bbb-c3dd93158c05,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-742d587d-7354-46b6-b9b1-164768723b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-47632b1b-ff18-41b0-a349-3d6c55ebf080,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-05912b73-ef7f-455a-a9ea-3ee060377f66,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-873229a5-d608-41da-86f1-82510a9775eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-937359960-172.17.0.20-1597482617205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33405,DS-70fbbdee-c666-4c5c-b3c0-ec141efd0a95,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-227d217e-7007-4653-82a4-b78df5cefe07,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-1c0a6081-decf-4be5-9974-ef05dc56e4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-f8b27b02-6a3d-4a29-8bbb-c3dd93158c05,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-742d587d-7354-46b6-b9b1-164768723b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-47632b1b-ff18-41b0-a349-3d6c55ebf080,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-05912b73-ef7f-455a-a9ea-3ee060377f66,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-873229a5-d608-41da-86f1-82510a9775eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726036715-172.17.0.20-1597482921283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38181,DS-81e6a179-5a89-4c14-987d-bb3c573beaef,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-6f177442-c0ad-4b39-97aa-6518906f1280,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-f79ebc6b-794e-4d2b-8267-a8720937a977,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-0d5ad377-e6ab-40a5-9145-8128e41cf3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-fd5b2297-67a9-46fd-a9ce-2c74016f78a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-10add30f-0cb3-4f7b-914c-4d43d0d2c578,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-f68fdf99-b809-4846-8226-d77b5c5295a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-ef0d835c-95bd-4e41-ad20-033f395e6226,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1726036715-172.17.0.20-1597482921283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38181,DS-81e6a179-5a89-4c14-987d-bb3c573beaef,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-6f177442-c0ad-4b39-97aa-6518906f1280,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-f79ebc6b-794e-4d2b-8267-a8720937a977,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-0d5ad377-e6ab-40a5-9145-8128e41cf3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-fd5b2297-67a9-46fd-a9ce-2c74016f78a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-10add30f-0cb3-4f7b-914c-4d43d0d2c578,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-f68fdf99-b809-4846-8226-d77b5c5295a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-ef0d835c-95bd-4e41-ad20-033f395e6226,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1208352592-172.17.0.20-1597482962640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33170,DS-d8210499-6e1b-4019-861e-c28188181136,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-35459ff9-762e-4d41-920e-152aa0e9fd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-61196aa3-7224-4528-bcec-db62bbadafd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-9361be1c-ed44-45ae-bbc4-f8849168d13c,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-b80713b3-f25b-4a28-9748-2e9d0c7e0f24,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-5d8a7f23-036f-4c93-934a-ccd2bd99c443,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-1b25427e-63ef-47a5-bc59-a59b18c03e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-347b7f89-83d6-40e8-9858-8b33fdfa47d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1208352592-172.17.0.20-1597482962640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33170,DS-d8210499-6e1b-4019-861e-c28188181136,DISK], DatanodeInfoWithStorage[127.0.0.1:42697,DS-35459ff9-762e-4d41-920e-152aa0e9fd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-61196aa3-7224-4528-bcec-db62bbadafd5,DISK], DatanodeInfoWithStorage[127.0.0.1:41574,DS-9361be1c-ed44-45ae-bbc4-f8849168d13c,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-b80713b3-f25b-4a28-9748-2e9d0c7e0f24,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-5d8a7f23-036f-4c93-934a-ccd2bd99c443,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-1b25427e-63ef-47a5-bc59-a59b18c03e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-347b7f89-83d6-40e8-9858-8b33fdfa47d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-517201795-172.17.0.20-1597483377988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40959,DS-f3d73ca3-55ce-4c7a-9f1a-49f36e9420f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-18379095-389d-4a35-b9c3-2717a3d4c5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-2be80431-67af-47df-a340-9d70fad72ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-531edc6d-ef3a-409a-9738-2783ca8bc71d,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-32f559f2-da73-47fd-b628-2cdbdf6e9eee,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-5c3c301a-80c7-4dd9-abf3-3c4d6c52d62f,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-4c086ed4-e3aa-46d3-9792-8e9dfacb3110,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-f0e37d4f-8681-4c0f-b187-6df96734080d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-517201795-172.17.0.20-1597483377988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40959,DS-f3d73ca3-55ce-4c7a-9f1a-49f36e9420f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-18379095-389d-4a35-b9c3-2717a3d4c5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-2be80431-67af-47df-a340-9d70fad72ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-531edc6d-ef3a-409a-9738-2783ca8bc71d,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-32f559f2-da73-47fd-b628-2cdbdf6e9eee,DISK], DatanodeInfoWithStorage[127.0.0.1:39279,DS-5c3c301a-80c7-4dd9-abf3-3c4d6c52d62f,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-4c086ed4-e3aa-46d3-9792-8e9dfacb3110,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-f0e37d4f-8681-4c0f-b187-6df96734080d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20538587-172.17.0.20-1597483457404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44513,DS-0af63583-beeb-429d-a9cf-898fc9c7b714,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-cae3d9ab-4798-4eda-b910-07488986dc57,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-4aadddd4-0821-485d-a949-855bd84ab7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-8faed509-f092-4543-9868-2eecfdc3af7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-2f1acf2d-6dad-442b-9daf-e0a32f010126,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-a1fcdd43-374c-4b79-81a2-52d38373c98b,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-6105403b-303e-4807-8957-ed0c9f694393,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-9e3361b6-4828-4a8b-9129-fc85579ade65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20538587-172.17.0.20-1597483457404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44513,DS-0af63583-beeb-429d-a9cf-898fc9c7b714,DISK], DatanodeInfoWithStorage[127.0.0.1:36181,DS-cae3d9ab-4798-4eda-b910-07488986dc57,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-4aadddd4-0821-485d-a949-855bd84ab7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-8faed509-f092-4543-9868-2eecfdc3af7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-2f1acf2d-6dad-442b-9daf-e0a32f010126,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-a1fcdd43-374c-4b79-81a2-52d38373c98b,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-6105403b-303e-4807-8957-ed0c9f694393,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-9e3361b6-4828-4a8b-9129-fc85579ade65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75425631-172.17.0.20-1597483687152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43348,DS-c34ab2e4-cc52-4b37-b62c-ef57623d10b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-5450c630-6088-443c-987f-05418d2ab7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-44bd0f0e-bf62-4677-8cee-9a91ed6114d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-2d544b3a-07ae-46fd-a0f3-ec269e136519,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-3018dd41-0849-4112-aef7-4587b9d397d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-a77bdc3d-dd41-4dbb-a076-02132234baba,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-10ff0b23-e8b3-4037-95f2-7f17ad6640e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-8d93e8a8-f000-4440-8637-13d7070f7b3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-75425631-172.17.0.20-1597483687152:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43348,DS-c34ab2e4-cc52-4b37-b62c-ef57623d10b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-5450c630-6088-443c-987f-05418d2ab7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39447,DS-44bd0f0e-bf62-4677-8cee-9a91ed6114d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-2d544b3a-07ae-46fd-a0f3-ec269e136519,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-3018dd41-0849-4112-aef7-4587b9d397d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-a77bdc3d-dd41-4dbb-a076-02132234baba,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-10ff0b23-e8b3-4037-95f2-7f17ad6640e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-8d93e8a8-f000-4440-8637-13d7070f7b3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 2
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-132040076-172.17.0.20-1597484692144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41279,DS-8fc30d44-9a1c-4ee4-8001-08428f04d276,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-07d308fe-dadb-4aa7-b0ec-70c9c271e996,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-f4fcad65-f724-4795-816d-1808a75f2627,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-2398112f-62fe-47c2-be13-5fda3eccc135,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-c0c6dfd8-ada1-437d-84be-95dcf02cf520,DISK], DatanodeInfoWithStorage[127.0.0.1:33541,DS-b96f7d02-af92-447f-848a-6b92b1455990,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-f9beac84-0fb1-440a-87e1-c009162876f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-314cff66-3727-4125-8543-bb979cfedf1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-132040076-172.17.0.20-1597484692144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41279,DS-8fc30d44-9a1c-4ee4-8001-08428f04d276,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-07d308fe-dadb-4aa7-b0ec-70c9c271e996,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-f4fcad65-f724-4795-816d-1808a75f2627,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-2398112f-62fe-47c2-be13-5fda3eccc135,DISK], DatanodeInfoWithStorage[127.0.0.1:44984,DS-c0c6dfd8-ada1-437d-84be-95dcf02cf520,DISK], DatanodeInfoWithStorage[127.0.0.1:33541,DS-b96f7d02-af92-447f-848a-6b92b1455990,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-f9beac84-0fb1-440a-87e1-c009162876f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-314cff66-3727-4125-8543-bb979cfedf1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5693
