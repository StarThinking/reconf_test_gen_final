reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-621911687-172.17.0.17-1597468554141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33815,DS-c80c4fa1-5363-473b-b321-b5c2038da3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-74b84206-c1aa-4ace-91c9-d113ab647eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-52a0d6e9-914e-41f8-a53a-f9c501965f55,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-067bedef-aa72-45d9-9f9c-54e763ccdc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-d6eafbac-dd53-4954-b585-20103a7e114b,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-d6a966f6-c293-4b6a-bdca-eb4a8099a9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-b63eff81-9da2-437f-9230-023baa13bcbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-07678188-b745-4627-ba05-a768fd1e8fef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-621911687-172.17.0.17-1597468554141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33815,DS-c80c4fa1-5363-473b-b321-b5c2038da3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-74b84206-c1aa-4ace-91c9-d113ab647eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-52a0d6e9-914e-41f8-a53a-f9c501965f55,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-067bedef-aa72-45d9-9f9c-54e763ccdc2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-d6eafbac-dd53-4954-b585-20103a7e114b,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-d6a966f6-c293-4b6a-bdca-eb4a8099a9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-b63eff81-9da2-437f-9230-023baa13bcbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-07678188-b745-4627-ba05-a768fd1e8fef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1447045697-172.17.0.17-1597468596549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33419,DS-0977c2b7-5927-4924-a983-ee7fc2655ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-41a4a64b-997d-404e-98c7-3dc6a054f75b,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-9a37a107-d778-4c34-ad09-b14e7c67ca9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-a6a5bb06-abd3-48e1-b109-1f04f7f8ab52,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-ff978f24-f540-4d76-a1f7-86ac4b1d5359,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-f593c166-20c5-4ef4-8cb0-58a95fff06ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-046929c9-7613-4bb9-8543-5725f2f7d49a,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-e1dd8999-8ee4-4ddf-b050-b5e6d5a263a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1447045697-172.17.0.17-1597468596549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33419,DS-0977c2b7-5927-4924-a983-ee7fc2655ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-41a4a64b-997d-404e-98c7-3dc6a054f75b,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-9a37a107-d778-4c34-ad09-b14e7c67ca9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-a6a5bb06-abd3-48e1-b109-1f04f7f8ab52,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-ff978f24-f540-4d76-a1f7-86ac4b1d5359,DISK], DatanodeInfoWithStorage[127.0.0.1:35874,DS-f593c166-20c5-4ef4-8cb0-58a95fff06ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-046929c9-7613-4bb9-8543-5725f2f7d49a,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-e1dd8999-8ee4-4ddf-b050-b5e6d5a263a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1326624787-172.17.0.17-1597468759223:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34270,DS-f9f02ea2-e660-4045-9d15-a2ea3d7f86ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-03299093-f900-46c5-be38-3d62d08bddf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-51062655-dc7a-4b91-ac74-6040b79dfa92,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-ffac8843-c8b4-4bc9-b16e-cf6317f1f09f,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-a4384036-e822-479d-9482-26669ea4a35a,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-e89d024a-23c3-4759-972a-27a32b1a72af,DISK], DatanodeInfoWithStorage[127.0.0.1:35994,DS-c21caef1-70f7-4e9a-9ac3-04e5ac8f5233,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-366e0a6a-da53-46dc-be8c-bb782ac4c54c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1326624787-172.17.0.17-1597468759223:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34270,DS-f9f02ea2-e660-4045-9d15-a2ea3d7f86ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-03299093-f900-46c5-be38-3d62d08bddf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-51062655-dc7a-4b91-ac74-6040b79dfa92,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-ffac8843-c8b4-4bc9-b16e-cf6317f1f09f,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-a4384036-e822-479d-9482-26669ea4a35a,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-e89d024a-23c3-4759-972a-27a32b1a72af,DISK], DatanodeInfoWithStorage[127.0.0.1:35994,DS-c21caef1-70f7-4e9a-9ac3-04e5ac8f5233,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-366e0a6a-da53-46dc-be8c-bb782ac4c54c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-71031765-172.17.0.17-1597469593397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40512,DS-ab72585b-44b2-420e-924d-1424f8277e89,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-6be0369a-e1b2-4386-8870-a62943398c24,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-1a29fd5b-b2b5-4c14-9b91-eeb0734f6984,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-da1e9233-c97e-4f54-8086-184a9617ab4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-e9dd222e-f4c3-4395-9766-15855c3e9e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-b78b08f6-a0b0-48a6-8229-ecf9f937f9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-710fd292-92ad-46a7-b304-7732b3e7a873,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-eb069338-3ed4-40b6-9fd2-1e18ddf3f5ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-71031765-172.17.0.17-1597469593397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40512,DS-ab72585b-44b2-420e-924d-1424f8277e89,DISK], DatanodeInfoWithStorage[127.0.0.1:33990,DS-6be0369a-e1b2-4386-8870-a62943398c24,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-1a29fd5b-b2b5-4c14-9b91-eeb0734f6984,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-da1e9233-c97e-4f54-8086-184a9617ab4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-e9dd222e-f4c3-4395-9766-15855c3e9e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-b78b08f6-a0b0-48a6-8229-ecf9f937f9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-710fd292-92ad-46a7-b304-7732b3e7a873,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-eb069338-3ed4-40b6-9fd2-1e18ddf3f5ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696634610-172.17.0.17-1597469714781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32798,DS-742b2ad1-c5b1-4c79-abfa-084e8e7725f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-ce9a0695-a4a4-41a4-bc5b-7bb5fba86168,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-740a91e5-0ed2-4e4a-93a7-633afc6d4524,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-ab499768-1efe-4a30-8bff-48cfacaa5fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-5cbfd551-4ae9-4b6b-a3fb-b34732e44434,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-243a223e-d2b1-47ce-8ba6-806281ab8d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-a6447b76-29fe-427a-8fb4-6b1f882705c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38183,DS-9b18c7be-4f4c-41a8-b8c2-12d23c5a22df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-696634610-172.17.0.17-1597469714781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32798,DS-742b2ad1-c5b1-4c79-abfa-084e8e7725f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-ce9a0695-a4a4-41a4-bc5b-7bb5fba86168,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-740a91e5-0ed2-4e4a-93a7-633afc6d4524,DISK], DatanodeInfoWithStorage[127.0.0.1:42607,DS-ab499768-1efe-4a30-8bff-48cfacaa5fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-5cbfd551-4ae9-4b6b-a3fb-b34732e44434,DISK], DatanodeInfoWithStorage[127.0.0.1:37265,DS-243a223e-d2b1-47ce-8ba6-806281ab8d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-a6447b76-29fe-427a-8fb4-6b1f882705c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38183,DS-9b18c7be-4f4c-41a8-b8c2-12d23c5a22df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1978894043-172.17.0.17-1597469878984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44821,DS-41995553-e634-4eae-bc1f-7571833442e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-30301d10-e471-4af5-996b-70e0a03e8a40,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-886186b1-d11e-4993-b799-f710c91e365c,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-191e4527-0fda-41f5-8d76-c9e065046c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-83b3dfcc-d493-46ea-8c36-efd60bd7ee86,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-da8e6380-1fe6-45f3-9109-c20c972c5eff,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-73dcdec1-8f6c-43e5-9b19-75e8ea11dc12,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-1b72fc5f-9991-4b62-816a-237141d555f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1978894043-172.17.0.17-1597469878984:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44821,DS-41995553-e634-4eae-bc1f-7571833442e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-30301d10-e471-4af5-996b-70e0a03e8a40,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-886186b1-d11e-4993-b799-f710c91e365c,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-191e4527-0fda-41f5-8d76-c9e065046c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-83b3dfcc-d493-46ea-8c36-efd60bd7ee86,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-da8e6380-1fe6-45f3-9109-c20c972c5eff,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-73dcdec1-8f6c-43e5-9b19-75e8ea11dc12,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-1b72fc5f-9991-4b62-816a-237141d555f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1383900977-172.17.0.17-1597469957165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43040,DS-7634002f-0595-47f0-8023-345f058cbe87,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-aad77ebd-667a-400d-96dd-cba684bb9415,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-9ba74931-068c-4cfd-a7e9-03afb458ee94,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-a1e84634-13c6-46d2-8a75-b940245c2724,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-60cc155b-e365-40e4-b570-64bc8e2e8b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-6d4760cc-5901-420c-8ba3-2138879bc730,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-7e55e8d7-3666-4113-be78-2b89ba9808f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-e77673a8-b804-44a0-b49e-dfad28d43c9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1383900977-172.17.0.17-1597469957165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43040,DS-7634002f-0595-47f0-8023-345f058cbe87,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-aad77ebd-667a-400d-96dd-cba684bb9415,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-9ba74931-068c-4cfd-a7e9-03afb458ee94,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-a1e84634-13c6-46d2-8a75-b940245c2724,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-60cc155b-e365-40e4-b570-64bc8e2e8b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-6d4760cc-5901-420c-8ba3-2138879bc730,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-7e55e8d7-3666-4113-be78-2b89ba9808f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-e77673a8-b804-44a0-b49e-dfad28d43c9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-751642746-172.17.0.17-1597470145474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36900,DS-2fece81f-594f-4517-8a52-94b136948052,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-5e0595ec-05d6-4317-8402-a8628214f1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-93035445-d8c3-4125-b268-cebe8509464d,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-c8c85801-bb0e-4e26-8f71-c90589f51260,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-cd22dbef-10e6-4bf2-88ba-92a24f992ade,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-3d1dbc8b-07eb-44c8-84c8-c7f3bfaa3c83,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-a3dd12e6-f5b9-4f1a-8c1a-3183b59ff752,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-34269089-b94e-480b-82d1-9a45a622b6a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-751642746-172.17.0.17-1597470145474:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36900,DS-2fece81f-594f-4517-8a52-94b136948052,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-5e0595ec-05d6-4317-8402-a8628214f1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-93035445-d8c3-4125-b268-cebe8509464d,DISK], DatanodeInfoWithStorage[127.0.0.1:44998,DS-c8c85801-bb0e-4e26-8f71-c90589f51260,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-cd22dbef-10e6-4bf2-88ba-92a24f992ade,DISK], DatanodeInfoWithStorage[127.0.0.1:35941,DS-3d1dbc8b-07eb-44c8-84c8-c7f3bfaa3c83,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-a3dd12e6-f5b9-4f1a-8c1a-3183b59ff752,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-34269089-b94e-480b-82d1-9a45a622b6a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1806137910-172.17.0.17-1597470341479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44646,DS-7a99634b-352b-43f2-ad47-65553eb00832,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-67cce4bd-d305-424f-814f-ba6d69c044c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-54e80087-296a-4bb1-98e2-6f9396e21aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-d2c29d03-4286-4ac0-a02c-28489a98819c,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-b2ff501b-ab63-4e67-81b6-615a25b6afcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-500ee704-2aea-4e32-8e1c-07f7503448e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-8c00d5f6-c2eb-4383-8e73-1321c133c335,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-eb990367-5083-4a94-94d4-d5d9227f15f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1806137910-172.17.0.17-1597470341479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44646,DS-7a99634b-352b-43f2-ad47-65553eb00832,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-67cce4bd-d305-424f-814f-ba6d69c044c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-54e80087-296a-4bb1-98e2-6f9396e21aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-d2c29d03-4286-4ac0-a02c-28489a98819c,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-b2ff501b-ab63-4e67-81b6-615a25b6afcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-500ee704-2aea-4e32-8e1c-07f7503448e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42227,DS-8c00d5f6-c2eb-4383-8e73-1321c133c335,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-eb990367-5083-4a94-94d4-d5d9227f15f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1389212998-172.17.0.17-1597470427619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46469,DS-038858bb-a9df-454d-9928-94147bce4f69,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-2416b7c4-d40b-4b25-9cdb-8456826f4734,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-12538fbc-8b76-46a0-9bf3-4b40538e37bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-3ee23fce-ab90-453f-8383-18f146c63ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-eb52ffea-9c9c-4815-8b03-038fde657b06,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-a64524ea-b81e-4c31-9718-5dfd45cdce00,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-ec40ff0e-f9b4-47ca-86d7-90314eeea137,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-63613b26-1068-4c0c-950c-5b22aa9ed231,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1389212998-172.17.0.17-1597470427619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46469,DS-038858bb-a9df-454d-9928-94147bce4f69,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-2416b7c4-d40b-4b25-9cdb-8456826f4734,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-12538fbc-8b76-46a0-9bf3-4b40538e37bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-3ee23fce-ab90-453f-8383-18f146c63ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-eb52ffea-9c9c-4815-8b03-038fde657b06,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-a64524ea-b81e-4c31-9718-5dfd45cdce00,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-ec40ff0e-f9b4-47ca-86d7-90314eeea137,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-63613b26-1068-4c0c-950c-5b22aa9ed231,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-386687729-172.17.0.17-1597470504742:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36722,DS-8cbe3125-5d04-4b7a-be9e-64f894d76f85,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-c3bb0b83-6772-41dc-a1f5-ba2ed9c190a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-eda1626b-4382-4740-aafa-d658a9eea7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-cb1926fc-185a-4c8d-892f-ad608f2af43a,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-63f41022-10d4-4268-8836-c52aacdc2285,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-3392a406-0b38-4dcf-9294-d0a8e6275d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-54751aaf-1f33-4008-8a5e-ee81b560e2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-99d859f2-8107-41ae-800d-dba8cd02d623,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-386687729-172.17.0.17-1597470504742:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36722,DS-8cbe3125-5d04-4b7a-be9e-64f894d76f85,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-c3bb0b83-6772-41dc-a1f5-ba2ed9c190a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-eda1626b-4382-4740-aafa-d658a9eea7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-cb1926fc-185a-4c8d-892f-ad608f2af43a,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-63f41022-10d4-4268-8836-c52aacdc2285,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-3392a406-0b38-4dcf-9294-d0a8e6275d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-54751aaf-1f33-4008-8a5e-ee81b560e2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-99d859f2-8107-41ae-800d-dba8cd02d623,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1573047441-172.17.0.17-1597470821346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43475,DS-463155cd-dda1-4c3e-9b0b-1499628ac064,DISK], DatanodeInfoWithStorage[127.0.0.1:45954,DS-a4eafa10-07d5-4079-8c34-5be7ece7dcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-f54da882-813a-48da-aac1-d191a4611efe,DISK], DatanodeInfoWithStorage[127.0.0.1:44956,DS-9525cda5-04fd-4799-9e55-a28d5db5635c,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-b6a13db2-0f1a-49e9-b297-c2f026987a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-7475d464-05ea-4ca2-81ae-656fd419f5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-a0b36985-4cfe-4470-abc7-b9bb69589c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-531b68fe-4ab3-4d99-af27-51ad68682122,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1573047441-172.17.0.17-1597470821346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43475,DS-463155cd-dda1-4c3e-9b0b-1499628ac064,DISK], DatanodeInfoWithStorage[127.0.0.1:45954,DS-a4eafa10-07d5-4079-8c34-5be7ece7dcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-f54da882-813a-48da-aac1-d191a4611efe,DISK], DatanodeInfoWithStorage[127.0.0.1:44956,DS-9525cda5-04fd-4799-9e55-a28d5db5635c,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-b6a13db2-0f1a-49e9-b297-c2f026987a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-7475d464-05ea-4ca2-81ae-656fd419f5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-a0b36985-4cfe-4470-abc7-b9bb69589c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-531b68fe-4ab3-4d99-af27-51ad68682122,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-788926124-172.17.0.17-1597471353269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38800,DS-e029dbfb-99b2-40cf-b6fc-2c6fab3b9a41,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-2b1719d4-c08d-459d-872b-10f13f2170d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-de6797d2-781d-48ad-828a-83f168ad5349,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-ef004278-e79e-4a64-bf88-067727c641b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-12df3f8e-bdcf-4f70-98f8-05eeb9018643,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-474b6dc2-03f6-4b9c-a9a9-e83ddf9b987b,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-6c4a957a-89a4-4f62-9721-ea9dfd4f351e,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-fd162c32-c967-4ed9-aaef-847446c85ea1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-788926124-172.17.0.17-1597471353269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38800,DS-e029dbfb-99b2-40cf-b6fc-2c6fab3b9a41,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-2b1719d4-c08d-459d-872b-10f13f2170d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46794,DS-de6797d2-781d-48ad-828a-83f168ad5349,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-ef004278-e79e-4a64-bf88-067727c641b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-12df3f8e-bdcf-4f70-98f8-05eeb9018643,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-474b6dc2-03f6-4b9c-a9a9-e83ddf9b987b,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-6c4a957a-89a4-4f62-9721-ea9dfd4f351e,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-fd162c32-c967-4ed9-aaef-847446c85ea1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-388790465-172.17.0.17-1597472068266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34709,DS-7c9de11d-97e3-401a-a277-898e545ce6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-30a30e1f-9860-4ce6-8dc7-2608d203593f,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-2087c90e-24bf-4300-9737-3478869a3fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-f5dbed2e-22cb-47d3-b3a5-7aa3909911ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-818f88e9-be83-430b-b143-e1cc9f39f9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-6aa48a4d-ea30-4ade-b5a2-b4d06cc42a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-1f6e1ec2-1fc5-43f9-8803-725d50734211,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-c49c1f87-b392-477f-a9e9-3fe0048e4418,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-388790465-172.17.0.17-1597472068266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34709,DS-7c9de11d-97e3-401a-a277-898e545ce6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-30a30e1f-9860-4ce6-8dc7-2608d203593f,DISK], DatanodeInfoWithStorage[127.0.0.1:34173,DS-2087c90e-24bf-4300-9737-3478869a3fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-f5dbed2e-22cb-47d3-b3a5-7aa3909911ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-818f88e9-be83-430b-b143-e1cc9f39f9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-6aa48a4d-ea30-4ade-b5a2-b4d06cc42a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-1f6e1ec2-1fc5-43f9-8803-725d50734211,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-c49c1f87-b392-477f-a9e9-3fe0048e4418,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1016104135-172.17.0.17-1597472289513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40506,DS-017e7815-d05a-4e9d-8eff-0f955e217dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-63fd1cbb-01b0-402b-ab2b-8a177e503462,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-13b0d913-eaa3-41eb-b897-027f40f8525f,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-de177743-1c28-43e6-90c7-ad81caee5035,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-b4b4ffb4-c02c-4c81-96ac-a436d3e000b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43824,DS-fa487a7d-011a-437c-8956-6db83c377502,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-253b9776-1d8f-4794-8ab8-d66fff8dc779,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-1dda70fc-1082-49c3-b00c-d9aee6e73aab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1016104135-172.17.0.17-1597472289513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40506,DS-017e7815-d05a-4e9d-8eff-0f955e217dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-63fd1cbb-01b0-402b-ab2b-8a177e503462,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-13b0d913-eaa3-41eb-b897-027f40f8525f,DISK], DatanodeInfoWithStorage[127.0.0.1:45462,DS-de177743-1c28-43e6-90c7-ad81caee5035,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-b4b4ffb4-c02c-4c81-96ac-a436d3e000b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43824,DS-fa487a7d-011a-437c-8956-6db83c377502,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-253b9776-1d8f-4794-8ab8-d66fff8dc779,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-1dda70fc-1082-49c3-b00c-d9aee6e73aab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-750809359-172.17.0.17-1597472521687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43622,DS-73f65cc7-8fd0-4db8-829b-9a0522bf4676,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-9fe46f88-e36a-4dd5-86aa-7e5dd40e0104,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-bc03a578-17f1-4d1a-86a5-9e568633bda0,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-70a49f1b-587b-4283-8da9-91acdb19f3db,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-5e99547a-f3af-442d-97e3-2e7db328ec66,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-ca37b80f-9c89-4c2e-abec-5247727df356,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-58cf408c-8682-43af-8b22-869a5b8e2e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-b502fd0a-0d4a-4dd3-b8fb-c1e9d48f8de3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-750809359-172.17.0.17-1597472521687:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43622,DS-73f65cc7-8fd0-4db8-829b-9a0522bf4676,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-9fe46f88-e36a-4dd5-86aa-7e5dd40e0104,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-bc03a578-17f1-4d1a-86a5-9e568633bda0,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-70a49f1b-587b-4283-8da9-91acdb19f3db,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-5e99547a-f3af-442d-97e3-2e7db328ec66,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-ca37b80f-9c89-4c2e-abec-5247727df356,DISK], DatanodeInfoWithStorage[127.0.0.1:44570,DS-58cf408c-8682-43af-8b22-869a5b8e2e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-b502fd0a-0d4a-4dd3-b8fb-c1e9d48f8de3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.incremental.intervalMsec
component: hdfs:DataNode
v1: 1000
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2033723527-172.17.0.17-1597473391939:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44325,DS-fddc0813-ea09-497d-a1bc-93e323fabd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-eb0d2ab2-d810-4780-bc31-1471cf74af16,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-07745d05-fe60-46e1-aab4-7690bed90659,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-8f311787-0f1f-477b-8084-4b7cdbdaef92,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-5633f34a-30e7-4ccd-a3d2-45599930f7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-5ad367c8-410d-426d-9f81-dc0449174b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-045751c9-855e-4ab6-9912-a4863256cc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-47415a9a-b243-4589-ab06-3f88c49adbe7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2033723527-172.17.0.17-1597473391939:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44325,DS-fddc0813-ea09-497d-a1bc-93e323fabd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38923,DS-eb0d2ab2-d810-4780-bc31-1471cf74af16,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-07745d05-fe60-46e1-aab4-7690bed90659,DISK], DatanodeInfoWithStorage[127.0.0.1:35488,DS-8f311787-0f1f-477b-8084-4b7cdbdaef92,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-5633f34a-30e7-4ccd-a3d2-45599930f7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36991,DS-5ad367c8-410d-426d-9f81-dc0449174b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-045751c9-855e-4ab6-9912-a4863256cc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-47415a9a-b243-4589-ab06-3f88c49adbe7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5899
