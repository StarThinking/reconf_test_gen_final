reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-894182388-172.17.0.2-1597508940880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41891,DS-306e9071-c39b-45f5-a88a-af3e6f7cba3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-11bd7e51-584a-41d5-a762-4a8d1aa0434b,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-ba788187-e98f-44c1-b7cd-fa9f508ab856,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-946ded2e-98be-4813-9a43-23e69d4f7a19,DISK], DatanodeInfoWithStorage[127.0.0.1:33796,DS-ebde49c1-6c4e-4c2c-917b-6c5ba5c246ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-2e60af83-7d70-44dd-8d63-0ebfade3f38d,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-eacfb8a0-33ac-4df1-8912-f8447055eda2,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-cae4117c-950a-41ca-977c-af8efc63fab3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-894182388-172.17.0.2-1597508940880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41891,DS-306e9071-c39b-45f5-a88a-af3e6f7cba3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44330,DS-11bd7e51-584a-41d5-a762-4a8d1aa0434b,DISK], DatanodeInfoWithStorage[127.0.0.1:41584,DS-ba788187-e98f-44c1-b7cd-fa9f508ab856,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-946ded2e-98be-4813-9a43-23e69d4f7a19,DISK], DatanodeInfoWithStorage[127.0.0.1:33796,DS-ebde49c1-6c4e-4c2c-917b-6c5ba5c246ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-2e60af83-7d70-44dd-8d63-0ebfade3f38d,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-eacfb8a0-33ac-4df1-8912-f8447055eda2,DISK], DatanodeInfoWithStorage[127.0.0.1:36513,DS-cae4117c-950a-41ca-977c-af8efc63fab3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-348108843-172.17.0.2-1597509467146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40355,DS-4c32ad2b-8e56-4a37-9ffe-0bb147e80b69,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-ddc94b5b-4705-4c1e-8404-bac634bb5002,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-f63fd41d-c428-4948-89c0-eb97137d123f,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-75848995-d1b9-4894-a78e-52813e602b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-50aae72c-4872-49c4-9d9c-c3af366be4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-9bb4c8fa-1245-4610-8fb2-78490d34d8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-afe03a30-0fa9-4ef7-8c84-5f8a6bafb3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-c75ea26f-65e1-475e-8937-e237567462b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-348108843-172.17.0.2-1597509467146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40355,DS-4c32ad2b-8e56-4a37-9ffe-0bb147e80b69,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-ddc94b5b-4705-4c1e-8404-bac634bb5002,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-f63fd41d-c428-4948-89c0-eb97137d123f,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-75848995-d1b9-4894-a78e-52813e602b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-50aae72c-4872-49c4-9d9c-c3af366be4c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-9bb4c8fa-1245-4610-8fb2-78490d34d8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-afe03a30-0fa9-4ef7-8c84-5f8a6bafb3cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-c75ea26f-65e1-475e-8937-e237567462b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1225505365-172.17.0.2-1597509507866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41083,DS-fbc4e5e1-bf71-4a24-8eff-f9739c19e539,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-d82a021b-b4d3-4a1f-94ea-79a825ef6ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-cb9db9b2-c39b-4a7c-a284-8d582fbec8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-40d158fa-2221-4a9b-932a-9c31d16c18b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-92b95d10-701c-426d-aee9-e35d0e0db08c,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-3251ba80-eb57-4b2b-9e69-5f0a2f1c54ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-0e16310d-401d-4f58-b6df-b2f63670b120,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-7e54dc02-c5cf-44aa-941f-6042d1705e31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1225505365-172.17.0.2-1597509507866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41083,DS-fbc4e5e1-bf71-4a24-8eff-f9739c19e539,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-d82a021b-b4d3-4a1f-94ea-79a825ef6ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-cb9db9b2-c39b-4a7c-a284-8d582fbec8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41907,DS-40d158fa-2221-4a9b-932a-9c31d16c18b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-92b95d10-701c-426d-aee9-e35d0e0db08c,DISK], DatanodeInfoWithStorage[127.0.0.1:42353,DS-3251ba80-eb57-4b2b-9e69-5f0a2f1c54ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-0e16310d-401d-4f58-b6df-b2f63670b120,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-7e54dc02-c5cf-44aa-941f-6042d1705e31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1520236160-172.17.0.2-1597509682457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35257,DS-71438088-fc58-4488-8c1e-1c2ac5d10ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-cef8f8ce-ff02-45ca-a556-6b77363e3ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-07c3d13a-f33e-40e5-9f8f-bd9006f7437e,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-760ed14f-c421-40c4-b161-ec383c8a5988,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-6171497f-1e56-4b9a-b651-c843d876a6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-6cb8e5d6-95ff-49fb-a553-91c4833f7f74,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-a92c65cf-69bd-4088-8b06-d4d38b9e7a68,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-471a5cf3-098f-4699-bb91-a93cef5b11de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1520236160-172.17.0.2-1597509682457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35257,DS-71438088-fc58-4488-8c1e-1c2ac5d10ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-cef8f8ce-ff02-45ca-a556-6b77363e3ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-07c3d13a-f33e-40e5-9f8f-bd9006f7437e,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-760ed14f-c421-40c4-b161-ec383c8a5988,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-6171497f-1e56-4b9a-b651-c843d876a6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-6cb8e5d6-95ff-49fb-a553-91c4833f7f74,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-a92c65cf-69bd-4088-8b06-d4d38b9e7a68,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-471a5cf3-098f-4699-bb91-a93cef5b11de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-954761078-172.17.0.2-1597509721355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46460,DS-b09503c1-97b8-4f1d-82b7-d4b98d2ffe59,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-4acf3ec8-e2ae-4a3e-be4a-b522af1bac2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-3aa3eace-8e96-425c-a276-7b07541c4b66,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-5dd094a1-9144-4877-a547-ac71be8ce51f,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-611e002e-4d5a-4455-ba55-f2a24a710bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-aba122cb-cb19-4d23-bbfe-44206ca3e180,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-8bcfc014-22df-4436-a028-995e0df666ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-3b971822-7160-4fd7-bf57-cc7cd3f87f25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-954761078-172.17.0.2-1597509721355:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46460,DS-b09503c1-97b8-4f1d-82b7-d4b98d2ffe59,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-4acf3ec8-e2ae-4a3e-be4a-b522af1bac2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-3aa3eace-8e96-425c-a276-7b07541c4b66,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-5dd094a1-9144-4877-a547-ac71be8ce51f,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-611e002e-4d5a-4455-ba55-f2a24a710bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-aba122cb-cb19-4d23-bbfe-44206ca3e180,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-8bcfc014-22df-4436-a028-995e0df666ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-3b971822-7160-4fd7-bf57-cc7cd3f87f25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1424141393-172.17.0.2-1597509794896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40179,DS-ce29eca0-8014-42a2-ad88-3931ab2563ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36593,DS-34095c6c-5d0f-4adf-b876-6017eeb6bd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-6aba9e58-a072-4d24-b045-d283b04b9806,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-d3632191-6fc5-4ac8-8ac4-74009a65fc76,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-14ee7fe8-9166-4891-a446-e22a042434f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-c61722a8-626f-4d2a-8bee-72eae5eb73a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-19d5a0fd-7373-474b-85b8-f05fbe44752c,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-5febba1d-4723-4f41-b9ed-15aeff28396f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1424141393-172.17.0.2-1597509794896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40179,DS-ce29eca0-8014-42a2-ad88-3931ab2563ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36593,DS-34095c6c-5d0f-4adf-b876-6017eeb6bd5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-6aba9e58-a072-4d24-b045-d283b04b9806,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-d3632191-6fc5-4ac8-8ac4-74009a65fc76,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-14ee7fe8-9166-4891-a446-e22a042434f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-c61722a8-626f-4d2a-8bee-72eae5eb73a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38523,DS-19d5a0fd-7373-474b-85b8-f05fbe44752c,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-5febba1d-4723-4f41-b9ed-15aeff28396f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-330466984-172.17.0.2-1597509952821:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36373,DS-e073c129-0e18-4697-b7f0-5b0616b02eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-6702241d-5336-4b0d-9812-3c274af8a26f,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-07ba97ed-0b37-4a23-a0b6-0155255e3781,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-77a04793-71c7-465d-88c7-0c1e5f273e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-085d38bc-1735-4c91-a18e-79d5878492c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-6d894a8e-28f8-44e8-9798-3944b581726a,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-d993ac25-a26e-45d9-a6e9-d710d9eb0b64,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-eb0021b5-4e0f-48cc-b4f5-ff07f6e95ed3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-330466984-172.17.0.2-1597509952821:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36373,DS-e073c129-0e18-4697-b7f0-5b0616b02eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-6702241d-5336-4b0d-9812-3c274af8a26f,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-07ba97ed-0b37-4a23-a0b6-0155255e3781,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-77a04793-71c7-465d-88c7-0c1e5f273e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-085d38bc-1735-4c91-a18e-79d5878492c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-6d894a8e-28f8-44e8-9798-3944b581726a,DISK], DatanodeInfoWithStorage[127.0.0.1:41826,DS-d993ac25-a26e-45d9-a6e9-d710d9eb0b64,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-eb0021b5-4e0f-48cc-b4f5-ff07f6e95ed3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-467038108-172.17.0.2-1597510182191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36117,DS-3af4169f-ffa9-4340-aaca-e6c38dbcaa4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-67884e34-9aa9-4d50-80c2-1e3c3381eba1,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-06045f7e-1746-43cb-ba94-79fdc61b49e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-f9942698-5c28-479d-89f7-6e9591b30ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-f95e0585-8194-4f45-8a83-c544f9b33a12,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-17a2df58-7897-4ae2-8be1-fd324c71b572,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-4b7fe557-ea19-463a-b071-5a76363a5faa,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-eea9084a-3f66-4098-b906-639eb3b60456,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-467038108-172.17.0.2-1597510182191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36117,DS-3af4169f-ffa9-4340-aaca-e6c38dbcaa4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-67884e34-9aa9-4d50-80c2-1e3c3381eba1,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-06045f7e-1746-43cb-ba94-79fdc61b49e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34894,DS-f9942698-5c28-479d-89f7-6e9591b30ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-f95e0585-8194-4f45-8a83-c544f9b33a12,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-17a2df58-7897-4ae2-8be1-fd324c71b572,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-4b7fe557-ea19-463a-b071-5a76363a5faa,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-eea9084a-3f66-4098-b906-639eb3b60456,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2074655963-172.17.0.2-1597510254435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35938,DS-bbff2ccf-b4c3-4250-be89-2d3fc39aee2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-f03c57c4-5f85-45a3-b884-23505d535ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-75e56145-2c1d-475f-849b-a26c92e7748e,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-1e26a0ff-3103-4f8a-947e-32c1d98676c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-94d6f89e-4d87-4c06-8008-32a2680960fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35584,DS-2046db87-1d2c-4ad8-952d-6bca8ac07eab,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-c72b5c5a-b457-416c-b620-36e0ec0a5d04,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-35bd0752-8d3a-4eb5-9e49-f668a6f37c80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2074655963-172.17.0.2-1597510254435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35938,DS-bbff2ccf-b4c3-4250-be89-2d3fc39aee2f,DISK], DatanodeInfoWithStorage[127.0.0.1:35835,DS-f03c57c4-5f85-45a3-b884-23505d535ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-75e56145-2c1d-475f-849b-a26c92e7748e,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-1e26a0ff-3103-4f8a-947e-32c1d98676c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-94d6f89e-4d87-4c06-8008-32a2680960fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35584,DS-2046db87-1d2c-4ad8-952d-6bca8ac07eab,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-c72b5c5a-b457-416c-b620-36e0ec0a5d04,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-35bd0752-8d3a-4eb5-9e49-f668a6f37c80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1927666989-172.17.0.2-1597510741452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33336,DS-5f9f3e34-e8f4-4100-b2d2-818996bd78af,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-23d882a3-ec9f-4393-bfba-475f6998708c,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-fce2a232-a194-4529-b119-44af8bda5bab,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-1ed9d720-bd1a-44a8-ad37-9175043b78ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-a7a51e57-4a58-4a3b-848a-c7839528b01e,DISK], DatanodeInfoWithStorage[127.0.0.1:35541,DS-14b17864-e9ad-4ef2-ae2d-592db5937df5,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-bb1106d5-9579-4ef9-acf8-9f7304ea01f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-f508d031-45f6-49e4-9c24-3de1d94465f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1927666989-172.17.0.2-1597510741452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33336,DS-5f9f3e34-e8f4-4100-b2d2-818996bd78af,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-23d882a3-ec9f-4393-bfba-475f6998708c,DISK], DatanodeInfoWithStorage[127.0.0.1:33168,DS-fce2a232-a194-4529-b119-44af8bda5bab,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-1ed9d720-bd1a-44a8-ad37-9175043b78ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-a7a51e57-4a58-4a3b-848a-c7839528b01e,DISK], DatanodeInfoWithStorage[127.0.0.1:35541,DS-14b17864-e9ad-4ef2-ae2d-592db5937df5,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-bb1106d5-9579-4ef9-acf8-9f7304ea01f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-f508d031-45f6-49e4-9c24-3de1d94465f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-900184236-172.17.0.2-1597510852021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37913,DS-faadb7fc-f373-41c2-a235-91f57da304fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-b23d1e9f-63c3-4e88-8941-fdbd86656f73,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-5e37e06e-268c-4754-8b7f-a45ac2d31b77,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-a7815c76-ec38-4730-bf2d-2d55f715f0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-b4fbe5c4-63b9-4ca9-956c-9dc0dd7b8734,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-89a8cc48-8d8a-4828-812e-05e0d146566e,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-8991fa76-5618-4c44-af2b-2aee102b0245,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-652dc99e-7db6-4b4b-a051-953d4f19b9f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-900184236-172.17.0.2-1597510852021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37913,DS-faadb7fc-f373-41c2-a235-91f57da304fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37048,DS-b23d1e9f-63c3-4e88-8941-fdbd86656f73,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-5e37e06e-268c-4754-8b7f-a45ac2d31b77,DISK], DatanodeInfoWithStorage[127.0.0.1:36553,DS-a7815c76-ec38-4730-bf2d-2d55f715f0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-b4fbe5c4-63b9-4ca9-956c-9dc0dd7b8734,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-89a8cc48-8d8a-4828-812e-05e0d146566e,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-8991fa76-5618-4c44-af2b-2aee102b0245,DISK], DatanodeInfoWithStorage[127.0.0.1:39651,DS-652dc99e-7db6-4b4b-a051-953d4f19b9f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1688247600-172.17.0.2-1597512305774:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38706,DS-7be0bc5f-0e6f-4e2a-8090-b0580000d648,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-444270b7-acf5-4f7c-8b81-d39194cf8f75,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-0a42c85b-30bc-4d66-8dec-a7fc48e71e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-7d03aaa9-b579-435e-ac10-a688f07c3611,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-2dbfc04e-1234-4666-ad87-e62bcd5c23f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-754f9deb-df70-4cc2-9148-38c9975956ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-36395571-8b77-41e5-b3ec-f4a86edd59e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-ad5e4a3d-a704-44dc-b4c1-a1db240752b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1688247600-172.17.0.2-1597512305774:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38706,DS-7be0bc5f-0e6f-4e2a-8090-b0580000d648,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-444270b7-acf5-4f7c-8b81-d39194cf8f75,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-0a42c85b-30bc-4d66-8dec-a7fc48e71e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-7d03aaa9-b579-435e-ac10-a688f07c3611,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-2dbfc04e-1234-4666-ad87-e62bcd5c23f0,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-754f9deb-df70-4cc2-9148-38c9975956ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-36395571-8b77-41e5-b3ec-f4a86edd59e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-ad5e4a3d-a704-44dc-b4c1-a1db240752b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1643527034-172.17.0.2-1597512345686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34423,DS-344ffba1-715c-485b-8b19-0b086aaf2467,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-87c8afb6-e555-427d-a476-db09251adff8,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-3793554a-b720-4b10-9eb2-c080178de5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-720b47a0-5cbd-4d87-b089-b5a5fafdd796,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-8d44380a-9936-4aa7-886d-9b8c3e181121,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-a18e849d-5f87-406d-827c-baa053d21374,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-ed7a85bf-ee2f-4e71-951d-7449e4fe493e,DISK], DatanodeInfoWithStorage[127.0.0.1:33853,DS-e7205a35-4f3d-4538-aac6-9b894b1c5004,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1643527034-172.17.0.2-1597512345686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34423,DS-344ffba1-715c-485b-8b19-0b086aaf2467,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-87c8afb6-e555-427d-a476-db09251adff8,DISK], DatanodeInfoWithStorage[127.0.0.1:38948,DS-3793554a-b720-4b10-9eb2-c080178de5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33267,DS-720b47a0-5cbd-4d87-b089-b5a5fafdd796,DISK], DatanodeInfoWithStorage[127.0.0.1:42864,DS-8d44380a-9936-4aa7-886d-9b8c3e181121,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-a18e849d-5f87-406d-827c-baa053d21374,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-ed7a85bf-ee2f-4e71-951d-7449e4fe493e,DISK], DatanodeInfoWithStorage[127.0.0.1:33853,DS-e7205a35-4f3d-4538-aac6-9b894b1c5004,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-318745447-172.17.0.2-1597512380646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40185,DS-d0a47564-5fef-421f-bf4b-80a6fee763e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-531586c7-ae2b-4dd0-8d92-a52ba853625a,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-b221276e-ce4a-497d-8be2-9f760b02bb64,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-072aef03-9a03-4265-9f1b-752a3857f65c,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-78b85fe1-de48-4c24-a377-85d9d0e9ee71,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-0f6f6409-4276-4dd5-a9a6-46274e82499d,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-f7a22fba-d735-45a2-965a-3b9513bb47db,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-78bf9b5b-3e37-4d4b-a74b-126457c1da6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-318745447-172.17.0.2-1597512380646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40185,DS-d0a47564-5fef-421f-bf4b-80a6fee763e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-531586c7-ae2b-4dd0-8d92-a52ba853625a,DISK], DatanodeInfoWithStorage[127.0.0.1:37198,DS-b221276e-ce4a-497d-8be2-9f760b02bb64,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-072aef03-9a03-4265-9f1b-752a3857f65c,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-78b85fe1-de48-4c24-a377-85d9d0e9ee71,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-0f6f6409-4276-4dd5-a9a6-46274e82499d,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-f7a22fba-d735-45a2-965a-3b9513bb47db,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-78bf9b5b-3e37-4d4b-a74b-126457c1da6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1792647681-172.17.0.2-1597512773247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39914,DS-e039bd38-85dd-4c9d-ac43-972f5069363d,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-518c960f-aac3-4b62-8521-025b1f62c90e,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-29aa82d0-3724-41d7-ae82-1f9d2944ae5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-00c99def-7cf8-4459-8b84-c98323beedb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-a7621d3f-4900-49b3-bd73-fabcc17f6f53,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-420416b3-4107-43a5-ae0d-33f4b5d298c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40746,DS-6fd168f6-7f0b-4c02-adfc-31607fe46dec,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-29768521-2108-4da2-bdf8-d1b5c628df14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1792647681-172.17.0.2-1597512773247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39914,DS-e039bd38-85dd-4c9d-ac43-972f5069363d,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-518c960f-aac3-4b62-8521-025b1f62c90e,DISK], DatanodeInfoWithStorage[127.0.0.1:36373,DS-29aa82d0-3724-41d7-ae82-1f9d2944ae5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41819,DS-00c99def-7cf8-4459-8b84-c98323beedb7,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-a7621d3f-4900-49b3-bd73-fabcc17f6f53,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-420416b3-4107-43a5-ae0d-33f4b5d298c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40746,DS-6fd168f6-7f0b-4c02-adfc-31607fe46dec,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-29768521-2108-4da2-bdf8-d1b5c628df14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-101306189-172.17.0.2-1597513134386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43973,DS-5c9b597b-34c4-462c-b5c0-35e67d8826ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-1522676d-fc78-479e-9bee-47f1f7d3f834,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-3b172539-edbb-4349-bb8f-16305fca90db,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-cb5e3dc4-6b0a-434b-90c6-d7d2ec08b097,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-cb33cae2-6feb-482b-8cc6-4bda138ae052,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-d76c231c-2150-4c8b-b184-a8560edab1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-449a1207-d751-41be-8b21-49a2f137a052,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-6ca5b846-618e-4cc3-97b3-d5e88a375589,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-101306189-172.17.0.2-1597513134386:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43973,DS-5c9b597b-34c4-462c-b5c0-35e67d8826ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-1522676d-fc78-479e-9bee-47f1f7d3f834,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-3b172539-edbb-4349-bb8f-16305fca90db,DISK], DatanodeInfoWithStorage[127.0.0.1:33089,DS-cb5e3dc4-6b0a-434b-90c6-d7d2ec08b097,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-cb33cae2-6feb-482b-8cc6-4bda138ae052,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-d76c231c-2150-4c8b-b184-a8560edab1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35656,DS-449a1207-d751-41be-8b21-49a2f137a052,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-6ca5b846-618e-4cc3-97b3-d5e88a375589,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1186959368-172.17.0.2-1597513591158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44894,DS-6bbfcd6d-d955-4853-8796-77c59a25db1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-eb648d27-362b-409b-b189-86a6f99d3ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-0511a76e-f5f7-4f6a-84ca-03ea5d859253,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-927a1c39-d0f2-4996-bf04-6ae09b96915d,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-5f54113e-f87e-44ce-99f7-9b86af866220,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-95a73579-b35c-4447-8d6c-80383032d276,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-6706c902-1f3a-4838-b530-8203140d0309,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-14d72273-986a-456c-bfc9-d589848416b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1186959368-172.17.0.2-1597513591158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44894,DS-6bbfcd6d-d955-4853-8796-77c59a25db1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-eb648d27-362b-409b-b189-86a6f99d3ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:46556,DS-0511a76e-f5f7-4f6a-84ca-03ea5d859253,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-927a1c39-d0f2-4996-bf04-6ae09b96915d,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-5f54113e-f87e-44ce-99f7-9b86af866220,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-95a73579-b35c-4447-8d6c-80383032d276,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-6706c902-1f3a-4838-b530-8203140d0309,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-14d72273-986a-456c-bfc9-d589848416b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1109985180-172.17.0.2-1597513742916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45218,DS-92e0539c-38a3-463d-a2cc-76bbd40bdbca,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-7312a89a-686a-45c4-8f71-390e16ace961,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-6241aa7c-c1ef-4dfc-9f3e-25bd16776b87,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-74834617-0ec2-49d1-b1c5-6bb1b70537b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-7ff9a7bc-d4f7-4aa8-ba54-45cfc676bfb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-cb272ed6-a99d-476c-9623-d4eeb048985e,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-12d72600-63e1-41ef-be88-4078ed748959,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-09ca73e7-aa39-43ba-89d4-c8112c0a32d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1109985180-172.17.0.2-1597513742916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45218,DS-92e0539c-38a3-463d-a2cc-76bbd40bdbca,DISK], DatanodeInfoWithStorage[127.0.0.1:43929,DS-7312a89a-686a-45c4-8f71-390e16ace961,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-6241aa7c-c1ef-4dfc-9f3e-25bd16776b87,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-74834617-0ec2-49d1-b1c5-6bb1b70537b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36273,DS-7ff9a7bc-d4f7-4aa8-ba54-45cfc676bfb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-cb272ed6-a99d-476c-9623-d4eeb048985e,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-12d72600-63e1-41ef-be88-4078ed748959,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-09ca73e7-aa39-43ba-89d4-c8112c0a32d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-880654949-172.17.0.2-1597514032005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35620,DS-aead197f-49de-43e9-a310-9354aa11adac,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-04bbd7d6-7973-4017-87b1-43f58c5299be,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-fb202e71-d0ba-4480-b132-5a88cbb81751,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-2e8c31ba-8c39-4100-82ef-bfceba486eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-4dfc42c0-37c9-4d4c-aa52-51a68dd91318,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-34c45040-0c89-4266-96d6-85f4d616984e,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-f68f4ff8-fae1-4514-9a12-73bb15d65001,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-a0b147c4-4f74-45c0-a31a-70b3b09914a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-880654949-172.17.0.2-1597514032005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35620,DS-aead197f-49de-43e9-a310-9354aa11adac,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-04bbd7d6-7973-4017-87b1-43f58c5299be,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-fb202e71-d0ba-4480-b132-5a88cbb81751,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-2e8c31ba-8c39-4100-82ef-bfceba486eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34232,DS-4dfc42c0-37c9-4d4c-aa52-51a68dd91318,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-34c45040-0c89-4266-96d6-85f4d616984e,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-f68f4ff8-fae1-4514-9a12-73bb15d65001,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-a0b147c4-4f74-45c0-a31a-70b3b09914a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.retry.timeout.ms
component: hdfs:NameNode
v1: 30
v2: 300000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-123120454-172.17.0.2-1597514071375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46173,DS-63513fa1-0c0c-417e-a5c3-138e74d6b36a,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-583b0b32-d730-4c34-bc83-cd05081c434f,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-6c36b1b5-5428-48a9-8192-28b0d01a1488,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-a3d1134c-3935-41a1-b35a-9c2c714d5ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-684541e5-9752-4b43-962c-d100c9c65f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-abead6ff-5ff2-4f54-a49f-db5d98cd0b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-9bac331c-1c24-4785-90c3-62824e0c8174,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-072ac649-2ec1-45ee-97d3-fb89583fa20f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-123120454-172.17.0.2-1597514071375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46173,DS-63513fa1-0c0c-417e-a5c3-138e74d6b36a,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-583b0b32-d730-4c34-bc83-cd05081c434f,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-6c36b1b5-5428-48a9-8192-28b0d01a1488,DISK], DatanodeInfoWithStorage[127.0.0.1:38259,DS-a3d1134c-3935-41a1-b35a-9c2c714d5ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-684541e5-9752-4b43-962c-d100c9c65f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-abead6ff-5ff2-4f54-a49f-db5d98cd0b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-9bac331c-1c24-4785-90c3-62824e0c8174,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-072ac649-2ec1-45ee-97d3-fb89583fa20f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5571
