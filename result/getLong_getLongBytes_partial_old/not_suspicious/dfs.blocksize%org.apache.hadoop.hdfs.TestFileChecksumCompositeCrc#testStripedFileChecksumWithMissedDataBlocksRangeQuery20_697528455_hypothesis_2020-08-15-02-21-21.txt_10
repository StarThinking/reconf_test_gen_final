reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-436141374-172.17.0.3-1597458093834:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35441,DS-7d919399-32f4-45cd-b01b-5dce701558fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-17881268-c906-4664-8a92-f1536ec76840,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-29ad4e5e-7c81-43e8-add6-bb9ea4515c49,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-704b85f0-a8bb-4bf8-9b06-4b000b97676f,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-07a10db4-63e4-4377-a9a2-ae3876d27d17,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-8a9c255b-a72f-4498-8f19-8df9db7373f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-8f2ebb8f-c31d-449b-85d5-3a0ee6110a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-02b11b11-3622-4d84-a5ff-42f6ffca1d8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-436141374-172.17.0.3-1597458093834:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35441,DS-7d919399-32f4-45cd-b01b-5dce701558fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-17881268-c906-4664-8a92-f1536ec76840,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-29ad4e5e-7c81-43e8-add6-bb9ea4515c49,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-704b85f0-a8bb-4bf8-9b06-4b000b97676f,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-07a10db4-63e4-4377-a9a2-ae3876d27d17,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-8a9c255b-a72f-4498-8f19-8df9db7373f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-8f2ebb8f-c31d-449b-85d5-3a0ee6110a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45932,DS-02b11b11-3622-4d84-a5ff-42f6ffca1d8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-116813655-172.17.0.3-1597458676081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42834,DS-c242bd85-3570-4e89-b9af-6c0f4f218a77,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-5781bb77-9e6b-483d-8f4a-dbe9887c9e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-5452ab5b-e231-4cf4-864d-cd3c5d11e52c,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-168bf829-0ff4-4fc3-91d8-1c2e8280b202,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-bec34813-9e3b-4b62-80a2-4ed5f899961b,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-4954eedc-54b7-4f4d-86f7-a0ca71727645,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-b5bee41e-9888-47de-982a-6f6baf127bed,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-fcbcd4cc-e20c-4bbc-8726-4155349f7f83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-116813655-172.17.0.3-1597458676081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42834,DS-c242bd85-3570-4e89-b9af-6c0f4f218a77,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-5781bb77-9e6b-483d-8f4a-dbe9887c9e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-5452ab5b-e231-4cf4-864d-cd3c5d11e52c,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-168bf829-0ff4-4fc3-91d8-1c2e8280b202,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-bec34813-9e3b-4b62-80a2-4ed5f899961b,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-4954eedc-54b7-4f4d-86f7-a0ca71727645,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-b5bee41e-9888-47de-982a-6f6baf127bed,DISK], DatanodeInfoWithStorage[127.0.0.1:44392,DS-fcbcd4cc-e20c-4bbc-8726-4155349f7f83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-428370572-172.17.0.3-1597459409623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44796,DS-7e8ff6a1-e7a7-41fc-943f-3ddbbcc57865,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-54c6831b-cf5d-493d-b1f1-e3a8b2b4abcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-51c6c68d-38e3-4f32-9f31-94930a52a35e,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-aab728cf-e2a2-4592-96c2-62f90365614b,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-fdde8c88-7a47-4d50-96be-f717036f4853,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-b5979272-867c-47b1-b741-8f5f933e7230,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-a8358668-9292-4724-8781-d0e23adcbb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-9659d0ef-743a-4ab1-b12f-a2aeecc234ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-428370572-172.17.0.3-1597459409623:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44796,DS-7e8ff6a1-e7a7-41fc-943f-3ddbbcc57865,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-54c6831b-cf5d-493d-b1f1-e3a8b2b4abcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-51c6c68d-38e3-4f32-9f31-94930a52a35e,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-aab728cf-e2a2-4592-96c2-62f90365614b,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-fdde8c88-7a47-4d50-96be-f717036f4853,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-b5979272-867c-47b1-b741-8f5f933e7230,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-a8358668-9292-4724-8781-d0e23adcbb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-9659d0ef-743a-4ab1-b12f-a2aeecc234ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-889098826-172.17.0.3-1597459680766:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39550,DS-2f834951-0483-4f3d-804d-549cdf6a5170,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-d8457d34-2e88-435c-92d5-e553b738b512,DISK], DatanodeInfoWithStorage[127.0.0.1:45871,DS-9e0bcae3-2124-48de-8da4-22fa5d9fa718,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-6d967c97-0406-4ec9-94f4-c802f17e521c,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-c86628db-4220-437b-ad30-2bdec8112559,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-56048ccd-96c9-472c-a0e3-790db588ffef,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-725968f8-30ff-4888-a5c3-d5a3e81ce011,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-f3ff1ff1-388e-48f3-8826-d277247e8dc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-889098826-172.17.0.3-1597459680766:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39550,DS-2f834951-0483-4f3d-804d-549cdf6a5170,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-d8457d34-2e88-435c-92d5-e553b738b512,DISK], DatanodeInfoWithStorage[127.0.0.1:45871,DS-9e0bcae3-2124-48de-8da4-22fa5d9fa718,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-6d967c97-0406-4ec9-94f4-c802f17e521c,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-c86628db-4220-437b-ad30-2bdec8112559,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-56048ccd-96c9-472c-a0e3-790db588ffef,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-725968f8-30ff-4888-a5c3-d5a3e81ce011,DISK], DatanodeInfoWithStorage[127.0.0.1:42601,DS-f3ff1ff1-388e-48f3-8826-d277247e8dc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-5425137-172.17.0.3-1597460147367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37030,DS-2c5d1c9a-07b0-45f4-b1a4-1283f0dcf811,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-b5505ff9-b986-4ee5-858b-2f09a026424c,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-1513e08b-c017-4176-b83a-536b6e7858f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-55279f09-f57a-494d-8ce6-894691a3ade7,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-34afe527-0c39-4645-ba73-181751d19890,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-9b05aa02-f567-4344-876f-1a0dbf1d244b,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-2b6d82ad-f093-4a87-8611-75f88bf04bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-4fa3d433-2db8-4599-9ec1-1c1b1a6506a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-5425137-172.17.0.3-1597460147367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37030,DS-2c5d1c9a-07b0-45f4-b1a4-1283f0dcf811,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-b5505ff9-b986-4ee5-858b-2f09a026424c,DISK], DatanodeInfoWithStorage[127.0.0.1:42197,DS-1513e08b-c017-4176-b83a-536b6e7858f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-55279f09-f57a-494d-8ce6-894691a3ade7,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-34afe527-0c39-4645-ba73-181751d19890,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-9b05aa02-f567-4344-876f-1a0dbf1d244b,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-2b6d82ad-f093-4a87-8611-75f88bf04bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-4fa3d433-2db8-4599-9ec1-1c1b1a6506a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1134734738-172.17.0.3-1597460494198:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42951,DS-410e206d-d20c-414a-be2b-c11421db0c80,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-ce9b4ba4-8301-4bd1-8d86-d0eaf0777c55,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-ccf3c8e2-d6e1-40cc-940d-bda9d1a7e8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-d003eaf7-bdb6-4a0a-b7bc-c39f6cfc20da,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-820347c6-5d71-451d-b54e-53c8eba9b7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-80116cc0-bd5d-425a-a222-b7e97cd9f3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-211236df-59a9-4690-b519-e592c1f41055,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-e08b64c4-8550-4fed-9348-3431823923ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1134734738-172.17.0.3-1597460494198:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42951,DS-410e206d-d20c-414a-be2b-c11421db0c80,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-ce9b4ba4-8301-4bd1-8d86-d0eaf0777c55,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-ccf3c8e2-d6e1-40cc-940d-bda9d1a7e8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34125,DS-d003eaf7-bdb6-4a0a-b7bc-c39f6cfc20da,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-820347c6-5d71-451d-b54e-53c8eba9b7bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-80116cc0-bd5d-425a-a222-b7e97cd9f3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-211236df-59a9-4690-b519-e592c1f41055,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-e08b64c4-8550-4fed-9348-3431823923ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-873788475-172.17.0.3-1597461284793:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41669,DS-10d277f8-c9db-4fa2-ab61-ef13d75bf5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-0521d84e-1ea8-4523-93ee-6da30dac115f,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-15465f7e-dfde-488d-bf90-a182282a04c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-bfb9d202-b956-4994-b880-eb0607c74e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-aa14641c-4466-4c6f-ba4c-160348081a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-6c28f399-f8a1-4cc3-8088-5501fb398d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-0b6e98f9-48af-48f9-801d-1f72cd84f28e,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-2ee2e628-15e2-4f0d-a87c-b273d6f78d30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-873788475-172.17.0.3-1597461284793:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41669,DS-10d277f8-c9db-4fa2-ab61-ef13d75bf5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-0521d84e-1ea8-4523-93ee-6da30dac115f,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-15465f7e-dfde-488d-bf90-a182282a04c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-bfb9d202-b956-4994-b880-eb0607c74e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-aa14641c-4466-4c6f-ba4c-160348081a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40371,DS-6c28f399-f8a1-4cc3-8088-5501fb398d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39840,DS-0b6e98f9-48af-48f9-801d-1f72cd84f28e,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-2ee2e628-15e2-4f0d-a87c-b273d6f78d30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-265633287-172.17.0.3-1597461551471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34179,DS-a304113f-fe98-4762-bb03-eb86b0a3c0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-3440aad0-7244-4ea2-ba1d-986b5a270ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-6a30b402-af1c-43e9-8cb2-30f0c260c62a,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-a93ea89c-52c6-4124-940d-90e47fe2afdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-2983ca54-9cde-4b55-9700-3cfce305ac85,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-a4830f14-ad59-4de7-8110-41e8fae13f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-b7a29022-8b5c-45df-acaf-f79078b46f86,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-b75b10f9-af3f-4265-b023-4767486b64c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-265633287-172.17.0.3-1597461551471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34179,DS-a304113f-fe98-4762-bb03-eb86b0a3c0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-3440aad0-7244-4ea2-ba1d-986b5a270ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-6a30b402-af1c-43e9-8cb2-30f0c260c62a,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-a93ea89c-52c6-4124-940d-90e47fe2afdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-2983ca54-9cde-4b55-9700-3cfce305ac85,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-a4830f14-ad59-4de7-8110-41e8fae13f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-b7a29022-8b5c-45df-acaf-f79078b46f86,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-b75b10f9-af3f-4265-b023-4767486b64c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-679281108-172.17.0.3-1597461628627:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42968,DS-fa0a6744-d8a4-405b-862c-2396cf26814a,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-f44e34a0-b80b-4209-81f2-364caa4e377a,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-211951dd-c689-4d89-a73c-f4a424db0f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-1acb24a5-188a-4878-bba8-9c4ec11d325f,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-0967118c-a8b0-4e8c-b1b3-0a4f533549e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-b30f2fb7-55ef-461f-aa22-d0934c2529c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-94fd6d13-31ec-4162-9983-f0df90546087,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-83772d45-0260-4b04-a9e5-2ac9f6b2d60c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-679281108-172.17.0.3-1597461628627:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42968,DS-fa0a6744-d8a4-405b-862c-2396cf26814a,DISK], DatanodeInfoWithStorage[127.0.0.1:38298,DS-f44e34a0-b80b-4209-81f2-364caa4e377a,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-211951dd-c689-4d89-a73c-f4a424db0f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-1acb24a5-188a-4878-bba8-9c4ec11d325f,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-0967118c-a8b0-4e8c-b1b3-0a4f533549e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-b30f2fb7-55ef-461f-aa22-d0934c2529c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-94fd6d13-31ec-4162-9983-f0df90546087,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-83772d45-0260-4b04-a9e5-2ac9f6b2d60c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-431505594-172.17.0.3-1597461823622:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36821,DS-a7338f90-af49-474f-a031-ab44fc5b7c46,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-bbf53c0f-a422-4e88-9af4-2e9218123fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-b2cb6dd2-e3c0-4e2d-a04f-e2725c6b2f60,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-8cc67adf-630a-4019-8100-973d7de800e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-116769b1-6828-4e31-a975-f0213e6c9326,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-4012c29c-0a1e-4539-adc7-7ab8fc1c8512,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-bc7a9cbf-7669-4335-b18e-a79ae71d8f74,DISK], DatanodeInfoWithStorage[127.0.0.1:35766,DS-4599937c-d95b-464e-8a04-c72c8349b9ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-431505594-172.17.0.3-1597461823622:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36821,DS-a7338f90-af49-474f-a031-ab44fc5b7c46,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-bbf53c0f-a422-4e88-9af4-2e9218123fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-b2cb6dd2-e3c0-4e2d-a04f-e2725c6b2f60,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-8cc67adf-630a-4019-8100-973d7de800e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-116769b1-6828-4e31-a975-f0213e6c9326,DISK], DatanodeInfoWithStorage[127.0.0.1:45260,DS-4012c29c-0a1e-4539-adc7-7ab8fc1c8512,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-bc7a9cbf-7669-4335-b18e-a79ae71d8f74,DISK], DatanodeInfoWithStorage[127.0.0.1:35766,DS-4599937c-d95b-464e-8a04-c72c8349b9ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-202398217-172.17.0.3-1597461857781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43568,DS-3d7dbfc4-3366-44f3-b2a2-a451d3d2ea2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-088147d8-2174-43ea-a935-9d11a2c1996b,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-02da3afc-b092-4934-adbe-3a4917fc4f54,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-49bdd99a-6fe3-4c96-8edb-168e58db2e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-6447aa18-7df6-47d2-8fb7-34b5ade493ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-b7498816-1dcf-4e39-a1d5-e42a9bc7367d,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-dbf33612-77c7-469e-87ef-27fb29366336,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-56f45232-80eb-4cad-9f82-4bc7788334fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-202398217-172.17.0.3-1597461857781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43568,DS-3d7dbfc4-3366-44f3-b2a2-a451d3d2ea2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-088147d8-2174-43ea-a935-9d11a2c1996b,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-02da3afc-b092-4934-adbe-3a4917fc4f54,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-49bdd99a-6fe3-4c96-8edb-168e58db2e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-6447aa18-7df6-47d2-8fb7-34b5ade493ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-b7498816-1dcf-4e39-a1d5-e42a9bc7367d,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-dbf33612-77c7-469e-87ef-27fb29366336,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-56f45232-80eb-4cad-9f82-4bc7788334fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-820458550-172.17.0.3-1597461926761:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45536,DS-8e654106-1b02-47a9-bd10-5359a7d6e254,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-eb827e2d-b13e-4b75-ad45-b311078cc9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-b27597a3-2ef5-44ff-a137-72d6bf892249,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-e2d643e8-03e9-45f0-86c4-b842e07c3eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-fd53aee7-17f4-451f-a5f3-6d7a74f35e61,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-0f605be1-39ea-48a0-addf-8e79c63f1bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-a0c5e4dd-3e44-44b5-918e-8b6ddaf706fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-8ef7b401-b765-4190-a8ea-a92af846ea9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-820458550-172.17.0.3-1597461926761:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45536,DS-8e654106-1b02-47a9-bd10-5359a7d6e254,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-eb827e2d-b13e-4b75-ad45-b311078cc9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-b27597a3-2ef5-44ff-a137-72d6bf892249,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-e2d643e8-03e9-45f0-86c4-b842e07c3eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46480,DS-fd53aee7-17f4-451f-a5f3-6d7a74f35e61,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-0f605be1-39ea-48a0-addf-8e79c63f1bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-a0c5e4dd-3e44-44b5-918e-8b6ddaf706fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-8ef7b401-b765-4190-a8ea-a92af846ea9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1093277360-172.17.0.3-1597462151642:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40250,DS-b325f4dd-5e6e-44c7-ad83-e3bcce55ccb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-885aa037-222c-4161-a42b-0c91b835d0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-090829b0-dd7e-4cc8-9371-6d720a4be71d,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-aca540a4-1825-4c66-8233-e680ef33ef0c,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-63c72908-ce90-4d63-88ce-41427ab790a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-588f82e0-a951-4720-aacd-6f666fdaa225,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-611a880b-34ac-4fcc-b1d4-2107f4fd046f,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-dbb696d0-6dbd-4f71-93d2-9b173f3ce218,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1093277360-172.17.0.3-1597462151642:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40250,DS-b325f4dd-5e6e-44c7-ad83-e3bcce55ccb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-885aa037-222c-4161-a42b-0c91b835d0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-090829b0-dd7e-4cc8-9371-6d720a4be71d,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-aca540a4-1825-4c66-8233-e680ef33ef0c,DISK], DatanodeInfoWithStorage[127.0.0.1:32865,DS-63c72908-ce90-4d63-88ce-41427ab790a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-588f82e0-a951-4720-aacd-6f666fdaa225,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-611a880b-34ac-4fcc-b1d4-2107f4fd046f,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-dbb696d0-6dbd-4f71-93d2-9b173f3ce218,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-277051837-172.17.0.3-1597462192190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41973,DS-38fc2f5d-a03f-471c-9026-3cc6fb1fc265,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-3d3ee89b-f622-4966-a712-bbf910bbfcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-b8c81abc-5461-4273-8846-f642bb3263c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-d8dbc653-d7ed-4b07-9b0d-d2765773d164,DISK], DatanodeInfoWithStorage[127.0.0.1:37901,DS-90e83e9f-6b99-4a94-a293-f0888151ebb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-2b5d35ee-ed94-4516-a061-9e8b190985d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-7d480ce0-6f02-468c-8013-8ae09e6e536a,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-30be1c6c-5d77-4bf8-a6c6-c76f2a86aae6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-277051837-172.17.0.3-1597462192190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41973,DS-38fc2f5d-a03f-471c-9026-3cc6fb1fc265,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-3d3ee89b-f622-4966-a712-bbf910bbfcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-b8c81abc-5461-4273-8846-f642bb3263c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-d8dbc653-d7ed-4b07-9b0d-d2765773d164,DISK], DatanodeInfoWithStorage[127.0.0.1:37901,DS-90e83e9f-6b99-4a94-a293-f0888151ebb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-2b5d35ee-ed94-4516-a061-9e8b190985d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-7d480ce0-6f02-468c-8013-8ae09e6e536a,DISK], DatanodeInfoWithStorage[127.0.0.1:35833,DS-30be1c6c-5d77-4bf8-a6c6-c76f2a86aae6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1117106766-172.17.0.3-1597462302838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33964,DS-6ad30c93-3f49-46e9-9aeb-b5ee75f6b816,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-24654f6f-cb9c-4c3f-b2ab-a222db54cc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-5a9408d5-ab9a-47b3-8c1c-74e05bba1de1,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-62410a47-e7e4-488f-9a31-487a7e0df7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-754d0b99-baee-43b3-9abb-6d7729abeb90,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-0cf58282-9989-41af-b6fc-5a098b7337f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-4c7f406b-5a91-4d94-8ff3-8fc7d7394822,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-6c0aa4a2-c37d-4221-aa01-581907b8f568,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1117106766-172.17.0.3-1597462302838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33964,DS-6ad30c93-3f49-46e9-9aeb-b5ee75f6b816,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-24654f6f-cb9c-4c3f-b2ab-a222db54cc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-5a9408d5-ab9a-47b3-8c1c-74e05bba1de1,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-62410a47-e7e4-488f-9a31-487a7e0df7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-754d0b99-baee-43b3-9abb-6d7729abeb90,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-0cf58282-9989-41af-b6fc-5a098b7337f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-4c7f406b-5a91-4d94-8ff3-8fc7d7394822,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-6c0aa4a2-c37d-4221-aa01-581907b8f568,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 536870912
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1456350968-172.17.0.3-1597462481760:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37846,DS-84dfd309-22c7-440e-9d52-ff4e68bd47bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-bcd88404-457f-461e-9fe3-a4f09e87fa78,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-4bfc43c7-acea-46d9-9fbf-fe523188002b,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-86c0c2de-7c2a-465f-a7c3-296663da37e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-bf3de0da-a684-4054-9d14-4e2c35c6c8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-464f0947-466b-40fb-a21c-61219e805ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-0b24cc30-0509-4cfb-8689-b028bbf5d59c,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-401f11ee-9132-4d68-8df5-e981567cb9ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1456350968-172.17.0.3-1597462481760:blk_-9223372036854775776_1002; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37846,DS-84dfd309-22c7-440e-9d52-ff4e68bd47bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-bcd88404-457f-461e-9fe3-a4f09e87fa78,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-4bfc43c7-acea-46d9-9fbf-fe523188002b,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-86c0c2de-7c2a-465f-a7c3-296663da37e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-bf3de0da-a684-4054-9d14-4e2c35c6c8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-464f0947-466b-40fb-a21c-61219e805ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-0b24cc30-0509-4cfb-8689-b028bbf5d59c,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-401f11ee-9132-4d68-8df5-e981567cb9ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5315
