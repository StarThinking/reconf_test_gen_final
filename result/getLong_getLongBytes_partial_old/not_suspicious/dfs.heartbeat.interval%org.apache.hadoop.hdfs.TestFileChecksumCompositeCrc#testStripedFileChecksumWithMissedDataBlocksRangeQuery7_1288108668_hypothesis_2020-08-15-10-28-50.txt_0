reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1073837539-172.17.0.9-1597487422426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38132,DS-f128806a-f754-48fa-a125-782c10ffe60c,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-271accfb-ad85-4bf5-9883-e057f30f70e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-e2dfd5c5-3d81-493c-a10d-5644b1bcf365,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-baf8c4b7-c4e9-49e8-b837-a88f12946c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-fa98f7e7-3a8d-4ccb-a1dc-80651b6a62e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-9cbe08d3-cdf7-4902-8542-91264281a508,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-8954a468-250a-450f-9f9c-3a78c839e962,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-b8b635d0-e037-434c-9fac-98e4be2b3515,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1073837539-172.17.0.9-1597487422426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38132,DS-f128806a-f754-48fa-a125-782c10ffe60c,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-271accfb-ad85-4bf5-9883-e057f30f70e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-e2dfd5c5-3d81-493c-a10d-5644b1bcf365,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-baf8c4b7-c4e9-49e8-b837-a88f12946c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-fa98f7e7-3a8d-4ccb-a1dc-80651b6a62e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-9cbe08d3-cdf7-4902-8542-91264281a508,DISK], DatanodeInfoWithStorage[127.0.0.1:43339,DS-8954a468-250a-450f-9f9c-3a78c839e962,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-b8b635d0-e037-434c-9fac-98e4be2b3515,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-44369193-172.17.0.9-1597487690135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40475,DS-3e84748e-e6d7-4817-9e8a-9d630452ee10,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-5a5026ab-c8e7-473b-ac60-cea89d8cce73,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-28fc1b7f-9ee6-444e-a9ff-2d37f2405c07,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-e48eb3e6-896d-4bd3-b900-aac2ac89ae18,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-0a99d051-a99a-46c8-b6f1-4b3f28954035,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-d7f1cc00-1ec5-414f-b838-a25f2264471c,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-b9e039a8-3627-409a-a335-a4aff3d1d253,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-9648a94a-4b36-475e-8de8-ed95ab7a69d0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-44369193-172.17.0.9-1597487690135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40475,DS-3e84748e-e6d7-4817-9e8a-9d630452ee10,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-5a5026ab-c8e7-473b-ac60-cea89d8cce73,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-28fc1b7f-9ee6-444e-a9ff-2d37f2405c07,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-e48eb3e6-896d-4bd3-b900-aac2ac89ae18,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-0a99d051-a99a-46c8-b6f1-4b3f28954035,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-d7f1cc00-1ec5-414f-b838-a25f2264471c,DISK], DatanodeInfoWithStorage[127.0.0.1:41026,DS-b9e039a8-3627-409a-a335-a4aff3d1d253,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-9648a94a-4b36-475e-8de8-ed95ab7a69d0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155633332-172.17.0.9-1597487837577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41197,DS-02262cda-a1e2-4462-be75-4aec65c60645,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-50293dba-952d-4c5f-a318-7420376d3397,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-e9d6cd06-a2f5-4286-adad-fd0856ec23b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-292815da-e3f8-40e0-9467-04299af75d03,DISK], DatanodeInfoWithStorage[127.0.0.1:44652,DS-327a7ede-772d-4f9d-8890-5dece51bf545,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-85f83a0a-09e0-4cfd-b27a-33a78be961b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-0fc1124e-e351-43de-9139-ce56e45ec956,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-85f4238d-26e6-4f1c-a63d-d4285202eec3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155633332-172.17.0.9-1597487837577:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41197,DS-02262cda-a1e2-4462-be75-4aec65c60645,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-50293dba-952d-4c5f-a318-7420376d3397,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-e9d6cd06-a2f5-4286-adad-fd0856ec23b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-292815da-e3f8-40e0-9467-04299af75d03,DISK], DatanodeInfoWithStorage[127.0.0.1:44652,DS-327a7ede-772d-4f9d-8890-5dece51bf545,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-85f83a0a-09e0-4cfd-b27a-33a78be961b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-0fc1124e-e351-43de-9139-ce56e45ec956,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-85f4238d-26e6-4f1c-a63d-d4285202eec3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-588088827-172.17.0.9-1597487878992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40838,DS-c653dd34-cfd3-4591-ae3f-1bc49e529bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-e887fa4a-d8af-4fbd-bf69-3cd8d5933c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-b946bc95-414d-4c63-b9ad-35542458bb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-d22262c5-963e-4581-9a10-bbc01754cf15,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-f6e0be32-1a7a-4dc4-9764-7fb23b85929a,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-178ab503-cfd7-441b-a99f-df6dc2b18f92,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-4152fd24-2066-42fd-8409-a7c3a07970f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-e00c823a-d5d7-46b8-bc70-84fb31edcf67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-588088827-172.17.0.9-1597487878992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40838,DS-c653dd34-cfd3-4591-ae3f-1bc49e529bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-e887fa4a-d8af-4fbd-bf69-3cd8d5933c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-b946bc95-414d-4c63-b9ad-35542458bb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-d22262c5-963e-4581-9a10-bbc01754cf15,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-f6e0be32-1a7a-4dc4-9764-7fb23b85929a,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-178ab503-cfd7-441b-a99f-df6dc2b18f92,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-4152fd24-2066-42fd-8409-a7c3a07970f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-e00c823a-d5d7-46b8-bc70-84fb31edcf67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1919032820-172.17.0.9-1597487926178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41858,DS-6c9f7671-bc02-42b0-9a9c-42b3f902c768,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-935c3d8d-2edc-4053-902e-ba78de1a8f55,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-33aace94-68cd-4052-9e51-9dc16086c2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-940081f9-a42e-4913-83f6-e8fce512633f,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-7a241768-80c0-4661-bc1a-db2faf47def2,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-e5309157-3943-470c-a947-fbb1bb24f870,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-e8266e9f-c3f6-43ea-80ea-53638f2d7655,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-4a471539-5314-47d6-af05-1217dc069536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1919032820-172.17.0.9-1597487926178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41858,DS-6c9f7671-bc02-42b0-9a9c-42b3f902c768,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-935c3d8d-2edc-4053-902e-ba78de1a8f55,DISK], DatanodeInfoWithStorage[127.0.0.1:40069,DS-33aace94-68cd-4052-9e51-9dc16086c2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-940081f9-a42e-4913-83f6-e8fce512633f,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-7a241768-80c0-4661-bc1a-db2faf47def2,DISK], DatanodeInfoWithStorage[127.0.0.1:37929,DS-e5309157-3943-470c-a947-fbb1bb24f870,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-e8266e9f-c3f6-43ea-80ea-53638f2d7655,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-4a471539-5314-47d6-af05-1217dc069536,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1593315758-172.17.0.9-1597487995222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36448,DS-353ba935-af76-4150-bd59-38f621ff9f09,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-83231cdc-5494-48fe-95e5-0202a98e2de6,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-105f5d21-1c9e-4ac8-8a3b-0d240dfdd938,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-0eb0095c-a29e-4f2d-959a-e8cdddb6986d,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-8b90a1d9-0796-4811-80a7-5e58284f7d28,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-d99fa3e9-cffe-44e9-a280-a72f25070403,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-26ba54a3-0b4a-441d-a999-bb320b11d126,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-0398f551-8a92-4f88-ac90-1f86a8aa7b66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1593315758-172.17.0.9-1597487995222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36448,DS-353ba935-af76-4150-bd59-38f621ff9f09,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-83231cdc-5494-48fe-95e5-0202a98e2de6,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-105f5d21-1c9e-4ac8-8a3b-0d240dfdd938,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-0eb0095c-a29e-4f2d-959a-e8cdddb6986d,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-8b90a1d9-0796-4811-80a7-5e58284f7d28,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-d99fa3e9-cffe-44e9-a280-a72f25070403,DISK], DatanodeInfoWithStorage[127.0.0.1:44092,DS-26ba54a3-0b4a-441d-a999-bb320b11d126,DISK], DatanodeInfoWithStorage[127.0.0.1:42341,DS-0398f551-8a92-4f88-ac90-1f86a8aa7b66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1938590083-172.17.0.9-1597488075465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44495,DS-50d4db52-4927-47b6-91ef-64b6bb84f2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-083c2344-0c69-4331-8d00-607f1711d5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-5757c197-4044-4085-88ee-20e0cde7abc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-a525f647-1599-482b-a44e-133d55c4b05d,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-ca6c438c-9478-4708-aed3-ac759f25fadc,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-d40ab47a-c014-4072-9a91-b0eabfcf704c,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-c5fc7735-b42a-4367-8aee-8c9d316d79ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-11f68c44-396f-4ea7-ad33-12723c56adfd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1938590083-172.17.0.9-1597488075465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44495,DS-50d4db52-4927-47b6-91ef-64b6bb84f2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-083c2344-0c69-4331-8d00-607f1711d5ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34254,DS-5757c197-4044-4085-88ee-20e0cde7abc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-a525f647-1599-482b-a44e-133d55c4b05d,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-ca6c438c-9478-4708-aed3-ac759f25fadc,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-d40ab47a-c014-4072-9a91-b0eabfcf704c,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-c5fc7735-b42a-4367-8aee-8c9d316d79ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-11f68c44-396f-4ea7-ad33-12723c56adfd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1050919892-172.17.0.9-1597488111518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44330,DS-c5016585-a43d-402a-8bc9-4443b0909496,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-7fcfd230-051a-4189-bda7-d19cd4d01797,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-850d5ab1-1e12-4842-bc35-33ad6299b6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-12e3b754-0c18-47a4-bb78-dc1a52a27e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-e116b83d-98a7-47bc-b6ed-792ce7401587,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-c805cc4b-4921-4618-8450-4865a86c570b,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-f06fa0a5-b68f-4b74-9791-e6c9e7763d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-ffb2c1f5-df25-489c-a709-d4bdfc912bf2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1050919892-172.17.0.9-1597488111518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44330,DS-c5016585-a43d-402a-8bc9-4443b0909496,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-7fcfd230-051a-4189-bda7-d19cd4d01797,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-850d5ab1-1e12-4842-bc35-33ad6299b6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-12e3b754-0c18-47a4-bb78-dc1a52a27e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-e116b83d-98a7-47bc-b6ed-792ce7401587,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-c805cc4b-4921-4618-8450-4865a86c570b,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-f06fa0a5-b68f-4b74-9791-e6c9e7763d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33312,DS-ffb2c1f5-df25-489c-a709-d4bdfc912bf2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-758344111-172.17.0.9-1597488150707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46156,DS-2a9215e2-92a3-44da-8217-96fda204fc41,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-c70656c0-e1ad-4823-8376-1b2dabb4556c,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-1242753a-e4ac-4a6b-a151-5b4c2274e7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-5f6b4f19-6740-4e18-8623-43de15a80e69,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-bce41e13-3fd4-4b87-b670-7586ab9b0b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-41606997-984f-47e3-b4cf-295bef290a43,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-4ded511e-c9c7-4cbb-a2e3-46397350b005,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-5832b8ee-47e4-47cf-9451-ed51e85b9975,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-758344111-172.17.0.9-1597488150707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46156,DS-2a9215e2-92a3-44da-8217-96fda204fc41,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-c70656c0-e1ad-4823-8376-1b2dabb4556c,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-1242753a-e4ac-4a6b-a151-5b4c2274e7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-5f6b4f19-6740-4e18-8623-43de15a80e69,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-bce41e13-3fd4-4b87-b670-7586ab9b0b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-41606997-984f-47e3-b4cf-295bef290a43,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-4ded511e-c9c7-4cbb-a2e3-46397350b005,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-5832b8ee-47e4-47cf-9451-ed51e85b9975,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-426671016-172.17.0.9-1597488347998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41715,DS-476a235f-ea8b-478e-ac4f-1198c9254237,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-d66097cf-f866-4858-8382-173897b6b246,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-36f3a22e-5f98-4a4f-98fd-0e89c06767b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-4e186b06-e708-4157-a813-848270ce9a87,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-77c292fc-04f4-4b45-b8ed-404bc6a9cc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-1e76edef-ee31-4717-a473-432b771939d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-423080bf-c8ad-46ee-8043-adc8a31ff15b,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-a46692c9-a608-47fa-8b40-d861c77d0556,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-426671016-172.17.0.9-1597488347998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41715,DS-476a235f-ea8b-478e-ac4f-1198c9254237,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-d66097cf-f866-4858-8382-173897b6b246,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-36f3a22e-5f98-4a4f-98fd-0e89c06767b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-4e186b06-e708-4157-a813-848270ce9a87,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-77c292fc-04f4-4b45-b8ed-404bc6a9cc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-1e76edef-ee31-4717-a473-432b771939d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-423080bf-c8ad-46ee-8043-adc8a31ff15b,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-a46692c9-a608-47fa-8b40-d861c77d0556,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-341529994-172.17.0.9-1597488633480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39474,DS-6852e2ba-5a16-4d36-9aa2-1c195de9b046,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-22db3ab7-e736-46ce-bd97-0c83ee3cf47b,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-a696dff0-a56f-4f1e-a823-b5eea87311b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-f7c49f43-e5d7-455f-a063-61374c36ea30,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-94bf1602-6459-4abf-af29-f0db1c8a330e,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-a429ef7a-1858-467d-b256-4198dc84f85c,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-a4ecb0b7-d2a9-4257-a8f7-0595e10aae9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-10573959-5261-43f3-893c-6fcd873f47b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-341529994-172.17.0.9-1597488633480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39474,DS-6852e2ba-5a16-4d36-9aa2-1c195de9b046,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-22db3ab7-e736-46ce-bd97-0c83ee3cf47b,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-a696dff0-a56f-4f1e-a823-b5eea87311b4,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-f7c49f43-e5d7-455f-a063-61374c36ea30,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-94bf1602-6459-4abf-af29-f0db1c8a330e,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-a429ef7a-1858-467d-b256-4198dc84f85c,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-a4ecb0b7-d2a9-4257-a8f7-0595e10aae9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42799,DS-10573959-5261-43f3-893c-6fcd873f47b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789011995-172.17.0.9-1597488818245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33173,DS-0a785837-8f89-45ae-a979-7674ac80c304,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-b269e20a-fa1d-4840-9835-24cf079d33dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-c8cb0332-69ae-4103-a443-e67619b08472,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-89a2b9c8-ee74-4f1c-9653-00128cbbb2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-b1600149-3cd6-496a-8cd8-b48601b4abcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-1bc85582-df9f-4125-b260-9461640db357,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-fdf3cf02-c140-4887-a4cf-534d186922f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-ba917120-c155-42d6-9b05-55c631c5ad58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-789011995-172.17.0.9-1597488818245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33173,DS-0a785837-8f89-45ae-a979-7674ac80c304,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-b269e20a-fa1d-4840-9835-24cf079d33dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-c8cb0332-69ae-4103-a443-e67619b08472,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-89a2b9c8-ee74-4f1c-9653-00128cbbb2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-b1600149-3cd6-496a-8cd8-b48601b4abcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-1bc85582-df9f-4125-b260-9461640db357,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-fdf3cf02-c140-4887-a4cf-534d186922f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-ba917120-c155-42d6-9b05-55c631c5ad58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204163853-172.17.0.9-1597488958890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44883,DS-a6a0f376-409f-4e99-956c-8d9acc83cedb,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-3203d111-2d05-4007-8747-bd64606545b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-4c1f03bf-75de-4cf0-be4b-379033bded7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-010a3b19-2553-437c-a882-a564e6ccc8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-43148608-c5f9-4ff5-a8ef-b6d8b01c809d,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-3e970390-f33b-442b-841c-be22af8c5db3,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-dbf8809b-14b7-4d64-82f4-1424ce62fc1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-832dadc4-9cc2-4f13-9691-54303a75104d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1204163853-172.17.0.9-1597488958890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44883,DS-a6a0f376-409f-4e99-956c-8d9acc83cedb,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-3203d111-2d05-4007-8747-bd64606545b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-4c1f03bf-75de-4cf0-be4b-379033bded7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37529,DS-010a3b19-2553-437c-a882-a564e6ccc8b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-43148608-c5f9-4ff5-a8ef-b6d8b01c809d,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-3e970390-f33b-442b-841c-be22af8c5db3,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-dbf8809b-14b7-4d64-82f4-1424ce62fc1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-832dadc4-9cc2-4f13-9691-54303a75104d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267517003-172.17.0.9-1597489065830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42301,DS-f3b27679-2483-4343-a3c5-91540ed657e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-7c5243ac-d5a3-4c2a-be6f-bca093170c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35739,DS-290e9be1-65a9-4f0e-8e29-39325e62ab3f,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-62be29ca-0308-46e3-8a45-22342efb3b40,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-5daa2117-595e-4ad9-8890-0bb2ef2f173b,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-b1f0a24a-55fd-4fe5-a519-078f65f101bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-4698d9b8-5583-4eb3-90be-1f43d002fa31,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-7e4bed0d-bb82-4d75-b292-68f26772a706,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-267517003-172.17.0.9-1597489065830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42301,DS-f3b27679-2483-4343-a3c5-91540ed657e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-7c5243ac-d5a3-4c2a-be6f-bca093170c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35739,DS-290e9be1-65a9-4f0e-8e29-39325e62ab3f,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-62be29ca-0308-46e3-8a45-22342efb3b40,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-5daa2117-595e-4ad9-8890-0bb2ef2f173b,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-b1f0a24a-55fd-4fe5-a519-078f65f101bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-4698d9b8-5583-4eb3-90be-1f43d002fa31,DISK], DatanodeInfoWithStorage[127.0.0.1:36559,DS-7e4bed0d-bb82-4d75-b292-68f26772a706,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-881147094-172.17.0.9-1597489329617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44052,DS-f54bc116-7e44-4898-ae22-f67a13e50e51,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-49f3d3ab-c16a-414b-93c6-c2e57e44e6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-bd6ed093-399f-4125-ad9c-7595938ef2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-13ba2ff7-c1ca-4ea2-897d-76061c18475f,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-73e69127-ca04-45f5-a983-c6dd9b4f5b36,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-582a9cf3-6f33-4cc2-a8f3-3c559d5de0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-1141c834-af76-42c8-a6e9-e1cbd082d793,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-42acc0b5-0fa6-4f62-bbcf-82a30a719c80,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-881147094-172.17.0.9-1597489329617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44052,DS-f54bc116-7e44-4898-ae22-f67a13e50e51,DISK], DatanodeInfoWithStorage[127.0.0.1:42500,DS-49f3d3ab-c16a-414b-93c6-c2e57e44e6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-bd6ed093-399f-4125-ad9c-7595938ef2c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-13ba2ff7-c1ca-4ea2-897d-76061c18475f,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-73e69127-ca04-45f5-a983-c6dd9b4f5b36,DISK], DatanodeInfoWithStorage[127.0.0.1:44436,DS-582a9cf3-6f33-4cc2-a8f3-3c559d5de0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-1141c834-af76-42c8-a6e9-e1cbd082d793,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-42acc0b5-0fa6-4f62-bbcf-82a30a719c80,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-269334881-172.17.0.9-1597489625589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46592,DS-21155189-9b70-44bf-8a15-abadb25a238b,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-a6470e98-832e-4f46-92a1-d9eb0ba6157b,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-0f1f8bac-91d6-4c18-85a7-d101d1f4e921,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-44435120-928a-4391-948e-77e6156912d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-4856c18f-17cc-4702-a1bf-8ecf7c8fb092,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-87a84202-3f2b-4cfd-a2f3-36141e1331b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-d360a530-cedc-4776-b102-dc3a4259ac42,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-243d7e76-12ac-48bb-bbbe-e3cee62c3088,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-269334881-172.17.0.9-1597489625589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46592,DS-21155189-9b70-44bf-8a15-abadb25a238b,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-a6470e98-832e-4f46-92a1-d9eb0ba6157b,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-0f1f8bac-91d6-4c18-85a7-d101d1f4e921,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-44435120-928a-4391-948e-77e6156912d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-4856c18f-17cc-4702-a1bf-8ecf7c8fb092,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-87a84202-3f2b-4cfd-a2f3-36141e1331b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-d360a530-cedc-4776-b102-dc3a4259ac42,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-243d7e76-12ac-48bb-bbbe-e3cee62c3088,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-953574046-172.17.0.9-1597489877349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41710,DS-a7bfe834-1b3d-48e7-8e8c-9e453ea6aaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-410204c8-477a-4b96-b1fa-554440231934,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-6edc4f11-8159-4bae-9e5a-baea10bce408,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-cd771bc4-3733-4f51-b647-bbdcd1e60ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-741e4241-bfa3-4aff-8156-0d1a6ab4aae0,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-ab91c914-697d-4e2a-a2c7-4a71f3db1961,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-b6974cfc-1214-43a3-9052-356fb06c83f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-513df3b2-64a0-4290-b07b-036b8eed7206,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-953574046-172.17.0.9-1597489877349:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41710,DS-a7bfe834-1b3d-48e7-8e8c-9e453ea6aaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-410204c8-477a-4b96-b1fa-554440231934,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-6edc4f11-8159-4bae-9e5a-baea10bce408,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-cd771bc4-3733-4f51-b647-bbdcd1e60ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-741e4241-bfa3-4aff-8156-0d1a6ab4aae0,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-ab91c914-697d-4e2a-a2c7-4a71f3db1961,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-b6974cfc-1214-43a3-9052-356fb06c83f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-513df3b2-64a0-4290-b07b-036b8eed7206,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1515328430-172.17.0.9-1597489997090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42334,DS-632f7665-25d1-4abd-9b55-781c90fdaac4,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-dcf29897-f524-40ef-a708-025c172c89ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-1001d714-22fa-4f42-8c02-38821c71b5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-581e4642-a02c-4fc8-84ce-a86f923e008b,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-d3de8140-7f6c-4e31-9f4d-132d59d47fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-10dda8fb-c340-44c5-a21d-3d180cd675c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-beec57b9-d738-4497-aeef-e4edc29c7c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-1144ec69-3402-433e-bcf0-afb99c8eeff2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1515328430-172.17.0.9-1597489997090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42334,DS-632f7665-25d1-4abd-9b55-781c90fdaac4,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-dcf29897-f524-40ef-a708-025c172c89ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-1001d714-22fa-4f42-8c02-38821c71b5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-581e4642-a02c-4fc8-84ce-a86f923e008b,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-d3de8140-7f6c-4e31-9f4d-132d59d47fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-10dda8fb-c340-44c5-a21d-3d180cd675c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-beec57b9-d738-4497-aeef-e4edc29c7c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-1144ec69-3402-433e-bcf0-afb99c8eeff2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465594565-172.17.0.9-1597490199649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45529,DS-49c9dd24-5d1a-40c1-a87f-0c38e2d60d60,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-0b9b242f-7dd3-4fb4-ba46-ed307201a747,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-7d3526bf-fd99-47e7-8b66-80be89c01cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-d0067193-2a3b-45fe-a168-17a914a2a3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-308a9b0f-26b6-478b-813d-63da047e7709,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-cd238798-c1df-4df2-adb7-68967fce520d,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-b6597b99-3ebb-4c20-9aae-b4684ccb6ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-f34143fc-4965-479a-af61-165618358604,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465594565-172.17.0.9-1597490199649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45529,DS-49c9dd24-5d1a-40c1-a87f-0c38e2d60d60,DISK], DatanodeInfoWithStorage[127.0.0.1:38725,DS-0b9b242f-7dd3-4fb4-ba46-ed307201a747,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-7d3526bf-fd99-47e7-8b66-80be89c01cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-d0067193-2a3b-45fe-a168-17a914a2a3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-308a9b0f-26b6-478b-813d-63da047e7709,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-cd238798-c1df-4df2-adb7-68967fce520d,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-b6597b99-3ebb-4c20-9aae-b4684ccb6ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-f34143fc-4965-479a-af61-165618358604,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430319946-172.17.0.9-1597490246096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38354,DS-7f2bef90-2c54-4804-a4f3-9031fbc74f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-7d2eaee3-1c0d-4483-8e80-99f050fc6507,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-8561fa2f-2cfd-4642-9df2-1b32ab5f02f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-45f512b6-2026-47c5-8f2f-2242f5e81a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-ab33ab53-bffa-4db1-84e6-96588806671b,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-f58fdf3b-c015-48ce-b626-9e11b941e951,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-9e23bad7-51e4-4cdc-b95e-20a68b59495b,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-1d20995d-73b1-449a-9deb-594904d92e88,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-430319946-172.17.0.9-1597490246096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38354,DS-7f2bef90-2c54-4804-a4f3-9031fbc74f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-7d2eaee3-1c0d-4483-8e80-99f050fc6507,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-8561fa2f-2cfd-4642-9df2-1b32ab5f02f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-45f512b6-2026-47c5-8f2f-2242f5e81a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-ab33ab53-bffa-4db1-84e6-96588806671b,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-f58fdf3b-c015-48ce-b626-9e11b941e951,DISK], DatanodeInfoWithStorage[127.0.0.1:38538,DS-9e23bad7-51e4-4cdc-b95e-20a68b59495b,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-1d20995d-73b1-449a-9deb-594904d92e88,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851089723-172.17.0.9-1597490353671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33145,DS-b553810d-d853-4444-acac-86c2248088e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-2c55d78f-eaff-484e-8295-2f0760643b21,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-a9b9ceba-1548-4163-93a7-e9f78b203ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-7614e169-ead5-4e07-a126-91da305fefc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-49893648-6d94-4e37-b135-c6cb7368459e,DISK], DatanodeInfoWithStorage[127.0.0.1:42333,DS-5351f4b0-f0d9-4e75-8137-9e6893666e31,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-0fd4f704-4282-48a1-bcc7-27e9619e1c58,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-8d54ee6b-9798-49c3-9df4-b129473d5e4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851089723-172.17.0.9-1597490353671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33145,DS-b553810d-d853-4444-acac-86c2248088e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-2c55d78f-eaff-484e-8295-2f0760643b21,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-a9b9ceba-1548-4163-93a7-e9f78b203ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-7614e169-ead5-4e07-a126-91da305fefc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-49893648-6d94-4e37-b135-c6cb7368459e,DISK], DatanodeInfoWithStorage[127.0.0.1:42333,DS-5351f4b0-f0d9-4e75-8137-9e6893666e31,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-0fd4f704-4282-48a1-bcc7-27e9619e1c58,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-8d54ee6b-9798-49c3-9df4-b129473d5e4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894414706-172.17.0.9-1597490723837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45847,DS-fdc051bb-8564-416c-bd97-e008cd885af9,DISK], DatanodeInfoWithStorage[127.0.0.1:34646,DS-638a49fa-2ef8-4dcf-aef2-39d32650717e,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-4641db2f-f81d-4b82-9398-7b069d3c4a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-c5c78bca-98df-4cf4-acd8-dbf8c2d94527,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-c32c119b-0489-4488-8edd-3ca8950e763b,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-d9e204bd-2643-4a1d-9359-6d374a02b13d,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-f25c8af3-5a63-4d1f-9bbe-a4d91502634b,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-ea004a39-73f5-4f28-aeb8-64b242393770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894414706-172.17.0.9-1597490723837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45847,DS-fdc051bb-8564-416c-bd97-e008cd885af9,DISK], DatanodeInfoWithStorage[127.0.0.1:34646,DS-638a49fa-2ef8-4dcf-aef2-39d32650717e,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-4641db2f-f81d-4b82-9398-7b069d3c4a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-c5c78bca-98df-4cf4-acd8-dbf8c2d94527,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-c32c119b-0489-4488-8edd-3ca8950e763b,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-d9e204bd-2643-4a1d-9359-6d374a02b13d,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-f25c8af3-5a63-4d1f-9bbe-a4d91502634b,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-ea004a39-73f5-4f28-aeb8-64b242393770,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111338898-172.17.0.9-1597490919330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44719,DS-5af89fd8-3de8-4e3c-acf8-294b7a083222,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-395c0f5b-451d-4aec-8ded-3cd94f62074c,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-47e655a1-057b-46e0-bb6f-ce3033acf528,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-7217a8a5-3b05-41f0-bb75-97c38b1c1296,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-4c7bd93b-7bc2-413f-bdff-db9f75c0829b,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-05522263-6caf-481b-8ae5-00ea5910b8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-313cca74-ef72-486a-aba8-7301d3eeb03d,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-df796a0d-d382-4d4d-b3bb-b08fdc7447ba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111338898-172.17.0.9-1597490919330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44719,DS-5af89fd8-3de8-4e3c-acf8-294b7a083222,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-395c0f5b-451d-4aec-8ded-3cd94f62074c,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-47e655a1-057b-46e0-bb6f-ce3033acf528,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-7217a8a5-3b05-41f0-bb75-97c38b1c1296,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-4c7bd93b-7bc2-413f-bdff-db9f75c0829b,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-05522263-6caf-481b-8ae5-00ea5910b8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46380,DS-313cca74-ef72-486a-aba8-7301d3eeb03d,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-df796a0d-d382-4d4d-b3bb-b08fdc7447ba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1050407178-172.17.0.9-1597491208930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45298,DS-f2abe9bc-acde-4f8c-af19-e7a8d61b039e,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-2eb01e6e-3cb1-4b0d-983d-c132802a3849,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-72833c19-30e8-4344-b538-a794f26c76dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-de194ee0-e5b3-4e82-b8fe-81860b4a0477,DISK], DatanodeInfoWithStorage[127.0.0.1:42279,DS-12992930-e50b-4794-b400-1a4d0c9348cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-f86cff25-8936-49dd-ae68-eb80251a1852,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-cdcf142a-9dfc-40e2-b2ea-0cbc011245c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-32752c84-f411-4e84-ae1c-47416b7a724c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1050407178-172.17.0.9-1597491208930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45298,DS-f2abe9bc-acde-4f8c-af19-e7a8d61b039e,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-2eb01e6e-3cb1-4b0d-983d-c132802a3849,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-72833c19-30e8-4344-b538-a794f26c76dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-de194ee0-e5b3-4e82-b8fe-81860b4a0477,DISK], DatanodeInfoWithStorage[127.0.0.1:42279,DS-12992930-e50b-4794-b400-1a4d0c9348cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-f86cff25-8936-49dd-ae68-eb80251a1852,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-cdcf142a-9dfc-40e2-b2ea-0cbc011245c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-32752c84-f411-4e84-ae1c-47416b7a724c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1972590121-172.17.0.9-1597491287321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45727,DS-3c767aab-47a0-415f-ac73-c0666cad3343,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-acbd8b98-8915-41a7-85a3-ddd80fdf7fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:43896,DS-88b3f45a-1033-40b2-a784-e988c268e609,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-d1abf081-c0df-460a-a017-c2917f3a412e,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-d146d014-685f-4474-b374-5ced5666625d,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-1e9e53aa-0b2c-4279-8545-4f10cda9a549,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-4c30bc2f-d249-47d6-9d83-5bd9feb873ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-98b517d4-d76b-4054-8ce3-5e885ac8c0a8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1972590121-172.17.0.9-1597491287321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45727,DS-3c767aab-47a0-415f-ac73-c0666cad3343,DISK], DatanodeInfoWithStorage[127.0.0.1:39440,DS-acbd8b98-8915-41a7-85a3-ddd80fdf7fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:43896,DS-88b3f45a-1033-40b2-a784-e988c268e609,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-d1abf081-c0df-460a-a017-c2917f3a412e,DISK], DatanodeInfoWithStorage[127.0.0.1:46238,DS-d146d014-685f-4474-b374-5ced5666625d,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-1e9e53aa-0b2c-4279-8545-4f10cda9a549,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-4c30bc2f-d249-47d6-9d83-5bd9feb873ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-98b517d4-d76b-4054-8ce3-5e885ac8c0a8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-525487195-172.17.0.9-1597491910979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41725,DS-62ec3e1b-5d23-4fa8-bc38-7f9acfcab7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-0fc3bc7b-39d8-4175-bbb3-4adfc4b1c20b,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-bf8b6a39-84f0-436a-8d27-9b38417e28a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-a4754d12-ac1d-4240-82cb-b272621a4d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-6009077c-d117-433b-8e19-18074b3ba29f,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-613206fc-2065-49df-a3d5-cf5b93a48f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-3469f22c-d0d0-4fc4-bcd7-30f4487cb85a,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-8200d9fe-0958-43ce-8d2a-0a3cfc513f17,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-525487195-172.17.0.9-1597491910979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41725,DS-62ec3e1b-5d23-4fa8-bc38-7f9acfcab7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-0fc3bc7b-39d8-4175-bbb3-4adfc4b1c20b,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-bf8b6a39-84f0-436a-8d27-9b38417e28a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-a4754d12-ac1d-4240-82cb-b272621a4d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35212,DS-6009077c-d117-433b-8e19-18074b3ba29f,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-613206fc-2065-49df-a3d5-cf5b93a48f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-3469f22c-d0d0-4fc4-bcd7-30f4487cb85a,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-8200d9fe-0958-43ce-8d2a-0a3cfc513f17,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-636889980-172.17.0.9-1597492068189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40345,DS-df5974e9-d781-4073-b5fb-608b3fc30b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-5bf65911-96d5-4d54-8730-621b442674fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-e6f2cffa-ff07-47e9-b68c-f543e09b80c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-b7fd4b85-99d6-429d-bfac-60b52e786fad,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-4dcc4c96-241e-4d82-90e9-53b59a9d695b,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-6102a2c1-2175-4d82-917f-8a7e8722f017,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-d123a11d-00d7-4225-9a9d-8ab35dfa39f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-464ea8c0-ea48-4466-8618-a1ccc376bfd0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-636889980-172.17.0.9-1597492068189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40345,DS-df5974e9-d781-4073-b5fb-608b3fc30b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-5bf65911-96d5-4d54-8730-621b442674fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37604,DS-e6f2cffa-ff07-47e9-b68c-f543e09b80c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-b7fd4b85-99d6-429d-bfac-60b52e786fad,DISK], DatanodeInfoWithStorage[127.0.0.1:43640,DS-4dcc4c96-241e-4d82-90e9-53b59a9d695b,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-6102a2c1-2175-4d82-917f-8a7e8722f017,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-d123a11d-00d7-4225-9a9d-8ab35dfa39f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-464ea8c0-ea48-4466-8618-a1ccc376bfd0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273087307-172.17.0.9-1597492115208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42036,DS-188f2643-6961-445b-9cf8-bae9548b63f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-557452a4-8bd5-4973-89eb-17d8e99bbdd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-abb77022-36ef-4997-a7f9-7a31215413d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-b4325cc2-630d-4e32-adaf-bad45e136a71,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-924c0f9b-57df-4431-9c43-97de97168c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-9e9feb95-a0d0-4c55-9411-5f3f7481780a,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-aab68011-3d4f-4db4-a782-80f87d0ade9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-3863f4e5-c4ce-42f8-b740-a9b49cdc0ab7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273087307-172.17.0.9-1597492115208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42036,DS-188f2643-6961-445b-9cf8-bae9548b63f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-557452a4-8bd5-4973-89eb-17d8e99bbdd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-abb77022-36ef-4997-a7f9-7a31215413d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-b4325cc2-630d-4e32-adaf-bad45e136a71,DISK], DatanodeInfoWithStorage[127.0.0.1:45378,DS-924c0f9b-57df-4431-9c43-97de97168c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-9e9feb95-a0d0-4c55-9411-5f3f7481780a,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-aab68011-3d4f-4db4-a782-80f87d0ade9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-3863f4e5-c4ce-42f8-b740-a9b49cdc0ab7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-802745657-172.17.0.9-1597492159525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33705,DS-3039955a-1df0-4c3a-8c0a-3107b634baab,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-b425f1f5-431e-44b7-af78-3a391f03d1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-b6c25947-a82d-4192-8c74-c92d272aa38c,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-a26ed449-3f10-4ae5-aa3a-f1d3099cbdbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-c6563634-28ec-4a81-938d-2f512b07f4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-1ddc4a21-6274-42b5-861c-61cb365aecc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-232793cb-b19a-4dbc-aaef-8ac341a5928a,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-0dcd62aa-a861-48b5-93fa-1f31142a3d69,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-802745657-172.17.0.9-1597492159525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33705,DS-3039955a-1df0-4c3a-8c0a-3107b634baab,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-b425f1f5-431e-44b7-af78-3a391f03d1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-b6c25947-a82d-4192-8c74-c92d272aa38c,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-a26ed449-3f10-4ae5-aa3a-f1d3099cbdbb,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-c6563634-28ec-4a81-938d-2f512b07f4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-1ddc4a21-6274-42b5-861c-61cb365aecc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-232793cb-b19a-4dbc-aaef-8ac341a5928a,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-0dcd62aa-a861-48b5-93fa-1f31142a3d69,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1148072166-172.17.0.9-1597492192335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45538,DS-792abef9-aa75-4453-8323-462fa293399d,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-0b2f828c-81ad-40c3-a968-0aaa69b36a09,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-1139bf8e-b7b0-45e7-a02d-69776d7076a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-39d9fbb1-caec-4fce-9ffa-6630fa3051ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-6508052d-cfb8-461b-8bf3-986a606b8e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-f06216a9-4ce2-4e30-826a-0dbaebe91a18,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-864e6b78-39ac-4b6a-9713-acb4c827e823,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-b69f8c1d-5bc3-4284-8491-e84a4d2f8a3a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1148072166-172.17.0.9-1597492192335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45538,DS-792abef9-aa75-4453-8323-462fa293399d,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-0b2f828c-81ad-40c3-a968-0aaa69b36a09,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-1139bf8e-b7b0-45e7-a02d-69776d7076a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-39d9fbb1-caec-4fce-9ffa-6630fa3051ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33071,DS-6508052d-cfb8-461b-8bf3-986a606b8e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-f06216a9-4ce2-4e30-826a-0dbaebe91a18,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-864e6b78-39ac-4b6a-9713-acb4c827e823,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-b69f8c1d-5bc3-4284-8491-e84a4d2f8a3a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-521814609-172.17.0.9-1597492313100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44608,DS-ee4bec86-1106-4a68-8900-fa27fbf90f55,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-7162b5bc-5f67-4cba-a2c1-7bbd73fcc134,DISK], DatanodeInfoWithStorage[127.0.0.1:44159,DS-24163424-3c86-4269-a59b-f1b3dbbc98a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-fb95277e-6be7-4a11-88c4-7141bcdb0fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-06ddbdcd-0784-4b84-a8f4-b6cb53f84589,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-a9112289-e9d0-49df-97f4-28c6f4501576,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-c0a5877b-0aac-4807-8936-a904ed27d8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-4e5b2415-74a1-4dbc-a78a-164b81880d94,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-521814609-172.17.0.9-1597492313100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44608,DS-ee4bec86-1106-4a68-8900-fa27fbf90f55,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-7162b5bc-5f67-4cba-a2c1-7bbd73fcc134,DISK], DatanodeInfoWithStorage[127.0.0.1:44159,DS-24163424-3c86-4269-a59b-f1b3dbbc98a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-fb95277e-6be7-4a11-88c4-7141bcdb0fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-06ddbdcd-0784-4b84-a8f4-b6cb53f84589,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-a9112289-e9d0-49df-97f4-28c6f4501576,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-c0a5877b-0aac-4807-8936-a904ed27d8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38407,DS-4e5b2415-74a1-4dbc-a78a-164b81880d94,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1731191416-172.17.0.9-1597492389346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36942,DS-d242c795-dac7-44f0-9e1b-38bd81c40055,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-83f75a32-70d9-41de-a7c1-7587d72ad8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45331,DS-2f23bccb-ee91-4e94-842e-9f1fc0d5118b,DISK], DatanodeInfoWithStorage[127.0.0.1:46730,DS-27db38fc-d6fd-437a-997a-d91952f346c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-067d9ab8-fbc5-4f68-9520-a2c8fdb066ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-31e93b64-285c-4016-ab0d-bb0543d4c26e,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-4f94a1fd-491b-4d68-992c-1c065fabbf68,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-a3e130a0-b2a8-42b4-8e92-5da378f92b2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1731191416-172.17.0.9-1597492389346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36942,DS-d242c795-dac7-44f0-9e1b-38bd81c40055,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-83f75a32-70d9-41de-a7c1-7587d72ad8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45331,DS-2f23bccb-ee91-4e94-842e-9f1fc0d5118b,DISK], DatanodeInfoWithStorage[127.0.0.1:46730,DS-27db38fc-d6fd-437a-997a-d91952f346c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-067d9ab8-fbc5-4f68-9520-a2c8fdb066ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-31e93b64-285c-4016-ab0d-bb0543d4c26e,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-4f94a1fd-491b-4d68-992c-1c065fabbf68,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-a3e130a0-b2a8-42b4-8e92-5da378f92b2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872015673-172.17.0.9-1597492471645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42069,DS-b3b7ef36-926b-4e3d-a500-443491d283c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-364544e3-65a5-4e5e-8177-8a300170cd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-d8a50a84-aa81-42dc-af6c-3716abd7724d,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-148e135a-9e7e-4289-acff-d1fe54dbd069,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-94411d49-afa6-4231-9a1a-e41170eca817,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-f388cdeb-4a15-4092-9c0e-e96f64208b38,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-ef6539f8-6467-4577-ac34-ff6b1a07b1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-d6b7537a-a1c9-4294-a8a3-0a1bb9932a9c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872015673-172.17.0.9-1597492471645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42069,DS-b3b7ef36-926b-4e3d-a500-443491d283c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-364544e3-65a5-4e5e-8177-8a300170cd6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-d8a50a84-aa81-42dc-af6c-3716abd7724d,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-148e135a-9e7e-4289-acff-d1fe54dbd069,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-94411d49-afa6-4231-9a1a-e41170eca817,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-f388cdeb-4a15-4092-9c0e-e96f64208b38,DISK], DatanodeInfoWithStorage[127.0.0.1:43209,DS-ef6539f8-6467-4577-ac34-ff6b1a07b1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46654,DS-d6b7537a-a1c9-4294-a8a3-0a1bb9932a9c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-631641577-172.17.0.9-1597492546529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45819,DS-d4d232c7-71cd-4664-8125-0bfb08364a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-47fe2839-49cf-4858-b24d-66d1c67d461d,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-eaa5090f-767e-4f46-bae7-dfe58f3bcea8,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-42a47ba3-8392-4b13-b5e6-1450fcb9d92e,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-143316a8-fc0e-4406-88db-2cb7d3a8b73f,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-692cd8c2-19a6-403c-82ee-6688a40e64da,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-15202278-2adb-4d2f-8fe5-f0ef13167632,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-72653898-4003-4041-af70-adc678a595b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-631641577-172.17.0.9-1597492546529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45819,DS-d4d232c7-71cd-4664-8125-0bfb08364a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-47fe2839-49cf-4858-b24d-66d1c67d461d,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-eaa5090f-767e-4f46-bae7-dfe58f3bcea8,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-42a47ba3-8392-4b13-b5e6-1450fcb9d92e,DISK], DatanodeInfoWithStorage[127.0.0.1:39536,DS-143316a8-fc0e-4406-88db-2cb7d3a8b73f,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-692cd8c2-19a6-403c-82ee-6688a40e64da,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-15202278-2adb-4d2f-8fe5-f0ef13167632,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-72653898-4003-4041-af70-adc678a595b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097610549-172.17.0.9-1597492579391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44812,DS-a8281879-a382-40ce-a867-a00c5405977d,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-1430e118-a755-4379-981c-808a3e3433d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-ad5340e2-bb27-457f-be09-a17c14f23ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-df8d873a-4c93-4ead-8d80-3bcc7db9307a,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-8f2f5ab9-3d0d-498e-8d7d-ad461da2d174,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-675c756a-d464-4d15-95ba-b162cb1bdaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-96340682-ad9a-4637-af81-b0d93792ed18,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-61270401-a051-4e7a-9065-e8c4f4221ea1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2097610549-172.17.0.9-1597492579391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44812,DS-a8281879-a382-40ce-a867-a00c5405977d,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-1430e118-a755-4379-981c-808a3e3433d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-ad5340e2-bb27-457f-be09-a17c14f23ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-df8d873a-4c93-4ead-8d80-3bcc7db9307a,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-8f2f5ab9-3d0d-498e-8d7d-ad461da2d174,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-675c756a-d464-4d15-95ba-b162cb1bdaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-96340682-ad9a-4637-af81-b0d93792ed18,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-61270401-a051-4e7a-9065-e8c4f4221ea1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1562830772-172.17.0.9-1597493007602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42424,DS-e9c389f6-d611-4434-a70f-45caf39c4046,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-1bc423fb-eba0-44e4-9e41-82f390b76729,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-6b80761c-22f4-4199-962b-59ddbdb34f15,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-6f68c3bc-c020-4218-8b29-7e95f533512b,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-8efb845b-61c0-40cf-bf1d-e267c0df0e46,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-a2e37546-10a5-44b5-8b03-a7a8dcbceb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-cbca1f53-f61b-47aa-af68-b0abc1dadd86,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-f8877cb7-d386-4a64-8f86-8b71fce4b568,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1562830772-172.17.0.9-1597493007602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42424,DS-e9c389f6-d611-4434-a70f-45caf39c4046,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-1bc423fb-eba0-44e4-9e41-82f390b76729,DISK], DatanodeInfoWithStorage[127.0.0.1:37563,DS-6b80761c-22f4-4199-962b-59ddbdb34f15,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-6f68c3bc-c020-4218-8b29-7e95f533512b,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-8efb845b-61c0-40cf-bf1d-e267c0df0e46,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-a2e37546-10a5-44b5-8b03-a7a8dcbceb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40915,DS-cbca1f53-f61b-47aa-af68-b0abc1dadd86,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-f8877cb7-d386-4a64-8f86-8b71fce4b568,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 13 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 5815
