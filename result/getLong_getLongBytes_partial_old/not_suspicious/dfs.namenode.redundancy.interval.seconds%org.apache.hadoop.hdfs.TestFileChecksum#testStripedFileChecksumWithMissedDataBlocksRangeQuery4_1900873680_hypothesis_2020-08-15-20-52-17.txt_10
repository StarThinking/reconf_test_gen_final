reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548492910-172.17.0.11-1597524758347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35218,DS-35ef13ca-0b7d-4251-98f4-cdd8fa179d17,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-fd82dadc-f6b0-4586-b777-d29b58c5fc56,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-cb1fa93d-b195-46f1-8e07-5755dc30a138,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-360e956c-6791-4f0a-834c-2e600e819d25,DISK], DatanodeInfoWithStorage[127.0.0.1:41680,DS-f4615c1e-35aa-4037-bc09-47ad61b4dd82,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-40e44961-b399-4a6f-8675-d718681a12d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-068567a5-d185-4218-bc84-ab6a26df936a,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-d57c96a9-c990-440d-a8c9-463a1767d0ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548492910-172.17.0.11-1597524758347:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35218,DS-35ef13ca-0b7d-4251-98f4-cdd8fa179d17,DISK], DatanodeInfoWithStorage[127.0.0.1:38568,DS-fd82dadc-f6b0-4586-b777-d29b58c5fc56,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-cb1fa93d-b195-46f1-8e07-5755dc30a138,DISK], DatanodeInfoWithStorage[127.0.0.1:33484,DS-360e956c-6791-4f0a-834c-2e600e819d25,DISK], DatanodeInfoWithStorage[127.0.0.1:41680,DS-f4615c1e-35aa-4037-bc09-47ad61b4dd82,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-40e44961-b399-4a6f-8675-d718681a12d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-068567a5-d185-4218-bc84-ab6a26df936a,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-d57c96a9-c990-440d-a8c9-463a1767d0ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1000547243-172.17.0.11-1597524848791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33258,DS-c0c1160b-5379-4116-b024-93f0d10a0eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-1904ae3b-a818-49ef-87ea-c8130129417a,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-6f573308-0225-48ae-ad57-55028955840f,DISK], DatanodeInfoWithStorage[127.0.0.1:46082,DS-55000fad-082f-4460-add4-481fe551ade2,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-2e0ce742-b984-4dda-8f77-ae52c314194c,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-6c519cf4-d0d4-4b12-bbb1-da740d61b9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-80b0d075-1ca7-4856-9d01-0e4b8b64306d,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-67a861bd-6cc6-437f-92ae-91b7f8f2e4d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1000547243-172.17.0.11-1597524848791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33258,DS-c0c1160b-5379-4116-b024-93f0d10a0eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34261,DS-1904ae3b-a818-49ef-87ea-c8130129417a,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-6f573308-0225-48ae-ad57-55028955840f,DISK], DatanodeInfoWithStorage[127.0.0.1:46082,DS-55000fad-082f-4460-add4-481fe551ade2,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-2e0ce742-b984-4dda-8f77-ae52c314194c,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-6c519cf4-d0d4-4b12-bbb1-da740d61b9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46001,DS-80b0d075-1ca7-4856-9d01-0e4b8b64306d,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-67a861bd-6cc6-437f-92ae-91b7f8f2e4d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-362278962-172.17.0.11-1597525245901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43679,DS-f706cd91-720a-4f5e-bb38-0fb4f9895d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-4afb18bc-e05e-42dc-910c-4b32e99e582a,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-0309e1c3-72ad-49d9-9f17-1ac8b73d5f62,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-3526092d-fbdc-4852-be7f-9f9e5607ff48,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-a2714514-d71c-4785-a05f-905e8d5f761f,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-2d1d66f7-cdeb-4005-8b68-cf912cf22138,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-35993b76-fa0a-4ded-b093-0b976971a358,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-fb0c1d3b-37dd-4375-9cb7-d1fb0f79b8b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-362278962-172.17.0.11-1597525245901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43679,DS-f706cd91-720a-4f5e-bb38-0fb4f9895d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36589,DS-4afb18bc-e05e-42dc-910c-4b32e99e582a,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-0309e1c3-72ad-49d9-9f17-1ac8b73d5f62,DISK], DatanodeInfoWithStorage[127.0.0.1:33897,DS-3526092d-fbdc-4852-be7f-9f9e5607ff48,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-a2714514-d71c-4785-a05f-905e8d5f761f,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-2d1d66f7-cdeb-4005-8b68-cf912cf22138,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-35993b76-fa0a-4ded-b093-0b976971a358,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-fb0c1d3b-37dd-4375-9cb7-d1fb0f79b8b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376800225-172.17.0.11-1597525517587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43946,DS-9ce21237-66bc-4f05-b3d7-d63bee80bca5,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-7cd03d29-41f9-42b3-b2a3-1ac815d38275,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-a3d5b628-7574-4811-aaa6-f3a04a5aacb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-8a8ae79c-b701-4703-90fd-b2bf21f5ee7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-a28a3427-6b5f-4d6d-9e64-b5f7a5f8ad49,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-7be1d3bb-740e-48c4-b1ee-bc5e0a8de1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-7fcefe2d-5496-4488-8a09-23aeb390d30c,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-0729b02d-f89e-450d-857a-a94e6e2d22e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376800225-172.17.0.11-1597525517587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43946,DS-9ce21237-66bc-4f05-b3d7-d63bee80bca5,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-7cd03d29-41f9-42b3-b2a3-1ac815d38275,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-a3d5b628-7574-4811-aaa6-f3a04a5aacb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-8a8ae79c-b701-4703-90fd-b2bf21f5ee7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-a28a3427-6b5f-4d6d-9e64-b5f7a5f8ad49,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-7be1d3bb-740e-48c4-b1ee-bc5e0a8de1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-7fcefe2d-5496-4488-8a09-23aeb390d30c,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-0729b02d-f89e-450d-857a-a94e6e2d22e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-735308315-172.17.0.11-1597525657720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35071,DS-9c367aa7-52a8-4158-9da7-e047a848aa0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-69e95bf1-4a30-4c3a-874d-d7f4c4d7f25d,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-e8f8c712-a7aa-401d-9b03-204f1fd6dbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-9cd21f33-9044-4467-bb0b-45b3fdf66e82,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-c6251270-8c5d-4c1f-b7ff-211feadf7722,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-0e465f1d-ff6f-476b-881f-a8c283254b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-e721292e-a6cd-42cc-8ee6-b28254b37ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-ba01fb87-00a1-4e89-a512-98a3371711b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-735308315-172.17.0.11-1597525657720:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35071,DS-9c367aa7-52a8-4158-9da7-e047a848aa0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43837,DS-69e95bf1-4a30-4c3a-874d-d7f4c4d7f25d,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-e8f8c712-a7aa-401d-9b03-204f1fd6dbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36935,DS-9cd21f33-9044-4467-bb0b-45b3fdf66e82,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-c6251270-8c5d-4c1f-b7ff-211feadf7722,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-0e465f1d-ff6f-476b-881f-a8c283254b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-e721292e-a6cd-42cc-8ee6-b28254b37ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-ba01fb87-00a1-4e89-a512-98a3371711b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1343597036-172.17.0.11-1597526347868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39437,DS-387689a4-2609-4e54-a15f-b64b47183d54,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-29063a8c-94ee-4e59-b6f1-5ae91ab36467,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-c02a7cc5-b153-40e3-87e8-d927171cc052,DISK], DatanodeInfoWithStorage[127.0.0.1:41627,DS-5d41a85f-05b8-424a-a412-3176789ff4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-8dfcd4e3-72a9-4ca8-ac06-0376dc2270f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-ba4433f0-66c1-4565-ba1d-26455576db8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-d70113e8-af1a-4bb0-b1ba-48eca333a63e,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-4afe854f-1999-47e3-a56c-d355a9568e81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1343597036-172.17.0.11-1597526347868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39437,DS-387689a4-2609-4e54-a15f-b64b47183d54,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-29063a8c-94ee-4e59-b6f1-5ae91ab36467,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-c02a7cc5-b153-40e3-87e8-d927171cc052,DISK], DatanodeInfoWithStorage[127.0.0.1:41627,DS-5d41a85f-05b8-424a-a412-3176789ff4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-8dfcd4e3-72a9-4ca8-ac06-0376dc2270f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-ba4433f0-66c1-4565-ba1d-26455576db8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-d70113e8-af1a-4bb0-b1ba-48eca333a63e,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-4afe854f-1999-47e3-a56c-d355a9568e81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1759601469-172.17.0.11-1597527194267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41997,DS-726f7f9b-a82b-479d-908b-50721fc6456b,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-a4106646-7ed1-47a0-b220-5a67ad2a5abc,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-bef6bac6-3556-40fd-b3f3-545f47fe0205,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-052bd94c-d2cb-4444-be2d-76b2ffc17543,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-ed0afb5e-d27e-42c8-90b5-1d938df074e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-38649753-b1bb-42e8-8473-17259185caa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-10909bc8-fb43-4ab6-aea6-aca2faa3f392,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-0a05c5f4-d6e1-46e7-a1ed-618176629d13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1759601469-172.17.0.11-1597527194267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41997,DS-726f7f9b-a82b-479d-908b-50721fc6456b,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-a4106646-7ed1-47a0-b220-5a67ad2a5abc,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-bef6bac6-3556-40fd-b3f3-545f47fe0205,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-052bd94c-d2cb-4444-be2d-76b2ffc17543,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-ed0afb5e-d27e-42c8-90b5-1d938df074e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40188,DS-38649753-b1bb-42e8-8473-17259185caa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-10909bc8-fb43-4ab6-aea6-aca2faa3f392,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-0a05c5f4-d6e1-46e7-a1ed-618176629d13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-299613141-172.17.0.11-1597527521537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34734,DS-989bb3b0-77a1-4eb5-85f7-53a0de823a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-d681cb53-e945-4b09-9249-9366e0f646f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-324c4db6-f781-4f50-afde-828878bae0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-31b5d8f7-e537-4382-86ea-d3d824bf9568,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-af360807-afac-4700-93d3-576ebc412d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-9de66f32-3062-47e2-9e97-6fea1150d941,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-9dfefea7-123a-40a2-bbdb-7ee9577f3681,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-257852d3-3e21-4a84-88d0-6b7dead0e476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-299613141-172.17.0.11-1597527521537:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34734,DS-989bb3b0-77a1-4eb5-85f7-53a0de823a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:36712,DS-d681cb53-e945-4b09-9249-9366e0f646f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40654,DS-324c4db6-f781-4f50-afde-828878bae0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-31b5d8f7-e537-4382-86ea-d3d824bf9568,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-af360807-afac-4700-93d3-576ebc412d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-9de66f32-3062-47e2-9e97-6fea1150d941,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-9dfefea7-123a-40a2-bbdb-7ee9577f3681,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-257852d3-3e21-4a84-88d0-6b7dead0e476,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1115929843-172.17.0.11-1597527858613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33240,DS-7761cb10-ecde-44bd-8977-2e54e0538272,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-8e6c9239-913e-4130-9aad-ce4280f30280,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-a579b48b-6272-4712-8303-94658cf664a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-7951f1d5-02a4-464b-aa52-d62b58829f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-63dbd299-bc6f-41d3-a5ad-4bc15f5de5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-ea521e60-72fe-499e-a71f-411f2d6b9d32,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-315b0181-dc8d-4039-800e-1d2d977aec3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-c7381620-98f0-46db-84ed-6e495a7aa9b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1115929843-172.17.0.11-1597527858613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33240,DS-7761cb10-ecde-44bd-8977-2e54e0538272,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-8e6c9239-913e-4130-9aad-ce4280f30280,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-a579b48b-6272-4712-8303-94658cf664a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-7951f1d5-02a4-464b-aa52-d62b58829f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-63dbd299-bc6f-41d3-a5ad-4bc15f5de5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-ea521e60-72fe-499e-a71f-411f2d6b9d32,DISK], DatanodeInfoWithStorage[127.0.0.1:43665,DS-315b0181-dc8d-4039-800e-1d2d977aec3d,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-c7381620-98f0-46db-84ed-6e495a7aa9b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688898376-172.17.0.11-1597527987699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41903,DS-890a3a14-7e8f-4602-b939-0cda5eaa20d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-aab03034-94c6-468d-8b6f-ad61fd87e098,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-b5a7b8a4-1374-4b42-b8d8-9370a2b23fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-218293d0-4656-4f14-824d-e48319825ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-3d241125-a4e7-4996-8887-22414aeefd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-a7c49b3e-b314-4a62-a0f2-ba6d42b03745,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-8c597342-d15a-4565-be5e-c06d41b13aef,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-f27459b4-de2c-4109-9a81-7af304cb1c4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688898376-172.17.0.11-1597527987699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41903,DS-890a3a14-7e8f-4602-b939-0cda5eaa20d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-aab03034-94c6-468d-8b6f-ad61fd87e098,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-b5a7b8a4-1374-4b42-b8d8-9370a2b23fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43774,DS-218293d0-4656-4f14-824d-e48319825ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-3d241125-a4e7-4996-8887-22414aeefd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-a7c49b3e-b314-4a62-a0f2-ba6d42b03745,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-8c597342-d15a-4565-be5e-c06d41b13aef,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-f27459b4-de2c-4109-9a81-7af304cb1c4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1181274804-172.17.0.11-1597528509029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40571,DS-a1996b75-998d-44bc-9c11-c9b556aee14a,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-f4ec2358-ecdd-42f2-a72a-8e7758a0d1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-72e4a52b-804a-42f0-abb1-8da114f0675d,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-66184548-4b37-40e8-8815-a8e4e2de3960,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-7a2e0ee5-477e-4330-b1c7-7f28113e5a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-1c05794f-4cb7-476e-a211-3d7efc455762,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-d4ba8c3c-7122-4e1e-88b0-ac4ccf67b598,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-6588dc54-e8fa-4709-a05c-5661415dc796,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1181274804-172.17.0.11-1597528509029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40571,DS-a1996b75-998d-44bc-9c11-c9b556aee14a,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-f4ec2358-ecdd-42f2-a72a-8e7758a0d1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-72e4a52b-804a-42f0-abb1-8da114f0675d,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-66184548-4b37-40e8-8815-a8e4e2de3960,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-7a2e0ee5-477e-4330-b1c7-7f28113e5a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-1c05794f-4cb7-476e-a211-3d7efc455762,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-d4ba8c3c-7122-4e1e-88b0-ac4ccf67b598,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-6588dc54-e8fa-4709-a05c-5661415dc796,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1261631896-172.17.0.11-1597528691142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34770,DS-e86d4cc5-58fe-4a91-ba80-37958fc325c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-9a027a45-dc57-478d-b2bd-ce546e3c96fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-beeaa68a-4e66-4c8e-b689-671133c4b9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-53ca2c73-c8cb-4b01-ab95-5944244e5084,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-68a900b7-bd49-4ea8-9f13-4554d3286062,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-80cdcd7a-d3d8-46af-8f79-359b55a5cc80,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-5193c803-9515-43a4-bd04-b328ecf56000,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-4a7ab4c4-8038-4544-bb42-ba62b6220d4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1261631896-172.17.0.11-1597528691142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34770,DS-e86d4cc5-58fe-4a91-ba80-37958fc325c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-9a027a45-dc57-478d-b2bd-ce546e3c96fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-beeaa68a-4e66-4c8e-b689-671133c4b9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-53ca2c73-c8cb-4b01-ab95-5944244e5084,DISK], DatanodeInfoWithStorage[127.0.0.1:35262,DS-68a900b7-bd49-4ea8-9f13-4554d3286062,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-80cdcd7a-d3d8-46af-8f79-359b55a5cc80,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-5193c803-9515-43a4-bd04-b328ecf56000,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-4a7ab4c4-8038-4544-bb42-ba62b6220d4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-865690773-172.17.0.11-1597529121364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33178,DS-164a16a4-1edf-47a4-815e-100b6ce48f22,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-6353c287-596e-4f08-ae99-6614ff7201b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-b1cdea29-9e77-4943-bb51-ce60209e27e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-f09c75ae-5c30-4a25-b5cc-5ff33e433f10,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-5dd094cc-772a-4b9b-8c94-fdfc21b34ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-c0a4705b-d90b-4d8a-aaab-4a897b752522,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-071de87a-4f5d-4301-81be-6410bb79df10,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-2f4cf3c3-7cdb-450a-a27c-2fa67fe5578c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-865690773-172.17.0.11-1597529121364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33178,DS-164a16a4-1edf-47a4-815e-100b6ce48f22,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-6353c287-596e-4f08-ae99-6614ff7201b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-b1cdea29-9e77-4943-bb51-ce60209e27e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-f09c75ae-5c30-4a25-b5cc-5ff33e433f10,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-5dd094cc-772a-4b9b-8c94-fdfc21b34ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-c0a4705b-d90b-4d8a-aaab-4a897b752522,DISK], DatanodeInfoWithStorage[127.0.0.1:36047,DS-071de87a-4f5d-4301-81be-6410bb79df10,DISK], DatanodeInfoWithStorage[127.0.0.1:45257,DS-2f4cf3c3-7cdb-450a-a27c-2fa67fe5578c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1738206736-172.17.0.11-1597529161483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35303,DS-4f42dcf6-7afa-4171-9e9a-613b38c8b3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-13bc6209-f3f1-4f07-8ef7-4a5cd6f5d379,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-3418ef13-5e39-4906-b973-e400179b9102,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-69bcfa7f-71d7-4dec-98d7-0964fb72208e,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-c52030eb-9207-4d23-970e-c4ec8478d65f,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-d69728b3-66f7-42cb-a2b2-70c49ed09631,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-664f0faa-b8c4-4e13-9794-00d95f27fdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-69c48ce1-9431-447c-889c-699e177d3ff2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1738206736-172.17.0.11-1597529161483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35303,DS-4f42dcf6-7afa-4171-9e9a-613b38c8b3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-13bc6209-f3f1-4f07-8ef7-4a5cd6f5d379,DISK], DatanodeInfoWithStorage[127.0.0.1:38117,DS-3418ef13-5e39-4906-b973-e400179b9102,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-69bcfa7f-71d7-4dec-98d7-0964fb72208e,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-c52030eb-9207-4d23-970e-c4ec8478d65f,DISK], DatanodeInfoWithStorage[127.0.0.1:37725,DS-d69728b3-66f7-42cb-a2b2-70c49ed09631,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-664f0faa-b8c4-4e13-9794-00d95f27fdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37978,DS-69c48ce1-9431-447c-889c-699e177d3ff2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-715707448-172.17.0.11-1597529464103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45337,DS-6de6bf0a-ddf0-4db3-a1d1-16256e0d2183,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-27905af2-5cd9-4c6f-9d2d-0fe81776e5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-6a6c1c94-6165-43c0-937d-ab59176f0b81,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-76792bec-bd96-40ee-b5d6-506b880037e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-7f306a35-f429-4514-b11e-7adf246f6a57,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-bf4e7c47-fb30-4636-93cf-ce8d6474816f,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-b029fbe5-a3eb-42fc-8bfb-aab4b5eb1d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-1864f4df-e79c-478f-b733-abbb4f0afa8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-715707448-172.17.0.11-1597529464103:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45337,DS-6de6bf0a-ddf0-4db3-a1d1-16256e0d2183,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-27905af2-5cd9-4c6f-9d2d-0fe81776e5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-6a6c1c94-6165-43c0-937d-ab59176f0b81,DISK], DatanodeInfoWithStorage[127.0.0.1:45857,DS-76792bec-bd96-40ee-b5d6-506b880037e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-7f306a35-f429-4514-b11e-7adf246f6a57,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-bf4e7c47-fb30-4636-93cf-ce8d6474816f,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-b029fbe5-a3eb-42fc-8bfb-aab4b5eb1d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-1864f4df-e79c-478f-b733-abbb4f0afa8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-575286080-172.17.0.11-1597529516312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38745,DS-293611c4-5ed6-45db-b0ea-c4ea756047a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-c9c5cc24-574e-424e-a14f-1ed245a5fb73,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-a529ed98-6c4d-4974-9ab9-32c5a8bbaade,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-817d3a75-6ea9-4ddf-8e51-d6034611ce2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-0edd6d76-40b8-4c20-be66-287180b81baf,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-0ff76f89-31d2-4a6b-bf79-0608a02baf95,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-12d1fd1e-af75-46a8-82f9-9a1440b16207,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-7aea2e07-95f6-4aa7-a977-36cacfc60f41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-575286080-172.17.0.11-1597529516312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38745,DS-293611c4-5ed6-45db-b0ea-c4ea756047a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-c9c5cc24-574e-424e-a14f-1ed245a5fb73,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-a529ed98-6c4d-4974-9ab9-32c5a8bbaade,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-817d3a75-6ea9-4ddf-8e51-d6034611ce2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-0edd6d76-40b8-4c20-be66-287180b81baf,DISK], DatanodeInfoWithStorage[127.0.0.1:45345,DS-0ff76f89-31d2-4a6b-bf79-0608a02baf95,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-12d1fd1e-af75-46a8-82f9-9a1440b16207,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-7aea2e07-95f6-4aa7-a977-36cacfc60f41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-24487478-172.17.0.11-1597529693875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40691,DS-80f30014-4688-4f37-82ba-e14407aa7c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-7aa92e65-fb20-4a2c-8a89-582ffe2b21b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-0c106209-9f0f-4b2f-b6d3-2bfd55c72021,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-157a4719-6b45-4f12-ae01-958567b0d446,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-5f23b4f8-0f22-429f-8cce-ac3d7ad92b48,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-87a384d4-2bb0-4f44-87ee-fdcdcc5af1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-934cafab-a389-4924-85f0-7ff185eed342,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-7a2d2aaa-6f10-4120-9e96-5ddbc3c130f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-24487478-172.17.0.11-1597529693875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40691,DS-80f30014-4688-4f37-82ba-e14407aa7c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-7aa92e65-fb20-4a2c-8a89-582ffe2b21b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-0c106209-9f0f-4b2f-b6d3-2bfd55c72021,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-157a4719-6b45-4f12-ae01-958567b0d446,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-5f23b4f8-0f22-429f-8cce-ac3d7ad92b48,DISK], DatanodeInfoWithStorage[127.0.0.1:39964,DS-87a384d4-2bb0-4f44-87ee-fdcdcc5af1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36420,DS-934cafab-a389-4924-85f0-7ff185eed342,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-7a2d2aaa-6f10-4120-9e96-5ddbc3c130f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132743135-172.17.0.11-1597529735169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44933,DS-1f01004f-87dd-42ab-aecc-f1fadab9867a,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-aa964de2-e1dc-41db-aa5b-3cbd156fc447,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-65c85391-293b-4a99-98e6-cc063bce69b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-ba448a87-baf0-4e13-a4ab-3aebd3161c71,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-715ec580-2f75-4c63-bbfd-22c49457eca0,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-3ef70dae-b341-40f7-8ac4-dcc6336a2d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-42da3d65-0433-4b3f-bea1-d5da4896de27,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-bee76e82-93b2-49f4-9de6-700e3832aaa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132743135-172.17.0.11-1597529735169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44933,DS-1f01004f-87dd-42ab-aecc-f1fadab9867a,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-aa964de2-e1dc-41db-aa5b-3cbd156fc447,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-65c85391-293b-4a99-98e6-cc063bce69b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-ba448a87-baf0-4e13-a4ab-3aebd3161c71,DISK], DatanodeInfoWithStorage[127.0.0.1:39753,DS-715ec580-2f75-4c63-bbfd-22c49457eca0,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-3ef70dae-b341-40f7-8ac4-dcc6336a2d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-42da3d65-0433-4b3f-bea1-d5da4896de27,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-bee76e82-93b2-49f4-9de6-700e3832aaa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1063989005-172.17.0.11-1597530018164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41758,DS-0e7317d9-8630-47c3-8a7c-c4f500578b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-854c7765-675b-4b22-9cc6-2173f045dfab,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-da39080c-eef6-4043-82c8-85ba48775bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-f4305ec9-01d7-4f8b-ae18-af2ca39ab3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-de3b0ed4-a52a-4c98-9d64-efa5593cf88e,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-cf7cfe6c-4d7b-4886-95c1-11d6f54ade09,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-d49aea92-97ea-4ad8-9416-b29005b958ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-17dbb2b4-5711-4bfb-9482-502738a1e505,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1063989005-172.17.0.11-1597530018164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41758,DS-0e7317d9-8630-47c3-8a7c-c4f500578b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-854c7765-675b-4b22-9cc6-2173f045dfab,DISK], DatanodeInfoWithStorage[127.0.0.1:39756,DS-da39080c-eef6-4043-82c8-85ba48775bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-f4305ec9-01d7-4f8b-ae18-af2ca39ab3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-de3b0ed4-a52a-4c98-9d64-efa5593cf88e,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-cf7cfe6c-4d7b-4886-95c1-11d6f54ade09,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-d49aea92-97ea-4ad8-9416-b29005b958ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-17dbb2b4-5711-4bfb-9482-502738a1e505,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040156066-172.17.0.11-1597531440084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37871,DS-b4677b93-2154-4d09-9a65-8b57ef38b340,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-a3f1ef46-aa86-4877-8dc9-bd0df72892fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-4c24b8bd-76aa-4d81-9105-cfc5645eea7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-8dbabb6d-c2da-44f8-b4fd-f7952df05c44,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-d80fb609-9013-4161-bbb0-e161ef0d2dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-44d2dfaf-065b-47a0-aabf-33f2dac99381,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-75ef4c75-d978-414d-9cf5-e76b4753b148,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-e3909d01-1d6a-408d-a8fe-bd3e71345072,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040156066-172.17.0.11-1597531440084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37871,DS-b4677b93-2154-4d09-9a65-8b57ef38b340,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-a3f1ef46-aa86-4877-8dc9-bd0df72892fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-4c24b8bd-76aa-4d81-9105-cfc5645eea7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-8dbabb6d-c2da-44f8-b4fd-f7952df05c44,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-d80fb609-9013-4161-bbb0-e161ef0d2dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-44d2dfaf-065b-47a0-aabf-33f2dac99381,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-75ef4c75-d978-414d-9cf5-e76b4753b148,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-e3909d01-1d6a-408d-a8fe-bd3e71345072,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.interval.seconds
component: hdfs:NameNode
v1: 300s
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1036420952-172.17.0.11-1597531487890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46004,DS-ae7ccd2f-6063-4033-a8ab-886251d384ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-2e654582-9214-4934-ad78-e04198ee9ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-19b93961-6a0c-476b-9290-06eee3ce97b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-3e056af7-e08d-4adf-b0f0-44ef700b95fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-62da9e1d-b143-4410-a390-1d38c7baf145,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-f39140a2-69d8-4e99-90c6-0a887b041a37,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-147c7a45-d7ce-4f2e-b3cf-fbecb499372a,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-b105d8e7-7d3c-4f8d-a42d-a12799b51893,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1036420952-172.17.0.11-1597531487890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46004,DS-ae7ccd2f-6063-4033-a8ab-886251d384ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-2e654582-9214-4934-ad78-e04198ee9ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-19b93961-6a0c-476b-9290-06eee3ce97b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-3e056af7-e08d-4adf-b0f0-44ef700b95fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-62da9e1d-b143-4410-a390-1d38c7baf145,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-f39140a2-69d8-4e99-90c6-0a887b041a37,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-147c7a45-d7ce-4f2e-b3cf-fbecb499372a,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-b105d8e7-7d3c-4f8d-a42d-a12799b51893,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 6832
