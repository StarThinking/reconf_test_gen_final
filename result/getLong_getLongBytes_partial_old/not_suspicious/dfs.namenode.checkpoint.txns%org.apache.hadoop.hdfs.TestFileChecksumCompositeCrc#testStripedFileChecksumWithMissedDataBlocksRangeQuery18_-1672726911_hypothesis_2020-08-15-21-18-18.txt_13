reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-798778436-172.17.0.16-1597526346260:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40232,DS-2ca7aa7e-3af8-4e43-aa1f-26a167e18e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-b015a0e6-5323-419c-8760-82a53e4244eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-6df272da-c517-4801-92b0-1bc6bd3c64bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-9de2ac3f-465e-4f9d-bfd8-bb920cbeb5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-75413958-6637-4c69-8299-6bef94d62db5,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-f4c22f6b-2222-4e7b-a7da-d06ecad2a562,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-bde3023e-3749-40e8-96bd-b85733f6c55f,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-85a7fbf3-8d5b-48b1-8957-02e873942176,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-798778436-172.17.0.16-1597526346260:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40232,DS-2ca7aa7e-3af8-4e43-aa1f-26a167e18e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-b015a0e6-5323-419c-8760-82a53e4244eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-6df272da-c517-4801-92b0-1bc6bd3c64bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-9de2ac3f-465e-4f9d-bfd8-bb920cbeb5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-75413958-6637-4c69-8299-6bef94d62db5,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-f4c22f6b-2222-4e7b-a7da-d06ecad2a562,DISK], DatanodeInfoWithStorage[127.0.0.1:35783,DS-bde3023e-3749-40e8-96bd-b85733f6c55f,DISK], DatanodeInfoWithStorage[127.0.0.1:34392,DS-85a7fbf3-8d5b-48b1-8957-02e873942176,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2109709074-172.17.0.16-1597526646476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34656,DS-7b73fc8a-727b-41e1-aedb-c75249bdb0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-d4148943-76e9-4d03-89d3-912351b366c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-f1623e57-433f-4ecf-b644-f23006de10af,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-b1e49b2c-7bfb-402a-a3e5-9dadfb7e834e,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-e1942182-0c34-41a9-8ae2-f43b9ca8775f,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-9405ab68-cc82-4c04-8091-92a6552a327e,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-5ffbe895-b5d3-4529-ab23-b963f9921566,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-6bc6e7e9-89fb-4be2-8756-b2c22c0d5884,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2109709074-172.17.0.16-1597526646476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34656,DS-7b73fc8a-727b-41e1-aedb-c75249bdb0d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39667,DS-d4148943-76e9-4d03-89d3-912351b366c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36286,DS-f1623e57-433f-4ecf-b644-f23006de10af,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-b1e49b2c-7bfb-402a-a3e5-9dadfb7e834e,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-e1942182-0c34-41a9-8ae2-f43b9ca8775f,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-9405ab68-cc82-4c04-8091-92a6552a327e,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-5ffbe895-b5d3-4529-ab23-b963f9921566,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-6bc6e7e9-89fb-4be2-8756-b2c22c0d5884,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1966477360-172.17.0.16-1597527073047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40103,DS-5f9c05a4-d657-4867-9fc5-bd628908a111,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-c3c27ff2-682a-4f26-8aee-71535334b311,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-95f54d68-d5ef-4706-a0c4-64d149166691,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-3a4330c4-042a-4e00-8010-c32021ecccb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-61d7dc20-7bb6-4640-a97d-a1465cc0fad2,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-4591e03b-ebec-41ef-b780-20290be44b69,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-1750d31a-e520-4c48-8e50-048aee81dff5,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-c221c08f-4a40-4222-8545-38d8a0953e8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1966477360-172.17.0.16-1597527073047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40103,DS-5f9c05a4-d657-4867-9fc5-bd628908a111,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-c3c27ff2-682a-4f26-8aee-71535334b311,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-95f54d68-d5ef-4706-a0c4-64d149166691,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-3a4330c4-042a-4e00-8010-c32021ecccb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-61d7dc20-7bb6-4640-a97d-a1465cc0fad2,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-4591e03b-ebec-41ef-b780-20290be44b69,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-1750d31a-e520-4c48-8e50-048aee81dff5,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-c221c08f-4a40-4222-8545-38d8a0953e8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-963138630-172.17.0.16-1597527306310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44814,DS-c34f2f1c-95c4-4d40-a931-f10d540c3ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:41958,DS-89dc9461-0b76-4c64-8ad0-8536ca276ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-1717e586-68c3-49a2-a906-1cb9ae7641aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-680d6d88-c16c-4c8a-b5e3-dd6e0a9fdb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-41a06ded-34fe-4ed3-85e5-728dd58be4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41012,DS-f5b33d7d-4d5b-49ed-be70-e6aaa08c84d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-b4a4af40-1bb8-45bc-b510-3c6bd479ecc6,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-d72fa7d7-564f-42ed-aa82-695c58b1161a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-963138630-172.17.0.16-1597527306310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44814,DS-c34f2f1c-95c4-4d40-a931-f10d540c3ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:41958,DS-89dc9461-0b76-4c64-8ad0-8536ca276ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-1717e586-68c3-49a2-a906-1cb9ae7641aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33713,DS-680d6d88-c16c-4c8a-b5e3-dd6e0a9fdb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42680,DS-41a06ded-34fe-4ed3-85e5-728dd58be4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41012,DS-f5b33d7d-4d5b-49ed-be70-e6aaa08c84d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46515,DS-b4a4af40-1bb8-45bc-b510-3c6bd479ecc6,DISK], DatanodeInfoWithStorage[127.0.0.1:32935,DS-d72fa7d7-564f-42ed-aa82-695c58b1161a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1537900579-172.17.0.16-1597527415457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36284,DS-e5fcce70-60ce-4098-9e6d-e5e00ce24179,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-4df2f65f-4f67-4f42-aeba-7af5552ba355,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-9b913f30-60fb-40f1-9397-bdb9213a5de0,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-44e3ebfb-6940-4b4a-8c81-8ce060e9ea03,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-2f7f7852-1cce-4cb8-9b2f-75c1364dac02,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-efab4e0d-c4b1-43a7-804d-5c44afb82570,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-81ae2032-d5ae-477b-b5b1-d8a8e9d18823,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-85059603-bd50-4432-a35e-5ab10f92c70c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1537900579-172.17.0.16-1597527415457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36284,DS-e5fcce70-60ce-4098-9e6d-e5e00ce24179,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-4df2f65f-4f67-4f42-aeba-7af5552ba355,DISK], DatanodeInfoWithStorage[127.0.0.1:41742,DS-9b913f30-60fb-40f1-9397-bdb9213a5de0,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-44e3ebfb-6940-4b4a-8c81-8ce060e9ea03,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-2f7f7852-1cce-4cb8-9b2f-75c1364dac02,DISK], DatanodeInfoWithStorage[127.0.0.1:40166,DS-efab4e0d-c4b1-43a7-804d-5c44afb82570,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-81ae2032-d5ae-477b-b5b1-d8a8e9d18823,DISK], DatanodeInfoWithStorage[127.0.0.1:39613,DS-85059603-bd50-4432-a35e-5ab10f92c70c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-274068047-172.17.0.16-1597527723169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42613,DS-6322577c-14bf-4109-8c1a-78b1ebd55d78,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-a8a5b12f-368c-4dcd-a077-fe5fc12f97b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-6475f1f2-7ae1-4f2c-a2db-02c6720921b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-e019bfc2-4541-420f-bb56-efc4fcc9f338,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-9a72d499-8723-40e8-8111-ef9ce69f1a87,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-d9339af8-9652-4844-8110-414eec202396,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-d815be5d-cc52-4443-9499-6c32351c98a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39694,DS-ba1d9f51-c88d-4c53-af3b-7c54ff07c07d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-274068047-172.17.0.16-1597527723169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42613,DS-6322577c-14bf-4109-8c1a-78b1ebd55d78,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-a8a5b12f-368c-4dcd-a077-fe5fc12f97b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-6475f1f2-7ae1-4f2c-a2db-02c6720921b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35568,DS-e019bfc2-4541-420f-bb56-efc4fcc9f338,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-9a72d499-8723-40e8-8111-ef9ce69f1a87,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-d9339af8-9652-4844-8110-414eec202396,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-d815be5d-cc52-4443-9499-6c32351c98a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39694,DS-ba1d9f51-c88d-4c53-af3b-7c54ff07c07d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1446611604-172.17.0.16-1597527879362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43678,DS-b290632a-fd0e-429a-ad6a-0c281ee75946,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-75495805-9a0b-46f2-927e-8fe73c6e45c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-e15ee9ac-ed9c-4cab-8a10-9af51e1d55df,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-def8c570-f983-4b57-b16e-6362b7c74730,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-25a6a1a0-a9b8-494c-aba0-822adb4945bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-0d4fccaa-1711-4d36-a706-4278472fa419,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-019e78cf-3aef-4dfc-b890-87732bf75095,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-a3093b95-5abc-4b43-bedb-cbfd6ec29ff2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1446611604-172.17.0.16-1597527879362:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43678,DS-b290632a-fd0e-429a-ad6a-0c281ee75946,DISK], DatanodeInfoWithStorage[127.0.0.1:45662,DS-75495805-9a0b-46f2-927e-8fe73c6e45c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-e15ee9ac-ed9c-4cab-8a10-9af51e1d55df,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-def8c570-f983-4b57-b16e-6362b7c74730,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-25a6a1a0-a9b8-494c-aba0-822adb4945bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36228,DS-0d4fccaa-1711-4d36-a706-4278472fa419,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-019e78cf-3aef-4dfc-b890-87732bf75095,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-a3093b95-5abc-4b43-bedb-cbfd6ec29ff2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1264105457-172.17.0.16-1597528496169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46145,DS-73001642-57e3-4775-bc8a-752e40a943ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-8500a0d1-40d6-46dd-97b0-8053148dde7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-579df1a0-4b88-499c-9819-4bd34f849840,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-1b7f7826-7245-4bcd-8117-4fbfbdf7df4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-fa7da03d-81c8-452e-b8c9-72359b217908,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-fc9e83a8-fc7a-4980-aff4-e7cfeb2cbcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-235d46e0-5883-40e0-b551-2575befa494f,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-222c1cc8-d5af-4980-977d-c1668627f8c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1264105457-172.17.0.16-1597528496169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46145,DS-73001642-57e3-4775-bc8a-752e40a943ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-8500a0d1-40d6-46dd-97b0-8053148dde7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-579df1a0-4b88-499c-9819-4bd34f849840,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-1b7f7826-7245-4bcd-8117-4fbfbdf7df4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-fa7da03d-81c8-452e-b8c9-72359b217908,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-fc9e83a8-fc7a-4980-aff4-e7cfeb2cbcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-235d46e0-5883-40e0-b551-2575befa494f,DISK], DatanodeInfoWithStorage[127.0.0.1:35560,DS-222c1cc8-d5af-4980-977d-c1668627f8c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-977819706-172.17.0.16-1597528533989:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40834,DS-f6a70aba-a447-4aae-951e-038ad5755d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-81881166-ed77-4b21-acd1-1eae8e231b26,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-f72509e2-913b-4ee8-b40c-c6c7723aab95,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-3cc0d554-08c5-46c3-992d-2f4c170d9837,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-27eca4bf-47a1-4aca-ab94-6c7871e83843,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-d6ac8f2d-0be1-4bfd-8c67-25e65530c355,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-6deeeda4-0bb0-4474-9214-a0bcdd637b14,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-dc496b7e-1d4a-4f08-996e-eb7174cae0c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-977819706-172.17.0.16-1597528533989:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40834,DS-f6a70aba-a447-4aae-951e-038ad5755d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-81881166-ed77-4b21-acd1-1eae8e231b26,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-f72509e2-913b-4ee8-b40c-c6c7723aab95,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-3cc0d554-08c5-46c3-992d-2f4c170d9837,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-27eca4bf-47a1-4aca-ab94-6c7871e83843,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-d6ac8f2d-0be1-4bfd-8c67-25e65530c355,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-6deeeda4-0bb0-4474-9214-a0bcdd637b14,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-dc496b7e-1d4a-4f08-996e-eb7174cae0c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1173548105-172.17.0.16-1597528605065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45676,DS-4638dd3c-f5c2-4b44-b6be-273dcd684df8,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-56661178-f83d-4e4a-b89b-e719d0840a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-9ca80dc1-1f40-41e5-9300-e6ab792dabd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-0e689a1b-843b-4801-9401-86ce4ffeb274,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-f22f63bf-3d4d-457f-b1ac-bf173e0f6450,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-7ccaac67-cfe3-47f1-99fa-63897b2d68b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-3694b72c-1572-44cd-b0e4-7b6648f10b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-1dd8d11b-968c-4d52-9281-e14d35552e24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1173548105-172.17.0.16-1597528605065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45676,DS-4638dd3c-f5c2-4b44-b6be-273dcd684df8,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-56661178-f83d-4e4a-b89b-e719d0840a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-9ca80dc1-1f40-41e5-9300-e6ab792dabd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-0e689a1b-843b-4801-9401-86ce4ffeb274,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-f22f63bf-3d4d-457f-b1ac-bf173e0f6450,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-7ccaac67-cfe3-47f1-99fa-63897b2d68b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-3694b72c-1572-44cd-b0e4-7b6648f10b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-1dd8d11b-968c-4d52-9281-e14d35552e24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-724357238-172.17.0.16-1597529670954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44359,DS-77c876a8-5e1d-4699-870f-3554b3c00d65,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-2fd892e5-a868-4d04-a08b-76f7af88495b,DISK], DatanodeInfoWithStorage[127.0.0.1:40851,DS-36a30439-929d-4b32-ac6f-32552de0c11b,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-121f81a1-8daf-468a-a80f-fa0ccbabddbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-3f28535b-876e-4f05-ab69-99a8af0cdfd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-1a93d4f3-3504-4838-bee7-fb37f72e4ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-3746def6-b2db-4f08-aeb2-3df431725739,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-ef80d1fd-0e04-4ae4-a1a3-b0271eade9b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-724357238-172.17.0.16-1597529670954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44359,DS-77c876a8-5e1d-4699-870f-3554b3c00d65,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-2fd892e5-a868-4d04-a08b-76f7af88495b,DISK], DatanodeInfoWithStorage[127.0.0.1:40851,DS-36a30439-929d-4b32-ac6f-32552de0c11b,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-121f81a1-8daf-468a-a80f-fa0ccbabddbc,DISK], DatanodeInfoWithStorage[127.0.0.1:44542,DS-3f28535b-876e-4f05-ab69-99a8af0cdfd2,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-1a93d4f3-3504-4838-bee7-fb37f72e4ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-3746def6-b2db-4f08-aeb2-3df431725739,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-ef80d1fd-0e04-4ae4-a1a3-b0271eade9b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1598298634-172.17.0.16-1597530578205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33233,DS-0d38d7e3-f716-48ce-88f3-85e9da3e9b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-69a3c207-c094-40b4-92f5-688290927987,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-2d53908e-fb3a-4d08-8621-e00c442820b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-f1dd8474-c961-4ffa-a842-07d96de247bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-075d0551-26ee-4ff2-aae0-7d7c935be7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-9a5ae8be-fc19-46c2-9b73-9a5cd3bd7d33,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-735d7e7d-82bc-4abd-af20-8b46621e5e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-7e843ecc-0cb2-468f-ac1c-c888d1f7fd31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1598298634-172.17.0.16-1597530578205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33233,DS-0d38d7e3-f716-48ce-88f3-85e9da3e9b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-69a3c207-c094-40b4-92f5-688290927987,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-2d53908e-fb3a-4d08-8621-e00c442820b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-f1dd8474-c961-4ffa-a842-07d96de247bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-075d0551-26ee-4ff2-aae0-7d7c935be7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-9a5ae8be-fc19-46c2-9b73-9a5cd3bd7d33,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-735d7e7d-82bc-4abd-af20-8b46621e5e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-7e843ecc-0cb2-468f-ac1c-c888d1f7fd31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1731704781-172.17.0.16-1597530613523:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43528,DS-ad545408-f980-4ec6-9f31-72b22da22200,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-1fb67116-2769-4c1b-8525-592155ee122e,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-8cf6eff6-4ecd-4c0b-ae82-c057b576b44c,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-f3752179-ef5e-4d9b-a0d4-9fbe4499cfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-5d08dd97-bf9f-46de-a809-3aab35eac554,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-19531c50-623e-48ad-bccd-79f965dc48d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37356,DS-f7c1c53e-2d6e-4702-9bbb-8bef0902078f,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-3a8f8448-1049-4683-b530-e4fb1a2c652e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1731704781-172.17.0.16-1597530613523:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43528,DS-ad545408-f980-4ec6-9f31-72b22da22200,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-1fb67116-2769-4c1b-8525-592155ee122e,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-8cf6eff6-4ecd-4c0b-ae82-c057b576b44c,DISK], DatanodeInfoWithStorage[127.0.0.1:41793,DS-f3752179-ef5e-4d9b-a0d4-9fbe4499cfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33117,DS-5d08dd97-bf9f-46de-a809-3aab35eac554,DISK], DatanodeInfoWithStorage[127.0.0.1:39004,DS-19531c50-623e-48ad-bccd-79f965dc48d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37356,DS-f7c1c53e-2d6e-4702-9bbb-8bef0902078f,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-3a8f8448-1049-4683-b530-e4fb1a2c652e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1479443274-172.17.0.16-1597530647080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42989,DS-dc66c1cb-8343-4473-8d88-6e3d8a873761,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-91d46e6f-8b2b-4869-9c25-0da8a4181d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-d5f6e8db-ea93-415b-88d4-a8d3f9ef535d,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-228f1199-0fd6-4ba5-95d2-25ee1cce2df9,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-c58240c7-2cce-46fc-b8cd-9af39c7206fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-267b3794-cf02-498c-a8c4-bb762593552a,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-f5c2379f-61e0-4ab5-87f6-87179f4a32bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-65699390-ca27-4000-8f9e-cf1a9abbb0a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1479443274-172.17.0.16-1597530647080:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42989,DS-dc66c1cb-8343-4473-8d88-6e3d8a873761,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-91d46e6f-8b2b-4869-9c25-0da8a4181d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-d5f6e8db-ea93-415b-88d4-a8d3f9ef535d,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-228f1199-0fd6-4ba5-95d2-25ee1cce2df9,DISK], DatanodeInfoWithStorage[127.0.0.1:39045,DS-c58240c7-2cce-46fc-b8cd-9af39c7206fc,DISK], DatanodeInfoWithStorage[127.0.0.1:39729,DS-267b3794-cf02-498c-a8c4-bb762593552a,DISK], DatanodeInfoWithStorage[127.0.0.1:35889,DS-f5c2379f-61e0-4ab5-87f6-87179f4a32bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-65699390-ca27-4000-8f9e-cf1a9abbb0a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-7154091-172.17.0.16-1597530755891:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37387,DS-9c8f1c9b-50cc-47f6-9dcb-2f0a0c9bcb92,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-aca9cf85-f608-4168-9662-18e6dd2c555e,DISK], DatanodeInfoWithStorage[127.0.0.1:44821,DS-94230e29-a3b1-43b0-8367-521bc9084c81,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-2912e526-3f7b-4bed-b28c-2a391d39be37,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-944388ef-3de0-4a0a-b3bb-8f6109e2ec66,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-7a310a6d-fa5b-45ca-bd2b-db58610e1318,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-9a8df82b-3a76-42ed-b0b3-9d5577136967,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-2c359649-2854-482d-8e73-21530bc60ee2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-7154091-172.17.0.16-1597530755891:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37387,DS-9c8f1c9b-50cc-47f6-9dcb-2f0a0c9bcb92,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-aca9cf85-f608-4168-9662-18e6dd2c555e,DISK], DatanodeInfoWithStorage[127.0.0.1:44821,DS-94230e29-a3b1-43b0-8367-521bc9084c81,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-2912e526-3f7b-4bed-b28c-2a391d39be37,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-944388ef-3de0-4a0a-b3bb-8f6109e2ec66,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-7a310a6d-fa5b-45ca-bd2b-db58610e1318,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-9a8df82b-3a76-42ed-b0b3-9d5577136967,DISK], DatanodeInfoWithStorage[127.0.0.1:41749,DS-2c359649-2854-482d-8e73-21530bc60ee2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006796984-172.17.0.16-1597530934850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40136,DS-c656a60e-c5be-4d87-959d-24be6bf7002e,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-b795f3c9-3753-45f1-966f-3d56ac9439b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-a07e00ee-9da5-4ea5-af82-b2e01735a298,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-672d6273-ac41-4110-bddb-0dd7deddb658,DISK], DatanodeInfoWithStorage[127.0.0.1:40882,DS-4fde3d56-fb39-4a9c-bf78-5262958aa178,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-3a6dddab-e32f-4893-b1ee-41ddd38014dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-78c6be67-9f73-4b54-8983-41a736a27e53,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-05ef4c08-c067-44a5-9298-db5cd04d47bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006796984-172.17.0.16-1597530934850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40136,DS-c656a60e-c5be-4d87-959d-24be6bf7002e,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-b795f3c9-3753-45f1-966f-3d56ac9439b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44303,DS-a07e00ee-9da5-4ea5-af82-b2e01735a298,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-672d6273-ac41-4110-bddb-0dd7deddb658,DISK], DatanodeInfoWithStorage[127.0.0.1:40882,DS-4fde3d56-fb39-4a9c-bf78-5262958aa178,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-3a6dddab-e32f-4893-b1ee-41ddd38014dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46588,DS-78c6be67-9f73-4b54-8983-41a736a27e53,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-05ef4c08-c067-44a5-9298-db5cd04d47bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1520996827-172.17.0.16-1597531087126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44306,DS-0b15035e-a5fe-4892-b7ac-e648fd4b6a01,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-1e7b9561-b8d5-48f9-83d3-6dff34298386,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-c21835f1-c9af-4809-9f5a-ee4564046c25,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-be0cbe6e-49b3-4b6d-9d27-47f0e9dc562d,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-c8d1bfb8-fdb4-468b-a20c-28fadb9464ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-fc4afa15-f9de-4513-a0f1-aff4261beb17,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-de624932-7b3a-401e-b12c-18973ae8f8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-4aa954bd-e3b8-4d26-89b8-df16576a78fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1520996827-172.17.0.16-1597531087126:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44306,DS-0b15035e-a5fe-4892-b7ac-e648fd4b6a01,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-1e7b9561-b8d5-48f9-83d3-6dff34298386,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-c21835f1-c9af-4809-9f5a-ee4564046c25,DISK], DatanodeInfoWithStorage[127.0.0.1:37523,DS-be0cbe6e-49b3-4b6d-9d27-47f0e9dc562d,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-c8d1bfb8-fdb4-468b-a20c-28fadb9464ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-fc4afa15-f9de-4513-a0f1-aff4261beb17,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-de624932-7b3a-401e-b12c-18973ae8f8a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-4aa954bd-e3b8-4d26-89b8-df16576a78fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1151812026-172.17.0.16-1597531355637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33048,DS-35eaf339-3e76-4fb9-93ce-977e944312ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-0b29f5e4-6fb7-4aa4-b147-fcc068e321de,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-a56b41da-abad-475b-8d1c-d9e13a277777,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-8d1fd22a-3708-4608-9387-db4ab7f4db1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-386abb63-9855-4d28-a81f-05f45d0d64c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-7476f7cc-3fc0-48c1-9524-4e3e96fa9deb,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-d5cba7ab-74ae-4ee7-8ad4-d979050aad65,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-a1ad3dc0-945b-4815-b243-34069a13b3a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1151812026-172.17.0.16-1597531355637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33048,DS-35eaf339-3e76-4fb9-93ce-977e944312ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-0b29f5e4-6fb7-4aa4-b147-fcc068e321de,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-a56b41da-abad-475b-8d1c-d9e13a277777,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-8d1fd22a-3708-4608-9387-db4ab7f4db1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-386abb63-9855-4d28-a81f-05f45d0d64c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-7476f7cc-3fc0-48c1-9524-4e3e96fa9deb,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-d5cba7ab-74ae-4ee7-8ad4-d979050aad65,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-a1ad3dc0-945b-4815-b243-34069a13b3a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-270170981-172.17.0.16-1597531466170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36107,DS-3fa65f72-71d4-4484-8acb-5fad9becf340,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-bdc3e93e-2408-424e-8e7e-81a4b35bfe6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-d31dab31-37dd-4a70-a9a4-f2f7f734fa16,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-4de0076f-e01e-4c46-87e3-55a59f2f8d53,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-1babe926-cbb2-465a-9f70-70f52b455198,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-845601f4-b4ec-4f2e-ae69-59318d69002e,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-b39cddee-f77b-4279-904c-293bb4d6f85b,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-c0a54366-d81c-4f48-8b53-2920fd4db87d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-270170981-172.17.0.16-1597531466170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36107,DS-3fa65f72-71d4-4484-8acb-5fad9becf340,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-bdc3e93e-2408-424e-8e7e-81a4b35bfe6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-d31dab31-37dd-4a70-a9a4-f2f7f734fa16,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-4de0076f-e01e-4c46-87e3-55a59f2f8d53,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-1babe926-cbb2-465a-9f70-70f52b455198,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-845601f4-b4ec-4f2e-ae69-59318d69002e,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-b39cddee-f77b-4279-904c-293bb4d6f85b,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-c0a54366-d81c-4f48-8b53-2920fd4db87d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1526040086-172.17.0.16-1597531533096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39641,DS-a4f6490a-9e43-4524-87a5-3e7757352382,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-1f942207-6823-4b85-89d8-f49b6603eb08,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-c305838a-0b75-49f1-a3f9-38f82da862e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-b39a03b3-9e8f-494e-b67e-ce97f1dd1544,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-48e50d2e-b046-462d-b106-dfcd8e1335c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-8f20d4d1-5e8d-47e9-a02c-fa95e0485631,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-2626a286-1160-4993-809a-59652cd7ad6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-d05e9a1c-2177-41eb-8f03-8548952775f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1526040086-172.17.0.16-1597531533096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39641,DS-a4f6490a-9e43-4524-87a5-3e7757352382,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-1f942207-6823-4b85-89d8-f49b6603eb08,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-c305838a-0b75-49f1-a3f9-38f82da862e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-b39a03b3-9e8f-494e-b67e-ce97f1dd1544,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-48e50d2e-b046-462d-b106-dfcd8e1335c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-8f20d4d1-5e8d-47e9-a02c-fa95e0485631,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-2626a286-1160-4993-809a-59652cd7ad6a,DISK], DatanodeInfoWithStorage[127.0.0.1:39899,DS-d05e9a1c-2177-41eb-8f03-8548952775f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.checkpoint.txns
component: hdfs:NameNode
v1: 1000000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-759902507-172.17.0.16-1597531564690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45494,DS-1238d2cc-cfbf-4e8d-a697-28e873ccd845,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-0fdd0d5d-eb6d-4d73-9323-1fd296067b18,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-464513e5-cf92-46ce-908c-18d39f1dca47,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-fc87c461-b97d-40ef-af1c-364be77222c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-6b0ae495-8678-4130-8bf0-19b7445a6278,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-8f6c1111-716e-4438-811e-14e6f26ec101,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-3ef8548e-79ae-4995-8ec9-7b2a19c67411,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-f054ac8e-781f-4574-9167-15bf6543b17c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-759902507-172.17.0.16-1597531564690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45494,DS-1238d2cc-cfbf-4e8d-a697-28e873ccd845,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-0fdd0d5d-eb6d-4d73-9323-1fd296067b18,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-464513e5-cf92-46ce-908c-18d39f1dca47,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-fc87c461-b97d-40ef-af1c-364be77222c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-6b0ae495-8678-4130-8bf0-19b7445a6278,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-8f6c1111-716e-4438-811e-14e6f26ec101,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-3ef8548e-79ae-4995-8ec9-7b2a19c67411,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-f054ac8e-781f-4574-9167-15bf6543b17c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5498
