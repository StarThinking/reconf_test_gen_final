reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439943539-172.17.0.7-1597308446087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40617,DS-269eac35-4b8a-4450-8196-b4ae70cfcc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-aab36ac8-8016-447b-a6d1-0dffce66aa0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-f0459339-45c4-4486-9e54-d67e72ce6218,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-116d381d-9467-431d-b317-d561ca6a8e34,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-289a1fb3-af43-4b9b-b926-0fa230d25d21,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-8447780b-ce09-4d92-b9f3-65c2bb67a10e,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-4db16019-f73a-4b20-a19c-edb6eb447423,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-942b64f9-d6cb-4b0c-a24d-e22513ed80f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439943539-172.17.0.7-1597308446087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40617,DS-269eac35-4b8a-4450-8196-b4ae70cfcc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-aab36ac8-8016-447b-a6d1-0dffce66aa0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-f0459339-45c4-4486-9e54-d67e72ce6218,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-116d381d-9467-431d-b317-d561ca6a8e34,DISK], DatanodeInfoWithStorage[127.0.0.1:44337,DS-289a1fb3-af43-4b9b-b926-0fa230d25d21,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-8447780b-ce09-4d92-b9f3-65c2bb67a10e,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-4db16019-f73a-4b20-a19c-edb6eb447423,DISK], DatanodeInfoWithStorage[127.0.0.1:45180,DS-942b64f9-d6cb-4b0c-a24d-e22513ed80f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-973011638-172.17.0.7-1597308661213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33599,DS-422b9e2d-7bba-4e26-8aca-8362f596123e,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-4a1ba459-0c57-4e1e-8bf7-d1398b8fb540,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-01bfca91-8cf6-4515-973b-9d9eb3259bde,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-226bd42b-eb65-4ae7-b32b-da35df3f6b67,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-ac5c6e71-ba11-4371-9d4a-a5be77527749,DISK], DatanodeInfoWithStorage[127.0.0.1:42740,DS-065d0cab-9bee-48e3-ac01-a0ea7e7c8d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-db38e7f9-2aba-4a02-8012-9ffc264729ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-546497b8-61bf-452a-bba9-303726ae6073,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-973011638-172.17.0.7-1597308661213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33599,DS-422b9e2d-7bba-4e26-8aca-8362f596123e,DISK], DatanodeInfoWithStorage[127.0.0.1:34663,DS-4a1ba459-0c57-4e1e-8bf7-d1398b8fb540,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-01bfca91-8cf6-4515-973b-9d9eb3259bde,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-226bd42b-eb65-4ae7-b32b-da35df3f6b67,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-ac5c6e71-ba11-4371-9d4a-a5be77527749,DISK], DatanodeInfoWithStorage[127.0.0.1:42740,DS-065d0cab-9bee-48e3-ac01-a0ea7e7c8d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40588,DS-db38e7f9-2aba-4a02-8012-9ffc264729ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-546497b8-61bf-452a-bba9-303726ae6073,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1478957771-172.17.0.7-1597308862527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34680,DS-01b1c31e-50e2-4125-8979-0133bf068fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-ab8386b3-7001-4f21-8d41-7f73a8db0ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-d06097d2-8fbf-4e49-b6b3-7f72b889d40a,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-7dacbeb2-6318-46ac-9a05-3fd76b3d6132,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-045ee67e-2e8b-4e83-b8bc-5df35a2efed4,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-bb08486d-5c3d-4598-ad3c-83d4730500e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-90378b63-bc6e-41cb-afdc-58b41a78f115,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-9d06671f-e990-48de-a10c-34b92ea5605a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1478957771-172.17.0.7-1597308862527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34680,DS-01b1c31e-50e2-4125-8979-0133bf068fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-ab8386b3-7001-4f21-8d41-7f73a8db0ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-d06097d2-8fbf-4e49-b6b3-7f72b889d40a,DISK], DatanodeInfoWithStorage[127.0.0.1:36396,DS-7dacbeb2-6318-46ac-9a05-3fd76b3d6132,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-045ee67e-2e8b-4e83-b8bc-5df35a2efed4,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-bb08486d-5c3d-4598-ad3c-83d4730500e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-90378b63-bc6e-41cb-afdc-58b41a78f115,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-9d06671f-e990-48de-a10c-34b92ea5605a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742911119-172.17.0.7-1597308908706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40739,DS-4ed53d4d-08af-4987-abf1-1254c53fae2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-a3a36aee-abf1-43b2-b4a0-e9756fc6a04f,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-22e40f49-94de-48ba-a6b0-a3fe3cdd561b,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-6a0a514c-47d4-4da4-a2ba-4f0a3c2901c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-e9bdc024-b494-49ca-b1b0-4bfe3779bb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-7c958f5b-b587-4650-9294-e39ef9ebc36d,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-d761df00-e368-4462-aa18-70ac18961482,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-f4750825-884b-4edd-ac2e-b6579de911c4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742911119-172.17.0.7-1597308908706:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40739,DS-4ed53d4d-08af-4987-abf1-1254c53fae2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-a3a36aee-abf1-43b2-b4a0-e9756fc6a04f,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-22e40f49-94de-48ba-a6b0-a3fe3cdd561b,DISK], DatanodeInfoWithStorage[127.0.0.1:40396,DS-6a0a514c-47d4-4da4-a2ba-4f0a3c2901c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-e9bdc024-b494-49ca-b1b0-4bfe3779bb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-7c958f5b-b587-4650-9294-e39ef9ebc36d,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-d761df00-e368-4462-aa18-70ac18961482,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-f4750825-884b-4edd-ac2e-b6579de911c4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-821962972-172.17.0.7-1597308952986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45621,DS-ceb2e08d-5631-4436-b0e3-43983deb0b47,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-9795cc79-a32d-41e7-b2f2-8e5d282752b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-7ed45815-9b27-4cdd-8eea-d7d24bf8c079,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-6fa0aabb-ebc3-4c1e-a4d7-0de055c9f085,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-abcca3f5-4e6f-443c-80c7-c3d8b4679c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-6921ff92-1ebd-4c52-a638-4458322c1dea,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-a4abe562-470a-4e84-98ae-699d28dd7489,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-5e6e2216-70c6-4531-91f2-0bb1c5989bd2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-821962972-172.17.0.7-1597308952986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45621,DS-ceb2e08d-5631-4436-b0e3-43983deb0b47,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-9795cc79-a32d-41e7-b2f2-8e5d282752b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-7ed45815-9b27-4cdd-8eea-d7d24bf8c079,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-6fa0aabb-ebc3-4c1e-a4d7-0de055c9f085,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-abcca3f5-4e6f-443c-80c7-c3d8b4679c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-6921ff92-1ebd-4c52-a638-4458322c1dea,DISK], DatanodeInfoWithStorage[127.0.0.1:36191,DS-a4abe562-470a-4e84-98ae-699d28dd7489,DISK], DatanodeInfoWithStorage[127.0.0.1:36338,DS-5e6e2216-70c6-4531-91f2-0bb1c5989bd2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117408177-172.17.0.7-1597309194594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37688,DS-3fbd0604-d8e6-4728-ba79-35a41a8dbb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-eb2fc14e-9fd6-4c1a-b642-78023e0d8211,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-14f8049b-a8bb-4062-8f35-5f9e1010a2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-01b522a6-c432-4128-9e7f-472d0bd8a226,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-d8a88579-946c-40ec-ba55-e37fcb277873,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-86a82cf6-39d4-42b4-9f36-dce13cd897ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-37244ce8-7445-4267-93bb-ce1ebec5217b,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-73d53526-414b-448b-9f20-e8e3c9f0482e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117408177-172.17.0.7-1597309194594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37688,DS-3fbd0604-d8e6-4728-ba79-35a41a8dbb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-eb2fc14e-9fd6-4c1a-b642-78023e0d8211,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-14f8049b-a8bb-4062-8f35-5f9e1010a2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-01b522a6-c432-4128-9e7f-472d0bd8a226,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-d8a88579-946c-40ec-ba55-e37fcb277873,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-86a82cf6-39d4-42b4-9f36-dce13cd897ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-37244ce8-7445-4267-93bb-ce1ebec5217b,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-73d53526-414b-448b-9f20-e8e3c9f0482e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1445096864-172.17.0.7-1597309251189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37905,DS-dc031e11-3152-43cf-bc8a-4d4af40cc548,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-927e2848-4b7f-4f29-ad68-24f1155d3aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-86c9630a-c75a-4442-9a77-f894ae0d6a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-31e9c4e6-2feb-4d23-a3a5-5181bcb4a717,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-c0a48721-e8e1-4a9b-9fd7-b5c13185e3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-833a1393-36ee-4132-89b8-28d7853f53b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35743,DS-14572775-74aa-4615-9b21-bc83064b9a42,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-19825cfa-a2fb-4301-96f3-e572f20ec928,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1445096864-172.17.0.7-1597309251189:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37905,DS-dc031e11-3152-43cf-bc8a-4d4af40cc548,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-927e2848-4b7f-4f29-ad68-24f1155d3aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:46244,DS-86c9630a-c75a-4442-9a77-f894ae0d6a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42547,DS-31e9c4e6-2feb-4d23-a3a5-5181bcb4a717,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-c0a48721-e8e1-4a9b-9fd7-b5c13185e3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-833a1393-36ee-4132-89b8-28d7853f53b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35743,DS-14572775-74aa-4615-9b21-bc83064b9a42,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-19825cfa-a2fb-4301-96f3-e572f20ec928,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061869117-172.17.0.7-1597309638391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38950,DS-0b6e2d4d-b34f-4790-900b-7220e7ba841e,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-d84a6c32-d250-414f-9e0b-08c077622d12,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-df8b8d8b-6db5-45ea-9cc3-91553f07014e,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-421cc259-ea77-43bf-a7b6-228d8aa0cad8,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-28ae9a66-6245-46bd-9bde-6d61fa478dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-d6abedbb-d1a9-4375-bd8d-767bb21e2a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-e0df04f1-a5c7-4515-b220-9b17d82af71f,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-bf226ba4-d2ed-4135-aa67-4fa1e0cb6af2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061869117-172.17.0.7-1597309638391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38950,DS-0b6e2d4d-b34f-4790-900b-7220e7ba841e,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-d84a6c32-d250-414f-9e0b-08c077622d12,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-df8b8d8b-6db5-45ea-9cc3-91553f07014e,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-421cc259-ea77-43bf-a7b6-228d8aa0cad8,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-28ae9a66-6245-46bd-9bde-6d61fa478dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:44107,DS-d6abedbb-d1a9-4375-bd8d-767bb21e2a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-e0df04f1-a5c7-4515-b220-9b17d82af71f,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-bf226ba4-d2ed-4135-aa67-4fa1e0cb6af2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1576113545-172.17.0.7-1597309988980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45881,DS-b7651e4a-7b24-4b22-887f-b247cb0b9f76,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-29f4bb2a-6b60-4c7e-9af0-7fe057c53ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-527e7309-52f9-4b7f-bcf0-fca45c62c2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-1e162a54-9a55-4ed1-a6b5-a4e5d2b3dedc,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-f7914967-b4e7-4ad4-b4fa-a9b437691bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46811,DS-14832a65-a136-420b-8ab2-1b3891d0b583,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-198fb5e6-2e06-4a99-a78c-f33cb0dc9ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-25e25bb5-6a69-463c-99e7-d1443434fc9e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1576113545-172.17.0.7-1597309988980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45881,DS-b7651e4a-7b24-4b22-887f-b247cb0b9f76,DISK], DatanodeInfoWithStorage[127.0.0.1:43063,DS-29f4bb2a-6b60-4c7e-9af0-7fe057c53ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-527e7309-52f9-4b7f-bcf0-fca45c62c2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-1e162a54-9a55-4ed1-a6b5-a4e5d2b3dedc,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-f7914967-b4e7-4ad4-b4fa-a9b437691bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46811,DS-14832a65-a136-420b-8ab2-1b3891d0b583,DISK], DatanodeInfoWithStorage[127.0.0.1:38331,DS-198fb5e6-2e06-4a99-a78c-f33cb0dc9ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-25e25bb5-6a69-463c-99e7-d1443434fc9e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-787975956-172.17.0.7-1597310344156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41076,DS-7aae146d-286a-4f84-b8e0-2efdb8ed63df,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-b48864e3-e760-4072-a41a-6af3f0fe7861,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-1021b526-e442-4a7a-8705-d7d5752375a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-2c9c0020-41e6-4899-bf97-9b0986c5218f,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-cbd8dfbc-273c-4808-85d9-508f9c891d18,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-552065c9-20fb-47a7-a24d-0e0a5e00a1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-b5ced301-82dd-490b-a9fe-277bf7441e58,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-e275c98d-b731-4c51-b32e-dd32d1c3c101,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-787975956-172.17.0.7-1597310344156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41076,DS-7aae146d-286a-4f84-b8e0-2efdb8ed63df,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-b48864e3-e760-4072-a41a-6af3f0fe7861,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-1021b526-e442-4a7a-8705-d7d5752375a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-2c9c0020-41e6-4899-bf97-9b0986c5218f,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-cbd8dfbc-273c-4808-85d9-508f9c891d18,DISK], DatanodeInfoWithStorage[127.0.0.1:40836,DS-552065c9-20fb-47a7-a24d-0e0a5e00a1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41234,DS-b5ced301-82dd-490b-a9fe-277bf7441e58,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-e275c98d-b731-4c51-b32e-dd32d1c3c101,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-425373292-172.17.0.7-1597310548002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39494,DS-82be89ae-aff4-4d2a-90ff-0bddf5827956,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-83eb58c3-5c18-4f60-b478-464eaaef44f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-4e86c5d1-f224-489a-9b7d-501d2f8a326a,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-2bc6404e-f527-461c-be37-ac3da227933a,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-2bdd50b0-7372-48fa-8a89-0c908bb73abe,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-05a1b157-798f-42d8-9d16-1b872b5f066d,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-5431bdf7-9546-46e5-a3ea-208ed78e822c,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-d277bac7-cfd1-43ee-881a-8dc4ec5b07c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-425373292-172.17.0.7-1597310548002:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39494,DS-82be89ae-aff4-4d2a-90ff-0bddf5827956,DISK], DatanodeInfoWithStorage[127.0.0.1:33110,DS-83eb58c3-5c18-4f60-b478-464eaaef44f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-4e86c5d1-f224-489a-9b7d-501d2f8a326a,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-2bc6404e-f527-461c-be37-ac3da227933a,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-2bdd50b0-7372-48fa-8a89-0c908bb73abe,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-05a1b157-798f-42d8-9d16-1b872b5f066d,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-5431bdf7-9546-46e5-a3ea-208ed78e822c,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-d277bac7-cfd1-43ee-881a-8dc4ec5b07c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2027399283-172.17.0.7-1597310600990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42732,DS-1a6adfaf-1085-4386-8ae6-6c39ce218292,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-addea439-c48b-403c-9291-20b8beb7f60a,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-39de4a74-6d93-426c-8876-b9c14ef043f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-ee87e73c-84fa-49d6-b601-a08725444a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-5f1f74cb-5951-4e1c-96be-da9b371ace91,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-ff47a06e-db34-4c4a-bff7-08873c8c4b49,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-25b6ce09-8416-43ca-9bda-88282f86365a,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-d436b79f-c027-4b05-af46-ded2e7a6ed1b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2027399283-172.17.0.7-1597310600990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42732,DS-1a6adfaf-1085-4386-8ae6-6c39ce218292,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-addea439-c48b-403c-9291-20b8beb7f60a,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-39de4a74-6d93-426c-8876-b9c14ef043f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-ee87e73c-84fa-49d6-b601-a08725444a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-5f1f74cb-5951-4e1c-96be-da9b371ace91,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-ff47a06e-db34-4c4a-bff7-08873c8c4b49,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-25b6ce09-8416-43ca-9bda-88282f86365a,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-d436b79f-c027-4b05-af46-ded2e7a6ed1b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150504105-172.17.0.7-1597310786496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37792,DS-8f26eb2e-f831-4336-905e-ab00612104b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-153674dc-543d-4e87-9bcd-bda71b4cccba,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-954c4f1e-dd7a-480a-9308-c42496929e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-1ddbe03f-7784-4d38-bb6c-01da199d1fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-f01cb069-f480-4361-900a-c5cbd7379de1,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-b305f15c-4293-4229-a62b-4a10394f68d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-96e14aae-b63c-4ace-bd5e-89160e54bb43,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-2bf475c7-b705-42d7-9b85-ea48f60a4c29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150504105-172.17.0.7-1597310786496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37792,DS-8f26eb2e-f831-4336-905e-ab00612104b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-153674dc-543d-4e87-9bcd-bda71b4cccba,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-954c4f1e-dd7a-480a-9308-c42496929e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-1ddbe03f-7784-4d38-bb6c-01da199d1fe2,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-f01cb069-f480-4361-900a-c5cbd7379de1,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-b305f15c-4293-4229-a62b-4a10394f68d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-96e14aae-b63c-4ace-bd5e-89160e54bb43,DISK], DatanodeInfoWithStorage[127.0.0.1:45351,DS-2bf475c7-b705-42d7-9b85-ea48f60a4c29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367163294-172.17.0.7-1597310828858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33080,DS-aa05068c-f1ba-485f-b932-b089f80e455b,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-cc65b591-a113-46c7-874f-0fee3d1cdfc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-e36f8a94-885d-4ac9-822c-ac8b0970c258,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-b35ed83b-7394-4721-bdd9-99458bd520ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-7b672d9f-7837-4667-8a3f-2c80c91c570a,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-dff1aee6-1412-4eae-935a-58feeec6cd20,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-468575f2-9965-4961-bb47-945f42164fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-3e6f4323-9219-4a90-95e1-f3b9270a6f27,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367163294-172.17.0.7-1597310828858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33080,DS-aa05068c-f1ba-485f-b932-b089f80e455b,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-cc65b591-a113-46c7-874f-0fee3d1cdfc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-e36f8a94-885d-4ac9-822c-ac8b0970c258,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-b35ed83b-7394-4721-bdd9-99458bd520ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45413,DS-7b672d9f-7837-4667-8a3f-2c80c91c570a,DISK], DatanodeInfoWithStorage[127.0.0.1:40516,DS-dff1aee6-1412-4eae-935a-58feeec6cd20,DISK], DatanodeInfoWithStorage[127.0.0.1:36112,DS-468575f2-9965-4961-bb47-945f42164fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-3e6f4323-9219-4a90-95e1-f3b9270a6f27,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587632095-172.17.0.7-1597310865274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39068,DS-a8852a45-2fc4-4f67-a6be-a01ff2fd1ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:44603,DS-254ca1e3-dae4-4aef-bd8b-be2c4e0812a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-64f359fe-0d4e-4865-89e5-f12b4b980927,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-7a96c68e-acd8-4d4e-be85-207c17bd005f,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-1033fe5c-8c95-42bd-90f8-1595eb00cb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-b6b4649f-1dde-480c-9ec6-c209a38b3510,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-165adb8a-48e7-4704-be5c-52556b8e33fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-0c26c99c-6ee2-440a-887e-65192c2b75be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-587632095-172.17.0.7-1597310865274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39068,DS-a8852a45-2fc4-4f67-a6be-a01ff2fd1ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:44603,DS-254ca1e3-dae4-4aef-bd8b-be2c4e0812a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-64f359fe-0d4e-4865-89e5-f12b4b980927,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-7a96c68e-acd8-4d4e-be85-207c17bd005f,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-1033fe5c-8c95-42bd-90f8-1595eb00cb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-b6b4649f-1dde-480c-9ec6-c209a38b3510,DISK], DatanodeInfoWithStorage[127.0.0.1:37892,DS-165adb8a-48e7-4704-be5c-52556b8e33fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-0c26c99c-6ee2-440a-887e-65192c2b75be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619638822-172.17.0.7-1597311195107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37361,DS-5ee03bc0-17ee-4fcb-b0c0-c1dde8fe639a,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-6ade1181-f500-428d-bb9b-d1b64e5295cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-e7138455-0f25-4f90-88dc-96751b922e03,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-3ec3b842-ba8e-4445-86be-aa7aebcfe68e,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-f40644d8-1a68-40e8-a4fb-bc04bc073576,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-e57216a4-c094-4ba6-bd24-a362f319a8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-c5e5043c-760e-4e05-ba12-d89203bd4185,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-b0a64d14-deb4-4797-b8bb-7199b3b69e20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619638822-172.17.0.7-1597311195107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37361,DS-5ee03bc0-17ee-4fcb-b0c0-c1dde8fe639a,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-6ade1181-f500-428d-bb9b-d1b64e5295cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-e7138455-0f25-4f90-88dc-96751b922e03,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-3ec3b842-ba8e-4445-86be-aa7aebcfe68e,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-f40644d8-1a68-40e8-a4fb-bc04bc073576,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-e57216a4-c094-4ba6-bd24-a362f319a8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-c5e5043c-760e-4e05-ba12-d89203bd4185,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-b0a64d14-deb4-4797-b8bb-7199b3b69e20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1540464692-172.17.0.7-1597311346354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39644,DS-e78a4af7-7a9d-4c96-832d-031c00fefc93,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-679a6df9-d00a-493c-a6c7-71ec5c8166c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-616e1911-3800-4433-85d7-48412b8d1cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-4978d3d7-0602-4372-8050-6c088296e482,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-955973ae-68a9-4ee1-9ddc-a59d65d343fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-ee8ff19d-e9fa-4ca2-a334-d0e51bcbc3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-1ff42b74-2287-4b74-9572-5c3c4ca10b18,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-0fd4f162-979a-4549-83e5-d0ea4a7b57be,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1540464692-172.17.0.7-1597311346354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39644,DS-e78a4af7-7a9d-4c96-832d-031c00fefc93,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-679a6df9-d00a-493c-a6c7-71ec5c8166c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-616e1911-3800-4433-85d7-48412b8d1cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-4978d3d7-0602-4372-8050-6c088296e482,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-955973ae-68a9-4ee1-9ddc-a59d65d343fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40505,DS-ee8ff19d-e9fa-4ca2-a334-d0e51bcbc3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-1ff42b74-2287-4b74-9572-5c3c4ca10b18,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-0fd4f162-979a-4549-83e5-d0ea4a7b57be,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-288469689-172.17.0.7-1597311390578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33706,DS-c48d6e34-cb32-4b7e-a635-ed384ea22cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-0f6cf93c-f0fa-4a78-a45d-ce6f7c15156e,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-b7e5d37a-108a-48ff-ac40-f9a2cc33549b,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-44563d30-3543-41ec-b410-1ad08525edae,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-f276d26b-cd4d-4f79-89a9-ddb06c6d0c34,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-dd2459cd-0555-4638-9163-938eef1a3c60,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-0b949237-90e7-4a0d-9a8f-f2c893adc3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-05b23f69-6df9-45d1-a58d-d6f43d0093c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-288469689-172.17.0.7-1597311390578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33706,DS-c48d6e34-cb32-4b7e-a635-ed384ea22cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-0f6cf93c-f0fa-4a78-a45d-ce6f7c15156e,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-b7e5d37a-108a-48ff-ac40-f9a2cc33549b,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-44563d30-3543-41ec-b410-1ad08525edae,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-f276d26b-cd4d-4f79-89a9-ddb06c6d0c34,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-dd2459cd-0555-4638-9163-938eef1a3c60,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-0b949237-90e7-4a0d-9a8f-f2c893adc3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-05b23f69-6df9-45d1-a58d-d6f43d0093c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351554590-172.17.0.7-1597311764620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43551,DS-f5f6b338-7bb5-4525-baaa-32f9ee71bc51,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-0f1312ad-1ff2-4543-9028-d0cb38b25a18,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-79e54877-b5e1-41a0-948e-61c3df2b2895,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-72412cdd-b381-419d-9231-8b935cf81be4,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-068ddb50-27e5-46a8-9a54-b606d86b76b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-e8a5b79e-b14f-4767-8439-d55b2d994cea,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-4c91bbb5-16cc-4986-a57c-a588c55efea3,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-81ee440e-7113-4fb8-a687-f46441fcb8cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351554590-172.17.0.7-1597311764620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43551,DS-f5f6b338-7bb5-4525-baaa-32f9ee71bc51,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-0f1312ad-1ff2-4543-9028-d0cb38b25a18,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-79e54877-b5e1-41a0-948e-61c3df2b2895,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-72412cdd-b381-419d-9231-8b935cf81be4,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-068ddb50-27e5-46a8-9a54-b606d86b76b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44211,DS-e8a5b79e-b14f-4767-8439-d55b2d994cea,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-4c91bbb5-16cc-4986-a57c-a588c55efea3,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-81ee440e-7113-4fb8-a687-f46441fcb8cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1787766633-172.17.0.7-1597311846717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45672,DS-128acbb3-6055-45c3-9c45-51173dd4b7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-25f93afa-394e-4e9d-a825-33a9fa66c539,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-8b7957c6-01c4-4f87-954f-6307706e32be,DISK], DatanodeInfoWithStorage[127.0.0.1:41774,DS-0034e02f-50e2-4d6a-b972-d3eb437dde20,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-1ea7685f-82ad-42cf-a117-95fcfa72d152,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-e6aac998-b5e3-44b2-aa08-f21a5d7ad2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-38678399-c35a-40b8-8073-15c0aca594be,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-adbcd27b-7616-4651-970e-b17c47d6e4a5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1787766633-172.17.0.7-1597311846717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45672,DS-128acbb3-6055-45c3-9c45-51173dd4b7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-25f93afa-394e-4e9d-a825-33a9fa66c539,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-8b7957c6-01c4-4f87-954f-6307706e32be,DISK], DatanodeInfoWithStorage[127.0.0.1:41774,DS-0034e02f-50e2-4d6a-b972-d3eb437dde20,DISK], DatanodeInfoWithStorage[127.0.0.1:42871,DS-1ea7685f-82ad-42cf-a117-95fcfa72d152,DISK], DatanodeInfoWithStorage[127.0.0.1:43496,DS-e6aac998-b5e3-44b2-aa08-f21a5d7ad2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-38678399-c35a-40b8-8073-15c0aca594be,DISK], DatanodeInfoWithStorage[127.0.0.1:33651,DS-adbcd27b-7616-4651-970e-b17c47d6e4a5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-984523392-172.17.0.7-1597311937378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39670,DS-0039054a-33cd-47b2-ba0b-aec7a0e7accc,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-eab2bd35-7721-475d-99ff-81918571a0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-ac7b8dfe-759e-4d29-bdb7-5739731845f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-7495a00c-243d-414d-b6b6-195b32c2ff24,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-a29bc6ae-83c5-4e95-bbd8-5cbb760a6e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-fb288de8-6ae1-44a4-a4f0-2df2458e4918,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-8a07ebf3-f58c-4b71-b2a4-f48de4999c01,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-bd885f4d-7647-4b9f-8c07-6ce7d18e5f1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-984523392-172.17.0.7-1597311937378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39670,DS-0039054a-33cd-47b2-ba0b-aec7a0e7accc,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-eab2bd35-7721-475d-99ff-81918571a0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-ac7b8dfe-759e-4d29-bdb7-5739731845f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-7495a00c-243d-414d-b6b6-195b32c2ff24,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-a29bc6ae-83c5-4e95-bbd8-5cbb760a6e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-fb288de8-6ae1-44a4-a4f0-2df2458e4918,DISK], DatanodeInfoWithStorage[127.0.0.1:43753,DS-8a07ebf3-f58c-4b71-b2a4-f48de4999c01,DISK], DatanodeInfoWithStorage[127.0.0.1:35747,DS-bd885f4d-7647-4b9f-8c07-6ce7d18e5f1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-77270554-172.17.0.7-1597311988480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38613,DS-d9b12317-50ed-4229-8fff-ce3438b4c10a,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-7059cdc7-9daf-4d48-9297-0298fed8f3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-5dc9d129-abbf-45b8-89df-e6a474046a44,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-6ab15c63-5a8a-4b6a-bd06-87a8d5f82022,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-157c06c5-0e7c-4633-a99c-bf13914e909b,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-484eaf4d-8a37-42f7-a404-c892fb691d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-16772941-9ab6-4662-9155-bcf6eb783d12,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-cb5a89b4-d1c8-46b9-98d6-0f173934bc66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-77270554-172.17.0.7-1597311988480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38613,DS-d9b12317-50ed-4229-8fff-ce3438b4c10a,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-7059cdc7-9daf-4d48-9297-0298fed8f3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-5dc9d129-abbf-45b8-89df-e6a474046a44,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-6ab15c63-5a8a-4b6a-bd06-87a8d5f82022,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-157c06c5-0e7c-4633-a99c-bf13914e909b,DISK], DatanodeInfoWithStorage[127.0.0.1:45135,DS-484eaf4d-8a37-42f7-a404-c892fb691d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-16772941-9ab6-4662-9155-bcf6eb783d12,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-cb5a89b4-d1c8-46b9-98d6-0f173934bc66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143547046-172.17.0.7-1597312311514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38884,DS-def578ab-1b5b-43cc-91a4-69eca16bb772,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-e6699b17-33da-478c-951d-2530dc6a691c,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-7a446234-666c-4c94-8ad5-d17aa1313e63,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-d624fe10-9282-4414-8d44-ce6d46064e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-e148e525-c153-40c0-8c25-33021bfc2ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-bdc96e22-0956-4424-9712-2c3c453895e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-b8f53e49-8ed8-4f80-aeab-0f0d99abffcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-b8d2e665-a366-4b17-b067-99c51e639957,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143547046-172.17.0.7-1597312311514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38884,DS-def578ab-1b5b-43cc-91a4-69eca16bb772,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-e6699b17-33da-478c-951d-2530dc6a691c,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-7a446234-666c-4c94-8ad5-d17aa1313e63,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-d624fe10-9282-4414-8d44-ce6d46064e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-e148e525-c153-40c0-8c25-33021bfc2ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-bdc96e22-0956-4424-9712-2c3c453895e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38235,DS-b8f53e49-8ed8-4f80-aeab-0f0d99abffcc,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-b8d2e665-a366-4b17-b067-99c51e639957,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143803909-172.17.0.7-1597312400294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40011,DS-c817d47c-e37b-4695-9cba-a2c7078536dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-494c0e14-e5f7-4cfc-8f71-508ecb122e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-0cd3bc34-33bb-4cb5-ab06-a933a91ac3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-872a074b-6a92-44aa-9b9b-dfdd25bef84e,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-25ce10a0-1ae8-44e7-81af-c00ba90b169c,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-2a5759f0-3894-4a11-8d13-682e5ee2d0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-fb5e21f2-02cf-47f6-9e93-650561a207b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-8b2e83e7-1793-4c63-b7d6-1a6ff762deb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143803909-172.17.0.7-1597312400294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40011,DS-c817d47c-e37b-4695-9cba-a2c7078536dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-494c0e14-e5f7-4cfc-8f71-508ecb122e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-0cd3bc34-33bb-4cb5-ab06-a933a91ac3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-872a074b-6a92-44aa-9b9b-dfdd25bef84e,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-25ce10a0-1ae8-44e7-81af-c00ba90b169c,DISK], DatanodeInfoWithStorage[127.0.0.1:34297,DS-2a5759f0-3894-4a11-8d13-682e5ee2d0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-fb5e21f2-02cf-47f6-9e93-650561a207b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-8b2e83e7-1793-4c63-b7d6-1a6ff762deb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489931657-172.17.0.7-1597312888319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43714,DS-c9fa8371-a836-4c93-9ebd-ff94664601e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-19226696-af8f-417b-8fd7-7cbbddb39547,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-52d33d1f-0234-4d9d-a531-57835c723a71,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-15feb710-2093-423b-80df-f0b7a5b91db7,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-e3081034-5b3a-4be1-8732-c463e10b3302,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-bde038a2-c974-4b31-8d9e-1d963138e92e,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-f4d07240-d1cc-494c-a0d1-a69622459709,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-647e5aee-d0da-4994-94ee-3c1bf3efae87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489931657-172.17.0.7-1597312888319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43714,DS-c9fa8371-a836-4c93-9ebd-ff94664601e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-19226696-af8f-417b-8fd7-7cbbddb39547,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-52d33d1f-0234-4d9d-a531-57835c723a71,DISK], DatanodeInfoWithStorage[127.0.0.1:42123,DS-15feb710-2093-423b-80df-f0b7a5b91db7,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-e3081034-5b3a-4be1-8732-c463e10b3302,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-bde038a2-c974-4b31-8d9e-1d963138e92e,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-f4d07240-d1cc-494c-a0d1-a69622459709,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-647e5aee-d0da-4994-94ee-3c1bf3efae87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-259322165-172.17.0.7-1597313071788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45221,DS-3db4aeef-a2a3-4ef6-8f5c-9e44ad41be99,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-b5e2745c-6314-4b24-96a8-2a80cc639d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-05530e74-d5f8-42dc-a8e6-6cb1f5258a37,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-c65f3c9a-1987-47d0-9c18-871eb3b991ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-fecc7b37-691f-4a01-bae9-331c45d83041,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-6d252663-6ec1-4954-bdeb-635350c85cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-d01d139d-67db-4ac5-ba2a-ad713edd40ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-b1feb18f-6710-4530-8d2d-3d6efc644240,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-259322165-172.17.0.7-1597313071788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45221,DS-3db4aeef-a2a3-4ef6-8f5c-9e44ad41be99,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-b5e2745c-6314-4b24-96a8-2a80cc639d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-05530e74-d5f8-42dc-a8e6-6cb1f5258a37,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-c65f3c9a-1987-47d0-9c18-871eb3b991ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-fecc7b37-691f-4a01-bae9-331c45d83041,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-6d252663-6ec1-4954-bdeb-635350c85cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-d01d139d-67db-4ac5-ba2a-ad713edd40ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-b1feb18f-6710-4530-8d2d-3d6efc644240,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803644038-172.17.0.7-1597313145385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46535,DS-5abce34d-f902-4bd7-80b8-2cefc00cb92b,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-e878191b-0fba-4d3b-90d0-2aca1240445c,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-f1c554f5-a24d-4163-b6a6-c41571b4a154,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-e7d52e8f-88ab-4ec4-982c-cf784af9b007,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-d64a1fe1-dc90-45ad-b392-9786146b0f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42149,DS-e4bfd3cd-1286-47af-9d95-571da54214e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-738dc92f-4712-431e-bb29-f364b71f5968,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-0ed050c9-6352-46a3-a1d3-fdc895a8731f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-803644038-172.17.0.7-1597313145385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46535,DS-5abce34d-f902-4bd7-80b8-2cefc00cb92b,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-e878191b-0fba-4d3b-90d0-2aca1240445c,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-f1c554f5-a24d-4163-b6a6-c41571b4a154,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-e7d52e8f-88ab-4ec4-982c-cf784af9b007,DISK], DatanodeInfoWithStorage[127.0.0.1:40949,DS-d64a1fe1-dc90-45ad-b392-9786146b0f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42149,DS-e4bfd3cd-1286-47af-9d95-571da54214e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40276,DS-738dc92f-4712-431e-bb29-f364b71f5968,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-0ed050c9-6352-46a3-a1d3-fdc895a8731f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361206231-172.17.0.7-1597313472434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34733,DS-e4450a54-068d-4ec8-bd18-9173601e3b21,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-8c1700d9-d4a8-48f7-8ce5-e43923e8f4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-41d6f930-812a-46df-8beb-32cd13847f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-f3f2afe1-2bc4-4dea-840b-7abfff0ea616,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-87ea1cd1-8f1f-495b-a605-f8785f59da45,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-65b6b898-784d-409b-b68d-7931e3f2c989,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-65ed2804-5ad2-409d-bfe6-cdeef897f7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-598c9370-c9e7-4812-8e64-e2f96bbb8b7b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-361206231-172.17.0.7-1597313472434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34733,DS-e4450a54-068d-4ec8-bd18-9173601e3b21,DISK], DatanodeInfoWithStorage[127.0.0.1:37705,DS-8c1700d9-d4a8-48f7-8ce5-e43923e8f4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-41d6f930-812a-46df-8beb-32cd13847f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-f3f2afe1-2bc4-4dea-840b-7abfff0ea616,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-87ea1cd1-8f1f-495b-a605-f8785f59da45,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-65b6b898-784d-409b-b68d-7931e3f2c989,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-65ed2804-5ad2-409d-bfe6-cdeef897f7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-598c9370-c9e7-4812-8e64-e2f96bbb8b7b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-927347920-172.17.0.7-1597313762453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34454,DS-9293afca-0bca-469d-9aa7-a2b79d0eac97,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-fb17acc9-7d3a-42ab-8817-68820899b846,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-738d7a95-3ec8-45e6-942c-1f3277e80cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-9bf36482-4415-4749-ba16-1142f4003ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-cc3dd241-940b-4962-a09f-dd6b14a5a98e,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-ba4d0281-975b-4fb1-8ce7-e0d82da9fa94,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-6539374d-4cb1-42b6-8348-6f33fff1d9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-5b1bc2c0-0162-4bda-a506-2d65ffb89765,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-927347920-172.17.0.7-1597313762453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34454,DS-9293afca-0bca-469d-9aa7-a2b79d0eac97,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-fb17acc9-7d3a-42ab-8817-68820899b846,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-738d7a95-3ec8-45e6-942c-1f3277e80cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-9bf36482-4415-4749-ba16-1142f4003ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:40424,DS-cc3dd241-940b-4962-a09f-dd6b14a5a98e,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-ba4d0281-975b-4fb1-8ce7-e0d82da9fa94,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-6539374d-4cb1-42b6-8348-6f33fff1d9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34858,DS-5b1bc2c0-0162-4bda-a506-2d65ffb89765,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211520588-172.17.0.7-1597314158006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34297,DS-09bd41ee-e15f-4876-915b-2253a9137cee,DISK], DatanodeInfoWithStorage[127.0.0.1:45749,DS-5d09db22-7cda-4912-b32e-e899d40bdd4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-cc71541b-46ae-48c5-83dc-74de0baf0189,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-6f8dc377-f44f-4080-88bd-ab5b5237b32c,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-a1817390-1621-406d-9088-c0386513a00c,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-e1b02fef-0ffd-4fe8-b216-5d19db1e5558,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-032e0841-9251-46ea-aa2f-d4fdf2841d93,DISK], DatanodeInfoWithStorage[127.0.0.1:34667,DS-193983e8-f35d-461f-a3e4-6d79f1171807,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211520588-172.17.0.7-1597314158006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34297,DS-09bd41ee-e15f-4876-915b-2253a9137cee,DISK], DatanodeInfoWithStorage[127.0.0.1:45749,DS-5d09db22-7cda-4912-b32e-e899d40bdd4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-cc71541b-46ae-48c5-83dc-74de0baf0189,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-6f8dc377-f44f-4080-88bd-ab5b5237b32c,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-a1817390-1621-406d-9088-c0386513a00c,DISK], DatanodeInfoWithStorage[127.0.0.1:32832,DS-e1b02fef-0ffd-4fe8-b216-5d19db1e5558,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-032e0841-9251-46ea-aa2f-d4fdf2841d93,DISK], DatanodeInfoWithStorage[127.0.0.1:34667,DS-193983e8-f35d-461f-a3e4-6d79f1171807,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-517538721-172.17.0.7-1597314352785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35594,DS-babf5513-1273-4d84-8ecc-17e28d78d127,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-5e763446-4518-435a-b1a6-dd8b46fe61f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-52fbb12c-1cd8-4132-ad7e-76953cd655e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-4eacedd7-c55b-4492-8c83-cb0c82a449e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-db0f75e0-e61f-4537-8eac-9678c334fd53,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-0f98fd99-316d-42bf-a3e8-3996a45880fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-d4374e81-6266-42ea-8f97-c993eb372d64,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-adc17aff-a96f-49ba-af2d-58e881f092c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-517538721-172.17.0.7-1597314352785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35594,DS-babf5513-1273-4d84-8ecc-17e28d78d127,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-5e763446-4518-435a-b1a6-dd8b46fe61f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-52fbb12c-1cd8-4132-ad7e-76953cd655e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-4eacedd7-c55b-4492-8c83-cb0c82a449e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-db0f75e0-e61f-4537-8eac-9678c334fd53,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-0f98fd99-316d-42bf-a3e8-3996a45880fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-d4374e81-6266-42ea-8f97-c993eb372d64,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-adc17aff-a96f-49ba-af2d-58e881f092c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367159536-172.17.0.7-1597314519308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41630,DS-956d662e-74d7-449c-bebc-c13026e9561e,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-6948f776-51e1-436b-8e1d-e0836492266c,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-e23baf16-c900-4684-9796-904037372bec,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-c152fd3e-5c8f-4cce-ad5a-1e6b9307aa38,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-4634c718-a7d1-4ec8-962a-49186c081d81,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-bb20afe2-66c0-4800-99b6-e684f1266d73,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-3820c5e5-720b-4e99-875f-108c70fecc92,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-3dbab35c-66f2-465b-8301-5d6f652864cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367159536-172.17.0.7-1597314519308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41630,DS-956d662e-74d7-449c-bebc-c13026e9561e,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-6948f776-51e1-436b-8e1d-e0836492266c,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-e23baf16-c900-4684-9796-904037372bec,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-c152fd3e-5c8f-4cce-ad5a-1e6b9307aa38,DISK], DatanodeInfoWithStorage[127.0.0.1:36780,DS-4634c718-a7d1-4ec8-962a-49186c081d81,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-bb20afe2-66c0-4800-99b6-e684f1266d73,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-3820c5e5-720b-4e99-875f-108c70fecc92,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-3dbab35c-66f2-465b-8301-5d6f652864cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1777067487-172.17.0.7-1597314642000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36934,DS-c6af0a43-025c-4624-b7af-676711bc9e25,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-37f84dee-8947-455d-b484-19be2bd5f72d,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-a89e3405-a19d-4878-935e-190a857c233c,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-9cd45bf5-6d01-48a2-bdb5-03710742ab66,DISK], DatanodeInfoWithStorage[127.0.0.1:41957,DS-d7f8a808-7993-45d8-b0bd-a1c105028ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-b92778a0-7d35-4030-87dd-0f1e59f0ca5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-fb4ddb56-d52a-4726-8986-083834d9b012,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-ea49e1e4-6bac-42b4-8ae1-96400ebc69a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1777067487-172.17.0.7-1597314642000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36934,DS-c6af0a43-025c-4624-b7af-676711bc9e25,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-37f84dee-8947-455d-b484-19be2bd5f72d,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-a89e3405-a19d-4878-935e-190a857c233c,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-9cd45bf5-6d01-48a2-bdb5-03710742ab66,DISK], DatanodeInfoWithStorage[127.0.0.1:41957,DS-d7f8a808-7993-45d8-b0bd-a1c105028ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-b92778a0-7d35-4030-87dd-0f1e59f0ca5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-fb4ddb56-d52a-4726-8986-083834d9b012,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-ea49e1e4-6bac-42b4-8ae1-96400ebc69a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-901242682-172.17.0.7-1597314737226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41867,DS-aba3d83b-198f-487e-93d0-8ed2320f1639,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-a47683b7-c2e1-4159-8f11-2863ebe66c89,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-3cbd26e4-e283-4bfa-ac13-d6c0a05423dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-3aafafb6-4672-46d3-b60a-b78eaed30341,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-425bc4b9-77dc-44d5-9f69-8ad14b928e07,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-f359897e-4c87-431b-9f82-77e40bd92f86,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-b77d3b8c-640a-416c-991a-47df0719f1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-ab91b1cc-f566-4a92-8c68-74d102cf2df2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-901242682-172.17.0.7-1597314737226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41867,DS-aba3d83b-198f-487e-93d0-8ed2320f1639,DISK], DatanodeInfoWithStorage[127.0.0.1:39559,DS-a47683b7-c2e1-4159-8f11-2863ebe66c89,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-3cbd26e4-e283-4bfa-ac13-d6c0a05423dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-3aafafb6-4672-46d3-b60a-b78eaed30341,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-425bc4b9-77dc-44d5-9f69-8ad14b928e07,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-f359897e-4c87-431b-9f82-77e40bd92f86,DISK], DatanodeInfoWithStorage[127.0.0.1:36480,DS-b77d3b8c-640a-416c-991a-47df0719f1fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-ab91b1cc-f566-4a92-8c68-74d102cf2df2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-299230542-172.17.0.7-1597314775304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35587,DS-5f2f27d8-38b2-4e45-90fe-27dd2c4fcaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-d10663e2-f426-4e3c-b384-f0996a6b1728,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-992ee705-5a85-4c51-a4d0-46edf42d39fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-c7bd4ae7-dd78-47f4-9b17-a8c118311d09,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-57f7ef62-f03f-4752-9cbc-5e6253e380bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-750f7a91-6c3a-4e39-94c5-2f4946dde5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-ca7f7302-9e7c-480f-889e-d69dddbdb40f,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-91210409-206f-4421-b9e0-ca86bfcbad8e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-299230542-172.17.0.7-1597314775304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35587,DS-5f2f27d8-38b2-4e45-90fe-27dd2c4fcaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-d10663e2-f426-4e3c-b384-f0996a6b1728,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-992ee705-5a85-4c51-a4d0-46edf42d39fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42625,DS-c7bd4ae7-dd78-47f4-9b17-a8c118311d09,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-57f7ef62-f03f-4752-9cbc-5e6253e380bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-750f7a91-6c3a-4e39-94c5-2f4946dde5fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-ca7f7302-9e7c-480f-889e-d69dddbdb40f,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-91210409-206f-4421-b9e0-ca86bfcbad8e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35222296-172.17.0.7-1597315001447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36626,DS-cf09ba04-e095-492e-9d03-a35fc5ad8327,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-697622cc-3658-4b30-a84e-4b542a72ce72,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-559ef640-efed-446e-ba56-7556c0754a50,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-a7d0ff14-5867-4f23-9661-21fd33d52670,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-fa9ac2bf-b540-4b5f-b6a0-939960bb5151,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-ac180f8f-ce54-4529-9502-646f298fb8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-5844379b-56ee-46ac-99d2-76392637484b,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-520cb6df-6c92-4228-b485-5f0b57a7ac66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35222296-172.17.0.7-1597315001447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36626,DS-cf09ba04-e095-492e-9d03-a35fc5ad8327,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-697622cc-3658-4b30-a84e-4b542a72ce72,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-559ef640-efed-446e-ba56-7556c0754a50,DISK], DatanodeInfoWithStorage[127.0.0.1:38615,DS-a7d0ff14-5867-4f23-9661-21fd33d52670,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-fa9ac2bf-b540-4b5f-b6a0-939960bb5151,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-ac180f8f-ce54-4529-9502-646f298fb8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42069,DS-5844379b-56ee-46ac-99d2-76392637484b,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-520cb6df-6c92-4228-b485-5f0b57a7ac66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 10ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1134361952-172.17.0.7-1597315097847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33038,DS-e8f497c5-45a6-4ed4-80ee-09742eb4a41e,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-14122532-0e80-4389-82d3-e67a7931ca56,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-1d148d59-bec9-4ebc-b6cc-5ac2d278b567,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-2917e5df-be8d-4270-ae65-043f228014bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-cb1e23c9-e546-4b28-8552-05261e8adc74,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-f3710697-e9c6-45de-861d-f2eb40ac4c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-699efa18-c2ac-42e6-865b-8a8501350901,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-ecd730d2-91a6-4bfb-a8d9-72d64678bc46,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1134361952-172.17.0.7-1597315097847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33038,DS-e8f497c5-45a6-4ed4-80ee-09742eb4a41e,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-14122532-0e80-4389-82d3-e67a7931ca56,DISK], DatanodeInfoWithStorage[127.0.0.1:35563,DS-1d148d59-bec9-4ebc-b6cc-5ac2d278b567,DISK], DatanodeInfoWithStorage[127.0.0.1:36395,DS-2917e5df-be8d-4270-ae65-043f228014bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-cb1e23c9-e546-4b28-8552-05261e8adc74,DISK], DatanodeInfoWithStorage[127.0.0.1:45577,DS-f3710697-e9c6-45de-861d-f2eb40ac4c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-699efa18-c2ac-42e6-865b-8a8501350901,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-ecd730d2-91a6-4bfb-a8d9-72d64678bc46,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 24 out of 50
result: false positive !!!
Total execution time in seconds : 6933
