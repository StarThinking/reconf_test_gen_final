reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1900767681-172.17.0.15-1597397706825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33266,DS-cf77e22d-a7fd-4fce-8f80-e51469fa6bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-a0b03dba-050c-4f8e-87bf-3665da6aff3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-54e50035-b91d-47e0-9f4b-1e186e254eed,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-afcb6967-e9dd-497f-9565-b33ca9c2e619,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-b7109368-66f7-4020-9d11-84f48d6a9ded,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-8bef1626-2821-46ab-bfa6-a0e1ba233d73,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-a662f72e-3bd7-48f2-a11d-7e3a3e461fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-40ac3761-9ebe-408a-88a4-25e0b6226b75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1900767681-172.17.0.15-1597397706825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33266,DS-cf77e22d-a7fd-4fce-8f80-e51469fa6bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-a0b03dba-050c-4f8e-87bf-3665da6aff3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-54e50035-b91d-47e0-9f4b-1e186e254eed,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-afcb6967-e9dd-497f-9565-b33ca9c2e619,DISK], DatanodeInfoWithStorage[127.0.0.1:37111,DS-b7109368-66f7-4020-9d11-84f48d6a9ded,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-8bef1626-2821-46ab-bfa6-a0e1ba233d73,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-a662f72e-3bd7-48f2-a11d-7e3a3e461fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-40ac3761-9ebe-408a-88a4-25e0b6226b75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-827264050-172.17.0.15-1597397866617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41506,DS-4106ed93-c851-4021-a806-34106cbfcda7,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-d4adbf91-ebfb-435a-9a5d-1fdaa1360127,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-d5222e50-2de8-42c0-b171-1742485f8efd,DISK], DatanodeInfoWithStorage[127.0.0.1:37382,DS-db2376bc-fbf1-469c-be06-9b358e27667d,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-8b1fff46-ad59-4419-9386-297a9e13cefe,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-48d92edb-630e-4cc7-9aef-0082d9eaed0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-45b25239-edbb-4393-b155-a4317f81a47a,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-9a7b305f-168d-4f9b-bb7c-bae884ed6090,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-827264050-172.17.0.15-1597397866617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41506,DS-4106ed93-c851-4021-a806-34106cbfcda7,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-d4adbf91-ebfb-435a-9a5d-1fdaa1360127,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-d5222e50-2de8-42c0-b171-1742485f8efd,DISK], DatanodeInfoWithStorage[127.0.0.1:37382,DS-db2376bc-fbf1-469c-be06-9b358e27667d,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-8b1fff46-ad59-4419-9386-297a9e13cefe,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-48d92edb-630e-4cc7-9aef-0082d9eaed0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-45b25239-edbb-4393-b155-a4317f81a47a,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-9a7b305f-168d-4f9b-bb7c-bae884ed6090,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-406995503-172.17.0.15-1597398326228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34363,DS-4e6bda5a-6c45-489e-afef-b731680be00f,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-20ebac30-4b70-4243-9ee2-b5345d0aec77,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-9a2c863c-35ef-492a-948e-75555cf88e32,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-6f384f06-1cde-44ac-aa3a-8977afe44a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-4acc0dd7-3506-4ee3-9074-97924cc8444d,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-ead551de-a6b4-4d9f-9ffa-89915184d9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-0ef05f73-9b64-499f-a4b7-1e38a12f348a,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-29cc9b52-49b6-4c14-b6da-be4c721eb723,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-406995503-172.17.0.15-1597398326228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34363,DS-4e6bda5a-6c45-489e-afef-b731680be00f,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-20ebac30-4b70-4243-9ee2-b5345d0aec77,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-9a2c863c-35ef-492a-948e-75555cf88e32,DISK], DatanodeInfoWithStorage[127.0.0.1:33979,DS-6f384f06-1cde-44ac-aa3a-8977afe44a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-4acc0dd7-3506-4ee3-9074-97924cc8444d,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-ead551de-a6b4-4d9f-9ffa-89915184d9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-0ef05f73-9b64-499f-a4b7-1e38a12f348a,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-29cc9b52-49b6-4c14-b6da-be4c721eb723,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-17400221-172.17.0.15-1597399211217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43754,DS-b222f541-63d7-4014-a8bb-cd95de621e22,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-3870913e-1178-4734-9c01-d57bc1c35b59,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-5a992ea0-834e-468c-9ade-864cda8a5b87,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-62c4cb99-aa62-4e7a-999b-d39692f31dde,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-e54ec576-e734-4640-b90c-d538a7bc73c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-f706b6b6-17fe-4e02-b9d3-f9df6fd15714,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-570400f1-25eb-49f0-8473-fdbe3fe2229c,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-145aa4fa-45be-470e-a8b4-4190ee49e97d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-17400221-172.17.0.15-1597399211217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43754,DS-b222f541-63d7-4014-a8bb-cd95de621e22,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-3870913e-1178-4734-9c01-d57bc1c35b59,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-5a992ea0-834e-468c-9ade-864cda8a5b87,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-62c4cb99-aa62-4e7a-999b-d39692f31dde,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-e54ec576-e734-4640-b90c-d538a7bc73c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-f706b6b6-17fe-4e02-b9d3-f9df6fd15714,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-570400f1-25eb-49f0-8473-fdbe3fe2229c,DISK], DatanodeInfoWithStorage[127.0.0.1:46262,DS-145aa4fa-45be-470e-a8b4-4190ee49e97d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1479258517-172.17.0.15-1597399394915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45367,DS-9fd1abde-7bd3-40fa-ba66-30fb9bd61ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-3e42bd01-27fc-426b-8554-2b0f5b5a77dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-ed12fa9c-f175-4e26-b515-92b7489325df,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-0f807aab-1ae7-4c5c-a120-900896e98fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-64ef335a-4718-42f8-a25c-2fa7f4011b02,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-db316139-273f-49e6-80b9-17eba2786d40,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-73efa652-0759-4c97-aab7-2e58999e82e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-3644af0d-e4c7-4057-80ad-0ad80ef0bddf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1479258517-172.17.0.15-1597399394915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45367,DS-9fd1abde-7bd3-40fa-ba66-30fb9bd61ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:35006,DS-3e42bd01-27fc-426b-8554-2b0f5b5a77dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43546,DS-ed12fa9c-f175-4e26-b515-92b7489325df,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-0f807aab-1ae7-4c5c-a120-900896e98fb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-64ef335a-4718-42f8-a25c-2fa7f4011b02,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-db316139-273f-49e6-80b9-17eba2786d40,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-73efa652-0759-4c97-aab7-2e58999e82e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33359,DS-3644af0d-e4c7-4057-80ad-0ad80ef0bddf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982271713-172.17.0.15-1597400816385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42559,DS-26d60126-1559-43b6-8caa-7993634758b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-62cd75fe-33df-41ab-97ee-c2f1790d5460,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-b0aebe15-3beb-4e08-8eec-eb87b8873b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-5c7810b1-c2db-46bf-b833-47080704811c,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-90ec579a-661d-4851-8454-0fce1b1e9b07,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-7447021c-a759-4dde-be8f-2a479f33bf80,DISK], DatanodeInfoWithStorage[127.0.0.1:46835,DS-02ffbb7a-5466-4e94-91c7-06ef15dbac4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-49992475-7b34-4fc6-9a47-1a1e01d9c59c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982271713-172.17.0.15-1597400816385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42559,DS-26d60126-1559-43b6-8caa-7993634758b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-62cd75fe-33df-41ab-97ee-c2f1790d5460,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-b0aebe15-3beb-4e08-8eec-eb87b8873b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-5c7810b1-c2db-46bf-b833-47080704811c,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-90ec579a-661d-4851-8454-0fce1b1e9b07,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-7447021c-a759-4dde-be8f-2a479f33bf80,DISK], DatanodeInfoWithStorage[127.0.0.1:46835,DS-02ffbb7a-5466-4e94-91c7-06ef15dbac4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-49992475-7b34-4fc6-9a47-1a1e01d9c59c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1878641811-172.17.0.15-1597401330837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39549,DS-ced8b0cc-1a1c-443a-a5f7-72c313837534,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-7c864646-c14c-48da-8e86-282e011cabc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-52766e2c-822f-423e-a4aa-d3b147e2631e,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-988d0269-40c5-4ded-8b5f-55f8d943cd9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-67cdc6a4-c032-485a-a422-782b84174807,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-08521040-622e-4f7f-829f-834fc096daba,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-75260704-ee2f-4cc1-b5e1-246075699670,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-80cf28ce-ec8f-494c-b740-588ea41e3d31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1878641811-172.17.0.15-1597401330837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39549,DS-ced8b0cc-1a1c-443a-a5f7-72c313837534,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-7c864646-c14c-48da-8e86-282e011cabc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-52766e2c-822f-423e-a4aa-d3b147e2631e,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-988d0269-40c5-4ded-8b5f-55f8d943cd9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43643,DS-67cdc6a4-c032-485a-a422-782b84174807,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-08521040-622e-4f7f-829f-834fc096daba,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-75260704-ee2f-4cc1-b5e1-246075699670,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-80cf28ce-ec8f-494c-b740-588ea41e3d31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-977241279-172.17.0.15-1597401410321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40147,DS-3df5bfcd-3e4d-4642-ada5-ed4ac1a0fe43,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-d2b7c60b-1c4e-4197-8496-3bac32264be9,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-bd0e6888-5358-4bba-87f5-b1422239f7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-7c305e56-cf7a-4eaf-a722-e858ed6d1205,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-48e4e89d-246d-4c6a-af9b-1c2e47fef968,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-f7f0960e-a004-499f-ac17-3faafdb69e08,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-bdc4a146-06e5-4821-8bae-e9e487a6c378,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-c566f2b1-0049-4e18-8b97-25887b67601b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-977241279-172.17.0.15-1597401410321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40147,DS-3df5bfcd-3e4d-4642-ada5-ed4ac1a0fe43,DISK], DatanodeInfoWithStorage[127.0.0.1:38756,DS-d2b7c60b-1c4e-4197-8496-3bac32264be9,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-bd0e6888-5358-4bba-87f5-b1422239f7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-7c305e56-cf7a-4eaf-a722-e858ed6d1205,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-48e4e89d-246d-4c6a-af9b-1c2e47fef968,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-f7f0960e-a004-499f-ac17-3faafdb69e08,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-bdc4a146-06e5-4821-8bae-e9e487a6c378,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-c566f2b1-0049-4e18-8b97-25887b67601b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-793565805-172.17.0.15-1597401917182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45294,DS-0c542df0-bc96-42bd-b758-c2525a7f59ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-6f61156d-f4db-462e-b643-89e77abdf683,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-55223a8a-7bb7-4e78-9f1e-36101994d9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-c432560c-3939-47b4-9902-60b0778db3be,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-9ae0c0f8-d4c6-40eb-8fc6-1c665b23ef1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-faafbe64-be7c-4c74-b60b-f92a12e605cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-792765d8-32ed-4523-90a3-199d237aa7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-519b55dc-88cc-42a7-aa97-3e304b759640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-793565805-172.17.0.15-1597401917182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45294,DS-0c542df0-bc96-42bd-b758-c2525a7f59ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-6f61156d-f4db-462e-b643-89e77abdf683,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-55223a8a-7bb7-4e78-9f1e-36101994d9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-c432560c-3939-47b4-9902-60b0778db3be,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-9ae0c0f8-d4c6-40eb-8fc6-1c665b23ef1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38822,DS-faafbe64-be7c-4c74-b60b-f92a12e605cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-792765d8-32ed-4523-90a3-199d237aa7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-519b55dc-88cc-42a7-aa97-3e304b759640,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382793160-172.17.0.15-1597402533964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35242,DS-60eb980d-86c4-487b-9e60-daaf6725d855,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-0efbfcdf-52ce-4771-86ef-3d9ee48fefd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35943,DS-100762e7-d929-4f9b-82db-b48784d00c77,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-2ec82ff4-8f8a-4e51-8ac8-ab9a7dc57d87,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-a59dfe67-cfe0-431a-a908-1859bf70f2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-887d5857-7b1a-4e4b-8a2a-0ce85cce708f,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-ad3c91ac-11aa-4704-b4c0-86bdd2720784,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-f1221bcb-cf20-4b04-9690-076c34684698,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382793160-172.17.0.15-1597402533964:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35242,DS-60eb980d-86c4-487b-9e60-daaf6725d855,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-0efbfcdf-52ce-4771-86ef-3d9ee48fefd7,DISK], DatanodeInfoWithStorage[127.0.0.1:35943,DS-100762e7-d929-4f9b-82db-b48784d00c77,DISK], DatanodeInfoWithStorage[127.0.0.1:46545,DS-2ec82ff4-8f8a-4e51-8ac8-ab9a7dc57d87,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-a59dfe67-cfe0-431a-a908-1859bf70f2cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34074,DS-887d5857-7b1a-4e4b-8a2a-0ce85cce708f,DISK], DatanodeInfoWithStorage[127.0.0.1:43904,DS-ad3c91ac-11aa-4704-b4c0-86bdd2720784,DISK], DatanodeInfoWithStorage[127.0.0.1:39511,DS-f1221bcb-cf20-4b04-9690-076c34684698,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926944194-172.17.0.15-1597402731210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38534,DS-7cb94b47-9464-46c5-aa34-989f2393731f,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-2a93007a-9118-44c6-86e1-b4001c2e643f,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-f86daadd-f366-4c85-be0a-10b863c2b672,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-0ac41dce-1070-41ca-961a-d40882175bee,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-539ba76b-22f8-42e3-a816-d46180fefc55,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-18f73388-0637-4677-8002-34d009e28a35,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-c734fa9f-b1fe-488a-b719-6413c375b7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-be2f4998-0b37-43a8-ac4e-2dddb69159e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926944194-172.17.0.15-1597402731210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38534,DS-7cb94b47-9464-46c5-aa34-989f2393731f,DISK], DatanodeInfoWithStorage[127.0.0.1:34200,DS-2a93007a-9118-44c6-86e1-b4001c2e643f,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-f86daadd-f366-4c85-be0a-10b863c2b672,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-0ac41dce-1070-41ca-961a-d40882175bee,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-539ba76b-22f8-42e3-a816-d46180fefc55,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-18f73388-0637-4677-8002-34d009e28a35,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-c734fa9f-b1fe-488a-b719-6413c375b7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-be2f4998-0b37-43a8-ac4e-2dddb69159e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: -1
v2: 504
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-987092878-172.17.0.15-1597402938762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44424,DS-8b603744-9311-4fcf-a22b-9083c0979d03,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-537c96ce-1e1e-413f-990a-d50d0eb228e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-78a43414-f7d5-4936-bb30-3d18bc65ec24,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-3a9b5027-ed12-4053-8293-758a0b02f17d,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-08710984-faf8-4039-a2a3-09c4dfad8848,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-3d07aa0d-e51e-4671-9d41-fdc9a9c3c007,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-328780d8-65eb-4deb-b83e-aefbd665bb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-4db4be5a-aa2e-4e56-898b-cfd24f2c9dc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-987092878-172.17.0.15-1597402938762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44424,DS-8b603744-9311-4fcf-a22b-9083c0979d03,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-537c96ce-1e1e-413f-990a-d50d0eb228e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-78a43414-f7d5-4936-bb30-3d18bc65ec24,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-3a9b5027-ed12-4053-8293-758a0b02f17d,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-08710984-faf8-4039-a2a3-09c4dfad8848,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-3d07aa0d-e51e-4671-9d41-fdc9a9c3c007,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-328780d8-65eb-4deb-b83e-aefbd665bb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-4db4be5a-aa2e-4e56-898b-cfd24f2c9dc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5952
