reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2107541468-172.17.0.19-1597399780009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46864,DS-8023d962-6bc6-4e63-9075-aca0ed43ccdc,DISK], DatanodeInfoWithStorage[127.0.0.1:40909,DS-4003a94e-f5df-42a2-ace3-49fc54d9fcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-6a78e34a-f648-48bc-a449-0e536f8b5ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-98c3a4a7-2069-49aa-9859-dcefc84647c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-e47ecf7c-f463-47d9-a928-f3999c4ece69,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-bfb7d983-7317-4792-95af-6bb2c440307f,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-b5b70e69-9d33-4f84-9a8f-180f52aa64fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-fbc205d7-0aa4-4478-9db0-17ddf3f0b020,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2107541468-172.17.0.19-1597399780009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46864,DS-8023d962-6bc6-4e63-9075-aca0ed43ccdc,DISK], DatanodeInfoWithStorage[127.0.0.1:40909,DS-4003a94e-f5df-42a2-ace3-49fc54d9fcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33345,DS-6a78e34a-f648-48bc-a449-0e536f8b5ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-98c3a4a7-2069-49aa-9859-dcefc84647c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-e47ecf7c-f463-47d9-a928-f3999c4ece69,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-bfb7d983-7317-4792-95af-6bb2c440307f,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-b5b70e69-9d33-4f84-9a8f-180f52aa64fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33208,DS-fbc205d7-0aa4-4478-9db0-17ddf3f0b020,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442084707-172.17.0.19-1597400855194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36131,DS-6e552e1c-76d0-43b5-b90f-681c562d3459,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-61d16371-6f38-489b-91ea-3fcc9c9ee851,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-07766c41-2798-475d-b5d5-4524a5e67838,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-3b6e82ad-eb6a-4a76-a580-acfcde7be1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-2a04abad-cc85-46d6-b5c5-2c3350c0ac7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-585452ea-88a0-484d-9128-330b840f5eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-12035227-58f1-4236-ae0f-a8cb214d16a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-7c51a612-aee3-44d3-aaa0-da78ca0e0a74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442084707-172.17.0.19-1597400855194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36131,DS-6e552e1c-76d0-43b5-b90f-681c562d3459,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-61d16371-6f38-489b-91ea-3fcc9c9ee851,DISK], DatanodeInfoWithStorage[127.0.0.1:42220,DS-07766c41-2798-475d-b5d5-4524a5e67838,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-3b6e82ad-eb6a-4a76-a580-acfcde7be1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-2a04abad-cc85-46d6-b5c5-2c3350c0ac7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-585452ea-88a0-484d-9128-330b840f5eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-12035227-58f1-4236-ae0f-a8cb214d16a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-7c51a612-aee3-44d3-aaa0-da78ca0e0a74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1635195286-172.17.0.19-1597401036784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45850,DS-08eb0366-78f6-41e6-91e0-309a4c035d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-0a0e151e-4d5d-466c-b977-a5516c8a9d30,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-7ba43f12-6635-4c59-8a76-cbbf57af9a20,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-ccd5b0f5-dd82-4cee-b34e-c9cd9f5a055b,DISK], DatanodeInfoWithStorage[127.0.0.1:46313,DS-e11b12af-acd3-43c4-b7a9-f853d6b8c9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-0d19ee95-3bef-4c61-87c6-9d6b620af343,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-c5db9622-21db-47b4-8c35-6fd9c589dafc,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-69f4b22e-a429-4f30-a5cc-8b06e8ab9329,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1635195286-172.17.0.19-1597401036784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45850,DS-08eb0366-78f6-41e6-91e0-309a4c035d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-0a0e151e-4d5d-466c-b977-a5516c8a9d30,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-7ba43f12-6635-4c59-8a76-cbbf57af9a20,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-ccd5b0f5-dd82-4cee-b34e-c9cd9f5a055b,DISK], DatanodeInfoWithStorage[127.0.0.1:46313,DS-e11b12af-acd3-43c4-b7a9-f853d6b8c9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-0d19ee95-3bef-4c61-87c6-9d6b620af343,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-c5db9622-21db-47b4-8c35-6fd9c589dafc,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-69f4b22e-a429-4f30-a5cc-8b06e8ab9329,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1803446476-172.17.0.19-1597401654126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44394,DS-805d5d3e-da08-4bf0-8dc4-4ea091d2a2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-3f8228ae-2ea8-4f1a-8b4a-18c5e58b2133,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-0e4e3b4a-06be-4fec-bef1-4c93e78a1906,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-ff3c8a63-9179-4513-b3b0-690e2db3cfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-9ead4f14-22dc-4766-badd-9f37c829b217,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-2a555b27-3e53-46e4-b550-24b0dec3d529,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-3945901d-9afe-4acb-b542-465ec83a0899,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-e3e9495f-6515-46bc-b38d-51d8b60c2052,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1803446476-172.17.0.19-1597401654126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44394,DS-805d5d3e-da08-4bf0-8dc4-4ea091d2a2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-3f8228ae-2ea8-4f1a-8b4a-18c5e58b2133,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-0e4e3b4a-06be-4fec-bef1-4c93e78a1906,DISK], DatanodeInfoWithStorage[127.0.0.1:35055,DS-ff3c8a63-9179-4513-b3b0-690e2db3cfcb,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-9ead4f14-22dc-4766-badd-9f37c829b217,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-2a555b27-3e53-46e4-b550-24b0dec3d529,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-3945901d-9afe-4acb-b542-465ec83a0899,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-e3e9495f-6515-46bc-b38d-51d8b60c2052,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182513579-172.17.0.19-1597401919903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39882,DS-d1dfa858-a40d-42cf-8477-f6c00ec37517,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-256db516-0717-4979-afaa-14aa4b4df985,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-cbe5b03d-3db7-4f3f-ba19-1ad525830ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-38024f7d-5540-4c8a-b110-efc018019236,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-ad7a3e33-ac04-419f-87e7-869efb14052b,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-46077400-ba8b-456f-bba0-4598cd68938b,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-19f8ae9b-1692-415f-b3f2-61ce763f261e,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-f66d76fc-8ece-41fe-99f9-36be426919f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182513579-172.17.0.19-1597401919903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39882,DS-d1dfa858-a40d-42cf-8477-f6c00ec37517,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-256db516-0717-4979-afaa-14aa4b4df985,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-cbe5b03d-3db7-4f3f-ba19-1ad525830ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-38024f7d-5540-4c8a-b110-efc018019236,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-ad7a3e33-ac04-419f-87e7-869efb14052b,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-46077400-ba8b-456f-bba0-4598cd68938b,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-19f8ae9b-1692-415f-b3f2-61ce763f261e,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-f66d76fc-8ece-41fe-99f9-36be426919f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-4428787-172.17.0.19-1597402104828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39873,DS-a5ee2c4c-6ed8-464b-8de3-e8e2d5c7b2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-e25607e8-f986-413f-81da-09b197e17332,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-30c74538-f76d-491c-9ed2-42f1307ff503,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-f095b783-26e2-40f1-8c3f-76390b8bf2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-ff8fb17c-0085-4071-b6be-b8188fcca211,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-ba0c06d2-7694-4291-8828-e23c5de0ed9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-47880ef0-c03e-4fa1-a36e-4cdd3c911952,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-9c86373a-fbae-41f9-8f61-f15f11912f78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-4428787-172.17.0.19-1597402104828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39873,DS-a5ee2c4c-6ed8-464b-8de3-e8e2d5c7b2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-e25607e8-f986-413f-81da-09b197e17332,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-30c74538-f76d-491c-9ed2-42f1307ff503,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-f095b783-26e2-40f1-8c3f-76390b8bf2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-ff8fb17c-0085-4071-b6be-b8188fcca211,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-ba0c06d2-7694-4291-8828-e23c5de0ed9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-47880ef0-c03e-4fa1-a36e-4cdd3c911952,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-9c86373a-fbae-41f9-8f61-f15f11912f78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1117147322-172.17.0.19-1597402142295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34445,DS-1f95c49b-1945-4acd-b817-2cf7bbf096fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-c8ba5bac-1252-4a61-acfd-3160544942c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-7e90fbdc-4efd-4b96-8f4d-3192a986db7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-10ee820d-2f18-449b-9eb6-e68377f6e35e,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-67c45e7a-5719-421a-934f-dba652ecfb87,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-34e07839-7523-4bbb-bd9d-f468f2769b22,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-74da55b1-9c71-4bcc-9270-f7d2737eea7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-4fc839f9-c0b9-47bb-a02e-8818b6419e4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1117147322-172.17.0.19-1597402142295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34445,DS-1f95c49b-1945-4acd-b817-2cf7bbf096fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-c8ba5bac-1252-4a61-acfd-3160544942c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-7e90fbdc-4efd-4b96-8f4d-3192a986db7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-10ee820d-2f18-449b-9eb6-e68377f6e35e,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-67c45e7a-5719-421a-934f-dba652ecfb87,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-34e07839-7523-4bbb-bd9d-f468f2769b22,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-74da55b1-9c71-4bcc-9270-f7d2737eea7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-4fc839f9-c0b9-47bb-a02e-8818b6419e4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-126848076-172.17.0.19-1597402297027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42180,DS-6cadafc9-0f9f-4a92-a9b4-10e5ad05c9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-ad562a62-1155-4d03-900f-50454e214b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-ebc3ae4a-a97f-4b92-875f-aa35230e9637,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-bc4fb4e5-25e5-45a7-96a0-a3d211c1b27e,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-31b198d9-a555-40c1-b4b0-657108bb4277,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-14f18685-0485-450c-9afb-e8fd43c4d04b,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-25e85bcd-4db3-480e-b097-9412e00564e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-c02dd5fc-a3be-4fc5-bed9-2551fdbcaf4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-126848076-172.17.0.19-1597402297027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42180,DS-6cadafc9-0f9f-4a92-a9b4-10e5ad05c9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-ad562a62-1155-4d03-900f-50454e214b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-ebc3ae4a-a97f-4b92-875f-aa35230e9637,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-bc4fb4e5-25e5-45a7-96a0-a3d211c1b27e,DISK], DatanodeInfoWithStorage[127.0.0.1:35081,DS-31b198d9-a555-40c1-b4b0-657108bb4277,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-14f18685-0485-450c-9afb-e8fd43c4d04b,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-25e85bcd-4db3-480e-b097-9412e00564e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-c02dd5fc-a3be-4fc5-bed9-2551fdbcaf4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1594228318-172.17.0.19-1597402337709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38546,DS-26000e17-4b35-4f99-9469-b794f7c27155,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-87a774c5-2eaf-4e04-bdaa-d3686e5d0d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-9ae1d4ae-3371-48a4-9bcb-1cfe26f52dff,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-f84a83f7-7b03-4c08-b79d-e25a162e2e09,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-315d540f-6797-4d37-9565-09c7bcfb0037,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-10aadfb2-2ab5-43e3-a642-82f68ecfd85d,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-08274ceb-c0a6-49c0-ae46-dfd43475ee49,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-a7e7167a-beb2-44ac-89c3-f75c37fde3d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1594228318-172.17.0.19-1597402337709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38546,DS-26000e17-4b35-4f99-9469-b794f7c27155,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-87a774c5-2eaf-4e04-bdaa-d3686e5d0d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-9ae1d4ae-3371-48a4-9bcb-1cfe26f52dff,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-f84a83f7-7b03-4c08-b79d-e25a162e2e09,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-315d540f-6797-4d37-9565-09c7bcfb0037,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-10aadfb2-2ab5-43e3-a642-82f68ecfd85d,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-08274ceb-c0a6-49c0-ae46-dfd43475ee49,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-a7e7167a-beb2-44ac-89c3-f75c37fde3d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1426872855-172.17.0.19-1597402642229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45074,DS-96564ef5-8872-4b74-a953-a07d9592df34,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-d6146a42-dc62-44aa-bce8-ad25396b203f,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-45ab990d-faaf-4791-9eea-6c252ff55814,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-3a300f7c-29ee-417c-94e3-aa1b6562d89b,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-f3d9f04a-43a7-497f-a07b-bcd3598bab53,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-ab62455a-c603-44cf-a77f-dac61dbae94a,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-8d8d39a1-5a23-452a-be78-a5dc16d32f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-f4290e69-cc40-454d-9c1a-2a9b87abe3ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1426872855-172.17.0.19-1597402642229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45074,DS-96564ef5-8872-4b74-a953-a07d9592df34,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-d6146a42-dc62-44aa-bce8-ad25396b203f,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-45ab990d-faaf-4791-9eea-6c252ff55814,DISK], DatanodeInfoWithStorage[127.0.0.1:46041,DS-3a300f7c-29ee-417c-94e3-aa1b6562d89b,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-f3d9f04a-43a7-497f-a07b-bcd3598bab53,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-ab62455a-c603-44cf-a77f-dac61dbae94a,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-8d8d39a1-5a23-452a-be78-a5dc16d32f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-f4290e69-cc40-454d-9c1a-2a9b87abe3ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595048887-172.17.0.19-1597402792587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33234,DS-900fa809-a5ef-48da-839e-f8d0c60a6f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-4bc6d07b-cfcc-4aee-8bcf-7f92cc5a9955,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-7879ddb9-e97c-4551-8d1e-33ae3668b7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-a526b6cd-b270-45ea-af73-a9813edfc8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-4d566ff0-843a-47d7-bb88-2312685702b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-e5bb6c45-4667-404b-a2cb-b085c8e4e6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-cd0fafa4-9864-4b23-8b4d-6b9f76b44730,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-3910d75c-794c-4535-9fb3-56611b75e1d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1595048887-172.17.0.19-1597402792587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33234,DS-900fa809-a5ef-48da-839e-f8d0c60a6f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-4bc6d07b-cfcc-4aee-8bcf-7f92cc5a9955,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-7879ddb9-e97c-4551-8d1e-33ae3668b7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-a526b6cd-b270-45ea-af73-a9813edfc8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-4d566ff0-843a-47d7-bb88-2312685702b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-e5bb6c45-4667-404b-a2cb-b085c8e4e6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-cd0fafa4-9864-4b23-8b4d-6b9f76b44730,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-3910d75c-794c-4535-9fb3-56611b75e1d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1747269232-172.17.0.19-1597402954770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44603,DS-2a7bda91-b1ef-4bf2-aa9c-d20fae024542,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-f55771b2-fe83-49bb-84fb-3eab61e97ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-7659cb70-3592-4e59-acd8-5f7f381c7833,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-bcaa59ec-c890-43ba-b0fb-196fed798dda,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-9cc18a89-c3f4-4e9f-a74c-c168f03f6ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-cdd37923-abde-486d-8f26-9aa9070558ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-7118f607-ef0b-40e0-9f18-1ab65a83be34,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-f521ff8a-f17c-41e6-a0d8-e18269470524,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1747269232-172.17.0.19-1597402954770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44603,DS-2a7bda91-b1ef-4bf2-aa9c-d20fae024542,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-f55771b2-fe83-49bb-84fb-3eab61e97ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-7659cb70-3592-4e59-acd8-5f7f381c7833,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-bcaa59ec-c890-43ba-b0fb-196fed798dda,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-9cc18a89-c3f4-4e9f-a74c-c168f03f6ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-cdd37923-abde-486d-8f26-9aa9070558ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-7118f607-ef0b-40e0-9f18-1ab65a83be34,DISK], DatanodeInfoWithStorage[127.0.0.1:43478,DS-f521ff8a-f17c-41e6-a0d8-e18269470524,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-457618621-172.17.0.19-1597403077280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40249,DS-d0996249-cae5-42d0-9182-01ff7e5966e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-7926e3a6-de01-49e4-8d79-74fda5dd4494,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-3d66dea1-22e7-4554-9193-6d4869325473,DISK], DatanodeInfoWithStorage[127.0.0.1:43419,DS-43909f55-4a0e-48f9-b021-b49995f203eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-229737e7-d039-4ca3-bab7-4c469b14764c,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-b1efcbe1-287b-4eb8-8069-58c0bf04ddb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-fd6afb1d-c130-4634-a649-f83dbae6243c,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-2a118af7-8bb0-420a-ab4e-667189318d92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-457618621-172.17.0.19-1597403077280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40249,DS-d0996249-cae5-42d0-9182-01ff7e5966e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-7926e3a6-de01-49e4-8d79-74fda5dd4494,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-3d66dea1-22e7-4554-9193-6d4869325473,DISK], DatanodeInfoWithStorage[127.0.0.1:43419,DS-43909f55-4a0e-48f9-b021-b49995f203eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44246,DS-229737e7-d039-4ca3-bab7-4c469b14764c,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-b1efcbe1-287b-4eb8-8069-58c0bf04ddb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36551,DS-fd6afb1d-c130-4634-a649-f83dbae6243c,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-2a118af7-8bb0-420a-ab4e-667189318d92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851227195-172.17.0.19-1597403494394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35644,DS-54def3eb-e56c-4318-8858-cdc685c57eca,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-35e428af-07e9-40d7-93a7-94ae9234f90e,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-3a4e6c45-e14b-4c54-a3d5-ad6f5c4d2b63,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-9a6e3c01-691d-4182-b2ca-c8005f4c394f,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-259f8be2-3bd3-427a-a3d5-ffe29efc02ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-cfd36361-8566-4b5d-aaa5-731a8e793cae,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-d40d677a-d69c-416c-98b7-797713734902,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-d0466161-33cc-4695-b75e-a7168486bdd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851227195-172.17.0.19-1597403494394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35644,DS-54def3eb-e56c-4318-8858-cdc685c57eca,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-35e428af-07e9-40d7-93a7-94ae9234f90e,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-3a4e6c45-e14b-4c54-a3d5-ad6f5c4d2b63,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-9a6e3c01-691d-4182-b2ca-c8005f4c394f,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-259f8be2-3bd3-427a-a3d5-ffe29efc02ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-cfd36361-8566-4b5d-aaa5-731a8e793cae,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-d40d677a-d69c-416c-98b7-797713734902,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-d0466161-33cc-4695-b75e-a7168486bdd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1882387599-172.17.0.19-1597404421756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45477,DS-21691e40-5cc3-4ea8-8b0f-ea7b0ee4f77d,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-aabbc4b3-18c6-4ed8-afb9-df2d19e7e60f,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-4f5a3356-d93f-4817-89ff-81d8a23c6fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-6640b8c3-6ed7-430b-ae33-d0d534994935,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-159ed109-f732-4894-94b9-e1a0ca4eb22d,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-f78f5618-9a41-480d-a624-e8723eca1e86,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-285a00ae-81ef-42f8-a2f9-5b78bb0ee6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-dbac68f3-8551-429e-b359-70b1003e83d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1882387599-172.17.0.19-1597404421756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45477,DS-21691e40-5cc3-4ea8-8b0f-ea7b0ee4f77d,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-aabbc4b3-18c6-4ed8-afb9-df2d19e7e60f,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-4f5a3356-d93f-4817-89ff-81d8a23c6fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-6640b8c3-6ed7-430b-ae33-d0d534994935,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-159ed109-f732-4894-94b9-e1a0ca4eb22d,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-f78f5618-9a41-480d-a624-e8723eca1e86,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-285a00ae-81ef-42f8-a2f9-5b78bb0ee6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-dbac68f3-8551-429e-b359-70b1003e83d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-903414973-172.17.0.19-1597404457630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32850,DS-70e81a01-162b-451b-8b9d-873761ce8d60,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-abf22e11-90e6-4c10-a4f7-538f5f510c95,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-9de31430-9381-4d83-a848-4d45c564423c,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-7fec1e25-765a-49c0-b8bb-52716163537b,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-e3eeb8cc-2a97-422a-a449-0bedfb3b619b,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-887617c5-4dcc-4031-853c-a79d79fa6fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-81993e63-b93e-4bb0-9a04-1f4073487976,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-89494861-fca3-469c-8df2-3dd1188bc254,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-903414973-172.17.0.19-1597404457630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32850,DS-70e81a01-162b-451b-8b9d-873761ce8d60,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-abf22e11-90e6-4c10-a4f7-538f5f510c95,DISK], DatanodeInfoWithStorage[127.0.0.1:33554,DS-9de31430-9381-4d83-a848-4d45c564423c,DISK], DatanodeInfoWithStorage[127.0.0.1:36749,DS-7fec1e25-765a-49c0-b8bb-52716163537b,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-e3eeb8cc-2a97-422a-a449-0bedfb3b619b,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-887617c5-4dcc-4031-853c-a79d79fa6fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-81993e63-b93e-4bb0-9a04-1f4073487976,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-89494861-fca3-469c-8df2-3dd1188bc254,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-59298194-172.17.0.19-1597404680333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40746,DS-fd19c60d-952d-4b8f-93fe-bbd83eafdd58,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-139d5ca1-00d8-4376-8129-5e9bb08a1626,DISK], DatanodeInfoWithStorage[127.0.0.1:35091,DS-91c761c5-5498-4dcd-a495-966a51523b92,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-454eebec-009a-46fe-ad3d-a6b2f323fa93,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-623ddd3d-c44c-4638-af5f-30ef09071048,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-63da3381-5fc0-48ba-8147-6793bcd2152e,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-646f698b-2da0-408a-ab38-cc1daf377fed,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-9e8d3cd1-e4fa-41dd-b29e-bbc7312f7cc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-59298194-172.17.0.19-1597404680333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40746,DS-fd19c60d-952d-4b8f-93fe-bbd83eafdd58,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-139d5ca1-00d8-4376-8129-5e9bb08a1626,DISK], DatanodeInfoWithStorage[127.0.0.1:35091,DS-91c761c5-5498-4dcd-a495-966a51523b92,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-454eebec-009a-46fe-ad3d-a6b2f323fa93,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-623ddd3d-c44c-4638-af5f-30ef09071048,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-63da3381-5fc0-48ba-8147-6793bcd2152e,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-646f698b-2da0-408a-ab38-cc1daf377fed,DISK], DatanodeInfoWithStorage[127.0.0.1:43561,DS-9e8d3cd1-e4fa-41dd-b29e-bbc7312f7cc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 600
v2: 300
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-615583405-172.17.0.19-1597405434521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36791,DS-84f32751-a355-42aa-94ec-653314379118,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-8efb790f-29da-455c-9600-ebd67804b1be,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-437cfc4b-0a09-48e1-b689-3c2a02a93109,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-8267cf09-bf71-4ae8-b20e-941f10d9df7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-1902fa0c-db0c-4839-8fc4-a09deccca1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-24bdb601-9b22-41ed-b6dd-5d677ccf8ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-4f4bf58d-caf8-49ff-83ae-092b771c7fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-68f8a78b-1ba7-4a9d-94c7-55ee77c052ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-615583405-172.17.0.19-1597405434521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36791,DS-84f32751-a355-42aa-94ec-653314379118,DISK], DatanodeInfoWithStorage[127.0.0.1:33515,DS-8efb790f-29da-455c-9600-ebd67804b1be,DISK], DatanodeInfoWithStorage[127.0.0.1:37804,DS-437cfc4b-0a09-48e1-b689-3c2a02a93109,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-8267cf09-bf71-4ae8-b20e-941f10d9df7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-1902fa0c-db0c-4839-8fc4-a09deccca1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-24bdb601-9b22-41ed-b6dd-5d677ccf8ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:46207,DS-4f4bf58d-caf8-49ff-83ae-092b771c7fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-68f8a78b-1ba7-4a9d-94c7-55ee77c052ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5748
