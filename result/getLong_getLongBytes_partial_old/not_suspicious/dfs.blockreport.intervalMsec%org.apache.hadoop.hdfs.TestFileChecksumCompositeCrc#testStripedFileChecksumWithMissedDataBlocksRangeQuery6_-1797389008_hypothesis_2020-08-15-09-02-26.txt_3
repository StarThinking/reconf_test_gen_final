reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545451496-172.17.0.9-1597482333940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45801,DS-58c73b1e-0c4e-431b-b00a-242cc720e2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-9d3198e8-e086-4792-808e-c32ae832acb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35352,DS-3634c801-0596-4c72-a81f-57495b264d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-7d9bf482-3e13-468a-bf87-d1d4c0730f43,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-999ff0c8-7464-4849-8cca-7227babc6ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-32465d4d-547c-4d34-9e85-b8df9c5a72c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-9b83d22d-3c6e-4d19-9891-377eb2fad2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-2e41880e-2286-4365-87c2-54b8717eb975,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545451496-172.17.0.9-1597482333940:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45801,DS-58c73b1e-0c4e-431b-b00a-242cc720e2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-9d3198e8-e086-4792-808e-c32ae832acb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35352,DS-3634c801-0596-4c72-a81f-57495b264d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-7d9bf482-3e13-468a-bf87-d1d4c0730f43,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-999ff0c8-7464-4849-8cca-7227babc6ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-32465d4d-547c-4d34-9e85-b8df9c5a72c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46563,DS-9b83d22d-3c6e-4d19-9891-377eb2fad2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-2e41880e-2286-4365-87c2-54b8717eb975,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934693547-172.17.0.9-1597482368731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42790,DS-448907a0-114a-4da8-948e-273ae50d0dba,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-ec6ae549-6ad8-45ea-8938-3b20edefaf27,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-7a16a40d-1ac6-48ad-98fa-f12457e0c6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-5d71feac-53a4-443c-831a-381619911041,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-a06142f4-a8a7-42e9-a0cc-f94a0fd2c9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-fee222cf-bc1a-462e-b2cd-20a14969e205,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-e52aeb1e-e73e-40e8-970c-40a7749b21e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-09ba60ec-4e42-41b9-ac41-fbf335e40814,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934693547-172.17.0.9-1597482368731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42790,DS-448907a0-114a-4da8-948e-273ae50d0dba,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-ec6ae549-6ad8-45ea-8938-3b20edefaf27,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-7a16a40d-1ac6-48ad-98fa-f12457e0c6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-5d71feac-53a4-443c-831a-381619911041,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-a06142f4-a8a7-42e9-a0cc-f94a0fd2c9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39494,DS-fee222cf-bc1a-462e-b2cd-20a14969e205,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-e52aeb1e-e73e-40e8-970c-40a7749b21e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-09ba60ec-4e42-41b9-ac41-fbf335e40814,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-988367456-172.17.0.9-1597482405491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35682,DS-3554d2f0-a080-4b30-83d9-350a0052eac1,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-509bf609-5286-4934-ada1-19e5e7ffe3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-df9f25da-afc9-4ca3-9379-d9600ab89e59,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-fc55288c-559d-47f1-9bff-23b714697e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-1d523d0e-d715-4f80-8fea-28126a6ef1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-5dd69a3e-45dc-40f9-bae3-53f0f27f9deb,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-2ae687b7-c308-402e-98bb-3ab580c8d933,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-71ef20c0-ec8c-4e6b-babf-46c881902408,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-988367456-172.17.0.9-1597482405491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35682,DS-3554d2f0-a080-4b30-83d9-350a0052eac1,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-509bf609-5286-4934-ada1-19e5e7ffe3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-df9f25da-afc9-4ca3-9379-d9600ab89e59,DISK], DatanodeInfoWithStorage[127.0.0.1:43902,DS-fc55288c-559d-47f1-9bff-23b714697e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36992,DS-1d523d0e-d715-4f80-8fea-28126a6ef1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-5dd69a3e-45dc-40f9-bae3-53f0f27f9deb,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-2ae687b7-c308-402e-98bb-3ab580c8d933,DISK], DatanodeInfoWithStorage[127.0.0.1:38497,DS-71ef20c0-ec8c-4e6b-babf-46c881902408,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1889508770-172.17.0.9-1597482439634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43792,DS-e096e6e1-0bd6-40e3-8a64-ad0330ddf9de,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-d4e4bd09-09d2-422d-b177-e1b168372180,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-703d1068-0c94-40a0-89a2-2fd8f732308a,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-70a5d6d6-cd53-43a6-9b91-a2ccd6e36ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-1978b472-4c1c-44be-b965-f5639bab0ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-5df5b1fe-9ace-4f18-8156-6a76f3b77ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-29e9c8b6-2d87-43d2-8862-6a2267994fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-49f9fdb7-7787-476d-8905-4c59aae0f404,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1889508770-172.17.0.9-1597482439634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43792,DS-e096e6e1-0bd6-40e3-8a64-ad0330ddf9de,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-d4e4bd09-09d2-422d-b177-e1b168372180,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-703d1068-0c94-40a0-89a2-2fd8f732308a,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-70a5d6d6-cd53-43a6-9b91-a2ccd6e36ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:46695,DS-1978b472-4c1c-44be-b965-f5639bab0ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-5df5b1fe-9ace-4f18-8156-6a76f3b77ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-29e9c8b6-2d87-43d2-8862-6a2267994fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-49f9fdb7-7787-476d-8905-4c59aae0f404,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1601934115-172.17.0.9-1597482477417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33203,DS-3ed9c290-892f-48b2-9650-788878167504,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-5a0ebe73-9e8f-4eb0-b596-eb55179de433,DISK], DatanodeInfoWithStorage[127.0.0.1:33046,DS-da592fa3-66fa-40ad-8a70-3a3d42e2ad36,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-ce4e7230-a889-4097-a7de-00872357b519,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-adb7c990-d7d5-4b02-8dc0-7252ec17f0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46799,DS-94b2eccd-51ad-45b5-9f45-7a5f63065db2,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-ced7b978-00b3-4bf3-976a-82044b1fa3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-3235749e-8243-4ee1-841e-d0475a5b7d87,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1601934115-172.17.0.9-1597482477417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33203,DS-3ed9c290-892f-48b2-9650-788878167504,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-5a0ebe73-9e8f-4eb0-b596-eb55179de433,DISK], DatanodeInfoWithStorage[127.0.0.1:33046,DS-da592fa3-66fa-40ad-8a70-3a3d42e2ad36,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-ce4e7230-a889-4097-a7de-00872357b519,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-adb7c990-d7d5-4b02-8dc0-7252ec17f0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46799,DS-94b2eccd-51ad-45b5-9f45-7a5f63065db2,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-ced7b978-00b3-4bf3-976a-82044b1fa3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44086,DS-3235749e-8243-4ee1-841e-d0475a5b7d87,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-569027059-172.17.0.9-1597482654541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38786,DS-d49d0421-7002-44ab-b1fe-7e8c4e8fa423,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-47aca0a8-b963-4053-ac35-3efaa4d797c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-776b4e98-aa98-475e-a049-b1e571285067,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-d90bc32d-f2b6-4cde-96bf-d408921d94f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-0b4f77ce-a179-4dd5-a79e-6745c9323753,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-7db6d0cd-4133-4a08-b8dd-2dddfddb4871,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-6f1ff46c-4862-4a6e-b535-ad47ef6c6b54,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-5148c714-ef3a-4c75-a42e-641aa6123ae7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-569027059-172.17.0.9-1597482654541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38786,DS-d49d0421-7002-44ab-b1fe-7e8c4e8fa423,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-47aca0a8-b963-4053-ac35-3efaa4d797c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-776b4e98-aa98-475e-a049-b1e571285067,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-d90bc32d-f2b6-4cde-96bf-d408921d94f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39081,DS-0b4f77ce-a179-4dd5-a79e-6745c9323753,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-7db6d0cd-4133-4a08-b8dd-2dddfddb4871,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-6f1ff46c-4862-4a6e-b535-ad47ef6c6b54,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-5148c714-ef3a-4c75-a42e-641aa6123ae7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1794371711-172.17.0.9-1597483158924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38084,DS-7b285a6a-77a5-4dad-94bd-5ee65d5c479c,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-7c83d5a9-8a40-4c03-be64-6ef672c332aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-7a44695c-e16f-400d-a6d4-53a1dc0917ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-c7072e0d-d35e-452e-a7ee-cccb1846cabf,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-ace6fbb9-269b-4821-a77d-a4a696b75fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-bfdae7b6-a589-4c79-9a7a-b5261ece5711,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-5fe2e3be-33cd-4d23-9536-36c4c0b65a91,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-733b111f-5f88-4ed3-85f5-b720aa949756,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1794371711-172.17.0.9-1597483158924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38084,DS-7b285a6a-77a5-4dad-94bd-5ee65d5c479c,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-7c83d5a9-8a40-4c03-be64-6ef672c332aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-7a44695c-e16f-400d-a6d4-53a1dc0917ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-c7072e0d-d35e-452e-a7ee-cccb1846cabf,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-ace6fbb9-269b-4821-a77d-a4a696b75fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-bfdae7b6-a589-4c79-9a7a-b5261ece5711,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-5fe2e3be-33cd-4d23-9536-36c4c0b65a91,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-733b111f-5f88-4ed3-85f5-b720aa949756,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1468427066-172.17.0.9-1597483200355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44429,DS-58b69af1-90e3-450f-9e5e-f5a4720fb0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-e0b14bb0-ac2a-4908-947b-920b16d8af73,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-03bc3001-a695-4ab1-9bbf-1525db7c5081,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-ccfcd034-348c-4309-b531-ce174787f625,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-8840d96c-fe00-4331-af6d-bb6b9bf73b48,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-6544154e-6149-416b-8aba-e579bbd37fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-8d6ef634-444b-43dd-9725-a864dcaf72ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-f8e2797b-85d7-4be4-a5e6-3930d3b08ae6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1468427066-172.17.0.9-1597483200355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44429,DS-58b69af1-90e3-450f-9e5e-f5a4720fb0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38956,DS-e0b14bb0-ac2a-4908-947b-920b16d8af73,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-03bc3001-a695-4ab1-9bbf-1525db7c5081,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-ccfcd034-348c-4309-b531-ce174787f625,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-8840d96c-fe00-4331-af6d-bb6b9bf73b48,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-6544154e-6149-416b-8aba-e579bbd37fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-8d6ef634-444b-43dd-9725-a864dcaf72ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-f8e2797b-85d7-4be4-a5e6-3930d3b08ae6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1483508567-172.17.0.9-1597483286960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42214,DS-b72d34bf-2994-40c4-916b-e349f31b1c42,DISK], DatanodeInfoWithStorage[127.0.0.1:43169,DS-9e3e186b-e418-4961-9647-1780ad488baf,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-3f204fa4-20df-435c-a438-5181dd5fae7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39609,DS-1166cb2b-78e9-4c9b-92cb-2bec490b70b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-de9f56d3-7072-4cb3-95fe-dac9f4094b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43937,DS-2f86ea78-a60d-482d-9adf-f30be6fe1d21,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-3a0240e2-7659-4e3b-97a9-58707b18a22b,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-9627dd00-8093-4366-b639-e89bec21f394,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1483508567-172.17.0.9-1597483286960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42214,DS-b72d34bf-2994-40c4-916b-e349f31b1c42,DISK], DatanodeInfoWithStorage[127.0.0.1:43169,DS-9e3e186b-e418-4961-9647-1780ad488baf,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-3f204fa4-20df-435c-a438-5181dd5fae7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39609,DS-1166cb2b-78e9-4c9b-92cb-2bec490b70b4,DISK], DatanodeInfoWithStorage[127.0.0.1:46291,DS-de9f56d3-7072-4cb3-95fe-dac9f4094b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43937,DS-2f86ea78-a60d-482d-9adf-f30be6fe1d21,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-3a0240e2-7659-4e3b-97a9-58707b18a22b,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-9627dd00-8093-4366-b639-e89bec21f394,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210643473-172.17.0.9-1597483896617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37762,DS-37df8b0a-91ee-4ca1-8f7c-eaa015992bac,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-d37b582f-2500-4fd5-9e71-bdc004f8e75d,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-5093df02-95f8-4f5f-b7e7-be48e8c8db2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-c50cdc5f-77a0-464c-bfd6-cd80ab31785b,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-55814faf-e672-45e5-8d9a-5482352fb3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-a7fee073-7ac0-42f5-af84-3eb54df65a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-e20f263f-f645-4b1d-af3d-712935033996,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-b2a24670-e5c7-4616-a1b7-39ed2d3ca1ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210643473-172.17.0.9-1597483896617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37762,DS-37df8b0a-91ee-4ca1-8f7c-eaa015992bac,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-d37b582f-2500-4fd5-9e71-bdc004f8e75d,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-5093df02-95f8-4f5f-b7e7-be48e8c8db2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40896,DS-c50cdc5f-77a0-464c-bfd6-cd80ab31785b,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-55814faf-e672-45e5-8d9a-5482352fb3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-a7fee073-7ac0-42f5-af84-3eb54df65a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-e20f263f-f645-4b1d-af3d-712935033996,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-b2a24670-e5c7-4616-a1b7-39ed2d3ca1ab,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2033803192-172.17.0.9-1597484466942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46262,DS-9628d44e-e073-424e-9437-2bacaa4d97ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-a96071e6-3627-4b41-9140-b5a223f1de68,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-2ca1fc4b-8606-4e99-b21b-9f655109e6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-dacdcc43-a056-48e7-b0f5-5636a8ced0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-20026196-f0a6-45d6-b5c3-a1ad8f81ed09,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-b4cbbca4-f6ed-4aed-8035-463ccc3350f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-35cb26b4-cae9-49fc-a292-1b94d0d55003,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-612192b3-06e5-45a9-bbe8-5b7cb1e14458,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2033803192-172.17.0.9-1597484466942:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46262,DS-9628d44e-e073-424e-9437-2bacaa4d97ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-a96071e6-3627-4b41-9140-b5a223f1de68,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-2ca1fc4b-8606-4e99-b21b-9f655109e6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44706,DS-dacdcc43-a056-48e7-b0f5-5636a8ced0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43171,DS-20026196-f0a6-45d6-b5c3-a1ad8f81ed09,DISK], DatanodeInfoWithStorage[127.0.0.1:33698,DS-b4cbbca4-f6ed-4aed-8035-463ccc3350f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33852,DS-35cb26b4-cae9-49fc-a292-1b94d0d55003,DISK], DatanodeInfoWithStorage[127.0.0.1:45018,DS-612192b3-06e5-45a9-bbe8-5b7cb1e14458,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-922882868-172.17.0.9-1597484598402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37731,DS-bf6e3115-cf0d-4c0c-8c7e-cb4cd98de1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-40f5e1d3-bdbf-4187-8782-dc813b3a682e,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-f439e540-e022-4ea0-a603-5df250e4bca1,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-2e32c1f0-1688-4b78-9216-ff7432be1a62,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-ff7c33ba-14bf-4a78-9c99-926ab8dc30e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-c0d66201-4225-4690-bd77-f5df03f83f58,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-73983bbc-4bd2-48db-9197-b62e497a53f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-48a16003-635d-4878-8cca-ded735cd99a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-922882868-172.17.0.9-1597484598402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37731,DS-bf6e3115-cf0d-4c0c-8c7e-cb4cd98de1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-40f5e1d3-bdbf-4187-8782-dc813b3a682e,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-f439e540-e022-4ea0-a603-5df250e4bca1,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-2e32c1f0-1688-4b78-9216-ff7432be1a62,DISK], DatanodeInfoWithStorage[127.0.0.1:44945,DS-ff7c33ba-14bf-4a78-9c99-926ab8dc30e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-c0d66201-4225-4690-bd77-f5df03f83f58,DISK], DatanodeInfoWithStorage[127.0.0.1:34453,DS-73983bbc-4bd2-48db-9197-b62e497a53f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-48a16003-635d-4878-8cca-ded735cd99a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-833247881-172.17.0.9-1597484752630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46732,DS-ae61ca44-309d-429a-a32d-252267653d33,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-013e6038-2de1-4d7d-a189-1c06cd4cfb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-2712c3f3-2922-4e1d-b0f5-70ca5a47cb95,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-f2772565-f085-4c42-9f55-2137cf7f83ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-1c295c86-f3ab-47ab-9307-82922cf5786a,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-32da1116-325e-4444-943a-94c61e72ca3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-46c91b8e-1b14-42a1-aa84-72c876522edf,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-cf0fc629-bec5-439a-94b2-3b33276cd37c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-833247881-172.17.0.9-1597484752630:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46732,DS-ae61ca44-309d-429a-a32d-252267653d33,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-013e6038-2de1-4d7d-a189-1c06cd4cfb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:43102,DS-2712c3f3-2922-4e1d-b0f5-70ca5a47cb95,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-f2772565-f085-4c42-9f55-2137cf7f83ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-1c295c86-f3ab-47ab-9307-82922cf5786a,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-32da1116-325e-4444-943a-94c61e72ca3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-46c91b8e-1b14-42a1-aa84-72c876522edf,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-cf0fc629-bec5-439a-94b2-3b33276cd37c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1143364156-172.17.0.9-1597484947827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37602,DS-dc3d8d95-c2b9-404b-84cd-977f3b1b0a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-98f0a75e-b204-46db-935f-f3b7e9451acc,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-27e330f2-7d51-4578-a8e6-b412ae3aed7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-e3683bb9-fca2-4154-afce-1ac632670e89,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-57b652e6-57f8-49de-a0e0-481bd18c6410,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-f9ffca53-fb6a-4804-94c6-f404d116bc83,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-6c58f906-d5ff-4749-8a3c-ffaf7555594d,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-d258d7ee-d27f-45c0-a519-4b00b707c25f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1143364156-172.17.0.9-1597484947827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37602,DS-dc3d8d95-c2b9-404b-84cd-977f3b1b0a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-98f0a75e-b204-46db-935f-f3b7e9451acc,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-27e330f2-7d51-4578-a8e6-b412ae3aed7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-e3683bb9-fca2-4154-afce-1ac632670e89,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-57b652e6-57f8-49de-a0e0-481bd18c6410,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-f9ffca53-fb6a-4804-94c6-f404d116bc83,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-6c58f906-d5ff-4749-8a3c-ffaf7555594d,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-d258d7ee-d27f-45c0-a519-4b00b707c25f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-221388050-172.17.0.9-1597484984398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33696,DS-0237008e-e8ba-4b12-b3a9-b3be18296124,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-7bc180e1-8f6d-454a-87b6-31dfabd07a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-32ec0bf9-6f14-4e81-8750-2abbccd9b03d,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-0abb1796-6a1a-4d03-b013-211a313082f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-e86a5582-5a00-4571-9b1b-d43aaf71c911,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-08fb121a-4fff-4302-b21f-02638ca0d67d,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-d5bfca3d-011c-4217-91c0-d0850378210e,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-2f9bb2cc-9925-4d43-a52c-93442865286b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-221388050-172.17.0.9-1597484984398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33696,DS-0237008e-e8ba-4b12-b3a9-b3be18296124,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-7bc180e1-8f6d-454a-87b6-31dfabd07a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-32ec0bf9-6f14-4e81-8750-2abbccd9b03d,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-0abb1796-6a1a-4d03-b013-211a313082f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-e86a5582-5a00-4571-9b1b-d43aaf71c911,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-08fb121a-4fff-4302-b21f-02638ca0d67d,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-d5bfca3d-011c-4217-91c0-d0850378210e,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-2f9bb2cc-9925-4d43-a52c-93442865286b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948323191-172.17.0.9-1597485096885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33165,DS-646fe4b2-4843-4494-b410-39b6d95b1699,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-5a48705f-fd45-4b64-b4b8-edf78cb68eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-8de7680a-8998-45f4-8b23-c09148b0a0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41711,DS-65181862-3bfd-4e90-a4b9-415c4c7e69c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-9ae5aea6-816c-42e4-b34c-ca475f545108,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-c01b7262-9ae5-406f-be8a-380e89f0ee3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-7e081e58-fdd9-4329-abc0-e561a366e7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-d609f8c2-a8f8-421e-9df9-de48aae77c59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948323191-172.17.0.9-1597485096885:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33165,DS-646fe4b2-4843-4494-b410-39b6d95b1699,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-5a48705f-fd45-4b64-b4b8-edf78cb68eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-8de7680a-8998-45f4-8b23-c09148b0a0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41711,DS-65181862-3bfd-4e90-a4b9-415c4c7e69c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-9ae5aea6-816c-42e4-b34c-ca475f545108,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-c01b7262-9ae5-406f-be8a-380e89f0ee3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-7e081e58-fdd9-4329-abc0-e561a366e7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-d609f8c2-a8f8-421e-9df9-de48aae77c59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1354795223-172.17.0.9-1597485221127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38681,DS-68420f43-e56f-4f67-9999-8ba4938a2873,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-82c07348-b10e-436d-9fb2-834fe861d2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-995e2888-7d2e-48fc-81af-d67cefcb4285,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-7e1c9c5f-7729-47f3-9614-c61238b731f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41762,DS-940bbf27-a7cf-48d3-95f5-53c912565b14,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-20184d4d-44c5-479d-946d-770f8c622eac,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-798938bf-5659-4d52-8091-2c25cf0dc610,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-96aa43d5-e076-4be6-8e61-b23bc0d6ff6a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1354795223-172.17.0.9-1597485221127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38681,DS-68420f43-e56f-4f67-9999-8ba4938a2873,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-82c07348-b10e-436d-9fb2-834fe861d2f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-995e2888-7d2e-48fc-81af-d67cefcb4285,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-7e1c9c5f-7729-47f3-9614-c61238b731f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41762,DS-940bbf27-a7cf-48d3-95f5-53c912565b14,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-20184d4d-44c5-479d-946d-770f8c622eac,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-798938bf-5659-4d52-8091-2c25cf0dc610,DISK], DatanodeInfoWithStorage[127.0.0.1:45240,DS-96aa43d5-e076-4be6-8e61-b23bc0d6ff6a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1963096703-172.17.0.9-1597485295588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45418,DS-f66079c0-037b-474c-914f-50ce0bde56c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-08a1a498-5902-4abe-85d9-1241fa7074af,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-e91ee697-acd4-4d73-8839-b242ff855d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-3b278d65-c3f0-4c3f-b19c-9bfb728abbde,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-49888383-7f7a-4573-9c94-c4ac3ea59e13,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-e3c3903c-d6bf-46ad-a1cc-2a288907696d,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-8a720590-7347-4072-b285-b37fde9f94c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-3d8f7f52-a2be-4961-afda-0ab11013d87a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1963096703-172.17.0.9-1597485295588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45418,DS-f66079c0-037b-474c-914f-50ce0bde56c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-08a1a498-5902-4abe-85d9-1241fa7074af,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-e91ee697-acd4-4d73-8839-b242ff855d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-3b278d65-c3f0-4c3f-b19c-9bfb728abbde,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-49888383-7f7a-4573-9c94-c4ac3ea59e13,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-e3c3903c-d6bf-46ad-a1cc-2a288907696d,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-8a720590-7347-4072-b285-b37fde9f94c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40726,DS-3d8f7f52-a2be-4961-afda-0ab11013d87a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1247345648-172.17.0.9-1597485516188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37444,DS-24695b9a-32cd-4bc4-825a-4ecf58cdb0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-10e017f7-22fc-4250-8167-607c4f790823,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-7490e8be-6bb8-408f-81d9-6710c41cf1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-d2dec2f2-cd09-4fd0-afbf-2d55ecd2142c,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-6c11a89b-8010-4303-a8a0-a1ce25a96ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-5a9e91fa-a9c3-4762-b606-427b58545b24,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-603ab02e-6ad0-43d3-9297-922efe00c292,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-fc655e6c-b514-4864-b8af-db1d53ee3ba3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1247345648-172.17.0.9-1597485516188:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37444,DS-24695b9a-32cd-4bc4-825a-4ecf58cdb0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34743,DS-10e017f7-22fc-4250-8167-607c4f790823,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-7490e8be-6bb8-408f-81d9-6710c41cf1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39073,DS-d2dec2f2-cd09-4fd0-afbf-2d55ecd2142c,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-6c11a89b-8010-4303-a8a0-a1ce25a96ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-5a9e91fa-a9c3-4762-b606-427b58545b24,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-603ab02e-6ad0-43d3-9297-922efe00c292,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-fc655e6c-b514-4864-b8af-db1d53ee3ba3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731778388-172.17.0.9-1597485901021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36638,DS-c12277af-57d4-43f8-a589-3d54198919aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-61b4331c-3324-412e-8ddc-d8c168048c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-e9c08389-0831-40ae-adcc-176ede518fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-e6f0311a-cc29-489d-a63d-2ddd75f7c394,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-d8fc5e4c-7b8a-4816-a0ea-8d11c2dfef42,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-4b342a66-ab99-439c-9141-dd0b81ae231b,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-cd645f3e-a446-4605-a1f7-e52a4a79d681,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-f4dfa9dc-90ce-4dfa-8ddf-1e797ca9920f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-731778388-172.17.0.9-1597485901021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36638,DS-c12277af-57d4-43f8-a589-3d54198919aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-61b4331c-3324-412e-8ddc-d8c168048c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-e9c08389-0831-40ae-adcc-176ede518fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-e6f0311a-cc29-489d-a63d-2ddd75f7c394,DISK], DatanodeInfoWithStorage[127.0.0.1:45423,DS-d8fc5e4c-7b8a-4816-a0ea-8d11c2dfef42,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-4b342a66-ab99-439c-9141-dd0b81ae231b,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-cd645f3e-a446-4605-a1f7-e52a4a79d681,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-f4dfa9dc-90ce-4dfa-8ddf-1e797ca9920f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616157022-172.17.0.9-1597485980605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38378,DS-0ae5c607-2b17-41b0-9422-d826bff7bbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-7e4603ab-c79f-4306-96e7-c21a3ddad804,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-95efed38-5de6-4f55-b3b9-c17a48b52745,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-04c9fa27-0cdd-4dc2-a19c-759907fe9c80,DISK], DatanodeInfoWithStorage[127.0.0.1:41374,DS-41c33b5c-045c-47d3-ab8a-fd3920dcf8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-c8a96c46-36ce-42fa-9352-b1ea57380fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-d24a8faf-505c-446d-88f3-7715d566b74a,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-ec1d5a0b-6c29-428e-8b6f-359676ff293f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616157022-172.17.0.9-1597485980605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38378,DS-0ae5c607-2b17-41b0-9422-d826bff7bbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-7e4603ab-c79f-4306-96e7-c21a3ddad804,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-95efed38-5de6-4f55-b3b9-c17a48b52745,DISK], DatanodeInfoWithStorage[127.0.0.1:44591,DS-04c9fa27-0cdd-4dc2-a19c-759907fe9c80,DISK], DatanodeInfoWithStorage[127.0.0.1:41374,DS-41c33b5c-045c-47d3-ab8a-fd3920dcf8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-c8a96c46-36ce-42fa-9352-b1ea57380fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-d24a8faf-505c-446d-88f3-7715d566b74a,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-ec1d5a0b-6c29-428e-8b6f-359676ff293f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851312386-172.17.0.9-1597486132192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34117,DS-450b14a6-7331-4765-bcc2-ff3f0fe98315,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-422272e6-70c4-4b00-97e2-74a455bf49bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-646d779b-222f-4693-b66b-98f5dfe1c36c,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-7b1612a9-1b81-428f-af2a-66f9e32c2a99,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-97b9c6d3-239b-4712-8293-546443c69112,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-41c48e67-c03d-4e3a-a509-5375481c176c,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-8b76eb87-d6a7-4f73-bed4-bafeb8404c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-c86fcc3f-60c0-4a58-92f5-48c845964a68,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851312386-172.17.0.9-1597486132192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34117,DS-450b14a6-7331-4765-bcc2-ff3f0fe98315,DISK], DatanodeInfoWithStorage[127.0.0.1:35778,DS-422272e6-70c4-4b00-97e2-74a455bf49bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-646d779b-222f-4693-b66b-98f5dfe1c36c,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-7b1612a9-1b81-428f-af2a-66f9e32c2a99,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-97b9c6d3-239b-4712-8293-546443c69112,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-41c48e67-c03d-4e3a-a509-5375481c176c,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-8b76eb87-d6a7-4f73-bed4-bafeb8404c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-c86fcc3f-60c0-4a58-92f5-48c845964a68,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-595181816-172.17.0.9-1597486237181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36387,DS-992f0009-06e6-4abd-b1ad-4f8d3f838868,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-ff9f2144-87d1-4eef-bae3-1850e7e01c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-63902f20-476e-443e-b19d-9589de4faaed,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-91239d22-6dc2-464b-bec1-dd3955afad12,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-70ea3cfc-14eb-408e-81a5-05bf86015295,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-1faac23e-e8d7-401c-9202-8c9d316d9194,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-e8f0bff1-85b8-47c1-87c4-b6d5794d5f42,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-ff7dd9b9-65a5-457a-bde2-7e2b476b6bfb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-595181816-172.17.0.9-1597486237181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36387,DS-992f0009-06e6-4abd-b1ad-4f8d3f838868,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-ff9f2144-87d1-4eef-bae3-1850e7e01c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-63902f20-476e-443e-b19d-9589de4faaed,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-91239d22-6dc2-464b-bec1-dd3955afad12,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-70ea3cfc-14eb-408e-81a5-05bf86015295,DISK], DatanodeInfoWithStorage[127.0.0.1:41537,DS-1faac23e-e8d7-401c-9202-8c9d316d9194,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-e8f0bff1-85b8-47c1-87c4-b6d5794d5f42,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-ff7dd9b9-65a5-457a-bde2-7e2b476b6bfb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454951557-172.17.0.9-1597486441302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35007,DS-e2c02916-cd29-4700-aecd-a9495b681f62,DISK], DatanodeInfoWithStorage[127.0.0.1:45969,DS-ad2e3e30-9a95-42fb-a8e7-c4313f70ed68,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-3c5494c6-1626-4c11-a799-ad93f59ebd02,DISK], DatanodeInfoWithStorage[127.0.0.1:39291,DS-9f476ad0-89bb-47fd-b5f1-ad05e594a95c,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-dbd98607-9115-412a-b5b9-d6df28165cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-df6b7ce0-c2b5-40a9-89c8-09af5ccd0260,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-320ddafb-d8cb-45ce-9653-7f688b72593b,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-290f516a-117c-4389-8ade-25a89711ca93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-454951557-172.17.0.9-1597486441302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35007,DS-e2c02916-cd29-4700-aecd-a9495b681f62,DISK], DatanodeInfoWithStorage[127.0.0.1:45969,DS-ad2e3e30-9a95-42fb-a8e7-c4313f70ed68,DISK], DatanodeInfoWithStorage[127.0.0.1:36982,DS-3c5494c6-1626-4c11-a799-ad93f59ebd02,DISK], DatanodeInfoWithStorage[127.0.0.1:39291,DS-9f476ad0-89bb-47fd-b5f1-ad05e594a95c,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-dbd98607-9115-412a-b5b9-d6df28165cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-df6b7ce0-c2b5-40a9-89c8-09af5ccd0260,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-320ddafb-d8cb-45ce-9653-7f688b72593b,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-290f516a-117c-4389-8ade-25a89711ca93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062023642-172.17.0.9-1597486877814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36493,DS-9ce02927-742a-45d3-bc70-1b65e04b42a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-682d9660-9e8a-4ebc-b913-42898ea09264,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-7c6d9944-46a0-41aa-b035-5dfd6fef7c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-bb8525a5-4143-4ffb-9b9c-23f3857d3f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-f728b91d-a030-40f1-af1f-74f9e45dcdf3,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-6106c767-6e0c-4c04-a10c-2434e1472c12,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-936338b6-e3c5-4032-8162-f0dfe2efd2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-a1dcfcee-d1c9-4ec9-91e5-c240b791a710,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062023642-172.17.0.9-1597486877814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36493,DS-9ce02927-742a-45d3-bc70-1b65e04b42a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-682d9660-9e8a-4ebc-b913-42898ea09264,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-7c6d9944-46a0-41aa-b035-5dfd6fef7c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-bb8525a5-4143-4ffb-9b9c-23f3857d3f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-f728b91d-a030-40f1-af1f-74f9e45dcdf3,DISK], DatanodeInfoWithStorage[127.0.0.1:43363,DS-6106c767-6e0c-4c04-a10c-2434e1472c12,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-936338b6-e3c5-4032-8162-f0dfe2efd2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-a1dcfcee-d1c9-4ec9-91e5-c240b791a710,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1407074895-172.17.0.9-1597486914729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41774,DS-2196b432-1b3f-4765-ad4e-4ac642b154a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-c43e6490-a80f-4611-b618-a2298b425b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-32ed8a67-a653-46b8-abb0-a1a01faa686d,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-ff7a860c-bb32-4ae0-a7ff-ac50e577c7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34796,DS-6b87d6d7-4ad6-4523-863e-b2d465ab0fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-634b44d3-1d17-4a3c-a26d-fddfbd999e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-c06cb1c9-b519-40bd-a25a-2dbc4a792d79,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-38bbcae7-85b4-4ed1-9f65-0707b3e59f4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1407074895-172.17.0.9-1597486914729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41774,DS-2196b432-1b3f-4765-ad4e-4ac642b154a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-c43e6490-a80f-4611-b618-a2298b425b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-32ed8a67-a653-46b8-abb0-a1a01faa686d,DISK], DatanodeInfoWithStorage[127.0.0.1:34782,DS-ff7a860c-bb32-4ae0-a7ff-ac50e577c7d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34796,DS-6b87d6d7-4ad6-4523-863e-b2d465ab0fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-634b44d3-1d17-4a3c-a26d-fddfbd999e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-c06cb1c9-b519-40bd-a25a-2dbc4a792d79,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-38bbcae7-85b4-4ed1-9f65-0707b3e59f4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1164714212-172.17.0.9-1597486955046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44565,DS-7acef90b-b2f6-4269-ae2d-f3800ec8bbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-1c573842-5133-4449-880c-1438c224e677,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-c5bb838e-b684-4e5c-b808-7381ddae6236,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-0fe82389-2f67-4c5d-acfe-d2ebd5174a10,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-c6599185-93c2-49a6-95cf-d762e165b5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-129deac0-7dd5-438c-b9e5-7a42a8e92b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-ede43870-7c84-4cae-80ab-540f28369291,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-75a81faa-7556-45ec-8c3f-77cef31aa783,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1164714212-172.17.0.9-1597486955046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44565,DS-7acef90b-b2f6-4269-ae2d-f3800ec8bbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-1c573842-5133-4449-880c-1438c224e677,DISK], DatanodeInfoWithStorage[127.0.0.1:37741,DS-c5bb838e-b684-4e5c-b808-7381ddae6236,DISK], DatanodeInfoWithStorage[127.0.0.1:45675,DS-0fe82389-2f67-4c5d-acfe-d2ebd5174a10,DISK], DatanodeInfoWithStorage[127.0.0.1:40919,DS-c6599185-93c2-49a6-95cf-d762e165b5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-129deac0-7dd5-438c-b9e5-7a42a8e92b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-ede43870-7c84-4cae-80ab-540f28369291,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-75a81faa-7556-45ec-8c3f-77cef31aa783,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-345712981-172.17.0.9-1597487332065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41626,DS-e51895e8-5049-4c47-8686-7e68ab7a3daf,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-00ac0c89-1149-45a5-9939-3a8c66eb495a,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-3b5ea334-c5ed-495d-936a-34da583b77c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-18dae8c0-a35a-4fae-8cc5-32297b6c5a64,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-bc6c1012-a9f4-4145-9983-33decd2d178c,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-0e09fc79-158b-4bae-b742-d82cc05e0bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-6fa93a0b-e46d-490b-8604-2cce912edd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-985a6e2f-76ae-4417-aebb-65037d899aa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-345712981-172.17.0.9-1597487332065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41626,DS-e51895e8-5049-4c47-8686-7e68ab7a3daf,DISK], DatanodeInfoWithStorage[127.0.0.1:44925,DS-00ac0c89-1149-45a5-9939-3a8c66eb495a,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-3b5ea334-c5ed-495d-936a-34da583b77c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-18dae8c0-a35a-4fae-8cc5-32297b6c5a64,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-bc6c1012-a9f4-4145-9983-33decd2d178c,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-0e09fc79-158b-4bae-b742-d82cc05e0bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43205,DS-6fa93a0b-e46d-490b-8604-2cce912edd6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-985a6e2f-76ae-4417-aebb-65037d899aa7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1249682264-172.17.0.9-1597487452826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34267,DS-6ea29783-b8de-4687-9246-308ed0d1423c,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-d6eec8d3-2fea-45db-8194-d9b490908feb,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-dd948717-2594-4188-a5e4-6cb69c2d0205,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-c003b432-8185-4942-8d91-bc0915628497,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-186d6a09-10a1-483a-8219-65eed49b1dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-07d3c9dc-e5fd-41eb-a64a-1807223e3808,DISK], DatanodeInfoWithStorage[127.0.0.1:34247,DS-446a6364-19ee-4113-82a4-1ed7666fcc22,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-171067a7-efff-48d2-aa7d-2f4c2793fc62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1249682264-172.17.0.9-1597487452826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34267,DS-6ea29783-b8de-4687-9246-308ed0d1423c,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-d6eec8d3-2fea-45db-8194-d9b490908feb,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-dd948717-2594-4188-a5e4-6cb69c2d0205,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-c003b432-8185-4942-8d91-bc0915628497,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-186d6a09-10a1-483a-8219-65eed49b1dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-07d3c9dc-e5fd-41eb-a64a-1807223e3808,DISK], DatanodeInfoWithStorage[127.0.0.1:34247,DS-446a6364-19ee-4113-82a4-1ed7666fcc22,DISK], DatanodeInfoWithStorage[127.0.0.1:43967,DS-171067a7-efff-48d2-aa7d-2f4c2793fc62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1225732441-172.17.0.9-1597487490634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41202,DS-3ff00db7-2641-4b29-bea7-c9b090fe7871,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-a411aa8f-3115-410a-83dd-5aa487211fff,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-d26ac63a-2343-4fe5-8e4c-4d357017ac3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-967e964b-9766-4294-9810-47beb32b8ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-43cbdb84-7add-48c1-8b4a-d391d452e77c,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-fffc8eb2-caa9-4c7a-bb50-6bb4fc140c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-f34f0f6e-533f-46be-a078-33de64ee9f58,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-9cc95cf7-77cb-4887-a763-2cd62099f548,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1225732441-172.17.0.9-1597487490634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41202,DS-3ff00db7-2641-4b29-bea7-c9b090fe7871,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-a411aa8f-3115-410a-83dd-5aa487211fff,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-d26ac63a-2343-4fe5-8e4c-4d357017ac3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-967e964b-9766-4294-9810-47beb32b8ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-43cbdb84-7add-48c1-8b4a-d391d452e77c,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-fffc8eb2-caa9-4c7a-bb50-6bb4fc140c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-f34f0f6e-533f-46be-a078-33de64ee9f58,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-9cc95cf7-77cb-4887-a763-2cd62099f548,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1240530360-172.17.0.9-1597487570513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33971,DS-60c6b5e2-1c49-48a0-8e03-6158a4a52d45,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-90fef16f-167b-4870-b270-9da24845fa44,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-4204573a-f6c3-4805-81eb-9338cc204613,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-bd93b603-f752-46ed-9e81-98a6f1b124f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-da2dd269-53e4-4568-acb1-32784db081d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-33d8de95-c957-4a6d-86c3-31909541e6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40411,DS-2280d158-9f1e-4f7d-909c-db150bf5c7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-e63bf8f2-7b22-497f-8308-945ec27a14d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1240530360-172.17.0.9-1597487570513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33971,DS-60c6b5e2-1c49-48a0-8e03-6158a4a52d45,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-90fef16f-167b-4870-b270-9da24845fa44,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-4204573a-f6c3-4805-81eb-9338cc204613,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-bd93b603-f752-46ed-9e81-98a6f1b124f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43808,DS-da2dd269-53e4-4568-acb1-32784db081d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-33d8de95-c957-4a6d-86c3-31909541e6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40411,DS-2280d158-9f1e-4f7d-909c-db150bf5c7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46474,DS-e63bf8f2-7b22-497f-8308-945ec27a14d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-458334707-172.17.0.9-1597487650356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35852,DS-4deef2a9-e0ac-483b-907d-89bd3191d0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-5e3a0efa-8c0e-428e-8070-b583fe4aada4,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-1b8679d6-f9a2-4e9d-9b96-415a2e61b6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-c5e5af24-3d09-4523-9916-ce0b303a693e,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-2075f296-5be0-4e26-bae6-dae22113756b,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-ff4857c8-5430-4a0f-9891-f35d84c3a0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-724f4b44-915b-40fd-85c3-585c014ac14e,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-efd88c49-da3d-4761-89d2-05f117b9bed8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-458334707-172.17.0.9-1597487650356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35852,DS-4deef2a9-e0ac-483b-907d-89bd3191d0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38404,DS-5e3a0efa-8c0e-428e-8070-b583fe4aada4,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-1b8679d6-f9a2-4e9d-9b96-415a2e61b6b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45192,DS-c5e5af24-3d09-4523-9916-ce0b303a693e,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-2075f296-5be0-4e26-bae6-dae22113756b,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-ff4857c8-5430-4a0f-9891-f35d84c3a0f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-724f4b44-915b-40fd-85c3-585c014ac14e,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-efd88c49-da3d-4761-89d2-05f117b9bed8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346483197-172.17.0.9-1597487681872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44655,DS-ecee6e4a-4b12-4ad1-95bc-a3e617421f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-a2f41074-5d2c-4846-96f3-4e0acb858ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-710a07cc-0bcd-4633-b1b1-2c8b7d8e0061,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-6c58e18d-6553-4690-af7b-7c02f75e64be,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-dbac69c2-3518-4d75-bb00-d08b5dbbcd31,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-9eba9ac5-a2d6-4c72-9f83-e37a7da155cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-58c29f34-9d74-4986-aacf-e5f63e0109c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-88abe9de-9db8-4419-a096-65c5c56464e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346483197-172.17.0.9-1597487681872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44655,DS-ecee6e4a-4b12-4ad1-95bc-a3e617421f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-a2f41074-5d2c-4846-96f3-4e0acb858ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-710a07cc-0bcd-4633-b1b1-2c8b7d8e0061,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-6c58e18d-6553-4690-af7b-7c02f75e64be,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-dbac69c2-3518-4d75-bb00-d08b5dbbcd31,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-9eba9ac5-a2d6-4c72-9f83-e37a7da155cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34164,DS-58c29f34-9d74-4986-aacf-e5f63e0109c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-88abe9de-9db8-4419-a096-65c5c56464e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 216
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-882909221-172.17.0.9-1597487952811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45173,DS-483636b5-8061-4363-bb9a-986c92291ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-0b33a852-aff0-4aaf-a1b3-eb0efd59739f,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-7452f73e-a2cf-4e46-b781-7fd12ad68463,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-365a96ee-eddc-4732-8368-ec623fe2eb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-0bd0e1d8-ee0f-4ef6-94e0-0685fee87aec,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-688b7d2a-7528-45a1-8dd3-30fbdcd7bba0,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-a6d1c07b-6893-4d7b-ba83-3fa8e3d90d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-2f5730f0-8f21-4554-a79a-05e886831e33,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-882909221-172.17.0.9-1597487952811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45173,DS-483636b5-8061-4363-bb9a-986c92291ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-0b33a852-aff0-4aaf-a1b3-eb0efd59739f,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-7452f73e-a2cf-4e46-b781-7fd12ad68463,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-365a96ee-eddc-4732-8368-ec623fe2eb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-0bd0e1d8-ee0f-4ef6-94e0-0685fee87aec,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-688b7d2a-7528-45a1-8dd3-30fbdcd7bba0,DISK], DatanodeInfoWithStorage[127.0.0.1:36091,DS-a6d1c07b-6893-4d7b-ba83-3fa8e3d90d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-2f5730f0-8f21-4554-a79a-05e886831e33,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 12 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 5902
