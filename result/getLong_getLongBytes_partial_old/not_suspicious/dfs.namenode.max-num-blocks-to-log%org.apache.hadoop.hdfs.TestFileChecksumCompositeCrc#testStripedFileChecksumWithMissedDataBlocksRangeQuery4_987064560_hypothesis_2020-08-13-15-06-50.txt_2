reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-491722748-172.17.0.17-1597331601773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45684,DS-ed905bce-9320-479e-b55c-c0eb83002b59,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-62d93328-a030-4289-b4a8-0eebb1a4facb,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-f7ea46b3-0fe1-40d5-a6de-152e775f05ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-9740dae9-1007-44d6-94d6-cd614761a5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-2abac5b7-220f-4948-b570-4f49ee00b7da,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-8a1d4511-5832-486f-bbff-2addb07523dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-8003622d-0809-4733-926e-85174b31e4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-b5073129-5981-4656-8a81-1093440a080a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-491722748-172.17.0.17-1597331601773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45684,DS-ed905bce-9320-479e-b55c-c0eb83002b59,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-62d93328-a030-4289-b4a8-0eebb1a4facb,DISK], DatanodeInfoWithStorage[127.0.0.1:42676,DS-f7ea46b3-0fe1-40d5-a6de-152e775f05ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-9740dae9-1007-44d6-94d6-cd614761a5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-2abac5b7-220f-4948-b570-4f49ee00b7da,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-8a1d4511-5832-486f-bbff-2addb07523dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45739,DS-8003622d-0809-4733-926e-85174b31e4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-b5073129-5981-4656-8a81-1093440a080a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-90822409-172.17.0.17-1597331916680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43732,DS-9da25276-8a09-492b-99a2-60936b414dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-7f5010f4-bbef-498b-bef9-b95ae27ae7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-77d414ff-1b40-40c9-856b-9cf548f84f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-3714a8ce-7094-4d26-931f-1b6197a6b11e,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-c25249a3-58f1-46d8-9aca-b1467875afae,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-1571fcd7-fb42-4408-8140-56f13dfeb12f,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-fb46e319-958e-471c-be26-662641bd7f96,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-c2e14823-74df-4998-a4b0-508290558093,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-90822409-172.17.0.17-1597331916680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43732,DS-9da25276-8a09-492b-99a2-60936b414dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36635,DS-7f5010f4-bbef-498b-bef9-b95ae27ae7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39892,DS-77d414ff-1b40-40c9-856b-9cf548f84f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-3714a8ce-7094-4d26-931f-1b6197a6b11e,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-c25249a3-58f1-46d8-9aca-b1467875afae,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-1571fcd7-fb42-4408-8140-56f13dfeb12f,DISK], DatanodeInfoWithStorage[127.0.0.1:39168,DS-fb46e319-958e-471c-be26-662641bd7f96,DISK], DatanodeInfoWithStorage[127.0.0.1:39197,DS-c2e14823-74df-4998-a4b0-508290558093,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1622213197-172.17.0.17-1597332000218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44326,DS-209b60e9-9df2-4faa-8870-4e8030b7421b,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-35b11897-1f4c-479c-862e-18738e06dc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-66c56f3d-73a0-4224-a83d-4b4e5fb99884,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-ce98b5ab-5018-4db5-ad04-86486c278d93,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-b9270511-20e9-40c0-b019-1e4c6b3f962f,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-a88c58a7-75dc-4feb-90c0-7b50a3c923e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-22394c67-d73e-4852-8bdc-17dd4dd2200b,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-9718676a-36cc-43ac-90b9-15f5c8a0971d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1622213197-172.17.0.17-1597332000218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44326,DS-209b60e9-9df2-4faa-8870-4e8030b7421b,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-35b11897-1f4c-479c-862e-18738e06dc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-66c56f3d-73a0-4224-a83d-4b4e5fb99884,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-ce98b5ab-5018-4db5-ad04-86486c278d93,DISK], DatanodeInfoWithStorage[127.0.0.1:36332,DS-b9270511-20e9-40c0-b019-1e4c6b3f962f,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-a88c58a7-75dc-4feb-90c0-7b50a3c923e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-22394c67-d73e-4852-8bdc-17dd4dd2200b,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-9718676a-36cc-43ac-90b9-15f5c8a0971d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517335525-172.17.0.17-1597332462521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39039,DS-fe520d0a-b533-425c-9179-3796392d9497,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-1347d569-dda0-4f7e-91c0-7f828b590cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-56199b27-4ca5-4329-b710-d44fe507999d,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-750ed93a-4a3f-495d-a4e0-2b8d5f7df899,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-ca2c5d1e-0e24-472f-b6d7-bb82592e7af6,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-aee82c7c-b961-448d-93b6-8fc873170296,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-d4588179-7445-4f71-9046-9971cd3ac2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-3b052063-862b-4fdc-a63a-649505342b5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1517335525-172.17.0.17-1597332462521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39039,DS-fe520d0a-b533-425c-9179-3796392d9497,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-1347d569-dda0-4f7e-91c0-7f828b590cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-56199b27-4ca5-4329-b710-d44fe507999d,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-750ed93a-4a3f-495d-a4e0-2b8d5f7df899,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-ca2c5d1e-0e24-472f-b6d7-bb82592e7af6,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-aee82c7c-b961-448d-93b6-8fc873170296,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-d4588179-7445-4f71-9046-9971cd3ac2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-3b052063-862b-4fdc-a63a-649505342b5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1126996465-172.17.0.17-1597333160884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43845,DS-75c56382-09a6-4c91-868d-015011693e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-984b4cdf-b35c-4915-bb12-7aea0e9c6d19,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-86e95450-d98a-461c-bd1e-ded41b7c7439,DISK], DatanodeInfoWithStorage[127.0.0.1:38142,DS-63cc99be-60f4-4df9-923e-62172e3925fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-45373946-438e-448c-bfd7-73da786a0460,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-b027ab16-29fc-415b-8bf8-3111a4ecb3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-a865a564-b2e5-4c7f-831d-71ec884c68ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-a58cbf80-b158-428e-ae64-06437cd4cc58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1126996465-172.17.0.17-1597333160884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43845,DS-75c56382-09a6-4c91-868d-015011693e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33566,DS-984b4cdf-b35c-4915-bb12-7aea0e9c6d19,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-86e95450-d98a-461c-bd1e-ded41b7c7439,DISK], DatanodeInfoWithStorage[127.0.0.1:38142,DS-63cc99be-60f4-4df9-923e-62172e3925fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-45373946-438e-448c-bfd7-73da786a0460,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-b027ab16-29fc-415b-8bf8-3111a4ecb3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-a865a564-b2e5-4c7f-831d-71ec884c68ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-a58cbf80-b158-428e-ae64-06437cd4cc58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796063197-172.17.0.17-1597333658750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39741,DS-572e9192-969a-4696-81e8-7e5417ba39ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-17f143b7-592e-419e-bba7-f0bcb4c59d16,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-ffbc59aa-fff7-419c-bfb9-21f40f2633aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41658,DS-030e9739-ca7e-4c89-b990-d69828b5a3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-b3087190-1b46-4066-bd31-62ffddd7ffb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-093fed06-2aec-488b-bc32-7dd452d52c71,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-dcbff437-0d0e-49dd-a224-465dd9c23cea,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-a3b06c77-91e8-461e-a454-12d48b03beb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796063197-172.17.0.17-1597333658750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39741,DS-572e9192-969a-4696-81e8-7e5417ba39ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44297,DS-17f143b7-592e-419e-bba7-f0bcb4c59d16,DISK], DatanodeInfoWithStorage[127.0.0.1:34802,DS-ffbc59aa-fff7-419c-bfb9-21f40f2633aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41658,DS-030e9739-ca7e-4c89-b990-d69828b5a3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-b3087190-1b46-4066-bd31-62ffddd7ffb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44141,DS-093fed06-2aec-488b-bc32-7dd452d52c71,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-dcbff437-0d0e-49dd-a224-465dd9c23cea,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-a3b06c77-91e8-461e-a454-12d48b03beb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-881436967-172.17.0.17-1597333863985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40560,DS-92d13b8c-9884-4a62-bb24-bffdb43ba24e,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-21be90da-fc1b-4b28-8f29-c0d010b31561,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-261e32a2-9bfc-4f49-ad70-1f0d77dbefaa,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-466c055b-94d0-4f25-9979-84203e071be8,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-c3cb4547-2d30-4690-9437-6d758011a12a,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-a914d743-6cd9-437a-9b33-9afc1aece208,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-dbc6cd32-4a55-4ee9-8ae0-7be46835c885,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-4e5d1252-69bd-4014-b49e-a40fefb697bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-881436967-172.17.0.17-1597333863985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40560,DS-92d13b8c-9884-4a62-bb24-bffdb43ba24e,DISK], DatanodeInfoWithStorage[127.0.0.1:46783,DS-21be90da-fc1b-4b28-8f29-c0d010b31561,DISK], DatanodeInfoWithStorage[127.0.0.1:42892,DS-261e32a2-9bfc-4f49-ad70-1f0d77dbefaa,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-466c055b-94d0-4f25-9979-84203e071be8,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-c3cb4547-2d30-4690-9437-6d758011a12a,DISK], DatanodeInfoWithStorage[127.0.0.1:38017,DS-a914d743-6cd9-437a-9b33-9afc1aece208,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-dbc6cd32-4a55-4ee9-8ae0-7be46835c885,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-4e5d1252-69bd-4014-b49e-a40fefb697bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-414948508-172.17.0.17-1597334009398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37593,DS-7e2b2288-85a2-48e7-8a4d-4e9020538ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-9b5ef1b1-5da9-4b4a-9c3b-89ac093ebb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-ebc46883-4402-4b7c-9003-00272b9da6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-8fd79e75-2fda-4b8a-883c-3da1ac96a160,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-22dc90e8-10e8-49f6-88ad-1398467ffd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-a566e6b1-3511-4fc0-9b96-cf3b2bb226a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-8ef3836c-4f8e-46cd-9ee1-d67333b1915e,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-a867e2f9-51bd-4d80-b6f4-012323d0d6d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-414948508-172.17.0.17-1597334009398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37593,DS-7e2b2288-85a2-48e7-8a4d-4e9020538ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:40786,DS-9b5ef1b1-5da9-4b4a-9c3b-89ac093ebb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37647,DS-ebc46883-4402-4b7c-9003-00272b9da6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-8fd79e75-2fda-4b8a-883c-3da1ac96a160,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-22dc90e8-10e8-49f6-88ad-1398467ffd2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44601,DS-a566e6b1-3511-4fc0-9b96-cf3b2bb226a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-8ef3836c-4f8e-46cd-9ee1-d67333b1915e,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-a867e2f9-51bd-4d80-b6f4-012323d0d6d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1785075926-172.17.0.17-1597334157552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40796,DS-cd73eae6-e6d2-40a9-a7c4-d60942241dad,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-ee830711-bac9-4b80-b7b0-b8f185f967c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-ab1784df-5d5a-4d05-8349-3a2a58247d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-1ed23d2d-7896-46ab-b72f-c6c72f82d38d,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-9271c6a2-6126-4ddb-b13e-3e236e8822e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-932c50b2-a52a-4887-a232-e36c0fa66bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-01e6846f-bba0-438b-829c-3d75c458b2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-7e268453-1f40-43a2-ad74-bba09e1b703c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1785075926-172.17.0.17-1597334157552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40796,DS-cd73eae6-e6d2-40a9-a7c4-d60942241dad,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-ee830711-bac9-4b80-b7b0-b8f185f967c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-ab1784df-5d5a-4d05-8349-3a2a58247d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44470,DS-1ed23d2d-7896-46ab-b72f-c6c72f82d38d,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-9271c6a2-6126-4ddb-b13e-3e236e8822e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-932c50b2-a52a-4887-a232-e36c0fa66bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-01e6846f-bba0-438b-829c-3d75c458b2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-7e268453-1f40-43a2-ad74-bba09e1b703c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855203839-172.17.0.17-1597334714043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38462,DS-932e581e-03d7-4690-97a9-bcdf830e963b,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-973983e4-6f37-403d-80b8-3796faae3f30,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-e2998d48-0d4c-49ab-a8bf-5f3c391aa70c,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-29fb8e85-ca31-4d69-a8bc-16d02571aeb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-90591f99-176a-4ea4-b218-f1c15bc76350,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-2766721e-d219-4b2d-bfc5-84c21b58676c,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-78e08a28-02f8-4f65-bb4c-081b9ef25124,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-f05ee1b7-d46a-4f4e-9fd5-98ac3b7ac7b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855203839-172.17.0.17-1597334714043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38462,DS-932e581e-03d7-4690-97a9-bcdf830e963b,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-973983e4-6f37-403d-80b8-3796faae3f30,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-e2998d48-0d4c-49ab-a8bf-5f3c391aa70c,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-29fb8e85-ca31-4d69-a8bc-16d02571aeb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-90591f99-176a-4ea4-b218-f1c15bc76350,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-2766721e-d219-4b2d-bfc5-84c21b58676c,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-78e08a28-02f8-4f65-bb4c-081b9ef25124,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-f05ee1b7-d46a-4f4e-9fd5-98ac3b7ac7b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-806788034-172.17.0.17-1597334830218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37996,DS-b7e64379-dcd7-4246-bfef-4f0620a71c31,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-abdfd957-f384-4d3e-a199-41ef8951beb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-ce45b1fe-1e38-46ba-a9aa-b619a943fe77,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-b76e3ce0-d392-4a51-9fb4-c2541b1db7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-81f6fe69-f04c-4eb2-8a32-311078fd6c48,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-e3e10a05-d10c-40ce-a42f-6c7519a4a18a,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-1f79458a-e503-4de4-8734-88d0e7090d99,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-4fda2cd5-3ba1-4b9b-a58d-2fea989d8678,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-806788034-172.17.0.17-1597334830218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37996,DS-b7e64379-dcd7-4246-bfef-4f0620a71c31,DISK], DatanodeInfoWithStorage[127.0.0.1:38439,DS-abdfd957-f384-4d3e-a199-41ef8951beb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42836,DS-ce45b1fe-1e38-46ba-a9aa-b619a943fe77,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-b76e3ce0-d392-4a51-9fb4-c2541b1db7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-81f6fe69-f04c-4eb2-8a32-311078fd6c48,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-e3e10a05-d10c-40ce-a42f-6c7519a4a18a,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-1f79458a-e503-4de4-8734-88d0e7090d99,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-4fda2cd5-3ba1-4b9b-a58d-2fea989d8678,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982632549-172.17.0.17-1597335461637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43878,DS-600e4204-784b-4495-aad0-62cad47ab78b,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-cd58e91e-27b3-41df-bfea-f296c473b77a,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-811965c6-0030-4eb9-8ba5-4759978332c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-3ec0182d-fa38-4ba0-83e8-5643253700d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-dec96085-d344-40a9-9227-7c75c18165bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-5414aefe-a5f8-435b-91f0-bc4d647d7125,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-0b6c0938-80ac-44fe-823f-657e42eaeaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-00da0764-c41b-4198-a0e5-3aacb38ee032,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982632549-172.17.0.17-1597335461637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43878,DS-600e4204-784b-4495-aad0-62cad47ab78b,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-cd58e91e-27b3-41df-bfea-f296c473b77a,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-811965c6-0030-4eb9-8ba5-4759978332c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-3ec0182d-fa38-4ba0-83e8-5643253700d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-dec96085-d344-40a9-9227-7c75c18165bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35878,DS-5414aefe-a5f8-435b-91f0-bc4d647d7125,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-0b6c0938-80ac-44fe-823f-657e42eaeaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-00da0764-c41b-4198-a0e5-3aacb38ee032,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-445157700-172.17.0.17-1597335568388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37486,DS-2bf15984-46bb-4d2e-a113-589eda679cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-339536b8-ca3f-432f-8e8a-7d1007b750f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-d0e3afb3-7949-4a0a-a997-2f626feec0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-c945705b-cbd1-4a50-9d5a-b879f8416425,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-b5d4d411-4c2d-4421-8bb7-61a1a7fd1c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-7d5cbcc9-dc58-41b5-bbc3-7af58fe2e6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-93a74b09-d393-40d0-bf8f-90a33bdc4bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-52f06c17-7901-405e-98b8-c254b7ea3cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-445157700-172.17.0.17-1597335568388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37486,DS-2bf15984-46bb-4d2e-a113-589eda679cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-339536b8-ca3f-432f-8e8a-7d1007b750f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-d0e3afb3-7949-4a0a-a997-2f626feec0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-c945705b-cbd1-4a50-9d5a-b879f8416425,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-b5d4d411-4c2d-4421-8bb7-61a1a7fd1c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-7d5cbcc9-dc58-41b5-bbc3-7af58fe2e6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-93a74b09-d393-40d0-bf8f-90a33bdc4bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-52f06c17-7901-405e-98b8-c254b7ea3cda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1390542518-172.17.0.17-1597335746494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40451,DS-a67cd22e-1e82-44bc-8327-175935210af8,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-22a2924e-ad1a-49e6-835a-e666dd2d3a33,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-05e22077-d263-4edb-a4a5-fd4d0cc8f936,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-1bd7fe2b-779b-4d0a-9fb0-c86907718539,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-6ebb2100-1522-47ce-8ecf-b7bd6030b387,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-ddcb5b64-6976-4f51-8ec5-2708ea0c76ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-2ccb953d-2f4a-4a78-8c4e-daa0991eeb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-ee11578b-c735-4d01-91b9-d4ae94a6c8a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1390542518-172.17.0.17-1597335746494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40451,DS-a67cd22e-1e82-44bc-8327-175935210af8,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-22a2924e-ad1a-49e6-835a-e666dd2d3a33,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-05e22077-d263-4edb-a4a5-fd4d0cc8f936,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-1bd7fe2b-779b-4d0a-9fb0-c86907718539,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-6ebb2100-1522-47ce-8ecf-b7bd6030b387,DISK], DatanodeInfoWithStorage[127.0.0.1:34165,DS-ddcb5b64-6976-4f51-8ec5-2708ea0c76ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-2ccb953d-2f4a-4a78-8c4e-daa0991eeb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-ee11578b-c735-4d01-91b9-d4ae94a6c8a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1159396511-172.17.0.17-1597336713790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40636,DS-e833e9d8-6321-4d80-a2d7-6903f7e95271,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-8128f364-dee4-4256-8a33-3a1bfd6f212f,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-8faeffba-16fe-4ea6-95ef-d91b7b59eb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-4c74a2b5-4f92-492c-95d2-2be6c78710ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-af922861-28ab-497f-9e32-be33f61f8a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-821c0606-c2e7-4502-bff3-66a02a9e361a,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-db606a21-c7e1-41b8-baac-9f27dbe80670,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-80d9b8a5-d626-49ed-9cfb-c3ea0021ea68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1159396511-172.17.0.17-1597336713790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40636,DS-e833e9d8-6321-4d80-a2d7-6903f7e95271,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-8128f364-dee4-4256-8a33-3a1bfd6f212f,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-8faeffba-16fe-4ea6-95ef-d91b7b59eb6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-4c74a2b5-4f92-492c-95d2-2be6c78710ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-af922861-28ab-497f-9e32-be33f61f8a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-821c0606-c2e7-4502-bff3-66a02a9e361a,DISK], DatanodeInfoWithStorage[127.0.0.1:37085,DS-db606a21-c7e1-41b8-baac-9f27dbe80670,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-80d9b8a5-d626-49ed-9cfb-c3ea0021ea68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267818029-172.17.0.17-1597336745367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33441,DS-0cfef312-381a-40cc-b259-532db4a8b2af,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-d618aee6-a9ad-4fb2-ab3b-77580c614d30,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-e90f8beb-311d-49bb-8daf-cda44cfac680,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-20499236-9fc0-4042-b8a6-08c51e7e0bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44603,DS-fc97803f-055d-4e9c-a2a3-ae85969515c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-56389433-7d06-4194-a4e4-65a9d87ab366,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-0825697a-54a8-4e72-aaaa-b283a68105b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-7a90e3ef-7696-4ea9-8126-ab481119e32e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267818029-172.17.0.17-1597336745367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33441,DS-0cfef312-381a-40cc-b259-532db4a8b2af,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-d618aee6-a9ad-4fb2-ab3b-77580c614d30,DISK], DatanodeInfoWithStorage[127.0.0.1:36155,DS-e90f8beb-311d-49bb-8daf-cda44cfac680,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-20499236-9fc0-4042-b8a6-08c51e7e0bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44603,DS-fc97803f-055d-4e9c-a2a3-ae85969515c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-56389433-7d06-4194-a4e4-65a9d87ab366,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-0825697a-54a8-4e72-aaaa-b283a68105b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-7a90e3ef-7696-4ea9-8126-ab481119e32e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5690
