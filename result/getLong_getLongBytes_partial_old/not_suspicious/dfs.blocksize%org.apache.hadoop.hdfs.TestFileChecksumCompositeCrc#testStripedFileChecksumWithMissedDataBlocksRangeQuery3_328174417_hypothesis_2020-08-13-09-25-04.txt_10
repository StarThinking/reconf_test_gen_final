reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1547116192-172.17.0.18-1597311388062:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41452,DS-a39fa2f5-78cf-460d-9b4b-7006896a1c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-b4428b02-8192-41a0-b217-cd0eddd47da2,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-f4cc0633-54fc-4b06-b8aa-2a42c955fb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-62213669-1c8e-40c5-bc6a-d4fa62d74b01,DISK], DatanodeInfoWithStorage[127.0.0.1:37239,DS-936ee421-29be-4525-b4e6-ebb8269270d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-e49e6326-b51a-46a6-8d2e-b31705482894,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-904775fe-b0ca-4adf-b2d1-e869ad670fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-22612998-68f8-4eb9-9dd2-fe7420f2d33e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1547116192-172.17.0.18-1597311388062:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41452,DS-a39fa2f5-78cf-460d-9b4b-7006896a1c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-b4428b02-8192-41a0-b217-cd0eddd47da2,DISK], DatanodeInfoWithStorage[127.0.0.1:44754,DS-f4cc0633-54fc-4b06-b8aa-2a42c955fb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-62213669-1c8e-40c5-bc6a-d4fa62d74b01,DISK], DatanodeInfoWithStorage[127.0.0.1:37239,DS-936ee421-29be-4525-b4e6-ebb8269270d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35485,DS-e49e6326-b51a-46a6-8d2e-b31705482894,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-904775fe-b0ca-4adf-b2d1-e869ad670fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-22612998-68f8-4eb9-9dd2-fe7420f2d33e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-525696673-172.17.0.18-1597311705687:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34929,DS-93048d8c-3cc8-4445-9374-bfc8ab091133,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-d94113ab-f9f1-416c-a825-c7399384a9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-48ca1b37-cb4e-46b5-9b86-a80014a74a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-cd3c8e69-5d03-4586-b498-e5c604b63be7,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-e3195d16-fca1-4b09-b96a-a6474b85a64b,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-ff726caf-d442-4f83-96f0-97f7f7d00622,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-8a408f1f-d541-4039-9905-af74f4379d83,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-24174f8f-ec40-48d5-bfea-19cce400272e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-525696673-172.17.0.18-1597311705687:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34929,DS-93048d8c-3cc8-4445-9374-bfc8ab091133,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-d94113ab-f9f1-416c-a825-c7399384a9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-48ca1b37-cb4e-46b5-9b86-a80014a74a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-cd3c8e69-5d03-4586-b498-e5c604b63be7,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-e3195d16-fca1-4b09-b96a-a6474b85a64b,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-ff726caf-d442-4f83-96f0-97f7f7d00622,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-8a408f1f-d541-4039-9905-af74f4379d83,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-24174f8f-ec40-48d5-bfea-19cce400272e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-8109638-172.17.0.18-1597311975428:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38646,DS-e074bd9f-856d-4e29-9ae3-f2ecda49af0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-b5297b84-465c-4c30-8529-4a3d826eb693,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-79dd87c5-a23e-4081-8901-bf8a208f03ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-b0f769c1-28a5-4fff-b709-faf6300d3261,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-150e8b52-c589-45ea-a62e-f9064bdd293a,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-71f53ed4-e1ed-4c8b-9b3d-ba4b05316210,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-1503db39-a2b3-4d02-a576-7c49f2ae7f98,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-c4e90677-db58-4b13-afbd-6210fd49915a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-8109638-172.17.0.18-1597311975428:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38646,DS-e074bd9f-856d-4e29-9ae3-f2ecda49af0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-b5297b84-465c-4c30-8529-4a3d826eb693,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-79dd87c5-a23e-4081-8901-bf8a208f03ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-b0f769c1-28a5-4fff-b709-faf6300d3261,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-150e8b52-c589-45ea-a62e-f9064bdd293a,DISK], DatanodeInfoWithStorage[127.0.0.1:43455,DS-71f53ed4-e1ed-4c8b-9b3d-ba4b05316210,DISK], DatanodeInfoWithStorage[127.0.0.1:41057,DS-1503db39-a2b3-4d02-a576-7c49f2ae7f98,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-c4e90677-db58-4b13-afbd-6210fd49915a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1502812483-172.17.0.18-1597312360352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38754,DS-f53324b0-e3c4-4f24-9bf9-933b337a353f,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-316a1e5f-a926-4507-b058-12fda1a1ab70,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-4b039c3c-473a-4742-9f67-fa239800a82d,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-210e907f-1cb4-45b6-b0db-2e98632bdbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-d48bd41f-e8c9-4624-b2c0-301a602f53d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-6f7e6078-0fdd-40c7-ad6f-f7033eb9519f,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-967fa4f5-4005-4a3f-b74d-d22d270eca51,DISK], DatanodeInfoWithStorage[127.0.0.1:32978,DS-5669cc33-618f-4d5c-9145-4b962db755dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1502812483-172.17.0.18-1597312360352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38754,DS-f53324b0-e3c4-4f24-9bf9-933b337a353f,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-316a1e5f-a926-4507-b058-12fda1a1ab70,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-4b039c3c-473a-4742-9f67-fa239800a82d,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-210e907f-1cb4-45b6-b0db-2e98632bdbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-d48bd41f-e8c9-4624-b2c0-301a602f53d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-6f7e6078-0fdd-40c7-ad6f-f7033eb9519f,DISK], DatanodeInfoWithStorage[127.0.0.1:41869,DS-967fa4f5-4005-4a3f-b74d-d22d270eca51,DISK], DatanodeInfoWithStorage[127.0.0.1:32978,DS-5669cc33-618f-4d5c-9145-4b962db755dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-541717456-172.17.0.18-1597312396488:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39871,DS-12d01d37-2314-444f-a7f6-9474b9e57501,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-d4f09743-38fc-4ab4-bea2-9bd1fbbab7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-6d2f7538-0225-4c0f-83ca-cf79681435be,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-76860abc-3cfc-498f-9a79-5b7e29fce0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-f2a87982-a991-4401-8bb0-23ce0ffdc188,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-4c4ebbdd-2694-4037-8a3d-a4582d575135,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-0fb4fd54-9883-4a46-b2e8-d899feeaa946,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-ddac00ba-4d89-4558-a259-fb5624800301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-541717456-172.17.0.18-1597312396488:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39871,DS-12d01d37-2314-444f-a7f6-9474b9e57501,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-d4f09743-38fc-4ab4-bea2-9bd1fbbab7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-6d2f7538-0225-4c0f-83ca-cf79681435be,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-76860abc-3cfc-498f-9a79-5b7e29fce0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-f2a87982-a991-4401-8bb0-23ce0ffdc188,DISK], DatanodeInfoWithStorage[127.0.0.1:33214,DS-4c4ebbdd-2694-4037-8a3d-a4582d575135,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-0fb4fd54-9883-4a46-b2e8-d899feeaa946,DISK], DatanodeInfoWithStorage[127.0.0.1:44178,DS-ddac00ba-4d89-4558-a259-fb5624800301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1594357699-172.17.0.18-1597312547441:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38241,DS-6dfc2f6a-c35d-44e3-8374-ceb8fd300831,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-f7b496f3-cfdf-49ec-b914-4762b0900c32,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-451c4bfa-c7a2-492d-ba2c-36d4628a0227,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-f0699ec4-2ff7-488f-b21a-671847a00a83,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-6dc5f093-444c-44b9-b0cd-fbd588428840,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-0ffceac3-f5a1-4779-9b2f-09c2c3ce095b,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-b2166832-2414-4bf6-92db-02a94d690469,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-82e40037-34f5-4ac5-ada7-559eee8ca9fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1594357699-172.17.0.18-1597312547441:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38241,DS-6dfc2f6a-c35d-44e3-8374-ceb8fd300831,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-f7b496f3-cfdf-49ec-b914-4762b0900c32,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-451c4bfa-c7a2-492d-ba2c-36d4628a0227,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-f0699ec4-2ff7-488f-b21a-671847a00a83,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-6dc5f093-444c-44b9-b0cd-fbd588428840,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-0ffceac3-f5a1-4779-9b2f-09c2c3ce095b,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-b2166832-2414-4bf6-92db-02a94d690469,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-82e40037-34f5-4ac5-ada7-559eee8ca9fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130140154-172.17.0.18-1597312937813:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42359,DS-ead918c0-750c-4b0a-93c1-3ea16d201807,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-9ed73ed8-50d3-4ed0-95b7-d8e5dd4a8788,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-44340b5f-8915-4b17-8ec6-db2d960a1d15,DISK], DatanodeInfoWithStorage[127.0.0.1:42199,DS-590510c5-d9df-49dc-9b08-684d282a4afe,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-95fa9c56-1c98-4ee3-9414-23b5398a538a,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-a8f205d6-df8c-4b0b-9f73-20e33b945d26,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-f9673cf0-083c-4139-a264-235ccdc812fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-32e4abbe-6846-4013-b0ed-51ec816be238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130140154-172.17.0.18-1597312937813:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42359,DS-ead918c0-750c-4b0a-93c1-3ea16d201807,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-9ed73ed8-50d3-4ed0-95b7-d8e5dd4a8788,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-44340b5f-8915-4b17-8ec6-db2d960a1d15,DISK], DatanodeInfoWithStorage[127.0.0.1:42199,DS-590510c5-d9df-49dc-9b08-684d282a4afe,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-95fa9c56-1c98-4ee3-9414-23b5398a538a,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-a8f205d6-df8c-4b0b-9f73-20e33b945d26,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-f9673cf0-083c-4139-a264-235ccdc812fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-32e4abbe-6846-4013-b0ed-51ec816be238,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-667325525-172.17.0.18-1597313121272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37496,DS-d243de22-d448-4bae-abed-7a9683c167f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-80f21e64-842e-4659-b485-43df0d1c8aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-0581ae1d-2cb1-45e3-ad06-0eeaa87591ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-c908e5ac-b8ba-40b4-9270-155a13ee205c,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-66419217-5ead-4ef4-84ec-c5e904390576,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-a36193e0-0fed-4338-9724-4f1285e27018,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-1e99f735-617b-4dd0-8be7-a97996e49489,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-dad72351-afff-496e-bde9-6d0200261ec6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-667325525-172.17.0.18-1597313121272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37496,DS-d243de22-d448-4bae-abed-7a9683c167f4,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-80f21e64-842e-4659-b485-43df0d1c8aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-0581ae1d-2cb1-45e3-ad06-0eeaa87591ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-c908e5ac-b8ba-40b4-9270-155a13ee205c,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-66419217-5ead-4ef4-84ec-c5e904390576,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-a36193e0-0fed-4338-9724-4f1285e27018,DISK], DatanodeInfoWithStorage[127.0.0.1:37224,DS-1e99f735-617b-4dd0-8be7-a97996e49489,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-dad72351-afff-496e-bde9-6d0200261ec6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-374329953-172.17.0.18-1597313232375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41862,DS-0580e298-51b0-473d-9c37-1b2441bbabc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-b65e450a-cc2a-4721-9d43-f089d3e8c8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-bf901811-42fa-4b7b-a801-1f9a3cd52035,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-8e287807-daf3-4113-96de-e5cbbe8b2940,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-6679d23b-60c0-4743-ac0c-71d709036b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-2b1243ca-73f0-4835-8338-e5582cec8fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-4a3b2d1c-7e16-49f7-a726-e6140ed549be,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-bda82e58-1ba6-4a8e-b6d8-b6e252102245,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-374329953-172.17.0.18-1597313232375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41862,DS-0580e298-51b0-473d-9c37-1b2441bbabc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-b65e450a-cc2a-4721-9d43-f089d3e8c8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-bf901811-42fa-4b7b-a801-1f9a3cd52035,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-8e287807-daf3-4113-96de-e5cbbe8b2940,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-6679d23b-60c0-4743-ac0c-71d709036b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-2b1243ca-73f0-4835-8338-e5582cec8fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-4a3b2d1c-7e16-49f7-a726-e6140ed549be,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-bda82e58-1ba6-4a8e-b6d8-b6e252102245,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-959647326-172.17.0.18-1597313714836:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41822,DS-627305cc-039b-4505-9841-1d3740c293f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-c0435617-bce5-44f9-9da1-a37bdec8dc58,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-d8a979b8-858e-4c72-95b4-926c2407b9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-898df2c2-51ff-4dab-8b74-667d9d6cd7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-c59ce956-1c8b-42b9-a272-33e2d4ab69ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-1988b6b6-430e-4535-9c8f-0fee6eef807f,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-c3215922-221b-4f49-930c-b2a94b4633c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-dd42c0b5-7bb0-49cb-b8cb-40e5a863012a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-959647326-172.17.0.18-1597313714836:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41822,DS-627305cc-039b-4505-9841-1d3740c293f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-c0435617-bce5-44f9-9da1-a37bdec8dc58,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-d8a979b8-858e-4c72-95b4-926c2407b9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-898df2c2-51ff-4dab-8b74-667d9d6cd7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45381,DS-c59ce956-1c8b-42b9-a272-33e2d4ab69ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-1988b6b6-430e-4535-9c8f-0fee6eef807f,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-c3215922-221b-4f49-930c-b2a94b4633c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-dd42c0b5-7bb0-49cb-b8cb-40e5a863012a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1129539963-172.17.0.18-1597314118440:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35716,DS-46e64ea1-cedc-4489-968e-f1ea39cfa701,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-a5d3ab5c-f598-44ae-92d5-e1cd3ba749aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-1eacff98-b338-4018-905d-def0691befab,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-6d5a7511-245e-427c-af4e-2c2df57769f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-8edf51c3-7d2b-442c-a9db-26e738e85528,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-f0534c10-451c-42c2-bb0b-a3552de8e61c,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-03c870ef-d47c-41a9-9492-9373f8e82fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-40f69988-c7a5-4628-afe9-78fe2ad36098,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1129539963-172.17.0.18-1597314118440:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35716,DS-46e64ea1-cedc-4489-968e-f1ea39cfa701,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-a5d3ab5c-f598-44ae-92d5-e1cd3ba749aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-1eacff98-b338-4018-905d-def0691befab,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-6d5a7511-245e-427c-af4e-2c2df57769f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42269,DS-8edf51c3-7d2b-442c-a9db-26e738e85528,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-f0534c10-451c-42c2-bb0b-a3552de8e61c,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-03c870ef-d47c-41a9-9492-9373f8e82fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-40f69988-c7a5-4628-afe9-78fe2ad36098,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-95503057-172.17.0.18-1597314388288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33362,DS-c9c32aae-bcb6-4790-9fec-dfe48666609b,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-484179da-e4de-42fe-aec5-868023fc45fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-0fc4ff7e-e1e5-4856-91d4-65e542905cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-09fcaad8-a6a3-45bd-98f7-6de08c07b3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-9556509f-a240-455f-a0e7-f956b5e0ce32,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-cccce409-d2b6-46fa-ad3b-daf67f9ad684,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-c563124e-848d-4b46-a6c1-1eb76e9dd58d,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-3c31691c-00a0-402b-94df-357e48911083,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-95503057-172.17.0.18-1597314388288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33362,DS-c9c32aae-bcb6-4790-9fec-dfe48666609b,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-484179da-e4de-42fe-aec5-868023fc45fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-0fc4ff7e-e1e5-4856-91d4-65e542905cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-09fcaad8-a6a3-45bd-98f7-6de08c07b3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-9556509f-a240-455f-a0e7-f956b5e0ce32,DISK], DatanodeInfoWithStorage[127.0.0.1:39327,DS-cccce409-d2b6-46fa-ad3b-daf67f9ad684,DISK], DatanodeInfoWithStorage[127.0.0.1:46190,DS-c563124e-848d-4b46-a6c1-1eb76e9dd58d,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-3c31691c-00a0-402b-94df-357e48911083,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1942860408-172.17.0.18-1597314434638:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42654,DS-1045247c-2140-4948-b16b-b47dede7adcb,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-e6187787-4049-4d08-8d11-be63ff13dd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-7afc7de1-d153-4233-abce-7ffe07eadc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-c0a2f77e-3681-4d97-9f20-064d804da714,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-338b3956-8d30-42cb-a360-4b4d0e66bd07,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-bfc9d5b0-4e03-4a28-b234-b59b6ad763ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-42184be3-2a00-4f14-9ced-f7f38c798bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-a913b99f-ee86-48f0-92e4-c1acded6f728,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1942860408-172.17.0.18-1597314434638:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42654,DS-1045247c-2140-4948-b16b-b47dede7adcb,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-e6187787-4049-4d08-8d11-be63ff13dd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-7afc7de1-d153-4233-abce-7ffe07eadc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-c0a2f77e-3681-4d97-9f20-064d804da714,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-338b3956-8d30-42cb-a360-4b4d0e66bd07,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-bfc9d5b0-4e03-4a28-b234-b59b6ad763ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-42184be3-2a00-4f14-9ced-f7f38c798bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-a913b99f-ee86-48f0-92e4-c1acded6f728,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1217363066-172.17.0.18-1597314700024:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38192,DS-e1c632ae-a76f-4e70-bfc6-bb44aa789391,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-7c0d87cf-a230-4d7c-bd5c-521632e0f3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-b659b82c-17d5-44e5-95bc-e19aad9b6928,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-f729c41f-c895-49e6-8eb2-1846e82b73fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-b47f6892-4cac-44e3-9394-6e6319f845a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-dc901372-db38-4f01-810e-fda8618141b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-1e070347-7e70-4645-a280-b72bb69a4720,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-085ac7b4-bc80-4b9c-862d-b1db7f81680a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1217363066-172.17.0.18-1597314700024:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38192,DS-e1c632ae-a76f-4e70-bfc6-bb44aa789391,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-7c0d87cf-a230-4d7c-bd5c-521632e0f3a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-b659b82c-17d5-44e5-95bc-e19aad9b6928,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-f729c41f-c895-49e6-8eb2-1846e82b73fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-b47f6892-4cac-44e3-9394-6e6319f845a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34522,DS-dc901372-db38-4f01-810e-fda8618141b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-1e070347-7e70-4645-a280-b72bb69a4720,DISK], DatanodeInfoWithStorage[127.0.0.1:42186,DS-085ac7b4-bc80-4b9c-862d-b1db7f81680a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1447485601-172.17.0.18-1597314920652:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38125,DS-a27aeed9-9e4e-4b8d-b502-5f0e65a0d040,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-c6994cf5-d1c5-44bf-b0b6-a2ad43af929e,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-526db36b-0e0d-4113-97ff-20d11965cc36,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-aa885dcd-d122-4950-88ad-a12a6cddc3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-3a8683cc-362a-458c-81f0-c1099e6e21b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-afedd729-a993-496e-a299-358628fec064,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-e86b6f37-1bbf-4663-83f0-2f701dcacc45,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-bedefd06-fae7-40c7-bc29-e935934322d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1447485601-172.17.0.18-1597314920652:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38125,DS-a27aeed9-9e4e-4b8d-b502-5f0e65a0d040,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-c6994cf5-d1c5-44bf-b0b6-a2ad43af929e,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-526db36b-0e0d-4113-97ff-20d11965cc36,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-aa885dcd-d122-4950-88ad-a12a6cddc3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-3a8683cc-362a-458c-81f0-c1099e6e21b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-afedd729-a993-496e-a299-358628fec064,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-e86b6f37-1bbf-4663-83f0-2f701dcacc45,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-bedefd06-fae7-40c7-bc29-e935934322d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-764951248-172.17.0.18-1597315364368:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37537,DS-b5d99915-6b7e-43cb-a216-cb90d5102272,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-a973d9cb-2655-4b80-8d8d-e80b7e387e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-0c79a43d-cfa0-4d19-8521-858bc7225332,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-10e0af05-c20a-439d-aab0-9b7bc760da7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-a70fd500-c00e-4955-bf21-d5de1a964ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-66eb5176-8b79-464b-bcd9-0bb75370c5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-e31d0463-9aaa-44ec-a28e-b7055baed4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-eb2761b1-a335-4815-813f-b2d4614f0edf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-764951248-172.17.0.18-1597315364368:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37537,DS-b5d99915-6b7e-43cb-a216-cb90d5102272,DISK], DatanodeInfoWithStorage[127.0.0.1:35032,DS-a973d9cb-2655-4b80-8d8d-e80b7e387e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-0c79a43d-cfa0-4d19-8521-858bc7225332,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-10e0af05-c20a-439d-aab0-9b7bc760da7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-a70fd500-c00e-4955-bf21-d5de1a964ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-66eb5176-8b79-464b-bcd9-0bb75370c5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-e31d0463-9aaa-44ec-a28e-b7055baed4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41125,DS-eb2761b1-a335-4815-813f-b2d4614f0edf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1528756354-172.17.0.18-1597315437703:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40483,DS-435e3384-c6f9-4588-b87d-e9fcae52d57a,DISK], DatanodeInfoWithStorage[127.0.0.1:41254,DS-30757f7c-8152-4f07-a409-69ea23c91664,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-b3e3f442-7d31-4778-9e0f-602b1fabc2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-5ebe4461-c3a1-442b-a47f-ab4850650ece,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-607e400e-8618-4be0-8188-5cf54413b906,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-6f8d335b-3808-4b0a-aaa9-930a49ee73dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-d04ad1f7-7693-45dc-acd6-b7de763d8376,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-9867d12f-20c0-4290-8dc8-58cd5743fdf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1528756354-172.17.0.18-1597315437703:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40483,DS-435e3384-c6f9-4588-b87d-e9fcae52d57a,DISK], DatanodeInfoWithStorage[127.0.0.1:41254,DS-30757f7c-8152-4f07-a409-69ea23c91664,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-b3e3f442-7d31-4778-9e0f-602b1fabc2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-5ebe4461-c3a1-442b-a47f-ab4850650ece,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-607e400e-8618-4be0-8188-5cf54413b906,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-6f8d335b-3808-4b0a-aaa9-930a49ee73dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-d04ad1f7-7693-45dc-acd6-b7de763d8376,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-9867d12f-20c0-4290-8dc8-58cd5743fdf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-248706251-172.17.0.18-1597315509538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41597,DS-0f83d0c0-6dd3-4b61-abae-0628a2871160,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-178bbc9b-83e4-404a-a63a-e7e88db76c56,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-2162e33f-6293-4c69-bdff-fd873181ca5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-40eb33c9-691a-43c5-a8d2-5872c62d7df0,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-cd3bcc93-76cf-41a1-8edc-1fe969330684,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-af42aff4-ce5a-4f7f-aaab-fffc95fd05da,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-cc97de6d-5f67-4f8b-ab56-3ffb58e81188,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-72c3f35f-add6-4b37-97d2-db571f395dc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-248706251-172.17.0.18-1597315509538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41597,DS-0f83d0c0-6dd3-4b61-abae-0628a2871160,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-178bbc9b-83e4-404a-a63a-e7e88db76c56,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-2162e33f-6293-4c69-bdff-fd873181ca5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-40eb33c9-691a-43c5-a8d2-5872c62d7df0,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-cd3bcc93-76cf-41a1-8edc-1fe969330684,DISK], DatanodeInfoWithStorage[127.0.0.1:37348,DS-af42aff4-ce5a-4f7f-aaab-fffc95fd05da,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-cc97de6d-5f67-4f8b-ab56-3ffb58e81188,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-72c3f35f-add6-4b37-97d2-db571f395dc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 134217728
v2: 6291456
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756664891-172.17.0.18-1597316270018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36346,DS-94829d4a-85fb-49e7-af12-eee14718068d,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-b5f91270-634a-4856-8f16-0947bd0a1ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-a4012881-01e2-401b-98fb-5dd62b2b6110,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-2abb269c-700b-42ae-9ea7-546d599fa8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-096b07b9-a4f3-432f-b4a8-e8e90776e927,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-6fcdbced-443a-4183-a27e-b868721d4a33,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-abd64cc1-8b20-4f3a-9dc8-93fc556f8f36,DISK], DatanodeInfoWithStorage[127.0.0.1:33514,DS-9338a2cb-3d92-4162-8902-e6ec705776d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756664891-172.17.0.18-1597316270018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36346,DS-94829d4a-85fb-49e7-af12-eee14718068d,DISK], DatanodeInfoWithStorage[127.0.0.1:39282,DS-b5f91270-634a-4856-8f16-0947bd0a1ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-a4012881-01e2-401b-98fb-5dd62b2b6110,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-2abb269c-700b-42ae-9ea7-546d599fa8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-096b07b9-a4f3-432f-b4a8-e8e90776e927,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-6fcdbced-443a-4183-a27e-b868721d4a33,DISK], DatanodeInfoWithStorage[127.0.0.1:33235,DS-abd64cc1-8b20-4f3a-9dc8-93fc556f8f36,DISK], DatanodeInfoWithStorage[127.0.0.1:33514,DS-9338a2cb-3d92-4162-8902-e6ec705776d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5584
