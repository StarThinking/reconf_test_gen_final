reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680278920-172.17.0.5-1597571331947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42196,DS-77d4368d-c3e7-4b85-8b1e-d04a51fb4567,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-3b0a32f4-f19b-44f6-95cf-b95f714f6cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-52502ef6-d487-4816-9a54-a392359ad120,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-4daaf574-9729-47b3-9d81-13d07a8d0ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-7b1ee343-daed-439e-8c70-bad6320c2cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-3a2c479f-3c8d-4e7d-bee7-bdf8370f812a,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-b173a1f7-0654-4a5e-80a9-39c871a1ae0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-77b5f3c8-4d64-4ec1-8470-16aae53f381b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680278920-172.17.0.5-1597571331947:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42196,DS-77d4368d-c3e7-4b85-8b1e-d04a51fb4567,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-3b0a32f4-f19b-44f6-95cf-b95f714f6cc1,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-52502ef6-d487-4816-9a54-a392359ad120,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-4daaf574-9729-47b3-9d81-13d07a8d0ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:39310,DS-7b1ee343-daed-439e-8c70-bad6320c2cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-3a2c479f-3c8d-4e7d-bee7-bdf8370f812a,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-b173a1f7-0654-4a5e-80a9-39c871a1ae0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-77b5f3c8-4d64-4ec1-8470-16aae53f381b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-79443102-172.17.0.5-1597571411095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38308,DS-b606feca-4f89-4b3c-b09b-ce25beb0467e,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-58daa092-3ff1-4bea-867b-2de409c936e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-8febd19c-4d9d-4d68-b2fd-854bafa0099b,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-0f92c02f-d6a4-4c93-9419-f16280523e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-25961314-d7e8-40da-b6bb-fe6b1af74b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-fd762eab-e9de-4059-ab28-039f1e4ead17,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-38951ae5-8151-4570-ab80-993ca26b4130,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-fd2bca0b-094a-479b-8e00-81c53e332df9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-79443102-172.17.0.5-1597571411095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38308,DS-b606feca-4f89-4b3c-b09b-ce25beb0467e,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-58daa092-3ff1-4bea-867b-2de409c936e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-8febd19c-4d9d-4d68-b2fd-854bafa0099b,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-0f92c02f-d6a4-4c93-9419-f16280523e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-25961314-d7e8-40da-b6bb-fe6b1af74b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-fd762eab-e9de-4059-ab28-039f1e4ead17,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-38951ae5-8151-4570-ab80-993ca26b4130,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-fd2bca0b-094a-479b-8e00-81c53e332df9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-448836984-172.17.0.5-1597571556719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41919,DS-ce3faf17-b656-40f1-b3a6-7717b0495f91,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-d6a24591-dbe5-4f33-a38b-7fef67e789a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-41915dbf-d14a-4288-9a22-7f786e2ee919,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-55b24f48-eb7a-4570-8e09-66e2c15c4604,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-4f4e7862-7914-4b41-a611-30a8f85fd01b,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-fa4f5d89-b198-4cb6-beae-274905bd2d85,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-00bc07ea-1ebe-4a0c-866f-35dd1d54aa53,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-d132b315-3620-4dcb-af7e-f0f9b958acef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-448836984-172.17.0.5-1597571556719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41919,DS-ce3faf17-b656-40f1-b3a6-7717b0495f91,DISK], DatanodeInfoWithStorage[127.0.0.1:41939,DS-d6a24591-dbe5-4f33-a38b-7fef67e789a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-41915dbf-d14a-4288-9a22-7f786e2ee919,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-55b24f48-eb7a-4570-8e09-66e2c15c4604,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-4f4e7862-7914-4b41-a611-30a8f85fd01b,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-fa4f5d89-b198-4cb6-beae-274905bd2d85,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-00bc07ea-1ebe-4a0c-866f-35dd1d54aa53,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-d132b315-3620-4dcb-af7e-f0f9b958acef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-364046041-172.17.0.5-1597571589590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39704,DS-1b58e471-04c0-4c4d-8bf2-3430a27357bd,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-2f126275-21fa-49f3-94e3-f4c32bac8264,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-c1d5edb2-eeae-48e7-b58a-c90697fbd386,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-583f28ab-aefd-4a78-aeaa-60d41f28de70,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-ee60a7d4-1db1-437f-988c-8deb847f4998,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-c45d457f-01af-4c71-b0fa-41a9c839e2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-4bfc0d3c-f620-4239-bcd4-99ccaf60ab23,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-d020cc12-c7c3-4026-aa54-f5533be6269b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-364046041-172.17.0.5-1597571589590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39704,DS-1b58e471-04c0-4c4d-8bf2-3430a27357bd,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-2f126275-21fa-49f3-94e3-f4c32bac8264,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-c1d5edb2-eeae-48e7-b58a-c90697fbd386,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-583f28ab-aefd-4a78-aeaa-60d41f28de70,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-ee60a7d4-1db1-437f-988c-8deb847f4998,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-c45d457f-01af-4c71-b0fa-41a9c839e2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-4bfc0d3c-f620-4239-bcd4-99ccaf60ab23,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-d020cc12-c7c3-4026-aa54-f5533be6269b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-908935585-172.17.0.5-1597571754549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42308,DS-574b6467-d289-4582-b9ce-31f29fea9e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-9ed14c43-b41b-4574-9b10-9aba2d4cd728,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-7516c459-8f10-47f6-875c-5e6dc7382375,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-299dcbb9-ff7c-4479-86d9-405acb2dfc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-3fa2f476-14e2-492a-8ee5-05fcbef73c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-7dd4507e-a66b-410b-a701-06609483f04f,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-2874d0cb-ec82-4ba6-bcbc-c68d036d7497,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-60db77d7-4aa7-45ac-962b-1a0d21d650aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-908935585-172.17.0.5-1597571754549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42308,DS-574b6467-d289-4582-b9ce-31f29fea9e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-9ed14c43-b41b-4574-9b10-9aba2d4cd728,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-7516c459-8f10-47f6-875c-5e6dc7382375,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-299dcbb9-ff7c-4479-86d9-405acb2dfc9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42377,DS-3fa2f476-14e2-492a-8ee5-05fcbef73c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-7dd4507e-a66b-410b-a701-06609483f04f,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-2874d0cb-ec82-4ba6-bcbc-c68d036d7497,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-60db77d7-4aa7-45ac-962b-1a0d21d650aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1989129409-172.17.0.5-1597572773921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46492,DS-7059cee7-752b-47d0-8d22-46a99910098d,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-be2362de-72e4-4d27-8954-97594c733a56,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-104b1a94-583e-4e71-a688-7d8a5009bd82,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-d82f22a0-8b0f-49a1-9966-4df4ef53c9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-440c7d95-2678-4895-936f-c605fa3d1355,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-1c339d22-4151-4538-b784-961501ec8007,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-6a55ec74-fefd-4b26-8076-bb48dffea6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-d282c485-7b7e-4a64-a00e-b744e0aa2d2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1989129409-172.17.0.5-1597572773921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46492,DS-7059cee7-752b-47d0-8d22-46a99910098d,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-be2362de-72e4-4d27-8954-97594c733a56,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-104b1a94-583e-4e71-a688-7d8a5009bd82,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-d82f22a0-8b0f-49a1-9966-4df4ef53c9b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-440c7d95-2678-4895-936f-c605fa3d1355,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-1c339d22-4151-4538-b784-961501ec8007,DISK], DatanodeInfoWithStorage[127.0.0.1:38380,DS-6a55ec74-fefd-4b26-8076-bb48dffea6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33253,DS-d282c485-7b7e-4a64-a00e-b744e0aa2d2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-269829629-172.17.0.5-1597573491800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46722,DS-2b29d58b-3658-4bf5-90ef-091d8920b536,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-7b04f43a-e5ab-4767-9208-b3a9d549f727,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-e68e691a-a631-4a94-aa9b-077e763ae53b,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-9f7fbace-f3ed-4a20-9952-15cea9eee1da,DISK], DatanodeInfoWithStorage[127.0.0.1:46582,DS-c4392aad-0fe9-4b7e-841d-970e2367fc08,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-625a709c-6e27-4264-b1f8-0d453ec6d17e,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-f21d1e54-603a-4512-bcb8-8578fbabbf99,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-77919d07-008e-477a-b55a-55def85a7dc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-269829629-172.17.0.5-1597573491800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46722,DS-2b29d58b-3658-4bf5-90ef-091d8920b536,DISK], DatanodeInfoWithStorage[127.0.0.1:34119,DS-7b04f43a-e5ab-4767-9208-b3a9d549f727,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-e68e691a-a631-4a94-aa9b-077e763ae53b,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-9f7fbace-f3ed-4a20-9952-15cea9eee1da,DISK], DatanodeInfoWithStorage[127.0.0.1:46582,DS-c4392aad-0fe9-4b7e-841d-970e2367fc08,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-625a709c-6e27-4264-b1f8-0d453ec6d17e,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-f21d1e54-603a-4512-bcb8-8578fbabbf99,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-77919d07-008e-477a-b55a-55def85a7dc9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-717066083-172.17.0.5-1597573610909:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44483,DS-017fe16a-f875-4fec-a3aa-23da3bda6e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33831,DS-da721650-4f6d-40fb-aedb-88a9e4511672,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-71a7e066-3698-416d-ac0f-8149e7de125a,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-6219a853-65cd-4712-bdcc-ccc194b52dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-2145637f-5144-4f6b-8f19-59158e710bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-24011168-df18-43cd-bd58-cbefb063c26a,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-ca2f5474-29a5-47bf-b086-90ea0a76598a,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-5f1c4cbe-7219-42e9-b0c7-48281f5f36f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-717066083-172.17.0.5-1597573610909:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44483,DS-017fe16a-f875-4fec-a3aa-23da3bda6e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33831,DS-da721650-4f6d-40fb-aedb-88a9e4511672,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-71a7e066-3698-416d-ac0f-8149e7de125a,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-6219a853-65cd-4712-bdcc-ccc194b52dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-2145637f-5144-4f6b-8f19-59158e710bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-24011168-df18-43cd-bd58-cbefb063c26a,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-ca2f5474-29a5-47bf-b086-90ea0a76598a,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-5f1c4cbe-7219-42e9-b0c7-48281f5f36f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-716132622-172.17.0.5-1597573822439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34843,DS-29aea4ba-c090-4854-b0f6-597dd29e18ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-b5001f08-b6f1-4825-b3ab-cd069a5dcb87,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-0e36e094-4e5a-4ab1-9d27-dfb48dd10784,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-6c03cc74-1434-4adb-8251-2e83cfe2fe5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43520,DS-f74bfbad-eb83-479b-a51a-771eb14474e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-93f18532-b6d0-4eb9-af4a-5b3c7d977182,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-11569087-86ad-42ed-9780-3168bb53dc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-0c401b32-d045-47e4-944b-b277a67c456a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-716132622-172.17.0.5-1597573822439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34843,DS-29aea4ba-c090-4854-b0f6-597dd29e18ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45072,DS-b5001f08-b6f1-4825-b3ab-cd069a5dcb87,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-0e36e094-4e5a-4ab1-9d27-dfb48dd10784,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-6c03cc74-1434-4adb-8251-2e83cfe2fe5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43520,DS-f74bfbad-eb83-479b-a51a-771eb14474e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-93f18532-b6d0-4eb9-af4a-5b3c7d977182,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-11569087-86ad-42ed-9780-3168bb53dc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-0c401b32-d045-47e4-944b-b277a67c456a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1094553542-172.17.0.5-1597573928533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36340,DS-bab86670-20f2-4804-ab86-53e6050c8863,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-441fd889-f4f3-4280-8abc-0acfb210efb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-7f2529f4-7812-4c9e-a1e4-b97be0db4cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-73439dd6-f9a3-40f1-b9be-5b3295c31109,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-27f8bff9-81af-433f-8af8-140f51360064,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-b984033e-35c8-4ca8-a5e0-07d0842eb187,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-242f9bdc-05cf-4efe-8db7-149170e891b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-be2c0731-5085-41c0-a747-ee5367c2d3b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1094553542-172.17.0.5-1597573928533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36340,DS-bab86670-20f2-4804-ab86-53e6050c8863,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-441fd889-f4f3-4280-8abc-0acfb210efb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39911,DS-7f2529f4-7812-4c9e-a1e4-b97be0db4cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-73439dd6-f9a3-40f1-b9be-5b3295c31109,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-27f8bff9-81af-433f-8af8-140f51360064,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-b984033e-35c8-4ca8-a5e0-07d0842eb187,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-242f9bdc-05cf-4efe-8db7-149170e891b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-be2c0731-5085-41c0-a747-ee5367c2d3b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-167178079-172.17.0.5-1597574191394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43994,DS-044d390f-e89d-45e6-b597-be92e17e9ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-7ab3313f-4022-42ff-858d-074696e0102e,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-52340a73-2339-4549-a9c0-ff108d50fd29,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-b3e0d367-3ba4-41ac-a881-7efea1d3ec50,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-2186a5dd-aceb-417a-914b-b232fe86bccd,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-4e62976e-0598-435a-9b3f-6c1645795a20,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-3f7f9c7e-b06e-4657-bb13-23b63c54bcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-5550d026-87ee-4e17-913e-f26b847d8132,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-167178079-172.17.0.5-1597574191394:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43994,DS-044d390f-e89d-45e6-b597-be92e17e9ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-7ab3313f-4022-42ff-858d-074696e0102e,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-52340a73-2339-4549-a9c0-ff108d50fd29,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-b3e0d367-3ba4-41ac-a881-7efea1d3ec50,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-2186a5dd-aceb-417a-914b-b232fe86bccd,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-4e62976e-0598-435a-9b3f-6c1645795a20,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-3f7f9c7e-b06e-4657-bb13-23b63c54bcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-5550d026-87ee-4e17-913e-f26b847d8132,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1937849592-172.17.0.5-1597574358879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39101,DS-635abc14-dcc3-4c4d-9b18-a8c06fb89ede,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-04b4671d-b88e-4075-a7d0-a004cb556962,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-49158f3b-7109-4d6b-add2-5ce1d52a54da,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-b1c16aad-f84b-4626-a74e-9d26eca8e7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-77aa88be-0a7a-4ff5-a948-1fb5f2aec1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-ad7c2270-1683-477c-9f8c-7305c5d01b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-0a670727-8059-48ca-bab6-82929dbd1409,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-72aa0fcb-dfcf-46b2-8cc0-1443606e1929,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1937849592-172.17.0.5-1597574358879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39101,DS-635abc14-dcc3-4c4d-9b18-a8c06fb89ede,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-04b4671d-b88e-4075-a7d0-a004cb556962,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-49158f3b-7109-4d6b-add2-5ce1d52a54da,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-b1c16aad-f84b-4626-a74e-9d26eca8e7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-77aa88be-0a7a-4ff5-a948-1fb5f2aec1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-ad7c2270-1683-477c-9f8c-7305c5d01b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-0a670727-8059-48ca-bab6-82929dbd1409,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-72aa0fcb-dfcf-46b2-8cc0-1443606e1929,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-549022702-172.17.0.5-1597574800800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39039,DS-8c32637f-1698-49e7-8daf-32f5da27996a,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-3b551c6b-4e47-4cec-8d09-8e3d1cf1ba37,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-1b4cb065-a374-4de0-b1fd-df56cac7cd21,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-f81df520-8072-4198-beb5-593aae38bd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-8d3bd6cd-4987-4bda-a2d4-cf1d19db432a,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-6108da35-0198-4e01-bcc0-ef4bd7705868,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-a10ae759-09d2-479a-8b8d-d60bcf687629,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-c65e5209-b0ab-4750-a421-750dcea6c1ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-549022702-172.17.0.5-1597574800800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39039,DS-8c32637f-1698-49e7-8daf-32f5da27996a,DISK], DatanodeInfoWithStorage[127.0.0.1:36250,DS-3b551c6b-4e47-4cec-8d09-8e3d1cf1ba37,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-1b4cb065-a374-4de0-b1fd-df56cac7cd21,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-f81df520-8072-4198-beb5-593aae38bd2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-8d3bd6cd-4987-4bda-a2d4-cf1d19db432a,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-6108da35-0198-4e01-bcc0-ef4bd7705868,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-a10ae759-09d2-479a-8b8d-d60bcf687629,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-c65e5209-b0ab-4750-a421-750dcea6c1ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1094838887-172.17.0.5-1597575114831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35279,DS-17673ada-fc63-4b2e-be80-93b669f5b76f,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-b47c29b6-dd2e-48e3-b9dd-fa9bf12eecc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-10bcd3a9-a1f1-4048-a0c7-1b618011f29f,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-9d3b5351-1ec2-4087-a18a-57a6ecfde520,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-90a6514a-f596-4edd-ba50-1fe02c028838,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-fc00be25-dfff-4a8f-bcf3-7fe2a7bc0d55,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-b643753a-320a-4fe3-ad5b-7a14e26070df,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-c8cead2d-97f0-4336-b988-0fb3fa062b5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1094838887-172.17.0.5-1597575114831:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35279,DS-17673ada-fc63-4b2e-be80-93b669f5b76f,DISK], DatanodeInfoWithStorage[127.0.0.1:35499,DS-b47c29b6-dd2e-48e3-b9dd-fa9bf12eecc4,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-10bcd3a9-a1f1-4048-a0c7-1b618011f29f,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-9d3b5351-1ec2-4087-a18a-57a6ecfde520,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-90a6514a-f596-4edd-ba50-1fe02c028838,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-fc00be25-dfff-4a8f-bcf3-7fe2a7bc0d55,DISK], DatanodeInfoWithStorage[127.0.0.1:32997,DS-b643753a-320a-4fe3-ad5b-7a14e26070df,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-c8cead2d-97f0-4336-b988-0fb3fa062b5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-792756156-172.17.0.5-1597575708287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33600,DS-4aecec0c-f79a-450f-a551-0bea06893fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-bff57e56-4f72-4c7b-aa2c-febe105074f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-af5e1f84-3264-41e7-86c4-8279a86fab4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-43c3af0f-aafb-4906-a72a-43e7a2ad33b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-c5410d41-de29-4c29-b4be-c8b4c954f4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-ea8fd87a-4c5a-46df-9f21-e082ea5ad1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-7f2bd3cc-0a18-43d1-92f8-80fbd0218e56,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-fddfcceb-aa60-4212-a161-e42a1dab092e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-792756156-172.17.0.5-1597575708287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33600,DS-4aecec0c-f79a-450f-a551-0bea06893fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:46302,DS-bff57e56-4f72-4c7b-aa2c-febe105074f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46388,DS-af5e1f84-3264-41e7-86c4-8279a86fab4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-43c3af0f-aafb-4906-a72a-43e7a2ad33b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-c5410d41-de29-4c29-b4be-c8b4c954f4ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41783,DS-ea8fd87a-4c5a-46df-9f21-e082ea5ad1ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-7f2bd3cc-0a18-43d1-92f8-80fbd0218e56,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-fddfcceb-aa60-4212-a161-e42a1dab092e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-914105118-172.17.0.5-1597575857283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38155,DS-eefd4148-5f08-4e3c-9ce3-6da933f6db33,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-46fe9ae1-114a-4815-8406-63276d51a16b,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-c88d52af-a81f-4b5d-a6c3-2ad33b9b88d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-89bff846-ffcb-4622-af1e-1780425f4099,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-4fb7d266-b8c8-4afa-9c2e-56be9e9e3bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-8c6251e0-dd48-4236-b50d-d85093821693,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-f77224a2-4b95-49d0-8feb-76b8b258e428,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-78a70065-50f7-4f1a-955d-49512e8035d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-914105118-172.17.0.5-1597575857283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38155,DS-eefd4148-5f08-4e3c-9ce3-6da933f6db33,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-46fe9ae1-114a-4815-8406-63276d51a16b,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-c88d52af-a81f-4b5d-a6c3-2ad33b9b88d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-89bff846-ffcb-4622-af1e-1780425f4099,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-4fb7d266-b8c8-4afa-9c2e-56be9e9e3bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-8c6251e0-dd48-4236-b50d-d85093821693,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-f77224a2-4b95-49d0-8feb-76b8b258e428,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-78a70065-50f7-4f1a-955d-49512e8035d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1749914086-172.17.0.5-1597576109090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45972,DS-84df14f5-be84-4e88-b3a2-20c2fdd2ee27,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-e0392528-c3db-4996-9309-2c6376b2f229,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-d0c5030d-7c90-4f52-8e3a-3fcdc351030e,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-c2e3b3e2-361e-42c5-9e62-d4fcb59a5a21,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-320c8774-1eb4-47ea-8a41-5fae1c0e54c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-53d63175-099c-452f-ab8f-9537b3295a45,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-2ccd0b0e-2b49-4e72-b2c1-923947e616ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-ae611519-7c97-4b7a-a60e-a25db1310f74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1749914086-172.17.0.5-1597576109090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45972,DS-84df14f5-be84-4e88-b3a2-20c2fdd2ee27,DISK], DatanodeInfoWithStorage[127.0.0.1:45475,DS-e0392528-c3db-4996-9309-2c6376b2f229,DISK], DatanodeInfoWithStorage[127.0.0.1:34440,DS-d0c5030d-7c90-4f52-8e3a-3fcdc351030e,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-c2e3b3e2-361e-42c5-9e62-d4fcb59a5a21,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-320c8774-1eb4-47ea-8a41-5fae1c0e54c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43980,DS-53d63175-099c-452f-ab8f-9537b3295a45,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-2ccd0b0e-2b49-4e72-b2c1-923947e616ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-ae611519-7c97-4b7a-a60e-a25db1310f74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-494286401-172.17.0.5-1597576376262:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36842,DS-8bfc8752-9ae1-4340-bdfa-7a3e4f47eb37,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-ac3b58bf-53ed-4dad-b4e4-5d3edad0de27,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-46804c39-2c05-4f19-b116-6c2b0eab4a03,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-d077b29c-ce62-4a4c-a1f0-c247744a168d,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-204330dc-cef8-4aa2-aaf7-86bcee349da5,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-7ce2b201-eda0-433b-88c4-2ae52ab7810d,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-8d1701b0-4e9a-42f7-9cff-2cefdcc7453b,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-287f3978-5f07-49a7-bd56-c14fc5364f9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-494286401-172.17.0.5-1597576376262:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36842,DS-8bfc8752-9ae1-4340-bdfa-7a3e4f47eb37,DISK], DatanodeInfoWithStorage[127.0.0.1:39155,DS-ac3b58bf-53ed-4dad-b4e4-5d3edad0de27,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-46804c39-2c05-4f19-b116-6c2b0eab4a03,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-d077b29c-ce62-4a4c-a1f0-c247744a168d,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-204330dc-cef8-4aa2-aaf7-86bcee349da5,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-7ce2b201-eda0-433b-88c4-2ae52ab7810d,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-8d1701b0-4e9a-42f7-9cff-2cefdcc7453b,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-287f3978-5f07-49a7-bd56-c14fc5364f9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5635
