reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-471349838-172.17.0.16-1597477841272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44358,DS-f216be89-c60f-4aaf-85ad-cae29e77574e,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-b82ba407-ddc4-4da6-b58f-9a3d45c23359,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-25bb434f-e390-4308-9e78-4d6a457c5f51,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-2dece207-f379-4112-b91b-8ca66b9309e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-f33bc644-04c1-477e-b691-3666562eefa3,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-b5903d48-159a-4423-976e-9ef446322218,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-cea53d4c-6106-4e4b-ba44-04c9964a5827,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-447b03db-98c1-4a71-95f1-3653e933d18f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-471349838-172.17.0.16-1597477841272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44358,DS-f216be89-c60f-4aaf-85ad-cae29e77574e,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-b82ba407-ddc4-4da6-b58f-9a3d45c23359,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-25bb434f-e390-4308-9e78-4d6a457c5f51,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-2dece207-f379-4112-b91b-8ca66b9309e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-f33bc644-04c1-477e-b691-3666562eefa3,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-b5903d48-159a-4423-976e-9ef446322218,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-cea53d4c-6106-4e4b-ba44-04c9964a5827,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-447b03db-98c1-4a71-95f1-3653e933d18f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1605950894-172.17.0.16-1597477871204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37202,DS-f7744efb-6ac6-4caa-a76a-e3a8715f77e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-184d8f6c-44fa-4243-869b-67ca872909ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-079613f5-a0e9-418a-8f84-43fbc4ffa7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-34eb90d1-4755-4a91-90da-37f19b4bd20c,DISK], DatanodeInfoWithStorage[127.0.0.1:35146,DS-9a1c1299-24ce-44c9-a58e-70cd5dbcc1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-3729511a-096a-4476-b299-7fafe0b2fd07,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-b37ebd72-e0aa-40c8-8b74-eb4a636fc62b,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-9cbbf1d7-42c1-4792-a4db-395f0a6938de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1605950894-172.17.0.16-1597477871204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37202,DS-f7744efb-6ac6-4caa-a76a-e3a8715f77e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-184d8f6c-44fa-4243-869b-67ca872909ef,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-079613f5-a0e9-418a-8f84-43fbc4ffa7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36337,DS-34eb90d1-4755-4a91-90da-37f19b4bd20c,DISK], DatanodeInfoWithStorage[127.0.0.1:35146,DS-9a1c1299-24ce-44c9-a58e-70cd5dbcc1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-3729511a-096a-4476-b299-7fafe0b2fd07,DISK], DatanodeInfoWithStorage[127.0.0.1:44623,DS-b37ebd72-e0aa-40c8-8b74-eb4a636fc62b,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-9cbbf1d7-42c1-4792-a4db-395f0a6938de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1769753156-172.17.0.16-1597477976464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42822,DS-14b4c817-143f-4bdb-9463-bb9e11ee7af5,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-b6442928-8d90-4c58-908b-5ede56890d94,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-812abacb-13e1-4c8d-b742-294fc702fc02,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-f8e82a04-100d-4f40-8d03-5b10d1bb78dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-83fa3a54-d6fe-4913-b34e-0d3257e7d43a,DISK], DatanodeInfoWithStorage[127.0.0.1:33838,DS-83352200-3fc5-426d-9710-65db4ab9e81b,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-f13f4715-6290-440d-b60c-bad31ce19329,DISK], DatanodeInfoWithStorage[127.0.0.1:37146,DS-7d50bc68-8834-450f-97ba-3dccc1a3f0b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1769753156-172.17.0.16-1597477976464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42822,DS-14b4c817-143f-4bdb-9463-bb9e11ee7af5,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-b6442928-8d90-4c58-908b-5ede56890d94,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-812abacb-13e1-4c8d-b742-294fc702fc02,DISK], DatanodeInfoWithStorage[127.0.0.1:34821,DS-f8e82a04-100d-4f40-8d03-5b10d1bb78dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-83fa3a54-d6fe-4913-b34e-0d3257e7d43a,DISK], DatanodeInfoWithStorage[127.0.0.1:33838,DS-83352200-3fc5-426d-9710-65db4ab9e81b,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-f13f4715-6290-440d-b60c-bad31ce19329,DISK], DatanodeInfoWithStorage[127.0.0.1:37146,DS-7d50bc68-8834-450f-97ba-3dccc1a3f0b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-986440933-172.17.0.16-1597478195679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33572,DS-ee45c68b-467a-4534-8bfd-31ec47acd250,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-cbd40357-0814-420e-8b72-d7c51cadefc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-76d62f6d-d92e-4a37-9cb5-d46333a12080,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-1b5fc5e4-26eb-46b7-b565-141ed481c752,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-1bf7c4bd-7aef-4d93-9da3-0683195fd6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-98757cb2-3dd1-483b-9fef-c637621e5f31,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-92d8cb7d-643f-4cc7-ae01-2e8ee43d7b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-83e8da43-c6a7-418c-9ea3-8f39872db4cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-986440933-172.17.0.16-1597478195679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33572,DS-ee45c68b-467a-4534-8bfd-31ec47acd250,DISK], DatanodeInfoWithStorage[127.0.0.1:37698,DS-cbd40357-0814-420e-8b72-d7c51cadefc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-76d62f6d-d92e-4a37-9cb5-d46333a12080,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-1b5fc5e4-26eb-46b7-b565-141ed481c752,DISK], DatanodeInfoWithStorage[127.0.0.1:41120,DS-1bf7c4bd-7aef-4d93-9da3-0683195fd6dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36253,DS-98757cb2-3dd1-483b-9fef-c637621e5f31,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-92d8cb7d-643f-4cc7-ae01-2e8ee43d7b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-83e8da43-c6a7-418c-9ea3-8f39872db4cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-967741505-172.17.0.16-1597478795814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33175,DS-30c72e02-8361-4213-b104-f5803ea292aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-d66e287e-2b60-4dfb-84d5-a42e0e0760b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-9716ceec-5fee-416d-89b4-8a1477a0a539,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-6147fc82-753e-4d7c-a2cd-c39cfb69aa19,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-e6465bce-0cdc-4b71-978f-e05daacba54e,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-102721e1-4149-46f0-9b37-a9bd5156539b,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-f92716f9-c830-4a01-a5ae-e66f69a72f32,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-6ff6a38b-c577-4268-aa81-05aff5e7d84d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-967741505-172.17.0.16-1597478795814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33175,DS-30c72e02-8361-4213-b104-f5803ea292aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-d66e287e-2b60-4dfb-84d5-a42e0e0760b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-9716ceec-5fee-416d-89b4-8a1477a0a539,DISK], DatanodeInfoWithStorage[127.0.0.1:46322,DS-6147fc82-753e-4d7c-a2cd-c39cfb69aa19,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-e6465bce-0cdc-4b71-978f-e05daacba54e,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-102721e1-4149-46f0-9b37-a9bd5156539b,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-f92716f9-c830-4a01-a5ae-e66f69a72f32,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-6ff6a38b-c577-4268-aa81-05aff5e7d84d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-790099698-172.17.0.16-1597479180832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44936,DS-9cb6394a-d392-4248-b209-99af890a36ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-aa089c71-d2df-401d-8cc6-8d09a249d920,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-3f962a63-ae78-462e-8010-57ab1d2414dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-b82ee59b-7535-4e49-985c-45ea964f903e,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-ea0750a0-fb4c-44c8-9831-470186f9d366,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-48a176dd-25d5-42b5-9c84-1a4e6e6cc1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-a7d6c9d7-f234-40b2-870f-3f832ff9c58c,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-c846e0c6-ca36-4aa6-a7c8-5b43483862c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-790099698-172.17.0.16-1597479180832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44936,DS-9cb6394a-d392-4248-b209-99af890a36ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-aa089c71-d2df-401d-8cc6-8d09a249d920,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-3f962a63-ae78-462e-8010-57ab1d2414dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-b82ee59b-7535-4e49-985c-45ea964f903e,DISK], DatanodeInfoWithStorage[127.0.0.1:39687,DS-ea0750a0-fb4c-44c8-9831-470186f9d366,DISK], DatanodeInfoWithStorage[127.0.0.1:46484,DS-48a176dd-25d5-42b5-9c84-1a4e6e6cc1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-a7d6c9d7-f234-40b2-870f-3f832ff9c58c,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-c846e0c6-ca36-4aa6-a7c8-5b43483862c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-816326108-172.17.0.16-1597479364956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37192,DS-9a66e1c2-113f-449d-8a40-ffa5e6ed8a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-70088c54-99de-47e6-aae8-331e3bbc4f98,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-0c83c3fa-3bab-4d01-950e-8581434aaf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-5765d668-52c8-4c2d-b6e0-e4fb5eeb604d,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-ea21a940-940a-463d-8f60-d40ee2253f35,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-fa020271-f053-49f3-9c40-2b42637c8213,DISK], DatanodeInfoWithStorage[127.0.0.1:33373,DS-ac6d82bd-97d4-4712-bd2b-1147ee7c4703,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-00d7921e-9203-4c93-9638-3704e767c14d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-816326108-172.17.0.16-1597479364956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37192,DS-9a66e1c2-113f-449d-8a40-ffa5e6ed8a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33295,DS-70088c54-99de-47e6-aae8-331e3bbc4f98,DISK], DatanodeInfoWithStorage[127.0.0.1:43690,DS-0c83c3fa-3bab-4d01-950e-8581434aaf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46030,DS-5765d668-52c8-4c2d-b6e0-e4fb5eeb604d,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-ea21a940-940a-463d-8f60-d40ee2253f35,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-fa020271-f053-49f3-9c40-2b42637c8213,DISK], DatanodeInfoWithStorage[127.0.0.1:33373,DS-ac6d82bd-97d4-4712-bd2b-1147ee7c4703,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-00d7921e-9203-4c93-9638-3704e767c14d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-585613792-172.17.0.16-1597480378012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33469,DS-d25a8711-82bd-4ae4-8739-c59cdb5a7ded,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-061054e9-86c0-48c9-92ff-983039af58c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-9bc5e144-eee7-4f9a-8ea9-188f9e14f9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-7fc516a7-385b-4aba-bbec-89d02e39bf59,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-d3a38b4b-4333-4e14-80ee-a9109062e4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-fa2fd0ef-c744-4e3e-9665-5d3fb9f0086c,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-07d96b70-4e27-409b-bac8-037f1ee424db,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-ae4c082f-c1ff-4e82-893a-85bef6563c2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-585613792-172.17.0.16-1597480378012:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33469,DS-d25a8711-82bd-4ae4-8739-c59cdb5a7ded,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-061054e9-86c0-48c9-92ff-983039af58c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-9bc5e144-eee7-4f9a-8ea9-188f9e14f9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-7fc516a7-385b-4aba-bbec-89d02e39bf59,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-d3a38b4b-4333-4e14-80ee-a9109062e4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44055,DS-fa2fd0ef-c744-4e3e-9665-5d3fb9f0086c,DISK], DatanodeInfoWithStorage[127.0.0.1:40550,DS-07d96b70-4e27-409b-bac8-037f1ee424db,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-ae4c082f-c1ff-4e82-893a-85bef6563c2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167056221-172.17.0.16-1597481029388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36798,DS-912e9614-b2bc-436f-a7a9-d12ab4b43fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-db3b7f23-2678-471b-b9e5-fcd2ed56f75d,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-7d04ae9d-6b49-47c0-a367-102a4da2097d,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-9722dbaa-aaea-45f9-8605-14c6490786ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-b6dd7d79-b9d4-4ae5-8133-b2e3f9f1e85f,DISK], DatanodeInfoWithStorage[127.0.0.1:37209,DS-c1e9f455-9706-4950-9b5a-875bf83fd9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-79ce35b8-98b6-4973-995b-e9a4626ccaca,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-65c00e3c-2fe2-4dda-a2dd-640dc506b6e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167056221-172.17.0.16-1597481029388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36798,DS-912e9614-b2bc-436f-a7a9-d12ab4b43fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-db3b7f23-2678-471b-b9e5-fcd2ed56f75d,DISK], DatanodeInfoWithStorage[127.0.0.1:37667,DS-7d04ae9d-6b49-47c0-a367-102a4da2097d,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-9722dbaa-aaea-45f9-8605-14c6490786ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-b6dd7d79-b9d4-4ae5-8133-b2e3f9f1e85f,DISK], DatanodeInfoWithStorage[127.0.0.1:37209,DS-c1e9f455-9706-4950-9b5a-875bf83fd9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-79ce35b8-98b6-4973-995b-e9a4626ccaca,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-65c00e3c-2fe2-4dda-a2dd-640dc506b6e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1063933557-172.17.0.16-1597481062640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34830,DS-187e3009-8969-4533-9140-b3ccb3c8db44,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-08e40264-7a3e-4b1a-b869-bd17cf8be56d,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-cff2087f-ba3d-4dcd-829c-2e6c2dbd8a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-4b1e9a95-6b05-4b9f-8bd8-2fd12ddafa85,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-53e163cd-96b1-42d1-b923-a86adceb3dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-caff53bf-ee30-4730-b6f9-32fa1be0acd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-7bb9f8f0-6c3e-4f09-9e56-efaaa26f9183,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-1e5e5ed0-31e6-45d4-ab81-50709c638a95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1063933557-172.17.0.16-1597481062640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34830,DS-187e3009-8969-4533-9140-b3ccb3c8db44,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-08e40264-7a3e-4b1a-b869-bd17cf8be56d,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-cff2087f-ba3d-4dcd-829c-2e6c2dbd8a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-4b1e9a95-6b05-4b9f-8bd8-2fd12ddafa85,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-53e163cd-96b1-42d1-b923-a86adceb3dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-caff53bf-ee30-4730-b6f9-32fa1be0acd2,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-7bb9f8f0-6c3e-4f09-9e56-efaaa26f9183,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-1e5e5ed0-31e6-45d4-ab81-50709c638a95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-242942403-172.17.0.16-1597481555526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32980,DS-b33e1980-a861-4d38-ab42-14e98a022798,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-c0ecfbe6-f8d0-43f0-9231-65ffba081786,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-5b8611c9-77a4-4d92-8458-6dd031337ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-f573d1a8-cf0b-45df-86c1-d47116f8d320,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-28992ca4-721f-4fee-8037-8e9d55a770c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-90d064fd-7a45-4a12-87bb-9019b62190ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-0d7ba074-1089-4665-a2d9-2a4f238cd513,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-57fd3860-d7ef-4e9c-aa60-91308f2a13bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-242942403-172.17.0.16-1597481555526:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32980,DS-b33e1980-a861-4d38-ab42-14e98a022798,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-c0ecfbe6-f8d0-43f0-9231-65ffba081786,DISK], DatanodeInfoWithStorage[127.0.0.1:38130,DS-5b8611c9-77a4-4d92-8458-6dd031337ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-f573d1a8-cf0b-45df-86c1-d47116f8d320,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-28992ca4-721f-4fee-8037-8e9d55a770c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-90d064fd-7a45-4a12-87bb-9019b62190ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-0d7ba074-1089-4665-a2d9-2a4f238cd513,DISK], DatanodeInfoWithStorage[127.0.0.1:44346,DS-57fd3860-d7ef-4e9c-aa60-91308f2a13bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1042506211-172.17.0.16-1597481909065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38158,DS-2d637d55-a5bd-47b0-83db-ebbc7e82670d,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-b68b5a0d-bbaa-4b33-b776-793241d6826a,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-46b41087-21b7-4a81-b3d1-094eabd18dec,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-848185d1-d976-4fa6-a994-c2d575b1e5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-650ffd8f-c0da-487e-9334-0fbb6274b8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-d11cfac2-9ce3-42ab-bfda-05d6d732616f,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-99fa48de-e2a9-4988-9ffd-fdc510bd597b,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-a77afe4f-f328-4b4c-ada0-63c8fb46f334,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1042506211-172.17.0.16-1597481909065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38158,DS-2d637d55-a5bd-47b0-83db-ebbc7e82670d,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-b68b5a0d-bbaa-4b33-b776-793241d6826a,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-46b41087-21b7-4a81-b3d1-094eabd18dec,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-848185d1-d976-4fa6-a994-c2d575b1e5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-650ffd8f-c0da-487e-9334-0fbb6274b8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-d11cfac2-9ce3-42ab-bfda-05d6d732616f,DISK], DatanodeInfoWithStorage[127.0.0.1:33291,DS-99fa48de-e2a9-4988-9ffd-fdc510bd597b,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-a77afe4f-f328-4b4c-ada0-63c8fb46f334,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-795939255-172.17.0.16-1597482243244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35862,DS-1dd11f9d-bede-412a-a175-9e9e6850b4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-1500f0a6-2a64-4572-9056-2470de629b20,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-706d9632-7540-43ca-b5ca-8b3bf5d51f35,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-b6894e16-edeb-4f27-b404-032d49c936ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-d7d86053-f6d8-483f-8dbc-fe598bfb7dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-839415e5-e80a-4f76-87dd-0977f53e5b73,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-33028085-b873-4636-8a0b-ed2543aa407f,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-ae6423f7-ab24-41d7-bc85-4a926cc90c69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-795939255-172.17.0.16-1597482243244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35862,DS-1dd11f9d-bede-412a-a175-9e9e6850b4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-1500f0a6-2a64-4572-9056-2470de629b20,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-706d9632-7540-43ca-b5ca-8b3bf5d51f35,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-b6894e16-edeb-4f27-b404-032d49c936ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-d7d86053-f6d8-483f-8dbc-fe598bfb7dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42756,DS-839415e5-e80a-4f76-87dd-0977f53e5b73,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-33028085-b873-4636-8a0b-ed2543aa407f,DISK], DatanodeInfoWithStorage[127.0.0.1:37709,DS-ae6423f7-ab24-41d7-bc85-4a926cc90c69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5708
