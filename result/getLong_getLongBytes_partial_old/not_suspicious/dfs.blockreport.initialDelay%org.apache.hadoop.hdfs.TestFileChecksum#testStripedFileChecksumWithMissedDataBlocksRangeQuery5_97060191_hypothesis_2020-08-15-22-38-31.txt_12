reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1930646934-172.17.0.14-1597531128373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42250,DS-35caa4bb-1d3f-42e5-89c7-e16d01315092,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-64cba186-9821-4e19-a105-fdad6c492736,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-df3de479-f258-4746-a7c3-f3a4b804b682,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-d5e5e8f2-106f-4191-9893-73fb4833a936,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-f1c8d118-679b-4bff-bf49-eef71ca19fac,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-5ce746f2-f6a1-4723-8505-cbc2248ae3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-39744d62-34ad-4263-9adb-73c679ab7036,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-7ecaaa5e-5d2c-426a-8e84-05e4706a463b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1930646934-172.17.0.14-1597531128373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42250,DS-35caa4bb-1d3f-42e5-89c7-e16d01315092,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-64cba186-9821-4e19-a105-fdad6c492736,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-df3de479-f258-4746-a7c3-f3a4b804b682,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-d5e5e8f2-106f-4191-9893-73fb4833a936,DISK], DatanodeInfoWithStorage[127.0.0.1:33447,DS-f1c8d118-679b-4bff-bf49-eef71ca19fac,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-5ce746f2-f6a1-4723-8505-cbc2248ae3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37799,DS-39744d62-34ad-4263-9adb-73c679ab7036,DISK], DatanodeInfoWithStorage[127.0.0.1:41947,DS-7ecaaa5e-5d2c-426a-8e84-05e4706a463b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069433101-172.17.0.14-1597531271383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35364,DS-89a010c8-cbf1-41a0-8e4f-57649d3a1e78,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-93801a52-387d-4a40-9c9e-5050044f755b,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-8c3a36c7-2779-4471-9246-c275623545dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-a6eb6c24-b484-4790-8f98-ef6dc03bb091,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-6dcc9aea-dbca-4a40-9ec1-297e64412c75,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-6696f913-a68d-4efb-81ce-eaf073566add,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-beeed9d0-a2cf-4ff9-b664-b901402bf06d,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-07443d2d-2a1e-4244-a22c-a3f267e16a46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069433101-172.17.0.14-1597531271383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35364,DS-89a010c8-cbf1-41a0-8e4f-57649d3a1e78,DISK], DatanodeInfoWithStorage[127.0.0.1:43457,DS-93801a52-387d-4a40-9c9e-5050044f755b,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-8c3a36c7-2779-4471-9246-c275623545dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-a6eb6c24-b484-4790-8f98-ef6dc03bb091,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-6dcc9aea-dbca-4a40-9ec1-297e64412c75,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-6696f913-a68d-4efb-81ce-eaf073566add,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-beeed9d0-a2cf-4ff9-b664-b901402bf06d,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-07443d2d-2a1e-4244-a22c-a3f267e16a46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1541753187-172.17.0.14-1597531461536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40503,DS-d4e78a8b-a675-4a8d-a3e8-4fb4f6d6d78a,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-0bc842ad-b2f8-436f-912f-da281758d136,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-ce1ba588-a49e-4ad6-9cf4-8eee058e563d,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-c79b2294-e771-4c62-aa34-a6969e7f269b,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-f78756f7-ce68-4445-b5dc-4b28adcec281,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-27e80873-bb0a-46d1-8638-17b842087ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-7487d841-7368-47ac-a839-e7658b841c29,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-a9585701-ed1c-416d-a3c9-cf7da76035bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1541753187-172.17.0.14-1597531461536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40503,DS-d4e78a8b-a675-4a8d-a3e8-4fb4f6d6d78a,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-0bc842ad-b2f8-436f-912f-da281758d136,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-ce1ba588-a49e-4ad6-9cf4-8eee058e563d,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-c79b2294-e771-4c62-aa34-a6969e7f269b,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-f78756f7-ce68-4445-b5dc-4b28adcec281,DISK], DatanodeInfoWithStorage[127.0.0.1:46608,DS-27e80873-bb0a-46d1-8638-17b842087ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-7487d841-7368-47ac-a839-e7658b841c29,DISK], DatanodeInfoWithStorage[127.0.0.1:33797,DS-a9585701-ed1c-416d-a3c9-cf7da76035bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-776257354-172.17.0.14-1597531950228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40486,DS-4e352ef4-214e-47e5-83d9-bb7ec14bf672,DISK], DatanodeInfoWithStorage[127.0.0.1:33998,DS-5ce8b26c-74c2-46cf-9d12-d4d4658ab8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-d374b209-3818-4b9a-9e8a-1fb093b37ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-2d286da2-6e8e-42db-b498-71ef140107a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-563b7dbc-5927-4158-9af8-e199f788252f,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-f53b7cef-41b2-43c9-976d-7f97a746a2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-c5f33341-1232-42f9-8899-d810436e36b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-81a1d64e-c4b9-4db2-875d-4fcd302b195b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-776257354-172.17.0.14-1597531950228:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40486,DS-4e352ef4-214e-47e5-83d9-bb7ec14bf672,DISK], DatanodeInfoWithStorage[127.0.0.1:33998,DS-5ce8b26c-74c2-46cf-9d12-d4d4658ab8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-d374b209-3818-4b9a-9e8a-1fb093b37ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-2d286da2-6e8e-42db-b498-71ef140107a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-563b7dbc-5927-4158-9af8-e199f788252f,DISK], DatanodeInfoWithStorage[127.0.0.1:46870,DS-f53b7cef-41b2-43c9-976d-7f97a746a2b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-c5f33341-1232-42f9-8899-d810436e36b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-81a1d64e-c4b9-4db2-875d-4fcd302b195b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383958222-172.17.0.14-1597532079619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44837,DS-66ef4f87-97cc-42df-9a65-ed3789d42b68,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-3b353996-172a-4b34-afa8-7939b8831293,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-f4104151-7fde-473c-bc92-b88806aed071,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-30710ad0-b383-4b63-bb07-f87341acae6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-f2b8b4a3-417d-4e2b-a3f5-6caa43af208d,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-1227531d-41d6-4d73-8faf-43da712de6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-9db45ee9-aa5d-4614-9292-c89285d60276,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-3f28d6ea-5fa0-4aae-8c10-d411ba483d16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383958222-172.17.0.14-1597532079619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44837,DS-66ef4f87-97cc-42df-9a65-ed3789d42b68,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-3b353996-172a-4b34-afa8-7939b8831293,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-f4104151-7fde-473c-bc92-b88806aed071,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-30710ad0-b383-4b63-bb07-f87341acae6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-f2b8b4a3-417d-4e2b-a3f5-6caa43af208d,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-1227531d-41d6-4d73-8faf-43da712de6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40208,DS-9db45ee9-aa5d-4614-9292-c89285d60276,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-3f28d6ea-5fa0-4aae-8c10-d411ba483d16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257442291-172.17.0.14-1597532122522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45694,DS-86a1cbb4-9e5b-4395-a384-c48f8c2177c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-a0e81a1b-54f6-4122-ad14-11bc0f05e72f,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-da598b6f-68ab-41b0-8d3b-171fd4deadc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-dfb49545-6ee7-45a0-bd06-0aa30668afc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-bcbbf110-5c53-4c0c-a345-697bfe48a2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-4a4eb667-d97f-44a5-bd96-a7ba2f49cea6,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-05550166-007a-4170-a152-7d81edc43c34,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-77cdbe06-44fe-4b17-bc95-ecf041fe5610,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257442291-172.17.0.14-1597532122522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45694,DS-86a1cbb4-9e5b-4395-a384-c48f8c2177c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-a0e81a1b-54f6-4122-ad14-11bc0f05e72f,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-da598b6f-68ab-41b0-8d3b-171fd4deadc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-dfb49545-6ee7-45a0-bd06-0aa30668afc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-bcbbf110-5c53-4c0c-a345-697bfe48a2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37178,DS-4a4eb667-d97f-44a5-bd96-a7ba2f49cea6,DISK], DatanodeInfoWithStorage[127.0.0.1:42932,DS-05550166-007a-4170-a152-7d81edc43c34,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-77cdbe06-44fe-4b17-bc95-ecf041fe5610,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234678531-172.17.0.14-1597532639195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42996,DS-310679d7-d696-43bc-a58e-dd61c2fb1013,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-d754eb85-52b2-4864-b5ac-f90f5fc08042,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-aaa2f808-557d-4357-aa31-5d98eb98b406,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-c2ee3967-4dae-4bb9-b01f-083d79c22fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-382cf1d9-1f50-480f-8cec-f044ae43327e,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-e5bab399-4d15-4104-8098-94af302cf6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-53eae9b5-1827-486a-a159-6a402a6ea6af,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-af36dc6c-5e64-4499-b214-8174cae8e051,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234678531-172.17.0.14-1597532639195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42996,DS-310679d7-d696-43bc-a58e-dd61c2fb1013,DISK], DatanodeInfoWithStorage[127.0.0.1:33872,DS-d754eb85-52b2-4864-b5ac-f90f5fc08042,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-aaa2f808-557d-4357-aa31-5d98eb98b406,DISK], DatanodeInfoWithStorage[127.0.0.1:46530,DS-c2ee3967-4dae-4bb9-b01f-083d79c22fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-382cf1d9-1f50-480f-8cec-f044ae43327e,DISK], DatanodeInfoWithStorage[127.0.0.1:33918,DS-e5bab399-4d15-4104-8098-94af302cf6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-53eae9b5-1827-486a-a159-6a402a6ea6af,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-af36dc6c-5e64-4499-b214-8174cae8e051,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1818300967-172.17.0.14-1597533215963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43821,DS-20d3c4e9-84d1-4e6a-b7e8-a79ad5d7d31f,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-e53810b7-eb30-4868-8977-980db6389a70,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-f4807c56-5c85-44c9-873e-ed4d88987dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-b1d5ae78-6275-4fd0-b7ef-10bae7503a72,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-d67ddeba-a887-4197-8f9d-c738849d20e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-11e7ed0c-ddd4-448d-a3f8-ac239c031363,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-f91354f9-00cc-4634-bdf9-8f8160d1c5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-6a0b284e-f49e-4576-9162-7c2e79ca0aae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1818300967-172.17.0.14-1597533215963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43821,DS-20d3c4e9-84d1-4e6a-b7e8-a79ad5d7d31f,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-e53810b7-eb30-4868-8977-980db6389a70,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-f4807c56-5c85-44c9-873e-ed4d88987dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-b1d5ae78-6275-4fd0-b7ef-10bae7503a72,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-d67ddeba-a887-4197-8f9d-c738849d20e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-11e7ed0c-ddd4-448d-a3f8-ac239c031363,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-f91354f9-00cc-4634-bdf9-8f8160d1c5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-6a0b284e-f49e-4576-9162-7c2e79ca0aae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-70094213-172.17.0.14-1597533487318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43764,DS-8feb96f6-fdb2-43df-8d8c-cb93eca7efa8,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-a3a0586e-5cd4-4810-8090-3ffb4f8174a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-2a16d43a-5b72-4339-abce-9168d402c8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-77429f7b-2d74-42a6-aec3-cf6c3fb0b81f,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-fbb05d97-3576-4dcf-a97a-af7dc4183802,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-b71a477d-a2ec-4184-b030-0c8691038aab,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-d25f589c-c623-4d34-910f-28a07aa4f141,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-5d46cb1e-ff15-4989-9196-e82f297ceebc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-70094213-172.17.0.14-1597533487318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43764,DS-8feb96f6-fdb2-43df-8d8c-cb93eca7efa8,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-a3a0586e-5cd4-4810-8090-3ffb4f8174a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-2a16d43a-5b72-4339-abce-9168d402c8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-77429f7b-2d74-42a6-aec3-cf6c3fb0b81f,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-fbb05d97-3576-4dcf-a97a-af7dc4183802,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-b71a477d-a2ec-4184-b030-0c8691038aab,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-d25f589c-c623-4d34-910f-28a07aa4f141,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-5d46cb1e-ff15-4989-9196-e82f297ceebc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1470383098-172.17.0.14-1597533796595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40001,DS-17fcc51a-382b-4ff5-804b-a4f27a245f30,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-5b1e7245-4cf1-4089-a3a6-b25ad7e4d452,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-cf447b8f-2c05-4ec6-a760-baf878fe2ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-40b739d4-a648-45d2-8275-603ff5981933,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-826d38a5-8f4d-44aa-ba6f-fb125d84fcfe,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-f735c9be-ed00-4268-8fc1-b65e9dfce520,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-37f81b64-b34a-4364-a143-18f6f21aa101,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-bfa5ab0f-7d69-48f7-aabf-7d5b747cdfba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1470383098-172.17.0.14-1597533796595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40001,DS-17fcc51a-382b-4ff5-804b-a4f27a245f30,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-5b1e7245-4cf1-4089-a3a6-b25ad7e4d452,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-cf447b8f-2c05-4ec6-a760-baf878fe2ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-40b739d4-a648-45d2-8275-603ff5981933,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-826d38a5-8f4d-44aa-ba6f-fb125d84fcfe,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-f735c9be-ed00-4268-8fc1-b65e9dfce520,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-37f81b64-b34a-4364-a143-18f6f21aa101,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-bfa5ab0f-7d69-48f7-aabf-7d5b747cdfba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2111551505-172.17.0.14-1597535428125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37959,DS-19275ed2-db06-40c9-aeec-9aeaf14525ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-f31afc79-2307-4f47-87ba-6f70b79a90b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-7c83883d-4856-4242-b396-d8348bc771c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-f0b3c9be-c215-4ff0-9db2-7d5a76abaeae,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-d805edf6-5a42-4e9e-970b-82f1a6d09d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-00fc1446-daa3-49a7-a95a-6f3863d4a9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-d8e26252-f3de-4472-84b5-b0c76449221c,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-32b6f39e-ac71-46e6-8647-f4a75e9dadc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2111551505-172.17.0.14-1597535428125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37959,DS-19275ed2-db06-40c9-aeec-9aeaf14525ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-f31afc79-2307-4f47-87ba-6f70b79a90b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40932,DS-7c83883d-4856-4242-b396-d8348bc771c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-f0b3c9be-c215-4ff0-9db2-7d5a76abaeae,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-d805edf6-5a42-4e9e-970b-82f1a6d09d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-00fc1446-daa3-49a7-a95a-6f3863d4a9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-d8e26252-f3de-4472-84b5-b0c76449221c,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-32b6f39e-ac71-46e6-8647-f4a75e9dadc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1206241918-172.17.0.14-1597535631792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45951,DS-02c488a6-b215-4358-beb5-e0cd1b1e3f34,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-374424a0-a8c7-4fd5-8370-9f6fa5c0d036,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-af25fece-1c83-4df4-94bc-2741acd9faba,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-94b65c84-6cac-42e1-af8e-43b064d69bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-7f7292ba-34ce-4de0-84ec-776e64dc7c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-6d1a5999-b521-437c-92b2-cfb2bf96218e,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-bdb3ed62-73bb-4662-8cdd-bd6e11a0aea2,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-dd44e19b-0362-4804-a30f-11aca2931fff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1206241918-172.17.0.14-1597535631792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45951,DS-02c488a6-b215-4358-beb5-e0cd1b1e3f34,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-374424a0-a8c7-4fd5-8370-9f6fa5c0d036,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-af25fece-1c83-4df4-94bc-2741acd9faba,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-94b65c84-6cac-42e1-af8e-43b064d69bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-7f7292ba-34ce-4de0-84ec-776e64dc7c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-6d1a5999-b521-437c-92b2-cfb2bf96218e,DISK], DatanodeInfoWithStorage[127.0.0.1:45172,DS-bdb3ed62-73bb-4662-8cdd-bd6e11a0aea2,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-dd44e19b-0362-4804-a30f-11aca2931fff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673771395-172.17.0.14-1597535870170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44575,DS-3019bc35-7216-49d4-a347-e613d3d14b44,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-ec95a0fc-2913-4a19-8003-6dc63cc5b4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-7961ad39-12f9-4b2e-a6f6-707c8178d7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38360,DS-5511073d-9f8a-45ae-b7e9-955cf3eba92f,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-6730a384-48bb-406a-aef1-d285e691ec99,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-99f3386f-15be-401f-9ca1-4dbb7dc28381,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-c2d868bb-59fc-412c-9ee9-20db6f0319cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-a9424fbd-5475-4222-abfd-ddc075385874,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673771395-172.17.0.14-1597535870170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44575,DS-3019bc35-7216-49d4-a347-e613d3d14b44,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-ec95a0fc-2913-4a19-8003-6dc63cc5b4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-7961ad39-12f9-4b2e-a6f6-707c8178d7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38360,DS-5511073d-9f8a-45ae-b7e9-955cf3eba92f,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-6730a384-48bb-406a-aef1-d285e691ec99,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-99f3386f-15be-401f-9ca1-4dbb7dc28381,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-c2d868bb-59fc-412c-9ee9-20db6f0319cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-a9424fbd-5475-4222-abfd-ddc075385874,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-276023098-172.17.0.14-1597536262614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36612,DS-db117680-5956-45e0-908a-289c42b71fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-03a61030-8eac-4ee8-a414-03c8414fb3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-da930c81-47bf-4388-a98f-ddcf269ee293,DISK], DatanodeInfoWithStorage[127.0.0.1:44652,DS-e3c8f356-1de1-425a-bcb9-383e1ab04c30,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-bbaeabea-bb2a-4d20-8263-0b4efdce0299,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-e7c84915-8f38-4188-b1c5-b1edca190081,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-8c40eda3-d850-4f1c-9e06-ced1d0263659,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-1153f473-dc2f-4450-80f5-e3aa63545825,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-276023098-172.17.0.14-1597536262614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36612,DS-db117680-5956-45e0-908a-289c42b71fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-03a61030-8eac-4ee8-a414-03c8414fb3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44879,DS-da930c81-47bf-4388-a98f-ddcf269ee293,DISK], DatanodeInfoWithStorage[127.0.0.1:44652,DS-e3c8f356-1de1-425a-bcb9-383e1ab04c30,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-bbaeabea-bb2a-4d20-8263-0b4efdce0299,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-e7c84915-8f38-4188-b1c5-b1edca190081,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-8c40eda3-d850-4f1c-9e06-ced1d0263659,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-1153f473-dc2f-4450-80f5-e3aa63545825,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1426240258-172.17.0.14-1597536693324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38596,DS-b945669d-0dda-4944-ba33-1b679c356904,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-f22d859a-b578-4057-82cb-15bd91830969,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-1cecc60b-74f4-44b1-ad7c-ea6aff7ba9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-55595b7e-b31d-451e-baaf-f003245f553b,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-47f067b7-c6b0-47c0-ae78-f36c0ca0ef87,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-d7aef955-a66b-410a-babb-d89badc28c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-1043f174-db56-4307-987b-7ed931415b71,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-08ead943-4012-4bb2-bbb6-46cbffeba11d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1426240258-172.17.0.14-1597536693324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38596,DS-b945669d-0dda-4944-ba33-1b679c356904,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-f22d859a-b578-4057-82cb-15bd91830969,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-1cecc60b-74f4-44b1-ad7c-ea6aff7ba9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-55595b7e-b31d-451e-baaf-f003245f553b,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-47f067b7-c6b0-47c0-ae78-f36c0ca0ef87,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-d7aef955-a66b-410a-babb-d89badc28c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-1043f174-db56-4307-987b-7ed931415b71,DISK], DatanodeInfoWithStorage[127.0.0.1:40449,DS-08ead943-4012-4bb2-bbb6-46cbffeba11d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-257305791-172.17.0.14-1597536909938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45986,DS-521e4ff5-ce0e-480a-aede-0d14bb680986,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-a4738b4b-2597-4bb7-be8b-ce10f6f99b40,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-af82cae9-59e2-4ccd-9afe-08cbd9c0a97e,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-8a8c9de2-73cf-4c0c-8167-abd5f1cd0252,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-faba9e60-4774-400d-adc8-f32b6f8a1e61,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-67c0f1e8-6aa5-46d8-aa0c-56c51b7c3cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-05314aa7-dae7-4ba5-82f2-c69335fbf764,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-c65875bc-32b7-4cc8-8d9e-3d134908357c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-257305791-172.17.0.14-1597536909938:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45986,DS-521e4ff5-ce0e-480a-aede-0d14bb680986,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-a4738b4b-2597-4bb7-be8b-ce10f6f99b40,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-af82cae9-59e2-4ccd-9afe-08cbd9c0a97e,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-8a8c9de2-73cf-4c0c-8167-abd5f1cd0252,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-faba9e60-4774-400d-adc8-f32b6f8a1e61,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-67c0f1e8-6aa5-46d8-aa0c-56c51b7c3cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-05314aa7-dae7-4ba5-82f2-c69335fbf764,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-c65875bc-32b7-4cc8-8d9e-3d134908357c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5824
