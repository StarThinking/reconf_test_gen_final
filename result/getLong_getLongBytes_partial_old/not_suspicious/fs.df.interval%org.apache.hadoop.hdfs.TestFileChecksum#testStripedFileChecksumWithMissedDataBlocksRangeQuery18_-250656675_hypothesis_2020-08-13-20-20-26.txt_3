reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1447539124-172.17.0.17-1597350101712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42631,DS-5c748289-8abe-498d-a4a7-df210faa7a66,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-ab514cea-d367-4411-acbe-443ed3da0752,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-553a2344-d235-4366-975a-b97b70b20ece,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-97d01c40-4d99-4b26-8864-7b5f5463b59b,DISK], DatanodeInfoWithStorage[127.0.0.1:42961,DS-80df18da-6896-4c83-938b-71d803dd16b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-4a039a95-13c6-46f8-bb44-fce7aa91b54c,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-901a2385-3ff1-49ec-8410-f7a2165ef3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-beadfe0c-459d-47a8-b3df-ef021e30401f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1447539124-172.17.0.17-1597350101712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42631,DS-5c748289-8abe-498d-a4a7-df210faa7a66,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-ab514cea-d367-4411-acbe-443ed3da0752,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-553a2344-d235-4366-975a-b97b70b20ece,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-97d01c40-4d99-4b26-8864-7b5f5463b59b,DISK], DatanodeInfoWithStorage[127.0.0.1:42961,DS-80df18da-6896-4c83-938b-71d803dd16b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-4a039a95-13c6-46f8-bb44-fce7aa91b54c,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-901a2385-3ff1-49ec-8410-f7a2165ef3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35527,DS-beadfe0c-459d-47a8-b3df-ef021e30401f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1288212446-172.17.0.17-1597350228581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43534,DS-62a23d49-a4cb-4fda-b920-68159f222ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-1fbc56a1-1488-469a-bf4f-c727622a288c,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-f48ad3c2-fa07-406f-ba9c-d35f62d28e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-3c24c7b0-5be2-4587-9d30-a2a1cf3dfe40,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-22864626-0eaa-429c-bdbc-5b3a4a0b77a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-77823a68-94c4-474f-b418-fa81ceb1c8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-9595d9d4-9a7a-410b-b36a-770ab5643fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-f2ae6acb-efa2-4675-84b5-89751e0f4a66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1288212446-172.17.0.17-1597350228581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43534,DS-62a23d49-a4cb-4fda-b920-68159f222ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:38513,DS-1fbc56a1-1488-469a-bf4f-c727622a288c,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-f48ad3c2-fa07-406f-ba9c-d35f62d28e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-3c24c7b0-5be2-4587-9d30-a2a1cf3dfe40,DISK], DatanodeInfoWithStorage[127.0.0.1:39455,DS-22864626-0eaa-429c-bdbc-5b3a4a0b77a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34159,DS-77823a68-94c4-474f-b418-fa81ceb1c8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-9595d9d4-9a7a-410b-b36a-770ab5643fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:33374,DS-f2ae6acb-efa2-4675-84b5-89751e0f4a66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-858607949-172.17.0.17-1597350825026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40446,DS-79493246-0b15-41cf-be85-2761b1ed1629,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-0765f808-c665-4198-891b-b30ca0d61319,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-5789f7ee-c61b-4f74-9c0f-8e44491f174b,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-ae47c580-3868-40cb-93d5-0c96d554f2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-53e176fa-a91d-4377-8033-8f4d73cbcddc,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-aa0d1a4a-3fb2-4826-889e-11ef1c4fe4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-cba0e34a-a48c-4c94-94f3-270650ab957b,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-e44a4672-9323-4639-9ae9-0f64840418f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-858607949-172.17.0.17-1597350825026:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40446,DS-79493246-0b15-41cf-be85-2761b1ed1629,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-0765f808-c665-4198-891b-b30ca0d61319,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-5789f7ee-c61b-4f74-9c0f-8e44491f174b,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-ae47c580-3868-40cb-93d5-0c96d554f2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-53e176fa-a91d-4377-8033-8f4d73cbcddc,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-aa0d1a4a-3fb2-4826-889e-11ef1c4fe4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-cba0e34a-a48c-4c94-94f3-270650ab957b,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-e44a4672-9323-4639-9ae9-0f64840418f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1767740190-172.17.0.17-1597351096816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41933,DS-f5a549f9-a09a-4f23-be7c-ca07f4e834c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-e634f482-5aeb-4c8e-aec8-f027145c5a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-6fcb5c99-77b8-42ac-b0d3-092d4d2715c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-d0e37211-9056-4bdf-b473-19eaa8d0d60e,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-c523afc2-2927-4975-8a69-55862c42227b,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-9d80862a-0b1e-42e8-b97f-c4f5a4fd965b,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-349b56de-e1dd-4bae-bf29-ec55910be660,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-effc38aa-d181-43fe-a1d3-256a648e0733,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1767740190-172.17.0.17-1597351096816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41933,DS-f5a549f9-a09a-4f23-be7c-ca07f4e834c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37358,DS-e634f482-5aeb-4c8e-aec8-f027145c5a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-6fcb5c99-77b8-42ac-b0d3-092d4d2715c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46525,DS-d0e37211-9056-4bdf-b473-19eaa8d0d60e,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-c523afc2-2927-4975-8a69-55862c42227b,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-9d80862a-0b1e-42e8-b97f-c4f5a4fd965b,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-349b56de-e1dd-4bae-bf29-ec55910be660,DISK], DatanodeInfoWithStorage[127.0.0.1:34189,DS-effc38aa-d181-43fe-a1d3-256a648e0733,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-71623552-172.17.0.17-1597351227408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32941,DS-96d037df-595d-4d4f-9a9f-44ed04e85092,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-743cb72f-c4f3-4d44-9485-507e95c2c778,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-5972ad93-d473-4dbe-9aef-a8f6e1bd53ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-1fbe3067-af84-4a02-b7e6-e7a631803cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-0ab07fef-14e6-449d-9091-cb633f9ec215,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-52c202df-e39b-4da9-9e52-2db28ac16472,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-ff823e1c-7cbe-49ec-a504-26e4ea44538f,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-cf3ff5db-6ef7-440a-977b-308aee360713,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-71623552-172.17.0.17-1597351227408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32941,DS-96d037df-595d-4d4f-9a9f-44ed04e85092,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-743cb72f-c4f3-4d44-9485-507e95c2c778,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-5972ad93-d473-4dbe-9aef-a8f6e1bd53ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-1fbe3067-af84-4a02-b7e6-e7a631803cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-0ab07fef-14e6-449d-9091-cb633f9ec215,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-52c202df-e39b-4da9-9e52-2db28ac16472,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-ff823e1c-7cbe-49ec-a504-26e4ea44538f,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-cf3ff5db-6ef7-440a-977b-308aee360713,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2098578190-172.17.0.17-1597351467547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36833,DS-7812aa03-4ec9-41a2-aa1f-cdfe0ae72bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-9c27dd1c-939f-40e9-a244-c65e67413079,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-3cb24375-96fa-4232-bf39-af1538612b22,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-427c0eb1-e969-4f46-960c-f339e9983af0,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-ad01ceae-8ac6-403d-a8dd-4154c14185de,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-9b0dc1bb-2a54-4f5b-bd6e-87907f710f21,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-2ce70ba5-7973-42cb-9379-01e5d29ed8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-b7006f89-b936-4c57-b969-0cec66ccf049,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2098578190-172.17.0.17-1597351467547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36833,DS-7812aa03-4ec9-41a2-aa1f-cdfe0ae72bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-9c27dd1c-939f-40e9-a244-c65e67413079,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-3cb24375-96fa-4232-bf39-af1538612b22,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-427c0eb1-e969-4f46-960c-f339e9983af0,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-ad01ceae-8ac6-403d-a8dd-4154c14185de,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-9b0dc1bb-2a54-4f5b-bd6e-87907f710f21,DISK], DatanodeInfoWithStorage[127.0.0.1:36098,DS-2ce70ba5-7973-42cb-9379-01e5d29ed8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-b7006f89-b936-4c57-b969-0cec66ccf049,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1462804294-172.17.0.17-1597351705358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41602,DS-2be8cb47-ccde-413c-82c5-b94a8aacbed4,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-03f6610e-c06b-42d6-aa8d-a2a9442a0b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-2ca8f1e0-1767-4250-aa31-6bdf78b862b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-d3f23acd-f416-499c-a94a-f7ede28d0c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-a83aafea-1306-4842-94eb-d5fb5559ac50,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-a972f51b-f917-4dcd-aa04-f05797057b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-e55814e9-f4ba-4f7f-ad36-a309f9920f50,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-fb54da65-c629-47c1-a8d3-a07fe398ed6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1462804294-172.17.0.17-1597351705358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41602,DS-2be8cb47-ccde-413c-82c5-b94a8aacbed4,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-03f6610e-c06b-42d6-aa8d-a2a9442a0b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-2ca8f1e0-1767-4250-aa31-6bdf78b862b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-d3f23acd-f416-499c-a94a-f7ede28d0c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-a83aafea-1306-4842-94eb-d5fb5559ac50,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-a972f51b-f917-4dcd-aa04-f05797057b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-e55814e9-f4ba-4f7f-ad36-a309f9920f50,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-fb54da65-c629-47c1-a8d3-a07fe398ed6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1196015964-172.17.0.17-1597351886934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37919,DS-c33b12c3-baeb-4047-a4b1-8c1db47d7412,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-b8230b2e-47a3-4ec3-bd29-97f49522abe9,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-bb436a94-726a-4276-b170-98c12e43f4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-d78cf2d1-a73e-41c3-8874-56877bd993b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-e211592a-2930-4201-8e81-a522f3ca0f83,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-df333f08-5555-494d-bda1-fd73fa63841e,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-27f9b250-1352-4dcf-b13f-530911377694,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-ce5c4374-1a07-45cf-83b7-b738ceb54193,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1196015964-172.17.0.17-1597351886934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37919,DS-c33b12c3-baeb-4047-a4b1-8c1db47d7412,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-b8230b2e-47a3-4ec3-bd29-97f49522abe9,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-bb436a94-726a-4276-b170-98c12e43f4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-d78cf2d1-a73e-41c3-8874-56877bd993b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-e211592a-2930-4201-8e81-a522f3ca0f83,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-df333f08-5555-494d-bda1-fd73fa63841e,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-27f9b250-1352-4dcf-b13f-530911377694,DISK], DatanodeInfoWithStorage[127.0.0.1:39772,DS-ce5c4374-1a07-45cf-83b7-b738ceb54193,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1012967639-172.17.0.17-1597352858272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38465,DS-bd8350ae-c826-4891-b191-1017de6cdefa,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-bc406403-4198-45eb-a683-2d32fe638551,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-8e495752-b668-4877-ba04-96b3b44702f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-9491d0bc-7546-43f2-9ad3-1838ca66cb92,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-8a5baa54-d7e4-42eb-a640-f7b0007bbe36,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-5e25a85e-e92d-459c-8dac-07c48c0f7412,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-595eb623-8340-4c96-8ea5-5e3c23e261b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-ac3311da-df2c-44ba-a227-501b5fcda269,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1012967639-172.17.0.17-1597352858272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38465,DS-bd8350ae-c826-4891-b191-1017de6cdefa,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-bc406403-4198-45eb-a683-2d32fe638551,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-8e495752-b668-4877-ba04-96b3b44702f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-9491d0bc-7546-43f2-9ad3-1838ca66cb92,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-8a5baa54-d7e4-42eb-a640-f7b0007bbe36,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-5e25a85e-e92d-459c-8dac-07c48c0f7412,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-595eb623-8340-4c96-8ea5-5e3c23e261b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-ac3311da-df2c-44ba-a227-501b5fcda269,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1285896499-172.17.0.17-1597352929457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32902,DS-017e4751-6c80-42f6-929a-fa22e18b8733,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-82777055-9e7a-4c88-8d7e-b21f6de6e52f,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-f46cd08f-e737-485a-bae9-f94359fb0a91,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-bea1e88d-0e18-4fae-bad9-420908809a10,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-ae4eca5a-272b-462f-84c3-b331a8b37682,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-b84985e7-ae01-4e8f-a878-7f0ebe578ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-105becf3-8006-4495-9b84-8c5255081b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-9d350506-7d47-4534-832e-e807d1626414,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1285896499-172.17.0.17-1597352929457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32902,DS-017e4751-6c80-42f6-929a-fa22e18b8733,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-82777055-9e7a-4c88-8d7e-b21f6de6e52f,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-f46cd08f-e737-485a-bae9-f94359fb0a91,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-bea1e88d-0e18-4fae-bad9-420908809a10,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-ae4eca5a-272b-462f-84c3-b331a8b37682,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-b84985e7-ae01-4e8f-a878-7f0ebe578ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-105becf3-8006-4495-9b84-8c5255081b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-9d350506-7d47-4534-832e-e807d1626414,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-154841710-172.17.0.17-1597353308879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39836,DS-9d73ca7e-6918-4f58-9e76-98e4cd45a41f,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-b57e4043-cd46-4cfd-98ae-34a5dd5dc52f,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-6c99c02f-4446-42f8-ac99-9bb58cb0f50f,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-90dc400c-acb2-45c3-8a7f-b9bc3264512e,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-10d4f61a-d4ce-45ff-986c-c0da607e67b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-5ed26edb-d917-4307-8b94-13016cf1732f,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-ca39bb3a-98f6-4ab9-8598-97c9846f0f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-38c92180-e731-4ab1-acae-3b3139ab7bf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-154841710-172.17.0.17-1597353308879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39836,DS-9d73ca7e-6918-4f58-9e76-98e4cd45a41f,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-b57e4043-cd46-4cfd-98ae-34a5dd5dc52f,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-6c99c02f-4446-42f8-ac99-9bb58cb0f50f,DISK], DatanodeInfoWithStorage[127.0.0.1:46735,DS-90dc400c-acb2-45c3-8a7f-b9bc3264512e,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-10d4f61a-d4ce-45ff-986c-c0da607e67b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-5ed26edb-d917-4307-8b94-13016cf1732f,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-ca39bb3a-98f6-4ab9-8598-97c9846f0f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-38c92180-e731-4ab1-acae-3b3139ab7bf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-88368897-172.17.0.17-1597353626249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45607,DS-6245903c-8c14-403f-ae8f-14903927aad3,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-ad8edc84-561b-45ca-bace-016d3dc8bc38,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-74ced9f5-2b81-4308-9a0a-ef40b789f736,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-52a9bbb8-a06a-4961-9f1f-c48110b7c62e,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-a232b29b-6d5a-438f-abde-0493a8a92d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-408b88f1-24c3-4e1d-91f6-14ed66efebe8,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-c4fde780-592b-4c1f-aa33-fe3e0587b1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-6d7bc78f-d368-4258-8063-f5d80dde0a4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-88368897-172.17.0.17-1597353626249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45607,DS-6245903c-8c14-403f-ae8f-14903927aad3,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-ad8edc84-561b-45ca-bace-016d3dc8bc38,DISK], DatanodeInfoWithStorage[127.0.0.1:39492,DS-74ced9f5-2b81-4308-9a0a-ef40b789f736,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-52a9bbb8-a06a-4961-9f1f-c48110b7c62e,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-a232b29b-6d5a-438f-abde-0493a8a92d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-408b88f1-24c3-4e1d-91f6-14ed66efebe8,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-c4fde780-592b-4c1f-aa33-fe3e0587b1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-6d7bc78f-d368-4258-8063-f5d80dde0a4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2112807340-172.17.0.17-1597353694303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39277,DS-47556c5a-1acf-4b90-bcfb-7c53ccba29e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-d8397df3-637d-499f-a6d6-3683e0e8d6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-e8f0ac47-a77e-4d93-b4bd-4a3dc0c461c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-505eeb71-ed6f-4f6a-a6cd-6657323ac2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-15318731-a993-4d41-afab-b034729888ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-8bfc639a-7c86-42f2-94e4-61f59d89976a,DISK], DatanodeInfoWithStorage[127.0.0.1:37487,DS-4ed6908f-15a3-4fc8-a9a6-888f2657ce32,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-27f1d80f-610b-4de9-9509-e7d8df328feb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2112807340-172.17.0.17-1597353694303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39277,DS-47556c5a-1acf-4b90-bcfb-7c53ccba29e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-d8397df3-637d-499f-a6d6-3683e0e8d6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-e8f0ac47-a77e-4d93-b4bd-4a3dc0c461c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-505eeb71-ed6f-4f6a-a6cd-6657323ac2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-15318731-a993-4d41-afab-b034729888ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38390,DS-8bfc639a-7c86-42f2-94e4-61f59d89976a,DISK], DatanodeInfoWithStorage[127.0.0.1:37487,DS-4ed6908f-15a3-4fc8-a9a6-888f2657ce32,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-27f1d80f-610b-4de9-9509-e7d8df328feb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1780989317-172.17.0.17-1597353768429:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44520,DS-8723dd10-7002-4cca-a0fa-0bc98c74a958,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-9a18a6a4-17b1-4847-a93d-94df5d736b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-14b6589d-953a-4179-975b-8ced958ba480,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-56a4824e-8345-4a6d-81aa-c32596b8c9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-274457b8-90b4-4429-ad57-c0cc00c00354,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-d216f189-ac5f-45cd-ae29-52f649438bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-ce9be55f-5cda-42be-814e-1bceb2298e03,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-542e408a-ca45-425b-a0cb-93383c0aff69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1780989317-172.17.0.17-1597353768429:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44520,DS-8723dd10-7002-4cca-a0fa-0bc98c74a958,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-9a18a6a4-17b1-4847-a93d-94df5d736b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-14b6589d-953a-4179-975b-8ced958ba480,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-56a4824e-8345-4a6d-81aa-c32596b8c9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-274457b8-90b4-4429-ad57-c0cc00c00354,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-d216f189-ac5f-45cd-ae29-52f649438bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-ce9be55f-5cda-42be-814e-1bceb2298e03,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-542e408a-ca45-425b-a0cb-93383c0aff69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1825918891-172.17.0.17-1597354066670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41969,DS-eadb0f45-2c98-46e4-a566-a18bc22bfcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-c9eda510-fb76-4aac-a0de-2707f18ddc45,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-9ddfecfc-0046-4449-aa02-688337fa00ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-14cfbc6f-316d-4572-b471-d886d4574804,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-05470104-9e85-4a3b-800d-06bca7923da7,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-7d564748-fa01-42ac-8408-d86784eb3ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:35688,DS-606e9bf7-97bd-4426-adb9-ec72a0a815b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-76d6f539-a20d-4bef-8b40-f2003e4966aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1825918891-172.17.0.17-1597354066670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41969,DS-eadb0f45-2c98-46e4-a566-a18bc22bfcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-c9eda510-fb76-4aac-a0de-2707f18ddc45,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-9ddfecfc-0046-4449-aa02-688337fa00ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-14cfbc6f-316d-4572-b471-d886d4574804,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-05470104-9e85-4a3b-800d-06bca7923da7,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-7d564748-fa01-42ac-8408-d86784eb3ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:35688,DS-606e9bf7-97bd-4426-adb9-ec72a0a815b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-76d6f539-a20d-4bef-8b40-f2003e4966aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1299223941-172.17.0.17-1597354376276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43985,DS-7f96278d-27b1-46de-b163-742ea9af41f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-728a57ea-2711-4d25-9aad-bf0a40fab6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-190680ab-23ec-45b6-b567-a8dd20fb32c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-c74fa786-e650-4304-9635-29f4ab22e6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-dac2140b-33ab-4a5a-903f-cfedbd327ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-4c1dd633-aee5-4502-acdc-bf7f3b9616cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-94782dd7-6181-4345-b4a5-27408a8d8624,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-e40c5ace-93de-46a9-8299-603863912c83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1299223941-172.17.0.17-1597354376276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43985,DS-7f96278d-27b1-46de-b163-742ea9af41f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44238,DS-728a57ea-2711-4d25-9aad-bf0a40fab6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40792,DS-190680ab-23ec-45b6-b567-a8dd20fb32c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-c74fa786-e650-4304-9635-29f4ab22e6f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-dac2140b-33ab-4a5a-903f-cfedbd327ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-4c1dd633-aee5-4502-acdc-bf7f3b9616cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-94782dd7-6181-4345-b4a5-27408a8d8624,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-e40c5ace-93de-46a9-8299-603863912c83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1516795508-172.17.0.17-1597354647486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36946,DS-07571850-a2ba-4c8f-8b5f-432cec75a99c,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-34dec0d9-1c3e-4d92-ae60-7d4172f1db84,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-97d81274-ee80-4cdc-8506-e52f94d924f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-6796e0cf-1f54-4e9e-a2d6-afa9b326a2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-e8dbf3a1-eb17-47bd-8240-6da59a9e3688,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-684d7e8b-9303-4d67-a970-c7698690dfa8,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-47e220fc-5aea-4ca7-87b2-33ddbe158bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-969da7a7-be93-4418-8ddc-c238afdc16e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1516795508-172.17.0.17-1597354647486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36946,DS-07571850-a2ba-4c8f-8b5f-432cec75a99c,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-34dec0d9-1c3e-4d92-ae60-7d4172f1db84,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-97d81274-ee80-4cdc-8506-e52f94d924f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-6796e0cf-1f54-4e9e-a2d6-afa9b326a2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-e8dbf3a1-eb17-47bd-8240-6da59a9e3688,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-684d7e8b-9303-4d67-a970-c7698690dfa8,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-47e220fc-5aea-4ca7-87b2-33ddbe158bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-969da7a7-be93-4418-8ddc-c238afdc16e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-690518711-172.17.0.17-1597354862611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38585,DS-be36a394-8778-4707-8d45-26b6ae9a07e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-548e93ed-9b5d-4b90-9fa5-3daf943fcc91,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-7f2efc2b-7014-44cf-bdf6-a9f79d23f59b,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-e130a75d-64cc-4c17-b1ab-70b52bf480a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-d8204112-e09b-4a4c-997c-221967dd1e93,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-d372c57a-21f3-4a01-9343-6741134cf54b,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-e49b0df3-54cd-47f4-9487-17763f4c0e91,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-ea56b29e-069a-4a3a-b07d-cf40ea9a0c32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-690518711-172.17.0.17-1597354862611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38585,DS-be36a394-8778-4707-8d45-26b6ae9a07e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-548e93ed-9b5d-4b90-9fa5-3daf943fcc91,DISK], DatanodeInfoWithStorage[127.0.0.1:39690,DS-7f2efc2b-7014-44cf-bdf6-a9f79d23f59b,DISK], DatanodeInfoWithStorage[127.0.0.1:45471,DS-e130a75d-64cc-4c17-b1ab-70b52bf480a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-d8204112-e09b-4a4c-997c-221967dd1e93,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-d372c57a-21f3-4a01-9343-6741134cf54b,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-e49b0df3-54cd-47f4-9487-17763f4c0e91,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-ea56b29e-069a-4a3a-b07d-cf40ea9a0c32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5104
