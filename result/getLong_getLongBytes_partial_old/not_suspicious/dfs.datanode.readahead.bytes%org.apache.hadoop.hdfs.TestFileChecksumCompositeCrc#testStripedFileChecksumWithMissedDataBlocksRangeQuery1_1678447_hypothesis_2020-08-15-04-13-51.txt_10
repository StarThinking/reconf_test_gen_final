reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-723240092-172.17.0.5-1597464971295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45332,DS-5db6d5e4-da59-45ee-8314-e02f1c3b7bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-50a17b2e-4890-4f16-97b2-0d17560ea02e,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-e6c95602-6d59-4d26-8ef4-31af96a34882,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-9fc72db7-3a32-4595-b1e0-d03cb78474c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-ebcff6ab-cedd-4d6d-80a4-8723930c3448,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-fe56b005-e139-4726-b607-e54396fa1036,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-94edcc35-9a27-4c2c-a04c-07a9d3049325,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-ac1cbd43-1560-41ab-b26a-192831bef6d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-723240092-172.17.0.5-1597464971295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45332,DS-5db6d5e4-da59-45ee-8314-e02f1c3b7bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-50a17b2e-4890-4f16-97b2-0d17560ea02e,DISK], DatanodeInfoWithStorage[127.0.0.1:33879,DS-e6c95602-6d59-4d26-8ef4-31af96a34882,DISK], DatanodeInfoWithStorage[127.0.0.1:46866,DS-9fc72db7-3a32-4595-b1e0-d03cb78474c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45061,DS-ebcff6ab-cedd-4d6d-80a4-8723930c3448,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-fe56b005-e139-4726-b607-e54396fa1036,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-94edcc35-9a27-4c2c-a04c-07a9d3049325,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-ac1cbd43-1560-41ab-b26a-192831bef6d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1733813787-172.17.0.5-1597465157321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46767,DS-4d37a894-af42-4c4d-9766-0d4f4c93e230,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-6359cf70-a8f9-49b9-9ee6-1606416fdf19,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-0063ebb6-3c44-4427-921d-b00db0b9038b,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-87144e4f-104f-4428-8247-4f6b2922d783,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-a5a47fd5-dd37-4f7f-b8e3-649d2866845f,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-3c8b6d3f-67ba-4faf-8af0-76d6ae738966,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-39688189-d12d-43ea-8724-e4cbc9f363d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-9c58a5c9-923e-483c-95ad-01eb83e7a5f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1733813787-172.17.0.5-1597465157321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46767,DS-4d37a894-af42-4c4d-9766-0d4f4c93e230,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-6359cf70-a8f9-49b9-9ee6-1606416fdf19,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-0063ebb6-3c44-4427-921d-b00db0b9038b,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-87144e4f-104f-4428-8247-4f6b2922d783,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-a5a47fd5-dd37-4f7f-b8e3-649d2866845f,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-3c8b6d3f-67ba-4faf-8af0-76d6ae738966,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-39688189-d12d-43ea-8724-e4cbc9f363d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-9c58a5c9-923e-483c-95ad-01eb83e7a5f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483814787-172.17.0.5-1597465510316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42797,DS-8142ec36-0456-4a7b-b417-24beb056fea4,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-adcc63b1-837d-4563-857f-f5d5c199b12f,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-42eaf99d-be15-462e-aa08-64f2b18fce12,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-fac25755-d7ca-43f0-adf7-0fd8c13a193f,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-61162c4b-633c-4db6-869f-d59cb739bf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-14a60ecc-ff5f-4c38-81ec-2d4c112d5523,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-3de0e511-052f-474e-9bf9-a4e58c0f7ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-53cc7f7c-3709-4c3d-a45d-dbf7f50f4831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-483814787-172.17.0.5-1597465510316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42797,DS-8142ec36-0456-4a7b-b417-24beb056fea4,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-adcc63b1-837d-4563-857f-f5d5c199b12f,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-42eaf99d-be15-462e-aa08-64f2b18fce12,DISK], DatanodeInfoWithStorage[127.0.0.1:33060,DS-fac25755-d7ca-43f0-adf7-0fd8c13a193f,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-61162c4b-633c-4db6-869f-d59cb739bf0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-14a60ecc-ff5f-4c38-81ec-2d4c112d5523,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-3de0e511-052f-474e-9bf9-a4e58c0f7ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-53cc7f7c-3709-4c3d-a45d-dbf7f50f4831,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1527634273-172.17.0.5-1597466243921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35114,DS-be13cf43-6a3c-4967-b1f6-458ca9944b72,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-cefcc0e4-aa71-4dc3-9b20-fd6d91e83b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-3766c9e4-15b0-4cf1-8771-96d244bf2585,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-9148de35-be2a-41c5-97b1-990cf86c4ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-30eadee0-4d5f-4c7e-9ead-7e661128263f,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-bb55b18f-f1be-49ad-8f92-3cf424e8a745,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-4c5fec87-252a-4d48-8f02-939d8f97f1af,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-440082b6-4d65-422b-8ecb-132f86e9ff5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1527634273-172.17.0.5-1597466243921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35114,DS-be13cf43-6a3c-4967-b1f6-458ca9944b72,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-cefcc0e4-aa71-4dc3-9b20-fd6d91e83b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-3766c9e4-15b0-4cf1-8771-96d244bf2585,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-9148de35-be2a-41c5-97b1-990cf86c4ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-30eadee0-4d5f-4c7e-9ead-7e661128263f,DISK], DatanodeInfoWithStorage[127.0.0.1:39395,DS-bb55b18f-f1be-49ad-8f92-3cf424e8a745,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-4c5fec87-252a-4d48-8f02-939d8f97f1af,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-440082b6-4d65-422b-8ecb-132f86e9ff5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612157165-172.17.0.5-1597466357250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36689,DS-1cba94e1-0ee1-4397-b58c-2fdd1ae96051,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-d8b1680e-06da-4c0c-899b-2c46a0478ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-cbfe0e86-5123-4a38-bf46-2f52f21a4c70,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-7ca8cbc7-48a2-40d8-a1f7-f92fa544f78e,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-17ad402f-8378-480e-99ee-af04a877d4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-70915ba5-20fd-4457-882e-a116798a6dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-f6dab86e-cf97-4e29-9a4d-b4064749a8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-27056654-c292-4dbf-b676-a9d299112a07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612157165-172.17.0.5-1597466357250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36689,DS-1cba94e1-0ee1-4397-b58c-2fdd1ae96051,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-d8b1680e-06da-4c0c-899b-2c46a0478ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-cbfe0e86-5123-4a38-bf46-2f52f21a4c70,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-7ca8cbc7-48a2-40d8-a1f7-f92fa544f78e,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-17ad402f-8378-480e-99ee-af04a877d4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-70915ba5-20fd-4457-882e-a116798a6dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-f6dab86e-cf97-4e29-9a4d-b4064749a8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40629,DS-27056654-c292-4dbf-b676-a9d299112a07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183857522-172.17.0.5-1597466758327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41383,DS-55e2cde4-462a-4230-afef-6348b012d934,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-9bc5075f-e56c-4cc7-bf38-c5d20af83bea,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-4963bd08-4844-4f25-b730-10b276139a74,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-b200bf16-80df-4384-9baa-b618d112faf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-0ad9336c-eb6c-4b36-b49f-ec2379bb986c,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-ea116e23-6f72-4c31-b8b4-e2e101bfa040,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-9dac9eb5-7772-4d86-846a-a5dac89792f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-e0e99a61-61c7-4f2f-9573-6dce8ba77e08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183857522-172.17.0.5-1597466758327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41383,DS-55e2cde4-462a-4230-afef-6348b012d934,DISK], DatanodeInfoWithStorage[127.0.0.1:33192,DS-9bc5075f-e56c-4cc7-bf38-c5d20af83bea,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-4963bd08-4844-4f25-b730-10b276139a74,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-b200bf16-80df-4384-9baa-b618d112faf2,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-0ad9336c-eb6c-4b36-b49f-ec2379bb986c,DISK], DatanodeInfoWithStorage[127.0.0.1:37546,DS-ea116e23-6f72-4c31-b8b4-e2e101bfa040,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-9dac9eb5-7772-4d86-846a-a5dac89792f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-e0e99a61-61c7-4f2f-9573-6dce8ba77e08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1708629200-172.17.0.5-1597466906791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37157,DS-35d435bf-bf8a-4211-9f27-5fef96ebbafd,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-3a59dcbd-f47c-4aff-be9d-78c748211ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-6bb70ba2-5fd6-44e0-9f5a-d20b375d548b,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-9e6d1834-b1d5-4d9f-ba81-d659b61b9e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-1197c7d6-12ae-4322-86e4-4a47e5a40d42,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-22420eef-b1fb-49cb-8022-ee8148e01a83,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-932692aa-bf5c-463f-87fe-e1b3ed56be84,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-3675c1b7-b7b0-4edf-a1ec-e59c196641d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1708629200-172.17.0.5-1597466906791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37157,DS-35d435bf-bf8a-4211-9f27-5fef96ebbafd,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-3a59dcbd-f47c-4aff-be9d-78c748211ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-6bb70ba2-5fd6-44e0-9f5a-d20b375d548b,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-9e6d1834-b1d5-4d9f-ba81-d659b61b9e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-1197c7d6-12ae-4322-86e4-4a47e5a40d42,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-22420eef-b1fb-49cb-8022-ee8148e01a83,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-932692aa-bf5c-463f-87fe-e1b3ed56be84,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-3675c1b7-b7b0-4edf-a1ec-e59c196641d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1543124687-172.17.0.5-1597467136821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45623,DS-863dfc3a-e18d-476e-b0ac-f9a76cb92ded,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-8be4899d-8450-496c-8161-ce81d5c01864,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-5d7f70b3-4132-4a82-a7d3-0367dd2ce355,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-2dac9a9a-b2f3-4c8c-b099-80a1aed92075,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-b0891948-af1d-4c41-9e20-977c01ba6c51,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-1b44a208-24b0-4b8d-8e16-dac94884a3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-d0e17a7c-3a13-470f-b7d3-c40ef08e1f81,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-36649fd5-32d0-4c05-9eae-e1ce089a8d8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1543124687-172.17.0.5-1597467136821:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45623,DS-863dfc3a-e18d-476e-b0ac-f9a76cb92ded,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-8be4899d-8450-496c-8161-ce81d5c01864,DISK], DatanodeInfoWithStorage[127.0.0.1:35165,DS-5d7f70b3-4132-4a82-a7d3-0367dd2ce355,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-2dac9a9a-b2f3-4c8c-b099-80a1aed92075,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-b0891948-af1d-4c41-9e20-977c01ba6c51,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-1b44a208-24b0-4b8d-8e16-dac94884a3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-d0e17a7c-3a13-470f-b7d3-c40ef08e1f81,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-36649fd5-32d0-4c05-9eae-e1ce089a8d8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-681121986-172.17.0.5-1597467340513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41570,DS-0fe0d371-8e18-4223-b376-cf7614913ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-449aafff-dbcd-4513-8e25-b353616de54e,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-affe8dc8-ebe7-4794-8523-f5c893c3bd12,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-aa153973-7c9c-47a7-91be-906034e5a459,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-98d20962-9d5f-4367-bb23-f2f415546bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-960243f9-2ac7-4bf8-a86e-1e0ecaf309f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-ab987d47-3b46-4b50-85b6-f61de1a6e86f,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-b8739295-62d0-40e4-8bac-bab164cc4255,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-681121986-172.17.0.5-1597467340513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41570,DS-0fe0d371-8e18-4223-b376-cf7614913ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:34965,DS-449aafff-dbcd-4513-8e25-b353616de54e,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-affe8dc8-ebe7-4794-8523-f5c893c3bd12,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-aa153973-7c9c-47a7-91be-906034e5a459,DISK], DatanodeInfoWithStorage[127.0.0.1:44820,DS-98d20962-9d5f-4367-bb23-f2f415546bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40636,DS-960243f9-2ac7-4bf8-a86e-1e0ecaf309f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-ab987d47-3b46-4b50-85b6-f61de1a6e86f,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-b8739295-62d0-40e4-8bac-bab164cc4255,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1670162764-172.17.0.5-1597467382788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39303,DS-38ed3a61-2afa-457e-b25e-e5c4ad4a5afb,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-957ee0b3-9578-456b-bec2-ebba500f5dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-c3ee3ccf-45a8-468f-a037-f98a22f68735,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-8db6959c-891e-49a5-84a6-40b7560a401f,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-b863436d-4499-4127-ab8b-1cdab8f8dd65,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-67318947-52e7-434d-bd19-f1ee849e863b,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-ce51e030-a2c8-4def-bf65-a7995f3d440a,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-668c2032-4bbe-4895-8f1c-de4d32812804,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1670162764-172.17.0.5-1597467382788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39303,DS-38ed3a61-2afa-457e-b25e-e5c4ad4a5afb,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-957ee0b3-9578-456b-bec2-ebba500f5dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-c3ee3ccf-45a8-468f-a037-f98a22f68735,DISK], DatanodeInfoWithStorage[127.0.0.1:35637,DS-8db6959c-891e-49a5-84a6-40b7560a401f,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-b863436d-4499-4127-ab8b-1cdab8f8dd65,DISK], DatanodeInfoWithStorage[127.0.0.1:37675,DS-67318947-52e7-434d-bd19-f1ee849e863b,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-ce51e030-a2c8-4def-bf65-a7995f3d440a,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-668c2032-4bbe-4895-8f1c-de4d32812804,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376787415-172.17.0.5-1597467540887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46022,DS-7b9b7f72-ed60-42d6-b251-f938e9379a33,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-f6954bc1-8feb-488b-abce-dbb75b500048,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-67e2c4a4-32dd-44b8-979b-cec07389e31f,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-92aec6df-081e-446a-b068-53978afd478c,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-10194731-58f8-41b2-93ea-63e8661ea8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-2ec72f59-48b8-454b-a969-1590f14273a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-71740153-86bd-48c2-b9db-1659458aae2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-7719aa23-f460-4602-b11a-88d7cea611a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376787415-172.17.0.5-1597467540887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46022,DS-7b9b7f72-ed60-42d6-b251-f938e9379a33,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-f6954bc1-8feb-488b-abce-dbb75b500048,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-67e2c4a4-32dd-44b8-979b-cec07389e31f,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-92aec6df-081e-446a-b068-53978afd478c,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-10194731-58f8-41b2-93ea-63e8661ea8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-2ec72f59-48b8-454b-a969-1590f14273a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-71740153-86bd-48c2-b9db-1659458aae2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33767,DS-7719aa23-f460-4602-b11a-88d7cea611a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-886813357-172.17.0.5-1597467746005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44056,DS-ee128d79-d3a9-470f-bdfd-2fa3defb91d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-eed644e6-c820-4a8c-8667-03927e846cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-ce484b35-893b-4ab7-a9f7-d9f442487263,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-9cdb6cc5-e3d0-4df0-948d-cdc7cb876e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-fad3e239-4fea-4f00-ae17-519cace41a18,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-7b0fc75e-16eb-40c6-8259-135557c952b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-4a3bb062-6c7e-43b4-8889-1259a98aa6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33097,DS-b764493a-506c-4576-a261-2e4b361afcac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-886813357-172.17.0.5-1597467746005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44056,DS-ee128d79-d3a9-470f-bdfd-2fa3defb91d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40251,DS-eed644e6-c820-4a8c-8667-03927e846cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-ce484b35-893b-4ab7-a9f7-d9f442487263,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-9cdb6cc5-e3d0-4df0-948d-cdc7cb876e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42272,DS-fad3e239-4fea-4f00-ae17-519cace41a18,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-7b0fc75e-16eb-40c6-8259-135557c952b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41994,DS-4a3bb062-6c7e-43b4-8889-1259a98aa6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33097,DS-b764493a-506c-4576-a261-2e4b361afcac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-767429711-172.17.0.5-1597468178381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37615,DS-b3e4ba60-cbd3-4445-98ba-650bd65ce9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-4d2fc807-692d-49a6-adaa-7300f67f3290,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-59c8bf67-4927-45e9-aaa1-d59228adf031,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-34420b6b-445f-4a1c-a14b-d31cb1e3b9be,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-efb201fa-864e-468a-b764-c9278676dc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-a80b2122-1c3b-4e9c-8d55-59aa1c01b951,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-edda9d0a-3fd9-4813-998a-ae3ce0ccc061,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-8e1632a7-edc7-4dfd-bd67-c1f758e5af23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-767429711-172.17.0.5-1597468178381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37615,DS-b3e4ba60-cbd3-4445-98ba-650bd65ce9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-4d2fc807-692d-49a6-adaa-7300f67f3290,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-59c8bf67-4927-45e9-aaa1-d59228adf031,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-34420b6b-445f-4a1c-a14b-d31cb1e3b9be,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-efb201fa-864e-468a-b764-c9278676dc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-a80b2122-1c3b-4e9c-8d55-59aa1c01b951,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-edda9d0a-3fd9-4813-998a-ae3ce0ccc061,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-8e1632a7-edc7-4dfd-bd67-c1f758e5af23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-870763710-172.17.0.5-1597468910136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34789,DS-16e34542-f3b0-4568-86e5-a739c94c2ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-efbd3392-096f-4a96-af2e-742b1e45bc40,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-f0ee1327-54ed-4bfb-8791-da9d2f0c615d,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-01c664f4-d401-43f8-b37a-e07863ce2653,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-b0d77415-fb39-4eed-9055-5cba81cc2b24,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-f68b4f1b-5804-432d-8a85-2fe875907e51,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-059d3dd3-1c38-4096-9dc4-a3f28ca840ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-a2a99357-b36d-4af9-a993-761fbb8887ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-870763710-172.17.0.5-1597468910136:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34789,DS-16e34542-f3b0-4568-86e5-a739c94c2ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-efbd3392-096f-4a96-af2e-742b1e45bc40,DISK], DatanodeInfoWithStorage[127.0.0.1:42047,DS-f0ee1327-54ed-4bfb-8791-da9d2f0c615d,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-01c664f4-d401-43f8-b37a-e07863ce2653,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-b0d77415-fb39-4eed-9055-5cba81cc2b24,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-f68b4f1b-5804-432d-8a85-2fe875907e51,DISK], DatanodeInfoWithStorage[127.0.0.1:41818,DS-059d3dd3-1c38-4096-9dc4-a3f28ca840ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-a2a99357-b36d-4af9-a993-761fbb8887ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934715492-172.17.0.5-1597469688121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42072,DS-5f78010a-4fa1-4522-b1e1-24b3a937e2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-c5272c3c-fc17-4364-ae0e-5b4dca97cef1,DISK], DatanodeInfoWithStorage[127.0.0.1:39902,DS-7edbb247-4486-4efb-817e-628c4f034879,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-b03c48cb-c9e6-4beb-baf6-f49c05604357,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-626cfcc9-ad31-4ba6-915f-e1a9904cd7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-b0468178-1bdb-451c-b11e-293a27d85e11,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-de254c46-92b0-4598-97ac-17f86a0c43d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-b9f87353-138d-4a3b-9ebc-1fbbb78a3caf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-934715492-172.17.0.5-1597469688121:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42072,DS-5f78010a-4fa1-4522-b1e1-24b3a937e2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-c5272c3c-fc17-4364-ae0e-5b4dca97cef1,DISK], DatanodeInfoWithStorage[127.0.0.1:39902,DS-7edbb247-4486-4efb-817e-628c4f034879,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-b03c48cb-c9e6-4beb-baf6-f49c05604357,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-626cfcc9-ad31-4ba6-915f-e1a9904cd7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-b0468178-1bdb-451c-b11e-293a27d85e11,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-de254c46-92b0-4598-97ac-17f86a0c43d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-b9f87353-138d-4a3b-9ebc-1fbbb78a3caf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114816873-172.17.0.5-1597470268786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41507,DS-30b3fc5a-c109-4e4c-ac06-a14b67d3c6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-91739837-efbc-40f8-a801-76f3488b7b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-87bac582-d97d-43aa-9801-da1f19f4dee7,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-75b7c8b3-397d-48f5-b9fe-4a4e8d76d817,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-7052fa2c-daf5-42e8-81a4-2a57c6125feb,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-db9a81b7-f976-4ddb-a58f-df2e1ea3dd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-580cade7-9cd0-45ac-a9e6-317db52ae7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-f1d5a9cc-d4e3-4883-8b50-86e56da43c7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114816873-172.17.0.5-1597470268786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41507,DS-30b3fc5a-c109-4e4c-ac06-a14b67d3c6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-91739837-efbc-40f8-a801-76f3488b7b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-87bac582-d97d-43aa-9801-da1f19f4dee7,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-75b7c8b3-397d-48f5-b9fe-4a4e8d76d817,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-7052fa2c-daf5-42e8-81a4-2a57c6125feb,DISK], DatanodeInfoWithStorage[127.0.0.1:45215,DS-db9a81b7-f976-4ddb-a58f-df2e1ea3dd0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-580cade7-9cd0-45ac-a9e6-317db52ae7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40436,DS-f1d5a9cc-d4e3-4883-8b50-86e56da43c7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1148044765-172.17.0.5-1597470306086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43280,DS-c6d53f2d-2c8d-4552-9794-c8eee4b017d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-600ae41b-89ec-4286-874a-d5c63d1a666f,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-2458e934-7771-4ecb-9b4c-5f025072e8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-62cd9fa2-983b-48a9-8524-3b867f2292f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-79965e92-a874-499f-aa70-d89dfe9853dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-604d9ed4-a107-4b7b-98dc-2623336b0bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-7d4a66fd-4b2f-4281-bdfa-248a564a63da,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-f75ddaec-925d-46b6-a1ee-e232700249fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1148044765-172.17.0.5-1597470306086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43280,DS-c6d53f2d-2c8d-4552-9794-c8eee4b017d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-600ae41b-89ec-4286-874a-d5c63d1a666f,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-2458e934-7771-4ecb-9b4c-5f025072e8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40684,DS-62cd9fa2-983b-48a9-8524-3b867f2292f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-79965e92-a874-499f-aa70-d89dfe9853dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46024,DS-604d9ed4-a107-4b7b-98dc-2623336b0bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-7d4a66fd-4b2f-4281-bdfa-248a564a63da,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-f75ddaec-925d-46b6-a1ee-e232700249fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 262144
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749117701-172.17.0.5-1597470340398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35459,DS-f99d9c28-ab8f-43b2-89db-fbb478df1c70,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-7ac787cd-3819-47c1-89a3-ca28955a45d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-dde9078b-afb6-4979-81de-a242cdb682ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-4554fd3f-ed16-4b72-865a-ce5ddaad0734,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-ac05b7f1-2692-4db2-9d98-5aa572a1abf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-12aab4fc-cee0-4098-98e8-d530b362c1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-46328eec-cd63-404f-85c6-c3e624db696b,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-28873f1e-d60e-4c08-923e-a38baf6e7ae2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749117701-172.17.0.5-1597470340398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35459,DS-f99d9c28-ab8f-43b2-89db-fbb478df1c70,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-7ac787cd-3819-47c1-89a3-ca28955a45d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-dde9078b-afb6-4979-81de-a242cdb682ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43464,DS-4554fd3f-ed16-4b72-865a-ce5ddaad0734,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-ac05b7f1-2692-4db2-9d98-5aa572a1abf1,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-12aab4fc-cee0-4098-98e8-d530b362c1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-46328eec-cd63-404f-85c6-c3e624db696b,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-28873f1e-d60e-4c08-923e-a38baf6e7ae2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: might be true error
Total execution time in seconds : 5637
