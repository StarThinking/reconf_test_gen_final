reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-640653410-172.17.0.9-1597478375957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34763,DS-ab500924-5131-421b-84f4-4f4f5f938ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-32a42ab0-a1ca-47cc-aca9-5bb1eaa8dadc,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-c087fe9d-5144-4410-ab3c-be8c791be0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-6b87b445-3752-4631-9b4c-4e9777fe6ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-5b9ebb31-d457-4f8c-8bc3-29a81eb753a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-bf1e56d5-5c18-478f-90c0-0e8e6e2d2271,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-611ea295-0de6-4d29-aa51-166655ab467d,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-4f42c11b-a277-407e-bb2a-725ae714c4ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-640653410-172.17.0.9-1597478375957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34763,DS-ab500924-5131-421b-84f4-4f4f5f938ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:38600,DS-32a42ab0-a1ca-47cc-aca9-5bb1eaa8dadc,DISK], DatanodeInfoWithStorage[127.0.0.1:46869,DS-c087fe9d-5144-4410-ab3c-be8c791be0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-6b87b445-3752-4631-9b4c-4e9777fe6ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:39552,DS-5b9ebb31-d457-4f8c-8bc3-29a81eb753a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-bf1e56d5-5c18-478f-90c0-0e8e6e2d2271,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-611ea295-0de6-4d29-aa51-166655ab467d,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-4f42c11b-a277-407e-bb2a-725ae714c4ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1667061400-172.17.0.9-1597478628879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46516,DS-fa89c572-c0f7-47bb-9e8c-4c47e4672f26,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-fa697db6-7bf2-47fb-921d-03754d4313a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-70b8673a-b11d-47c4-bcbe-f74dd3dc90ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-2c9738c3-cb79-4ab0-a2de-e3071b9d9d33,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-f50dfa29-f5fa-4ced-906e-99022466ca6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-e0493a84-e3be-414f-9453-2cb609e0da6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-2281f8da-25c2-4f7c-967e-e9bc985dedd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-2bca194e-8cc9-4117-8d85-746f79e400d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1667061400-172.17.0.9-1597478628879:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46516,DS-fa89c572-c0f7-47bb-9e8c-4c47e4672f26,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-fa697db6-7bf2-47fb-921d-03754d4313a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34234,DS-70b8673a-b11d-47c4-bcbe-f74dd3dc90ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42939,DS-2c9738c3-cb79-4ab0-a2de-e3071b9d9d33,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-f50dfa29-f5fa-4ced-906e-99022466ca6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-e0493a84-e3be-414f-9453-2cb609e0da6f,DISK], DatanodeInfoWithStorage[127.0.0.1:39994,DS-2281f8da-25c2-4f7c-967e-e9bc985dedd4,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-2bca194e-8cc9-4117-8d85-746f79e400d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-268335683-172.17.0.9-1597480815372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37750,DS-0db27063-7d51-4996-a51f-ae3b93df4ede,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-65a42a45-f90b-4e66-afc6-97eea11fcd38,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-2debd677-2b87-40dd-9f68-fe7333745e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-0490abc5-a313-43a1-962b-949746605161,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-1e778231-dad6-4a23-b914-26b8bfc02e84,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-f6cc8028-980a-4657-a6b7-884233f4e67c,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-8ab55eb9-1a3b-44d2-850c-9c977156c296,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-f77a17c7-f45a-446a-9081-041691570efd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-268335683-172.17.0.9-1597480815372:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37750,DS-0db27063-7d51-4996-a51f-ae3b93df4ede,DISK], DatanodeInfoWithStorage[127.0.0.1:35406,DS-65a42a45-f90b-4e66-afc6-97eea11fcd38,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-2debd677-2b87-40dd-9f68-fe7333745e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43264,DS-0490abc5-a313-43a1-962b-949746605161,DISK], DatanodeInfoWithStorage[127.0.0.1:44808,DS-1e778231-dad6-4a23-b914-26b8bfc02e84,DISK], DatanodeInfoWithStorage[127.0.0.1:42444,DS-f6cc8028-980a-4657-a6b7-884233f4e67c,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-8ab55eb9-1a3b-44d2-850c-9c977156c296,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-f77a17c7-f45a-446a-9081-041691570efd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1818719284-172.17.0.9-1597480966714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46625,DS-bb7d317f-b83c-46e5-957b-025b0e173035,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-75291bf2-25fa-41a7-89f0-5216417c42c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-2eafa943-5aab-491e-b0ba-49d0e971e24b,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-6e44eace-e16e-4e0b-a2cd-3ee0727c0170,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-f24cf722-27ee-4f78-a8ec-6c86c99d0911,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-bbc02f23-7f77-4b19-b888-3203e377ac86,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-05e234fd-9cab-4396-8ce7-c178c794c375,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-d546240c-a0c3-4753-8669-6a01a17ea9f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1818719284-172.17.0.9-1597480966714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46625,DS-bb7d317f-b83c-46e5-957b-025b0e173035,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-75291bf2-25fa-41a7-89f0-5216417c42c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-2eafa943-5aab-491e-b0ba-49d0e971e24b,DISK], DatanodeInfoWithStorage[127.0.0.1:34207,DS-6e44eace-e16e-4e0b-a2cd-3ee0727c0170,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-f24cf722-27ee-4f78-a8ec-6c86c99d0911,DISK], DatanodeInfoWithStorage[127.0.0.1:44794,DS-bbc02f23-7f77-4b19-b888-3203e377ac86,DISK], DatanodeInfoWithStorage[127.0.0.1:45253,DS-05e234fd-9cab-4396-8ce7-c178c794c375,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-d546240c-a0c3-4753-8669-6a01a17ea9f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1753244643-172.17.0.9-1597481002604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33841,DS-1383daba-ba09-45e9-bf83-2cf250f5b42e,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-f0521a61-28c8-4e4c-afcd-25964ba2af9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-5e399ef5-ab72-4a00-b061-61e5d472f7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-d7d74750-072e-4883-993c-5c54a8bcbd99,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-ce9a25a8-7055-4ce1-b3f4-56a61dc370a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-f15a9366-f142-40a7-9039-5392833c108b,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-85ecf0c2-4949-4f3c-9bf4-2bf7e3320276,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-35705bb4-8e4a-4c6f-8d9a-2dfcbc0045a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1753244643-172.17.0.9-1597481002604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33841,DS-1383daba-ba09-45e9-bf83-2cf250f5b42e,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-f0521a61-28c8-4e4c-afcd-25964ba2af9d,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-5e399ef5-ab72-4a00-b061-61e5d472f7d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-d7d74750-072e-4883-993c-5c54a8bcbd99,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-ce9a25a8-7055-4ce1-b3f4-56a61dc370a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-f15a9366-f142-40a7-9039-5392833c108b,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-85ecf0c2-4949-4f3c-9bf4-2bf7e3320276,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-35705bb4-8e4a-4c6f-8d9a-2dfcbc0045a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2025514645-172.17.0.9-1597481327612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35861,DS-925ff1aa-4366-46cf-b8f7-09448b25a625,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-799aa0cc-e16e-4c27-8be7-b2e0c63f0757,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-3b3326f6-7c8a-41ab-afe2-54ace4f17e47,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-03cfa2fe-dba1-4d28-bdcd-4dbb6daf3be8,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-94174016-74f9-4435-8628-ccaff0ff5fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-d255f1a1-e319-4c2b-9831-51df4758a54e,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-73394173-e1dc-4e7d-90a5-968c23e8f2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-59367d61-0711-4be8-ad6b-630d8518e652,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2025514645-172.17.0.9-1597481327612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35861,DS-925ff1aa-4366-46cf-b8f7-09448b25a625,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-799aa0cc-e16e-4c27-8be7-b2e0c63f0757,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-3b3326f6-7c8a-41ab-afe2-54ace4f17e47,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-03cfa2fe-dba1-4d28-bdcd-4dbb6daf3be8,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-94174016-74f9-4435-8628-ccaff0ff5fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-d255f1a1-e319-4c2b-9831-51df4758a54e,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-73394173-e1dc-4e7d-90a5-968c23e8f2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-59367d61-0711-4be8-ad6b-630d8518e652,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-700763161-172.17.0.9-1597481508929:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42875,DS-177abd64-f612-4719-a610-2a7573334a26,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-7e23e23d-0db9-439b-a098-6134f4138b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-7337a2f1-e74f-4e55-a230-5355fd1a46f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-a52354fd-d888-49b8-88d5-bd1899bfdfbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-219253b6-b93d-428c-a378-2f1f9b1f146c,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-89226886-2794-4b96-903d-912bbc3da96d,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-00ff8c76-9e3d-42ef-8404-f1e26a35901a,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-b07e2aa7-d532-443e-86ab-6b872708d06c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-700763161-172.17.0.9-1597481508929:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42875,DS-177abd64-f612-4719-a610-2a7573334a26,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-7e23e23d-0db9-439b-a098-6134f4138b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-7337a2f1-e74f-4e55-a230-5355fd1a46f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-a52354fd-d888-49b8-88d5-bd1899bfdfbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-219253b6-b93d-428c-a378-2f1f9b1f146c,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-89226886-2794-4b96-903d-912bbc3da96d,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-00ff8c76-9e3d-42ef-8404-f1e26a35901a,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-b07e2aa7-d532-443e-86ab-6b872708d06c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1694548728-172.17.0.9-1597481621098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37336,DS-0a6c96eb-b4d9-4e19-bdea-59bfd4069788,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-cfdd544d-1e58-4d16-9d61-5f8e0bb2dd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-62cd7371-3609-451a-812b-d57b11bb776c,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-43e287e6-6a4a-4ec4-a68b-286e4f3ac822,DISK], DatanodeInfoWithStorage[127.0.0.1:41427,DS-a87c03fb-47b5-4ea1-8616-13760b10f98d,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-9b6be0d2-7052-4f15-8b37-33d0ac01566b,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-a2e7b392-9d44-4ad5-94f5-59f7b4028bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-e0901ef5-2a57-45ed-baf4-08eaa8d9e1b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1694548728-172.17.0.9-1597481621098:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37336,DS-0a6c96eb-b4d9-4e19-bdea-59bfd4069788,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-cfdd544d-1e58-4d16-9d61-5f8e0bb2dd7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-62cd7371-3609-451a-812b-d57b11bb776c,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-43e287e6-6a4a-4ec4-a68b-286e4f3ac822,DISK], DatanodeInfoWithStorage[127.0.0.1:41427,DS-a87c03fb-47b5-4ea1-8616-13760b10f98d,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-9b6be0d2-7052-4f15-8b37-33d0ac01566b,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-a2e7b392-9d44-4ad5-94f5-59f7b4028bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:36244,DS-e0901ef5-2a57-45ed-baf4-08eaa8d9e1b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-926927276-172.17.0.9-1597481770488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34940,DS-7f04589e-2822-4ad2-aad4-e6e55d3f7ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:40081,DS-46630e39-71d0-4503-a4c9-49d97d3c6908,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-37ff1f37-0858-4bec-a43a-5ec2e1b8790a,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-721ea68f-2762-4ed5-9756-bb328169d9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-18bbe5a4-5f87-4ee6-9b1d-09d54839b1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-0841799d-392f-466f-b871-cd7138d1eed6,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-ab1e1f4d-fdf4-4068-8df2-4b7f2cec8412,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-10c90895-8b28-4dbf-b595-78dfb325b25b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-926927276-172.17.0.9-1597481770488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34940,DS-7f04589e-2822-4ad2-aad4-e6e55d3f7ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:40081,DS-46630e39-71d0-4503-a4c9-49d97d3c6908,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-37ff1f37-0858-4bec-a43a-5ec2e1b8790a,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-721ea68f-2762-4ed5-9756-bb328169d9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33760,DS-18bbe5a4-5f87-4ee6-9b1d-09d54839b1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-0841799d-392f-466f-b871-cd7138d1eed6,DISK], DatanodeInfoWithStorage[127.0.0.1:32802,DS-ab1e1f4d-fdf4-4068-8df2-4b7f2cec8412,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-10c90895-8b28-4dbf-b595-78dfb325b25b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-344303085-172.17.0.9-1597482981019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43400,DS-4106fe29-0d49-4201-bb6a-11ba20236024,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-73a301b2-ba08-4c4c-b5f1-ae54457e83a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-42247cbe-992f-4db2-a9d3-3d122eb56686,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-a1af3be9-e72f-4252-9d61-c737544bf941,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-e8b7d4a8-bc90-4daf-97cb-ad3c5af96071,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-bccaa07a-5b67-4ee8-a516-6c22455ae84f,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-293f0768-c7b9-4c17-9792-69475ced0a29,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-69627837-3688-48ed-8317-26448bdd7fba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-344303085-172.17.0.9-1597482981019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43400,DS-4106fe29-0d49-4201-bb6a-11ba20236024,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-73a301b2-ba08-4c4c-b5f1-ae54457e83a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38409,DS-42247cbe-992f-4db2-a9d3-3d122eb56686,DISK], DatanodeInfoWithStorage[127.0.0.1:36988,DS-a1af3be9-e72f-4252-9d61-c737544bf941,DISK], DatanodeInfoWithStorage[127.0.0.1:46612,DS-e8b7d4a8-bc90-4daf-97cb-ad3c5af96071,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-bccaa07a-5b67-4ee8-a516-6c22455ae84f,DISK], DatanodeInfoWithStorage[127.0.0.1:36801,DS-293f0768-c7b9-4c17-9792-69475ced0a29,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-69627837-3688-48ed-8317-26448bdd7fba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1247036136-172.17.0.9-1597483269187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40596,DS-fa3bb75c-33d0-4f2f-acdd-71d547a156be,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-1a813fd3-07a0-4c9b-962d-6b57408b8cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-26cbb812-3f93-4d02-966b-41a8bd037d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-f8ed52ae-faae-4480-9e69-4472f1d3b419,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-32e92446-2013-4c80-b146-4685f7d3b92b,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-eb8e23f0-154f-4dd1-8745-c62051a49e17,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-52d38c2e-88fd-4f5f-9e9a-479f5b6b31a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-4d1d03db-f146-461f-b57c-6fc21d390542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1247036136-172.17.0.9-1597483269187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40596,DS-fa3bb75c-33d0-4f2f-acdd-71d547a156be,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-1a813fd3-07a0-4c9b-962d-6b57408b8cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-26cbb812-3f93-4d02-966b-41a8bd037d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-f8ed52ae-faae-4480-9e69-4472f1d3b419,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-32e92446-2013-4c80-b146-4685f7d3b92b,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-eb8e23f0-154f-4dd1-8745-c62051a49e17,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-52d38c2e-88fd-4f5f-9e9a-479f5b6b31a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-4d1d03db-f146-461f-b57c-6fc21d390542,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 100000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1743905069-172.17.0.9-1597483462638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42844,DS-7b2d1f55-5004-426b-b5e5-cd40d348a079,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-2a10a53c-2fa4-446c-99d9-93b010f802e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-eaca6eae-d84e-4400-93eb-70009f1edb20,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-561a4301-5e08-4cd9-b26c-486ea05d8b53,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-710298cd-08e6-4882-9384-2d8e4310a337,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-cca78142-bec8-42fb-864c-05ce5fc7769e,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-ca863fa7-809d-47cf-b916-81633abd307b,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-eac5de48-af59-46cf-95d5-4dc2ec9b7d64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1743905069-172.17.0.9-1597483462638:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42844,DS-7b2d1f55-5004-426b-b5e5-cd40d348a079,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-2a10a53c-2fa4-446c-99d9-93b010f802e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-eaca6eae-d84e-4400-93eb-70009f1edb20,DISK], DatanodeInfoWithStorage[127.0.0.1:45043,DS-561a4301-5e08-4cd9-b26c-486ea05d8b53,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-710298cd-08e6-4882-9384-2d8e4310a337,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-cca78142-bec8-42fb-864c-05ce5fc7769e,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-ca863fa7-809d-47cf-b916-81633abd307b,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-eac5de48-af59-46cf-95d5-4dc2ec9b7d64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5522
