reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1334055403-172.17.0.4-1597467749900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36427,DS-599a209f-a350-46c2-84f3-b5281abc28e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-de728c32-051b-4725-bc9b-645304f6326c,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-597904a0-7fce-4b4c-a3a5-442435854f56,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-7863e6dd-d207-456d-9efd-7e784bfc71f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-0cf0384d-46f2-4e0a-8fc5-7017b8a0995a,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-f2cf0fc2-a83c-4c93-81dd-887f20d5d2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-8d0e98a3-2bc4-4be3-b3a0-699669e4ac31,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-e0264d0b-f139-4b06-b5d6-1f15f2b424f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1334055403-172.17.0.4-1597467749900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36427,DS-599a209f-a350-46c2-84f3-b5281abc28e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37218,DS-de728c32-051b-4725-bc9b-645304f6326c,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-597904a0-7fce-4b4c-a3a5-442435854f56,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-7863e6dd-d207-456d-9efd-7e784bfc71f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-0cf0384d-46f2-4e0a-8fc5-7017b8a0995a,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-f2cf0fc2-a83c-4c93-81dd-887f20d5d2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38338,DS-8d0e98a3-2bc4-4be3-b3a0-699669e4ac31,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-e0264d0b-f139-4b06-b5d6-1f15f2b424f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2005677217-172.17.0.4-1597468237580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36270,DS-23cbda2f-6b16-4a91-8b12-6dd5fa276d59,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-b972fbd3-7f32-4248-9869-ee4c2776a368,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-948334e2-bf81-416f-bff9-5591236b7c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-305ad637-9b50-4b8d-a342-5ba440b5243d,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-a227710c-fb3b-4d07-a990-bbe917a102aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-d6da1f94-0da2-4661-a442-4d17d308a82f,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-c82a8943-17c5-440c-ad64-f8a53530d3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-449a300d-2ea2-4735-826d-f2139e4c0129,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2005677217-172.17.0.4-1597468237580:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36270,DS-23cbda2f-6b16-4a91-8b12-6dd5fa276d59,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-b972fbd3-7f32-4248-9869-ee4c2776a368,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-948334e2-bf81-416f-bff9-5591236b7c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-305ad637-9b50-4b8d-a342-5ba440b5243d,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-a227710c-fb3b-4d07-a990-bbe917a102aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-d6da1f94-0da2-4661-a442-4d17d308a82f,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-c82a8943-17c5-440c-ad64-f8a53530d3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-449a300d-2ea2-4735-826d-f2139e4c0129,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2048235552-172.17.0.4-1597468983702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34925,DS-0f46daf4-3421-4143-9c51-5f5166629207,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-03207293-090e-4eec-8708-908765609556,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-1473828a-74ff-4968-a117-cfcdcc381d45,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-27459bce-7fad-4d62-9bb7-d2bb99566047,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-f7cd6b81-3152-4039-b847-95bd2a39ac41,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-c689f20c-196a-4918-a61d-e777a7ee4c95,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-711ea3e9-0dde-4eca-b92d-0c05ab335572,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-7922e881-19ca-4a39-a145-44d7533bb46e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2048235552-172.17.0.4-1597468983702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34925,DS-0f46daf4-3421-4143-9c51-5f5166629207,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-03207293-090e-4eec-8708-908765609556,DISK], DatanodeInfoWithStorage[127.0.0.1:43918,DS-1473828a-74ff-4968-a117-cfcdcc381d45,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-27459bce-7fad-4d62-9bb7-d2bb99566047,DISK], DatanodeInfoWithStorage[127.0.0.1:43505,DS-f7cd6b81-3152-4039-b847-95bd2a39ac41,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-c689f20c-196a-4918-a61d-e777a7ee4c95,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-711ea3e9-0dde-4eca-b92d-0c05ab335572,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-7922e881-19ca-4a39-a145-44d7533bb46e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440903035-172.17.0.4-1597469404075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45330,DS-ccac24c9-ce96-499c-84d9-c22eaa98270a,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-5a737ecd-c714-457a-aaba-baa67829e023,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-3e87a157-117a-4213-aa81-436a9993df53,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-6d0eed94-9caa-4e13-b1d2-04c758f09638,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-33eaa461-cfc4-4846-8e93-be3c50a99430,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-cb4341f6-65f9-493e-89d6-54ecacf02b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-4f3b4025-1d06-441f-913d-db19e063d809,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-845d9a27-7645-47a4-a277-20b7ed028565,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440903035-172.17.0.4-1597469404075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45330,DS-ccac24c9-ce96-499c-84d9-c22eaa98270a,DISK], DatanodeInfoWithStorage[127.0.0.1:43112,DS-5a737ecd-c714-457a-aaba-baa67829e023,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-3e87a157-117a-4213-aa81-436a9993df53,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-6d0eed94-9caa-4e13-b1d2-04c758f09638,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-33eaa461-cfc4-4846-8e93-be3c50a99430,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-cb4341f6-65f9-493e-89d6-54ecacf02b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-4f3b4025-1d06-441f-913d-db19e063d809,DISK], DatanodeInfoWithStorage[127.0.0.1:40075,DS-845d9a27-7645-47a4-a277-20b7ed028565,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-114712273-172.17.0.4-1597469481448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36380,DS-491f0bf0-0147-4247-8d16-34bed2c89e34,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-3ea82d45-009a-445d-8042-ffd727a1e6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-a731b3ba-684a-4765-9823-22070a5cb549,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-d224b04f-4745-440f-97a2-a11d381e025e,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-332468b8-7a3b-48ad-aa95-ebfc46549392,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-d81c26fc-b9a5-48a1-bab6-42d8655e0224,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-703b924c-99da-42df-a0b7-485478c0b82b,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-491adb04-8700-4320-b356-5ceae8dc169d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-114712273-172.17.0.4-1597469481448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36380,DS-491f0bf0-0147-4247-8d16-34bed2c89e34,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-3ea82d45-009a-445d-8042-ffd727a1e6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-a731b3ba-684a-4765-9823-22070a5cb549,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-d224b04f-4745-440f-97a2-a11d381e025e,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-332468b8-7a3b-48ad-aa95-ebfc46549392,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-d81c26fc-b9a5-48a1-bab6-42d8655e0224,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-703b924c-99da-42df-a0b7-485478c0b82b,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-491adb04-8700-4320-b356-5ceae8dc169d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712740791-172.17.0.4-1597470197533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37241,DS-a5b9705a-c683-422c-b65b-373c9eca4c77,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-d9256e37-92d9-4e1e-aeb7-4bc1c310e3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-db0632ef-ce44-41ad-a8cb-f8a7cb46c1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-da952e3a-ccfb-4880-b703-bfd4b83206f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-db590808-3bf4-48b2-b45e-f045d5230a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-7b76ce89-9884-461a-a956-525b152b394c,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-87962403-3960-4847-88bc-922d813381f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-9b920c05-09b6-424e-83c7-9eaa366aec52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712740791-172.17.0.4-1597470197533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37241,DS-a5b9705a-c683-422c-b65b-373c9eca4c77,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-d9256e37-92d9-4e1e-aeb7-4bc1c310e3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-db0632ef-ce44-41ad-a8cb-f8a7cb46c1b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-da952e3a-ccfb-4880-b703-bfd4b83206f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-db590808-3bf4-48b2-b45e-f045d5230a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-7b76ce89-9884-461a-a956-525b152b394c,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-87962403-3960-4847-88bc-922d813381f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-9b920c05-09b6-424e-83c7-9eaa366aec52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-210819258-172.17.0.4-1597470309358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46454,DS-b4c15fc6-7caf-484b-aa96-b5075763fb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-b2fed2cf-102a-48d9-b3e2-5950d38b9682,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-3639521e-c14b-42ed-bcd8-68dd1ca100ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-6de687c2-d296-41e3-87fc-bf9306ded7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-642449c9-0405-49de-aa72-fb936a4ee15c,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-24a245f0-7f0b-4501-88ac-494bcfb1595c,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-9a67eeed-1be7-45c7-af25-5aaffc853ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-b4d359a9-874f-4b8e-ac77-3e6b77b9fbd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-210819258-172.17.0.4-1597470309358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46454,DS-b4c15fc6-7caf-484b-aa96-b5075763fb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-b2fed2cf-102a-48d9-b3e2-5950d38b9682,DISK], DatanodeInfoWithStorage[127.0.0.1:38136,DS-3639521e-c14b-42ed-bcd8-68dd1ca100ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-6de687c2-d296-41e3-87fc-bf9306ded7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-642449c9-0405-49de-aa72-fb936a4ee15c,DISK], DatanodeInfoWithStorage[127.0.0.1:38353,DS-24a245f0-7f0b-4501-88ac-494bcfb1595c,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-9a67eeed-1be7-45c7-af25-5aaffc853ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-b4d359a9-874f-4b8e-ac77-3e6b77b9fbd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1331776359-172.17.0.4-1597470856234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41264,DS-a57e1264-842a-4e6f-9474-d299efd38e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-c8d980d8-915b-411a-bbfd-0c2a19bec7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-50f99fec-bad4-444a-8eee-5e0a81c5de0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41627,DS-3f822374-85c9-4fef-8ff6-f18da4cdda2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-6a63ad11-1f10-43f4-ae47-a2b44e09270a,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-d6328f7d-9e03-41b4-9849-5141c645c5df,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-48297dce-7cc5-4330-9761-d7ad03f6c744,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-9b5fd44c-f63a-464f-a739-9d14bfd3b611,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1331776359-172.17.0.4-1597470856234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41264,DS-a57e1264-842a-4e6f-9474-d299efd38e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-c8d980d8-915b-411a-bbfd-0c2a19bec7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37660,DS-50f99fec-bad4-444a-8eee-5e0a81c5de0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41627,DS-3f822374-85c9-4fef-8ff6-f18da4cdda2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-6a63ad11-1f10-43f4-ae47-a2b44e09270a,DISK], DatanodeInfoWithStorage[127.0.0.1:45981,DS-d6328f7d-9e03-41b4-9849-5141c645c5df,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-48297dce-7cc5-4330-9761-d7ad03f6c744,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-9b5fd44c-f63a-464f-a739-9d14bfd3b611,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786085789-172.17.0.4-1597471070339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41048,DS-097138ee-50b0-4094-8506-b8b7a2f10e73,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-a0107063-8602-486b-8d21-4c2c0f85fa63,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-8ba2f8ed-da5f-43ac-858d-7318c83ec33f,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-3b82f6cb-b33c-4b54-acf8-69e909b4a7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-de59d849-f4a5-4b89-b04b-c3c2452c12e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-e03bdaae-d81d-4d4f-9ba2-c0b1f35e1bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-4f632f93-d57a-4c88-bd45-b695fd4c0f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-de0c6b03-f717-46b1-80aa-072d83a635d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786085789-172.17.0.4-1597471070339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41048,DS-097138ee-50b0-4094-8506-b8b7a2f10e73,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-a0107063-8602-486b-8d21-4c2c0f85fa63,DISK], DatanodeInfoWithStorage[127.0.0.1:46767,DS-8ba2f8ed-da5f-43ac-858d-7318c83ec33f,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-3b82f6cb-b33c-4b54-acf8-69e909b4a7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40202,DS-de59d849-f4a5-4b89-b04b-c3c2452c12e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-e03bdaae-d81d-4d4f-9ba2-c0b1f35e1bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-4f632f93-d57a-4c88-bd45-b695fd4c0f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-de0c6b03-f717-46b1-80aa-072d83a635d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-349860127-172.17.0.4-1597471474196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34854,DS-01405826-af08-474f-8122-d3fea88c0b33,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-5d190db3-2906-45d7-a21a-e410a66ef4be,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-9d78e50f-daa1-4fa0-99f7-efd4e3b2c3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-172aa2b0-5058-467b-8984-74cdaad02fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-1fdfe55b-6154-4562-b3eb-f158170f0376,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-2948e63f-2bf5-4dcc-81ca-bf8ab5f034ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-ddf69752-71fb-468a-8c30-190a10ff9d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-969a8665-ab9d-41e9-8ee3-c976b935dc9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-349860127-172.17.0.4-1597471474196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34854,DS-01405826-af08-474f-8122-d3fea88c0b33,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-5d190db3-2906-45d7-a21a-e410a66ef4be,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-9d78e50f-daa1-4fa0-99f7-efd4e3b2c3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33360,DS-172aa2b0-5058-467b-8984-74cdaad02fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-1fdfe55b-6154-4562-b3eb-f158170f0376,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-2948e63f-2bf5-4dcc-81ca-bf8ab5f034ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-ddf69752-71fb-468a-8c30-190a10ff9d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-969a8665-ab9d-41e9-8ee3-c976b935dc9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143278989-172.17.0.4-1597471706266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45781,DS-3be90037-5c1e-4d37-8f0a-f6aae1cdcbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-5e5e009b-3f85-4cf2-a783-35a418828464,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-30be9a35-6d7c-4d18-8606-e28265a564a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-b5fa8772-1944-48b5-98a7-435d8b474d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-8d93099e-49a5-4bd4-a11f-8420a0babae8,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-18b92662-3886-415b-9dc2-b4e1df1ace55,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-41341661-9d64-4f7f-b412-3d6d4ff1c00c,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-6e9aeba6-1675-4a75-8c61-d03b25068902,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143278989-172.17.0.4-1597471706266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45781,DS-3be90037-5c1e-4d37-8f0a-f6aae1cdcbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-5e5e009b-3f85-4cf2-a783-35a418828464,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-30be9a35-6d7c-4d18-8606-e28265a564a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-b5fa8772-1944-48b5-98a7-435d8b474d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-8d93099e-49a5-4bd4-a11f-8420a0babae8,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-18b92662-3886-415b-9dc2-b4e1df1ace55,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-41341661-9d64-4f7f-b412-3d6d4ff1c00c,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-6e9aeba6-1675-4a75-8c61-d03b25068902,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892345434-172.17.0.4-1597471793310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36469,DS-cba34ae3-cb36-47c7-9e63-8b77b0cf87d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-9e9f37dd-24f7-4336-af37-48b99f684b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-12123ff2-e8ba-4c4a-aae6-8dd2b44f076a,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-39900733-f414-4033-b3b9-2ad221537a67,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-f22d8b61-5200-4a71-ac92-25a24d928902,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-b1d30958-923c-4b21-95b5-cfe90541a643,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-ae1a3be5-4660-4d36-bfce-ef77efa91ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-3daf332c-8fa3-4873-a1ed-0b5487c5db49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892345434-172.17.0.4-1597471793310:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36469,DS-cba34ae3-cb36-47c7-9e63-8b77b0cf87d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-9e9f37dd-24f7-4336-af37-48b99f684b3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-12123ff2-e8ba-4c4a-aae6-8dd2b44f076a,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-39900733-f414-4033-b3b9-2ad221537a67,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-f22d8b61-5200-4a71-ac92-25a24d928902,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-b1d30958-923c-4b21-95b5-cfe90541a643,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-ae1a3be5-4660-4d36-bfce-ef77efa91ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-3daf332c-8fa3-4873-a1ed-0b5487c5db49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-639380318-172.17.0.4-1597472119233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39425,DS-f468ed77-2d65-4740-932d-39c59ec85683,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-3864d530-827e-48f7-bcfd-9dc1b0f91ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-166a90c5-68a4-438b-b477-59153c6ca3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-c2b77630-7bef-49fc-a93c-5ad18d578b32,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-7d255b34-5427-4e3b-acaa-8c99d1b79b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-5e45752d-14cb-4fb4-b1dc-ace798edc7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-90066d89-525e-45a7-85c1-c77a67edb46b,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-94fae9cf-487f-40e7-9dc2-5323a684b601,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-639380318-172.17.0.4-1597472119233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39425,DS-f468ed77-2d65-4740-932d-39c59ec85683,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-3864d530-827e-48f7-bcfd-9dc1b0f91ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-166a90c5-68a4-438b-b477-59153c6ca3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-c2b77630-7bef-49fc-a93c-5ad18d578b32,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-7d255b34-5427-4e3b-acaa-8c99d1b79b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-5e45752d-14cb-4fb4-b1dc-ace798edc7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-90066d89-525e-45a7-85c1-c77a67edb46b,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-94fae9cf-487f-40e7-9dc2-5323a684b601,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 100
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961028233-172.17.0.4-1597472451684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35728,DS-3ee081b1-ce15-4e87-ba51-f80146009ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-67a40fd9-a264-4c62-9a05-259b67b967ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-441482cc-a3fa-43b3-a332-f2b07f13b37c,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-0675e494-7dc0-4003-998d-32e4e9aee460,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-e1f49064-fc41-4e6f-8326-e68010e35660,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-62daf77f-5cf8-4e3d-b1ed-5a792ff23df4,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-9564299b-d364-4cd8-94f3-7bcb6a0cf7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-537bdc85-b260-4083-b6a8-11a7f2644ff7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961028233-172.17.0.4-1597472451684:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35728,DS-3ee081b1-ce15-4e87-ba51-f80146009ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-67a40fd9-a264-4c62-9a05-259b67b967ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37411,DS-441482cc-a3fa-43b3-a332-f2b07f13b37c,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-0675e494-7dc0-4003-998d-32e4e9aee460,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-e1f49064-fc41-4e6f-8326-e68010e35660,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-62daf77f-5cf8-4e3d-b1ed-5a792ff23df4,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-9564299b-d364-4cd8-94f3-7bcb6a0cf7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-537bdc85-b260-4083-b6a8-11a7f2644ff7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5814
