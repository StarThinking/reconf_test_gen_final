reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-733753624-172.17.0.4-1597440519518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46136,DS-a37a4c9d-9f2f-4517-a1ed-3bc0cf19b2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-debab489-c3e5-4c54-84d0-39b931a5576a,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-379f535b-3f1f-428c-9d53-04dee6449093,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-5a5feeb3-10b6-46b2-a250-3b757f2732ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-58e55fc7-a8c0-4267-85d0-17942947a515,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-57d3941b-b902-4247-a706-987958e36a79,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-2954fda2-49be-487d-8bea-0940b9887003,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-c96ba10a-9689-4f11-90b9-fc5abf02d361,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-733753624-172.17.0.4-1597440519518:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46136,DS-a37a4c9d-9f2f-4517-a1ed-3bc0cf19b2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-debab489-c3e5-4c54-84d0-39b931a5576a,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-379f535b-3f1f-428c-9d53-04dee6449093,DISK], DatanodeInfoWithStorage[127.0.0.1:46488,DS-5a5feeb3-10b6-46b2-a250-3b757f2732ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-58e55fc7-a8c0-4267-85d0-17942947a515,DISK], DatanodeInfoWithStorage[127.0.0.1:37981,DS-57d3941b-b902-4247-a706-987958e36a79,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-2954fda2-49be-487d-8bea-0940b9887003,DISK], DatanodeInfoWithStorage[127.0.0.1:45282,DS-c96ba10a-9689-4f11-90b9-fc5abf02d361,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1368504660-172.17.0.4-1597440837770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34762,DS-9086711d-3b35-4358-8a4c-8cd382a337b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-e86373d2-a466-4851-9bbe-4efe4b8e5272,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-4da738aa-a22d-42b4-b021-71f0a283ab62,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-0e04fbaf-3402-4cfc-913e-1f730718f92d,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-dc98f872-580e-4944-95a4-41e5c3fa406c,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-bfedfa60-f824-418e-8d64-b268571224b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-a08bdf60-c6db-49db-927f-487b3424fb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-667f744a-a189-4b2f-908b-d0c7c418d86d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1368504660-172.17.0.4-1597440837770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34762,DS-9086711d-3b35-4358-8a4c-8cd382a337b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-e86373d2-a466-4851-9bbe-4efe4b8e5272,DISK], DatanodeInfoWithStorage[127.0.0.1:45742,DS-4da738aa-a22d-42b4-b021-71f0a283ab62,DISK], DatanodeInfoWithStorage[127.0.0.1:38750,DS-0e04fbaf-3402-4cfc-913e-1f730718f92d,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-dc98f872-580e-4944-95a4-41e5c3fa406c,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-bfedfa60-f824-418e-8d64-b268571224b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-a08bdf60-c6db-49db-927f-487b3424fb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33602,DS-667f744a-a189-4b2f-908b-d0c7c418d86d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1543695067-172.17.0.4-1597441254379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34659,DS-94480ebe-9495-4dd6-aedd-75fa9ef1bdca,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-d7cca161-d05c-4653-88ca-6ab6c2abdaec,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-8c923f89-860f-4beb-bca7-254ff8e87cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-3f64a9f0-0d0a-465d-a53a-8f8765f1e074,DISK], DatanodeInfoWithStorage[127.0.0.1:42887,DS-afbbba8d-bc51-4e6c-aa42-2acee41bbcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-45f9f133-1ca8-4160-90dc-5a9b75a877a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-b93bcd4b-6e0b-4b73-8838-0a45888bddf5,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-5b36ca65-0d2c-4e42-bf1c-364046e70825,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1543695067-172.17.0.4-1597441254379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34659,DS-94480ebe-9495-4dd6-aedd-75fa9ef1bdca,DISK], DatanodeInfoWithStorage[127.0.0.1:45509,DS-d7cca161-d05c-4653-88ca-6ab6c2abdaec,DISK], DatanodeInfoWithStorage[127.0.0.1:45852,DS-8c923f89-860f-4beb-bca7-254ff8e87cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:44370,DS-3f64a9f0-0d0a-465d-a53a-8f8765f1e074,DISK], DatanodeInfoWithStorage[127.0.0.1:42887,DS-afbbba8d-bc51-4e6c-aa42-2acee41bbcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-45f9f133-1ca8-4160-90dc-5a9b75a877a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-b93bcd4b-6e0b-4b73-8838-0a45888bddf5,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-5b36ca65-0d2c-4e42-bf1c-364046e70825,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1869458071-172.17.0.4-1597441339211:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33807,DS-1518f0f4-6fd7-4b3e-82d5-d98aef0f2ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-e1123dda-2735-4be8-97b7-c5370badb2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-439af284-a8e0-4017-93cd-725359f55b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-2f69b08a-3680-478d-86f6-10f7560894d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-5ccd87da-dca1-4ba8-95db-76ef9b12c24b,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-b44c1aa1-95ed-4bbc-8060-364ffb9df99d,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-65f9d2bd-381b-4f63-8cca-0da44324a56b,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-c71b2902-79b7-4c3e-acd9-36fdafc0637d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1869458071-172.17.0.4-1597441339211:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33807,DS-1518f0f4-6fd7-4b3e-82d5-d98aef0f2ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-e1123dda-2735-4be8-97b7-c5370badb2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-439af284-a8e0-4017-93cd-725359f55b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-2f69b08a-3680-478d-86f6-10f7560894d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-5ccd87da-dca1-4ba8-95db-76ef9b12c24b,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-b44c1aa1-95ed-4bbc-8060-364ffb9df99d,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-65f9d2bd-381b-4f63-8cca-0da44324a56b,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-c71b2902-79b7-4c3e-acd9-36fdafc0637d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1524772401-172.17.0.4-1597441489142:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35169,DS-587a2c0e-0ae9-4d3d-ab6a-16d475494bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-6a3a00d6-5020-4090-af28-e57a260d218f,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-3b43b78f-cc70-4b44-b1c4-a6f9f99c8808,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-8fc5ea89-406a-4f3f-b57e-b503bb8c2a60,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-bae3e828-8e2f-4c0c-b392-770e22eed9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-63ce4110-c708-42f5-abc0-c22eb1c2c57f,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-cb863c9a-1f8b-47a7-878f-fc49d8f1c1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-20436c40-db41-4d67-b6a1-630436bb9552,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1524772401-172.17.0.4-1597441489142:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35169,DS-587a2c0e-0ae9-4d3d-ab6a-16d475494bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38196,DS-6a3a00d6-5020-4090-af28-e57a260d218f,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-3b43b78f-cc70-4b44-b1c4-a6f9f99c8808,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-8fc5ea89-406a-4f3f-b57e-b503bb8c2a60,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-bae3e828-8e2f-4c0c-b392-770e22eed9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-63ce4110-c708-42f5-abc0-c22eb1c2c57f,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-cb863c9a-1f8b-47a7-878f-fc49d8f1c1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-20436c40-db41-4d67-b6a1-630436bb9552,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-816138478-172.17.0.4-1597441681527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41698,DS-8116664a-495e-4d80-844f-e2ef55260bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-2d20132d-ead7-440f-b661-e83bb2434ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-9e748ea1-0146-499a-b83c-c9892eef582f,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-fefb2a3f-b455-4830-bfa0-cfc78925003a,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-6010a024-1a95-4258-be40-54f3fdd14411,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-814f40f2-14b2-45bd-a658-90527743829c,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-f244b5bc-a8a6-4c87-bc23-660a04e70b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-2d53b799-a7b1-49d0-ad3c-e9bc05a975ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-816138478-172.17.0.4-1597441681527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41698,DS-8116664a-495e-4d80-844f-e2ef55260bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33500,DS-2d20132d-ead7-440f-b661-e83bb2434ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:35859,DS-9e748ea1-0146-499a-b83c-c9892eef582f,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-fefb2a3f-b455-4830-bfa0-cfc78925003a,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-6010a024-1a95-4258-be40-54f3fdd14411,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-814f40f2-14b2-45bd-a658-90527743829c,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-f244b5bc-a8a6-4c87-bc23-660a04e70b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-2d53b799-a7b1-49d0-ad3c-e9bc05a975ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-423745486-172.17.0.4-1597441767540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36235,DS-6d0ae169-6162-47dc-8b6a-f7d73925590a,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-019e76cb-d035-4a0d-994b-5eb7baec138e,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-ad7598b1-3254-43b1-ac59-e9e7f0938f34,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-f7391f9d-8407-4e7a-8663-1a06ff15cedb,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-b4e7eea5-ba1a-432f-b7d4-43ad7f27bba3,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-6e0bcf8b-3cd1-4dbd-9227-ea52a4e7c2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-2512932f-bddf-4ffc-9625-2ba0b2455aee,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-8b98daed-fcbd-413f-9900-5b8a937fc23e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-423745486-172.17.0.4-1597441767540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36235,DS-6d0ae169-6162-47dc-8b6a-f7d73925590a,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-019e76cb-d035-4a0d-994b-5eb7baec138e,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-ad7598b1-3254-43b1-ac59-e9e7f0938f34,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-f7391f9d-8407-4e7a-8663-1a06ff15cedb,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-b4e7eea5-ba1a-432f-b7d4-43ad7f27bba3,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-6e0bcf8b-3cd1-4dbd-9227-ea52a4e7c2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-2512932f-bddf-4ffc-9625-2ba0b2455aee,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-8b98daed-fcbd-413f-9900-5b8a937fc23e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-328661937-172.17.0.4-1597441852532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43314,DS-5802e3f3-cd85-4d21-9ba9-82c8f6dae4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-639d0b9e-e5b2-44bb-ba29-92ef91af30e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-52c911f1-6406-4ad8-8862-3df631610c38,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-d3c115f7-ae76-4576-915b-02aa37ba714f,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-f0b741c9-d867-444e-98ca-bcbf2ccd237d,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-2d4fdbd3-7e70-4536-a868-fad0b996a19d,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-d80a668e-5ecf-437c-8900-f9c3d3e8f6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-c6dbcf8a-1a79-493b-84e6-d4b9362a1385,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-328661937-172.17.0.4-1597441852532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43314,DS-5802e3f3-cd85-4d21-9ba9-82c8f6dae4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40012,DS-639d0b9e-e5b2-44bb-ba29-92ef91af30e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-52c911f1-6406-4ad8-8862-3df631610c38,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-d3c115f7-ae76-4576-915b-02aa37ba714f,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-f0b741c9-d867-444e-98ca-bcbf2ccd237d,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-2d4fdbd3-7e70-4536-a868-fad0b996a19d,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-d80a668e-5ecf-437c-8900-f9c3d3e8f6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39412,DS-c6dbcf8a-1a79-493b-84e6-d4b9362a1385,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-513463676-172.17.0.4-1597441873131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46280,DS-a026afb7-a600-4bf5-a096-ff11c659bedd,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-58557101-155d-4107-adf9-ac1633400208,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-4e73399d-e6f5-4b8f-adcd-097d3d24e12c,DISK], DatanodeInfoWithStorage[127.0.0.1:44858,DS-a0093bd5-5be2-4fb4-aa63-ab5705e60cad,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-a3286fb2-4980-46b1-bc10-a6917dae1080,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-89e5cefe-4012-45fc-8e3b-d0047d0d7aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-62d16d47-239e-49b6-8b40-e2c367da1e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-098a1ddd-50b8-430e-8184-34afb01f9a62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-513463676-172.17.0.4-1597441873131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46280,DS-a026afb7-a600-4bf5-a096-ff11c659bedd,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-58557101-155d-4107-adf9-ac1633400208,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-4e73399d-e6f5-4b8f-adcd-097d3d24e12c,DISK], DatanodeInfoWithStorage[127.0.0.1:44858,DS-a0093bd5-5be2-4fb4-aa63-ab5705e60cad,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-a3286fb2-4980-46b1-bc10-a6917dae1080,DISK], DatanodeInfoWithStorage[127.0.0.1:46351,DS-89e5cefe-4012-45fc-8e3b-d0047d0d7aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34436,DS-62d16d47-239e-49b6-8b40-e2c367da1e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-098a1ddd-50b8-430e-8184-34afb01f9a62,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131192103-172.17.0.4-1597442148957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44371,DS-96a89d3d-cd9b-4238-87df-f3dee2ec3ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-ad66d056-18a4-426d-9ecc-6c10d7df5928,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-bd421e29-fd94-4c8a-b105-f6532b9b0eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-2513e7eb-cec6-46a3-b1de-4bc134952653,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-2ae67545-e3ac-4eb4-99c1-a17083a2ca21,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-e7eef879-dde9-4cec-818f-95a8feabd980,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-acf8b055-efa6-470e-b326-9772193f64da,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-f5a1f9db-6945-49fe-ac42-dedc88bc0d89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1131192103-172.17.0.4-1597442148957:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44371,DS-96a89d3d-cd9b-4238-87df-f3dee2ec3ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-ad66d056-18a4-426d-9ecc-6c10d7df5928,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-bd421e29-fd94-4c8a-b105-f6532b9b0eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-2513e7eb-cec6-46a3-b1de-4bc134952653,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-2ae67545-e3ac-4eb4-99c1-a17083a2ca21,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-e7eef879-dde9-4cec-818f-95a8feabd980,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-acf8b055-efa6-470e-b326-9772193f64da,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-f5a1f9db-6945-49fe-ac42-dedc88bc0d89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-497260038-172.17.0.4-1597442234183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45593,DS-91bb27ed-2617-4363-8ae4-49aa7abeb171,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-d962d08e-5564-4c4a-aea0-4d0d6d4fa0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-c8c7d173-5c9b-4657-a3cd-a7ecab81817c,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-efe393c9-d5b0-4422-8e3d-8c55da4ebfe4,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-88029cb8-0603-4460-b61c-44538e7fa5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-5a802050-7cab-48ca-a110-162b6c93ca19,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-d59da80f-d4a4-4161-94b0-803e2e5d0c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-e1eb8d6a-9f26-4255-a49d-86dd7f5cfcdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-497260038-172.17.0.4-1597442234183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45593,DS-91bb27ed-2617-4363-8ae4-49aa7abeb171,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-d962d08e-5564-4c4a-aea0-4d0d6d4fa0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-c8c7d173-5c9b-4657-a3cd-a7ecab81817c,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-efe393c9-d5b0-4422-8e3d-8c55da4ebfe4,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-88029cb8-0603-4460-b61c-44538e7fa5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-5a802050-7cab-48ca-a110-162b6c93ca19,DISK], DatanodeInfoWithStorage[127.0.0.1:32855,DS-d59da80f-d4a4-4161-94b0-803e2e5d0c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-e1eb8d6a-9f26-4255-a49d-86dd7f5cfcdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-361936223-172.17.0.4-1597442634615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41672,DS-325176e3-d49c-4c2d-817b-070db848da4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-8f6ea988-0384-439a-bc7f-0a1b8e88700b,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-684f5828-ec45-481d-b6ea-a2393fd67ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-811f2e23-b20c-4a0d-a7c2-8b2829ffd343,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-fc872b41-4f99-4b6a-aede-5919d0b80fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-0bd2073b-a0b6-4989-94be-498de766c510,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-d6d78f03-65f0-4839-9896-afb23780d264,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-779eb482-d3f6-4e72-ae51-ae2da85f961f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-361936223-172.17.0.4-1597442634615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41672,DS-325176e3-d49c-4c2d-817b-070db848da4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37867,DS-8f6ea988-0384-439a-bc7f-0a1b8e88700b,DISK], DatanodeInfoWithStorage[127.0.0.1:33925,DS-684f5828-ec45-481d-b6ea-a2393fd67ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-811f2e23-b20c-4a0d-a7c2-8b2829ffd343,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-fc872b41-4f99-4b6a-aede-5919d0b80fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34983,DS-0bd2073b-a0b6-4989-94be-498de766c510,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-d6d78f03-65f0-4839-9896-afb23780d264,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-779eb482-d3f6-4e72-ae51-ae2da85f961f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1378179055-172.17.0.4-1597443143721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43694,DS-391edf32-74f8-473e-b33b-ddfb9181ee58,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-1ca6771c-458c-4e5e-bea3-7e863a88d410,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-9f5c5883-3182-49d3-bb82-77e415af9c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-130a9af3-1514-4af3-83d9-4c8faed21d54,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-b7fe674c-fcb8-47a6-8490-c0da0d53e954,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-33b27ed5-65da-4163-8538-3ffa064d2e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-144e97f7-b3bb-4f93-ada6-2ca822b38bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-1f285e49-e17b-41d2-9221-ddf95e17c28e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1378179055-172.17.0.4-1597443143721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43694,DS-391edf32-74f8-473e-b33b-ddfb9181ee58,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-1ca6771c-458c-4e5e-bea3-7e863a88d410,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-9f5c5883-3182-49d3-bb82-77e415af9c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-130a9af3-1514-4af3-83d9-4c8faed21d54,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-b7fe674c-fcb8-47a6-8490-c0da0d53e954,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-33b27ed5-65da-4163-8538-3ffa064d2e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:44928,DS-144e97f7-b3bb-4f93-ada6-2ca822b38bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-1f285e49-e17b-41d2-9221-ddf95e17c28e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1907665396-172.17.0.4-1597443164178:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36856,DS-f97cbc64-db56-457d-90bb-168ef171cc69,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-e3352a79-2039-4745-af55-6d6305125315,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-89a643da-c953-4a2e-a00d-a37f81350dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-c0dff818-4769-40ad-b9c8-1de75b033b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-ad86b7a6-f4c7-4094-a56f-1ac6466d329d,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-6e4d2f12-1e48-446e-8d9f-9bad494dc395,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-2dc01e47-13fe-41ca-b9df-50a109a76e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-63131b37-e767-4d42-a921-c97a9f4f8beb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1907665396-172.17.0.4-1597443164178:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36856,DS-f97cbc64-db56-457d-90bb-168ef171cc69,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-e3352a79-2039-4745-af55-6d6305125315,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-89a643da-c953-4a2e-a00d-a37f81350dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-c0dff818-4769-40ad-b9c8-1de75b033b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-ad86b7a6-f4c7-4094-a56f-1ac6466d329d,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-6e4d2f12-1e48-446e-8d9f-9bad494dc395,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-2dc01e47-13fe-41ca-b9df-50a109a76e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-63131b37-e767-4d42-a921-c97a9f4f8beb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.read.short.circuit.replica.stale.threshold.ms
component: hdfs:NameNode
v1: 18
v2: 1800000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-57005952-172.17.0.4-1597443184549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37741,DS-603211ce-bd8e-404e-9789-703a9fdaf683,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-1015cee7-f565-47b4-a5bd-3fc5013d1213,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-52829227-a0a6-4080-a4e4-721b8b856db7,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-b110e30c-41ca-4c59-91c7-695355ba3ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-45f973b6-c480-421a-8509-3993f732d551,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-90a65859-9ccf-4b76-b19c-5764c674e640,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-34155b46-455e-4fb3-9a6b-74c3aac2e3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-8494974c-5319-4854-915e-51e52d9b9568,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-57005952-172.17.0.4-1597443184549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37741,DS-603211ce-bd8e-404e-9789-703a9fdaf683,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-1015cee7-f565-47b4-a5bd-3fc5013d1213,DISK], DatanodeInfoWithStorage[127.0.0.1:40537,DS-52829227-a0a6-4080-a4e4-721b8b856db7,DISK], DatanodeInfoWithStorage[127.0.0.1:37305,DS-b110e30c-41ca-4c59-91c7-695355ba3ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-45f973b6-c480-421a-8509-3993f732d551,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-90a65859-9ccf-4b76-b19c-5764c674e640,DISK], DatanodeInfoWithStorage[127.0.0.1:39689,DS-34155b46-455e-4fb3-9a6b-74c3aac2e3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-8494974c-5319-4854-915e-51e52d9b9568,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 3492
