reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-492105218-172.17.0.11-1597484254576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44056,DS-c1e989cf-6cb0-49c5-a568-c2632cefcc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-76c6c168-d7c9-4cf5-86f7-c7b331d38658,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-35a79110-e5ff-427d-9e30-2357370ad721,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-c861ad0f-72a8-4194-9ece-00a5f6859da4,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-6698b29b-8b17-4c76-bae5-626de5aa5822,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-8c5727ca-760b-443c-b36b-42110678d19a,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-46161200-39ad-4ac8-a939-21265bcf071c,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-9db4dd16-04ba-498d-b48a-07d0eeee5208,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-492105218-172.17.0.11-1597484254576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44056,DS-c1e989cf-6cb0-49c5-a568-c2632cefcc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-76c6c168-d7c9-4cf5-86f7-c7b331d38658,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-35a79110-e5ff-427d-9e30-2357370ad721,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-c861ad0f-72a8-4194-9ece-00a5f6859da4,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-6698b29b-8b17-4c76-bae5-626de5aa5822,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-8c5727ca-760b-443c-b36b-42110678d19a,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-46161200-39ad-4ac8-a939-21265bcf071c,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-9db4dd16-04ba-498d-b48a-07d0eeee5208,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-424370048-172.17.0.11-1597484415064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40711,DS-73285b32-a895-4f39-ab3c-ff3bb9a82d31,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-4ad3cec8-b610-44e0-bab3-887ca6aa8d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-aaf99cb7-2a18-4d13-86d0-7e71f1b6e7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-b317335c-f5e6-4fc4-9a8d-7b8662b73a37,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-13e68fab-2a38-4c7d-b1ec-981669cbc62b,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-36a17459-ed1c-4059-9cf6-4c42b6025936,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-ee36702c-c664-44c4-89c5-f7370f3461a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-60ffe16f-b563-4bc1-9f8f-8f11f34d5236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-424370048-172.17.0.11-1597484415064:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40711,DS-73285b32-a895-4f39-ab3c-ff3bb9a82d31,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-4ad3cec8-b610-44e0-bab3-887ca6aa8d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-aaf99cb7-2a18-4d13-86d0-7e71f1b6e7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45411,DS-b317335c-f5e6-4fc4-9a8d-7b8662b73a37,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-13e68fab-2a38-4c7d-b1ec-981669cbc62b,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-36a17459-ed1c-4059-9cf6-4c42b6025936,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-ee36702c-c664-44c4-89c5-f7370f3461a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-60ffe16f-b563-4bc1-9f8f-8f11f34d5236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-887194042-172.17.0.11-1597484764347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33275,DS-14e37032-d63d-4f7c-9d87-c907e4834ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-96140701-62bd-4d46-b752-fd5c7cf09486,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-5be1664b-b905-4473-9585-281d4ac25d11,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-5f5fefeb-4c3f-4ef9-8c17-eeabbb8cb149,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-abfb11a5-3629-4772-8e61-7cc3569deb21,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-2818b570-109e-4030-8d73-9c67db3737d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45029,DS-762e1666-3b33-4063-b95e-1f20b1ca3260,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-3e04b95b-a9e7-4aae-ab53-5b18a0914669,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-887194042-172.17.0.11-1597484764347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33275,DS-14e37032-d63d-4f7c-9d87-c907e4834ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:40991,DS-96140701-62bd-4d46-b752-fd5c7cf09486,DISK], DatanodeInfoWithStorage[127.0.0.1:38864,DS-5be1664b-b905-4473-9585-281d4ac25d11,DISK], DatanodeInfoWithStorage[127.0.0.1:37151,DS-5f5fefeb-4c3f-4ef9-8c17-eeabbb8cb149,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-abfb11a5-3629-4772-8e61-7cc3569deb21,DISK], DatanodeInfoWithStorage[127.0.0.1:39929,DS-2818b570-109e-4030-8d73-9c67db3737d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45029,DS-762e1666-3b33-4063-b95e-1f20b1ca3260,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-3e04b95b-a9e7-4aae-ab53-5b18a0914669,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1882507464-172.17.0.11-1597485425176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42686,DS-811ec037-74cd-4759-83af-95aac5983307,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-44b9afaf-ccb6-4c29-bbdf-ab675715680f,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-3b8720ce-abf8-42f7-b1ad-5d34617cbdcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-768e8238-ec98-4371-8c2a-34ac315557fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-a132b21b-65be-4478-a872-019a37e89ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-ee62d687-d9c1-4da8-a31a-9f2f10510a44,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-e92453bd-2158-47ee-9a54-1c5eef338771,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-c361d28c-877a-41fd-a8a0-ab61865cdcb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1882507464-172.17.0.11-1597485425176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42686,DS-811ec037-74cd-4759-83af-95aac5983307,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-44b9afaf-ccb6-4c29-bbdf-ab675715680f,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-3b8720ce-abf8-42f7-b1ad-5d34617cbdcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-768e8238-ec98-4371-8c2a-34ac315557fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36702,DS-a132b21b-65be-4478-a872-019a37e89ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-ee62d687-d9c1-4da8-a31a-9f2f10510a44,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-e92453bd-2158-47ee-9a54-1c5eef338771,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-c361d28c-877a-41fd-a8a0-ab61865cdcb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-139594136-172.17.0.11-1597485534086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39693,DS-c4e1603a-a451-45e9-9dd9-68f44f9fcbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-b495555d-7117-4364-827e-28fd249d92e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33086,DS-92f78f8e-88ce-4fda-b9c0-9ce0bc01339f,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-1ed7edbc-0438-458c-9aa0-223a699bafd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-725cf2e1-6cc8-4a5f-a817-7f38c51232ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-fe29d2d2-1764-4275-b751-6af250ceb3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-314f5196-3e6a-4fcb-9bce-95f85c96cb93,DISK], DatanodeInfoWithStorage[127.0.0.1:45250,DS-cc791fca-4e15-453f-9106-0032a419791a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-139594136-172.17.0.11-1597485534086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39693,DS-c4e1603a-a451-45e9-9dd9-68f44f9fcbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-b495555d-7117-4364-827e-28fd249d92e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33086,DS-92f78f8e-88ce-4fda-b9c0-9ce0bc01339f,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-1ed7edbc-0438-458c-9aa0-223a699bafd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-725cf2e1-6cc8-4a5f-a817-7f38c51232ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-fe29d2d2-1764-4275-b751-6af250ceb3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-314f5196-3e6a-4fcb-9bce-95f85c96cb93,DISK], DatanodeInfoWithStorage[127.0.0.1:45250,DS-cc791fca-4e15-453f-9106-0032a419791a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1677381272-172.17.0.11-1597485980724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39640,DS-257f51f6-16bd-4c2a-bc4b-fe51aea944c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-56c75e4b-d3f2-41a5-a4de-394a60eb915d,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-bd29d4ce-4ad2-4118-af96-7ddf89e1322d,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-366cc00d-df19-4aa7-8e10-a88c85db27d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-9bcf2708-1769-4d2d-9e55-179bc7bb0a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-fbe0c48c-b517-4697-9732-88f607b7c16a,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-79ad2726-4f78-47ce-b3fe-60ea845d96db,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-9f21c124-f4a7-48e6-a7c3-a044e5806976,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1677381272-172.17.0.11-1597485980724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39640,DS-257f51f6-16bd-4c2a-bc4b-fe51aea944c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33522,DS-56c75e4b-d3f2-41a5-a4de-394a60eb915d,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-bd29d4ce-4ad2-4118-af96-7ddf89e1322d,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-366cc00d-df19-4aa7-8e10-a88c85db27d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43764,DS-9bcf2708-1769-4d2d-9e55-179bc7bb0a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-fbe0c48c-b517-4697-9732-88f607b7c16a,DISK], DatanodeInfoWithStorage[127.0.0.1:45755,DS-79ad2726-4f78-47ce-b3fe-60ea845d96db,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-9f21c124-f4a7-48e6-a7c3-a044e5806976,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1227221492-172.17.0.11-1597486344171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46522,DS-cefac744-97e0-4161-9746-c0f0ac24e23b,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-bd07f644-6414-4d4a-b83a-7e4ec98627de,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-06f2730c-0a70-4106-bdcf-fb4fd3a21ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-99673999-67c0-481a-b56e-2fe309c0ba02,DISK], DatanodeInfoWithStorage[127.0.0.1:37487,DS-57127912-2196-49fc-b2d8-389a48d22690,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-b923cd5c-43d7-4c62-aeeb-e8bed47832df,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-78931dd4-82c6-4fd8-aab9-65af886a7b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-9a49b85f-2312-4ce1-b285-8729c4d076ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1227221492-172.17.0.11-1597486344171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46522,DS-cefac744-97e0-4161-9746-c0f0ac24e23b,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-bd07f644-6414-4d4a-b83a-7e4ec98627de,DISK], DatanodeInfoWithStorage[127.0.0.1:39044,DS-06f2730c-0a70-4106-bdcf-fb4fd3a21ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-99673999-67c0-481a-b56e-2fe309c0ba02,DISK], DatanodeInfoWithStorage[127.0.0.1:37487,DS-57127912-2196-49fc-b2d8-389a48d22690,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-b923cd5c-43d7-4c62-aeeb-e8bed47832df,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-78931dd4-82c6-4fd8-aab9-65af886a7b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45702,DS-9a49b85f-2312-4ce1-b285-8729c4d076ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-630192804-172.17.0.11-1597486840967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39382,DS-2aa38843-1987-4c0d-aca1-0b16766fe6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-82f3a117-e2b7-4e05-8651-4338d7333b49,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-28299caa-f42c-4868-af01-33484a383904,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-4a85b891-8115-4e9b-9fc2-7f29ebcd3266,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-3978c12b-8eeb-41cd-80a6-d77b2ecf12a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-00f6ffc7-6a20-47f1-b1b3-d42fb695efb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-39535cd8-bbdd-4182-a457-7029ef6297ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-2b8d0230-2e0f-4cf5-9901-06bf56278342,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-630192804-172.17.0.11-1597486840967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39382,DS-2aa38843-1987-4c0d-aca1-0b16766fe6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-82f3a117-e2b7-4e05-8651-4338d7333b49,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-28299caa-f42c-4868-af01-33484a383904,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-4a85b891-8115-4e9b-9fc2-7f29ebcd3266,DISK], DatanodeInfoWithStorage[127.0.0.1:39199,DS-3978c12b-8eeb-41cd-80a6-d77b2ecf12a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-00f6ffc7-6a20-47f1-b1b3-d42fb695efb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-39535cd8-bbdd-4182-a457-7029ef6297ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40889,DS-2b8d0230-2e0f-4cf5-9901-06bf56278342,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-872615932-172.17.0.11-1597486880242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33904,DS-b4afa9fa-862e-41c9-b41c-c01328d1b5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-0f4929bc-5e5d-41e1-b0d3-6721d9077dad,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-1ee74f08-e8d2-4580-9285-d7077bdad58f,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-cbf91ff7-663e-4a71-bf5c-83e7dd533400,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-73771f24-86e8-48a4-83b9-d76ccec48c00,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-3e1b0536-d0af-4ef7-b9be-9ae5e162459f,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-da5750d4-c8de-4ac9-9618-d16118e20ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-60e07bbf-064b-48eb-9ea0-0e174bdb3b38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-872615932-172.17.0.11-1597486880242:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33904,DS-b4afa9fa-862e-41c9-b41c-c01328d1b5b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-0f4929bc-5e5d-41e1-b0d3-6721d9077dad,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-1ee74f08-e8d2-4580-9285-d7077bdad58f,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-cbf91ff7-663e-4a71-bf5c-83e7dd533400,DISK], DatanodeInfoWithStorage[127.0.0.1:43915,DS-73771f24-86e8-48a4-83b9-d76ccec48c00,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-3e1b0536-d0af-4ef7-b9be-9ae5e162459f,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-da5750d4-c8de-4ac9-9618-d16118e20ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-60e07bbf-064b-48eb-9ea0-0e174bdb3b38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1832339553-172.17.0.11-1597487036200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38035,DS-05878965-cf54-4151-a3d3-9abffc01221d,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-f7de33cb-c2a4-45c0-b975-132c898741ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-b9f27fb0-c19f-4efe-a0e9-1025a5b86dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-ec1d60f4-ef12-45cc-affa-54f1ce966683,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-f24b2a7c-7f47-4817-8725-5154164c3aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-68042daa-76c1-44d1-8403-f8677f7cb3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-191ab0f8-5fcf-45e1-aef7-9e938cd0148e,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-b9dfa9c2-877f-497b-a63f-5d70607b9c1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1832339553-172.17.0.11-1597487036200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38035,DS-05878965-cf54-4151-a3d3-9abffc01221d,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-f7de33cb-c2a4-45c0-b975-132c898741ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-b9f27fb0-c19f-4efe-a0e9-1025a5b86dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-ec1d60f4-ef12-45cc-affa-54f1ce966683,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-f24b2a7c-7f47-4817-8725-5154164c3aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-68042daa-76c1-44d1-8403-f8677f7cb3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42518,DS-191ab0f8-5fcf-45e1-aef7-9e938cd0148e,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-b9dfa9c2-877f-497b-a63f-5d70607b9c1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-855694424-172.17.0.11-1597487960067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45529,DS-a5eb764c-e788-4bb6-ad0b-ba89254590fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-43f24d5d-0cde-46d7-bc4d-a95391b24739,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-21f0cf35-2175-45f6-9180-c9f7b147dbed,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-6339d4cc-12e7-4a53-8624-3aafcbd09f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-409b5da0-caae-4564-9ca5-2507c7323ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-25f2a4c3-6f00-415c-bed3-a1f872ccab45,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-37298683-c6a1-47b8-a64e-5bc6cf5b9103,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-c2dfafde-0799-41cb-a8f9-01cef38920e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-855694424-172.17.0.11-1597487960067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45529,DS-a5eb764c-e788-4bb6-ad0b-ba89254590fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-43f24d5d-0cde-46d7-bc4d-a95391b24739,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-21f0cf35-2175-45f6-9180-c9f7b147dbed,DISK], DatanodeInfoWithStorage[127.0.0.1:41439,DS-6339d4cc-12e7-4a53-8624-3aafcbd09f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-409b5da0-caae-4564-9ca5-2507c7323ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-25f2a4c3-6f00-415c-bed3-a1f872ccab45,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-37298683-c6a1-47b8-a64e-5bc6cf5b9103,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-c2dfafde-0799-41cb-a8f9-01cef38920e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1936139732-172.17.0.11-1597488142427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44477,DS-6ad9b1f1-c419-4000-843f-dd7e5b373cda,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-9e4b6ae3-73d4-40e5-affc-fda629b68e11,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-aec2d6af-8f8a-460a-b5fd-003480c60939,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-2991a51f-714d-4b30-bebb-537fa2bca784,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-49cc63a1-517c-4ca3-9f8b-43a730baf73d,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-1945bbb6-38b1-4aac-800e-55444232fe09,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-6f12f69b-f281-4ff7-b02f-7dbe361860a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-e60919d9-f241-41c8-9afb-5a4b495ae75e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1936139732-172.17.0.11-1597488142427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44477,DS-6ad9b1f1-c419-4000-843f-dd7e5b373cda,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-9e4b6ae3-73d4-40e5-affc-fda629b68e11,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-aec2d6af-8f8a-460a-b5fd-003480c60939,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-2991a51f-714d-4b30-bebb-537fa2bca784,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-49cc63a1-517c-4ca3-9f8b-43a730baf73d,DISK], DatanodeInfoWithStorage[127.0.0.1:44485,DS-1945bbb6-38b1-4aac-800e-55444232fe09,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-6f12f69b-f281-4ff7-b02f-7dbe361860a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-e60919d9-f241-41c8-9afb-5a4b495ae75e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2045365499-172.17.0.11-1597488319843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38136,DS-43ae4461-491b-45ac-aab7-a5339549edc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-4d65459a-dccb-4ea4-a69b-47ff3667f104,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-0155af1b-1fa6-4d6b-97f9-5220488ee65a,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-908ec881-c636-4391-a878-46e2335f4177,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-05935b1a-ac74-46e1-b5b1-ea9a2c6b8954,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-22f47a17-1c5d-4034-850e-78cc64434a89,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-12fd4a4c-3e73-4ff8-8563-e0839908556b,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-c5184f58-ba49-4af9-86e0-e999dea12309,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2045365499-172.17.0.11-1597488319843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38136,DS-43ae4461-491b-45ac-aab7-a5339549edc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-4d65459a-dccb-4ea4-a69b-47ff3667f104,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-0155af1b-1fa6-4d6b-97f9-5220488ee65a,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-908ec881-c636-4391-a878-46e2335f4177,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-05935b1a-ac74-46e1-b5b1-ea9a2c6b8954,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-22f47a17-1c5d-4034-850e-78cc64434a89,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-12fd4a4c-3e73-4ff8-8563-e0839908556b,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-c5184f58-ba49-4af9-86e0-e999dea12309,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-383668198-172.17.0.11-1597488923888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40716,DS-9e50dad4-8a7c-40da-88d4-1aac8992ebe7,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-753b5cf9-de29-419f-9c16-a570ebb4b4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-6531d3de-85c7-4114-afde-be9c5ca19a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-bcec9de0-c60f-4fe5-8da6-e90766fc1851,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-87202ac4-205d-4d72-be82-d7013c7e36b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-0df9d84f-5957-4984-8a2e-4ab9858a2cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-d8ffce21-e134-400c-b673-f6b7f9007210,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-b8d45ae0-36c2-45dc-b370-be6dc7ec1408,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-383668198-172.17.0.11-1597488923888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40716,DS-9e50dad4-8a7c-40da-88d4-1aac8992ebe7,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-753b5cf9-de29-419f-9c16-a570ebb4b4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44409,DS-6531d3de-85c7-4114-afde-be9c5ca19a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-bcec9de0-c60f-4fe5-8da6-e90766fc1851,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-87202ac4-205d-4d72-be82-d7013c7e36b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-0df9d84f-5957-4984-8a2e-4ab9858a2cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-d8ffce21-e134-400c-b673-f6b7f9007210,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-b8d45ae0-36c2-45dc-b370-be6dc7ec1408,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-26496442-172.17.0.11-1597488954797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35474,DS-2e39af57-f09a-405f-a9e7-bc03f0d5b203,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-dbd0f114-b784-47c8-b801-b55d0bc678b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-d942f1ed-f33c-4972-b38c-7d2d3f9ffb81,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-8e13c2fe-421c-4bea-832f-2ee7eba2a6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-e7e08ca3-ac6b-4899-a53b-8bb4462ef5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-fe410772-7ff8-4e8f-ac61-0f6b3d562a85,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-d117c2ab-9bae-4b12-a78b-5b5e0eaafae0,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-af033c4c-2168-4e52-a50c-a1e2062c1122,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-26496442-172.17.0.11-1597488954797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35474,DS-2e39af57-f09a-405f-a9e7-bc03f0d5b203,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-dbd0f114-b784-47c8-b801-b55d0bc678b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44932,DS-d942f1ed-f33c-4972-b38c-7d2d3f9ffb81,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-8e13c2fe-421c-4bea-832f-2ee7eba2a6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39321,DS-e7e08ca3-ac6b-4899-a53b-8bb4462ef5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45146,DS-fe410772-7ff8-4e8f-ac61-0f6b3d562a85,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-d117c2ab-9bae-4b12-a78b-5b5e0eaafae0,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-af033c4c-2168-4e52-a50c-a1e2062c1122,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5810
