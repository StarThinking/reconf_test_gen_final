reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-813823200-172.17.0.7-1597387148779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32862,DS-71a8cef4-63ec-427f-b6b0-9a786a013606,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-1fce799a-9f2c-41fe-8b47-2c653fd26af4,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-a7d5f45a-bfc5-4c2a-ac9c-3368f8af3c11,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-f682f395-40d8-4e4f-a5fb-4c606c54f71b,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-1063320f-e3ec-4ee0-9ee5-2b36c60566b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-22fa2d4c-cf41-4111-8996-1c25da0dd067,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-a4cfd10f-54eb-4ae2-9096-12b298b7110d,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-f5d9f6e8-77fd-4e12-b6ce-cab387aca15f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-813823200-172.17.0.7-1597387148779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32862,DS-71a8cef4-63ec-427f-b6b0-9a786a013606,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-1fce799a-9f2c-41fe-8b47-2c653fd26af4,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-a7d5f45a-bfc5-4c2a-ac9c-3368f8af3c11,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-f682f395-40d8-4e4f-a5fb-4c606c54f71b,DISK], DatanodeInfoWithStorage[127.0.0.1:36247,DS-1063320f-e3ec-4ee0-9ee5-2b36c60566b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44031,DS-22fa2d4c-cf41-4111-8996-1c25da0dd067,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-a4cfd10f-54eb-4ae2-9096-12b298b7110d,DISK], DatanodeInfoWithStorage[127.0.0.1:45073,DS-f5d9f6e8-77fd-4e12-b6ce-cab387aca15f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1582995021-172.17.0.7-1597387317466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41806,DS-d3f0b693-e07e-4e37-86b0-04cf1ebfff49,DISK], DatanodeInfoWithStorage[127.0.0.1:40065,DS-b1affa66-c76f-4932-b325-d3d11224b191,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-8b91d8c6-a0ff-40d1-b892-82102699ee12,DISK], DatanodeInfoWithStorage[127.0.0.1:46835,DS-d6b90086-8003-4bb7-aa80-8afa48c4e466,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-aa36a455-0135-4d10-881d-2c81394fc907,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-9b550223-fa45-4ee8-855c-205ef5a707a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-25105ab1-31f8-4efa-925f-78d6a7389c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-bdd01f77-f2e8-450a-ad0a-9f2d9cc57a8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1582995021-172.17.0.7-1597387317466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41806,DS-d3f0b693-e07e-4e37-86b0-04cf1ebfff49,DISK], DatanodeInfoWithStorage[127.0.0.1:40065,DS-b1affa66-c76f-4932-b325-d3d11224b191,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-8b91d8c6-a0ff-40d1-b892-82102699ee12,DISK], DatanodeInfoWithStorage[127.0.0.1:46835,DS-d6b90086-8003-4bb7-aa80-8afa48c4e466,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-aa36a455-0135-4d10-881d-2c81394fc907,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-9b550223-fa45-4ee8-855c-205ef5a707a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-25105ab1-31f8-4efa-925f-78d6a7389c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-bdd01f77-f2e8-450a-ad0a-9f2d9cc57a8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1063140885-172.17.0.7-1597387354778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37710,DS-93d41619-2da4-4b8d-9fb7-f8c13bcaf6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-b149d591-0f4d-4824-8e0d-3be984b6f35b,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-db03b43a-b3e1-4417-bbf3-f797a7135068,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-ecb6ee01-37c2-48dc-bedd-c2429b22f4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-3c4b0220-7b5e-4602-8aba-c27d339d8398,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-a257fa83-e2d7-4e17-8301-2ea993329b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-ea4b0a8c-cf57-4afa-97fd-8753f283929a,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-d786a643-28ca-41b8-be4f-2f9bd2a273c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1063140885-172.17.0.7-1597387354778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37710,DS-93d41619-2da4-4b8d-9fb7-f8c13bcaf6fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-b149d591-0f4d-4824-8e0d-3be984b6f35b,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-db03b43a-b3e1-4417-bbf3-f797a7135068,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-ecb6ee01-37c2-48dc-bedd-c2429b22f4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-3c4b0220-7b5e-4602-8aba-c27d339d8398,DISK], DatanodeInfoWithStorage[127.0.0.1:34510,DS-a257fa83-e2d7-4e17-8301-2ea993329b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-ea4b0a8c-cf57-4afa-97fd-8753f283929a,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-d786a643-28ca-41b8-be4f-2f9bd2a273c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1836525724-172.17.0.7-1597387840041:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38263,DS-2c49f6c5-0c83-42a9-8198-c33ccd1c7f01,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-90118686-cc5a-48d6-b126-a2fd0ac4d7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-b1ed5fc2-e69b-44b5-8445-3a5790068acd,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-dde87d9f-30ff-489a-98f7-4aa402f29cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-fae2c862-2dd0-44e1-ab64-652220f74ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-6be68ea1-b1af-400c-b033-3861a0b3a95e,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-9e2a672e-d8af-457e-a55c-df7b762e6e76,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-6d408d97-1ae2-4cdd-b17f-e9f7d99fc1f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1836525724-172.17.0.7-1597387840041:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38263,DS-2c49f6c5-0c83-42a9-8198-c33ccd1c7f01,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-90118686-cc5a-48d6-b126-a2fd0ac4d7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-b1ed5fc2-e69b-44b5-8445-3a5790068acd,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-dde87d9f-30ff-489a-98f7-4aa402f29cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-fae2c862-2dd0-44e1-ab64-652220f74ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:34245,DS-6be68ea1-b1af-400c-b033-3861a0b3a95e,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-9e2a672e-d8af-457e-a55c-df7b762e6e76,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-6d408d97-1ae2-4cdd-b17f-e9f7d99fc1f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-412475853-172.17.0.7-1597388777884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40348,DS-b4ee5891-ca37-4749-9b3f-d349c80b2933,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-575c0523-ceb2-494a-9ebd-ffb05daae4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-1b0d7b3b-d6d7-4188-babd-f7e235ff5b90,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-474ff318-89d1-4377-9bbc-16ce7b5811ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-ff4d8f69-c3f1-4853-80bf-2a6863c5053e,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-02e048da-da3d-42ab-8512-71e10c88e297,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-19e42ca6-cc75-4897-8366-f6e5fc137993,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-740f1ec8-d2f9-43ff-9068-a6f95765ddcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-412475853-172.17.0.7-1597388777884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40348,DS-b4ee5891-ca37-4749-9b3f-d349c80b2933,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-575c0523-ceb2-494a-9ebd-ffb05daae4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-1b0d7b3b-d6d7-4188-babd-f7e235ff5b90,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-474ff318-89d1-4377-9bbc-16ce7b5811ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-ff4d8f69-c3f1-4853-80bf-2a6863c5053e,DISK], DatanodeInfoWithStorage[127.0.0.1:46547,DS-02e048da-da3d-42ab-8512-71e10c88e297,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-19e42ca6-cc75-4897-8366-f6e5fc137993,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-740f1ec8-d2f9-43ff-9068-a6f95765ddcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-489127637-172.17.0.7-1597389052093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32786,DS-2f103f0b-4119-4320-bc9a-264494f0d675,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-30493e5e-a858-4ce5-acd1-c870eff42e68,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-1f830d98-7040-4b64-af83-296ad1031c39,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-5b861e52-a82f-429a-aaf2-f242cb540a72,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-d6720ace-eb38-4970-80b2-31566f6d64d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-26460c03-ac39-4854-bd98-4dd7df0f8d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-bbf51004-5884-4a46-a8c3-fea12096f363,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-59cb3b7d-bcd6-42a6-a436-8fc38d2007bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-489127637-172.17.0.7-1597389052093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32786,DS-2f103f0b-4119-4320-bc9a-264494f0d675,DISK], DatanodeInfoWithStorage[127.0.0.1:43575,DS-30493e5e-a858-4ce5-acd1-c870eff42e68,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-1f830d98-7040-4b64-af83-296ad1031c39,DISK], DatanodeInfoWithStorage[127.0.0.1:35740,DS-5b861e52-a82f-429a-aaf2-f242cb540a72,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-d6720ace-eb38-4970-80b2-31566f6d64d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39478,DS-26460c03-ac39-4854-bd98-4dd7df0f8d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-bbf51004-5884-4a46-a8c3-fea12096f363,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-59cb3b7d-bcd6-42a6-a436-8fc38d2007bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1814482217-172.17.0.7-1597389254794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37827,DS-1cd008d9-9219-41af-9e3a-b5c0c0723208,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-5540ad1f-0c6b-4c32-915b-2c3bce389fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-1701f5a0-5cec-4519-ad67-7253f886c4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-8f33652f-8a85-423c-bd0e-1b714bd5758a,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-4e0a5f07-b777-4e7d-b269-340dbf16b6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-8e92b95d-dd33-42fe-b14c-667d525f09c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-8761fbca-3903-4f74-b124-6d94c5c7fa56,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-ae500b7e-6f10-41fc-9ae2-d043ee3cb107,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1814482217-172.17.0.7-1597389254794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37827,DS-1cd008d9-9219-41af-9e3a-b5c0c0723208,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-5540ad1f-0c6b-4c32-915b-2c3bce389fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-1701f5a0-5cec-4519-ad67-7253f886c4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-8f33652f-8a85-423c-bd0e-1b714bd5758a,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-4e0a5f07-b777-4e7d-b269-340dbf16b6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-8e92b95d-dd33-42fe-b14c-667d525f09c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-8761fbca-3903-4f74-b124-6d94c5c7fa56,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-ae500b7e-6f10-41fc-9ae2-d043ee3cb107,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680804294-172.17.0.7-1597389297229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33345,DS-6609b523-b3dd-41d9-bc27-259535759b55,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-d1d8b172-8a6d-4968-adaf-2e402dcc1a07,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-90b629cd-5b6a-47b5-b68a-03240675f743,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-33f02997-5e06-4842-9444-89c2888eec18,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-21022378-be27-4f1a-9a2d-cabf553a3d11,DISK], DatanodeInfoWithStorage[127.0.0.1:40638,DS-43baffa0-95d2-4e1d-8cd1-b739c32995d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-b907bfd2-97d3-425b-89c6-40d3027f67d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-d83a2b81-ea68-4ad6-9a65-808c16ecf51f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1680804294-172.17.0.7-1597389297229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33345,DS-6609b523-b3dd-41d9-bc27-259535759b55,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-d1d8b172-8a6d-4968-adaf-2e402dcc1a07,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-90b629cd-5b6a-47b5-b68a-03240675f743,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-33f02997-5e06-4842-9444-89c2888eec18,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-21022378-be27-4f1a-9a2d-cabf553a3d11,DISK], DatanodeInfoWithStorage[127.0.0.1:40638,DS-43baffa0-95d2-4e1d-8cd1-b739c32995d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-b907bfd2-97d3-425b-89c6-40d3027f67d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-d83a2b81-ea68-4ad6-9a65-808c16ecf51f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1316972875-172.17.0.7-1597389732501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44518,DS-ace04b47-e5cb-4c3d-b3ce-bf69b8831742,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-e52f3ac8-d5a9-4de0-9dc7-e085a37fed98,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-732feb99-99ee-4d9f-85ef-0083019482d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-210abb03-b887-4bf1-aebb-3c72a5b8ceab,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-ff04d68c-5b88-429a-9bfc-91c0c28fabf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-c9f6521c-671c-4606-9bcb-451b482f001b,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-8deab29b-0967-4f38-90d6-74846587743b,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-64bddc3d-56b1-4797-92b0-65b06110fe16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1316972875-172.17.0.7-1597389732501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44518,DS-ace04b47-e5cb-4c3d-b3ce-bf69b8831742,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-e52f3ac8-d5a9-4de0-9dc7-e085a37fed98,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-732feb99-99ee-4d9f-85ef-0083019482d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-210abb03-b887-4bf1-aebb-3c72a5b8ceab,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-ff04d68c-5b88-429a-9bfc-91c0c28fabf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-c9f6521c-671c-4606-9bcb-451b482f001b,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-8deab29b-0967-4f38-90d6-74846587743b,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-64bddc3d-56b1-4797-92b0-65b06110fe16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1835049330-172.17.0.7-1597390069348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40274,DS-cba8b4e6-cb65-4f07-b26d-0104bf8b4e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-59c19ea5-375f-4a35-bfc7-bf3d46cf25cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-b7b6d30e-a67d-4e26-a3e9-86ab85e7d623,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-5c1d5a54-e6be-43e0-9d7b-bdc6e43faa91,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-1de0a60b-78db-4e2b-a794-198f056f426a,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-5d26282c-3590-4783-ac57-f1e4d942f9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-17b82738-f121-4f5d-bdc0-d6dd72f2ee24,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-c86a8ae6-61b6-4dda-8b0b-9db3ae6021de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1835049330-172.17.0.7-1597390069348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40274,DS-cba8b4e6-cb65-4f07-b26d-0104bf8b4e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44766,DS-59c19ea5-375f-4a35-bfc7-bf3d46cf25cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-b7b6d30e-a67d-4e26-a3e9-86ab85e7d623,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-5c1d5a54-e6be-43e0-9d7b-bdc6e43faa91,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-1de0a60b-78db-4e2b-a794-198f056f426a,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-5d26282c-3590-4783-ac57-f1e4d942f9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-17b82738-f121-4f5d-bdc0-d6dd72f2ee24,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-c86a8ae6-61b6-4dda-8b0b-9db3ae6021de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-264499878-172.17.0.7-1597390531862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32841,DS-bfd8b486-73f4-413b-a5f2-35a6f6a911ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-d27b8d53-3538-4385-b378-3f85dd6b9107,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-935486db-e8e5-4af3-8f8a-e4b3114353be,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-63798d85-f046-47a0-9fe7-366a2e5d5b08,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-d6848825-89ee-4723-84cb-f0231458c8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-97b984d9-bc5b-482c-955c-ddda7cbdfb58,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-53ad813f-3cf8-4d05-b1b3-9acee626681d,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-61d707c9-4a98-408a-9b92-418bfd816f80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-264499878-172.17.0.7-1597390531862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32841,DS-bfd8b486-73f4-413b-a5f2-35a6f6a911ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33744,DS-d27b8d53-3538-4385-b378-3f85dd6b9107,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-935486db-e8e5-4af3-8f8a-e4b3114353be,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-63798d85-f046-47a0-9fe7-366a2e5d5b08,DISK], DatanodeInfoWithStorage[127.0.0.1:41435,DS-d6848825-89ee-4723-84cb-f0231458c8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-97b984d9-bc5b-482c-955c-ddda7cbdfb58,DISK], DatanodeInfoWithStorage[127.0.0.1:45494,DS-53ad813f-3cf8-4d05-b1b3-9acee626681d,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-61d707c9-4a98-408a-9b92-418bfd816f80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1976812528-172.17.0.7-1597390569262:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35469,DS-de0af1ad-72d8-43d6-bf4c-7f6f7e6cd889,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-16058b3a-c190-4530-85bb-f0d4d6b5214f,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-25cab599-b7ec-47d0-ac38-71d983f4e82d,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-235bb73b-096d-43f8-981b-b5abf47e898e,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-f4ac4f84-8018-44f4-88f8-9c0c0fbee661,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-9dd6d81f-753a-4dc0-abde-75703821482d,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-306cbccd-17c2-4358-9d6c-b729f4d25c36,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-5f257cb6-88cd-4e71-be60-7f502c464dbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1976812528-172.17.0.7-1597390569262:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35469,DS-de0af1ad-72d8-43d6-bf4c-7f6f7e6cd889,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-16058b3a-c190-4530-85bb-f0d4d6b5214f,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-25cab599-b7ec-47d0-ac38-71d983f4e82d,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-235bb73b-096d-43f8-981b-b5abf47e898e,DISK], DatanodeInfoWithStorage[127.0.0.1:41121,DS-f4ac4f84-8018-44f4-88f8-9c0c0fbee661,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-9dd6d81f-753a-4dc0-abde-75703821482d,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-306cbccd-17c2-4358-9d6c-b729f4d25c36,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-5f257cb6-88cd-4e71-be60-7f502c464dbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1985175836-172.17.0.7-1597390730354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41654,DS-5214c61d-dfae-474f-a12b-299d8e941007,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-510cf348-5935-4f30-9563-e3582835c975,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-ec92be21-5ec7-4705-bcc4-4522c4f16ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-601facb4-03d8-4753-b544-72a09451222b,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-9eceda99-2d33-4fec-8dd8-4d7383acd96a,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-568c8683-86b5-4e00-95c4-79d0ab955e13,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-eaa86158-ef45-4720-99be-073b61e48345,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-ba8eff92-23ae-47f9-9a88-7e2bcbef075b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1985175836-172.17.0.7-1597390730354:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41654,DS-5214c61d-dfae-474f-a12b-299d8e941007,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-510cf348-5935-4f30-9563-e3582835c975,DISK], DatanodeInfoWithStorage[127.0.0.1:34885,DS-ec92be21-5ec7-4705-bcc4-4522c4f16ca2,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-601facb4-03d8-4753-b544-72a09451222b,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-9eceda99-2d33-4fec-8dd8-4d7383acd96a,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-568c8683-86b5-4e00-95c4-79d0ab955e13,DISK], DatanodeInfoWithStorage[127.0.0.1:43780,DS-eaa86158-ef45-4720-99be-073b61e48345,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-ba8eff92-23ae-47f9-9a88-7e2bcbef075b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2106753838-172.17.0.7-1597391052934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46199,DS-d0bd35cd-bec0-424d-a0ef-d4f856e9cee4,DISK], DatanodeInfoWithStorage[127.0.0.1:37011,DS-0c1e1c55-e0a9-4d61-a683-41e5744c2e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-64a3adc2-9407-464f-9bc3-cbced5595e96,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-dff726ae-0af2-42df-bd8f-d77022de6d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44153,DS-ed0a8d3e-31a4-41eb-9c97-4a18bccda609,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-261c66df-3674-482e-933b-14ef879521eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-e7906193-3a17-431c-b558-bd4fdbae4296,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-f13425b8-b95c-41a8-9432-2c9166c0069f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2106753838-172.17.0.7-1597391052934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46199,DS-d0bd35cd-bec0-424d-a0ef-d4f856e9cee4,DISK], DatanodeInfoWithStorage[127.0.0.1:37011,DS-0c1e1c55-e0a9-4d61-a683-41e5744c2e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-64a3adc2-9407-464f-9bc3-cbced5595e96,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-dff726ae-0af2-42df-bd8f-d77022de6d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44153,DS-ed0a8d3e-31a4-41eb-9c97-4a18bccda609,DISK], DatanodeInfoWithStorage[127.0.0.1:34618,DS-261c66df-3674-482e-933b-14ef879521eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-e7906193-3a17-431c-b558-bd4fdbae4296,DISK], DatanodeInfoWithStorage[127.0.0.1:39359,DS-f13425b8-b95c-41a8-9432-2c9166c0069f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-743095348-172.17.0.7-1597391436729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38906,DS-dd413d72-093b-49b4-8e8c-b07ec1770467,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-e0f4d987-6a4b-4e0e-86d2-92ec67afec43,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-1271547f-1f24-4c0f-a553-eb608d8c8f19,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-4cc5c0bc-b8a1-41cb-bb8d-e9c357bc4a16,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-0782fba0-2c38-4954-b94a-e7486363789d,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-97e32c9a-3c3e-4fa3-80c8-bfcfa75a8b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-04ba7f87-1a37-4f3c-8279-bcfaf5e6a6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-15db048a-1805-4d32-ac92-9e9ef047c5b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-743095348-172.17.0.7-1597391436729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38906,DS-dd413d72-093b-49b4-8e8c-b07ec1770467,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-e0f4d987-6a4b-4e0e-86d2-92ec67afec43,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-1271547f-1f24-4c0f-a553-eb608d8c8f19,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-4cc5c0bc-b8a1-41cb-bb8d-e9c357bc4a16,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-0782fba0-2c38-4954-b94a-e7486363789d,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-97e32c9a-3c3e-4fa3-80c8-bfcfa75a8b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44186,DS-04ba7f87-1a37-4f3c-8279-bcfaf5e6a6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-15db048a-1805-4d32-ac92-9e9ef047c5b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-326351507-172.17.0.7-1597392783284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40920,DS-6a5d36ea-e994-47f5-b539-efe485a2b812,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-57baa975-ac32-44b7-a158-da71b5b5ac23,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-25f5c68e-7fd7-4485-b529-e9a23180501a,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-f3573716-f50a-4e76-9f78-83dbad33c228,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-cb0e9e8b-50cf-4308-9d0e-889781f4f521,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-ae2598ce-d557-4606-9a98-140def931a35,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-02a8e948-5fb3-4e65-92ae-0e1e2b506293,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-4d3fd8da-01e6-4467-b71b-5f407585902e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-326351507-172.17.0.7-1597392783284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40920,DS-6a5d36ea-e994-47f5-b539-efe485a2b812,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-57baa975-ac32-44b7-a158-da71b5b5ac23,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-25f5c68e-7fd7-4485-b529-e9a23180501a,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-f3573716-f50a-4e76-9f78-83dbad33c228,DISK], DatanodeInfoWithStorage[127.0.0.1:34053,DS-cb0e9e8b-50cf-4308-9d0e-889781f4f521,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-ae2598ce-d557-4606-9a98-140def931a35,DISK], DatanodeInfoWithStorage[127.0.0.1:35987,DS-02a8e948-5fb3-4e65-92ae-0e1e2b506293,DISK], DatanodeInfoWithStorage[127.0.0.1:40764,DS-4d3fd8da-01e6-4467-b71b-5f407585902e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1212431145-172.17.0.7-1597392956124:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40008,DS-f04bc97d-1f82-4399-989e-0f16018ab6d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-610fbbe7-ba81-4719-bd28-4834ab71bb81,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-65265b21-89e0-4c7e-a6c1-ad7b9b937be1,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-92feb483-2250-4312-8cd6-ac45b9432e52,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-1fd736f2-66b7-418e-a442-c12f7f4545f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-72f5dd84-135d-44e2-ab06-138f4b20e62c,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-9c909bc2-9bc6-4b39-a9e6-330b87cf6a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-31c7a844-6ecb-423f-b4a0-a9ab830a7a8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1212431145-172.17.0.7-1597392956124:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40008,DS-f04bc97d-1f82-4399-989e-0f16018ab6d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44572,DS-610fbbe7-ba81-4719-bd28-4834ab71bb81,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-65265b21-89e0-4c7e-a6c1-ad7b9b937be1,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-92feb483-2250-4312-8cd6-ac45b9432e52,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-1fd736f2-66b7-418e-a442-c12f7f4545f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-72f5dd84-135d-44e2-ab06-138f4b20e62c,DISK], DatanodeInfoWithStorage[127.0.0.1:40101,DS-9c909bc2-9bc6-4b39-a9e6-330b87cf6a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-31c7a844-6ecb-423f-b4a0-a9ab830a7a8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6146
