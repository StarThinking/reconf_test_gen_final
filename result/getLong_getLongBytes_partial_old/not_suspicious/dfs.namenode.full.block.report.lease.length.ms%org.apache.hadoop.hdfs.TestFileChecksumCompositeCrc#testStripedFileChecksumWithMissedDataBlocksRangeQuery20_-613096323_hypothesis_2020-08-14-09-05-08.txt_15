reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1970954057-172.17.0.10-1597396059671:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36033,DS-513a265f-5e8b-49cb-8a3b-09bf8501ab59,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-28075995-feb7-4caa-8d37-8dfb699a6094,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-49732817-8e22-4457-93c4-45deb19244a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-194f2326-5916-40b0-8158-45e9ea012202,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-6b98b4e2-977f-41e5-9637-f34f32ee09b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-ec44d0de-0e46-4865-8b89-2787bc2d02dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-88a3d4a2-3128-4feb-bc98-c563b132db39,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-09f65c25-1d65-4a0b-9b40-b2c6d6672d30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1970954057-172.17.0.10-1597396059671:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36033,DS-513a265f-5e8b-49cb-8a3b-09bf8501ab59,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-28075995-feb7-4caa-8d37-8dfb699a6094,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-49732817-8e22-4457-93c4-45deb19244a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36894,DS-194f2326-5916-40b0-8158-45e9ea012202,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-6b98b4e2-977f-41e5-9637-f34f32ee09b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-ec44d0de-0e46-4865-8b89-2787bc2d02dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-88a3d4a2-3128-4feb-bc98-c563b132db39,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-09f65c25-1d65-4a0b-9b40-b2c6d6672d30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-972639682-172.17.0.10-1597396939316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46847,DS-c858f557-9cb0-481f-821a-b9a87ddaada9,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-245370cc-2d57-4ef6-a5f2-fe71abe624d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-e69249e5-e2de-425a-8c26-f8583d0d19bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-dde39c12-e9d8-4b9c-8e1a-dd5610635527,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-34ee08ec-1880-4391-b45b-2d246f2c56cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-c4958a29-2ef0-4838-a0c7-aad2581a8d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-0d09f405-ad12-4919-9318-63a5d8caa805,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-c91f6309-6e52-40fb-9b40-63d7f5fecede,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-972639682-172.17.0.10-1597396939316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46847,DS-c858f557-9cb0-481f-821a-b9a87ddaada9,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-245370cc-2d57-4ef6-a5f2-fe71abe624d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-e69249e5-e2de-425a-8c26-f8583d0d19bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43743,DS-dde39c12-e9d8-4b9c-8e1a-dd5610635527,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-34ee08ec-1880-4391-b45b-2d246f2c56cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-c4958a29-2ef0-4838-a0c7-aad2581a8d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-0d09f405-ad12-4919-9318-63a5d8caa805,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-c91f6309-6e52-40fb-9b40-63d7f5fecede,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1233989783-172.17.0.10-1597397787520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38016,DS-32ec7ac5-bfa8-48e7-9057-991f7d98bdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-91ceb4fc-1286-475d-9941-bcf4ab9a87b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-06239d71-2f8f-4e45-b429-10f1267e34cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-87991981-3043-4534-a56f-55f73e2ead15,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-00a0e956-a2d3-4e04-9e3f-cac3de78ae71,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-a9b7a16b-f217-4305-8ac1-5aa416e4b64f,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-44953379-7fdf-430f-be76-9c4ee0fc7c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-6fd8020e-4e84-4fbf-a745-91f9ef499419,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1233989783-172.17.0.10-1597397787520:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38016,DS-32ec7ac5-bfa8-48e7-9057-991f7d98bdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-91ceb4fc-1286-475d-9941-bcf4ab9a87b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-06239d71-2f8f-4e45-b429-10f1267e34cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-87991981-3043-4534-a56f-55f73e2ead15,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-00a0e956-a2d3-4e04-9e3f-cac3de78ae71,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-a9b7a16b-f217-4305-8ac1-5aa416e4b64f,DISK], DatanodeInfoWithStorage[127.0.0.1:39358,DS-44953379-7fdf-430f-be76-9c4ee0fc7c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-6fd8020e-4e84-4fbf-a745-91f9ef499419,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1952977858-172.17.0.10-1597397931081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38986,DS-283a644b-ef88-4c02-8fd0-22e7d41b7013,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-5b647c04-b641-4da5-b548-aac5890f4c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-5132c594-1871-4a60-81a1-7d6af99e507d,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-4ab4c2ef-465c-406d-a600-51947a174d72,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-12c09d69-f883-4425-b779-0352f0371e00,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-463dfa7e-fd7a-4eff-aa8f-cf50dd71dcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-74c6aa44-36e7-474d-ba3a-4288f92c215d,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-2aa354dd-6ef7-4b50-ab85-b384830ca47e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1952977858-172.17.0.10-1597397931081:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38986,DS-283a644b-ef88-4c02-8fd0-22e7d41b7013,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-5b647c04-b641-4da5-b548-aac5890f4c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-5132c594-1871-4a60-81a1-7d6af99e507d,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-4ab4c2ef-465c-406d-a600-51947a174d72,DISK], DatanodeInfoWithStorage[127.0.0.1:41568,DS-12c09d69-f883-4425-b779-0352f0371e00,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-463dfa7e-fd7a-4eff-aa8f-cf50dd71dcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-74c6aa44-36e7-474d-ba3a-4288f92c215d,DISK], DatanodeInfoWithStorage[127.0.0.1:44655,DS-2aa354dd-6ef7-4b50-ab85-b384830ca47e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2109763578-172.17.0.10-1597398042300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46478,DS-2e219aa0-d357-4bb6-a7d2-646232bd02c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-94e8a3dd-7a6b-40a4-bd41-55f38c9bf9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-792bdb0b-9918-42e0-a30e-97b2a6ea9a17,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-12df7db0-20e4-4ec4-b19a-da588ba626aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-e316ba2c-533a-47bb-b725-269e1d315c41,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-aed3c313-b276-4811-b133-fd294e217678,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-47b7d247-7678-457e-8ae1-eb4e757ccdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-db900a45-caac-4368-9304-476f0a9cd7e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2109763578-172.17.0.10-1597398042300:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46478,DS-2e219aa0-d357-4bb6-a7d2-646232bd02c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-94e8a3dd-7a6b-40a4-bd41-55f38c9bf9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-792bdb0b-9918-42e0-a30e-97b2a6ea9a17,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-12df7db0-20e4-4ec4-b19a-da588ba626aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-e316ba2c-533a-47bb-b725-269e1d315c41,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-aed3c313-b276-4811-b133-fd294e217678,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-47b7d247-7678-457e-8ae1-eb4e757ccdcc,DISK], DatanodeInfoWithStorage[127.0.0.1:34104,DS-db900a45-caac-4368-9304-476f0a9cd7e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-409348389-172.17.0.10-1597398359218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41150,DS-cb55fb71-ea21-4128-9685-98614bd23b92,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-b17dfc4a-e1e8-417d-af7a-bca615a756d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-c2739e40-8b6a-4531-ba18-0c0e56212b94,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-c29f1280-c6cd-471f-afde-4557604fb095,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-eabe6c8b-94be-4b4d-ad8f-2b80167dde4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-ee99b773-9a91-4863-9613-71ddc6704024,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-c051b159-589a-4dc1-a601-fd8d8f3d976b,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-c2e4720b-ad9e-4c66-9ecc-96e4eb8cc324,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-409348389-172.17.0.10-1597398359218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41150,DS-cb55fb71-ea21-4128-9685-98614bd23b92,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-b17dfc4a-e1e8-417d-af7a-bca615a756d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-c2739e40-8b6a-4531-ba18-0c0e56212b94,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-c29f1280-c6cd-471f-afde-4557604fb095,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-eabe6c8b-94be-4b4d-ad8f-2b80167dde4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-ee99b773-9a91-4863-9613-71ddc6704024,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-c051b159-589a-4dc1-a601-fd8d8f3d976b,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-c2e4720b-ad9e-4c66-9ecc-96e4eb8cc324,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1025993863-172.17.0.10-1597399194117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41584,DS-10f11793-341a-4fe2-98b1-2d0f142915d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-03664267-0b14-4a68-bddf-c491e72ea4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-9096154e-2af5-4acf-b87b-49caf6bc6e83,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-501a9031-4cf8-44ca-bfad-78742b95ee34,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-db190a2b-1793-4fcb-8e6f-e8a9eafb5b08,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-53734132-40d8-408d-a13a-eea4a6ef56d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-20bd9198-2c79-4a09-a0e7-0a29248a8dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33783,DS-c067920d-c79f-4f75-873c-8b1543d4feb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1025993863-172.17.0.10-1597399194117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41584,DS-10f11793-341a-4fe2-98b1-2d0f142915d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-03664267-0b14-4a68-bddf-c491e72ea4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-9096154e-2af5-4acf-b87b-49caf6bc6e83,DISK], DatanodeInfoWithStorage[127.0.0.1:40381,DS-501a9031-4cf8-44ca-bfad-78742b95ee34,DISK], DatanodeInfoWithStorage[127.0.0.1:38790,DS-db190a2b-1793-4fcb-8e6f-e8a9eafb5b08,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-53734132-40d8-408d-a13a-eea4a6ef56d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-20bd9198-2c79-4a09-a0e7-0a29248a8dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33783,DS-c067920d-c79f-4f75-873c-8b1543d4feb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-665185576-172.17.0.10-1597399661574:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38684,DS-43aedda6-3140-49ab-956d-8d608769fa92,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-84086426-babc-403d-830b-ef0bf65bc552,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-6ea77ea2-d0b1-4659-a1f0-97f33a8ab500,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-bdc02416-c67d-4d14-93b6-83478bc5cb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-63c89a74-2694-4176-99c4-50f30b0a58a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-57d1f6f1-82af-452a-b237-0d6ecc6c992b,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-770e2fa6-e941-4f7c-b2f1-cfd995d57fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-b3b048fa-6ce8-497c-8cfa-3fc5d6fc89eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-665185576-172.17.0.10-1597399661574:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38684,DS-43aedda6-3140-49ab-956d-8d608769fa92,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-84086426-babc-403d-830b-ef0bf65bc552,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-6ea77ea2-d0b1-4659-a1f0-97f33a8ab500,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-bdc02416-c67d-4d14-93b6-83478bc5cb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-63c89a74-2694-4176-99c4-50f30b0a58a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-57d1f6f1-82af-452a-b237-0d6ecc6c992b,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-770e2fa6-e941-4f7c-b2f1-cfd995d57fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-b3b048fa-6ce8-497c-8cfa-3fc5d6fc89eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-409726835-172.17.0.10-1597399696537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43063,DS-9d86de31-82a0-474d-9731-4a4d8f876fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-66a8c616-0603-4ad6-8fef-53d8d8d8c44d,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-ec8bdf63-18c8-45d5-9c70-49173111cb6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-cca2df25-6f60-41b3-8a69-d5b9c10387c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-fd98af2b-b0c5-4ed9-abcf-c490a0d500aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-5fa54e0b-c9a9-4e20-82dd-b22fcfb5a0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-6f778159-73dc-4dc9-a2dc-2b8c98592ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-66546551-55c5-4e59-8359-a3179ec9de23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-409726835-172.17.0.10-1597399696537:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43063,DS-9d86de31-82a0-474d-9731-4a4d8f876fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-66a8c616-0603-4ad6-8fef-53d8d8d8c44d,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-ec8bdf63-18c8-45d5-9c70-49173111cb6b,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-cca2df25-6f60-41b3-8a69-d5b9c10387c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-fd98af2b-b0c5-4ed9-abcf-c490a0d500aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-5fa54e0b-c9a9-4e20-82dd-b22fcfb5a0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37645,DS-6f778159-73dc-4dc9-a2dc-2b8c98592ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-66546551-55c5-4e59-8359-a3179ec9de23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1280432687-172.17.0.10-1597400269873:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44432,DS-7984642f-b5ec-476b-b2ee-3c05e5d785ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-3bc1454f-df44-4635-99a0-eae5e397d27f,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-d382e284-7dea-494d-94ee-7ce0dff5fc84,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-dcdf62fc-5167-46af-8534-338929550893,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-29015da1-91bf-4bd7-97ff-36a27fd89700,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-ba391cf8-3767-468c-9f28-4f047d93d715,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-f2394122-d997-435d-9bc6-c3bebe120d62,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-466beb6b-6d69-4661-9b28-19e9dfd8270e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1280432687-172.17.0.10-1597400269873:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44432,DS-7984642f-b5ec-476b-b2ee-3c05e5d785ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-3bc1454f-df44-4635-99a0-eae5e397d27f,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-d382e284-7dea-494d-94ee-7ce0dff5fc84,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-dcdf62fc-5167-46af-8534-338929550893,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-29015da1-91bf-4bd7-97ff-36a27fd89700,DISK], DatanodeInfoWithStorage[127.0.0.1:38908,DS-ba391cf8-3767-468c-9f28-4f047d93d715,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-f2394122-d997-435d-9bc6-c3bebe120d62,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-466beb6b-6d69-4661-9b28-19e9dfd8270e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.full.block.report.lease.length.ms
component: hdfs:NameNode
v1: 300000
v2: 3000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1036320286-172.17.0.10-1597401136375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36496,DS-d2bf0af6-0878-4cd3-8695-41761ea2296d,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-d01ba527-2560-443f-808c-706f92f4ad97,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-4a9af582-8903-466b-9372-c918f0fce66e,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-359938d2-4a39-443d-8c9b-c09c4beb6364,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-0ded97a2-9a97-4c38-acc2-0c7d2165179c,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-afb28e6b-ef56-4b35-a8cb-3e33844a2f50,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-5df9fd65-682f-4660-ad76-eef24636c5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-63916afb-dba1-4509-8ee3-196b04227ba7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1036320286-172.17.0.10-1597401136375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36496,DS-d2bf0af6-0878-4cd3-8695-41761ea2296d,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-d01ba527-2560-443f-808c-706f92f4ad97,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-4a9af582-8903-466b-9372-c918f0fce66e,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-359938d2-4a39-443d-8c9b-c09c4beb6364,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-0ded97a2-9a97-4c38-acc2-0c7d2165179c,DISK], DatanodeInfoWithStorage[127.0.0.1:35302,DS-afb28e6b-ef56-4b35-a8cb-3e33844a2f50,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-5df9fd65-682f-4660-ad76-eef24636c5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-63916afb-dba1-4509-8ee3-196b04227ba7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5386
