reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2002773270-172.17.0.3-1597312204937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35407,DS-34ca643d-a6bf-45bf-9523-58fd407350fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-6408c287-23ab-4a90-ad05-45ad62eb29d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36296,DS-752b4d96-377c-4b20-8cf1-2f8fd9f3d6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-411e2203-6cb3-45be-a3be-8e5e15c084b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42154,DS-08fe5933-c566-4202-a142-b4303df3cddd,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-cc73eec8-b14d-4ddf-9d95-3864547cb06a,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-3914a81f-6098-4cb2-9e23-d2287cef7232,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-f069398b-6fb4-4377-a330-aab286630200,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2002773270-172.17.0.3-1597312204937:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35407,DS-34ca643d-a6bf-45bf-9523-58fd407350fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-6408c287-23ab-4a90-ad05-45ad62eb29d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36296,DS-752b4d96-377c-4b20-8cf1-2f8fd9f3d6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-411e2203-6cb3-45be-a3be-8e5e15c084b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42154,DS-08fe5933-c566-4202-a142-b4303df3cddd,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-cc73eec8-b14d-4ddf-9d95-3864547cb06a,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-3914a81f-6098-4cb2-9e23-d2287cef7232,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-f069398b-6fb4-4377-a330-aab286630200,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1196899853-172.17.0.3-1597312286079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45996,DS-02b0243c-08d8-46bf-a094-d2a3ef6d07a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-f802085c-aaf8-4c09-8744-985ae1afee54,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-65e8da43-048e-445c-9236-4dc50d83ba6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-55465a21-a1f6-46ad-a4d9-96be3d55e402,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-fc6a9eae-a20c-43bb-a757-d5d9538d129c,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-6b68bad1-ce90-4022-880f-00ed613dd489,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-68b4a693-a63f-46c9-87ee-94a157f6d9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41019,DS-deb8ac41-9ce5-4648-a3d6-a95027bba2a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1196899853-172.17.0.3-1597312286079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45996,DS-02b0243c-08d8-46bf-a094-d2a3ef6d07a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39034,DS-f802085c-aaf8-4c09-8744-985ae1afee54,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-65e8da43-048e-445c-9236-4dc50d83ba6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-55465a21-a1f6-46ad-a4d9-96be3d55e402,DISK], DatanodeInfoWithStorage[127.0.0.1:39948,DS-fc6a9eae-a20c-43bb-a757-d5d9538d129c,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-6b68bad1-ce90-4022-880f-00ed613dd489,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-68b4a693-a63f-46c9-87ee-94a157f6d9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41019,DS-deb8ac41-9ce5-4648-a3d6-a95027bba2a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092907783-172.17.0.3-1597312329583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44667,DS-8140abed-88c4-4563-8bc0-76ecd4d1b970,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-02cc3ea2-9c88-4c2d-bea9-5eaf1c359ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-5391516f-2956-48d0-8e10-98323cd46c29,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-abe6e8f1-ba27-4380-b82b-048b0c6842f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-a846536f-f975-4582-95c7-fb6bcf6a77e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-69f869a5-de26-4142-a048-a1ebf69802e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-63c842a9-e704-4af9-8ca1-a6a6d77e94d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-3d28e23c-081a-46a9-b216-b28aa32106da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1092907783-172.17.0.3-1597312329583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44667,DS-8140abed-88c4-4563-8bc0-76ecd4d1b970,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-02cc3ea2-9c88-4c2d-bea9-5eaf1c359ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-5391516f-2956-48d0-8e10-98323cd46c29,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-abe6e8f1-ba27-4380-b82b-048b0c6842f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-a846536f-f975-4582-95c7-fb6bcf6a77e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45127,DS-69f869a5-de26-4142-a048-a1ebf69802e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-63c842a9-e704-4af9-8ca1-a6a6d77e94d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-3d28e23c-081a-46a9-b216-b28aa32106da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700179711-172.17.0.3-1597312481777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43023,DS-556bd4d6-4e64-4cb7-82ff-0334883160ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-c07ecae0-9c0c-4cf1-b8e4-b9277891c1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-f552c647-025b-49bf-9532-684115129bab,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-c6ed1633-271a-4f15-9acc-f68e426e7105,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-d75e6342-fce8-452a-852b-477cef0f1e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-53b5ba39-9ebe-414d-bd3c-7bdfdc9d7a36,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-43d2096a-6019-4ad3-a317-2f46eece809b,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-6a738038-6926-476a-9077-4ca5ab549cc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700179711-172.17.0.3-1597312481777:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43023,DS-556bd4d6-4e64-4cb7-82ff-0334883160ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41351,DS-c07ecae0-9c0c-4cf1-b8e4-b9277891c1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-f552c647-025b-49bf-9532-684115129bab,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-c6ed1633-271a-4f15-9acc-f68e426e7105,DISK], DatanodeInfoWithStorage[127.0.0.1:42311,DS-d75e6342-fce8-452a-852b-477cef0f1e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36740,DS-53b5ba39-9ebe-414d-bd3c-7bdfdc9d7a36,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-43d2096a-6019-4ad3-a317-2f46eece809b,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-6a738038-6926-476a-9077-4ca5ab549cc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1095162816-172.17.0.3-1597312664554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41884,DS-3ad8416b-7299-4246-acb9-1403734003cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-5c99d5bf-d80a-44dd-92ad-661a5282bda8,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-e1ba2a35-0391-493e-a6a4-70ade4f0eb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-a2ecbcf4-459b-4f8e-907b-3b2070211ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-ef0f8641-589e-4eb9-a7e2-9831c57ccaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-942846df-5166-48d9-bd44-fb14be3b6d43,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-e6bc42a2-4d7c-4c78-850f-3b64c9ea2e61,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-523cd30a-dc93-4ec2-81f0-2560cfb19b7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1095162816-172.17.0.3-1597312664554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41884,DS-3ad8416b-7299-4246-acb9-1403734003cf,DISK], DatanodeInfoWithStorage[127.0.0.1:41731,DS-5c99d5bf-d80a-44dd-92ad-661a5282bda8,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-e1ba2a35-0391-493e-a6a4-70ade4f0eb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-a2ecbcf4-459b-4f8e-907b-3b2070211ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-ef0f8641-589e-4eb9-a7e2-9831c57ccaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:37401,DS-942846df-5166-48d9-bd44-fb14be3b6d43,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-e6bc42a2-4d7c-4c78-850f-3b64c9ea2e61,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-523cd30a-dc93-4ec2-81f0-2560cfb19b7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-17598451-172.17.0.3-1597313379643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45735,DS-0c44e8ff-6bda-4ffb-ac3c-b91f631975c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-c9caf652-bcdb-4c08-a896-92041536c976,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-42f02cdd-554f-40cb-9356-32cf44a0d044,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-e98be35e-6771-4144-9cf0-7052223bbc67,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-328bbdfa-b26f-4b1f-980e-9ae6ce02c127,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-5e249a4a-191a-4f98-9dae-0f466a50654e,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-18ae8d8a-1271-4a1d-a058-c297aec21f68,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-d128661a-d664-4cc7-bb8c-06bea2808ca4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-17598451-172.17.0.3-1597313379643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45735,DS-0c44e8ff-6bda-4ffb-ac3c-b91f631975c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-c9caf652-bcdb-4c08-a896-92041536c976,DISK], DatanodeInfoWithStorage[127.0.0.1:33889,DS-42f02cdd-554f-40cb-9356-32cf44a0d044,DISK], DatanodeInfoWithStorage[127.0.0.1:44383,DS-e98be35e-6771-4144-9cf0-7052223bbc67,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-328bbdfa-b26f-4b1f-980e-9ae6ce02c127,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-5e249a4a-191a-4f98-9dae-0f466a50654e,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-18ae8d8a-1271-4a1d-a058-c297aec21f68,DISK], DatanodeInfoWithStorage[127.0.0.1:43289,DS-d128661a-d664-4cc7-bb8c-06bea2808ca4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-905928353-172.17.0.3-1597313455337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38380,DS-0083afdc-ee43-4959-a14b-61c9c075981e,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-068caaad-24c1-467d-b4db-be1bc070d012,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-698b0b15-e50f-47ed-aded-653046706016,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-3c7d69b2-81ee-434e-8164-f869d6d7dd07,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-206f3ef1-86f9-4dac-a329-8cba7339135e,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-bbd02061-62fe-47d7-9078-4dd7a5510369,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-72f64930-f6ad-4e1f-9603-e1961ded9434,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-00ceec92-d904-47ce-8560-3049a1095e07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-905928353-172.17.0.3-1597313455337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38380,DS-0083afdc-ee43-4959-a14b-61c9c075981e,DISK], DatanodeInfoWithStorage[127.0.0.1:34958,DS-068caaad-24c1-467d-b4db-be1bc070d012,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-698b0b15-e50f-47ed-aded-653046706016,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-3c7d69b2-81ee-434e-8164-f869d6d7dd07,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-206f3ef1-86f9-4dac-a329-8cba7339135e,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-bbd02061-62fe-47d7-9078-4dd7a5510369,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-72f64930-f6ad-4e1f-9603-e1961ded9434,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-00ceec92-d904-47ce-8560-3049a1095e07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1303521809-172.17.0.3-1597313754800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44977,DS-e64cf02d-0884-4ba7-8d09-a789bb0e35d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-2c00e41b-6b42-420d-ae59-4402aa4b62c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-e3697ce6-0556-47a8-a053-f311e003f316,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-97d63a08-32dc-4218-a8c0-2e974a8e1e60,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-01835848-238c-4e85-b5c3-7fa916c43e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-882c4921-9a03-40da-a1ee-2bfd1c1552cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-296e4c83-051e-4853-bf70-9168bfeb9b73,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-2bd24ccf-c9ca-43b0-97da-ab84a38b31df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1303521809-172.17.0.3-1597313754800:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44977,DS-e64cf02d-0884-4ba7-8d09-a789bb0e35d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-2c00e41b-6b42-420d-ae59-4402aa4b62c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-e3697ce6-0556-47a8-a053-f311e003f316,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-97d63a08-32dc-4218-a8c0-2e974a8e1e60,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-01835848-238c-4e85-b5c3-7fa916c43e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-882c4921-9a03-40da-a1ee-2bfd1c1552cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-296e4c83-051e-4853-bf70-9168bfeb9b73,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-2bd24ccf-c9ca-43b0-97da-ab84a38b31df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968512979-172.17.0.3-1597313999050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44567,DS-16472969-a573-485b-bbc7-86fddff1f5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-466b9ab4-78b9-47e5-88eb-49e07e7213a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-aa069598-cf97-4689-903c-21b04c8d77f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-2cd0bfc0-041c-46aa-a798-8677c03c26d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-7c38c9dc-33ab-436e-aa47-1e5567e188b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-8472a2d3-ad01-4e56-86f8-62579f4c6184,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-3e1ea962-4134-44fc-b244-11f921e16c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-b2fc9c0e-c1f3-4794-bd86-af6ed866f62b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-968512979-172.17.0.3-1597313999050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44567,DS-16472969-a573-485b-bbc7-86fddff1f5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-466b9ab4-78b9-47e5-88eb-49e07e7213a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-aa069598-cf97-4689-903c-21b04c8d77f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-2cd0bfc0-041c-46aa-a798-8677c03c26d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-7c38c9dc-33ab-436e-aa47-1e5567e188b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-8472a2d3-ad01-4e56-86f8-62579f4c6184,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-3e1ea962-4134-44fc-b244-11f921e16c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-b2fc9c0e-c1f3-4794-bd86-af6ed866f62b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-288637228-172.17.0.3-1597314107503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34469,DS-9222714b-d169-4f27-8dbf-095d9d767152,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-626a5164-b1bd-45f6-b16f-bb79ac7983e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-3bfa7e25-4101-4fff-b7a7-e94b86e41607,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-a38b1f91-123f-4987-a831-1e0976d849ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-af9c54cb-15df-40e7-9f87-93b835b8ec85,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-b08ff67e-8fe1-43c7-ad4c-0f5c0f3d4ead,DISK], DatanodeInfoWithStorage[127.0.0.1:41122,DS-bf4bced5-9cbd-4d0e-8f03-9fd6e281901e,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-f03d5a9a-42c9-45fb-bfdd-d2305ce74a1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-288637228-172.17.0.3-1597314107503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34469,DS-9222714b-d169-4f27-8dbf-095d9d767152,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-626a5164-b1bd-45f6-b16f-bb79ac7983e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37350,DS-3bfa7e25-4101-4fff-b7a7-e94b86e41607,DISK], DatanodeInfoWithStorage[127.0.0.1:39773,DS-a38b1f91-123f-4987-a831-1e0976d849ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-af9c54cb-15df-40e7-9f87-93b835b8ec85,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-b08ff67e-8fe1-43c7-ad4c-0f5c0f3d4ead,DISK], DatanodeInfoWithStorage[127.0.0.1:41122,DS-bf4bced5-9cbd-4d0e-8f03-9fd6e281901e,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-f03d5a9a-42c9-45fb-bfdd-d2305ce74a1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1284726444-172.17.0.3-1597314488086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42663,DS-35ba0886-48c5-4ee8-b085-54f70298fda4,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-491dd66b-47ea-4b6b-8db5-b4ef9591ccaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-72a7fa1f-a8d4-4095-b90b-a8cbde62f620,DISK], DatanodeInfoWithStorage[127.0.0.1:42591,DS-085a3a65-3024-494f-b217-0ca60a9e55cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-4c6b6776-3695-4bb6-94a3-ad10370b45eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-1f83a934-138d-403d-8e77-0181b772101c,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-fe4a912a-26d4-4897-9194-f451fcf817a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-b4d0221b-37e2-4fd5-8a9d-73b0dd433ce2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1284726444-172.17.0.3-1597314488086:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42663,DS-35ba0886-48c5-4ee8-b085-54f70298fda4,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-491dd66b-47ea-4b6b-8db5-b4ef9591ccaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-72a7fa1f-a8d4-4095-b90b-a8cbde62f620,DISK], DatanodeInfoWithStorage[127.0.0.1:42591,DS-085a3a65-3024-494f-b217-0ca60a9e55cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-4c6b6776-3695-4bb6-94a3-ad10370b45eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-1f83a934-138d-403d-8e77-0181b772101c,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-fe4a912a-26d4-4897-9194-f451fcf817a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-b4d0221b-37e2-4fd5-8a9d-73b0dd433ce2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1819433063-172.17.0.3-1597314611891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40638,DS-6c61e715-d43a-420b-bab7-adbc54aeb499,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-6f5fb63a-4d5c-42a8-b29c-a217b8b31727,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-a3f43e91-c4ea-4110-b3cd-6164212f57f7,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-550b1d38-eb7b-468a-ad8c-cc5a3ddf48dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-6fb7584f-bcc9-40e1-ab86-a954f4d9caab,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-325472ad-d482-4e9e-8e4a-fc3d51df06e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-b4d8e71e-8cdd-4505-b484-bfe20be1d2db,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-4e3f802a-d5c1-4f73-918c-ee532860b9e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1819433063-172.17.0.3-1597314611891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40638,DS-6c61e715-d43a-420b-bab7-adbc54aeb499,DISK], DatanodeInfoWithStorage[127.0.0.1:36301,DS-6f5fb63a-4d5c-42a8-b29c-a217b8b31727,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-a3f43e91-c4ea-4110-b3cd-6164212f57f7,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-550b1d38-eb7b-468a-ad8c-cc5a3ddf48dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-6fb7584f-bcc9-40e1-ab86-a954f4d9caab,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-325472ad-d482-4e9e-8e4a-fc3d51df06e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-b4d8e71e-8cdd-4505-b484-bfe20be1d2db,DISK], DatanodeInfoWithStorage[127.0.0.1:42924,DS-4e3f802a-d5c1-4f73-918c-ee532860b9e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1354657174-172.17.0.3-1597314873877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42370,DS-757f8c67-0667-4c52-8aac-19b6be66bc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-0203c114-0f80-48ed-a634-5fa62e3fabca,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-50878a0c-2bd9-4ac7-8358-0ea8579a583d,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-54b35c48-f4a8-410c-84c5-acdb6b9a7a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-54236c04-e2a0-4548-9812-440708c3f82e,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-fd902e36-5bf2-492c-9faa-2640d0fbc2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-95a4a539-6458-4ba1-86ed-267c42a1f9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-ff31191f-319c-44ce-ae7a-030ea7b42a33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1354657174-172.17.0.3-1597314873877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42370,DS-757f8c67-0667-4c52-8aac-19b6be66bc7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-0203c114-0f80-48ed-a634-5fa62e3fabca,DISK], DatanodeInfoWithStorage[127.0.0.1:35229,DS-50878a0c-2bd9-4ac7-8358-0ea8579a583d,DISK], DatanodeInfoWithStorage[127.0.0.1:39752,DS-54b35c48-f4a8-410c-84c5-acdb6b9a7a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34022,DS-54236c04-e2a0-4548-9812-440708c3f82e,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-fd902e36-5bf2-492c-9faa-2640d0fbc2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-95a4a539-6458-4ba1-86ed-267c42a1f9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-ff31191f-319c-44ce-ae7a-030ea7b42a33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1806845801-172.17.0.3-1597314918368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41961,DS-a717cf87-5ff9-480f-a8f0-88a45188fc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33910,DS-a99d9406-4396-431f-a0f4-a1776262a0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-635289dd-3781-45e3-ba1c-fb281c2b1918,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-8934632f-43e4-4990-8d99-e221f5a89bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-af3303cb-7987-42d3-9b4e-0ed4078d6814,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-0ad65c5f-012b-4a8a-901a-8c5cd7098202,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-e820ab07-4542-44a5-9b8d-98ba4c41b46c,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-16412cdd-f222-49a2-9fe3-c05cd82f9804,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1806845801-172.17.0.3-1597314918368:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41961,DS-a717cf87-5ff9-480f-a8f0-88a45188fc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33910,DS-a99d9406-4396-431f-a0f4-a1776262a0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42955,DS-635289dd-3781-45e3-ba1c-fb281c2b1918,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-8934632f-43e4-4990-8d99-e221f5a89bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-af3303cb-7987-42d3-9b4e-0ed4078d6814,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-0ad65c5f-012b-4a8a-901a-8c5cd7098202,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-e820ab07-4542-44a5-9b8d-98ba4c41b46c,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-16412cdd-f222-49a2-9fe3-c05cd82f9804,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1885189071-172.17.0.3-1597315182717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44095,DS-5603f139-c509-4ce2-9b7f-e3b160355ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-edf18a36-7124-4c71-a8e4-530136594a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-1d9b36d1-2e47-4711-992e-31788ec11612,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-2c3c2980-49f1-4fd5-b3d7-7232918db373,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-a5321726-10ff-4acd-80fe-1783d01678dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-bbe1e450-28b4-46c7-9af7-5a65328d189b,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-c3ad3f32-a5df-4892-be38-a66afb475961,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-8b2fab1c-746a-45ba-bed0-9a4855bd2487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1885189071-172.17.0.3-1597315182717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44095,DS-5603f139-c509-4ce2-9b7f-e3b160355ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:46795,DS-edf18a36-7124-4c71-a8e4-530136594a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-1d9b36d1-2e47-4711-992e-31788ec11612,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-2c3c2980-49f1-4fd5-b3d7-7232918db373,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-a5321726-10ff-4acd-80fe-1783d01678dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-bbe1e450-28b4-46c7-9af7-5a65328d189b,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-c3ad3f32-a5df-4892-be38-a66afb475961,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-8b2fab1c-746a-45ba-bed0-9a4855bd2487,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1308174253-172.17.0.3-1597315414637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38979,DS-0b675ca1-208b-40f4-93e1-b7b2c51fc5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-4e4e2e3f-6b48-413b-aac2-47d145819202,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-2cf5a7d9-c94e-41d7-9e09-5ec00c575610,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-d4075fd7-d90f-4b67-b6fc-4b4342b893c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-bba354b9-10a6-4f7f-bce9-be830513895d,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-49c17cb4-897c-4352-912a-5f79e64c6e25,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-f5d2dce0-f3da-4d5a-8e9e-a39d5371f444,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-c31944f6-fe97-4b99-a521-a62d2d7523da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1308174253-172.17.0.3-1597315414637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38979,DS-0b675ca1-208b-40f4-93e1-b7b2c51fc5ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-4e4e2e3f-6b48-413b-aac2-47d145819202,DISK], DatanodeInfoWithStorage[127.0.0.1:46394,DS-2cf5a7d9-c94e-41d7-9e09-5ec00c575610,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-d4075fd7-d90f-4b67-b6fc-4b4342b893c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-bba354b9-10a6-4f7f-bce9-be830513895d,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-49c17cb4-897c-4352-912a-5f79e64c6e25,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-f5d2dce0-f3da-4d5a-8e9e-a39d5371f444,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-c31944f6-fe97-4b99-a521-a62d2d7523da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1798698637-172.17.0.3-1597315522868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36775,DS-849d5c88-d0a8-4431-bf4c-f76a4fd2ff19,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-c182a3ed-e36f-410e-83d9-6f613cc75410,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-155df858-e52f-46b6-8901-644993c9c532,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-1a8373d9-acca-4713-9f7f-aae00cdb36dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-ea2be361-2e6d-495b-a0a0-cc2cb8f14152,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-852e36a8-c140-4a3b-91eb-af34f447f007,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-a4cb154f-a44a-4923-832f-94a39c2d17c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-b102c6d0-d473-4d3e-8dc9-4b471557847c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1798698637-172.17.0.3-1597315522868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36775,DS-849d5c88-d0a8-4431-bf4c-f76a4fd2ff19,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-c182a3ed-e36f-410e-83d9-6f613cc75410,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-155df858-e52f-46b6-8901-644993c9c532,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-1a8373d9-acca-4713-9f7f-aae00cdb36dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-ea2be361-2e6d-495b-a0a0-cc2cb8f14152,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-852e36a8-c140-4a3b-91eb-af34f447f007,DISK], DatanodeInfoWithStorage[127.0.0.1:33439,DS-a4cb154f-a44a-4923-832f-94a39c2d17c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-b102c6d0-d473-4d3e-8dc9-4b471557847c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879696109-172.17.0.3-1597316343021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37685,DS-78a76577-82ab-44b0-836e-6ce1474c1891,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-c9658ea5-dac1-4704-8cda-354d22ef4c84,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-f42450d3-cbc6-412e-91df-7e4f4cd635d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-c98952b9-1f26-4764-a161-d377e141f284,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-4f24eb69-58f8-4dd0-a07e-68236b2850d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43671,DS-f161d085-b461-4c82-aafe-2a02cec2584a,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-1187edbb-a95f-4897-baa9-955f8e77e6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-f473e625-665d-4610-a04b-267acc0864fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879696109-172.17.0.3-1597316343021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37685,DS-78a76577-82ab-44b0-836e-6ce1474c1891,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-c9658ea5-dac1-4704-8cda-354d22ef4c84,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-f42450d3-cbc6-412e-91df-7e4f4cd635d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-c98952b9-1f26-4764-a161-d377e141f284,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-4f24eb69-58f8-4dd0-a07e-68236b2850d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43671,DS-f161d085-b461-4c82-aafe-2a02cec2584a,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-1187edbb-a95f-4897-baa9-955f8e77e6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35264,DS-f473e625-665d-4610-a04b-267acc0864fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1684740051-172.17.0.3-1597316451589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37572,DS-a714d4f4-9584-4240-95ad-1b963c25847e,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-8fd49f4b-3d5b-46d7-a712-57fe6281a5be,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-bcf6eac6-b655-41e7-bdcd-4f6ecfe566dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-b29fa591-7d95-40f2-891b-5e44dbfb0d40,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-d9bb48d5-4aab-428f-b5b7-383ef2c094f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-c9feec3d-6489-4cc0-b56c-06a00e992806,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-11a852cc-16dd-4460-9a4c-699e048ce3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-b50531be-3bee-4460-8e84-88bd8e617edd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1684740051-172.17.0.3-1597316451589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37572,DS-a714d4f4-9584-4240-95ad-1b963c25847e,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-8fd49f4b-3d5b-46d7-a712-57fe6281a5be,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-bcf6eac6-b655-41e7-bdcd-4f6ecfe566dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-b29fa591-7d95-40f2-891b-5e44dbfb0d40,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-d9bb48d5-4aab-428f-b5b7-383ef2c094f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-c9feec3d-6489-4cc0-b56c-06a00e992806,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-11a852cc-16dd-4460-9a4c-699e048ce3ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-b50531be-3bee-4460-8e84-88bd8e617edd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-618338770-172.17.0.3-1597316489332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33381,DS-b9bd9818-531c-439c-a4cf-70218d44a2da,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-bc923df9-79af-4959-880e-2a192948b8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-8ce11e28-a81f-403b-924b-80c5d2c0b7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-22fbb2db-8dc8-4abc-a15b-2bb6fca54306,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-f45d9b0d-c788-4815-bb30-f533995c3529,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-1bd2b654-51bd-4cc4-8627-0b708cec3cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-ef3b9fd1-bef3-4caa-86d3-26d68a84180b,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-844d35a8-b4e8-44ce-8129-22de596b8399,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-618338770-172.17.0.3-1597316489332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33381,DS-b9bd9818-531c-439c-a4cf-70218d44a2da,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-bc923df9-79af-4959-880e-2a192948b8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34752,DS-8ce11e28-a81f-403b-924b-80c5d2c0b7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-22fbb2db-8dc8-4abc-a15b-2bb6fca54306,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-f45d9b0d-c788-4815-bb30-f533995c3529,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-1bd2b654-51bd-4cc4-8627-0b708cec3cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44327,DS-ef3b9fd1-bef3-4caa-86d3-26d68a84180b,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-844d35a8-b4e8-44ce-8129-22de596b8399,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761982086-172.17.0.3-1597316529163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39776,DS-1730173e-f985-4909-8982-8aa159cc079d,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-a6791c3b-9171-4bbb-ba10-ff2e048764ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-5981aef8-1c5e-40b2-acb2-055cebe0fae1,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-eaddcb19-f153-4d45-9ca7-67dd9484c7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-f2512456-58f0-4119-baff-fbd42784d1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-e2519294-ce03-4de4-b902-aa32bb1e86c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-cb00b958-660c-4192-97f6-5621205deb73,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-26c4830b-4752-4796-9642-07c9ba2b82f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-761982086-172.17.0.3-1597316529163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39776,DS-1730173e-f985-4909-8982-8aa159cc079d,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-a6791c3b-9171-4bbb-ba10-ff2e048764ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39712,DS-5981aef8-1c5e-40b2-acb2-055cebe0fae1,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-eaddcb19-f153-4d45-9ca7-67dd9484c7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-f2512456-58f0-4119-baff-fbd42784d1b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-e2519294-ce03-4de4-b902-aa32bb1e86c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-cb00b958-660c-4192-97f6-5621205deb73,DISK], DatanodeInfoWithStorage[127.0.0.1:38159,DS-26c4830b-4752-4796-9642-07c9ba2b82f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111169228-172.17.0.3-1597316716288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43349,DS-756a5a57-876e-44d8-876b-de6b355b88d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-ba14f834-6a3c-48c3-8e5d-466253b02ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-47b7a988-58ca-4e06-884c-08ac922b809c,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-d962a727-fb5a-42f8-a982-cc8f9fd9920d,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-8d399b1d-adc1-4436-a165-79702e2efe92,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-cd2e0c62-0b71-46d7-8b9b-a48bc0be75c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-25c0e6c7-5146-437d-9a8c-9ce17f43b503,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-94a2ad97-9196-4e2d-9863-aa3f6ba8d899,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111169228-172.17.0.3-1597316716288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43349,DS-756a5a57-876e-44d8-876b-de6b355b88d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40409,DS-ba14f834-6a3c-48c3-8e5d-466253b02ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-47b7a988-58ca-4e06-884c-08ac922b809c,DISK], DatanodeInfoWithStorage[127.0.0.1:38589,DS-d962a727-fb5a-42f8-a982-cc8f9fd9920d,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-8d399b1d-adc1-4436-a165-79702e2efe92,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-cd2e0c62-0b71-46d7-8b9b-a48bc0be75c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37636,DS-25c0e6c7-5146-437d-9a8c-9ce17f43b503,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-94a2ad97-9196-4e2d-9863-aa3f6ba8d899,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5706
