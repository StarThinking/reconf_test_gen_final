reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-358799441-172.17.0.6-1597537756392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35901,DS-ed869538-86f0-4caa-ad1d-a4cde59ca97c,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-7b69fdf5-463a-4b17-919c-61b9d32b12d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-0203915f-fe47-4fe2-8ba3-817bb68c830e,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-720cd27b-5a41-4772-a73a-93963876e469,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-fce5d2f6-f764-4285-87f5-b59203e967e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-4428f266-a24a-4751-ab4b-1606a0df5f56,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-1535d583-b1ff-44f9-b00f-6bfced70a686,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-9562c327-82ea-4ff7-b696-e0766badf540,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-358799441-172.17.0.6-1597537756392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35901,DS-ed869538-86f0-4caa-ad1d-a4cde59ca97c,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-7b69fdf5-463a-4b17-919c-61b9d32b12d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-0203915f-fe47-4fe2-8ba3-817bb68c830e,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-720cd27b-5a41-4772-a73a-93963876e469,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-fce5d2f6-f764-4285-87f5-b59203e967e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-4428f266-a24a-4751-ab4b-1606a0df5f56,DISK], DatanodeInfoWithStorage[127.0.0.1:38399,DS-1535d583-b1ff-44f9-b00f-6bfced70a686,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-9562c327-82ea-4ff7-b696-e0766badf540,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2025370427-172.17.0.6-1597538636038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39222,DS-9006f88e-f641-4a98-a4bc-e01dea3cd338,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-e9d5fa2f-d5d6-4c99-bdbc-5174d84ad2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-b602d87e-266d-439c-af67-5c1ad0147cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-16ee1426-ca6f-4418-95f5-95f413d595f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-6318a73a-400c-47f7-9a43-c8e5b51a5b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-e328e051-df36-4c3a-a510-57f55236afeb,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-0581806d-6a02-4a40-81c5-12e47f2b41bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-9922b857-f6bc-4597-af83-2b6d9963cc9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2025370427-172.17.0.6-1597538636038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39222,DS-9006f88e-f641-4a98-a4bc-e01dea3cd338,DISK], DatanodeInfoWithStorage[127.0.0.1:46161,DS-e9d5fa2f-d5d6-4c99-bdbc-5174d84ad2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-b602d87e-266d-439c-af67-5c1ad0147cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-16ee1426-ca6f-4418-95f5-95f413d595f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-6318a73a-400c-47f7-9a43-c8e5b51a5b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40468,DS-e328e051-df36-4c3a-a510-57f55236afeb,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-0581806d-6a02-4a40-81c5-12e47f2b41bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35073,DS-9922b857-f6bc-4597-af83-2b6d9963cc9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376856298-172.17.0.6-1597538672099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41121,DS-6b867b33-16be-47a1-83f9-3cf9ffe2974d,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-2183f8a7-1cdc-42ae-81e5-6f28e21ade7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-75c94eac-0358-4f7a-944a-dddfbd6a2f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-8d595c96-3333-47ad-9068-bf92c292c526,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-f7ba6548-4edb-4950-8c7e-02138b6fcda7,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-3c6d56eb-167b-4713-8c01-6507bfaf15e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-008b53c2-8fc9-43a8-adcc-df470d9a1346,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-359bdcb1-4ebd-4e91-8195-7bea583d2003,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376856298-172.17.0.6-1597538672099:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41121,DS-6b867b33-16be-47a1-83f9-3cf9ffe2974d,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-2183f8a7-1cdc-42ae-81e5-6f28e21ade7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-75c94eac-0358-4f7a-944a-dddfbd6a2f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-8d595c96-3333-47ad-9068-bf92c292c526,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-f7ba6548-4edb-4950-8c7e-02138b6fcda7,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-3c6d56eb-167b-4713-8c01-6507bfaf15e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-008b53c2-8fc9-43a8-adcc-df470d9a1346,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-359bdcb1-4ebd-4e91-8195-7bea583d2003,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1038852802-172.17.0.6-1597538870394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39047,DS-a6f81ab0-ccf2-4668-aec4-fe90b2ca5a02,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-8ed37acc-b07a-4b6b-aaa4-01d42b3e227d,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-09aea416-92b1-4b2c-9235-00fe9c984541,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-141442aa-eecd-40e3-855b-b0b5ed30ca99,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-95bd006c-aeaf-4755-9331-6aef5159cac3,DISK], DatanodeInfoWithStorage[127.0.0.1:46502,DS-fa17bc02-6cc0-405c-b344-593a5fad8329,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-9b8a6f07-f42b-49a0-90f3-8673be6741cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-2f5bc090-acd6-40eb-8919-f45aaee5f4ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1038852802-172.17.0.6-1597538870394:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39047,DS-a6f81ab0-ccf2-4668-aec4-fe90b2ca5a02,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-8ed37acc-b07a-4b6b-aaa4-01d42b3e227d,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-09aea416-92b1-4b2c-9235-00fe9c984541,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-141442aa-eecd-40e3-855b-b0b5ed30ca99,DISK], DatanodeInfoWithStorage[127.0.0.1:46409,DS-95bd006c-aeaf-4755-9331-6aef5159cac3,DISK], DatanodeInfoWithStorage[127.0.0.1:46502,DS-fa17bc02-6cc0-405c-b344-593a5fad8329,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-9b8a6f07-f42b-49a0-90f3-8673be6741cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-2f5bc090-acd6-40eb-8919-f45aaee5f4ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061807926-172.17.0.6-1597539129591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35757,DS-f2171f05-e8a2-40ae-abce-f0d30082019f,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-8df4f23f-7bae-4fe1-804f-76ed50e1944c,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-bce9a4f5-6d19-42d7-a1a7-bd156d01e004,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-2828d2fe-9baf-4000-97ac-32335ea37dad,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-000b91e7-97fb-4352-923e-b321340b5f31,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-805ac989-5261-42c2-bf76-d55752b2601b,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-a5ff318b-734a-4369-b4fe-c80b967da264,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-9fbff1f2-89a3-4b8a-8350-4833568d90bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061807926-172.17.0.6-1597539129591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35757,DS-f2171f05-e8a2-40ae-abce-f0d30082019f,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-8df4f23f-7bae-4fe1-804f-76ed50e1944c,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-bce9a4f5-6d19-42d7-a1a7-bd156d01e004,DISK], DatanodeInfoWithStorage[127.0.0.1:39020,DS-2828d2fe-9baf-4000-97ac-32335ea37dad,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-000b91e7-97fb-4352-923e-b321340b5f31,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-805ac989-5261-42c2-bf76-d55752b2601b,DISK], DatanodeInfoWithStorage[127.0.0.1:42545,DS-a5ff318b-734a-4369-b4fe-c80b967da264,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-9fbff1f2-89a3-4b8a-8350-4833568d90bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-478767797-172.17.0.6-1597539255760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41179,DS-8384c1f0-d533-405a-bc72-ab2798be5fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-b5700bef-6377-4ab1-97c7-13ce549a8eab,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-c2c6ef2b-0aa3-42fb-93f9-ff3decbb2a28,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-d9d9644a-9de5-4e54-b962-2675fbf30c45,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-7d3d511e-8363-4b78-8ced-9f482e0d898a,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-b5df3eff-a0ae-47f4-ab62-0771697b7a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-8d035e7c-bd7b-46ae-9e86-a64dd3965496,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-d14016db-d2ba-44d5-aa46-f9f7525b6871,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-478767797-172.17.0.6-1597539255760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41179,DS-8384c1f0-d533-405a-bc72-ab2798be5fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-b5700bef-6377-4ab1-97c7-13ce549a8eab,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-c2c6ef2b-0aa3-42fb-93f9-ff3decbb2a28,DISK], DatanodeInfoWithStorage[127.0.0.1:38376,DS-d9d9644a-9de5-4e54-b962-2675fbf30c45,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-7d3d511e-8363-4b78-8ced-9f482e0d898a,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-b5df3eff-a0ae-47f4-ab62-0771697b7a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37922,DS-8d035e7c-bd7b-46ae-9e86-a64dd3965496,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-d14016db-d2ba-44d5-aa46-f9f7525b6871,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-657744666-172.17.0.6-1597539973689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44093,DS-9f48128d-48e7-4e66-933a-d2186810ba48,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-b09587c2-325a-4fdb-8598-ee6df8007945,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-e9b79222-a8ae-43fe-8252-a25e3a6eb965,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-548dd83c-c290-4314-873b-b090bd39bfde,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-60e2529f-043b-4b73-959c-0785cc731b22,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-fe2bee39-b115-480c-88ff-669f6e3836d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-ac96ec18-849d-434c-a89e-b49f183d2953,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-6c79e47c-d8a5-47c1-8df4-b57a3180f253,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-657744666-172.17.0.6-1597539973689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44093,DS-9f48128d-48e7-4e66-933a-d2186810ba48,DISK], DatanodeInfoWithStorage[127.0.0.1:38973,DS-b09587c2-325a-4fdb-8598-ee6df8007945,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-e9b79222-a8ae-43fe-8252-a25e3a6eb965,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-548dd83c-c290-4314-873b-b090bd39bfde,DISK], DatanodeInfoWithStorage[127.0.0.1:36537,DS-60e2529f-043b-4b73-959c-0785cc731b22,DISK], DatanodeInfoWithStorage[127.0.0.1:46584,DS-fe2bee39-b115-480c-88ff-669f6e3836d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-ac96ec18-849d-434c-a89e-b49f183d2953,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-6c79e47c-d8a5-47c1-8df4-b57a3180f253,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-419809506-172.17.0.6-1597540098747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33311,DS-a5f2f0a3-705e-4528-ad8c-3e3d239a8747,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-78a4cfed-9d11-4365-98c5-314f78e789f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39958,DS-cb1aaf8a-5e6d-4c85-8a9b-3dfbc6721ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-e95abf05-a5ce-4b08-8822-622097e03387,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-bcf0a829-25e4-455d-84ca-2983f56cd504,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-d1848ff9-c51c-4103-8fd5-e481c9f92b71,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-958416b3-7461-434a-bd72-3169f9eb7bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-66e0a014-fd08-481e-946f-9272fc050081,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-419809506-172.17.0.6-1597540098747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33311,DS-a5f2f0a3-705e-4528-ad8c-3e3d239a8747,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-78a4cfed-9d11-4365-98c5-314f78e789f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39958,DS-cb1aaf8a-5e6d-4c85-8a9b-3dfbc6721ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-e95abf05-a5ce-4b08-8822-622097e03387,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-bcf0a829-25e4-455d-84ca-2983f56cd504,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-d1848ff9-c51c-4103-8fd5-e481c9f92b71,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-958416b3-7461-434a-bd72-3169f9eb7bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-66e0a014-fd08-481e-946f-9272fc050081,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-492537948-172.17.0.6-1597540790275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39587,DS-073067de-b46a-41c0-bbc9-25391e55f090,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-b04539ac-987e-4cc2-b3ce-dc0d58c5b560,DISK], DatanodeInfoWithStorage[127.0.0.1:44674,DS-c2704e24-f7ae-416b-8fe0-d007bfa8d06b,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-09575392-717f-44d8-9e2a-2db9779fbe8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-5dd64b90-a144-4ff7-9ea2-3ee8629d2e20,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-85805c7d-297c-4285-853f-305e6738af2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-19bef006-c76c-4e6d-8573-bf9a2eed081d,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-a45beacd-28ab-4a79-8c66-fb05ece043a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-492537948-172.17.0.6-1597540790275:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39587,DS-073067de-b46a-41c0-bbc9-25391e55f090,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-b04539ac-987e-4cc2-b3ce-dc0d58c5b560,DISK], DatanodeInfoWithStorage[127.0.0.1:44674,DS-c2704e24-f7ae-416b-8fe0-d007bfa8d06b,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-09575392-717f-44d8-9e2a-2db9779fbe8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-5dd64b90-a144-4ff7-9ea2-3ee8629d2e20,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-85805c7d-297c-4285-853f-305e6738af2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-19bef006-c76c-4e6d-8573-bf9a2eed081d,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-a45beacd-28ab-4a79-8c66-fb05ece043a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1298839334-172.17.0.6-1597541579545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46751,DS-4a567331-f06a-4ba4-aa02-44d14864b208,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-f96c448d-5fac-452c-b41e-5e4e57360713,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-0866da39-6f80-4e8f-ba8e-d09512787c60,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-35ac059b-91a7-49f4-a6ed-963c81275e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-bc477e24-88d7-4a0a-8bff-69d11a2020a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-3d6a942f-65d2-43a4-a142-069a2ac46a72,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-967d722e-190a-4e9d-a689-4f536784dfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-40522fc2-bf94-416c-ab3f-b81da9a63c4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1298839334-172.17.0.6-1597541579545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46751,DS-4a567331-f06a-4ba4-aa02-44d14864b208,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-f96c448d-5fac-452c-b41e-5e4e57360713,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-0866da39-6f80-4e8f-ba8e-d09512787c60,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-35ac059b-91a7-49f4-a6ed-963c81275e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-bc477e24-88d7-4a0a-8bff-69d11a2020a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-3d6a942f-65d2-43a4-a142-069a2ac46a72,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-967d722e-190a-4e9d-a689-4f536784dfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41908,DS-40522fc2-bf94-416c-ab3f-b81da9a63c4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688107303-172.17.0.6-1597541657110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37548,DS-b9474646-ff61-467f-83ac-8f8c3c9dbef0,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-a47ba022-8bd5-4293-b5a1-da010b7fb9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-173765e0-45ac-4b5f-984d-63ea48acd0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-7207cb13-246e-43a6-aa8c-5cb633e921fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-c16b7c05-94a2-4446-8183-065324974ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-f46ff64b-010e-44f9-a835-19f293a352da,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-e7eefef5-2bd8-49f9-80bf-318b7c25df72,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-970aad09-332e-49e5-8a2a-72a670757f4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688107303-172.17.0.6-1597541657110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37548,DS-b9474646-ff61-467f-83ac-8f8c3c9dbef0,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-a47ba022-8bd5-4293-b5a1-da010b7fb9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39955,DS-173765e0-45ac-4b5f-984d-63ea48acd0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-7207cb13-246e-43a6-aa8c-5cb633e921fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-c16b7c05-94a2-4446-8183-065324974ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-f46ff64b-010e-44f9-a835-19f293a352da,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-e7eefef5-2bd8-49f9-80bf-318b7c25df72,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-970aad09-332e-49e5-8a2a-72a670757f4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-3871628-172.17.0.6-1597541962068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34249,DS-fd3c5e60-d268-470b-8e25-9bd250048edd,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-eae78086-f519-4254-b44a-86e6bb33b1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-87e3d888-7878-4399-9df6-162a6cbdd9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-b7a7a742-ad81-4a54-a01a-5904914a44e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-de438c61-1ff7-497d-bb14-9f68e29701cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-07adc03c-9aac-44c6-a4d3-cc3d6f45eb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-2abec3eb-a68d-4c83-8d7c-867a699dd6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-bd767e1c-35fd-4e09-9533-46409ac73eec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-3871628-172.17.0.6-1597541962068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34249,DS-fd3c5e60-d268-470b-8e25-9bd250048edd,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-eae78086-f519-4254-b44a-86e6bb33b1cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-87e3d888-7878-4399-9df6-162a6cbdd9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-b7a7a742-ad81-4a54-a01a-5904914a44e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-de438c61-1ff7-497d-bb14-9f68e29701cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-07adc03c-9aac-44c6-a4d3-cc3d6f45eb9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44095,DS-2abec3eb-a68d-4c83-8d7c-867a699dd6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43028,DS-bd767e1c-35fd-4e09-9533-46409ac73eec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1771075541-172.17.0.6-1597542510427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42025,DS-fe6482ac-15c0-4668-bb31-ab8d5d3aa434,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-f162e495-e276-4f47-8bc8-036c21f31f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-4cbdb79f-8319-4b2d-845e-a6dab1be514f,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-8de9f453-38c5-495f-8a5a-642d8ed550e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-06189e23-b95c-4053-bcc5-2e20c4cd9a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-3d34a352-edc2-4e84-9190-b04ae09bece4,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-6168b045-cd1d-4955-bd94-2b0678f45881,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-e144f4f6-57f1-4065-98a8-f52dd80cbc25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1771075541-172.17.0.6-1597542510427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42025,DS-fe6482ac-15c0-4668-bb31-ab8d5d3aa434,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-f162e495-e276-4f47-8bc8-036c21f31f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-4cbdb79f-8319-4b2d-845e-a6dab1be514f,DISK], DatanodeInfoWithStorage[127.0.0.1:45631,DS-8de9f453-38c5-495f-8a5a-642d8ed550e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44625,DS-06189e23-b95c-4053-bcc5-2e20c4cd9a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-3d34a352-edc2-4e84-9190-b04ae09bece4,DISK], DatanodeInfoWithStorage[127.0.0.1:46422,DS-6168b045-cd1d-4955-bd94-2b0678f45881,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-e144f4f6-57f1-4065-98a8-f52dd80cbc25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1472982936-172.17.0.6-1597542580459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45574,DS-78b654b6-727c-4301-b649-8d50435d0a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-ef99f387-4f73-4949-be4a-4f94cb44d298,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-d42af798-fb02-4a77-80fd-1dcd48f81a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-77b4eede-4b89-4b84-a487-fd66c8746369,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-d6d7c926-19c9-4611-942a-598b5c84181e,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-b8daf994-33d6-4061-9572-8a84967249c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-b6b76180-83bc-4e63-b6f6-014cfa37866f,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-0f203f9d-4280-4702-a717-3c98e13b810c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1472982936-172.17.0.6-1597542580459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45574,DS-78b654b6-727c-4301-b649-8d50435d0a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-ef99f387-4f73-4949-be4a-4f94cb44d298,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-d42af798-fb02-4a77-80fd-1dcd48f81a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38946,DS-77b4eede-4b89-4b84-a487-fd66c8746369,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-d6d7c926-19c9-4611-942a-598b5c84181e,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-b8daf994-33d6-4061-9572-8a84967249c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-b6b76180-83bc-4e63-b6f6-014cfa37866f,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-0f203f9d-4280-4702-a717-3c98e13b810c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214370541-172.17.0.6-1597542613011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43429,DS-43574bac-e4be-4e35-b0dd-fe2f6ed606ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-b4cbe54a-08cb-4166-bd63-47a6ebcf287d,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-6b8b2337-db95-4daa-a2f7-f0b9a0a9e55e,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-b855429d-e31d-4de6-888c-a92985c0e6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-49cae6c5-1909-4a10-8d5c-4ba3c872facb,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-1e5fd57c-2d67-4a9d-b936-08e58be0ce96,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-d82ce8f9-d9c0-4fab-a625-917a4e401383,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-96630052-d26b-4eb4-840e-7bb65a84aeba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214370541-172.17.0.6-1597542613011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43429,DS-43574bac-e4be-4e35-b0dd-fe2f6ed606ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-b4cbe54a-08cb-4166-bd63-47a6ebcf287d,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-6b8b2337-db95-4daa-a2f7-f0b9a0a9e55e,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-b855429d-e31d-4de6-888c-a92985c0e6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-49cae6c5-1909-4a10-8d5c-4ba3c872facb,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-1e5fd57c-2d67-4a9d-b936-08e58be0ce96,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-d82ce8f9-d9c0-4fab-a625-917a4e401383,DISK], DatanodeInfoWithStorage[127.0.0.1:35482,DS-96630052-d26b-4eb4-840e-7bb65a84aeba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 2160
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-953676202-172.17.0.6-1597542956195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39517,DS-f3431858-40a3-479e-9d28-7fce0372410a,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-a8196bb8-cb3d-4829-b4d3-20e759f2581a,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-cb1c0672-b4f6-4f49-9350-1e13644cc0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-621e5b9e-518d-4a48-93d6-1bc46630e0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-540156b5-f7ce-462a-a844-9fd19f76aa6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40891,DS-e087ed9f-cb57-403c-b211-ad1a36dfc350,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-6026a2d5-e1d9-4693-b6ed-7a04f9e7376f,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-3acd6145-cce3-4ea9-9f4c-7ee827fdeb65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-953676202-172.17.0.6-1597542956195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39517,DS-f3431858-40a3-479e-9d28-7fce0372410a,DISK], DatanodeInfoWithStorage[127.0.0.1:44332,DS-a8196bb8-cb3d-4829-b4d3-20e759f2581a,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-cb1c0672-b4f6-4f49-9350-1e13644cc0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-621e5b9e-518d-4a48-93d6-1bc46630e0b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-540156b5-f7ce-462a-a844-9fd19f76aa6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40891,DS-e087ed9f-cb57-403c-b211-ad1a36dfc350,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-6026a2d5-e1d9-4693-b6ed-7a04f9e7376f,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-3acd6145-cce3-4ea9-9f4c-7ee827fdeb65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5965
