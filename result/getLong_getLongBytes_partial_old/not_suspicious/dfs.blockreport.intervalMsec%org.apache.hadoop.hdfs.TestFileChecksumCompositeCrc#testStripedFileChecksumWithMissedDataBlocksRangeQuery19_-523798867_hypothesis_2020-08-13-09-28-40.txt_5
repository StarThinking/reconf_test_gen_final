reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1207445674-172.17.0.14-1597311082334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37960,DS-c5e7071f-cadb-4c4f-a3d0-3de841a47813,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-b12c058d-fbfd-4da9-8037-4a66440c5c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-114ea43a-3c0f-4014-8067-3b79d2e649c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-51f46e80-6232-45a2-84f6-c19005bf8eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-455962fe-30d7-418a-9753-c19c7fa841cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-2c30c434-0482-4acc-8e4f-690432ef3e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-d412771c-85c0-4c40-a914-fa72830af404,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-e60cea38-716b-44e5-b57c-3c49ac043780,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1207445674-172.17.0.14-1597311082334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37960,DS-c5e7071f-cadb-4c4f-a3d0-3de841a47813,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-b12c058d-fbfd-4da9-8037-4a66440c5c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-114ea43a-3c0f-4014-8067-3b79d2e649c8,DISK], DatanodeInfoWithStorage[127.0.0.1:42030,DS-51f46e80-6232-45a2-84f6-c19005bf8eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-455962fe-30d7-418a-9753-c19c7fa841cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35035,DS-2c30c434-0482-4acc-8e4f-690432ef3e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-d412771c-85c0-4c40-a914-fa72830af404,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-e60cea38-716b-44e5-b57c-3c49ac043780,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-713450833-172.17.0.14-1597311158477:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45223,DS-8c948f70-741a-4c86-986a-c84da795356a,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-a9e7dd1e-e2ac-48ba-92b8-9311a53dd98f,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-51814d0c-1757-4a0a-aa5a-0dadf314b6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-aef7fd30-f123-4e97-8d2b-989a0fc8d06a,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-d670e93b-3e9e-48c7-9567-8bec9d636bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-0d5703b2-f94c-49af-8bdb-86521f8cef6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-00cacc97-e831-4590-8483-9135f8893d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-7d648321-6c5b-42f1-98f3-fcafcc66e49a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-713450833-172.17.0.14-1597311158477:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45223,DS-8c948f70-741a-4c86-986a-c84da795356a,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-a9e7dd1e-e2ac-48ba-92b8-9311a53dd98f,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-51814d0c-1757-4a0a-aa5a-0dadf314b6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-aef7fd30-f123-4e97-8d2b-989a0fc8d06a,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-d670e93b-3e9e-48c7-9567-8bec9d636bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-0d5703b2-f94c-49af-8bdb-86521f8cef6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-00cacc97-e831-4590-8483-9135f8893d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-7d648321-6c5b-42f1-98f3-fcafcc66e49a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1978416223-172.17.0.14-1597311387653:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35567,DS-fc41414e-fc04-40b9-b7fd-622798476516,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-4f20c9d7-24b8-4b22-bf5e-a0738841abb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-333ad9fc-3c0e-4a84-9be2-1a1e774d36ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-08a21091-a4d8-4753-9209-cef0d73e5664,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-3624ca16-f4de-4406-998a-5e9752281136,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-5b53ef12-734b-496a-a2d5-39e14838fd21,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-21be791f-df28-4357-a808-87e8ef4fe9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-013bbd0e-07d5-4819-9f31-73d567653206,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1978416223-172.17.0.14-1597311387653:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35567,DS-fc41414e-fc04-40b9-b7fd-622798476516,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-4f20c9d7-24b8-4b22-bf5e-a0738841abb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-333ad9fc-3c0e-4a84-9be2-1a1e774d36ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-08a21091-a4d8-4753-9209-cef0d73e5664,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-3624ca16-f4de-4406-998a-5e9752281136,DISK], DatanodeInfoWithStorage[127.0.0.1:32834,DS-5b53ef12-734b-496a-a2d5-39e14838fd21,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-21be791f-df28-4357-a808-87e8ef4fe9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-013bbd0e-07d5-4819-9f31-73d567653206,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1856511991-172.17.0.14-1597311743963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36878,DS-e56a4135-9600-4dd5-b39e-85afba754ace,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-54d983b8-5491-4e57-9ea6-c4d814304523,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-ae1e599d-ffde-43ca-82cc-75f630c86245,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-86135f4a-c5bc-4299-90e8-53dad457c4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-2af584bb-7183-4926-b9c2-c11036eae47b,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-c29069ef-43c0-40fc-ba3c-6eaec29d5317,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-da8a1840-e736-42e8-b587-a9f10a3771e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-7aa6773d-210b-4d3e-9454-cadcac24d9e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1856511991-172.17.0.14-1597311743963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36878,DS-e56a4135-9600-4dd5-b39e-85afba754ace,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-54d983b8-5491-4e57-9ea6-c4d814304523,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-ae1e599d-ffde-43ca-82cc-75f630c86245,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-86135f4a-c5bc-4299-90e8-53dad457c4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-2af584bb-7183-4926-b9c2-c11036eae47b,DISK], DatanodeInfoWithStorage[127.0.0.1:46806,DS-c29069ef-43c0-40fc-ba3c-6eaec29d5317,DISK], DatanodeInfoWithStorage[127.0.0.1:40670,DS-da8a1840-e736-42e8-b587-a9f10a3771e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-7aa6773d-210b-4d3e-9454-cadcac24d9e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-794426007-172.17.0.14-1597312214684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45751,DS-a3e69cda-b998-49dd-b08d-fff5adbcc2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-5ba6a36f-eb3f-472c-b9a6-85fa13331abf,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-568061ea-ead7-48b8-a928-6cd5d01042db,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-c9b67632-ad13-4ac1-84f4-4ec226621619,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-9d130e03-cb3d-4b5e-816f-ab5b45141175,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-7c89a55c-3dff-4f9e-b71c-c8101131b69b,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-1745e649-7b58-4a55-b18c-9d70b1fbe2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-b08197c5-e7e1-48de-b18a-6c2a379170ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-794426007-172.17.0.14-1597312214684:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45751,DS-a3e69cda-b998-49dd-b08d-fff5adbcc2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-5ba6a36f-eb3f-472c-b9a6-85fa13331abf,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-568061ea-ead7-48b8-a928-6cd5d01042db,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-c9b67632-ad13-4ac1-84f4-4ec226621619,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-9d130e03-cb3d-4b5e-816f-ab5b45141175,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-7c89a55c-3dff-4f9e-b71c-c8101131b69b,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-1745e649-7b58-4a55-b18c-9d70b1fbe2a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-b08197c5-e7e1-48de-b18a-6c2a379170ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2043294925-172.17.0.14-1597312747366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36499,DS-ce7fd3d1-1910-419a-ae5e-8654db023919,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-60bfc1be-5d38-4541-87af-46093a3a64fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-77643ed9-f8fa-4575-b07d-9d9e9ca329cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-968a967f-ba6a-43f7-b815-428dd8bf854a,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-008adf71-682f-42b9-9f0d-03fa29448d54,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-8cdf3918-656d-4f69-a8a0-24bd57cf1a31,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-9f875d01-6ca2-40db-84d8-2682bee9e3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-e822519a-8924-4daa-b4dc-464488402fe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2043294925-172.17.0.14-1597312747366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36499,DS-ce7fd3d1-1910-419a-ae5e-8654db023919,DISK], DatanodeInfoWithStorage[127.0.0.1:33497,DS-60bfc1be-5d38-4541-87af-46093a3a64fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-77643ed9-f8fa-4575-b07d-9d9e9ca329cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-968a967f-ba6a-43f7-b815-428dd8bf854a,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-008adf71-682f-42b9-9f0d-03fa29448d54,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-8cdf3918-656d-4f69-a8a0-24bd57cf1a31,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-9f875d01-6ca2-40db-84d8-2682bee9e3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-e822519a-8924-4daa-b4dc-464488402fe5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-900217897-172.17.0.14-1597312794166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43369,DS-96684e5d-bf96-4c68-bc9b-88f89b9b3381,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-50498db8-8038-4c10-b028-ea05ca28ae66,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-02ad63c6-6b7a-459a-8a35-4a2cf67cef18,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-cdfe7857-a2e9-4916-b10f-0c121962c9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-245fc380-fb01-4f20-b72e-6e061729bcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-079eadd5-65f6-42f6-a3b3-1838395cf527,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-bb13af42-4c86-45e2-a013-0873eb79af51,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-1c95dc67-1f8e-4bf3-b209-f291080e86f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-900217897-172.17.0.14-1597312794166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43369,DS-96684e5d-bf96-4c68-bc9b-88f89b9b3381,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-50498db8-8038-4c10-b028-ea05ca28ae66,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-02ad63c6-6b7a-459a-8a35-4a2cf67cef18,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-cdfe7857-a2e9-4916-b10f-0c121962c9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-245fc380-fb01-4f20-b72e-6e061729bcd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-079eadd5-65f6-42f6-a3b3-1838395cf527,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-bb13af42-4c86-45e2-a013-0873eb79af51,DISK], DatanodeInfoWithStorage[127.0.0.1:36945,DS-1c95dc67-1f8e-4bf3-b209-f291080e86f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1387662040-172.17.0.14-1597313478817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39292,DS-eea3b5c8-c1e2-4d4c-bdab-f414742841b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-95b00241-b535-4974-9a54-16a15c25d8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-f1e3c6c5-15a8-4265-b904-fc882321cba5,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-97b9f93e-6c13-41f9-b8c1-2db9254604e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-68656546-ccc7-4d86-9e0c-ede5848ff5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-8a59baf2-d30c-48e0-a2d5-c9986bc2f240,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-06f590a7-21ff-4078-afbe-9dc39d00d82c,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-70b713f5-5d02-41bf-86ce-e99333d732be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1387662040-172.17.0.14-1597313478817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39292,DS-eea3b5c8-c1e2-4d4c-bdab-f414742841b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38194,DS-95b00241-b535-4974-9a54-16a15c25d8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-f1e3c6c5-15a8-4265-b904-fc882321cba5,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-97b9f93e-6c13-41f9-b8c1-2db9254604e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36798,DS-68656546-ccc7-4d86-9e0c-ede5848ff5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-8a59baf2-d30c-48e0-a2d5-c9986bc2f240,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-06f590a7-21ff-4078-afbe-9dc39d00d82c,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-70b713f5-5d02-41bf-86ce-e99333d732be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-405685337-172.17.0.14-1597313548209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40985,DS-f68f0f28-0749-4c17-b921-67ec0f8502d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-9a3f7059-d44a-4648-a73a-1dac45851f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-b10afcbf-03e3-4637-be5c-4335379333ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-803bd76b-bf1f-475d-a0e7-9473fd1c85b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-d21f13f6-108e-4c1c-bc10-38580d766573,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-7b01ec13-ec29-4e9a-bc51-ac4ae81333de,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-b39e6128-a896-4e3d-b60a-e45369addbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-9ef3c602-39c5-41fa-9cd8-de0d2f4f3c17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-405685337-172.17.0.14-1597313548209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40985,DS-f68f0f28-0749-4c17-b921-67ec0f8502d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38594,DS-9a3f7059-d44a-4648-a73a-1dac45851f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-b10afcbf-03e3-4637-be5c-4335379333ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-803bd76b-bf1f-475d-a0e7-9473fd1c85b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-d21f13f6-108e-4c1c-bc10-38580d766573,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-7b01ec13-ec29-4e9a-bc51-ac4ae81333de,DISK], DatanodeInfoWithStorage[127.0.0.1:40266,DS-b39e6128-a896-4e3d-b60a-e45369addbcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-9ef3c602-39c5-41fa-9cd8-de0d2f4f3c17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-19976485-172.17.0.14-1597313732962:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46838,DS-f637fd11-8fa2-4b7b-b44b-c17a2e31035c,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-e597b03a-4629-4d75-8c77-82c3c468f494,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-33ad2b3d-7017-414e-9d86-ce411dd54ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-346860cb-f85e-4bdb-a249-469efb5796a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-79c4ad7f-37ce-4653-8fd5-8b6772e805e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-31d3a993-4394-49c8-bd0b-a0e9095576e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-0f1bf883-b4c1-4c40-a25e-defe569d52d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-85ee32a3-ab44-4394-807b-2db2ccc8e172,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-19976485-172.17.0.14-1597313732962:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46838,DS-f637fd11-8fa2-4b7b-b44b-c17a2e31035c,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-e597b03a-4629-4d75-8c77-82c3c468f494,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-33ad2b3d-7017-414e-9d86-ce411dd54ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-346860cb-f85e-4bdb-a249-469efb5796a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-79c4ad7f-37ce-4653-8fd5-8b6772e805e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-31d3a993-4394-49c8-bd0b-a0e9095576e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45889,DS-0f1bf883-b4c1-4c40-a25e-defe569d52d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-85ee32a3-ab44-4394-807b-2db2ccc8e172,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-153158580-172.17.0.14-1597313803721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40117,DS-104f45c3-4828-4558-8c4f-d71e4576a1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-152eeffe-62f7-4437-b906-182867fc9b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-cc9d86da-9131-494c-9ad7-a8a063428784,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-9c28b2b0-7926-497c-bccd-a33785dbf631,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-231fb99b-847b-459a-b88e-e67a29f97053,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-5546ef69-6f07-4fd6-b71f-53d4f28aba4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-43faefe4-09a2-4324-b930-c4b02dfc4022,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-9ed4f726-2ac9-4354-aef6-28fff4f827a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-153158580-172.17.0.14-1597313803721:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40117,DS-104f45c3-4828-4558-8c4f-d71e4576a1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-152eeffe-62f7-4437-b906-182867fc9b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-cc9d86da-9131-494c-9ad7-a8a063428784,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-9c28b2b0-7926-497c-bccd-a33785dbf631,DISK], DatanodeInfoWithStorage[127.0.0.1:45258,DS-231fb99b-847b-459a-b88e-e67a29f97053,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-5546ef69-6f07-4fd6-b71f-53d4f28aba4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-43faefe4-09a2-4324-b930-c4b02dfc4022,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-9ed4f726-2ac9-4354-aef6-28fff4f827a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-900037009-172.17.0.14-1597314193884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36560,DS-efc74b8e-3965-44d7-a863-c4107ac54e97,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-47f73ca3-0c5a-4f5a-9f30-99fc9ae39cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-5436adff-1b68-4a5b-ab43-b76de8736dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-4b2fc547-c8f3-4941-8473-f5b0b413105d,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-881c86d8-0220-4466-a103-b5be099641cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-46eec169-dabb-40d0-b3fc-b26c240175d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-e06843a2-d923-4eb9-81ab-e73865ead96e,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-b22cc360-be88-4b9b-9af8-f88b147a224e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-900037009-172.17.0.14-1597314193884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36560,DS-efc74b8e-3965-44d7-a863-c4107ac54e97,DISK], DatanodeInfoWithStorage[127.0.0.1:45103,DS-47f73ca3-0c5a-4f5a-9f30-99fc9ae39cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-5436adff-1b68-4a5b-ab43-b76de8736dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:40444,DS-4b2fc547-c8f3-4941-8473-f5b0b413105d,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-881c86d8-0220-4466-a103-b5be099641cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-46eec169-dabb-40d0-b3fc-b26c240175d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-e06843a2-d923-4eb9-81ab-e73865ead96e,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-b22cc360-be88-4b9b-9af8-f88b147a224e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-292468500-172.17.0.14-1597314414209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32870,DS-464d70ba-f762-443a-bc84-4c1ddfb95c79,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-ec2035fe-068c-4033-ba1a-31765d54417a,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-3e3fc7fb-05a4-4b1c-91db-e463a12ff948,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-43142d61-13bb-47c1-95fc-a8331dd3508d,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-b96cff1f-fb32-4281-ae9e-613d4496dd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-1942c3d7-6178-4564-8840-8c5d1c6e7c35,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-a70f9b55-3b6a-415c-af10-c2f03951458d,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-f85960d4-674b-4372-a590-6e5a644b8915,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-292468500-172.17.0.14-1597314414209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32870,DS-464d70ba-f762-443a-bc84-4c1ddfb95c79,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-ec2035fe-068c-4033-ba1a-31765d54417a,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-3e3fc7fb-05a4-4b1c-91db-e463a12ff948,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-43142d61-13bb-47c1-95fc-a8331dd3508d,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-b96cff1f-fb32-4281-ae9e-613d4496dd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-1942c3d7-6178-4564-8840-8c5d1c6e7c35,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-a70f9b55-3b6a-415c-af10-c2f03951458d,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-f85960d4-674b-4372-a590-6e5a644b8915,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1890814096-172.17.0.14-1597314679626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40289,DS-330c1760-c32d-469e-a4f1-535305d8df73,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-686d9a41-4d9e-4e8f-a80c-45b65a734fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-220db0c5-bb95-41b4-8769-c54cf03273a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-ed2563f6-f244-4e74-9773-d3cd3749002e,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-f93b0964-8a04-4592-8c04-25612815ac41,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-bf7a9c8f-6716-4aef-8eb9-5d609eb88d52,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-2bbb5705-c21a-40b5-a65f-f78434673fca,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-64e4995f-a5f8-41f9-a2a5-5769032cc137,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1890814096-172.17.0.14-1597314679626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40289,DS-330c1760-c32d-469e-a4f1-535305d8df73,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-686d9a41-4d9e-4e8f-a80c-45b65a734fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-220db0c5-bb95-41b4-8769-c54cf03273a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-ed2563f6-f244-4e74-9773-d3cd3749002e,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-f93b0964-8a04-4592-8c04-25612815ac41,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-bf7a9c8f-6716-4aef-8eb9-5d609eb88d52,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-2bbb5705-c21a-40b5-a65f-f78434673fca,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-64e4995f-a5f8-41f9-a2a5-5769032cc137,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-68450647-172.17.0.14-1597315043648:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45423,DS-ac8ded26-93f2-4488-baf0-6740260ea1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-403018fa-99d0-46ab-9fdf-053d7e680833,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-25023af7-43a8-4401-8ed4-2c93b0c8d5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-6a953187-9490-4466-98c0-d8af51cf41ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-fd468457-8804-4565-86c6-32f2f4295e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-5b16e654-8dca-4ac2-8624-f486a4e9e5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-2325e011-682c-4c42-94ab-b030533f8d29,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-4c17fe51-e8d4-4766-baf9-2f5ced767a04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-68450647-172.17.0.14-1597315043648:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45423,DS-ac8ded26-93f2-4488-baf0-6740260ea1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-403018fa-99d0-46ab-9fdf-053d7e680833,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-25023af7-43a8-4401-8ed4-2c93b0c8d5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-6a953187-9490-4466-98c0-d8af51cf41ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-fd468457-8804-4565-86c6-32f2f4295e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-5b16e654-8dca-4ac2-8624-f486a4e9e5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-2325e011-682c-4c42-94ab-b030533f8d29,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-4c17fe51-e8d4-4766-baf9-2f5ced767a04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-846928011-172.17.0.14-1597315465628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32858,DS-f5422e9e-2400-4a39-9863-b23d22beef14,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-588e6c97-2bce-4e95-adf7-2089d5d696a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-906024da-4f85-41c6-8a1c-19569fa84eba,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-706f1e63-6d2f-4007-a607-45b2da49db75,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-9c320f22-4457-4e04-86c9-6b757a9a27f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-a6a819c3-1ff6-4983-bdae-3393f2a18239,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-2acc01c9-3e86-4d1f-bf10-80ea1c92c461,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-f1fb3e54-e95e-4c0b-a814-daa6cab23c05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-846928011-172.17.0.14-1597315465628:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32858,DS-f5422e9e-2400-4a39-9863-b23d22beef14,DISK], DatanodeInfoWithStorage[127.0.0.1:39280,DS-588e6c97-2bce-4e95-adf7-2089d5d696a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-906024da-4f85-41c6-8a1c-19569fa84eba,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-706f1e63-6d2f-4007-a607-45b2da49db75,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-9c320f22-4457-4e04-86c9-6b757a9a27f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-a6a819c3-1ff6-4983-bdae-3393f2a18239,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-2acc01c9-3e86-4d1f-bf10-80ea1c92c461,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-f1fb3e54-e95e-4c0b-a814-daa6cab23c05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1588304687-172.17.0.14-1597315507264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42002,DS-c21611be-ade9-4324-b480-f24c33709eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-b626142c-6b85-47b8-9a40-5bd839e70f55,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-d0948bf7-876b-4433-bf6d-5b28df5cd7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-eb2d199a-ff23-4faa-a0a4-19df757f1510,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-6dfc0a1f-3fb8-444b-9dfe-75d71c234ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-dbc4d562-0688-4f78-901b-65bb7da2b9df,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-189b873d-d97f-4bdf-a4eb-d7472cdc1e06,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-ff27188d-5f6f-4a8b-8411-aaef9b1afa2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1588304687-172.17.0.14-1597315507264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42002,DS-c21611be-ade9-4324-b480-f24c33709eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33977,DS-b626142c-6b85-47b8-9a40-5bd839e70f55,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-d0948bf7-876b-4433-bf6d-5b28df5cd7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-eb2d199a-ff23-4faa-a0a4-19df757f1510,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-6dfc0a1f-3fb8-444b-9dfe-75d71c234ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:39679,DS-dbc4d562-0688-4f78-901b-65bb7da2b9df,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-189b873d-d97f-4bdf-a4eb-d7472cdc1e06,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-ff27188d-5f6f-4a8b-8411-aaef9b1afa2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1321950600-172.17.0.14-1597315538799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42282,DS-23c75c3b-0ad3-4beb-abec-f4dceba197da,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-d4bc90db-070f-407b-8166-0a1508309b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-437f6657-ad81-40fc-985a-b67855698b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-7d35b2c5-d85a-47c0-93cc-9f4e75e49776,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-63acac3e-4841-4b8e-9b22-23436f3edf42,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-b602a084-9500-4db5-806b-6cfbfc37c2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-f0bed43e-5db8-45a1-8604-cb41c0ae6ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-50780e11-0de0-4d31-83a3-17c95cd6a309,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1321950600-172.17.0.14-1597315538799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42282,DS-23c75c3b-0ad3-4beb-abec-f4dceba197da,DISK], DatanodeInfoWithStorage[127.0.0.1:40837,DS-d4bc90db-070f-407b-8166-0a1508309b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-437f6657-ad81-40fc-985a-b67855698b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-7d35b2c5-d85a-47c0-93cc-9f4e75e49776,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-63acac3e-4841-4b8e-9b22-23436f3edf42,DISK], DatanodeInfoWithStorage[127.0.0.1:33719,DS-b602a084-9500-4db5-806b-6cfbfc37c2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-f0bed43e-5db8-45a1-8604-cb41c0ae6ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:34671,DS-50780e11-0de0-4d31-83a3-17c95cd6a309,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-35305490-172.17.0.14-1597315579051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37032,DS-cc32f451-0ac9-4bd1-b26c-fbd487315e67,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-7f8628a9-2611-4e9f-bf3e-0eacd794db13,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-6a39ff9f-fb6c-42e9-9ac2-2e7d5ef14ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-8c177c54-8bbe-4d18-8cb8-10f194314dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-88a087e8-36dc-4fc4-ba8f-9dd273f9b770,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-59506865-ec2d-4067-b8ac-2ce64d1dc130,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-14a7e1fd-9d70-4c72-b1dc-c6910041066b,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-905194c9-7948-47ff-ad4c-08723579a31f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-35305490-172.17.0.14-1597315579051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37032,DS-cc32f451-0ac9-4bd1-b26c-fbd487315e67,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-7f8628a9-2611-4e9f-bf3e-0eacd794db13,DISK], DatanodeInfoWithStorage[127.0.0.1:39898,DS-6a39ff9f-fb6c-42e9-9ac2-2e7d5ef14ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:33370,DS-8c177c54-8bbe-4d18-8cb8-10f194314dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-88a087e8-36dc-4fc4-ba8f-9dd273f9b770,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-59506865-ec2d-4067-b8ac-2ce64d1dc130,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-14a7e1fd-9d70-4c72-b1dc-c6910041066b,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-905194c9-7948-47ff-ad4c-08723579a31f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1342496513-172.17.0.14-1597315656197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36011,DS-a848db4b-8215-4f11-a496-30f3d0c12205,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-15ba77e3-466e-4d36-acf8-bfbf94dc05ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-06eeb2c8-c6bf-44f5-8706-241332545f41,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-94902532-4d3c-4d50-8fbf-8ca7dd97398c,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-13b2f655-15f3-468a-8b7d-9a4b8cbd2599,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-9ee033a5-a18b-49c8-a3b7-f70f52019e40,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-357c2aea-bf87-4af5-8408-98060b16e1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-1c7e5942-63bd-4ecb-91c5-641f7a27a118,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1342496513-172.17.0.14-1597315656197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36011,DS-a848db4b-8215-4f11-a496-30f3d0c12205,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-15ba77e3-466e-4d36-acf8-bfbf94dc05ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-06eeb2c8-c6bf-44f5-8706-241332545f41,DISK], DatanodeInfoWithStorage[127.0.0.1:35689,DS-94902532-4d3c-4d50-8fbf-8ca7dd97398c,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-13b2f655-15f3-468a-8b7d-9a4b8cbd2599,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-9ee033a5-a18b-49c8-a3b7-f70f52019e40,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-357c2aea-bf87-4af5-8408-98060b16e1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-1c7e5942-63bd-4ecb-91c5-641f7a27a118,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-832962869-172.17.0.14-1597316037764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35374,DS-9808c9de-8118-48cc-bb68-33476873b76d,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-fdda33a5-79cc-4587-a718-c9703478e90d,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-587f4213-07ad-459b-800d-4c284f8a8bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-9f72ac17-da2a-454f-9092-c5c05686f901,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-1f207427-95a8-4969-9a41-e0c6a0f240fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-033e8195-e540-4131-8301-4df971277cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-8f8cfccb-2ee2-4f3d-9fee-7aa3f15b3927,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-e45c9b93-f4f1-48a1-a9f7-b1e324de351e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-832962869-172.17.0.14-1597316037764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35374,DS-9808c9de-8118-48cc-bb68-33476873b76d,DISK], DatanodeInfoWithStorage[127.0.0.1:38190,DS-fdda33a5-79cc-4587-a718-c9703478e90d,DISK], DatanodeInfoWithStorage[127.0.0.1:45685,DS-587f4213-07ad-459b-800d-4c284f8a8bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-9f72ac17-da2a-454f-9092-c5c05686f901,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-1f207427-95a8-4969-9a41-e0c6a0f240fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-033e8195-e540-4131-8301-4df971277cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-8f8cfccb-2ee2-4f3d-9fee-7aa3f15b3927,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-e45c9b93-f4f1-48a1-a9f7-b1e324de351e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850596718-172.17.0.14-1597316183431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43276,DS-8e9f03e4-b932-4e43-b4a6-6395d02583fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-7afd2060-603b-4aca-b529-985039fda0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-a0f4e111-373c-4f70-9d9c-84e318f7b167,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-b0cc5457-8c48-4984-ae76-e677ed04c5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-fc3560ad-661e-4d0f-91fb-e3abf2aaa587,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-bdf528b6-2c83-4259-a853-641452f3ae97,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-a9ec0225-e98e-4203-a45f-00b8702e6b89,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-903cbbae-4a1d-4ccd-a7d7-b31125229465,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850596718-172.17.0.14-1597316183431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43276,DS-8e9f03e4-b932-4e43-b4a6-6395d02583fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-7afd2060-603b-4aca-b529-985039fda0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-a0f4e111-373c-4f70-9d9c-84e318f7b167,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-b0cc5457-8c48-4984-ae76-e677ed04c5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-fc3560ad-661e-4d0f-91fb-e3abf2aaa587,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-bdf528b6-2c83-4259-a853-641452f3ae97,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-a9ec0225-e98e-4203-a45f-00b8702e6b89,DISK], DatanodeInfoWithStorage[127.0.0.1:42695,DS-903cbbae-4a1d-4ccd-a7d7-b31125229465,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2051985322-172.17.0.14-1597316327752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44258,DS-cb8d67c1-18a1-49dc-a1fe-b0fdb5432c84,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-845e9bb9-4627-457a-9ca5-b678381a0b07,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-49c2f2ab-2728-4dd7-8f75-6eb02803d47b,DISK], DatanodeInfoWithStorage[127.0.0.1:35222,DS-aa12e3d1-0df0-4776-b4e4-44cf029f8097,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-8317c8bb-b2b4-495f-9b08-a6784d4ae73c,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-39347b69-a55d-450a-a2ff-1c7d9d22d174,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-d5308daf-25fb-4ee2-8271-753348f98544,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-ad407a1d-fa5f-428d-b83e-3d862a81e456,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2051985322-172.17.0.14-1597316327752:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44258,DS-cb8d67c1-18a1-49dc-a1fe-b0fdb5432c84,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-845e9bb9-4627-457a-9ca5-b678381a0b07,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-49c2f2ab-2728-4dd7-8f75-6eb02803d47b,DISK], DatanodeInfoWithStorage[127.0.0.1:35222,DS-aa12e3d1-0df0-4776-b4e4-44cf029f8097,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-8317c8bb-b2b4-495f-9b08-a6784d4ae73c,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-39347b69-a55d-450a-a2ff-1c7d9d22d174,DISK], DatanodeInfoWithStorage[127.0.0.1:37536,DS-d5308daf-25fb-4ee2-8271-753348f98544,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-ad407a1d-fa5f-428d-b83e-3d862a81e456,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5606
