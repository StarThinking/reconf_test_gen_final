reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-467489189-172.17.0.13-1597379190957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43975,DS-373f2df0-f75e-4fe1-b464-9f33496822d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-089d8689-f90d-4207-85fe-4d5a778f8fee,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-73000c46-971d-417a-b097-f99652663593,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-b782252c-487d-44ed-8868-cee4244f2bec,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-8bfbbff7-b4cc-4013-b5e7-14f55d806bec,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-1bd8d760-8285-45b7-99ca-a32d7a88fd16,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-a680ea24-e8de-4bfe-8558-4b4ba9aebf74,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-9d87a63d-3124-49a9-9657-dad20501cc91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-467489189-172.17.0.13-1597379190957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43975,DS-373f2df0-f75e-4fe1-b464-9f33496822d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-089d8689-f90d-4207-85fe-4d5a778f8fee,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-73000c46-971d-417a-b097-f99652663593,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-b782252c-487d-44ed-8868-cee4244f2bec,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-8bfbbff7-b4cc-4013-b5e7-14f55d806bec,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-1bd8d760-8285-45b7-99ca-a32d7a88fd16,DISK], DatanodeInfoWithStorage[127.0.0.1:36670,DS-a680ea24-e8de-4bfe-8558-4b4ba9aebf74,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-9d87a63d-3124-49a9-9657-dad20501cc91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1037626610-172.17.0.13-1597379244624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44949,DS-0be4b0c5-851f-4b64-b7f3-2d29a77b81ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-830a1910-b816-48b6-ba39-0b3761f65399,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-e72cd539-de00-4255-81d3-27ef86acc3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-dc7e3a10-aa48-4948-9e5b-3575908eda6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-eeb1720a-6190-4226-8320-ce376beff6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-2f5a0254-a8d8-4bc7-9a28-581459300dac,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-b8a121be-ffcc-4044-817d-2e31783dddd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-f07f4cf8-0902-412a-89bc-057b122d2ac8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1037626610-172.17.0.13-1597379244624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44949,DS-0be4b0c5-851f-4b64-b7f3-2d29a77b81ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-830a1910-b816-48b6-ba39-0b3761f65399,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-e72cd539-de00-4255-81d3-27ef86acc3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-dc7e3a10-aa48-4948-9e5b-3575908eda6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-eeb1720a-6190-4226-8320-ce376beff6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-2f5a0254-a8d8-4bc7-9a28-581459300dac,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-b8a121be-ffcc-4044-817d-2e31783dddd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-f07f4cf8-0902-412a-89bc-057b122d2ac8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-412480469-172.17.0.13-1597379874078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44423,DS-f9046f64-09bc-4a63-9e20-9add66cea188,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-ccedb4ed-1ec9-4216-bc2c-168f8b105383,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-716e867d-d653-42b6-80d2-a07522245c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-b887cbd8-7d9e-44d6-a1f6-bc04eaca1136,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-01b328a7-43a7-484b-af84-c946200cda56,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-1e729ac1-b779-4c25-95cf-876d7046dbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-a3fe1025-41af-40cd-8589-f65bb450cfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-6c42d462-a84b-4969-8863-af972c837caa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-412480469-172.17.0.13-1597379874078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44423,DS-f9046f64-09bc-4a63-9e20-9add66cea188,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-ccedb4ed-1ec9-4216-bc2c-168f8b105383,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-716e867d-d653-42b6-80d2-a07522245c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-b887cbd8-7d9e-44d6-a1f6-bc04eaca1136,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-01b328a7-43a7-484b-af84-c946200cda56,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-1e729ac1-b779-4c25-95cf-876d7046dbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-a3fe1025-41af-40cd-8589-f65bb450cfd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-6c42d462-a84b-4969-8863-af972c837caa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-694893548-172.17.0.13-1597380180972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41172,DS-09ac0bc1-8a35-4be4-aa86-7f1936ba0863,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-cd5d4e6e-a6cd-43cc-a76a-19f893f1ee1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-ac880bda-79c0-483f-ac19-7019c01d9953,DISK], DatanodeInfoWithStorage[127.0.0.1:43419,DS-3312a064-1ffe-4eb0-a657-b9ddaa7bb0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-34365bdb-8217-4275-87af-95e0d470f289,DISK], DatanodeInfoWithStorage[127.0.0.1:35295,DS-afb75976-7eac-450b-ae67-933557ecf17b,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-1c99a319-d410-4802-9d1d-63d3afbba88b,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-7ff052ba-4012-468b-a83b-bfd17539f61d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-694893548-172.17.0.13-1597380180972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41172,DS-09ac0bc1-8a35-4be4-aa86-7f1936ba0863,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-cd5d4e6e-a6cd-43cc-a76a-19f893f1ee1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-ac880bda-79c0-483f-ac19-7019c01d9953,DISK], DatanodeInfoWithStorage[127.0.0.1:43419,DS-3312a064-1ffe-4eb0-a657-b9ddaa7bb0fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-34365bdb-8217-4275-87af-95e0d470f289,DISK], DatanodeInfoWithStorage[127.0.0.1:35295,DS-afb75976-7eac-450b-ae67-933557ecf17b,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-1c99a319-d410-4802-9d1d-63d3afbba88b,DISK], DatanodeInfoWithStorage[127.0.0.1:46727,DS-7ff052ba-4012-468b-a83b-bfd17539f61d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2022224745-172.17.0.13-1597381237092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37288,DS-bf5d6b91-51b6-4ae8-8620-cbf7532493d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-2ee97241-bbc8-40b5-b079-a411f3810442,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-864b6434-7c3f-47d8-963e-ad005363126f,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-bc4d4a1f-42df-4280-bd3a-94d1864c8a58,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-ee261708-530f-4eb1-b017-709e704165b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-21f1a146-59b5-45a3-ad60-25057f601e23,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-ea48c10d-f8ab-47cc-9554-fae60fb0ef7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-9a3d337b-63c5-43b4-b13c-1f01227ae82e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2022224745-172.17.0.13-1597381237092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37288,DS-bf5d6b91-51b6-4ae8-8620-cbf7532493d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-2ee97241-bbc8-40b5-b079-a411f3810442,DISK], DatanodeInfoWithStorage[127.0.0.1:43458,DS-864b6434-7c3f-47d8-963e-ad005363126f,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-bc4d4a1f-42df-4280-bd3a-94d1864c8a58,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-ee261708-530f-4eb1-b017-709e704165b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39745,DS-21f1a146-59b5-45a3-ad60-25057f601e23,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-ea48c10d-f8ab-47cc-9554-fae60fb0ef7d,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-9a3d337b-63c5-43b4-b13c-1f01227ae82e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1658600061-172.17.0.13-1597381421988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34349,DS-662764d0-68b3-45fc-ad9b-c7fc4ce56ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-4efab6cb-a99f-4a1c-97b3-4cb7d4d90f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-5cc37f92-fb66-4ee0-902c-db90cdef6dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-83dd7d25-4f68-48c5-802f-2fda735ee91c,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-8a12dac7-bed4-41e8-b42b-d843293ba45a,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-dd16f4a7-39a9-43fa-8643-9768a16fdde9,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-b7367503-5f7c-46bd-82cd-4d28145522e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-cb1d405a-5653-4dc2-8bab-fede23382809,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1658600061-172.17.0.13-1597381421988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34349,DS-662764d0-68b3-45fc-ad9b-c7fc4ce56ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-4efab6cb-a99f-4a1c-97b3-4cb7d4d90f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36031,DS-5cc37f92-fb66-4ee0-902c-db90cdef6dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-83dd7d25-4f68-48c5-802f-2fda735ee91c,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-8a12dac7-bed4-41e8-b42b-d843293ba45a,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-dd16f4a7-39a9-43fa-8643-9768a16fdde9,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-b7367503-5f7c-46bd-82cd-4d28145522e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-cb1d405a-5653-4dc2-8bab-fede23382809,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2390633-172.17.0.13-1597381520137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38944,DS-61c6de7a-0e88-46ef-90ed-b3ebb5e35a28,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-7a3c9279-ba42-4aaa-9856-1be7cfdd4e64,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-c8b4c0ac-a02d-4361-9d62-8a57606eff03,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-9ff97f0b-ae99-42b9-ae34-2a75d5d54f42,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-f2077c48-0a45-485d-a2a6-5d558bf1846e,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-86bd5be2-8b5e-40af-bc23-16f1cd09693f,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-4cd76422-18ca-4da0-8dfa-93e55d4713df,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-e7e3ea86-73e8-4694-95dd-8e8f19dba89d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2390633-172.17.0.13-1597381520137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38944,DS-61c6de7a-0e88-46ef-90ed-b3ebb5e35a28,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-7a3c9279-ba42-4aaa-9856-1be7cfdd4e64,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-c8b4c0ac-a02d-4361-9d62-8a57606eff03,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-9ff97f0b-ae99-42b9-ae34-2a75d5d54f42,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-f2077c48-0a45-485d-a2a6-5d558bf1846e,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-86bd5be2-8b5e-40af-bc23-16f1cd09693f,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-4cd76422-18ca-4da0-8dfa-93e55d4713df,DISK], DatanodeInfoWithStorage[127.0.0.1:39477,DS-e7e3ea86-73e8-4694-95dd-8e8f19dba89d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1764032126-172.17.0.13-1597381947796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46236,DS-3122153d-6e88-4fdf-9edc-eaf99fb56454,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-7938f80b-59cd-4053-ad66-be83932fab50,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-63ff610d-bd63-4197-b374-2da1911e5552,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-f76d8dd9-7544-4506-8c9d-bc9a58a2eb73,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-4000dd5f-8fd9-48a3-83fc-a1b8f294eef9,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-c072c665-6216-4651-8a70-f40550ec886f,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-a8573e7f-b940-4c1c-94fe-c8e75a66519e,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-5c496300-4395-4488-8101-e214333ac06e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1764032126-172.17.0.13-1597381947796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46236,DS-3122153d-6e88-4fdf-9edc-eaf99fb56454,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-7938f80b-59cd-4053-ad66-be83932fab50,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-63ff610d-bd63-4197-b374-2da1911e5552,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-f76d8dd9-7544-4506-8c9d-bc9a58a2eb73,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-4000dd5f-8fd9-48a3-83fc-a1b8f294eef9,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-c072c665-6216-4651-8a70-f40550ec886f,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-a8573e7f-b940-4c1c-94fe-c8e75a66519e,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-5c496300-4395-4488-8101-e214333ac06e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1372703878-172.17.0.13-1597382428455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46171,DS-e2abb3d2-de7d-4138-960a-863053f458df,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-52b64166-8db7-431c-a53c-1015461f706b,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-d504c29d-b340-4851-99c4-2e3d2b8a2b88,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-d9b5ff49-31ea-4b97-b3dc-873a6e669391,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-ab403386-5664-417c-a568-dff800433c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-8af92a44-31d3-4f48-8789-40123f800b70,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-2e60e5b1-dd71-4b59-9437-af33c3993b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-4702e72f-ee54-439b-93c3-51ba82834c60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1372703878-172.17.0.13-1597382428455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46171,DS-e2abb3d2-de7d-4138-960a-863053f458df,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-52b64166-8db7-431c-a53c-1015461f706b,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-d504c29d-b340-4851-99c4-2e3d2b8a2b88,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-d9b5ff49-31ea-4b97-b3dc-873a6e669391,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-ab403386-5664-417c-a568-dff800433c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-8af92a44-31d3-4f48-8789-40123f800b70,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-2e60e5b1-dd71-4b59-9437-af33c3993b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-4702e72f-ee54-439b-93c3-51ba82834c60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1750998813-172.17.0.13-1597382598969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42191,DS-bcac6ec0-b204-4ef6-9f82-61d5dc2d28b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-e8a2d059-65fb-43c2-955a-79b0980c1b52,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-6a390155-3b02-404e-9aa3-75dc61bd8151,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-112d738a-02d4-4069-94ad-b6ed345cb031,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-486ab706-1501-4db7-9196-c688b5c7f6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-b7e32e54-065a-4c20-a28f-10abbea0e80c,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-b3f84306-c424-4b2a-ac26-002eebdbae10,DISK], DatanodeInfoWithStorage[127.0.0.1:37208,DS-85549340-556e-4deb-92e8-bcf1914c54fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1750998813-172.17.0.13-1597382598969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42191,DS-bcac6ec0-b204-4ef6-9f82-61d5dc2d28b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-e8a2d059-65fb-43c2-955a-79b0980c1b52,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-6a390155-3b02-404e-9aa3-75dc61bd8151,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-112d738a-02d4-4069-94ad-b6ed345cb031,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-486ab706-1501-4db7-9196-c688b5c7f6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-b7e32e54-065a-4c20-a28f-10abbea0e80c,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-b3f84306-c424-4b2a-ac26-002eebdbae10,DISK], DatanodeInfoWithStorage[127.0.0.1:37208,DS-85549340-556e-4deb-92e8-bcf1914c54fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1928735670-172.17.0.13-1597382679758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42665,DS-07ccb9e3-5c78-4002-afba-af938eb06727,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-3e97d2df-83c4-420f-87f7-e8c0e8b1332c,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-210d5f5f-e160-4df5-9b47-8cee2d1f4820,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-b71b63bd-c0b5-459f-b7d2-b13c5011882f,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-e83aab0d-4558-46df-b23b-5bd1c58577af,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-ac554a5d-d61b-4a70-bc9f-828152aa3aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-5f326459-ad70-4a18-955f-9567f5639ede,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-228d3320-da80-44bb-91d4-2233ad82d841,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1928735670-172.17.0.13-1597382679758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42665,DS-07ccb9e3-5c78-4002-afba-af938eb06727,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-3e97d2df-83c4-420f-87f7-e8c0e8b1332c,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-210d5f5f-e160-4df5-9b47-8cee2d1f4820,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-b71b63bd-c0b5-459f-b7d2-b13c5011882f,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-e83aab0d-4558-46df-b23b-5bd1c58577af,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-ac554a5d-d61b-4a70-bc9f-828152aa3aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-5f326459-ad70-4a18-955f-9567f5639ede,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-228d3320-da80-44bb-91d4-2233ad82d841,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1828016732-172.17.0.13-1597383368675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40834,DS-190c9581-4910-41a9-9337-ef4c3fe0451a,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-6cd83887-c68b-41f3-a936-b5d5fc7b309f,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-d32d16f7-1278-4a7f-bf30-a0f331591d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-069a2ea8-77bf-4494-ae10-0c2e68dc1260,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-ca7b046b-b217-4140-a261-c892c1a85357,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-53331ee1-6321-497b-8da9-428c0c2248ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-90d046e7-9cae-4008-8e2f-356155fd6858,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-45e987af-6bcc-44bf-93be-38618d408d5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1828016732-172.17.0.13-1597383368675:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40834,DS-190c9581-4910-41a9-9337-ef4c3fe0451a,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-6cd83887-c68b-41f3-a936-b5d5fc7b309f,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-d32d16f7-1278-4a7f-bf30-a0f331591d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38496,DS-069a2ea8-77bf-4494-ae10-0c2e68dc1260,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-ca7b046b-b217-4140-a261-c892c1a85357,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-53331ee1-6321-497b-8da9-428c0c2248ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-90d046e7-9cae-4008-8e2f-356155fd6858,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-45e987af-6bcc-44bf-93be-38618d408d5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448560582-172.17.0.13-1597383507900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32829,DS-e04b537f-b699-421d-8d3f-6b2a0dc90f71,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-9eba2ad3-9297-4b64-ac03-715ee23f7993,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-b3bb9044-e80f-4fc7-a7f4-4a23f415f7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-a9024f4a-13e3-4010-8443-8d8e9895b733,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-487dc387-1fde-417c-8f9a-fea5f03bd13f,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-411e5f67-5250-4b56-8ce2-7d9e012464a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-85a773ed-2bc0-424d-8a2f-4886cfb38c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-3f098da0-f50f-4ab5-8cec-8594313958d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448560582-172.17.0.13-1597383507900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32829,DS-e04b537f-b699-421d-8d3f-6b2a0dc90f71,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-9eba2ad3-9297-4b64-ac03-715ee23f7993,DISK], DatanodeInfoWithStorage[127.0.0.1:32831,DS-b3bb9044-e80f-4fc7-a7f4-4a23f415f7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-a9024f4a-13e3-4010-8443-8d8e9895b733,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-487dc387-1fde-417c-8f9a-fea5f03bd13f,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-411e5f67-5250-4b56-8ce2-7d9e012464a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-85a773ed-2bc0-424d-8a2f-4886cfb38c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-3f098da0-f50f-4ab5-8cec-8594313958d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597813725-172.17.0.13-1597383699245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35570,DS-6ddd01f1-3379-4499-adda-5aaf3bd0236b,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-01a0e294-9135-4a9e-a48c-2686e4bb90fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-e04e09d1-c61f-4763-bbb5-13f5fa8f7bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-1c61871b-5f1c-40ab-839c-f3df34d08225,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-b92ca242-d00c-480c-8cd5-5b7e2093b40d,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-8d00c599-2fc2-443c-bc2c-7945b4589e73,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-897b9c38-782d-45ec-9af1-00778f3fadbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-9dcae598-5384-4085-9979-39be15ae9b2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597813725-172.17.0.13-1597383699245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35570,DS-6ddd01f1-3379-4499-adda-5aaf3bd0236b,DISK], DatanodeInfoWithStorage[127.0.0.1:40885,DS-01a0e294-9135-4a9e-a48c-2686e4bb90fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-e04e09d1-c61f-4763-bbb5-13f5fa8f7bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-1c61871b-5f1c-40ab-839c-f3df34d08225,DISK], DatanodeInfoWithStorage[127.0.0.1:37727,DS-b92ca242-d00c-480c-8cd5-5b7e2093b40d,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-8d00c599-2fc2-443c-bc2c-7945b4589e73,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-897b9c38-782d-45ec-9af1-00778f3fadbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-9dcae598-5384-4085-9979-39be15ae9b2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1419853432-172.17.0.13-1597383844529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44413,DS-94688037-80de-43b2-a835-7fb4bbad557b,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-64ef6e98-fe6c-4027-8df4-c8afd5775033,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-02dcc536-58cb-4d00-ace1-026d7ad63524,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-55633c5a-4817-4ea9-ac91-310253e2bca7,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-242b4ca7-a3d6-419c-b7dc-391123081f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-98eda4aa-b081-4c78-8d3a-02a536551c66,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-2e3db1a3-1dd9-4159-b838-1b2c15e8c415,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-0755cd87-a0e1-45cc-ab58-2b40b92bd484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1419853432-172.17.0.13-1597383844529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44413,DS-94688037-80de-43b2-a835-7fb4bbad557b,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-64ef6e98-fe6c-4027-8df4-c8afd5775033,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-02dcc536-58cb-4d00-ace1-026d7ad63524,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-55633c5a-4817-4ea9-ac91-310253e2bca7,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-242b4ca7-a3d6-419c-b7dc-391123081f8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-98eda4aa-b081-4c78-8d3a-02a536551c66,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-2e3db1a3-1dd9-4159-b838-1b2c15e8c415,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-0755cd87-a0e1-45cc-ab58-2b40b92bd484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2022425012-172.17.0.13-1597384108679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42668,DS-1086e76a-0556-41a4-9388-6dae96555ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-3f94afd0-e565-4285-bccd-160d31d9ddfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-bc0bc0af-d89f-44a4-b959-825f62873de7,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-d6dacde7-7dba-4ed8-b203-a836f38ffea8,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-5ee656ca-600f-4507-b1ea-a5f966de6391,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-61e797ad-316e-4c7f-b4d3-f44dbcb6bfac,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-3ee00698-d548-4588-b5dc-1d97b1d889cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-f25a7a0f-4289-42f7-9a0b-4bb33fd1bbd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2022425012-172.17.0.13-1597384108679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42668,DS-1086e76a-0556-41a4-9388-6dae96555ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-3f94afd0-e565-4285-bccd-160d31d9ddfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-bc0bc0af-d89f-44a4-b959-825f62873de7,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-d6dacde7-7dba-4ed8-b203-a836f38ffea8,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-5ee656ca-600f-4507-b1ea-a5f966de6391,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-61e797ad-316e-4c7f-b4d3-f44dbcb6bfac,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-3ee00698-d548-4588-b5dc-1d97b1d889cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46605,DS-f25a7a0f-4289-42f7-9a0b-4bb33fd1bbd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-607241324-172.17.0.13-1597384449396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39594,DS-60a75448-f32c-4590-84b6-f43c6e4ad7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-6932a009-5422-4554-8ffd-4dccaa39fca3,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-12014940-666f-4da5-83b0-6798f158b463,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-b162f174-5ceb-43e6-81e8-1286604d394b,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-7a6f0a10-8dd4-4a33-af4c-1cb4efc53ede,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-8daafcf5-1ec2-4b1a-ac7f-5768be1aa29d,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-104a08ad-7e73-44cd-ab03-79fbd98224be,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-416d61f3-eeb4-4d47-9d2b-70a30ea849f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-607241324-172.17.0.13-1597384449396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39594,DS-60a75448-f32c-4590-84b6-f43c6e4ad7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44616,DS-6932a009-5422-4554-8ffd-4dccaa39fca3,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-12014940-666f-4da5-83b0-6798f158b463,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-b162f174-5ceb-43e6-81e8-1286604d394b,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-7a6f0a10-8dd4-4a33-af4c-1cb4efc53ede,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-8daafcf5-1ec2-4b1a-ac7f-5768be1aa29d,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-104a08ad-7e73-44cd-ab03-79fbd98224be,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-416d61f3-eeb4-4d47-9d2b-70a30ea849f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-712422862-172.17.0.13-1597384487370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45472,DS-c78f7f6f-8b6a-4058-85ec-31b0ddf75eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-23cb01ce-f681-4812-a1b3-ae04f0f72714,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-4e1ee9ce-a498-402c-8b65-e587480e821a,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-cb7c2469-4a00-4747-9548-f51ce72575e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-9cc8a002-fbd1-4603-be56-79e77e785ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-179624f2-5ac4-45c2-bad5-ca9a8161fc03,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-f3bcfea3-54e5-4bf1-a492-11f69334cf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-e05e27e7-c522-4abd-ad26-9cf0678f8d40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-712422862-172.17.0.13-1597384487370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45472,DS-c78f7f6f-8b6a-4058-85ec-31b0ddf75eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46732,DS-23cb01ce-f681-4812-a1b3-ae04f0f72714,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-4e1ee9ce-a498-402c-8b65-e587480e821a,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-cb7c2469-4a00-4747-9548-f51ce72575e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-9cc8a002-fbd1-4603-be56-79e77e785ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-179624f2-5ac4-45c2-bad5-ca9a8161fc03,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-f3bcfea3-54e5-4bf1-a492-11f69334cf6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-e05e27e7-c522-4abd-ad26-9cf0678f8d40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-771233890-172.17.0.13-1597384970509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41583,DS-1217ee24-9121-4d4e-b1cc-8c4eb3104bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-f09d7c67-ca8f-4e06-87f7-9aae201f07d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-023e3c33-f0c1-4b13-adf0-33420329eb40,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-87ab490a-a0b3-4efc-969e-8c832deb8101,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-d90415b0-9e90-4b1b-ab24-71013274f6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-70cffefc-2bbd-465f-8bf3-4a79414b8d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-980f3c61-6068-4ced-9bb7-1071c574db91,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-d8180cd4-52ba-4734-852c-a378959435c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-771233890-172.17.0.13-1597384970509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41583,DS-1217ee24-9121-4d4e-b1cc-8c4eb3104bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-f09d7c67-ca8f-4e06-87f7-9aae201f07d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-023e3c33-f0c1-4b13-adf0-33420329eb40,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-87ab490a-a0b3-4efc-969e-8c832deb8101,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-d90415b0-9e90-4b1b-ab24-71013274f6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-70cffefc-2bbd-465f-8bf3-4a79414b8d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-980f3c61-6068-4ced-9bb7-1071c574db91,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-d8180cd4-52ba-4734-852c-a378959435c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.heartbeat.interval
component: hdfs:DataNode
v1: 3
v2: 30ms
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-203810689-172.17.0.13-1597385511184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43839,DS-ebb295a4-cbdc-4fa2-9ffd-90e53a6d6b44,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-20b499a2-74c2-4513-af18-977d5f6bf656,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-dbcd0b83-1d77-40fb-a828-16d6698755d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-a25adf63-5b00-4f66-ba3b-a15075fae833,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-8c36aee2-5cc8-4ebe-8541-f1c3a807b6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-3f0bbf8a-eb3e-4782-a097-de7fd09a847d,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-664eeeff-f887-48e1-b8fd-f3b95eb1e60a,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-9ae192df-e953-42f0-bff0-4152c01171a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-203810689-172.17.0.13-1597385511184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43839,DS-ebb295a4-cbdc-4fa2-9ffd-90e53a6d6b44,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-20b499a2-74c2-4513-af18-977d5f6bf656,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-dbcd0b83-1d77-40fb-a828-16d6698755d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-a25adf63-5b00-4f66-ba3b-a15075fae833,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-8c36aee2-5cc8-4ebe-8541-f1c3a807b6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-3f0bbf8a-eb3e-4782-a097-de7fd09a847d,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-664eeeff-f887-48e1-b8fd-f3b95eb1e60a,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-9ae192df-e953-42f0-bff0-4152c01171a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 7036
