reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1192807738-172.17.0.18-1597273981643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45461,DS-c96aef04-7989-4ba6-a6d7-a7c8e0451389,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-23131f7d-8124-4dbe-a37a-9b296b5851bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-f6e11523-8def-42de-ac85-2319f845833f,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-2f763d6c-502c-47e9-a82f-a5ab7291e17f,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-032538eb-9c5f-4a4b-bc64-aab3fc133455,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-76d95b91-a839-47ab-8a29-de785ead9937,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-d8e25e6f-62e1-48fc-bc59-cbee9182bfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-cbce65c2-7dff-4fbc-8835-275427ec5cf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1192807738-172.17.0.18-1597273981643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45461,DS-c96aef04-7989-4ba6-a6d7-a7c8e0451389,DISK], DatanodeInfoWithStorage[127.0.0.1:41005,DS-23131f7d-8124-4dbe-a37a-9b296b5851bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39505,DS-f6e11523-8def-42de-ac85-2319f845833f,DISK], DatanodeInfoWithStorage[127.0.0.1:36193,DS-2f763d6c-502c-47e9-a82f-a5ab7291e17f,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-032538eb-9c5f-4a4b-bc64-aab3fc133455,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-76d95b91-a839-47ab-8a29-de785ead9937,DISK], DatanodeInfoWithStorage[127.0.0.1:42707,DS-d8e25e6f-62e1-48fc-bc59-cbee9182bfd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-cbce65c2-7dff-4fbc-8835-275427ec5cf2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-979769833-172.17.0.18-1597274549825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37918,DS-933f8c63-0902-4747-a566-37112e3c65a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-29a87545-8f93-4d94-ba45-29662e4a2da0,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-00e1235b-2044-480c-8801-949942bfcca5,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-a2e9d9ca-cf79-4036-84cb-b50ddce08943,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-0287774f-5ae8-44ac-b11a-8d3126782106,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-6c76d1ae-f1df-4819-b141-1f0ab5450ece,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-c37b9881-05e8-47d1-8e79-94117b21f507,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-5e4f11bc-fee8-406b-8e25-5e84345923a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-979769833-172.17.0.18-1597274549825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37918,DS-933f8c63-0902-4747-a566-37112e3c65a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-29a87545-8f93-4d94-ba45-29662e4a2da0,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-00e1235b-2044-480c-8801-949942bfcca5,DISK], DatanodeInfoWithStorage[127.0.0.1:39134,DS-a2e9d9ca-cf79-4036-84cb-b50ddce08943,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-0287774f-5ae8-44ac-b11a-8d3126782106,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-6c76d1ae-f1df-4819-b141-1f0ab5450ece,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-c37b9881-05e8-47d1-8e79-94117b21f507,DISK], DatanodeInfoWithStorage[127.0.0.1:37144,DS-5e4f11bc-fee8-406b-8e25-5e84345923a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1835271506-172.17.0.18-1597274658895:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43640,DS-a6d32609-74e2-4e5a-bd40-83c377156ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-01bef16b-42f5-47c6-adac-2f21f25c7360,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-861ca65d-d35c-4ac7-8323-8daf0c48361e,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-130d87d5-25b2-4044-bf28-b679a13de0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-de95c633-f226-4dec-a0bd-4d78e3a15df0,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-de3ad642-f07b-48c9-9a46-7b2676898c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-aab336ac-39a8-47fb-aaaa-336231cab200,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-488fe61c-9588-4c88-bf26-ea30d567cf21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1835271506-172.17.0.18-1597274658895:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43640,DS-a6d32609-74e2-4e5a-bd40-83c377156ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-01bef16b-42f5-47c6-adac-2f21f25c7360,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-861ca65d-d35c-4ac7-8323-8daf0c48361e,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-130d87d5-25b2-4044-bf28-b679a13de0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:46355,DS-de95c633-f226-4dec-a0bd-4d78e3a15df0,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-de3ad642-f07b-48c9-9a46-7b2676898c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-aab336ac-39a8-47fb-aaaa-336231cab200,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-488fe61c-9588-4c88-bf26-ea30d567cf21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-530915804-172.17.0.18-1597274721455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43855,DS-068c8d3d-db5b-442b-8fcb-d9fd244253f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-bcb2399c-06c0-43fb-9b84-886591e74649,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-b870d4ba-b3a3-4b60-8c9b-a1974f7718e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-e0433bc0-aaf3-4667-a6d6-456bf1a87a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-b8123b5f-3b4b-44c7-bd0e-bd369f8ca249,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-2049da24-8a23-49e7-ad6b-ef58158d6dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-f7e0a37b-c555-48da-9d44-78b37ea28da2,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-6dc43f4e-e72d-4761-94dc-4b25dad4d973,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-530915804-172.17.0.18-1597274721455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43855,DS-068c8d3d-db5b-442b-8fcb-d9fd244253f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-bcb2399c-06c0-43fb-9b84-886591e74649,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-b870d4ba-b3a3-4b60-8c9b-a1974f7718e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-e0433bc0-aaf3-4667-a6d6-456bf1a87a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-b8123b5f-3b4b-44c7-bd0e-bd369f8ca249,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-2049da24-8a23-49e7-ad6b-ef58158d6dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-f7e0a37b-c555-48da-9d44-78b37ea28da2,DISK], DatanodeInfoWithStorage[127.0.0.1:46528,DS-6dc43f4e-e72d-4761-94dc-4b25dad4d973,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1876645705-172.17.0.18-1597275083746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34668,DS-2a9c176f-0f46-4894-88db-0f462e3b1d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-4c7a010f-c994-4657-b59f-f33fb9890733,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-a62512d2-e58f-4b4b-a79f-88ebcf544cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-aaf5b84e-d83b-43f0-9161-375ac78b76f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-cbaee142-9d8e-4fbc-a470-c5667fa386a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-8b895d3a-719f-4869-afb5-f4ee97f5107a,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-14ee0d9f-58b1-49e9-bee2-444e84f3724e,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-aaffd340-d962-4b1b-9d6d-3566aef1f1a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1876645705-172.17.0.18-1597275083746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34668,DS-2a9c176f-0f46-4894-88db-0f462e3b1d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-4c7a010f-c994-4657-b59f-f33fb9890733,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-a62512d2-e58f-4b4b-a79f-88ebcf544cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-aaf5b84e-d83b-43f0-9161-375ac78b76f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-cbaee142-9d8e-4fbc-a470-c5667fa386a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-8b895d3a-719f-4869-afb5-f4ee97f5107a,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-14ee0d9f-58b1-49e9-bee2-444e84f3724e,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-aaffd340-d962-4b1b-9d6d-3566aef1f1a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-32126559-172.17.0.18-1597276011309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34753,DS-706f5a69-5186-4755-80c4-e6b74fe04457,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-aac7792f-1acb-4119-999d-9110c122918b,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-ee70dcfd-1cf2-45df-8086-0d298d0babae,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-bcc5dea6-6a88-42d5-9432-a779a4b808ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-0cbd72c3-3ec8-4a16-8f70-4acf137ed7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-f059b5c0-b953-4fc9-ba22-8f6161da801e,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-7e8b0e18-35ac-46e4-bb99-112e9a20a16a,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-7af85aaa-e71f-49b4-b58d-adab31256e03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-32126559-172.17.0.18-1597276011309:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34753,DS-706f5a69-5186-4755-80c4-e6b74fe04457,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-aac7792f-1acb-4119-999d-9110c122918b,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-ee70dcfd-1cf2-45df-8086-0d298d0babae,DISK], DatanodeInfoWithStorage[127.0.0.1:37541,DS-bcc5dea6-6a88-42d5-9432-a779a4b808ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-0cbd72c3-3ec8-4a16-8f70-4acf137ed7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-f059b5c0-b953-4fc9-ba22-8f6161da801e,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-7e8b0e18-35ac-46e4-bb99-112e9a20a16a,DISK], DatanodeInfoWithStorage[127.0.0.1:45334,DS-7af85aaa-e71f-49b4-b58d-adab31256e03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1363855258-172.17.0.18-1597276273544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34388,DS-37af8e94-ac60-4c7d-bd36-fe8fb1e56b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-3df2323d-eb0f-4e55-b074-9d47796ca125,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-e50400c8-6b95-4bfc-8709-c126d49a43d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-60ece732-d74e-4859-9320-18e284879733,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-021c0474-0b5a-4963-8128-ca5a12e18303,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-95d22993-0feb-4403-9e6a-c711f6e1572c,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-20445a48-cc9f-444b-b16c-21839ac53020,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-693c8f77-13dd-41ba-bdce-60e9eb1129fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1363855258-172.17.0.18-1597276273544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34388,DS-37af8e94-ac60-4c7d-bd36-fe8fb1e56b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-3df2323d-eb0f-4e55-b074-9d47796ca125,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-e50400c8-6b95-4bfc-8709-c126d49a43d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-60ece732-d74e-4859-9320-18e284879733,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-021c0474-0b5a-4963-8128-ca5a12e18303,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-95d22993-0feb-4403-9e6a-c711f6e1572c,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-20445a48-cc9f-444b-b16c-21839ac53020,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-693c8f77-13dd-41ba-bdce-60e9eb1129fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1098835228-172.17.0.18-1597276380916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43186,DS-533f31a7-3c83-40ce-94ce-d73a88bdbab3,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-c14c5958-b277-487e-a38c-9cb1ed51267c,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-0ffa32ca-d39f-4d47-9f14-d3c06ddb4016,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-998f9c1e-921c-46fc-a8c2-ce2c3ee2ab64,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-7dec4704-6edc-44e5-9ee7-224cd1b27ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-5791a0f4-91ca-4a96-9d07-cd36d084b0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-c2720ad5-d186-4e80-a182-4b5f8ae7db4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-ca199eb9-e2eb-41a4-8b8c-71f65494d83a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1098835228-172.17.0.18-1597276380916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43186,DS-533f31a7-3c83-40ce-94ce-d73a88bdbab3,DISK], DatanodeInfoWithStorage[127.0.0.1:39398,DS-c14c5958-b277-487e-a38c-9cb1ed51267c,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-0ffa32ca-d39f-4d47-9f14-d3c06ddb4016,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-998f9c1e-921c-46fc-a8c2-ce2c3ee2ab64,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-7dec4704-6edc-44e5-9ee7-224cd1b27ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-5791a0f4-91ca-4a96-9d07-cd36d084b0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44070,DS-c2720ad5-d186-4e80-a182-4b5f8ae7db4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-ca199eb9-e2eb-41a4-8b8c-71f65494d83a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2074485698-172.17.0.18-1597276568485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44540,DS-8e731a97-6ed4-498b-9ab7-fd8d8b7a1fef,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-56950e71-f16f-4924-9712-834be707394f,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-2711dea1-80aa-474e-9b19-c7982bd34822,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-e01dda0e-60fc-438e-8b54-41939a44a64e,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-85a529bb-67c0-47e1-8e3f-c5904f473169,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-940a3141-7c39-4d68-80a6-00735449cc16,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-61d76437-9d87-436e-b884-412b015f59af,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-4cf2f7da-90f0-4fe5-bb87-830a2e29f424,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2074485698-172.17.0.18-1597276568485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44540,DS-8e731a97-6ed4-498b-9ab7-fd8d8b7a1fef,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-56950e71-f16f-4924-9712-834be707394f,DISK], DatanodeInfoWithStorage[127.0.0.1:43912,DS-2711dea1-80aa-474e-9b19-c7982bd34822,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-e01dda0e-60fc-438e-8b54-41939a44a64e,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-85a529bb-67c0-47e1-8e3f-c5904f473169,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-940a3141-7c39-4d68-80a6-00735449cc16,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-61d76437-9d87-436e-b884-412b015f59af,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-4cf2f7da-90f0-4fe5-bb87-830a2e29f424,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-208569009-172.17.0.18-1597276791635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34315,DS-b1b4f855-eb78-483c-be5f-99003f95ec0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-6a389968-4a7f-4031-9afe-802579d0858c,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-137ebb7f-f2c1-43f0-905a-da7e9032a18a,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-2df8c708-4aba-4a8c-8051-6af958c824c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-0b27568f-3f8c-4c05-9d02-3074f010ec78,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-0ffc887b-48b6-48be-8bfa-1b8a5f2f9363,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-d9c25560-0363-474c-a402-b8a78294d2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-bc1eb1e7-50da-4731-b77d-cadce6d5c1f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-208569009-172.17.0.18-1597276791635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34315,DS-b1b4f855-eb78-483c-be5f-99003f95ec0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-6a389968-4a7f-4031-9afe-802579d0858c,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-137ebb7f-f2c1-43f0-905a-da7e9032a18a,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-2df8c708-4aba-4a8c-8051-6af958c824c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-0b27568f-3f8c-4c05-9d02-3074f010ec78,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-0ffc887b-48b6-48be-8bfa-1b8a5f2f9363,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-d9c25560-0363-474c-a402-b8a78294d2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45126,DS-bc1eb1e7-50da-4731-b77d-cadce6d5c1f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1509553116-172.17.0.18-1597277208205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46680,DS-218e2645-b5ed-4bb4-95d8-9e30d7ad94a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-fe9eeef4-172f-41fd-85ea-8e4595c4a7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-8bc18183-9fbc-45a0-a5f2-4053ac69f651,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-8c6c96d2-894c-4a95-8201-8173287c6467,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-d6f63655-b69b-40aa-a42a-635c1d7d5dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-331ec528-b6ee-4cba-a572-d3dac009cb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-5b4264ee-6f9a-4409-b2bf-a04e4bf09311,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-52220509-b7f9-4146-911c-45c15e35d691,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1509553116-172.17.0.18-1597277208205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46680,DS-218e2645-b5ed-4bb4-95d8-9e30d7ad94a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-fe9eeef4-172f-41fd-85ea-8e4595c4a7c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-8bc18183-9fbc-45a0-a5f2-4053ac69f651,DISK], DatanodeInfoWithStorage[127.0.0.1:36931,DS-8c6c96d2-894c-4a95-8201-8173287c6467,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-d6f63655-b69b-40aa-a42a-635c1d7d5dd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-331ec528-b6ee-4cba-a572-d3dac009cb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-5b4264ee-6f9a-4409-b2bf-a04e4bf09311,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-52220509-b7f9-4146-911c-45c15e35d691,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-567778032-172.17.0.18-1597277543187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46631,DS-c54fb30c-5851-423b-b8d5-c7b1042f7375,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-48ab542c-28f9-4a5b-8853-a0b41a542d27,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-e18ae77a-d972-48a1-96c5-241d8b60dd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-646d1124-4a72-4002-ba84-9eba897a2f21,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-9d6110fd-e050-45f3-a806-6b74c1db5c81,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-7416e064-4ec6-4ae0-86e0-1717eba46884,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-7e464092-bf88-42e6-9145-b5eb252a378a,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-8ef3ea21-8471-4d93-9db5-de1f0400c041,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-567778032-172.17.0.18-1597277543187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46631,DS-c54fb30c-5851-423b-b8d5-c7b1042f7375,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-48ab542c-28f9-4a5b-8853-a0b41a542d27,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-e18ae77a-d972-48a1-96c5-241d8b60dd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43771,DS-646d1124-4a72-4002-ba84-9eba897a2f21,DISK], DatanodeInfoWithStorage[127.0.0.1:45206,DS-9d6110fd-e050-45f3-a806-6b74c1db5c81,DISK], DatanodeInfoWithStorage[127.0.0.1:45864,DS-7416e064-4ec6-4ae0-86e0-1717eba46884,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-7e464092-bf88-42e6-9145-b5eb252a378a,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-8ef3ea21-8471-4d93-9db5-de1f0400c041,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1428654306-172.17.0.18-1597277702880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32899,DS-8d9861db-7472-46ab-b3ba-bd60eb8cc672,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-b52e0c24-e827-482f-9b9f-b08b07f1320a,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-df378902-747d-484b-9248-91fa676b5736,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-dc03b07c-da93-477b-bbab-55a2cb18adef,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-98553d38-1fa4-4935-9e94-fca8ccb7ee80,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-d6fc8167-abae-4742-922a-751c0e31d4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-0ec0957b-3112-44b5-980b-18865e9ff563,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-16cf7e0c-7a04-4155-a291-550b4758ce94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1428654306-172.17.0.18-1597277702880:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32899,DS-8d9861db-7472-46ab-b3ba-bd60eb8cc672,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-b52e0c24-e827-482f-9b9f-b08b07f1320a,DISK], DatanodeInfoWithStorage[127.0.0.1:38669,DS-df378902-747d-484b-9248-91fa676b5736,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-dc03b07c-da93-477b-bbab-55a2cb18adef,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-98553d38-1fa4-4935-9e94-fca8ccb7ee80,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-d6fc8167-abae-4742-922a-751c0e31d4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-0ec0957b-3112-44b5-980b-18865e9ff563,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-16cf7e0c-7a04-4155-a291-550b4758ce94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-681309276-172.17.0.18-1597278233820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41047,DS-09d3bd38-0470-4a04-9fc9-46509a642e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-0b33b845-9510-4dcc-a3e9-3b7c9d504e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-7b4eb313-8701-40c6-85f4-0f4032dcfc23,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-d29376b2-1e2f-44ae-ad39-09ac81e7b9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-d16359ea-cb66-45a8-8d8d-4995494a3e67,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-361c310f-ca70-42c7-b1b0-d5a831b1818b,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-90aafe10-1525-44a5-8a37-a8f48bf9e63a,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-4419b46d-22f2-4020-9183-c3fb2e381a31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-681309276-172.17.0.18-1597278233820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41047,DS-09d3bd38-0470-4a04-9fc9-46509a642e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-0b33b845-9510-4dcc-a3e9-3b7c9d504e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-7b4eb313-8701-40c6-85f4-0f4032dcfc23,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-d29376b2-1e2f-44ae-ad39-09ac81e7b9f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-d16359ea-cb66-45a8-8d8d-4995494a3e67,DISK], DatanodeInfoWithStorage[127.0.0.1:43311,DS-361c310f-ca70-42c7-b1b0-d5a831b1818b,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-90aafe10-1525-44a5-8a37-a8f48bf9e63a,DISK], DatanodeInfoWithStorage[127.0.0.1:46594,DS-4419b46d-22f2-4020-9183-c3fb2e381a31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5548
