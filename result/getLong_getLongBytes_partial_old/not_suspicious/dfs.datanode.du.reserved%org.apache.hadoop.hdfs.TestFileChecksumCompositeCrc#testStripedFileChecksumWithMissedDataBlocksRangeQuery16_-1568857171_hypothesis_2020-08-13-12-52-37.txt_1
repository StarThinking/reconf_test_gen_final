reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-977117322-172.17.0.13-1597323983250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43347,DS-7424e8f8-c577-45d3-a79b-ba7b133f0bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-03cf3cd9-9284-4bd3-b4ce-e152d018490f,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-69f3c62f-d790-4a63-aad1-cd511c782f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33751,DS-c62954c8-c8dd-4dbb-aaf6-4fe1d4377c55,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-2bbd628c-447c-4b03-b6be-ed414b752cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-8d9209f6-43dc-4974-89d3-c1725d7945e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-a490d47c-bea1-46fb-a502-df0f552c797b,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-49a95b64-1f17-44bd-9e67-c8e5cc9996d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-977117322-172.17.0.13-1597323983250:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43347,DS-7424e8f8-c577-45d3-a79b-ba7b133f0bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36168,DS-03cf3cd9-9284-4bd3-b4ce-e152d018490f,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-69f3c62f-d790-4a63-aad1-cd511c782f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33751,DS-c62954c8-c8dd-4dbb-aaf6-4fe1d4377c55,DISK], DatanodeInfoWithStorage[127.0.0.1:37595,DS-2bbd628c-447c-4b03-b6be-ed414b752cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-8d9209f6-43dc-4974-89d3-c1725d7945e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-a490d47c-bea1-46fb-a502-df0f552c797b,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-49a95b64-1f17-44bd-9e67-c8e5cc9996d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1997598533-172.17.0.13-1597324685961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36195,DS-cc1095fd-b84f-4e22-8bcd-9ac6df4d7128,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-13ab887b-f850-41b4-928d-e1d9856220af,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-73f989f5-7fdc-428f-a463-334e6e881e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-6d1badbd-1881-40ac-9ded-9178f155c6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-ee4e4d11-8275-4af9-a7bf-2d176c97aee9,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-02931929-9bcb-4da1-a4ea-9178f3af6aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-ecabdbeb-81df-48cc-bff8-7a6bee976a48,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-71133f93-5bcc-467e-926c-29ec842a9f0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1997598533-172.17.0.13-1597324685961:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36195,DS-cc1095fd-b84f-4e22-8bcd-9ac6df4d7128,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-13ab887b-f850-41b4-928d-e1d9856220af,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-73f989f5-7fdc-428f-a463-334e6e881e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-6d1badbd-1881-40ac-9ded-9178f155c6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-ee4e4d11-8275-4af9-a7bf-2d176c97aee9,DISK], DatanodeInfoWithStorage[127.0.0.1:35333,DS-02931929-9bcb-4da1-a4ea-9178f3af6aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:33958,DS-ecabdbeb-81df-48cc-bff8-7a6bee976a48,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-71133f93-5bcc-467e-926c-29ec842a9f0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1463945677-172.17.0.13-1597325646061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36499,DS-a4a31786-4c11-41f9-9ef0-633425057b11,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-78203324-8549-4252-8cb0-e425007795e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-12c02395-be68-468d-9009-5a98b0569507,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-2bca87e5-fab7-49a6-95bb-305aae6828c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-968bb2de-abb4-4522-a810-b4bbda0a46e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-b046dd24-8a77-40a0-aa72-9fd0f352e92a,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-1e77d072-d85c-4c92-870d-f2e967af9332,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-01515cd0-5d8a-4068-a499-92904d90e827,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1463945677-172.17.0.13-1597325646061:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36499,DS-a4a31786-4c11-41f9-9ef0-633425057b11,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-78203324-8549-4252-8cb0-e425007795e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-12c02395-be68-468d-9009-5a98b0569507,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-2bca87e5-fab7-49a6-95bb-305aae6828c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-968bb2de-abb4-4522-a810-b4bbda0a46e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-b046dd24-8a77-40a0-aa72-9fd0f352e92a,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-1e77d072-d85c-4c92-870d-f2e967af9332,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-01515cd0-5d8a-4068-a499-92904d90e827,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1730772083-172.17.0.13-1597325855334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35068,DS-cdb6b694-212c-421b-ba17-86b48a5a08d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-fdd7b581-dbf2-4554-9100-149f0edacc81,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-51d367f4-a7ba-4b71-81bf-95b851d543be,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-44cd461e-fbef-47ce-948c-f4375cb40f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-501d7f85-86f8-43c9-8d4c-06dcafe2788a,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-bf0fb7c4-78a7-447a-bcb7-60ec68fadde2,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-ccb58735-7443-4c04-bcf8-086d226cb321,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-2e13301a-da73-4e20-a66b-300f610964d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1730772083-172.17.0.13-1597325855334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35068,DS-cdb6b694-212c-421b-ba17-86b48a5a08d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-fdd7b581-dbf2-4554-9100-149f0edacc81,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-51d367f4-a7ba-4b71-81bf-95b851d543be,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-44cd461e-fbef-47ce-948c-f4375cb40f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40632,DS-501d7f85-86f8-43c9-8d4c-06dcafe2788a,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-bf0fb7c4-78a7-447a-bcb7-60ec68fadde2,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-ccb58735-7443-4c04-bcf8-086d226cb321,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-2e13301a-da73-4e20-a66b-300f610964d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1336856955-172.17.0.13-1597326214048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46620,DS-a96f9b82-172f-4737-8a08-de4698dd9fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-930b297a-50f4-4f0e-9cfe-f573912449e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-90344001-f2bb-493f-bab4-ae4ead0d7c19,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-c576edb3-8e77-4d9a-b187-fc10bc23aa84,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-db2d5e24-5ffe-4d39-a982-0714b551e5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-a2aef3ed-ca36-4094-b830-9b85fe23943b,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-e4993ca7-3a88-40c9-9782-29d91bcbd180,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-951b6038-af38-4e36-b599-7de78b8dd32e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1336856955-172.17.0.13-1597326214048:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46620,DS-a96f9b82-172f-4737-8a08-de4698dd9fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-930b297a-50f4-4f0e-9cfe-f573912449e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-90344001-f2bb-493f-bab4-ae4ead0d7c19,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-c576edb3-8e77-4d9a-b187-fc10bc23aa84,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-db2d5e24-5ffe-4d39-a982-0714b551e5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-a2aef3ed-ca36-4094-b830-9b85fe23943b,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-e4993ca7-3a88-40c9-9782-29d91bcbd180,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-951b6038-af38-4e36-b599-7de78b8dd32e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-476297476-172.17.0.13-1597326584983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32848,DS-c6942c77-3bac-463c-95b9-8da90ab19a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-e84649e8-1273-494d-b568-239f6962a33b,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-7e4c9e63-e1e8-4ed9-94f3-a487974f15ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-3bff8587-68c6-4366-93bc-66d49113740c,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-73b727ab-e8e4-47e4-b67c-92b526e18f74,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-91fd0a9b-e6b9-482a-a34b-933836f42cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-60ae47b2-b55e-4d1a-a4ba-726b98345e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39999,DS-ce5fe57d-36b3-439c-b397-65e26f274fda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-476297476-172.17.0.13-1597326584983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32848,DS-c6942c77-3bac-463c-95b9-8da90ab19a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35487,DS-e84649e8-1273-494d-b568-239f6962a33b,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-7e4c9e63-e1e8-4ed9-94f3-a487974f15ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-3bff8587-68c6-4366-93bc-66d49113740c,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-73b727ab-e8e4-47e4-b67c-92b526e18f74,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-91fd0a9b-e6b9-482a-a34b-933836f42cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-60ae47b2-b55e-4d1a-a4ba-726b98345e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39999,DS-ce5fe57d-36b3-439c-b397-65e26f274fda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1498931287-172.17.0.13-1597326696607:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44685,DS-06effd42-5540-4db0-a459-fa3b09bb79fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-f1df4bf0-c010-4258-a060-aae1f10be54f,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-976b0cb1-8865-45c8-ab56-43a55bdd2b94,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-e10cb858-abd7-4e77-8b1e-4e8e8f926e86,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-284e6f65-3ecc-4a14-9373-42bc1c69bbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-ac0cd7f9-c2e9-4ba6-ae19-00dc83f89f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-8c5315ba-f6f9-4189-a9ef-0c2d19f8c466,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-65715bcf-8c63-4157-8861-eb708e6b8100,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1498931287-172.17.0.13-1597326696607:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44685,DS-06effd42-5540-4db0-a459-fa3b09bb79fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-f1df4bf0-c010-4258-a060-aae1f10be54f,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-976b0cb1-8865-45c8-ab56-43a55bdd2b94,DISK], DatanodeInfoWithStorage[127.0.0.1:36535,DS-e10cb858-abd7-4e77-8b1e-4e8e8f926e86,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-284e6f65-3ecc-4a14-9373-42bc1c69bbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-ac0cd7f9-c2e9-4ba6-ae19-00dc83f89f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-8c5315ba-f6f9-4189-a9ef-0c2d19f8c466,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-65715bcf-8c63-4157-8861-eb708e6b8100,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-965119984-172.17.0.13-1597327040034:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38842,DS-0e9ac592-89d9-4d70-860a-262a0e2839c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-433d0f8a-e84d-4327-bd0d-983a6552a612,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-16a6084f-93e3-48a2-a733-1412cb7c5cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-237bd566-5f9c-4873-b90d-1f8c5304735a,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-0b482b2d-0121-4847-b574-747df3d8d651,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-a4d261d8-1ce4-428e-b5f4-59b5ef8f7c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-715ff9c9-9fbb-42b4-9232-7628b23bd97d,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-090c9e85-1184-4240-9237-9b24a1fa84b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-965119984-172.17.0.13-1597327040034:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38842,DS-0e9ac592-89d9-4d70-860a-262a0e2839c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35192,DS-433d0f8a-e84d-4327-bd0d-983a6552a612,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-16a6084f-93e3-48a2-a733-1412cb7c5cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-237bd566-5f9c-4873-b90d-1f8c5304735a,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-0b482b2d-0121-4847-b574-747df3d8d651,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-a4d261d8-1ce4-428e-b5f4-59b5ef8f7c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:37514,DS-715ff9c9-9fbb-42b4-9232-7628b23bd97d,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-090c9e85-1184-4240-9237-9b24a1fa84b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-251518246-172.17.0.13-1597327079492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41826,DS-2ea90343-b1c9-4fed-8f05-d8d0290c11e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-c73e2660-bad0-4f99-a816-a7bccd82a3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-e4a49eba-6164-4cbd-9cda-68d2e2d7033b,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-8be20cb0-ded1-40a2-b8e5-1fc64e59860e,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-c1acde01-3a73-4c42-acd2-34d2517a2bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-821b34f2-e23b-4e2c-ac08-a7d1e59ca01d,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-859e5ff7-4e2f-430a-93db-a0ce000d7942,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-b6fba8b3-77cf-4f98-8c02-fec6af84a5d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-251518246-172.17.0.13-1597327079492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41826,DS-2ea90343-b1c9-4fed-8f05-d8d0290c11e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-c73e2660-bad0-4f99-a816-a7bccd82a3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-e4a49eba-6164-4cbd-9cda-68d2e2d7033b,DISK], DatanodeInfoWithStorage[127.0.0.1:43705,DS-8be20cb0-ded1-40a2-b8e5-1fc64e59860e,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-c1acde01-3a73-4c42-acd2-34d2517a2bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-821b34f2-e23b-4e2c-ac08-a7d1e59ca01d,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-859e5ff7-4e2f-430a-93db-a0ce000d7942,DISK], DatanodeInfoWithStorage[127.0.0.1:41081,DS-b6fba8b3-77cf-4f98-8c02-fec6af84a5d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1852165260-172.17.0.13-1597327340379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41693,DS-b1303e69-a8cb-4727-91ad-3a81259e23c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-3b29ae6b-2299-4fcc-a0e0-3c1a5f333b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-fa581180-980d-44c3-b75e-1058d0dc3485,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-5b10c651-2d4e-4228-b61b-c414c41b03e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-962e95e6-3080-4673-8eef-bd4f5dd1c765,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-1549c618-04f1-466d-9856-3c82a06c055e,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-fefec2cd-b34e-46ce-afc3-cb945552acf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-41d0fb19-6e2f-4ca6-9120-3117455ff1a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1852165260-172.17.0.13-1597327340379:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41693,DS-b1303e69-a8cb-4727-91ad-3a81259e23c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37311,DS-3b29ae6b-2299-4fcc-a0e0-3c1a5f333b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-fa581180-980d-44c3-b75e-1058d0dc3485,DISK], DatanodeInfoWithStorage[127.0.0.1:39018,DS-5b10c651-2d4e-4228-b61b-c414c41b03e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34024,DS-962e95e6-3080-4673-8eef-bd4f5dd1c765,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-1549c618-04f1-466d-9856-3c82a06c055e,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-fefec2cd-b34e-46ce-afc3-cb945552acf3,DISK], DatanodeInfoWithStorage[127.0.0.1:38757,DS-41d0fb19-6e2f-4ca6-9120-3117455ff1a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-23628335-172.17.0.13-1597327642451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43487,DS-fb8e25f4-3d22-4e28-9c9c-5fdadcd0b271,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-1c9bc38d-efc9-4e3f-aec0-015c9de90046,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-eb2dbed9-98c0-4d22-b26c-13813c4b38ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-54ba8ea0-75f9-45e3-a9f6-f0b385d30f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-a6948895-e185-4f68-917d-95c4425ae996,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-ff12706b-1c1b-4c46-b773-fcb8cb1d5a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-50740d19-2a05-4d57-8c2c-ee457eb4c9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-feb50def-5d53-4c04-82b6-d4f99f6808ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-23628335-172.17.0.13-1597327642451:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43487,DS-fb8e25f4-3d22-4e28-9c9c-5fdadcd0b271,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-1c9bc38d-efc9-4e3f-aec0-015c9de90046,DISK], DatanodeInfoWithStorage[127.0.0.1:43694,DS-eb2dbed9-98c0-4d22-b26c-13813c4b38ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-54ba8ea0-75f9-45e3-a9f6-f0b385d30f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-a6948895-e185-4f68-917d-95c4425ae996,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-ff12706b-1c1b-4c46-b773-fcb8cb1d5a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-50740d19-2a05-4d57-8c2c-ee457eb4c9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-feb50def-5d53-4c04-82b6-d4f99f6808ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-53140789-172.17.0.13-1597327892864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37855,DS-3c4a68b4-b0ac-4216-a2c1-0bf6c2768efb,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-cc1c682a-1971-4797-b7b2-386bf0cd3e42,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-1837d8dd-6637-4bd2-aac7-bcceccbe390d,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-e343023a-aa3b-47f8-a93c-55b75dc1a43b,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-681960cb-36dd-4b96-9ebb-efa1288ba195,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-d1c6c11f-0e8e-40cc-9ca0-76ad3eed19ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-2e2679b2-259b-410f-b6ba-08277614bb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-3ceb0aa9-31ed-4dd6-a46c-7dfe34a74de4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-53140789-172.17.0.13-1597327892864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37855,DS-3c4a68b4-b0ac-4216-a2c1-0bf6c2768efb,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-cc1c682a-1971-4797-b7b2-386bf0cd3e42,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-1837d8dd-6637-4bd2-aac7-bcceccbe390d,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-e343023a-aa3b-47f8-a93c-55b75dc1a43b,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-681960cb-36dd-4b96-9ebb-efa1288ba195,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-d1c6c11f-0e8e-40cc-9ca0-76ad3eed19ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-2e2679b2-259b-410f-b6ba-08277614bb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-3ceb0aa9-31ed-4dd6-a46c-7dfe34a74de4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1848573812-172.17.0.13-1597327972897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42139,DS-2c55bab8-aebe-41ac-9f46-ac2c9c54d5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-22eabc50-f6e7-4b36-9f80-8adcb1d3258c,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-138e8d46-59ae-4fce-b216-461020e109a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-0adbaca7-2262-4c09-ad1b-f971e21a4e59,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-bb359ff1-d348-40d4-b6f9-347acc2f1cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-0a66c73d-b661-44e9-96ce-6dc0c5e46f11,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-40a3efb3-ba9e-477e-80d1-2c7f870f1139,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-4cb730cc-9052-49e4-b5f3-44edadbbd138,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1848573812-172.17.0.13-1597327972897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42139,DS-2c55bab8-aebe-41ac-9f46-ac2c9c54d5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-22eabc50-f6e7-4b36-9f80-8adcb1d3258c,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-138e8d46-59ae-4fce-b216-461020e109a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-0adbaca7-2262-4c09-ad1b-f971e21a4e59,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-bb359ff1-d348-40d4-b6f9-347acc2f1cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-0a66c73d-b661-44e9-96ce-6dc0c5e46f11,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-40a3efb3-ba9e-477e-80d1-2c7f870f1139,DISK], DatanodeInfoWithStorage[127.0.0.1:45201,DS-4cb730cc-9052-49e4-b5f3-44edadbbd138,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 1048576
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-40296008-172.17.0.13-1597328352981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34622,DS-4cefde4f-534f-4158-b33e-95574b580f68,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-f9fae84a-1aed-48a8-81cc-e8281e9b9178,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-943c27e1-6392-4a88-8809-b975ce19bcec,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-f4dc9775-7c4c-4b41-8452-b089e932daaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-2ea63097-ad93-47f4-ad78-6f2fa31d6fde,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-43d6dea0-9c24-4253-92c7-94be24da409b,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-fc7fed54-134a-401e-9b3a-1ca14c8f41cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-a7e6fe3a-c94b-4161-a1fe-5ba7559433af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-40296008-172.17.0.13-1597328352981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34622,DS-4cefde4f-534f-4158-b33e-95574b580f68,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-f9fae84a-1aed-48a8-81cc-e8281e9b9178,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-943c27e1-6392-4a88-8809-b975ce19bcec,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-f4dc9775-7c4c-4b41-8452-b089e932daaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-2ea63097-ad93-47f4-ad78-6f2fa31d6fde,DISK], DatanodeInfoWithStorage[127.0.0.1:45552,DS-43d6dea0-9c24-4253-92c7-94be24da409b,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-fc7fed54-134a-401e-9b3a-1ca14c8f41cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-a7e6fe3a-c94b-4161-a1fe-5ba7559433af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5487
