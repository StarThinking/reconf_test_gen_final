reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547965279-172.17.0.3-1597523199401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44233,DS-b2eec644-f652-4085-81c5-5e90ed7f775d,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-8d364d87-70f9-4867-953f-a85082dcdd52,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-b07acd66-e0f3-4fcc-bedc-ee87f9465ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-cb947500-8a5b-4772-b2ea-0ea17ad7981a,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-8e0c20b7-a211-4dad-a832-4985b6a8ff1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-a479ddc3-2398-49d0-be5c-6ea1df7eeb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-0ad64d43-5651-4a2a-b087-11583421f9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-7b686700-84aa-4d75-bc24-aa42364fa6fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1547965279-172.17.0.3-1597523199401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44233,DS-b2eec644-f652-4085-81c5-5e90ed7f775d,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-8d364d87-70f9-4867-953f-a85082dcdd52,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-b07acd66-e0f3-4fcc-bedc-ee87f9465ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-cb947500-8a5b-4772-b2ea-0ea17ad7981a,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-8e0c20b7-a211-4dad-a832-4985b6a8ff1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36017,DS-a479ddc3-2398-49d0-be5c-6ea1df7eeb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-0ad64d43-5651-4a2a-b087-11583421f9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-7b686700-84aa-4d75-bc24-aa42364fa6fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-197715618-172.17.0.3-1597523947128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40732,DS-1fcb7243-25dd-4b19-b2fd-45ddd715596e,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-1d765a9e-7564-439c-8699-ae0201f77362,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-c083a82f-e97d-4b25-8726-541c2f8772a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-ae6a2726-1c8f-4a65-bc91-b5b44d18e7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-de5cc1f6-189c-446a-999e-8b0e13b21373,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-1c6dc033-f8b9-4728-b648-a582f9bbafa2,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-54076749-51ff-4b02-bfc2-b8c472705423,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-e66e0ce9-ec3b-43f5-8fd3-07b679d33063,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-197715618-172.17.0.3-1597523947128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40732,DS-1fcb7243-25dd-4b19-b2fd-45ddd715596e,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-1d765a9e-7564-439c-8699-ae0201f77362,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-c083a82f-e97d-4b25-8726-541c2f8772a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-ae6a2726-1c8f-4a65-bc91-b5b44d18e7c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-de5cc1f6-189c-446a-999e-8b0e13b21373,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-1c6dc033-f8b9-4728-b648-a582f9bbafa2,DISK], DatanodeInfoWithStorage[127.0.0.1:39233,DS-54076749-51ff-4b02-bfc2-b8c472705423,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-e66e0ce9-ec3b-43f5-8fd3-07b679d33063,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1836085607-172.17.0.3-1597524018433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34273,DS-d0c49d5f-06cb-4c0e-b865-d1d834e1af0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-27cdc082-95ef-4c20-bd37-0321b22d272c,DISK], DatanodeInfoWithStorage[127.0.0.1:39946,DS-3483125b-9384-462f-93f7-c5060318b842,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-47a909f2-6492-40e7-aed7-b01bbc31031f,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-e52b0868-1a43-4bfb-95aa-9aa51036d793,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-b47a3274-f571-404c-9f55-2ec81c5947b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-bbd314fd-caa2-4743-b4b6-ec1534d622e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-67223578-4f1f-4b8d-8065-804a98ff5f86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1836085607-172.17.0.3-1597524018433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34273,DS-d0c49d5f-06cb-4c0e-b865-d1d834e1af0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-27cdc082-95ef-4c20-bd37-0321b22d272c,DISK], DatanodeInfoWithStorage[127.0.0.1:39946,DS-3483125b-9384-462f-93f7-c5060318b842,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-47a909f2-6492-40e7-aed7-b01bbc31031f,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-e52b0868-1a43-4bfb-95aa-9aa51036d793,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-b47a3274-f571-404c-9f55-2ec81c5947b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-bbd314fd-caa2-4743-b4b6-ec1534d622e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-67223578-4f1f-4b8d-8065-804a98ff5f86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1705299370-172.17.0.3-1597524274595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40000,DS-c78e29eb-f276-4c00-97f7-ff4eb6de5229,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-a5970178-fd8c-461d-af39-c81a6a2013df,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-a75bcd90-bf70-4b22-8462-bb3c30813990,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-bb2079e5-269e-45f6-baac-6e919994402a,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-7530fe27-fa08-45f9-8404-553441c018ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-669b8b33-7c5c-4831-9c1a-a284307d96cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-a9c66a14-7297-48bc-87e2-bc9c912c6a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-fc88e04e-7baf-48ab-8604-b2e892f41b4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1705299370-172.17.0.3-1597524274595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40000,DS-c78e29eb-f276-4c00-97f7-ff4eb6de5229,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-a5970178-fd8c-461d-af39-c81a6a2013df,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-a75bcd90-bf70-4b22-8462-bb3c30813990,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-bb2079e5-269e-45f6-baac-6e919994402a,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-7530fe27-fa08-45f9-8404-553441c018ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-669b8b33-7c5c-4831-9c1a-a284307d96cc,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-a9c66a14-7297-48bc-87e2-bc9c912c6a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-fc88e04e-7baf-48ab-8604-b2e892f41b4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-982203443-172.17.0.3-1597525320578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45099,DS-70e0a482-f2e2-4116-a418-10519760632d,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-a647407c-0022-45bc-a926-fd2a2d7f182f,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-f53d48f9-dd76-4f77-8a05-bc6ac3c6035a,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-f16a99d4-f867-49a2-83ea-f3f0745ab9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-6b9f5d57-03d5-428d-be66-75dafea0978b,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-27e8e5f6-977f-4618-9333-3c7e618846eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-da6517b8-d311-4e9b-81f7-9b8c36399322,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-0e7f87ef-6557-4d97-886a-b27c6766aeeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-982203443-172.17.0.3-1597525320578:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45099,DS-70e0a482-f2e2-4116-a418-10519760632d,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-a647407c-0022-45bc-a926-fd2a2d7f182f,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-f53d48f9-dd76-4f77-8a05-bc6ac3c6035a,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-f16a99d4-f867-49a2-83ea-f3f0745ab9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-6b9f5d57-03d5-428d-be66-75dafea0978b,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-27e8e5f6-977f-4618-9333-3c7e618846eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34488,DS-da6517b8-d311-4e9b-81f7-9b8c36399322,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-0e7f87ef-6557-4d97-886a-b27c6766aeeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-828418227-172.17.0.3-1597525533096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42361,DS-f679707b-67e5-4a92-b8c7-b4f0ca0880f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-94bcbfdc-922a-4920-9d77-c33954e12e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-17551a5f-da08-4d62-b017-9005040b2894,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-a40ae80f-445c-4e5a-9471-1cbd64676a54,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-e90505ed-200f-412d-8823-fdd7dff81b08,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-1947092e-84f8-4ed8-afa6-19edc9cd653d,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-6673f14e-e270-405b-a87b-d74316d0da10,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-6398dfd6-a5c7-4430-83be-117c2fc7e333,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-828418227-172.17.0.3-1597525533096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42361,DS-f679707b-67e5-4a92-b8c7-b4f0ca0880f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-94bcbfdc-922a-4920-9d77-c33954e12e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-17551a5f-da08-4d62-b017-9005040b2894,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-a40ae80f-445c-4e5a-9471-1cbd64676a54,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-e90505ed-200f-412d-8823-fdd7dff81b08,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-1947092e-84f8-4ed8-afa6-19edc9cd653d,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-6673f14e-e270-405b-a87b-d74316d0da10,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-6398dfd6-a5c7-4430-83be-117c2fc7e333,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-240465108-172.17.0.3-1597525647185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36331,DS-5421c7e3-b8a4-401c-a263-080f11c25cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-57fbd011-a069-4af9-b86c-0edf39e9dde4,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-44cd584a-7bb0-4c71-9b1d-ec420882747b,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-1e36c836-2a1c-4325-bf5e-58882c08b79b,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-9278a9c1-b49c-4262-b80f-f0b422c750e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-ef54540c-25cb-40ff-b629-902b6a3ee5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-d0370901-d2e0-470d-bd81-84cd2216b250,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-ad64e44e-4b02-4b1f-bda4-926fc54fa7a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-240465108-172.17.0.3-1597525647185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36331,DS-5421c7e3-b8a4-401c-a263-080f11c25cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-57fbd011-a069-4af9-b86c-0edf39e9dde4,DISK], DatanodeInfoWithStorage[127.0.0.1:32875,DS-44cd584a-7bb0-4c71-9b1d-ec420882747b,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-1e36c836-2a1c-4325-bf5e-58882c08b79b,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-9278a9c1-b49c-4262-b80f-f0b422c750e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-ef54540c-25cb-40ff-b629-902b6a3ee5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-d0370901-d2e0-470d-bd81-84cd2216b250,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-ad64e44e-4b02-4b1f-bda4-926fc54fa7a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-507534397-172.17.0.3-1597526136885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46392,DS-659f748d-384e-45c1-affb-00671b8f3739,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-65a71d70-7b8b-4e8f-bc6e-ef5b1b1e7e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-19b0abd4-dda0-411d-879e-bd6f8c312421,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-61fe5bcc-a4b7-4629-8842-f080dbcedec2,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-cbc34c09-b955-4d63-8d9b-92b7c116e28d,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-08e7e917-0359-4eb6-b70a-5690300d58c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-be44805d-8d83-4297-8247-f04c98207674,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-99629358-0033-4e97-b4c2-e20d005610c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-507534397-172.17.0.3-1597526136885:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46392,DS-659f748d-384e-45c1-affb-00671b8f3739,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-65a71d70-7b8b-4e8f-bc6e-ef5b1b1e7e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-19b0abd4-dda0-411d-879e-bd6f8c312421,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-61fe5bcc-a4b7-4629-8842-f080dbcedec2,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-cbc34c09-b955-4d63-8d9b-92b7c116e28d,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-08e7e917-0359-4eb6-b70a-5690300d58c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-be44805d-8d83-4297-8247-f04c98207674,DISK], DatanodeInfoWithStorage[127.0.0.1:37373,DS-99629358-0033-4e97-b4c2-e20d005610c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-938050735-172.17.0.3-1597526578877:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38542,DS-89da5ca2-5036-4bf3-986d-598f64ce6ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-becd779c-3186-4a69-9169-98198f4f8ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-3303f26e-8ee5-4ee6-b49a-ae358063c95d,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-13277432-6d5c-4c3f-9b9e-e889f0a2d3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-37d1f3d2-e048-4727-a0bb-7b314eb2c4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-208c0eb4-4149-47f2-8300-67eb7e77b18a,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-d39d9209-e2b6-4cc9-aeec-582afb8e6d14,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-51ff2e7b-6494-46cd-92e8-5d11f9dd3806,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-938050735-172.17.0.3-1597526578877:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38542,DS-89da5ca2-5036-4bf3-986d-598f64ce6ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-becd779c-3186-4a69-9169-98198f4f8ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-3303f26e-8ee5-4ee6-b49a-ae358063c95d,DISK], DatanodeInfoWithStorage[127.0.0.1:41436,DS-13277432-6d5c-4c3f-9b9e-e889f0a2d3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-37d1f3d2-e048-4727-a0bb-7b314eb2c4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-208c0eb4-4149-47f2-8300-67eb7e77b18a,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-d39d9209-e2b6-4cc9-aeec-582afb8e6d14,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-51ff2e7b-6494-46cd-92e8-5d11f9dd3806,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1650657090-172.17.0.3-1597526880099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36610,DS-528ed953-aa54-4816-a1b9-85836a33585d,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-ec632133-953b-4ec0-87ed-b48a56f316ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-e6a81b4c-8617-4a37-bb87-d78fbba4d90e,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-95b071bb-63a0-40b7-931e-0cc59f375813,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-b7235cb7-874e-4043-b7ef-c11358f32539,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-a4041b99-d12c-4d57-8129-e1eaf98dc15d,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-9425cbb4-5bcf-4701-b552-f161f1e857f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-e981d0ff-312a-4517-9549-995a28a9e143,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1650657090-172.17.0.3-1597526880099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36610,DS-528ed953-aa54-4816-a1b9-85836a33585d,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-ec632133-953b-4ec0-87ed-b48a56f316ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39799,DS-e6a81b4c-8617-4a37-bb87-d78fbba4d90e,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-95b071bb-63a0-40b7-931e-0cc59f375813,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-b7235cb7-874e-4043-b7ef-c11358f32539,DISK], DatanodeInfoWithStorage[127.0.0.1:44563,DS-a4041b99-d12c-4d57-8129-e1eaf98dc15d,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-9425cbb4-5bcf-4701-b552-f161f1e857f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-e981d0ff-312a-4517-9549-995a28a9e143,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-159327202-172.17.0.3-1597527758263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41503,DS-488fa761-3f43-41eb-b563-49cf5643fb22,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-93e1540f-23d8-4fd6-9319-fc92901f4e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-0c5ce53d-46ec-4f43-82e7-abca6817e734,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-722f4e57-c3eb-4557-bc4a-d33f759b55cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-b448e980-30dc-4179-885b-141a97ffbaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-a00d2c47-04da-4e63-9275-9dc57df2ace8,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-d8e9e53b-9fd6-4a73-b7ed-e62c9d4f1346,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-2273173f-2ae9-4e1f-8f21-1d315a01ebf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-159327202-172.17.0.3-1597527758263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41503,DS-488fa761-3f43-41eb-b563-49cf5643fb22,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-93e1540f-23d8-4fd6-9319-fc92901f4e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-0c5ce53d-46ec-4f43-82e7-abca6817e734,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-722f4e57-c3eb-4557-bc4a-d33f759b55cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-b448e980-30dc-4179-885b-141a97ffbaa6,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-a00d2c47-04da-4e63-9275-9dc57df2ace8,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-d8e9e53b-9fd6-4a73-b7ed-e62c9d4f1346,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-2273173f-2ae9-4e1f-8f21-1d315a01ebf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 50
v2: 1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2078611667-172.17.0.3-1597528181090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34355,DS-af3625ce-0de6-4e78-8b4d-efde25051a97,DISK], DatanodeInfoWithStorage[127.0.0.1:34796,DS-a94caca6-dca2-43cb-aaa2-ec24bcf34211,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-ec466eb2-2cb3-428b-a2bd-e484d60f314f,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-fa2aad69-163f-49e9-b238-6911ab0a591b,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-c07f1227-5bca-42e0-8a52-b9db2438db4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-075e0fdd-c108-4c0a-8c21-c9fa444c3e70,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-76a7ee73-ffd0-4c71-b1ee-631cbf748b56,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-c0c5b0d0-3849-43fc-bb79-3fed1faa91dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2078611667-172.17.0.3-1597528181090:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34355,DS-af3625ce-0de6-4e78-8b4d-efde25051a97,DISK], DatanodeInfoWithStorage[127.0.0.1:34796,DS-a94caca6-dca2-43cb-aaa2-ec24bcf34211,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-ec466eb2-2cb3-428b-a2bd-e484d60f314f,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-fa2aad69-163f-49e9-b238-6911ab0a591b,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-c07f1227-5bca-42e0-8a52-b9db2438db4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-075e0fdd-c108-4c0a-8c21-c9fa444c3e70,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-76a7ee73-ffd0-4c71-b1ee-631cbf748b56,DISK], DatanodeInfoWithStorage[127.0.0.1:33390,DS-c0c5b0d0-3849-43fc-bb79-3fed1faa91dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5655
