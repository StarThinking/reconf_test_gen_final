reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283179940-172.17.0.8-1597324479063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35232,DS-91a8f4b3-cd7c-466c-a761-759e01a21352,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-06b4b0b7-b359-4236-8227-a116843d5c67,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-e8d04a0f-a40d-42fd-bce1-28d6930670ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-6fc6e573-5c0e-4350-89f2-5ef712cb874e,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-06bc7c72-1166-4fae-872f-28e4b2b86f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-0c6a7fa1-338a-4c4d-b937-d03bbd812d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-00da90b4-ce3b-416c-9904-94ed1e897b34,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-b0809f20-e7b1-4631-83c8-15687d98a863,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-283179940-172.17.0.8-1597324479063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35232,DS-91a8f4b3-cd7c-466c-a761-759e01a21352,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-06b4b0b7-b359-4236-8227-a116843d5c67,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-e8d04a0f-a40d-42fd-bce1-28d6930670ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-6fc6e573-5c0e-4350-89f2-5ef712cb874e,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-06bc7c72-1166-4fae-872f-28e4b2b86f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-0c6a7fa1-338a-4c4d-b937-d03bbd812d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-00da90b4-ce3b-416c-9904-94ed1e897b34,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-b0809f20-e7b1-4631-83c8-15687d98a863,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-765402910-172.17.0.8-1597324651473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35281,DS-96b77307-74bc-4936-a9e7-344db4dd72db,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-3444c20a-f83f-423d-b015-bc1a81e5c0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-f4a77a1e-4dc5-438e-828e-78b3cb268fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-e0dac61b-3757-4735-802f-5971d1a2cfaa,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-00e17bbb-6277-4de0-956f-ffac7dc4e669,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-eff50465-41a0-4954-84e0-57a2456a13c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35793,DS-2716b41e-0936-46e4-bf49-b58991936933,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-638ab710-ceaa-42f9-9f03-30c6d4d727b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-765402910-172.17.0.8-1597324651473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35281,DS-96b77307-74bc-4936-a9e7-344db4dd72db,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-3444c20a-f83f-423d-b015-bc1a81e5c0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-f4a77a1e-4dc5-438e-828e-78b3cb268fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-e0dac61b-3757-4735-802f-5971d1a2cfaa,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-00e17bbb-6277-4de0-956f-ffac7dc4e669,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-eff50465-41a0-4954-84e0-57a2456a13c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35793,DS-2716b41e-0936-46e4-bf49-b58991936933,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-638ab710-ceaa-42f9-9f03-30c6d4d727b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1965971117-172.17.0.8-1597325696142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41091,DS-e5a4af49-0c20-4703-b177-4d4ab528e318,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-c2064958-b7ae-48fd-8cb3-30109d5895a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-af022c2b-6a38-4be7-8264-380345296ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:43387,DS-154b9b2e-bfc7-4748-9894-124f77168885,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-bdfaba2e-24a9-4d25-aebb-edb3840c3bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-481c4ec0-0599-4b2b-a035-c5f4fa611cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-d0f2a3e1-0f5e-4f3a-95dd-bc7dbf4bae1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-39e04096-9a03-468e-a2a6-9cbd39254d76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1965971117-172.17.0.8-1597325696142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41091,DS-e5a4af49-0c20-4703-b177-4d4ab528e318,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-c2064958-b7ae-48fd-8cb3-30109d5895a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-af022c2b-6a38-4be7-8264-380345296ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:43387,DS-154b9b2e-bfc7-4748-9894-124f77168885,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-bdfaba2e-24a9-4d25-aebb-edb3840c3bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-481c4ec0-0599-4b2b-a035-c5f4fa611cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:32969,DS-d0f2a3e1-0f5e-4f3a-95dd-bc7dbf4bae1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-39e04096-9a03-468e-a2a6-9cbd39254d76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1086214225-172.17.0.8-1597325788384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39287,DS-f6eb6998-e8ec-49aa-a874-15541f620637,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-9f0df3b9-31ac-4ef9-a9a7-ed648d109139,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-71548a4d-753b-43e1-8f0e-323ccf55f025,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-71e4088a-ee38-49fb-b3c1-7aa1502e8702,DISK], DatanodeInfoWithStorage[127.0.0.1:41173,DS-b6fee022-a158-496b-beda-b9fc9fcea2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-84dc3fb2-fe7f-4381-8d3f-42667d40de94,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-9ceb94ba-ab10-4ae4-b9c5-affde45ffd5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-5a7fde82-6eec-4751-bbb6-33affbd9bd79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1086214225-172.17.0.8-1597325788384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39287,DS-f6eb6998-e8ec-49aa-a874-15541f620637,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-9f0df3b9-31ac-4ef9-a9a7-ed648d109139,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-71548a4d-753b-43e1-8f0e-323ccf55f025,DISK], DatanodeInfoWithStorage[127.0.0.1:42207,DS-71e4088a-ee38-49fb-b3c1-7aa1502e8702,DISK], DatanodeInfoWithStorage[127.0.0.1:41173,DS-b6fee022-a158-496b-beda-b9fc9fcea2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-84dc3fb2-fe7f-4381-8d3f-42667d40de94,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-9ceb94ba-ab10-4ae4-b9c5-affde45ffd5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-5a7fde82-6eec-4751-bbb6-33affbd9bd79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-253347640-172.17.0.8-1597325828065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37969,DS-f4f400cd-5dde-4b68-8856-56108fd5e8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-99805fa0-535a-480e-bea4-bff90c4b04f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-33361d6a-d0c0-429d-bb15-9899d4baea32,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-51c788a9-a401-4ddf-9af9-d0fe69c096bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-b3d601f3-9b8f-492b-ab3a-87b7565cb18d,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-b3d45f57-1d57-411b-b512-b00d66e0dbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-592270ae-4dd2-47a9-ba72-d6ee0c908115,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-a95f5ea5-266a-48fa-b501-102ea2ca71d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-253347640-172.17.0.8-1597325828065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37969,DS-f4f400cd-5dde-4b68-8856-56108fd5e8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-99805fa0-535a-480e-bea4-bff90c4b04f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-33361d6a-d0c0-429d-bb15-9899d4baea32,DISK], DatanodeInfoWithStorage[127.0.0.1:36506,DS-51c788a9-a401-4ddf-9af9-d0fe69c096bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-b3d601f3-9b8f-492b-ab3a-87b7565cb18d,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-b3d45f57-1d57-411b-b512-b00d66e0dbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-592270ae-4dd2-47a9-ba72-d6ee0c908115,DISK], DatanodeInfoWithStorage[127.0.0.1:39795,DS-a95f5ea5-266a-48fa-b501-102ea2ca71d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1696350815-172.17.0.8-1597325959074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34662,DS-136405d4-79bf-441b-8fcd-7991da6a8d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-7894ee0d-5d1e-4b93-8955-e7db19493a05,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-f6a7b1d5-2b12-47ae-b5ca-8809afb8b368,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-79088fdb-9fae-4cb6-8782-767051a60108,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-8041fc14-097b-4289-84e1-62d55e09263b,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-43ef9a83-fc47-47f6-8bb6-33e0615d0d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-e0c7bc49-f15c-4fb9-9fd7-ed6e82b4d2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-88b7a1d6-1d6f-4f57-b288-b074e864441e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1696350815-172.17.0.8-1597325959074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34662,DS-136405d4-79bf-441b-8fcd-7991da6a8d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-7894ee0d-5d1e-4b93-8955-e7db19493a05,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-f6a7b1d5-2b12-47ae-b5ca-8809afb8b368,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-79088fdb-9fae-4cb6-8782-767051a60108,DISK], DatanodeInfoWithStorage[127.0.0.1:41784,DS-8041fc14-097b-4289-84e1-62d55e09263b,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-43ef9a83-fc47-47f6-8bb6-33e0615d0d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-e0c7bc49-f15c-4fb9-9fd7-ed6e82b4d2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43204,DS-88b7a1d6-1d6f-4f57-b288-b074e864441e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1637320914-172.17.0.8-1597326297178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43907,DS-b14f2eb3-92de-439f-a77d-26f4686a74f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-7ede713a-782a-469c-a8df-a1aacb540fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36694,DS-3aac909d-1200-4d72-a028-c95093d2d835,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-7ba6746d-ab74-48f7-a163-478fefb20fba,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-15ea56f8-7c97-4f4e-911d-890b17453bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34870,DS-c15234a7-cf6a-47e6-9e02-58292a45cf94,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-ee24ad56-d529-437c-8943-65b1ad446bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-44f41e5a-c3f9-45bc-9b98-de46b282df31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1637320914-172.17.0.8-1597326297178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43907,DS-b14f2eb3-92de-439f-a77d-26f4686a74f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-7ede713a-782a-469c-a8df-a1aacb540fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36694,DS-3aac909d-1200-4d72-a028-c95093d2d835,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-7ba6746d-ab74-48f7-a163-478fefb20fba,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-15ea56f8-7c97-4f4e-911d-890b17453bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34870,DS-c15234a7-cf6a-47e6-9e02-58292a45cf94,DISK], DatanodeInfoWithStorage[127.0.0.1:36123,DS-ee24ad56-d529-437c-8943-65b1ad446bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-44f41e5a-c3f9-45bc-9b98-de46b282df31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2065859957-172.17.0.8-1597326688951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45663,DS-1206ff1b-d47a-4230-827f-d432fa0d646f,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-6c69b1c7-3ed2-4abe-8ee4-ab9b6c41bd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-ca1b4676-d926-4748-a704-df7227bd2557,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-6391d3a5-a786-40ae-aafd-73ddc931a940,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-751206d3-fd1e-40f7-8f3e-bf7d6d4a4c06,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-c2f4e7ae-1dd0-4ea3-954c-ab50758e5be2,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-0344aaf3-d531-4816-b009-5d2776c7eb56,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-cdff909c-1c29-4135-9fd3-718bc4328dbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2065859957-172.17.0.8-1597326688951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45663,DS-1206ff1b-d47a-4230-827f-d432fa0d646f,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-6c69b1c7-3ed2-4abe-8ee4-ab9b6c41bd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-ca1b4676-d926-4748-a704-df7227bd2557,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-6391d3a5-a786-40ae-aafd-73ddc931a940,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-751206d3-fd1e-40f7-8f3e-bf7d6d4a4c06,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-c2f4e7ae-1dd0-4ea3-954c-ab50758e5be2,DISK], DatanodeInfoWithStorage[127.0.0.1:41273,DS-0344aaf3-d531-4816-b009-5d2776c7eb56,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-cdff909c-1c29-4135-9fd3-718bc4328dbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-718161852-172.17.0.8-1597328438256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38566,DS-65fdb87f-86a1-410b-9f7a-e625c45f9d36,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-daed6b9d-b6a4-491d-9dd6-e3b2c88e231c,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-e89f7ed1-cba4-4acf-beb1-23c41cac59aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-c6a3d10e-4eb0-4414-a000-8570222b4c25,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-7584f9bc-c896-40ee-afef-d2369a102f24,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-2e42ebe0-5569-4da6-8a19-f1dae052609c,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-ab572936-3810-4126-a4f2-eba9dcfd9665,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-f83f3dfe-b258-4ab9-8008-e066f197ab12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-718161852-172.17.0.8-1597328438256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38566,DS-65fdb87f-86a1-410b-9f7a-e625c45f9d36,DISK], DatanodeInfoWithStorage[127.0.0.1:36575,DS-daed6b9d-b6a4-491d-9dd6-e3b2c88e231c,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-e89f7ed1-cba4-4acf-beb1-23c41cac59aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-c6a3d10e-4eb0-4414-a000-8570222b4c25,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-7584f9bc-c896-40ee-afef-d2369a102f24,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-2e42ebe0-5569-4da6-8a19-f1dae052609c,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-ab572936-3810-4126-a4f2-eba9dcfd9665,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-f83f3dfe-b258-4ab9-8008-e066f197ab12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-160986725-172.17.0.8-1597329236352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37247,DS-eaa2fc6a-b87b-4250-b771-d7e5d7562cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-49b9545a-7e08-46d6-ac01-611e52b056d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-da151cde-29d6-41c9-8a9f-f1bdb1b1583d,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-ec5ecca0-3111-4752-b2f8-2356af35ce90,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-ab98373b-4a4d-44f0-b09b-b7010d512d01,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-c26ed13a-e659-4915-a701-b94b3784a0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-9bdf7b3f-a8e4-4afa-801c-7b87f81329e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-e27740ca-06a2-4838-9af5-ecf0aec39205,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-160986725-172.17.0.8-1597329236352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37247,DS-eaa2fc6a-b87b-4250-b771-d7e5d7562cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-49b9545a-7e08-46d6-ac01-611e52b056d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-da151cde-29d6-41c9-8a9f-f1bdb1b1583d,DISK], DatanodeInfoWithStorage[127.0.0.1:34389,DS-ec5ecca0-3111-4752-b2f8-2356af35ce90,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-ab98373b-4a4d-44f0-b09b-b7010d512d01,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-c26ed13a-e659-4915-a701-b94b3784a0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36497,DS-9bdf7b3f-a8e4-4afa-801c-7b87f81329e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-e27740ca-06a2-4838-9af5-ecf0aec39205,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929852324-172.17.0.8-1597330709379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42448,DS-8e409cfc-3edf-44f3-86fa-5bd47e50ba72,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-d5e1f27b-b04e-417d-b7b7-3d68532a1398,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-70ba0b05-7f7f-46bd-822e-d0dc9213f3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-5f655c64-9e1a-45ce-85b1-9258a539c6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-a76c5f8b-6e1e-435b-adfc-37c025c58cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-b3a4806e-1495-4b2e-aa7b-b10ea3146b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-6318bdf7-a089-43e4-9b36-5d55ecb18802,DISK], DatanodeInfoWithStorage[127.0.0.1:45233,DS-6ddee31b-a6af-4f40-8be6-c1b957ed14c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929852324-172.17.0.8-1597330709379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42448,DS-8e409cfc-3edf-44f3-86fa-5bd47e50ba72,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-d5e1f27b-b04e-417d-b7b7-3d68532a1398,DISK], DatanodeInfoWithStorage[127.0.0.1:39847,DS-70ba0b05-7f7f-46bd-822e-d0dc9213f3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-5f655c64-9e1a-45ce-85b1-9258a539c6f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-a76c5f8b-6e1e-435b-adfc-37c025c58cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:34941,DS-b3a4806e-1495-4b2e-aa7b-b10ea3146b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33521,DS-6318bdf7-a089-43e4-9b36-5d55ecb18802,DISK], DatanodeInfoWithStorage[127.0.0.1:45233,DS-6ddee31b-a6af-4f40-8be6-c1b957ed14c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-519063908-172.17.0.8-1597330753932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42057,DS-a152e10f-ccf4-4a20-af46-e182da948f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-425cc979-218f-4c8f-955f-2a7d635ecb19,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-a53ad0b7-bcc8-4d94-af71-cb91334c7ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-22ba7774-c180-4f55-ae04-132c8f6ffb23,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-a4b479f1-b09e-4c87-8c50-f156c761c605,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-24bc2bc4-cf32-4b19-832e-8e2d6143d04d,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-aca9cb63-6a74-47b5-9642-0e9616f2790c,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-56a01e6e-670c-4ae5-bdcb-8fbc9dc37658,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-519063908-172.17.0.8-1597330753932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42057,DS-a152e10f-ccf4-4a20-af46-e182da948f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-425cc979-218f-4c8f-955f-2a7d635ecb19,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-a53ad0b7-bcc8-4d94-af71-cb91334c7ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-22ba7774-c180-4f55-ae04-132c8f6ffb23,DISK], DatanodeInfoWithStorage[127.0.0.1:39357,DS-a4b479f1-b09e-4c87-8c50-f156c761c605,DISK], DatanodeInfoWithStorage[127.0.0.1:42957,DS-24bc2bc4-cf32-4b19-832e-8e2d6143d04d,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-aca9cb63-6a74-47b5-9642-0e9616f2790c,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-56a01e6e-670c-4ae5-bdcb-8fbc9dc37658,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:DataNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2141892742-172.17.0.8-1597331116547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43923,DS-956eef5a-7b08-4f62-9621-00fd01be925d,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-e3c20c37-2590-488a-a326-52434721ce3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-0e50f5af-863e-4f2c-b388-ba735c973056,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-41df3334-677f-4262-a592-5289a953bae4,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-2fd09b76-6d28-4890-8190-441d6ff53034,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-2a404073-87e7-4688-9a61-8c73d4fe3225,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-438bbe99-4558-4126-a71e-14c3dea4607f,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-2a933124-da5d-4969-8b45-f7e46cdfb746,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2141892742-172.17.0.8-1597331116547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43923,DS-956eef5a-7b08-4f62-9621-00fd01be925d,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-e3c20c37-2590-488a-a326-52434721ce3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-0e50f5af-863e-4f2c-b388-ba735c973056,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-41df3334-677f-4262-a592-5289a953bae4,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-2fd09b76-6d28-4890-8190-441d6ff53034,DISK], DatanodeInfoWithStorage[127.0.0.1:37072,DS-2a404073-87e7-4688-9a61-8c73d4fe3225,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-438bbe99-4558-4126-a71e-14c3dea4607f,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-2a933124-da5d-4969-8b45-f7e46cdfb746,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6887
