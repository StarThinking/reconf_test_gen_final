reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1379373960-172.17.0.3-1597466967680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41768,DS-c7467dc4-a19b-4e6e-bcb2-988565bfcacd,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-091a7478-dcc5-41ae-9efb-25f916259711,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-83a8895c-a6b8-48f0-8b02-a6e175389258,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-33176135-e025-41ff-bf1f-ec731f476213,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-8a4623b5-3823-4a97-a667-eba5a7df7ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-f9a4fa2f-06da-4a08-94af-c163a3f1fa14,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-fd23af7e-6d38-48f7-acbb-1b52baa7529f,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-bad2f920-d102-41bd-bfa1-9be502bfb62d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1379373960-172.17.0.3-1597466967680:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41768,DS-c7467dc4-a19b-4e6e-bcb2-988565bfcacd,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-091a7478-dcc5-41ae-9efb-25f916259711,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-83a8895c-a6b8-48f0-8b02-a6e175389258,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-33176135-e025-41ff-bf1f-ec731f476213,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-8a4623b5-3823-4a97-a667-eba5a7df7ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-f9a4fa2f-06da-4a08-94af-c163a3f1fa14,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-fd23af7e-6d38-48f7-acbb-1b52baa7529f,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-bad2f920-d102-41bd-bfa1-9be502bfb62d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-941879159-172.17.0.3-1597467865091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44948,DS-61c05429-6692-4789-b72f-18fdc5f2e1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-526e9f83-856f-4bd2-ac92-2564321bc0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-761456bf-ae16-49ed-8616-40884f9393ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-ef7125e8-7116-464f-ab5e-6cc303749e29,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-8ecad6d4-3c21-4295-9198-345aa0c01a95,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-63c1a956-313b-47b0-bf1e-1f5c2b0ef374,DISK], DatanodeInfoWithStorage[127.0.0.1:35146,DS-3c08965e-6308-440e-849a-88a2d566b695,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-04560703-b6e8-4608-9401-705f122209f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-941879159-172.17.0.3-1597467865091:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44948,DS-61c05429-6692-4789-b72f-18fdc5f2e1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-526e9f83-856f-4bd2-ac92-2564321bc0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-761456bf-ae16-49ed-8616-40884f9393ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39939,DS-ef7125e8-7116-464f-ab5e-6cc303749e29,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-8ecad6d4-3c21-4295-9198-345aa0c01a95,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-63c1a956-313b-47b0-bf1e-1f5c2b0ef374,DISK], DatanodeInfoWithStorage[127.0.0.1:35146,DS-3c08965e-6308-440e-849a-88a2d566b695,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-04560703-b6e8-4608-9401-705f122209f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-937439105-172.17.0.3-1597468202029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33544,DS-c3444bb0-3cd2-40ed-9ed0-1d14ffb05eba,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-31aeea3d-cf67-413a-a46b-699a4a68f8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-05da9037-73b2-4678-9e3f-43855f7284f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-2cd6ed77-3b7d-4742-884b-93d8bf6e620e,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-e29fbbfc-0efa-468b-8666-53758da8724f,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-93ba5b76-2564-4584-942f-aa3cb3735b89,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-919cb250-cbe1-453a-bbab-0b09cb7dcc97,DISK], DatanodeInfoWithStorage[127.0.0.1:40909,DS-def74c15-b88d-45f7-9f4d-e735e1819748,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-937439105-172.17.0.3-1597468202029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33544,DS-c3444bb0-3cd2-40ed-9ed0-1d14ffb05eba,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-31aeea3d-cf67-413a-a46b-699a4a68f8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-05da9037-73b2-4678-9e3f-43855f7284f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-2cd6ed77-3b7d-4742-884b-93d8bf6e620e,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-e29fbbfc-0efa-468b-8666-53758da8724f,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-93ba5b76-2564-4584-942f-aa3cb3735b89,DISK], DatanodeInfoWithStorage[127.0.0.1:33855,DS-919cb250-cbe1-453a-bbab-0b09cb7dcc97,DISK], DatanodeInfoWithStorage[127.0.0.1:40909,DS-def74c15-b88d-45f7-9f4d-e735e1819748,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-105651894-172.17.0.3-1597469066477:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34422,DS-f0f07f37-66d4-430d-83e0-5e40e355619f,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-ec7da36c-091c-4ba6-a465-d1368f7af4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-baa48242-2567-4ab5-b67c-e81079c2a5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-a6f177fd-3083-4af2-8dd5-d9fd2434764f,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-f7d28ef5-30b7-4fcb-9c86-2365defdfd76,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-327d3d3d-1673-4cbd-a02e-65781120aa5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-42750531-e26b-4cf0-ae50-1e444304c208,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-5993e73b-b571-4909-99b2-e106de127f78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-105651894-172.17.0.3-1597469066477:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34422,DS-f0f07f37-66d4-430d-83e0-5e40e355619f,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-ec7da36c-091c-4ba6-a465-d1368f7af4f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-baa48242-2567-4ab5-b67c-e81079c2a5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-a6f177fd-3083-4af2-8dd5-d9fd2434764f,DISK], DatanodeInfoWithStorage[127.0.0.1:41245,DS-f7d28ef5-30b7-4fcb-9c86-2365defdfd76,DISK], DatanodeInfoWithStorage[127.0.0.1:44600,DS-327d3d3d-1673-4cbd-a02e-65781120aa5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-42750531-e26b-4cf0-ae50-1e444304c208,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-5993e73b-b571-4909-99b2-e106de127f78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-587543180-172.17.0.3-1597470064007:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39829,DS-389112b7-c2d7-4f1a-b78f-b6d0f4c7c14c,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-856fb6ed-30b9-41eb-aa7c-f51d3aa4e718,DISK], DatanodeInfoWithStorage[127.0.0.1:46761,DS-e0384adb-227a-4667-87bc-9b9402ea27cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-88f82d31-5a91-414d-b53d-8db77aad15f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-81937004-f252-4b9e-a1b3-ccc1dca269ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-f83e5da6-35dc-4c32-9148-206541cfd017,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-70923972-339f-4015-8124-17571968a924,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-11f7869c-fbbf-4f30-a80e-25c49120d705,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-587543180-172.17.0.3-1597470064007:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39829,DS-389112b7-c2d7-4f1a-b78f-b6d0f4c7c14c,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-856fb6ed-30b9-41eb-aa7c-f51d3aa4e718,DISK], DatanodeInfoWithStorage[127.0.0.1:46761,DS-e0384adb-227a-4667-87bc-9b9402ea27cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45623,DS-88f82d31-5a91-414d-b53d-8db77aad15f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34500,DS-81937004-f252-4b9e-a1b3-ccc1dca269ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35951,DS-f83e5da6-35dc-4c32-9148-206541cfd017,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-70923972-339f-4015-8124-17571968a924,DISK], DatanodeInfoWithStorage[127.0.0.1:41604,DS-11f7869c-fbbf-4f30-a80e-25c49120d705,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-830789452-172.17.0.3-1597470097203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38030,DS-164defa0-e80a-40bb-8265-bfded31a4c63,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-85eefce7-0746-4122-8bc1-d818388ceb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-e61d1fb3-08d9-49c6-bc17-ffd96cced32a,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-e2bebc7f-0744-47ff-9e9f-6b162299b991,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-a824ae65-6b81-4fb4-90d5-7ca652b06e53,DISK], DatanodeInfoWithStorage[127.0.0.1:36858,DS-56031d70-a566-4d83-a60e-2b4d1d23769f,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-1553f183-d556-449e-9142-260f3abff8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-42351686-ecd2-4928-b3f3-de8c9bf88dbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-830789452-172.17.0.3-1597470097203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38030,DS-164defa0-e80a-40bb-8265-bfded31a4c63,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-85eefce7-0746-4122-8bc1-d818388ceb3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-e61d1fb3-08d9-49c6-bc17-ffd96cced32a,DISK], DatanodeInfoWithStorage[127.0.0.1:36859,DS-e2bebc7f-0744-47ff-9e9f-6b162299b991,DISK], DatanodeInfoWithStorage[127.0.0.1:42200,DS-a824ae65-6b81-4fb4-90d5-7ca652b06e53,DISK], DatanodeInfoWithStorage[127.0.0.1:36858,DS-56031d70-a566-4d83-a60e-2b4d1d23769f,DISK], DatanodeInfoWithStorage[127.0.0.1:46156,DS-1553f183-d556-449e-9142-260f3abff8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-42351686-ecd2-4928-b3f3-de8c9bf88dbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1670334074-172.17.0.3-1597470354257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40469,DS-3314f92d-b712-4dbd-a2df-00905e2776a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-6103dcbd-6abc-408c-a5b3-4f78b10e9161,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-8f7cd4c1-1bca-4173-8c8c-a6924d47039f,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-4fc4afff-cfb9-46f0-9f2a-1727212a91ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-a8ab1f9f-30ea-455c-b2ff-642cf48741c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-4af34eda-7d74-4766-ad8a-7e7b5e99c577,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-d41fbfce-2525-4c10-ac17-084251c07bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-ffece184-1068-4483-a8ff-3faca75f9bfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1670334074-172.17.0.3-1597470354257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40469,DS-3314f92d-b712-4dbd-a2df-00905e2776a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-6103dcbd-6abc-408c-a5b3-4f78b10e9161,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-8f7cd4c1-1bca-4173-8c8c-a6924d47039f,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-4fc4afff-cfb9-46f0-9f2a-1727212a91ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-a8ab1f9f-30ea-455c-b2ff-642cf48741c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-4af34eda-7d74-4766-ad8a-7e7b5e99c577,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-d41fbfce-2525-4c10-ac17-084251c07bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-ffece184-1068-4483-a8ff-3faca75f9bfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1622411461-172.17.0.3-1597470394882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35126,DS-a82e295c-673d-40ce-b72c-11b475d71031,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-1036995d-c4cb-4c86-b8b1-d66b91aca33a,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-a64404e5-b3c3-4ec9-93a7-2381f6c24672,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-a3358fb5-458b-4660-8ce2-f6b03db90494,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-923a8cde-b81d-4625-ba19-1c8b8d9b72b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-d200a652-c848-4098-82aa-39401ae8782a,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-c3c26ba6-76ac-4a7f-839e-efb89355f843,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-b5a39fb4-167c-4866-8a4f-20c604495fbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1622411461-172.17.0.3-1597470394882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35126,DS-a82e295c-673d-40ce-b72c-11b475d71031,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-1036995d-c4cb-4c86-b8b1-d66b91aca33a,DISK], DatanodeInfoWithStorage[127.0.0.1:40911,DS-a64404e5-b3c3-4ec9-93a7-2381f6c24672,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-a3358fb5-458b-4660-8ce2-f6b03db90494,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-923a8cde-b81d-4625-ba19-1c8b8d9b72b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-d200a652-c848-4098-82aa-39401ae8782a,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-c3c26ba6-76ac-4a7f-839e-efb89355f843,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-b5a39fb4-167c-4866-8a4f-20c604495fbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-3149463-172.17.0.3-1597470611979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34708,DS-4a51b442-e914-46c5-867d-b36a885b40ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-ff7c75a5-ca4d-4f07-8e67-802c5cb03c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-dfa52b89-7f0c-4464-976a-68ab2bfdefb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-1b639aa1-51e0-4cba-8cff-168ae35682eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-d2f1568a-97fe-4a06-b14f-ef956b5070f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-6ecea681-44e1-4274-8221-387c02573c53,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-195fa0f2-6aaf-4d94-962c-199a3b36e043,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-b2f51b80-3225-4bf0-a436-92c294509980,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-3149463-172.17.0.3-1597470611979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34708,DS-4a51b442-e914-46c5-867d-b36a885b40ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37303,DS-ff7c75a5-ca4d-4f07-8e67-802c5cb03c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-dfa52b89-7f0c-4464-976a-68ab2bfdefb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-1b639aa1-51e0-4cba-8cff-168ae35682eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-d2f1568a-97fe-4a06-b14f-ef956b5070f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-6ecea681-44e1-4274-8221-387c02573c53,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-195fa0f2-6aaf-4d94-962c-199a3b36e043,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-b2f51b80-3225-4bf0-a436-92c294509980,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-611462247-172.17.0.3-1597470686810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34510,DS-4b02ef09-1aa2-4c75-9b52-6529ab639e68,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-a76cc790-1e90-46bb-acf8-d498a8665d53,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-679d75d1-caf3-43a0-8928-83e76d468c45,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-03f9003e-a343-4c64-af81-0c9649ed5fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-d2713879-b9e4-4958-9d59-1b077ca0731f,DISK], DatanodeInfoWithStorage[127.0.0.1:42223,DS-8da8df2c-ece5-4148-b2c0-ba04e643ee8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-5cad2360-d7e7-475a-86e5-3a8994c1851d,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-d6fd7d00-43de-4895-b4f4-9ec7a36c3050,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-611462247-172.17.0.3-1597470686810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34510,DS-4b02ef09-1aa2-4c75-9b52-6529ab639e68,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-a76cc790-1e90-46bb-acf8-d498a8665d53,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-679d75d1-caf3-43a0-8928-83e76d468c45,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-03f9003e-a343-4c64-af81-0c9649ed5fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-d2713879-b9e4-4958-9d59-1b077ca0731f,DISK], DatanodeInfoWithStorage[127.0.0.1:42223,DS-8da8df2c-ece5-4148-b2c0-ba04e643ee8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-5cad2360-d7e7-475a-86e5-3a8994c1851d,DISK], DatanodeInfoWithStorage[127.0.0.1:35569,DS-d6fd7d00-43de-4895-b4f4-9ec7a36c3050,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1868695641-172.17.0.3-1597471094666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38882,DS-1be1902a-50f8-4501-abd9-6e326f47b8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-d0a300ff-cc9b-4788-80c2-474e649e610e,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-9fd2b8b4-507b-44b3-8137-4613c6dc68f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-a7cb8b0d-0c6d-4e46-a9dc-01d8c287148e,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-93c3ae10-94b5-4de4-8d54-52c05edb843a,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-f592d022-74ed-4ccb-90b9-0595dd502a70,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-c11f4fa7-34c1-47a9-b3b0-3f9fdb4cffb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-c5320d36-cca8-4e36-b12d-2591352c3571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1868695641-172.17.0.3-1597471094666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38882,DS-1be1902a-50f8-4501-abd9-6e326f47b8fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38428,DS-d0a300ff-cc9b-4788-80c2-474e649e610e,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-9fd2b8b4-507b-44b3-8137-4613c6dc68f1,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-a7cb8b0d-0c6d-4e46-a9dc-01d8c287148e,DISK], DatanodeInfoWithStorage[127.0.0.1:34432,DS-93c3ae10-94b5-4de4-8d54-52c05edb843a,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-f592d022-74ed-4ccb-90b9-0595dd502a70,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-c11f4fa7-34c1-47a9-b3b0-3f9fdb4cffb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44360,DS-c5320d36-cca8-4e36-b12d-2591352c3571,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-939514329-172.17.0.3-1597471747872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44905,DS-ae22d159-b9c8-4f1d-9ed2-eabf299d4942,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-7b24f14c-fdf0-4c0e-8a5f-4aee94138b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-1f9be84e-5b15-457c-8fbd-a278b3decf17,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-ff2d1746-95bc-42b3-817d-11a317f81b46,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-5523a80b-d514-4103-bf96-cad131494c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-b4ee7cbd-ea7a-4d9a-bd05-0503d0370bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-f68de11d-09d9-4fd4-953c-68d3b04bbd5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-135fc2b7-dc22-449b-9dad-882569c47b6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-939514329-172.17.0.3-1597471747872:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44905,DS-ae22d159-b9c8-4f1d-9ed2-eabf299d4942,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-7b24f14c-fdf0-4c0e-8a5f-4aee94138b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-1f9be84e-5b15-457c-8fbd-a278b3decf17,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-ff2d1746-95bc-42b3-817d-11a317f81b46,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-5523a80b-d514-4103-bf96-cad131494c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-b4ee7cbd-ea7a-4d9a-bd05-0503d0370bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-f68de11d-09d9-4fd4-953c-68d3b04bbd5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43965,DS-135fc2b7-dc22-449b-9dad-882569c47b6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1999425978-172.17.0.3-1597471820705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36207,DS-1db46a85-d217-4cf9-8c61-c08157aaf6da,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-1c394005-ba7f-44f2-9205-563385b6feb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-539cdf1a-6f1d-4a8c-a10e-3182c3ff76a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-0ff197b4-9d30-4880-bc21-043777cabab7,DISK], DatanodeInfoWithStorage[127.0.0.1:39663,DS-558d60af-abe6-4dc8-aff6-4c15ea286b72,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-c0b8c3e8-a40a-44f4-81aa-3e95b348b6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-8a203158-1151-427d-950c-85a14ca75d17,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-8024777e-f89c-4eb6-a9f2-bc9defe617bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1999425978-172.17.0.3-1597471820705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36207,DS-1db46a85-d217-4cf9-8c61-c08157aaf6da,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-1c394005-ba7f-44f2-9205-563385b6feb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-539cdf1a-6f1d-4a8c-a10e-3182c3ff76a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-0ff197b4-9d30-4880-bc21-043777cabab7,DISK], DatanodeInfoWithStorage[127.0.0.1:39663,DS-558d60af-abe6-4dc8-aff6-4c15ea286b72,DISK], DatanodeInfoWithStorage[127.0.0.1:43218,DS-c0b8c3e8-a40a-44f4-81aa-3e95b348b6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-8a203158-1151-427d-950c-85a14ca75d17,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-8024777e-f89c-4eb6-a9f2-bc9defe617bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2043357695-172.17.0.3-1597472009967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46109,DS-c67055eb-9854-47a4-bb83-6e2cf80a6e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-7aa7e9fb-313f-4a5a-bd97-311daa4bc206,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-8b452124-261b-4a61-8e2c-bd06b5eb2d20,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-93bcd2d6-3197-4ed1-a6c3-5e8242a95778,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-44aa53af-c76f-4df8-b0d8-d8075f210b57,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-3a87fdc3-73aa-4fd5-9602-be4a388d2459,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-ca3c1366-8ca8-4207-8614-c1a6eabe73c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-be156e02-3d75-48d8-8144-59709dacc0ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2043357695-172.17.0.3-1597472009967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46109,DS-c67055eb-9854-47a4-bb83-6e2cf80a6e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-7aa7e9fb-313f-4a5a-bd97-311daa4bc206,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-8b452124-261b-4a61-8e2c-bd06b5eb2d20,DISK], DatanodeInfoWithStorage[127.0.0.1:38733,DS-93bcd2d6-3197-4ed1-a6c3-5e8242a95778,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-44aa53af-c76f-4df8-b0d8-d8075f210b57,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-3a87fdc3-73aa-4fd5-9602-be4a388d2459,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-ca3c1366-8ca8-4207-8614-c1a6eabe73c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42270,DS-be156e02-3d75-48d8-8144-59709dacc0ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1112780329-172.17.0.3-1597472144764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35568,DS-e5105c6e-0f2f-44a2-b8c2-c7b218ce54b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-d021d8ce-e697-4c64-8770-49e1336efa1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-c3deea5b-66e9-4169-bdaf-59468a691bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-51bac846-70fa-4e37-901f-4459c1b80924,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-8bcc81f0-4e47-4bfa-8f1d-5a6ab09e7838,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-63102c63-bf36-483f-85fa-49c679e2b66c,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-0555fa34-e10f-4435-8237-911551a345e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-ea9c3720-9cac-4e0c-9e08-1ffdee010028,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1112780329-172.17.0.3-1597472144764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35568,DS-e5105c6e-0f2f-44a2-b8c2-c7b218ce54b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-d021d8ce-e697-4c64-8770-49e1336efa1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-c3deea5b-66e9-4169-bdaf-59468a691bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-51bac846-70fa-4e37-901f-4459c1b80924,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-8bcc81f0-4e47-4bfa-8f1d-5a6ab09e7838,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-63102c63-bf36-483f-85fa-49c679e2b66c,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-0555fa34-e10f-4435-8237-911551a345e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-ea9c3720-9cac-4e0c-9e08-1ffdee010028,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5599
