reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1089040516-172.17.0.12-1597564155209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45974,DS-36596793-1914-4737-8a4f-09f314c904d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-5bbe0506-5c9b-4527-8d7b-49c603f1813e,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-91ac72a8-6102-402e-a42f-8b1b539b0b96,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-aa18c955-e960-47aa-ae2b-a2417dc5eb55,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-8d1fd23d-1078-460d-9d57-1333cddac690,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-92f6d50f-f1e0-41a5-ba6f-b1b28ad1b447,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-abe850bd-ae89-4899-9749-94d8975e60d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-e3cb91fe-db70-495e-8126-64ae9133f0f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1089040516-172.17.0.12-1597564155209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45974,DS-36596793-1914-4737-8a4f-09f314c904d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-5bbe0506-5c9b-4527-8d7b-49c603f1813e,DISK], DatanodeInfoWithStorage[127.0.0.1:38275,DS-91ac72a8-6102-402e-a42f-8b1b539b0b96,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-aa18c955-e960-47aa-ae2b-a2417dc5eb55,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-8d1fd23d-1078-460d-9d57-1333cddac690,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-92f6d50f-f1e0-41a5-ba6f-b1b28ad1b447,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-abe850bd-ae89-4899-9749-94d8975e60d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42217,DS-e3cb91fe-db70-495e-8126-64ae9133f0f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367983698-172.17.0.12-1597564232566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45921,DS-1b1e3e39-456c-401e-9ce2-49cffcdb93b8,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-1b9894bf-4808-42b2-b622-9bc487b00fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-8091dd42-0a69-433c-99b1-be6e2b75bb44,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-31826b04-0a35-4d28-92df-42006b4d28ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-f910558a-b294-490f-8b5f-0b2a2234dd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-15db28a8-76c8-416d-bf16-c4f7443c51d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-cba76cad-446e-44f1-83f3-881ca5eb4a91,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-4737a8f5-52e2-4c84-8b34-2ee2b2195821,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367983698-172.17.0.12-1597564232566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45921,DS-1b1e3e39-456c-401e-9ce2-49cffcdb93b8,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-1b9894bf-4808-42b2-b622-9bc487b00fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-8091dd42-0a69-433c-99b1-be6e2b75bb44,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-31826b04-0a35-4d28-92df-42006b4d28ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39950,DS-f910558a-b294-490f-8b5f-0b2a2234dd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-15db28a8-76c8-416d-bf16-c4f7443c51d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-cba76cad-446e-44f1-83f3-881ca5eb4a91,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-4737a8f5-52e2-4c84-8b34-2ee2b2195821,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518118844-172.17.0.12-1597564466572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39243,DS-e668fef6-443d-4909-b4de-871cd32a9187,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-b6c4c05f-c4d0-4e8a-8d8d-446ab19e7150,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-2e0bdba4-2942-47ae-be3f-0c16e095db79,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-e344c9d7-29a1-42e1-80fa-a276d251c8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-e12ecef3-44a5-4f02-8a13-82aa23692e99,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-bc69f33b-1277-49ec-9cd1-bbb5dd6ded6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-581daae8-74c9-41b3-a8fb-f0fc39475684,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-9c812b6b-2ad4-4bd1-a894-66dbaf11e872,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518118844-172.17.0.12-1597564466572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39243,DS-e668fef6-443d-4909-b4de-871cd32a9187,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-b6c4c05f-c4d0-4e8a-8d8d-446ab19e7150,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-2e0bdba4-2942-47ae-be3f-0c16e095db79,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-e344c9d7-29a1-42e1-80fa-a276d251c8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-e12ecef3-44a5-4f02-8a13-82aa23692e99,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-bc69f33b-1277-49ec-9cd1-bbb5dd6ded6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-581daae8-74c9-41b3-a8fb-f0fc39475684,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-9c812b6b-2ad4-4bd1-a894-66dbaf11e872,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-48295197-172.17.0.12-1597564571538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37604,DS-00e823fa-7a06-4b23-a95f-6c3cdb312fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-2832d613-e493-4813-8813-69dd445a0560,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-76abd70e-a8e7-41d5-96d9-a4b035fe2aae,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-bca7e49c-60f6-4707-a542-ee28f1d0ab03,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-d6a8c2d5-8821-4651-ace6-f586d163d89f,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-61c12255-cb94-49c4-8bed-76d5601375cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-36d6da84-daf8-403a-8c69-c6603cc99880,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-13014957-e023-4aa1-8791-25ce3e09a923,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-48295197-172.17.0.12-1597564571538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37604,DS-00e823fa-7a06-4b23-a95f-6c3cdb312fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-2832d613-e493-4813-8813-69dd445a0560,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-76abd70e-a8e7-41d5-96d9-a4b035fe2aae,DISK], DatanodeInfoWithStorage[127.0.0.1:38804,DS-bca7e49c-60f6-4707-a542-ee28f1d0ab03,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-d6a8c2d5-8821-4651-ace6-f586d163d89f,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-61c12255-cb94-49c4-8bed-76d5601375cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-36d6da84-daf8-403a-8c69-c6603cc99880,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-13014957-e023-4aa1-8791-25ce3e09a923,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1105017076-172.17.0.12-1597564687169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44762,DS-0de28f7f-65aa-4346-bddf-7de5e5c1e817,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-99b20b3e-8175-4e71-a97c-5ca28b745ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-1664f3ae-e835-4af0-ac83-b05fd0b0a427,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-11347eea-8d43-42d1-8588-efa77c3a1960,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-73600225-5cec-4e9d-896e-28ae6b7b4e96,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-457ba8dd-0a4b-4377-97b7-d1e3edaee2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-a3f69397-1825-414b-a1fc-b7bd7bc42b90,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-3ff44c6c-576c-484f-ac2c-10ad86c4440d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1105017076-172.17.0.12-1597564687169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44762,DS-0de28f7f-65aa-4346-bddf-7de5e5c1e817,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-99b20b3e-8175-4e71-a97c-5ca28b745ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:34087,DS-1664f3ae-e835-4af0-ac83-b05fd0b0a427,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-11347eea-8d43-42d1-8588-efa77c3a1960,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-73600225-5cec-4e9d-896e-28ae6b7b4e96,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-457ba8dd-0a4b-4377-97b7-d1e3edaee2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40355,DS-a3f69397-1825-414b-a1fc-b7bd7bc42b90,DISK], DatanodeInfoWithStorage[127.0.0.1:36150,DS-3ff44c6c-576c-484f-ac2c-10ad86c4440d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202847814-172.17.0.12-1597564759754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33705,DS-5ec080a9-bfb5-435b-97a4-f070e031c49a,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-c8558825-ce50-43e0-b8e3-200c7c60866a,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-5a7703ed-7103-4158-b478-e2898ff1fd8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-66b1656f-6315-434a-b1c0-0390b6bad074,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-27236dca-7068-4573-bff1-653fa95ae0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-0226eedf-ea75-4229-ae0b-ff5d2f9764e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-bfb47d07-a44b-4e58-97a9-a18a62ca273c,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-9a36c36b-5458-43c1-a4f6-a940280f4e9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-202847814-172.17.0.12-1597564759754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33705,DS-5ec080a9-bfb5-435b-97a4-f070e031c49a,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-c8558825-ce50-43e0-b8e3-200c7c60866a,DISK], DatanodeInfoWithStorage[127.0.0.1:37190,DS-5a7703ed-7103-4158-b478-e2898ff1fd8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-66b1656f-6315-434a-b1c0-0390b6bad074,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-27236dca-7068-4573-bff1-653fa95ae0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-0226eedf-ea75-4229-ae0b-ff5d2f9764e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-bfb47d07-a44b-4e58-97a9-a18a62ca273c,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-9a36c36b-5458-43c1-a4f6-a940280f4e9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-97722278-172.17.0.12-1597565438180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33171,DS-46fc7add-546b-4c22-93ac-cf0b767dbff5,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-a4b47300-866d-4419-8c40-df1cae1386c7,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-ead7a98c-cce8-4069-b91e-bbe8841a7898,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-8fe20541-b355-483c-b7f8-edaae42805fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-3e1b4475-b831-4e79-a4bd-24f044b92720,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-0f9eae89-e8dc-4a1a-8f23-b3766af7c909,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-3c02d5b2-d572-4d9b-b4cc-55545f3874e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39946,DS-2bd38893-e6eb-4d4c-b772-a0939b74fcdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-97722278-172.17.0.12-1597565438180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33171,DS-46fc7add-546b-4c22-93ac-cf0b767dbff5,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-a4b47300-866d-4419-8c40-df1cae1386c7,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-ead7a98c-cce8-4069-b91e-bbe8841a7898,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-8fe20541-b355-483c-b7f8-edaae42805fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-3e1b4475-b831-4e79-a4bd-24f044b92720,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-0f9eae89-e8dc-4a1a-8f23-b3766af7c909,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-3c02d5b2-d572-4d9b-b4cc-55545f3874e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39946,DS-2bd38893-e6eb-4d4c-b772-a0939b74fcdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-64501882-172.17.0.12-1597565719861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35663,DS-7769e6ec-3b49-4614-a6d6-89ebb98ac6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-7772bbf7-5f11-411d-8ec3-e305245e6f47,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-0af36a07-951e-44c7-8480-0f8df265d536,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-dab93643-7dff-4901-9d74-597089e57472,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-4d806adf-a8a5-4ba1-9cc5-a7782332b757,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-6fb7ce0d-06a9-48ed-bd36-c46f3f5e1b35,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-c474c7fc-f2c1-4915-822c-583bf86d3fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-86b994c2-e3d8-4d60-8356-064d9cf36310,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-64501882-172.17.0.12-1597565719861:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35663,DS-7769e6ec-3b49-4614-a6d6-89ebb98ac6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41413,DS-7772bbf7-5f11-411d-8ec3-e305245e6f47,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-0af36a07-951e-44c7-8480-0f8df265d536,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-dab93643-7dff-4901-9d74-597089e57472,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-4d806adf-a8a5-4ba1-9cc5-a7782332b757,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-6fb7ce0d-06a9-48ed-bd36-c46f3f5e1b35,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-c474c7fc-f2c1-4915-822c-583bf86d3fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34734,DS-86b994c2-e3d8-4d60-8356-064d9cf36310,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63528568-172.17.0.12-1597565754081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37687,DS-9ae1ef64-a841-4a8d-97b3-586b26e209d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-37cfffc5-1007-4d3c-99bf-9cde35049ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-546ea746-a23b-4ea9-beb4-fe1d7831b046,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-ba72ec2d-0a06-4b98-9bb0-01b17adb1ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-87f227b4-2403-4fa5-8e51-d6d1fabc2523,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-f2dc9732-a3f2-4636-9d97-ceb1888cd64d,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-1a8b86de-58eb-4b3b-bee9-95a7039ffc27,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-f54abfa5-4163-4c1a-b6b1-c5cbfede7d87,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63528568-172.17.0.12-1597565754081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37687,DS-9ae1ef64-a841-4a8d-97b3-586b26e209d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37787,DS-37cfffc5-1007-4d3c-99bf-9cde35049ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:42531,DS-546ea746-a23b-4ea9-beb4-fe1d7831b046,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-ba72ec2d-0a06-4b98-9bb0-01b17adb1ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-87f227b4-2403-4fa5-8e51-d6d1fabc2523,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-f2dc9732-a3f2-4636-9d97-ceb1888cd64d,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-1a8b86de-58eb-4b3b-bee9-95a7039ffc27,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-f54abfa5-4163-4c1a-b6b1-c5cbfede7d87,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1420525748-172.17.0.12-1597565788819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37901,DS-113580b2-e402-4447-a227-0f0fe89efbf2,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-6db39d09-efe4-4c03-81dd-69546c824a06,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-0653895e-9c89-4ba1-b2ef-1725f5b7277f,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-4379745a-70b5-4895-92fb-0db47b01b146,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-b4f7b4ce-a5ef-4698-9d80-a635f2fd2a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-75dd90f1-607b-4e6b-ac8c-fc43fc9418e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-fba91721-1f13-4c50-90ad-473e85edddf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36915,DS-44dc47f1-5eb4-4243-81e8-651ea52ea316,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1420525748-172.17.0.12-1597565788819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37901,DS-113580b2-e402-4447-a227-0f0fe89efbf2,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-6db39d09-efe4-4c03-81dd-69546c824a06,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-0653895e-9c89-4ba1-b2ef-1725f5b7277f,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-4379745a-70b5-4895-92fb-0db47b01b146,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-b4f7b4ce-a5ef-4698-9d80-a635f2fd2a6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-75dd90f1-607b-4e6b-ac8c-fc43fc9418e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-fba91721-1f13-4c50-90ad-473e85edddf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36915,DS-44dc47f1-5eb4-4243-81e8-651ea52ea316,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1321810194-172.17.0.12-1597565826868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36944,DS-3feacc98-9e37-45cd-b3f6-4cf79b09e988,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-ce2dbb3b-99e4-448c-8a96-60f45992b1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-cbdb3f4a-4be2-4e2e-a51c-d7434ca12304,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-7600b0f7-29c3-4120-9935-8576309325dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-2ec6676d-ec31-4245-8a77-cb09254a7ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-d34d3dc8-bbaa-4989-a422-7016c07a0991,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-c1f7730d-d1b8-40a2-98bc-07194080c71c,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-c064f412-2b59-45ff-b0bf-4164118b6e4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1321810194-172.17.0.12-1597565826868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36944,DS-3feacc98-9e37-45cd-b3f6-4cf79b09e988,DISK], DatanodeInfoWithStorage[127.0.0.1:38385,DS-ce2dbb3b-99e4-448c-8a96-60f45992b1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38065,DS-cbdb3f4a-4be2-4e2e-a51c-d7434ca12304,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-7600b0f7-29c3-4120-9935-8576309325dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-2ec6676d-ec31-4245-8a77-cb09254a7ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-d34d3dc8-bbaa-4989-a422-7016c07a0991,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-c1f7730d-d1b8-40a2-98bc-07194080c71c,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-c064f412-2b59-45ff-b0bf-4164118b6e4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306770792-172.17.0.12-1597565978447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38716,DS-85e81abe-6653-44fc-adbe-015faab79370,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-50664f05-b694-4097-9896-a07809ecbc10,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-a25cea3c-1837-467f-84bb-cc84298da213,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-eaedff11-bfd5-4c07-a3c0-41abff5fe5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-cd10a967-442f-4bec-aa33-24c6a18ecc29,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-28279fbf-bbff-4317-93c3-92d6bb566455,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-c5b52963-ac6a-42df-b326-94f93374944f,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-8e92f85d-7a1c-4795-86dc-cc68c87e8a90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306770792-172.17.0.12-1597565978447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38716,DS-85e81abe-6653-44fc-adbe-015faab79370,DISK], DatanodeInfoWithStorage[127.0.0.1:33850,DS-50664f05-b694-4097-9896-a07809ecbc10,DISK], DatanodeInfoWithStorage[127.0.0.1:43415,DS-a25cea3c-1837-467f-84bb-cc84298da213,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-eaedff11-bfd5-4c07-a3c0-41abff5fe5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43350,DS-cd10a967-442f-4bec-aa33-24c6a18ecc29,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-28279fbf-bbff-4317-93c3-92d6bb566455,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-c5b52963-ac6a-42df-b326-94f93374944f,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-8e92f85d-7a1c-4795-86dc-cc68c87e8a90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-24843663-172.17.0.12-1597566256463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32831,DS-b24cfca9-30be-419d-9333-170ba3e235dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-1a7670b8-df61-448c-909d-fcdeccd35e45,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-5f9b4d3c-3cea-4ed3-b095-59d02b78dc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-77f8afa8-6e7f-4340-bfa1-718ba1df32af,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-d78ba6a5-4e71-4a18-8e6f-66b61c0dc718,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-dcdf5a82-54b6-40f5-8768-4099ac02acd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-2eab06c4-63f8-4537-b15d-fe98afa8aeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-909f5238-aac5-4752-b25b-0251374d9e9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-24843663-172.17.0.12-1597566256463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32831,DS-b24cfca9-30be-419d-9333-170ba3e235dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-1a7670b8-df61-448c-909d-fcdeccd35e45,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-5f9b4d3c-3cea-4ed3-b095-59d02b78dc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36365,DS-77f8afa8-6e7f-4340-bfa1-718ba1df32af,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-d78ba6a5-4e71-4a18-8e6f-66b61c0dc718,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-dcdf5a82-54b6-40f5-8768-4099ac02acd0,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-2eab06c4-63f8-4537-b15d-fe98afa8aeaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-909f5238-aac5-4752-b25b-0251374d9e9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-275358556-172.17.0.12-1597566362587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32838,DS-083f7d82-4b13-4324-a783-ad55f5070d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-fb2bb3d5-41cc-42d0-96f8-16c938076ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-f23c84b4-8a1f-4bea-943f-c09c68935cad,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-26efedc1-fe2b-4d4a-a8b7-20e3323f31fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-4d41aadb-224e-48c4-90f2-e393bb183b89,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-b8a4779f-96e8-4f6b-9600-da51e0f57f36,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-55404078-ddf1-43d0-915a-d02ee6d6c8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-a56297c7-02b2-432e-b50d-931ffaa7a488,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-275358556-172.17.0.12-1597566362587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32838,DS-083f7d82-4b13-4324-a783-ad55f5070d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41397,DS-fb2bb3d5-41cc-42d0-96f8-16c938076ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-f23c84b4-8a1f-4bea-943f-c09c68935cad,DISK], DatanodeInfoWithStorage[127.0.0.1:41951,DS-26efedc1-fe2b-4d4a-a8b7-20e3323f31fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-4d41aadb-224e-48c4-90f2-e393bb183b89,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-b8a4779f-96e8-4f6b-9600-da51e0f57f36,DISK], DatanodeInfoWithStorage[127.0.0.1:46004,DS-55404078-ddf1-43d0-915a-d02ee6d6c8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-a56297c7-02b2-432e-b50d-931ffaa7a488,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1724066330-172.17.0.12-1597566431111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35318,DS-490ef71a-2366-4989-8b07-b21a7e159d69,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-98e5c2af-b9a2-4f0a-850f-b5c5f72a6d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-df5b60be-cfbc-4998-b8a9-4a8be1bfb4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-a1d379b0-aac3-4441-bdd9-14ac7fb4dfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-da06618c-986a-4cbf-b2e3-8da76c005a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-3e5f6306-794e-4626-b262-0788d72c22a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-4ae10bc5-7375-46e9-b652-4cfdcf8eb4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-f6b47e97-b362-4c14-b343-57fd417478d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1724066330-172.17.0.12-1597566431111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35318,DS-490ef71a-2366-4989-8b07-b21a7e159d69,DISK], DatanodeInfoWithStorage[127.0.0.1:44201,DS-98e5c2af-b9a2-4f0a-850f-b5c5f72a6d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-df5b60be-cfbc-4998-b8a9-4a8be1bfb4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44552,DS-a1d379b0-aac3-4441-bdd9-14ac7fb4dfb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-da06618c-986a-4cbf-b2e3-8da76c005a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-3e5f6306-794e-4626-b262-0788d72c22a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-4ae10bc5-7375-46e9-b652-4cfdcf8eb4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-f6b47e97-b362-4c14-b343-57fd417478d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-147699505-172.17.0.12-1597566546500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44566,DS-88604e4e-a2ff-4c5f-9ea8-5d02dff93d68,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-1830e772-2f8e-4b38-a629-34c62fce5ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-b3d271eb-7ea4-43a7-a2cd-cb00dd46eca6,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-19fec611-e8ab-42b5-90f2-b679742d4865,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-10d66154-fedc-4306-920c-2fa21321132e,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-7ad25184-9670-4ad2-8842-0c5f17c23f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-ff80e711-ae73-440f-b5bc-73d9302257c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-5cb2851f-5af2-4517-bf72-91b178018ff1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-147699505-172.17.0.12-1597566546500:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44566,DS-88604e4e-a2ff-4c5f-9ea8-5d02dff93d68,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-1830e772-2f8e-4b38-a629-34c62fce5ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-b3d271eb-7ea4-43a7-a2cd-cb00dd46eca6,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-19fec611-e8ab-42b5-90f2-b679742d4865,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-10d66154-fedc-4306-920c-2fa21321132e,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-7ad25184-9670-4ad2-8842-0c5f17c23f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-ff80e711-ae73-440f-b5bc-73d9302257c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-5cb2851f-5af2-4517-bf72-91b178018ff1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1452460552-172.17.0.12-1597567032070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43254,DS-02f422b9-b053-4713-965f-a7ab423bb5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-e7f6271d-cd2a-4dd5-9baf-f74680234df1,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-2e69644e-41ea-474f-a680-49b1b97051ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-7ba70d12-39b8-49b7-a7f5-160fd286ba54,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-10f762a7-c475-4826-999b-887912931790,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-57f333e7-bd3f-4576-b04f-80d1ed10506a,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-fb77484e-257e-4fe6-a809-d2d34275573b,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-d89c48f5-7bc2-4a57-985b-8c8510a3eeaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1452460552-172.17.0.12-1597567032070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43254,DS-02f422b9-b053-4713-965f-a7ab423bb5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-e7f6271d-cd2a-4dd5-9baf-f74680234df1,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-2e69644e-41ea-474f-a680-49b1b97051ac,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-7ba70d12-39b8-49b7-a7f5-160fd286ba54,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-10f762a7-c475-4826-999b-887912931790,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-57f333e7-bd3f-4576-b04f-80d1ed10506a,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-fb77484e-257e-4fe6-a809-d2d34275573b,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-d89c48f5-7bc2-4a57-985b-8c8510a3eeaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-915693284-172.17.0.12-1597567137889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38449,DS-f5fb1dcf-b01e-47b1-9a50-21b7e0888ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-311d7fb0-6cf6-4ffd-96e7-e514ef4a6c07,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-241a4096-3a6c-4c7f-a566-d99cdb9e4131,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-939524d8-efc8-4bf5-abc0-a8f9781dc399,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-fd827801-13eb-4534-98c5-500e2a8aeebf,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-cbb82ceb-bb4a-40e4-8a82-70bb7ba5436d,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-72046065-a396-4f9e-9ff6-5e3691afa0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-ceb85bb5-be54-4728-adf4-c3dc850bce5e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-915693284-172.17.0.12-1597567137889:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38449,DS-f5fb1dcf-b01e-47b1-9a50-21b7e0888ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-311d7fb0-6cf6-4ffd-96e7-e514ef4a6c07,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-241a4096-3a6c-4c7f-a566-d99cdb9e4131,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-939524d8-efc8-4bf5-abc0-a8f9781dc399,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-fd827801-13eb-4534-98c5-500e2a8aeebf,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-cbb82ceb-bb4a-40e4-8a82-70bb7ba5436d,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-72046065-a396-4f9e-9ff6-5e3691afa0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-ceb85bb5-be54-4728-adf4-c3dc850bce5e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-787689969-172.17.0.12-1597567175212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40654,DS-fe8c5423-fdc8-4707-aeeb-3fdfd9a48469,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-179ee984-4ecc-4d5e-a998-df36ad85ad48,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-689a795f-2901-49eb-a2da-45be7936b13d,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-431dbfae-6518-4009-b962-14f3780ad225,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-c3ed53ab-4344-4208-bd2a-46bedffa392a,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-1a2cded8-724a-425c-ba3c-7ba57954f114,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-0982c148-20c7-4426-8433-f262a3716e38,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-a4bbdf7f-af84-4ec9-a123-3ca0aa701e9c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-787689969-172.17.0.12-1597567175212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40654,DS-fe8c5423-fdc8-4707-aeeb-3fdfd9a48469,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-179ee984-4ecc-4d5e-a998-df36ad85ad48,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-689a795f-2901-49eb-a2da-45be7936b13d,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-431dbfae-6518-4009-b962-14f3780ad225,DISK], DatanodeInfoWithStorage[127.0.0.1:36145,DS-c3ed53ab-4344-4208-bd2a-46bedffa392a,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-1a2cded8-724a-425c-ba3c-7ba57954f114,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-0982c148-20c7-4426-8433-f262a3716e38,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-a4bbdf7f-af84-4ec9-a123-3ca0aa701e9c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2073727975-172.17.0.12-1597567259680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42859,DS-be431834-ed24-4482-a5df-a5ac09929daa,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-b53f1693-99bf-43d2-bfc7-eb0353577e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-f81e95c0-c535-4704-9f0c-7085246615ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-bdacb048-732c-48b0-97d6-e9eb08540236,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-0c0a3d5e-056b-4828-b15c-03251f389473,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-d6c95ff5-1b20-46e8-b7d3-44fd988420a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-1dc320bf-0e61-44d0-80ca-bd01111d6150,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-66695eea-ab68-4b1d-959d-180f6c10f9d4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2073727975-172.17.0.12-1597567259680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42859,DS-be431834-ed24-4482-a5df-a5ac09929daa,DISK], DatanodeInfoWithStorage[127.0.0.1:39625,DS-b53f1693-99bf-43d2-bfc7-eb0353577e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-f81e95c0-c535-4704-9f0c-7085246615ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-bdacb048-732c-48b0-97d6-e9eb08540236,DISK], DatanodeInfoWithStorage[127.0.0.1:33708,DS-0c0a3d5e-056b-4828-b15c-03251f389473,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-d6c95ff5-1b20-46e8-b7d3-44fd988420a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42688,DS-1dc320bf-0e61-44d0-80ca-bd01111d6150,DISK], DatanodeInfoWithStorage[127.0.0.1:45443,DS-66695eea-ab68-4b1d-959d-180f6c10f9d4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-824023873-172.17.0.12-1597567332243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41686,DS-cf5c772d-206b-405c-9772-4f74f02a1b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-f26faed5-a731-4c75-9fd4-bc493b7b3efc,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-774b5b3f-cc82-4ebf-8320-93c6749a6d64,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-5e4d69a1-9668-4094-9c9a-4bf36ae93a01,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-a0f51d55-0965-46e7-9f83-c5b93b6f8959,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-73fd0bd4-c781-4ed7-9727-d855a921494b,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-040c316a-e785-4168-a37b-948a8b07649a,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-d8398624-27ff-4044-918c-a2788e0bb0cf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-824023873-172.17.0.12-1597567332243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41686,DS-cf5c772d-206b-405c-9772-4f74f02a1b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35351,DS-f26faed5-a731-4c75-9fd4-bc493b7b3efc,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-774b5b3f-cc82-4ebf-8320-93c6749a6d64,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-5e4d69a1-9668-4094-9c9a-4bf36ae93a01,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-a0f51d55-0965-46e7-9f83-c5b93b6f8959,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-73fd0bd4-c781-4ed7-9727-d855a921494b,DISK], DatanodeInfoWithStorage[127.0.0.1:43741,DS-040c316a-e785-4168-a37b-948a8b07649a,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-d8398624-27ff-4044-918c-a2788e0bb0cf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1885394090-172.17.0.12-1597567530550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34315,DS-66680ba6-50de-46d6-b38c-97c8dfbf8fea,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-d7fbc9ea-7400-45ec-a4e0-33ec4bd1ad26,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-093a5b7f-5924-4c20-9195-67d15dba0812,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-f4d4ee87-a088-46cf-b82a-2bbe178ec05e,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-378e6243-4dcd-4800-af9d-c3ae93666b56,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-5f18cfde-18e2-4169-bd7d-47876ff32d66,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-0d234ede-0e50-4a1c-a291-b3612e1fc822,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-954b09bf-941c-480d-b36f-eff7bee72bad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1885394090-172.17.0.12-1597567530550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34315,DS-66680ba6-50de-46d6-b38c-97c8dfbf8fea,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-d7fbc9ea-7400-45ec-a4e0-33ec4bd1ad26,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-093a5b7f-5924-4c20-9195-67d15dba0812,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-f4d4ee87-a088-46cf-b82a-2bbe178ec05e,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-378e6243-4dcd-4800-af9d-c3ae93666b56,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-5f18cfde-18e2-4169-bd7d-47876ff32d66,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-0d234ede-0e50-4a1c-a291-b3612e1fc822,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-954b09bf-941c-480d-b36f-eff7bee72bad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1128553510-172.17.0.12-1597567568385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42338,DS-38c1fcc4-33ae-48ae-b977-97f1d1f4f0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-24ced783-480a-4a3b-add4-e56dad9ead38,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-1f51657b-1531-4565-88f9-dbac950d51ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-21af93dd-321b-444a-ac73-c81cb8d001ed,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-b2240a7e-c2f5-4128-8477-eb8666dead2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-7d89e352-5f33-4405-af57-b988fd801f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-9e1d4b6f-8581-4e8f-ac21-323282cef57a,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-06986b87-daa4-46f0-96f3-e1884fa808d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1128553510-172.17.0.12-1597567568385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42338,DS-38c1fcc4-33ae-48ae-b977-97f1d1f4f0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:32968,DS-24ced783-480a-4a3b-add4-e56dad9ead38,DISK], DatanodeInfoWithStorage[127.0.0.1:36836,DS-1f51657b-1531-4565-88f9-dbac950d51ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-21af93dd-321b-444a-ac73-c81cb8d001ed,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-b2240a7e-c2f5-4128-8477-eb8666dead2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34963,DS-7d89e352-5f33-4405-af57-b988fd801f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-9e1d4b6f-8581-4e8f-ac21-323282cef57a,DISK], DatanodeInfoWithStorage[127.0.0.1:34728,DS-06986b87-daa4-46f0-96f3-e1884fa808d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804876420-172.17.0.12-1597567841330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37182,DS-6020d5fc-cc83-4cea-b0d3-6297872f27fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-f2a860c3-4513-44dd-941c-0c4947f49196,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-6d649922-407e-4e90-8553-e37c5c02c5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-d9c20240-3049-45de-878c-095de07480be,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-976bc5a3-894d-40c3-940d-a659bc000a53,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-f0428b99-0ed2-45fc-aed7-cf03367fda88,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-62ebb1a5-3618-4c1a-a362-785f921413f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-5e02869a-be63-4475-841e-c491fc3e9bb4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-804876420-172.17.0.12-1597567841330:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37182,DS-6020d5fc-cc83-4cea-b0d3-6297872f27fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-f2a860c3-4513-44dd-941c-0c4947f49196,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-6d649922-407e-4e90-8553-e37c5c02c5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-d9c20240-3049-45de-878c-095de07480be,DISK], DatanodeInfoWithStorage[127.0.0.1:46189,DS-976bc5a3-894d-40c3-940d-a659bc000a53,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-f0428b99-0ed2-45fc-aed7-cf03367fda88,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-62ebb1a5-3618-4c1a-a362-785f921413f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-5e02869a-be63-4475-841e-c491fc3e9bb4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1611707151-172.17.0.12-1597568001815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38645,DS-c578b2a1-cb91-4456-beb4-7db8def2fa8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-0f6e09dc-7861-44be-847c-f808dbb9d8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-c82b145c-401c-49fc-966b-0c996d46bd57,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-930d996a-192a-4e88-aca9-3353509785c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-91bdc25b-d10c-4b08-b8b0-00c2c2297bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-1a3bbf51-d766-4299-abbc-8a1225b0a81a,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-80e779c4-4642-4676-811f-a7872a8ee4de,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-e8e25011-5dec-474a-a2b3-321e5df62cd9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1611707151-172.17.0.12-1597568001815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38645,DS-c578b2a1-cb91-4456-beb4-7db8def2fa8a,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-0f6e09dc-7861-44be-847c-f808dbb9d8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41178,DS-c82b145c-401c-49fc-966b-0c996d46bd57,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-930d996a-192a-4e88-aca9-3353509785c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-91bdc25b-d10c-4b08-b8b0-00c2c2297bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-1a3bbf51-d766-4299-abbc-8a1225b0a81a,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-80e779c4-4642-4676-811f-a7872a8ee4de,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-e8e25011-5dec-474a-a2b3-321e5df62cd9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1885168690-172.17.0.12-1597568069979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46835,DS-90024537-ccf9-4993-ba61-6bb81fb51bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-175b2826-3d5b-4f9e-bb9b-b377f9d866fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-e7c4ed9d-070b-4da2-b815-23e79d6e2c49,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-e09d4511-f0bc-4362-9c33-2c765088f51f,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-e2d391d0-7c9b-4c2c-a27d-f8472d64069f,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-ad76ec6f-18ae-47fa-9396-534a738fd1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-2054c1fe-8f7d-45ae-b9ef-a4de6346ba97,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-a262f9f0-7e76-461f-af11-1da5cab05c90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1885168690-172.17.0.12-1597568069979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46835,DS-90024537-ccf9-4993-ba61-6bb81fb51bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-175b2826-3d5b-4f9e-bb9b-b377f9d866fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-e7c4ed9d-070b-4da2-b815-23e79d6e2c49,DISK], DatanodeInfoWithStorage[127.0.0.1:36322,DS-e09d4511-f0bc-4362-9c33-2c765088f51f,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-e2d391d0-7c9b-4c2c-a27d-f8472d64069f,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-ad76ec6f-18ae-47fa-9396-534a738fd1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-2054c1fe-8f7d-45ae-b9ef-a4de6346ba97,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-a262f9f0-7e76-461f-af11-1da5cab05c90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2104784113-172.17.0.12-1597568183939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46126,DS-4b29aa45-0e04-4f83-a98c-7679e15e21b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-b58df60a-8bbb-4456-9a7c-22654edaec7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-ccabf941-9891-4a80-8e24-f41a7194bfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-23a7a1d5-5153-45e5-a595-0a2b7c22cc53,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-5bd57ac7-7b25-4b3f-a6c6-ed925783577b,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-78a33c29-32b7-46fa-831a-240987650035,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-40f9275a-a960-4c6e-8ed2-0bd3c2c2533b,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-eb640cc7-101e-4d9b-ae23-750022428b44,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2104784113-172.17.0.12-1597568183939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46126,DS-4b29aa45-0e04-4f83-a98c-7679e15e21b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-b58df60a-8bbb-4456-9a7c-22654edaec7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-ccabf941-9891-4a80-8e24-f41a7194bfe0,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-23a7a1d5-5153-45e5-a595-0a2b7c22cc53,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-5bd57ac7-7b25-4b3f-a6c6-ed925783577b,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-78a33c29-32b7-46fa-831a-240987650035,DISK], DatanodeInfoWithStorage[127.0.0.1:44205,DS-40f9275a-a960-4c6e-8ed2-0bd3c2c2533b,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-eb640cc7-101e-4d9b-ae23-750022428b44,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-688977931-172.17.0.12-1597568252422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39158,DS-2dfba50d-83d1-45a8-a1fe-680537600047,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-d87f6164-b25f-4d15-a231-dbe696f87ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-f6daed4d-5d38-4ada-848e-0d909063a274,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-b2d04954-37aa-488b-8a9d-413d2d77f97d,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-36879c3a-1a91-4b9a-bac1-20345f5537be,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-d71fbfe9-e2bc-4c72-9625-d882f4af2202,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-e2043e95-0d84-4e29-b48e-6747138c2480,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-ea5cfb73-5f22-4658-94f1-627fa0fa7960,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-688977931-172.17.0.12-1597568252422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39158,DS-2dfba50d-83d1-45a8-a1fe-680537600047,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-d87f6164-b25f-4d15-a231-dbe696f87ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-f6daed4d-5d38-4ada-848e-0d909063a274,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-b2d04954-37aa-488b-8a9d-413d2d77f97d,DISK], DatanodeInfoWithStorage[127.0.0.1:34865,DS-36879c3a-1a91-4b9a-bac1-20345f5537be,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-d71fbfe9-e2bc-4c72-9625-d882f4af2202,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-e2043e95-0d84-4e29-b48e-6747138c2480,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-ea5cfb73-5f22-4658-94f1-627fa0fa7960,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1459200982-172.17.0.12-1597568451456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36093,DS-ecb16693-ab98-45a4-95a6-7381af622c09,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-03cd42d3-63b7-4e48-afef-e783857535ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-90dd577c-5b56-45f2-8b0a-4c584b64ef0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-204cabe1-160f-470a-9aba-e7db93f731e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-9450b31f-693a-4468-9759-3531d7fe9bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-d7049bce-868a-4bbf-854f-d6053ae8a326,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-597c66a9-ed09-4edd-92b5-6397ed2560d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-9d5fbb9e-c94b-4972-85e8-7a1053081a7e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1459200982-172.17.0.12-1597568451456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36093,DS-ecb16693-ab98-45a4-95a6-7381af622c09,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-03cd42d3-63b7-4e48-afef-e783857535ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35577,DS-90dd577c-5b56-45f2-8b0a-4c584b64ef0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-204cabe1-160f-470a-9aba-e7db93f731e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-9450b31f-693a-4468-9759-3531d7fe9bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45686,DS-d7049bce-868a-4bbf-854f-d6053ae8a326,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-597c66a9-ed09-4edd-92b5-6397ed2560d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36432,DS-9d5fbb9e-c94b-4972-85e8-7a1053081a7e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1823115023-172.17.0.12-1597568615450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40756,DS-66e2c635-e660-45aa-8640-9cc67722ef59,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-2762043a-7d9f-45cd-a1f4-ca1e6007c200,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-357a91eb-4e2d-40d7-a171-2f2d76032f42,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-4bc3921b-a2ec-48fc-9845-c4c6cf9b26c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-2aaf6323-5148-46ae-b5dd-b6f085567ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-46c8da72-7da4-4034-ab99-f7e9bcc2360e,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-188879d6-fefb-4767-a936-cd1792d32df8,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-e2db1986-ce3b-4bae-9d92-621333cca163,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1823115023-172.17.0.12-1597568615450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40756,DS-66e2c635-e660-45aa-8640-9cc67722ef59,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-2762043a-7d9f-45cd-a1f4-ca1e6007c200,DISK], DatanodeInfoWithStorage[127.0.0.1:46443,DS-357a91eb-4e2d-40d7-a171-2f2d76032f42,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-4bc3921b-a2ec-48fc-9845-c4c6cf9b26c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-2aaf6323-5148-46ae-b5dd-b6f085567ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-46c8da72-7da4-4034-ab99-f7e9bcc2360e,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-188879d6-fefb-4767-a936-cd1792d32df8,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-e2db1986-ce3b-4bae-9d92-621333cca163,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963543073-172.17.0.12-1597568732779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34075,DS-1c3846ab-736d-4e14-8336-80f6975038c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-3598f531-b394-498b-8fff-f623e00e7421,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-cf8b52db-b7ab-4224-8364-a1fa5c22d717,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-e04d1058-37c7-47c5-9967-45dae6fbfddc,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-86628e54-b1de-46f3-979a-92ba31b353dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-7014557d-9215-455c-bf03-24c68174d84a,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-d2f16ed7-8187-49a7-81dc-b3d87a14395e,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-b6836a77-21f0-47f5-8ebb-7dbf5c4d2496,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-963543073-172.17.0.12-1597568732779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34075,DS-1c3846ab-736d-4e14-8336-80f6975038c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33255,DS-3598f531-b394-498b-8fff-f623e00e7421,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-cf8b52db-b7ab-4224-8364-a1fa5c22d717,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-e04d1058-37c7-47c5-9967-45dae6fbfddc,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-86628e54-b1de-46f3-979a-92ba31b353dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33142,DS-7014557d-9215-455c-bf03-24c68174d84a,DISK], DatanodeInfoWithStorage[127.0.0.1:41182,DS-d2f16ed7-8187-49a7-81dc-b3d87a14395e,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-b6836a77-21f0-47f5-8ebb-7dbf5c4d2496,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950065701-172.17.0.12-1597568845799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38723,DS-75a7fd65-d013-407e-ad27-0833be912121,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-c1d9da6a-1a8d-4e5d-9c7a-6dca100e9484,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-cda86ec5-2be1-4c2c-aeae-fa46d4b2fa56,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-f3ca7807-ad88-438c-8391-b3e35e734fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-35b3edfb-9cf6-4261-9376-ef72c87169fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-3be0c9b4-1d4f-4d24-ad5e-f387af8ea807,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-c81e5c5d-5bba-4c81-8a15-a7f923040727,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-7058e8b0-e1a7-4d46-a78f-bda2d8f68e08,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1950065701-172.17.0.12-1597568845799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38723,DS-75a7fd65-d013-407e-ad27-0833be912121,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-c1d9da6a-1a8d-4e5d-9c7a-6dca100e9484,DISK], DatanodeInfoWithStorage[127.0.0.1:40917,DS-cda86ec5-2be1-4c2c-aeae-fa46d4b2fa56,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-f3ca7807-ad88-438c-8391-b3e35e734fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-35b3edfb-9cf6-4261-9376-ef72c87169fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-3be0c9b4-1d4f-4d24-ad5e-f387af8ea807,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-c81e5c5d-5bba-4c81-8a15-a7f923040727,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-7058e8b0-e1a7-4d46-a78f-bda2d8f68e08,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1536780335-172.17.0.12-1597569412649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34141,DS-4d38073a-756e-4c1a-8c45-b851bc00bc39,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-69c3893b-bfcf-4c05-841a-9b5a4c8213e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-91daa1c6-d3d2-4be2-9eda-aea2413ab22d,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-d2231932-7855-4921-81ba-e5a998043782,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-dcf096f4-02b9-402b-9b67-877cc7f85605,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-a16ef112-dbab-4ed3-a952-c50447f36c08,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-bbd22d99-b9e4-4936-b5a0-be92b80ef515,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-1c37c98d-5206-4f0e-9056-f58f497f35f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1536780335-172.17.0.12-1597569412649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34141,DS-4d38073a-756e-4c1a-8c45-b851bc00bc39,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-69c3893b-bfcf-4c05-841a-9b5a4c8213e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42322,DS-91daa1c6-d3d2-4be2-9eda-aea2413ab22d,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-d2231932-7855-4921-81ba-e5a998043782,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-dcf096f4-02b9-402b-9b67-877cc7f85605,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-a16ef112-dbab-4ed3-a952-c50447f36c08,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-bbd22d99-b9e4-4936-b5a0-be92b80ef515,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-1c37c98d-5206-4f0e-9056-f58f497f35f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1421190599-172.17.0.12-1597569524920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36982,DS-9bd1077f-68a1-4b6d-8897-c6fcb425ac30,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-613f75ed-5036-433d-a542-21b0a8465ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-17065787-9ee0-466b-a00a-36be7955341f,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-65413e42-9821-4b00-b2b0-94405843a6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-2399da47-7336-411f-91ce-c2766f24d82f,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-8a9a02ae-6bbb-4efe-a95b-b3740a4ad802,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-174ff525-8424-41e1-a6e8-bd4f1795da53,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-661ff5db-20d1-4ac3-be1b-aed32bb052c6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1421190599-172.17.0.12-1597569524920:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36982,DS-9bd1077f-68a1-4b6d-8897-c6fcb425ac30,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-613f75ed-5036-433d-a542-21b0a8465ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-17065787-9ee0-466b-a00a-36be7955341f,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-65413e42-9821-4b00-b2b0-94405843a6a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-2399da47-7336-411f-91ce-c2766f24d82f,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-8a9a02ae-6bbb-4efe-a95b-b3740a4ad802,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-174ff525-8424-41e1-a6e8-bd4f1795da53,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-661ff5db-20d1-4ac3-be1b-aed32bb052c6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.split.threshold
component: hdfs:DataNode
v1: 1000000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-36367894-172.17.0.12-1597569653336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39624,DS-82782bca-fbf8-4376-91c1-d6ef580e4ece,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-d948b1f4-e2da-407c-82c6-195c16dde61e,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-87ba32b1-1622-48bd-abda-9ab32413bbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-611394fe-e51a-4e1e-ba9c-f75cfa186858,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-f9c6fa62-f38b-4be1-928e-4b9697c19dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-306f6c6e-2d59-4872-9bbd-5c62d197e4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-ebd1f82e-41f7-4728-88c5-e495013b60d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-6d22bc79-01b0-4dbe-870f-b75a31ced1b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-36367894-172.17.0.12-1597569653336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39624,DS-82782bca-fbf8-4376-91c1-d6ef580e4ece,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-d948b1f4-e2da-407c-82c6-195c16dde61e,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-87ba32b1-1622-48bd-abda-9ab32413bbcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45384,DS-611394fe-e51a-4e1e-ba9c-f75cfa186858,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-f9c6fa62-f38b-4be1-928e-4b9697c19dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-306f6c6e-2d59-4872-9bbd-5c62d197e4fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41385,DS-ebd1f82e-41f7-4728-88c5-e495013b60d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33834,DS-6d22bc79-01b0-4dbe-870f-b75a31ced1b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 24 out of 50
result: false positive !!!
Total execution time in seconds : 5724
