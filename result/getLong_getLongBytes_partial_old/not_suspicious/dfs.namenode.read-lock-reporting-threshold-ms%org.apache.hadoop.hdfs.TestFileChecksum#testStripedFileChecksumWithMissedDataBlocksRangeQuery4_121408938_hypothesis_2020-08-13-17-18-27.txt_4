reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1661178584-172.17.0.17-1597339432283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34462,DS-9e793aa9-c993-40d2-a0a5-1e8883d37277,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-540799e6-8997-4d14-9daa-9d7267bd3a96,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-23f0a6a0-af9c-4657-83c5-b85e4fe46432,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-6fbf7bac-6920-4c08-8959-63fef79b7a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-8058773a-5793-4780-8b75-8f03b37e94ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-4cbc55f2-a81c-4b8a-9e40-2fae7ef79374,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-854ece82-a253-4c0d-a4af-b6b82c72432d,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-0c47a73a-4eed-4170-8b62-11f12298776c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1661178584-172.17.0.17-1597339432283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34462,DS-9e793aa9-c993-40d2-a0a5-1e8883d37277,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-540799e6-8997-4d14-9daa-9d7267bd3a96,DISK], DatanodeInfoWithStorage[127.0.0.1:45414,DS-23f0a6a0-af9c-4657-83c5-b85e4fe46432,DISK], DatanodeInfoWithStorage[127.0.0.1:43883,DS-6fbf7bac-6920-4c08-8959-63fef79b7a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-8058773a-5793-4780-8b75-8f03b37e94ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-4cbc55f2-a81c-4b8a-9e40-2fae7ef79374,DISK], DatanodeInfoWithStorage[127.0.0.1:33335,DS-854ece82-a253-4c0d-a4af-b6b82c72432d,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-0c47a73a-4eed-4170-8b62-11f12298776c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629724048-172.17.0.17-1597339475029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40116,DS-3b5c614a-6248-4418-87a1-480c79d62985,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-96cff012-8f86-4341-90f4-c595946fb2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-71fcae94-1a3c-479a-89d9-05021c9eb2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-d6aa12fa-7d2a-4c99-93cf-04229a508fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-c5022613-809d-4f71-98a8-632a4da27a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-d896b531-6c29-49a3-a832-822917fcb670,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-244736ad-20c3-4494-9c66-0fe164ad5a42,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-4f913b6c-5894-4fed-b640-8d1d0be96c3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629724048-172.17.0.17-1597339475029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40116,DS-3b5c614a-6248-4418-87a1-480c79d62985,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-96cff012-8f86-4341-90f4-c595946fb2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-71fcae94-1a3c-479a-89d9-05021c9eb2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-d6aa12fa-7d2a-4c99-93cf-04229a508fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-c5022613-809d-4f71-98a8-632a4da27a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-d896b531-6c29-49a3-a832-822917fcb670,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-244736ad-20c3-4494-9c66-0fe164ad5a42,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-4f913b6c-5894-4fed-b640-8d1d0be96c3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-531151471-172.17.0.17-1597340053773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45251,DS-7d667054-9479-4b5a-97ee-4f5f3b47a6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-496fdb70-ab13-453a-8ca8-5b51d261c678,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-44b0c6c5-bcb1-41bd-b9f9-38403fd79bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-f171bf0e-4c4b-4bfe-9ae3-7b563f3a6da9,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-3977006a-76ad-4432-96b1-acee984cef6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-54ac08d3-5d60-4e38-85ff-b00b1323d257,DISK], DatanodeInfoWithStorage[127.0.0.1:42835,DS-300ff220-dbb2-4c22-80ba-9336201afa87,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-d4f97e05-bfc2-42ad-a8ce-0b8eecf9bc10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-531151471-172.17.0.17-1597340053773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45251,DS-7d667054-9479-4b5a-97ee-4f5f3b47a6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37406,DS-496fdb70-ab13-453a-8ca8-5b51d261c678,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-44b0c6c5-bcb1-41bd-b9f9-38403fd79bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-f171bf0e-4c4b-4bfe-9ae3-7b563f3a6da9,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-3977006a-76ad-4432-96b1-acee984cef6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-54ac08d3-5d60-4e38-85ff-b00b1323d257,DISK], DatanodeInfoWithStorage[127.0.0.1:42835,DS-300ff220-dbb2-4c22-80ba-9336201afa87,DISK], DatanodeInfoWithStorage[127.0.0.1:44295,DS-d4f97e05-bfc2-42ad-a8ce-0b8eecf9bc10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-667300476-172.17.0.17-1597340489579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39428,DS-125f7262-4bd6-46f3-9e37-fbf8117a6df1,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-76edbd60-952e-4cb4-8eac-034a0633f74e,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-7b2446db-7594-4adc-a053-b2747fe8cf81,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-d499f0bd-1a3e-4ba8-aaf8-1cf620c1fdb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-f6af0f78-671a-4e37-9c90-109686ffb4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-60873136-3dc2-4cc9-a14a-8a48db1812c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-fce86139-9038-47bb-b182-50dae5fbe1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-3a1ab223-73ba-4f57-b2bf-b42f4f3e67fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-667300476-172.17.0.17-1597340489579:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39428,DS-125f7262-4bd6-46f3-9e37-fbf8117a6df1,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-76edbd60-952e-4cb4-8eac-034a0633f74e,DISK], DatanodeInfoWithStorage[127.0.0.1:34768,DS-7b2446db-7594-4adc-a053-b2747fe8cf81,DISK], DatanodeInfoWithStorage[127.0.0.1:41944,DS-d499f0bd-1a3e-4ba8-aaf8-1cf620c1fdb4,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-f6af0f78-671a-4e37-9c90-109686ffb4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-60873136-3dc2-4cc9-a14a-8a48db1812c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-fce86139-9038-47bb-b182-50dae5fbe1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-3a1ab223-73ba-4f57-b2bf-b42f4f3e67fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1218317574-172.17.0.17-1597340610225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42394,DS-f8ebefb8-b490-4902-a471-dc2184730a18,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-b2b93b9d-3d24-4374-ae01-032015786b35,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-92f59afe-137b-4968-97da-19c67ad1c95f,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-96beada7-dd68-4e4a-9a4f-3929dcbd0617,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-6e1ace54-dbe2-4a71-a644-7293a7e6237a,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-e2712708-1eee-4f6e-9e2b-46997bff1d45,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-c8951584-1e90-4afb-82ef-3b1db2b64a67,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-9d6344c7-ec5f-4aad-b26b-8a849dc337ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1218317574-172.17.0.17-1597340610225:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42394,DS-f8ebefb8-b490-4902-a471-dc2184730a18,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-b2b93b9d-3d24-4374-ae01-032015786b35,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-92f59afe-137b-4968-97da-19c67ad1c95f,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-96beada7-dd68-4e4a-9a4f-3929dcbd0617,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-6e1ace54-dbe2-4a71-a644-7293a7e6237a,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-e2712708-1eee-4f6e-9e2b-46997bff1d45,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-c8951584-1e90-4afb-82ef-3b1db2b64a67,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-9d6344c7-ec5f-4aad-b26b-8a849dc337ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-363032744-172.17.0.17-1597340893574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39328,DS-ea8ba632-08fd-479b-8f6e-1e13b323bad5,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-6285ce5e-9e63-4e8f-a463-562c3e6865ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-b65c3034-685e-49aa-b433-14f573054912,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-793aee51-8b5f-48a0-978e-66fa3597d67c,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-fcd2dcb0-9af3-4367-8aad-3fee6f485d10,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-fc6f7c31-bf85-4c18-9ec3-42995d687320,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-c6b8da1c-cdf0-4ea2-a9e5-b3020db3ed57,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-279398eb-aa55-4f18-a8fc-b6b16dab93cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-363032744-172.17.0.17-1597340893574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39328,DS-ea8ba632-08fd-479b-8f6e-1e13b323bad5,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-6285ce5e-9e63-4e8f-a463-562c3e6865ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-b65c3034-685e-49aa-b433-14f573054912,DISK], DatanodeInfoWithStorage[127.0.0.1:45655,DS-793aee51-8b5f-48a0-978e-66fa3597d67c,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-fcd2dcb0-9af3-4367-8aad-3fee6f485d10,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-fc6f7c31-bf85-4c18-9ec3-42995d687320,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-c6b8da1c-cdf0-4ea2-a9e5-b3020db3ed57,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-279398eb-aa55-4f18-a8fc-b6b16dab93cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1102533437-172.17.0.17-1597341073105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35755,DS-ce4ce3dc-2119-4d64-bfe0-d6d768ede433,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-7734dada-9ad8-4023-b07f-249401153b44,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-fdbd2658-37c0-46e7-9501-ce6a085db4de,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-70e75a47-2284-4037-b332-e595746a8e95,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-61164a2a-f305-4123-9510-af1af31f811a,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-bd1e6cd4-9115-4746-ae6f-9bcb911ed876,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-8f8bf491-80c8-4da4-abad-d4851b79c815,DISK], DatanodeInfoWithStorage[127.0.0.1:36767,DS-90f5633a-e0c8-4df8-9acd-e79f7749abf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1102533437-172.17.0.17-1597341073105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35755,DS-ce4ce3dc-2119-4d64-bfe0-d6d768ede433,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-7734dada-9ad8-4023-b07f-249401153b44,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-fdbd2658-37c0-46e7-9501-ce6a085db4de,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-70e75a47-2284-4037-b332-e595746a8e95,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-61164a2a-f305-4123-9510-af1af31f811a,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-bd1e6cd4-9115-4746-ae6f-9bcb911ed876,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-8f8bf491-80c8-4da4-abad-d4851b79c815,DISK], DatanodeInfoWithStorage[127.0.0.1:36767,DS-90f5633a-e0c8-4df8-9acd-e79f7749abf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1429983996-172.17.0.17-1597341110613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35577,DS-b8cf38f8-a0b0-4d70-80de-5a49e39813f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-fa7fcf82-adf3-4ab0-b7e5-486e6bc4abfe,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-01296e09-cad0-480f-8c2b-02ab5026efac,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-6a65ec36-4e9a-4633-b970-a927af3131a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-a37f324c-9708-4654-8296-2dfafbe24994,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-ec17e215-962f-4730-9e24-be7fce11a355,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-83d7f47a-fdba-4b76-923d-4c10b09d8beb,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-79f3afd5-164e-4ee2-90a8-b1b5a40d6f30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1429983996-172.17.0.17-1597341110613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35577,DS-b8cf38f8-a0b0-4d70-80de-5a49e39813f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-fa7fcf82-adf3-4ab0-b7e5-486e6bc4abfe,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-01296e09-cad0-480f-8c2b-02ab5026efac,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-6a65ec36-4e9a-4633-b970-a927af3131a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-a37f324c-9708-4654-8296-2dfafbe24994,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-ec17e215-962f-4730-9e24-be7fce11a355,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-83d7f47a-fdba-4b76-923d-4c10b09d8beb,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-79f3afd5-164e-4ee2-90a8-b1b5a40d6f30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-608256672-172.17.0.17-1597342786534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46135,DS-13799e5a-6f49-4e6e-9bf6-67e16f34d249,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-057b5686-9e99-40a3-8b36-a0c7525cb181,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-95bbf000-fd71-47ea-b1d8-82bbd84b7593,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-4357ba74-1ede-4873-8b8b-90f3c969227a,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-1ec58aab-b9b5-4d66-892f-522c60835812,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-6152e1ba-6444-4ce4-b537-03d6a1555338,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-c67a600b-5278-4eec-adf8-4fc04771402a,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-02f43b31-83c3-4d44-ae58-8c07da6db248,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-608256672-172.17.0.17-1597342786534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46135,DS-13799e5a-6f49-4e6e-9bf6-67e16f34d249,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-057b5686-9e99-40a3-8b36-a0c7525cb181,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-95bbf000-fd71-47ea-b1d8-82bbd84b7593,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-4357ba74-1ede-4873-8b8b-90f3c969227a,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-1ec58aab-b9b5-4d66-892f-522c60835812,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-6152e1ba-6444-4ce4-b537-03d6a1555338,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-c67a600b-5278-4eec-adf8-4fc04771402a,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-02f43b31-83c3-4d44-ae58-8c07da6db248,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-518545968-172.17.0.17-1597343100292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42593,DS-e2763876-d70b-4b8f-aba0-426ffc355942,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-601873ca-5320-482a-adc9-ade19cd7ef54,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-f7a8141c-d2a4-4625-8563-486cfd1701c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-e3c7c023-3e2e-4685-a62f-d3b6b1ebda06,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-06865e05-6d8a-4cff-bb92-b48675c7572f,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-6a5b5467-43a0-4876-ae83-f320d2e523ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-302625a2-b29a-475f-9f2a-29687a41987a,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-4e79f743-1076-47e1-8aa7-2dc93b7b4b7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-518545968-172.17.0.17-1597343100292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42593,DS-e2763876-d70b-4b8f-aba0-426ffc355942,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-601873ca-5320-482a-adc9-ade19cd7ef54,DISK], DatanodeInfoWithStorage[127.0.0.1:45082,DS-f7a8141c-d2a4-4625-8563-486cfd1701c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-e3c7c023-3e2e-4685-a62f-d3b6b1ebda06,DISK], DatanodeInfoWithStorage[127.0.0.1:39366,DS-06865e05-6d8a-4cff-bb92-b48675c7572f,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-6a5b5467-43a0-4876-ae83-f320d2e523ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-302625a2-b29a-475f-9f2a-29687a41987a,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-4e79f743-1076-47e1-8aa7-2dc93b7b4b7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567345309-172.17.0.17-1597343141916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40072,DS-3dce5060-7f9e-4bc9-8415-dc7d964126ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-3b595dad-25d8-4648-8134-73a8dccacd73,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-07c899d8-20a1-40a9-befa-39eb061ade33,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-5c36fa0c-b434-430a-ad81-43cff64d447f,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-140d7ce5-5f4e-439d-a7d0-98e993c0814f,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-5a86052e-402f-48e0-85bb-7636736d70f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-dd640afa-3ae1-4306-9e8d-78dfe41d1e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-0a5d4f93-b22d-4441-b168-2adc08b715ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567345309-172.17.0.17-1597343141916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40072,DS-3dce5060-7f9e-4bc9-8415-dc7d964126ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-3b595dad-25d8-4648-8134-73a8dccacd73,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-07c899d8-20a1-40a9-befa-39eb061ade33,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-5c36fa0c-b434-430a-ad81-43cff64d447f,DISK], DatanodeInfoWithStorage[127.0.0.1:41418,DS-140d7ce5-5f4e-439d-a7d0-98e993c0814f,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-5a86052e-402f-48e0-85bb-7636736d70f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38543,DS-dd640afa-3ae1-4306-9e8d-78dfe41d1e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-0a5d4f93-b22d-4441-b168-2adc08b715ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1432834374-172.17.0.17-1597343592663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46715,DS-82a27b26-80cc-4e69-a5bb-ee8040cc21a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-013be4a1-34bc-4823-9bfc-f0d46911b5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-58cccba5-1181-43d2-9cd7-151e5f669189,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-2097b6b7-6d9c-4aea-95e7-1e19040807f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-3462a480-3f24-4b96-98ea-eecd120f1dad,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-55f925cf-bec3-4561-8c96-6a85b3baec39,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-1c81f156-5607-4100-9d51-5149bc74dba5,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-0362d9d6-1006-46c0-b37f-397fd50d1a19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1432834374-172.17.0.17-1597343592663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46715,DS-82a27b26-80cc-4e69-a5bb-ee8040cc21a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-013be4a1-34bc-4823-9bfc-f0d46911b5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-58cccba5-1181-43d2-9cd7-151e5f669189,DISK], DatanodeInfoWithStorage[127.0.0.1:34634,DS-2097b6b7-6d9c-4aea-95e7-1e19040807f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-3462a480-3f24-4b96-98ea-eecd120f1dad,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-55f925cf-bec3-4561-8c96-6a85b3baec39,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-1c81f156-5607-4100-9d51-5149bc74dba5,DISK], DatanodeInfoWithStorage[127.0.0.1:44815,DS-0362d9d6-1006-46c0-b37f-397fd50d1a19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.read-lock-reporting-threshold-ms
component: hdfs:NameNode
v1: 500
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926611109-172.17.0.17-1597344038612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46131,DS-39942643-749a-419a-a6d7-487818e81bee,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-0216a430-0716-4c55-b671-ea0520d18406,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-4e5f5200-f2e2-419a-84ea-7f5012635682,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-1feef311-a58f-4a39-9f78-49e9e3afd46e,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-16c5dc88-7ae4-4b5c-bcba-b5d5cda0c4da,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-d1185fad-5225-49ed-ba95-b35d4cbb32f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-b2cb3a47-293a-4ddb-9a03-c1a1bfe53251,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-24f8a698-6a63-486b-8aef-92723079f828,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926611109-172.17.0.17-1597344038612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46131,DS-39942643-749a-419a-a6d7-487818e81bee,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-0216a430-0716-4c55-b671-ea0520d18406,DISK], DatanodeInfoWithStorage[127.0.0.1:41771,DS-4e5f5200-f2e2-419a-84ea-7f5012635682,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-1feef311-a58f-4a39-9f78-49e9e3afd46e,DISK], DatanodeInfoWithStorage[127.0.0.1:36163,DS-16c5dc88-7ae4-4b5c-bcba-b5d5cda0c4da,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-d1185fad-5225-49ed-ba95-b35d4cbb32f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-b2cb3a47-293a-4ddb-9a03-c1a1bfe53251,DISK], DatanodeInfoWithStorage[127.0.0.1:35638,DS-24f8a698-6a63-486b-8aef-92723079f828,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5493
