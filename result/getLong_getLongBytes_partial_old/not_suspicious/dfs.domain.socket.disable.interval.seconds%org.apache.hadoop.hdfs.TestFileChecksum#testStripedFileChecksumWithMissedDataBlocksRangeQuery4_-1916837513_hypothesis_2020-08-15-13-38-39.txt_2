reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-135613230-172.17.0.9-1597499335357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46172,DS-3e3f3768-b26d-4328-9ca1-6c4e1b0e3c41,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-e67c8cf4-5105-4459-a5be-88728fcfe658,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-137c3ba8-1540-4c46-86bf-ea2d56c5266b,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-c2a2a7d7-14ac-4feb-a384-fe244e7be60e,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-0e35811c-4d6d-46dc-a6bd-17c97e03f36e,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-342e7015-f881-4daf-acc4-ea912466a9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-ff0f1d99-23bc-4521-90d8-f5a8ca4e43f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41627,DS-a85088af-1fdc-4087-b448-9a03ef1ed4cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-135613230-172.17.0.9-1597499335357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46172,DS-3e3f3768-b26d-4328-9ca1-6c4e1b0e3c41,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-e67c8cf4-5105-4459-a5be-88728fcfe658,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-137c3ba8-1540-4c46-86bf-ea2d56c5266b,DISK], DatanodeInfoWithStorage[127.0.0.1:40360,DS-c2a2a7d7-14ac-4feb-a384-fe244e7be60e,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-0e35811c-4d6d-46dc-a6bd-17c97e03f36e,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-342e7015-f881-4daf-acc4-ea912466a9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-ff0f1d99-23bc-4521-90d8-f5a8ca4e43f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41627,DS-a85088af-1fdc-4087-b448-9a03ef1ed4cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-364332691-172.17.0.9-1597499732490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39332,DS-99ef5d25-0810-4b84-a0d9-7f92162fe27f,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-dd04f199-37cd-46c9-a480-095bd9f24d39,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-23c38ea8-e93f-4207-8da4-24356021d908,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-50f09b88-480b-478e-937b-cc63894104a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-83925ae4-be65-42ff-a14d-bb849dc3689c,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-8233d1f6-82ca-459a-9d74-57e95c693ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-3e7b1b71-6b9b-444e-8d63-c3dd04fc5a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-9613768b-1109-4afa-8ec8-146f71432bf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-364332691-172.17.0.9-1597499732490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39332,DS-99ef5d25-0810-4b84-a0d9-7f92162fe27f,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-dd04f199-37cd-46c9-a480-095bd9f24d39,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-23c38ea8-e93f-4207-8da4-24356021d908,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-50f09b88-480b-478e-937b-cc63894104a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-83925ae4-be65-42ff-a14d-bb849dc3689c,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-8233d1f6-82ca-459a-9d74-57e95c693ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-3e7b1b71-6b9b-444e-8d63-c3dd04fc5a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-9613768b-1109-4afa-8ec8-146f71432bf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1655683746-172.17.0.9-1597499919833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42531,DS-ccd7ef58-787b-48de-9a88-c4aa32e23164,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-1bc53df9-5829-458c-859d-864dc3d778c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-a8f6c063-a5c2-44e2-ba18-29fdfef63846,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-6e5e656c-c590-4ca7-ab48-f215de7551f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-e1b92203-147a-4c58-9aae-262e8ca00bab,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-92592bb9-1f0d-4891-b920-4daf53daffd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-8668709f-d4c4-427e-9c75-13ecf0886a67,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-2afb5063-fa9e-433b-b226-c2b939203fdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1655683746-172.17.0.9-1597499919833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42531,DS-ccd7ef58-787b-48de-9a88-c4aa32e23164,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-1bc53df9-5829-458c-859d-864dc3d778c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45923,DS-a8f6c063-a5c2-44e2-ba18-29fdfef63846,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-6e5e656c-c590-4ca7-ab48-f215de7551f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-e1b92203-147a-4c58-9aae-262e8ca00bab,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-92592bb9-1f0d-4891-b920-4daf53daffd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-8668709f-d4c4-427e-9c75-13ecf0886a67,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-2afb5063-fa9e-433b-b226-c2b939203fdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-135478784-172.17.0.9-1597499951578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45894,DS-f716c498-27a4-456e-b4de-d57e510dd62c,DISK], DatanodeInfoWithStorage[127.0.0.1:42251,DS-559b49fe-53e2-4f89-bb47-bb3eacc94e49,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-3ff37262-330b-410c-8228-1a180e049477,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-434e6d52-e086-4d5c-975a-1ffc3f41c58f,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-6a491a17-23a2-4f9e-9cf7-54f1cbecd59d,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-ef9317c6-ef3e-4688-8c95-56d8ea313538,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-7d535d24-d86e-43ce-b719-c71059ea4f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-24bd3ab2-b118-4876-a8d8-7f11c0f2d815,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-135478784-172.17.0.9-1597499951578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45894,DS-f716c498-27a4-456e-b4de-d57e510dd62c,DISK], DatanodeInfoWithStorage[127.0.0.1:42251,DS-559b49fe-53e2-4f89-bb47-bb3eacc94e49,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-3ff37262-330b-410c-8228-1a180e049477,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-434e6d52-e086-4d5c-975a-1ffc3f41c58f,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-6a491a17-23a2-4f9e-9cf7-54f1cbecd59d,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-ef9317c6-ef3e-4688-8c95-56d8ea313538,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-7d535d24-d86e-43ce-b719-c71059ea4f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-24bd3ab2-b118-4876-a8d8-7f11c0f2d815,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-276856032-172.17.0.9-1597500717337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38160,DS-b5a081db-ca8c-40ca-944a-aa45d1c70560,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-2054219c-9d32-42cd-a0bd-dc8403a8d530,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-0e548960-7356-4af1-8029-5f1aea59ce6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-f16bedd2-1fc0-4ff0-8ae3-a66db3bf5803,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-449bb957-572a-4b05-becb-47a755348f32,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-1d0c396d-5286-4719-ad79-358ae734c780,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-ad9ba74b-0b13-4169-94e1-9260a6b6775d,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-0eda2fcf-059a-4ef4-9f32-ced849f07301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-276856032-172.17.0.9-1597500717337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38160,DS-b5a081db-ca8c-40ca-944a-aa45d1c70560,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-2054219c-9d32-42cd-a0bd-dc8403a8d530,DISK], DatanodeInfoWithStorage[127.0.0.1:36516,DS-0e548960-7356-4af1-8029-5f1aea59ce6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-f16bedd2-1fc0-4ff0-8ae3-a66db3bf5803,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-449bb957-572a-4b05-becb-47a755348f32,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-1d0c396d-5286-4719-ad79-358ae734c780,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-ad9ba74b-0b13-4169-94e1-9260a6b6775d,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-0eda2fcf-059a-4ef4-9f32-ced849f07301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2134459394-172.17.0.9-1597502093511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38050,DS-040eb58e-1b64-42d6-9a8b-c9b014330e26,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-af603bb1-dd51-46a3-8006-1023d99f549b,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-fe152f74-de90-4227-a82e-9eefad72214d,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-ef0c8df0-7152-4e64-85a0-d053bc967166,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-eb8e6508-9059-4c52-9455-2235c5e59052,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-bc322a1a-99ef-48e1-ae29-7b0de2f48333,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-71d51828-72c5-4118-9a97-dc089a46873a,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-0d824937-ecb9-4af0-891c-c216a9b522cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2134459394-172.17.0.9-1597502093511:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38050,DS-040eb58e-1b64-42d6-9a8b-c9b014330e26,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-af603bb1-dd51-46a3-8006-1023d99f549b,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-fe152f74-de90-4227-a82e-9eefad72214d,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-ef0c8df0-7152-4e64-85a0-d053bc967166,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-eb8e6508-9059-4c52-9455-2235c5e59052,DISK], DatanodeInfoWithStorage[127.0.0.1:39658,DS-bc322a1a-99ef-48e1-ae29-7b0de2f48333,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-71d51828-72c5-4118-9a97-dc089a46873a,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-0d824937-ecb9-4af0-891c-c216a9b522cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106880842-172.17.0.9-1597502243731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35486,DS-8be099f4-eda8-4c13-aaa0-daae976a2148,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-60cc4589-b16d-458f-ac60-9d33612a3b81,DISK], DatanodeInfoWithStorage[127.0.0.1:39408,DS-b3c26745-3b11-4c41-bcd0-139843b2789d,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-a5e55a95-5848-49fc-81e9-2532da135ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-25ce253f-ea63-4252-839a-1456d51999e2,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-f2400934-351f-4106-b9e6-705c391b3071,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-44210c06-9e2e-4680-bd29-bbfa981f9fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-85fc440b-d562-4fed-a5d1-7ebb43252167,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106880842-172.17.0.9-1597502243731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35486,DS-8be099f4-eda8-4c13-aaa0-daae976a2148,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-60cc4589-b16d-458f-ac60-9d33612a3b81,DISK], DatanodeInfoWithStorage[127.0.0.1:39408,DS-b3c26745-3b11-4c41-bcd0-139843b2789d,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-a5e55a95-5848-49fc-81e9-2532da135ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-25ce253f-ea63-4252-839a-1456d51999e2,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-f2400934-351f-4106-b9e6-705c391b3071,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-44210c06-9e2e-4680-bd29-bbfa981f9fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-85fc440b-d562-4fed-a5d1-7ebb43252167,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-724700879-172.17.0.9-1597502470950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42651,DS-ff1b3436-e67b-45b9-ad23-7bd02ed8e2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-4ac122f7-9789-4ebf-8f35-8201c0a9229d,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-57a6f608-cd0b-4874-8dbc-2ff95bffd64f,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-0d3b3610-a627-40de-8fad-2984fff34193,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-b3f19fc3-dfac-45d9-b4a4-8417035fed91,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-65ddd138-2a01-4cb8-a852-b0927ca4b622,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-ba9f80d0-2823-4180-b350-3f0c90aa3dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-6cf70aa8-c28b-4da8-b0ba-afd0db62fafd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-724700879-172.17.0.9-1597502470950:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42651,DS-ff1b3436-e67b-45b9-ad23-7bd02ed8e2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-4ac122f7-9789-4ebf-8f35-8201c0a9229d,DISK], DatanodeInfoWithStorage[127.0.0.1:44757,DS-57a6f608-cd0b-4874-8dbc-2ff95bffd64f,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-0d3b3610-a627-40de-8fad-2984fff34193,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-b3f19fc3-dfac-45d9-b4a4-8417035fed91,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-65ddd138-2a01-4cb8-a852-b0927ca4b622,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-ba9f80d0-2823-4180-b350-3f0c90aa3dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-6cf70aa8-c28b-4da8-b0ba-afd0db62fafd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1215539072-172.17.0.9-1597502984109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46420,DS-5385318b-99cd-4e47-b1d6-bd6196de692b,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-5b5d914f-04b1-4bde-ab06-c9217ef3688d,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-13090a23-b2ce-4d8e-b3e8-b605294cc260,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-bcfa35df-a991-4eac-b2bc-fa04c1d21e03,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-d08fd24e-2244-4592-a3b6-29e657710ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-5dd07a15-3179-4a09-8ea1-0da404920ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-9db95424-f68c-4db5-bd9b-c0ae9b73e886,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-953d34bb-2c81-468b-b7a1-0a829976b2a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1215539072-172.17.0.9-1597502984109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46420,DS-5385318b-99cd-4e47-b1d6-bd6196de692b,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-5b5d914f-04b1-4bde-ab06-c9217ef3688d,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-13090a23-b2ce-4d8e-b3e8-b605294cc260,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-bcfa35df-a991-4eac-b2bc-fa04c1d21e03,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-d08fd24e-2244-4592-a3b6-29e657710ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:43798,DS-5dd07a15-3179-4a09-8ea1-0da404920ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-9db95424-f68c-4db5-bd9b-c0ae9b73e886,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-953d34bb-2c81-468b-b7a1-0a829976b2a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440039947-172.17.0.9-1597503140801:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46419,DS-f7c85898-ea04-488d-86c9-ffb691c2c26f,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-0371b67b-1004-4f7c-af7c-45479febaf06,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-47177155-0c0f-4155-a60b-27ebc4da87c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-c11f08b7-3bbb-4547-b7a7-abdc3b3dc438,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-d1e8ebd7-e7c7-453b-b9b4-ba54a9737af9,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-7979adad-c951-4f9c-a8dd-e565d1481cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-88d1a5d8-d5a1-4c0d-8663-175efba872a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-10a56284-85f1-43a5-a71a-089f933c10b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440039947-172.17.0.9-1597503140801:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46419,DS-f7c85898-ea04-488d-86c9-ffb691c2c26f,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-0371b67b-1004-4f7c-af7c-45479febaf06,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-47177155-0c0f-4155-a60b-27ebc4da87c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-c11f08b7-3bbb-4547-b7a7-abdc3b3dc438,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-d1e8ebd7-e7c7-453b-b9b4-ba54a9737af9,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-7979adad-c951-4f9c-a8dd-e565d1481cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-88d1a5d8-d5a1-4c0d-8663-175efba872a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-10a56284-85f1-43a5-a71a-089f933c10b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.domain.socket.disable.interval.seconds
component: hdfs:NameNode
v1: 1
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-403228000-172.17.0.9-1597503651155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36390,DS-9d022614-4d09-4ff2-9abe-090bc3ed58f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-f1f0ff8b-ecac-42af-bd84-c7567ed9e54e,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-0ac8f58b-b19f-4151-9ca9-d587d545fbce,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-1c1b15e5-0994-4d3d-aebc-e416366f7395,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-4e2d757b-db44-4019-a918-71dc53ccb307,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-c1622576-f8af-437b-9c08-ac31c3c0b426,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-54ce4316-4998-4292-a590-6d6c44691f20,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-aa793060-72f5-41a6-8f01-1fd746da4ddd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-403228000-172.17.0.9-1597503651155:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36390,DS-9d022614-4d09-4ff2-9abe-090bc3ed58f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-f1f0ff8b-ecac-42af-bd84-c7567ed9e54e,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-0ac8f58b-b19f-4151-9ca9-d587d545fbce,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-1c1b15e5-0994-4d3d-aebc-e416366f7395,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-4e2d757b-db44-4019-a918-71dc53ccb307,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-c1622576-f8af-437b-9c08-ac31c3c0b426,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-54ce4316-4998-4292-a590-6d6c44691f20,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-aa793060-72f5-41a6-8f01-1fd746da4ddd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 5623
