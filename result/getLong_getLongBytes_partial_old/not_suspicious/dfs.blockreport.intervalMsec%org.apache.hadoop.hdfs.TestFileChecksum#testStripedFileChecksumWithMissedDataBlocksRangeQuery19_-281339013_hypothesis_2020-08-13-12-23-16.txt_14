reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-548062865-172.17.0.17-1597321932842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43526,DS-ccc44d5f-1eec-4ad4-97d5-c062f12a703e,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-e2c39727-e07e-4dc1-bc85-42de49e4a1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-19dd481c-8cec-4c3e-a39d-eb941d5d2d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-cd53bfe7-52fd-41cb-a218-47eae16ab76f,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-62895b89-f3ae-4220-a3ab-96a513eadd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-77a51460-344b-4808-8cf2-a0a8f894eba5,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-921d16a7-203b-4818-afd8-a13a5ce4737e,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-c861ec62-9b06-4e9f-b5f0-c8ebcfff0113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-548062865-172.17.0.17-1597321932842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43526,DS-ccc44d5f-1eec-4ad4-97d5-c062f12a703e,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-e2c39727-e07e-4dc1-bc85-42de49e4a1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-19dd481c-8cec-4c3e-a39d-eb941d5d2d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:38083,DS-cd53bfe7-52fd-41cb-a218-47eae16ab76f,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-62895b89-f3ae-4220-a3ab-96a513eadd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-77a51460-344b-4808-8cf2-a0a8f894eba5,DISK], DatanodeInfoWithStorage[127.0.0.1:35702,DS-921d16a7-203b-4818-afd8-a13a5ce4737e,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-c861ec62-9b06-4e9f-b5f0-c8ebcfff0113,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-744113997-172.17.0.17-1597321978118:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41111,DS-71142441-6e77-4c1e-a576-f99e23331e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-88ab7a64-4317-4985-92ce-5ece6980d738,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-fdda6526-2567-43a8-93f6-c99058bc23bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-e83932e3-348c-4830-9d0b-7efae017dedb,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-f42d63e8-5489-4aa5-a3e9-9c650b95477d,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-b6df8cfb-d0fb-4573-9a42-4e9710b2f898,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-b814b53b-fc26-4183-942a-075df7598502,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-c6cfdb52-bcc2-4e40-9921-f06802bb7c75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-744113997-172.17.0.17-1597321978118:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41111,DS-71142441-6e77-4c1e-a576-f99e23331e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-88ab7a64-4317-4985-92ce-5ece6980d738,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-fdda6526-2567-43a8-93f6-c99058bc23bd,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-e83932e3-348c-4830-9d0b-7efae017dedb,DISK], DatanodeInfoWithStorage[127.0.0.1:40016,DS-f42d63e8-5489-4aa5-a3e9-9c650b95477d,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-b6df8cfb-d0fb-4573-9a42-4e9710b2f898,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-b814b53b-fc26-4183-942a-075df7598502,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-c6cfdb52-bcc2-4e40-9921-f06802bb7c75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1177535785-172.17.0.17-1597322234365:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39176,DS-242a91c1-aa09-4163-9eb1-db25287ef692,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-c97729d2-1ca7-4fc3-8770-2ece0d360d57,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-d4ee48d3-ff14-40c2-863c-5251d1b7ab39,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-7edd0478-4ff4-4f76-8a8c-af9cc60f914c,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-dfb41899-297c-48f1-8cbe-15e4f8062d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-2cf38a33-b0cb-41d6-ac27-faa8f189b57b,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-6cb45f7d-2090-4e95-aa23-1d1a96aa4f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-5adaf63d-ec2e-45bc-a0bb-09abfef94fd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1177535785-172.17.0.17-1597322234365:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39176,DS-242a91c1-aa09-4163-9eb1-db25287ef692,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-c97729d2-1ca7-4fc3-8770-2ece0d360d57,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-d4ee48d3-ff14-40c2-863c-5251d1b7ab39,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-7edd0478-4ff4-4f76-8a8c-af9cc60f914c,DISK], DatanodeInfoWithStorage[127.0.0.1:39516,DS-dfb41899-297c-48f1-8cbe-15e4f8062d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-2cf38a33-b0cb-41d6-ac27-faa8f189b57b,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-6cb45f7d-2090-4e95-aa23-1d1a96aa4f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-5adaf63d-ec2e-45bc-a0bb-09abfef94fd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-555994348-172.17.0.17-1597322283307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41975,DS-791795ef-cd8d-4f4b-926f-ca9215a3f399,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-8ef7a68c-30b0-47bd-b5f2-eee0f1381791,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-2ee9dfe2-3849-4b22-815f-79df3886b306,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-a7769e35-6747-4c5a-8077-000032cf474a,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-ceda6569-59ac-460a-942d-1c43233f4c11,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-c5ca2229-d413-447c-85b7-e84c85ba6ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-c7751e9b-1247-4676-bcbd-4ba7fcb85763,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-62b11492-0f3f-4fec-a8b9-808ab404acd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-555994348-172.17.0.17-1597322283307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41975,DS-791795ef-cd8d-4f4b-926f-ca9215a3f399,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-8ef7a68c-30b0-47bd-b5f2-eee0f1381791,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-2ee9dfe2-3849-4b22-815f-79df3886b306,DISK], DatanodeInfoWithStorage[127.0.0.1:35957,DS-a7769e35-6747-4c5a-8077-000032cf474a,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-ceda6569-59ac-460a-942d-1c43233f4c11,DISK], DatanodeInfoWithStorage[127.0.0.1:35197,DS-c5ca2229-d413-447c-85b7-e84c85ba6ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:37433,DS-c7751e9b-1247-4676-bcbd-4ba7fcb85763,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-62b11492-0f3f-4fec-a8b9-808ab404acd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1084505257-172.17.0.17-1597322425139:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37158,DS-e5bdea50-d96b-415b-8735-aecc55ea1f45,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-64ea9404-d9b4-425d-b511-817de1149fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-a80f869f-7673-490a-860d-89550a80d830,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-ebc3f88e-ccd1-4353-92cb-116e9b571479,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-c843de83-7754-4fea-9e80-0556db6dfec8,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-33dc7a0b-1da2-487c-accf-a0a9fff842a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-b74a409b-efb1-4fae-828f-4c908820fc73,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-cfcea4d5-88ee-4c48-b87a-2775b4c4a610,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1084505257-172.17.0.17-1597322425139:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37158,DS-e5bdea50-d96b-415b-8735-aecc55ea1f45,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-64ea9404-d9b4-425d-b511-817de1149fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-a80f869f-7673-490a-860d-89550a80d830,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-ebc3f88e-ccd1-4353-92cb-116e9b571479,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-c843de83-7754-4fea-9e80-0556db6dfec8,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-33dc7a0b-1da2-487c-accf-a0a9fff842a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46792,DS-b74a409b-efb1-4fae-828f-4c908820fc73,DISK], DatanodeInfoWithStorage[127.0.0.1:35996,DS-cfcea4d5-88ee-4c48-b87a-2775b4c4a610,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1137268902-172.17.0.17-1597322528409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39983,DS-989428c1-2fbf-4984-8bc7-cb1334c4a74f,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-fd050103-3c1a-47f4-85c2-033ad69b57e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-95e1af1e-4fd6-4848-aa77-061a8f44fba8,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-3762cff2-edb6-4949-ab8c-7a3dcc72f8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-b54883c3-c289-4c6c-80d5-5953582aec9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-06040672-1357-43cb-a1e8-65aada80c237,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-15fba927-8bfc-48a9-b348-97bc34d0d3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-9ff2b51c-efd0-40bd-a49b-374ab3565cb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1137268902-172.17.0.17-1597322528409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39983,DS-989428c1-2fbf-4984-8bc7-cb1334c4a74f,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-fd050103-3c1a-47f4-85c2-033ad69b57e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-95e1af1e-4fd6-4848-aa77-061a8f44fba8,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-3762cff2-edb6-4949-ab8c-7a3dcc72f8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-b54883c3-c289-4c6c-80d5-5953582aec9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37291,DS-06040672-1357-43cb-a1e8-65aada80c237,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-15fba927-8bfc-48a9-b348-97bc34d0d3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-9ff2b51c-efd0-40bd-a49b-374ab3565cb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-184330629-172.17.0.17-1597322892005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37512,DS-a26bbf60-90f9-4b72-aa8f-d243cd9d50eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-467e079b-b14a-4327-a25a-2d1a011489cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-a03e3872-a4ae-47b4-bed2-de649d9a0025,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-84494b27-6323-4885-9a3c-a66ab125b15f,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-86cbe1ff-9589-4012-8a52-12f6214b3309,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-7cf0f098-f5c4-4fac-906f-689f47fde7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-dc50d288-07c7-4706-b5b9-839a34ff1567,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-9243c8bc-7060-4891-91a2-182479d92059,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-184330629-172.17.0.17-1597322892005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37512,DS-a26bbf60-90f9-4b72-aa8f-d243cd9d50eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34533,DS-467e079b-b14a-4327-a25a-2d1a011489cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-a03e3872-a4ae-47b4-bed2-de649d9a0025,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-84494b27-6323-4885-9a3c-a66ab125b15f,DISK], DatanodeInfoWithStorage[127.0.0.1:44342,DS-86cbe1ff-9589-4012-8a52-12f6214b3309,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-7cf0f098-f5c4-4fac-906f-689f47fde7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-dc50d288-07c7-4706-b5b9-839a34ff1567,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-9243c8bc-7060-4891-91a2-182479d92059,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1800245611-172.17.0.17-1597323020206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33736,DS-93040b34-a1cc-4cca-a48a-91453c66aa44,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-db4a77a0-5573-47e4-a3bb-6c8322b6f34b,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-1a741cd2-f672-4d83-9777-cd6dfb881fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-10bb0ea1-c7b5-4a03-8ab3-53c38583402f,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-a6b7d233-0bd5-4974-bf1a-dd78e98d7669,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-c302e567-2558-4d53-9f0a-db8c07bd5399,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-60ae3120-d1a8-4355-95ae-66662f34855b,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-4c218b0e-196e-40dd-8074-140cd4e974b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1800245611-172.17.0.17-1597323020206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33736,DS-93040b34-a1cc-4cca-a48a-91453c66aa44,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-db4a77a0-5573-47e4-a3bb-6c8322b6f34b,DISK], DatanodeInfoWithStorage[127.0.0.1:44145,DS-1a741cd2-f672-4d83-9777-cd6dfb881fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-10bb0ea1-c7b5-4a03-8ab3-53c38583402f,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-a6b7d233-0bd5-4974-bf1a-dd78e98d7669,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-c302e567-2558-4d53-9f0a-db8c07bd5399,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-60ae3120-d1a8-4355-95ae-66662f34855b,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-4c218b0e-196e-40dd-8074-140cd4e974b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1599228530-172.17.0.17-1597323508368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38923,DS-ebe7feb7-61c7-44e1-a094-74af31b6fd09,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-ebbbf77c-ea46-4db2-8952-e26f5202f282,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-1fd47a4b-06d8-42e4-985a-ef63ddc98c10,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-c8524ba1-c386-4c71-8103-c5bdfb9c819e,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-2c727e13-c60a-4a41-adb8-1851dc57cefa,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-6fd5a118-3283-4015-b7ba-563e56399da7,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-b24c8f33-47ef-4a8f-bc7a-5f57afb60b47,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-d493457b-414d-49ed-9d47-1d808172735c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1599228530-172.17.0.17-1597323508368:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38923,DS-ebe7feb7-61c7-44e1-a094-74af31b6fd09,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-ebbbf77c-ea46-4db2-8952-e26f5202f282,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-1fd47a4b-06d8-42e4-985a-ef63ddc98c10,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-c8524ba1-c386-4c71-8103-c5bdfb9c819e,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-2c727e13-c60a-4a41-adb8-1851dc57cefa,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-6fd5a118-3283-4015-b7ba-563e56399da7,DISK], DatanodeInfoWithStorage[127.0.0.1:41533,DS-b24c8f33-47ef-4a8f-bc7a-5f57afb60b47,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-d493457b-414d-49ed-9d47-1d808172735c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1091285602-172.17.0.17-1597323568132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34501,DS-a46362c0-46a0-4de0-9c47-33fae2f8e8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-44582101-dc46-49d3-b860-9e0a77fe7bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-c92d34f2-18a3-4b38-9681-d7f46f74115d,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-0dd02f9a-f165-4a5f-bf1b-d7d54a9e4bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44821,DS-a701692b-89e2-45ee-80d2-2d642560a746,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-b16808ff-659a-4a0e-ac04-0ef931717b27,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-d0764035-c352-4b81-a72f-ca0d94545afa,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-c9ced92a-cb81-4b25-ad1d-859d888c10eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1091285602-172.17.0.17-1597323568132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34501,DS-a46362c0-46a0-4de0-9c47-33fae2f8e8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37838,DS-44582101-dc46-49d3-b860-9e0a77fe7bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:34205,DS-c92d34f2-18a3-4b38-9681-d7f46f74115d,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-0dd02f9a-f165-4a5f-bf1b-d7d54a9e4bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:44821,DS-a701692b-89e2-45ee-80d2-2d642560a746,DISK], DatanodeInfoWithStorage[127.0.0.1:40394,DS-b16808ff-659a-4a0e-ac04-0ef931717b27,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-d0764035-c352-4b81-a72f-ca0d94545afa,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-c9ced92a-cb81-4b25-ad1d-859d888c10eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1527137250-172.17.0.17-1597323796293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43999,DS-2576d84b-f6e2-4883-89c6-cf44a16e1a23,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-62093518-9a58-43fe-afea-860c94502bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-32843e78-fd77-4e52-993a-82d252f4923a,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-c098d599-76b2-4b3b-ac27-bbea87b6a755,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-5f126f7d-a04d-456e-96ab-1b5e4c02d3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-f049eacd-5077-405a-808d-1b959c724039,DISK], DatanodeInfoWithStorage[127.0.0.1:40587,DS-3268e98f-f78a-4239-b791-b04c25250bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-7a273578-91b4-4d83-9e25-a0a2ce08fac3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1527137250-172.17.0.17-1597323796293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43999,DS-2576d84b-f6e2-4883-89c6-cf44a16e1a23,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-62093518-9a58-43fe-afea-860c94502bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-32843e78-fd77-4e52-993a-82d252f4923a,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-c098d599-76b2-4b3b-ac27-bbea87b6a755,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-5f126f7d-a04d-456e-96ab-1b5e4c02d3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-f049eacd-5077-405a-808d-1b959c724039,DISK], DatanodeInfoWithStorage[127.0.0.1:40587,DS-3268e98f-f78a-4239-b791-b04c25250bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-7a273578-91b4-4d83-9e25-a0a2ce08fac3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1802996909-172.17.0.17-1597324168255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38837,DS-a86c7ac4-82d0-4d86-84c0-298cb3b98eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-1dd04c76-8782-4075-b297-70ad3b76921f,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-475c3bbc-034a-4f83-b62f-f378e4d1540a,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-af336424-baec-4da9-bc41-445cdbf23d95,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-dbe6bd92-78dc-4612-be89-20fc95bcdb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-9f15eb2f-fd62-4119-8ee2-b7f2c489d195,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-ddc92a9d-b983-480c-a147-63f9d980bb82,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-6f99284d-18dd-4b98-9588-a583a19f8312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1802996909-172.17.0.17-1597324168255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38837,DS-a86c7ac4-82d0-4d86-84c0-298cb3b98eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-1dd04c76-8782-4075-b297-70ad3b76921f,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-475c3bbc-034a-4f83-b62f-f378e4d1540a,DISK], DatanodeInfoWithStorage[127.0.0.1:34027,DS-af336424-baec-4da9-bc41-445cdbf23d95,DISK], DatanodeInfoWithStorage[127.0.0.1:35371,DS-dbe6bd92-78dc-4612-be89-20fc95bcdb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-9f15eb2f-fd62-4119-8ee2-b7f2c489d195,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-ddc92a9d-b983-480c-a147-63f9d980bb82,DISK], DatanodeInfoWithStorage[127.0.0.1:36108,DS-6f99284d-18dd-4b98-9588-a583a19f8312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1149743351-172.17.0.17-1597324617193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41140,DS-8b0e5d47-bde5-4090-b076-83b0acb793bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-9b40e155-7c52-4041-9535-e531241e083d,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-143f1870-8653-4bb1-8848-274b05ec1cab,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-e3740535-ec3c-4544-a685-a1604d9f81b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-b7c19e8c-0845-4e53-ade5-f53f80fb596d,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-6a7ddc37-fab7-4241-8893-260f1120f1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-b8d2dc17-98b1-4e89-833e-3e2d9e7dd2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-c1438e7b-0d56-4552-8209-820045b1d704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1149743351-172.17.0.17-1597324617193:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41140,DS-8b0e5d47-bde5-4090-b076-83b0acb793bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-9b40e155-7c52-4041-9535-e531241e083d,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-143f1870-8653-4bb1-8848-274b05ec1cab,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-e3740535-ec3c-4544-a685-a1604d9f81b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45432,DS-b7c19e8c-0845-4e53-ade5-f53f80fb596d,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-6a7ddc37-fab7-4241-8893-260f1120f1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-b8d2dc17-98b1-4e89-833e-3e2d9e7dd2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-c1438e7b-0d56-4552-8209-820045b1d704,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1424294056-172.17.0.17-1597325036249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43581,DS-6f10d10a-25e7-4de9-95b6-7e570ce442e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-0f83ed1f-8716-46ea-9211-8121fcc7be8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-39f93542-12c3-4a00-bbe1-8f4882283ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-cbc14258-6ea6-4b9b-9a92-86cc4aba0f95,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-73323c36-97b9-4c78-ab3b-1c40b5a4e539,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-80826195-2eae-47cb-b39e-3283b7abaf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-ca1f4098-3131-4600-a910-982cb533845f,DISK], DatanodeInfoWithStorage[127.0.0.1:33003,DS-6a5a0455-eaf5-4458-8160-6e6411da77d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1424294056-172.17.0.17-1597325036249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43581,DS-6f10d10a-25e7-4de9-95b6-7e570ce442e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46192,DS-0f83ed1f-8716-46ea-9211-8121fcc7be8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-39f93542-12c3-4a00-bbe1-8f4882283ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:44613,DS-cbc14258-6ea6-4b9b-9a92-86cc4aba0f95,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-73323c36-97b9-4c78-ab3b-1c40b5a4e539,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-80826195-2eae-47cb-b39e-3283b7abaf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-ca1f4098-3131-4600-a910-982cb533845f,DISK], DatanodeInfoWithStorage[127.0.0.1:33003,DS-6a5a0455-eaf5-4458-8160-6e6411da77d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-802101782-172.17.0.17-1597326233918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41252,DS-5b591957-63b4-45f8-a262-132ebe97052b,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-30e2ef06-df9d-48bc-8d5f-adfc2eaa80fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-fe439b5a-620f-4bad-a950-5c1a0ca93d19,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-7477eb01-262f-40e0-b079-07fce7d307d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-a282e7e5-17b8-4e06-a8b5-c8a41260ec01,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-951f3db6-acdb-47cd-9e5a-940c1a975505,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-3891db38-a551-4c94-9243-c38b8344cb7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-92a71719-6197-4cee-b707-03bebc004884,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-802101782-172.17.0.17-1597326233918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41252,DS-5b591957-63b4-45f8-a262-132ebe97052b,DISK], DatanodeInfoWithStorage[127.0.0.1:40331,DS-30e2ef06-df9d-48bc-8d5f-adfc2eaa80fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-fe439b5a-620f-4bad-a950-5c1a0ca93d19,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-7477eb01-262f-40e0-b079-07fce7d307d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-a282e7e5-17b8-4e06-a8b5-c8a41260ec01,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-951f3db6-acdb-47cd-9e5a-940c1a975505,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-3891db38-a551-4c94-9243-c38b8344cb7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-92a71719-6197-4cee-b707-03bebc004884,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-451610437-172.17.0.17-1597326617284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45209,DS-504e6720-7af2-4c07-bee1-0e905db1693a,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-13b8a098-4bfe-4898-a623-1fec407cf191,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-c58ff4bf-9fc1-4d93-9ec9-4079cd8f0bef,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-39797bb0-2bf7-4c3c-84ea-5044f12de796,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-65d6a76c-678e-4377-9a32-33afd71837f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-19124c94-0f34-4b0e-abf9-5e05b527a178,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-a6b9f1d1-e383-4dba-80e3-f39a968b73e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35584,DS-bc58b17c-8ec5-4bf1-aca1-4eb45e4df593,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-451610437-172.17.0.17-1597326617284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45209,DS-504e6720-7af2-4c07-bee1-0e905db1693a,DISK], DatanodeInfoWithStorage[127.0.0.1:41629,DS-13b8a098-4bfe-4898-a623-1fec407cf191,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-c58ff4bf-9fc1-4d93-9ec9-4079cd8f0bef,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-39797bb0-2bf7-4c3c-84ea-5044f12de796,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-65d6a76c-678e-4377-9a32-33afd71837f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-19124c94-0f34-4b0e-abf9-5e05b527a178,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-a6b9f1d1-e383-4dba-80e3-f39a968b73e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35584,DS-bc58b17c-8ec5-4bf1-aca1-4eb45e4df593,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1026082014-172.17.0.17-1597326988082:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43445,DS-e3b4d613-1949-4746-9789-64007713f1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-c53d4625-cc57-4872-ac1d-fd251112690c,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-8a6c6ae7-9e6e-440a-93cc-5ac4b1925c14,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-ec98b0d3-91a6-4043-bd18-58782f4bca20,DISK], DatanodeInfoWithStorage[127.0.0.1:38843,DS-14f84b91-0180-482d-911b-166f7944948b,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-b93ffa61-5141-4806-9a3b-a49350a66a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-ef61422f-8c18-47f1-8d71-4d9545027d04,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-edb83548-836e-4b5e-a19c-155440124c06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1026082014-172.17.0.17-1597326988082:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43445,DS-e3b4d613-1949-4746-9789-64007713f1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-c53d4625-cc57-4872-ac1d-fd251112690c,DISK], DatanodeInfoWithStorage[127.0.0.1:40677,DS-8a6c6ae7-9e6e-440a-93cc-5ac4b1925c14,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-ec98b0d3-91a6-4043-bd18-58782f4bca20,DISK], DatanodeInfoWithStorage[127.0.0.1:38843,DS-14f84b91-0180-482d-911b-166f7944948b,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-b93ffa61-5141-4806-9a3b-a49350a66a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-ef61422f-8c18-47f1-8d71-4d9545027d04,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-edb83548-836e-4b5e-a19c-155440124c06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1686294107-172.17.0.17-1597327136939:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44117,DS-5a87f089-5f25-4b87-b76d-82b50c89069e,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-d860604b-bf5c-4150-adb3-452dcebde288,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-8cb89413-9739-48de-8edc-76dbc028f5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-007b95bc-ad99-411b-b207-ae0a996307cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-a4a2ed2f-5d9e-4d15-85a0-85bfe6b1be7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-e62f6508-4e0e-48d6-9f46-7f6fa5c43caa,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-6fa70ad3-195b-4c8e-9796-9258bcf56137,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-e9499f51-0c7b-4fcb-b80c-81db19d278fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1686294107-172.17.0.17-1597327136939:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44117,DS-5a87f089-5f25-4b87-b76d-82b50c89069e,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-d860604b-bf5c-4150-adb3-452dcebde288,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-8cb89413-9739-48de-8edc-76dbc028f5a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-007b95bc-ad99-411b-b207-ae0a996307cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-a4a2ed2f-5d9e-4d15-85a0-85bfe6b1be7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-e62f6508-4e0e-48d6-9f46-7f6fa5c43caa,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-6fa70ad3-195b-4c8e-9796-9258bcf56137,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-e9499f51-0c7b-4fcb-b80c-81db19d278fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-223674455-172.17.0.17-1597327430195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46112,DS-e757aada-333b-44c3-80ac-50bd6c822b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-8b0b12d3-5bd1-4b55-83df-0f10c43ce581,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-b8a2627c-a857-4548-a531-a1a58edfae93,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-e6824f4e-c238-483d-bb12-e4069c53b23d,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-9316eb54-fa89-4de3-9544-c25c4ed02c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-0d767164-d4f6-4acb-b018-d04ac2426b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-bee69bb8-6021-4fe2-be52-ef80cb89b8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-49b7e205-107b-4438-b3b9-207dc7dc9bb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-223674455-172.17.0.17-1597327430195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46112,DS-e757aada-333b-44c3-80ac-50bd6c822b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-8b0b12d3-5bd1-4b55-83df-0f10c43ce581,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-b8a2627c-a857-4548-a531-a1a58edfae93,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-e6824f4e-c238-483d-bb12-e4069c53b23d,DISK], DatanodeInfoWithStorage[127.0.0.1:41896,DS-9316eb54-fa89-4de3-9544-c25c4ed02c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-0d767164-d4f6-4acb-b018-d04ac2426b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:39508,DS-bee69bb8-6021-4fe2-be52-ef80cb89b8ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37859,DS-49b7e205-107b-4438-b3b9-207dc7dc9bb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 21600000
v2: 21
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1468772679-172.17.0.17-1597328548335:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35985,DS-86801845-5f3b-4a4a-9c79-c2971290f8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-96a30a30-f04e-4a46-8acc-16ccc324f2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-b03817fa-8a12-45d8-be1b-7d5c6c1debcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-fc67be30-6290-40a8-8cf2-4ab9eadb0396,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-b0fa0622-e812-4310-bb09-5ac35a9b33b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-91f9155e-9763-4058-93d8-9284461b6b84,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-391ed2cd-f7f4-4a5a-aec1-7b80e647aead,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-414b7e89-8266-4919-a935-0bdeb8369d19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1468772679-172.17.0.17-1597328548335:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35985,DS-86801845-5f3b-4a4a-9c79-c2971290f8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-96a30a30-f04e-4a46-8acc-16ccc324f2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-b03817fa-8a12-45d8-be1b-7d5c6c1debcb,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-fc67be30-6290-40a8-8cf2-4ab9eadb0396,DISK], DatanodeInfoWithStorage[127.0.0.1:37418,DS-b0fa0622-e812-4310-bb09-5ac35a9b33b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-91f9155e-9763-4058-93d8-9284461b6b84,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-391ed2cd-f7f4-4a5a-aec1-7b80e647aead,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-414b7e89-8266-4919-a935-0bdeb8369d19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 7193
