reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2052934489-172.17.0.21-1597306592352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34455,DS-bbbffcc1-582d-4993-8ede-e214ebc98ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-7b4d40bf-d83d-437a-9246-41f89ab3386d,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-57803d6d-e441-480d-b49e-f772a0e69c56,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-13e8a8a4-2767-43cf-8127-6e2971a4001a,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-a26cbc99-1ee7-4741-9845-d311913666c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-bc2d9d52-08f1-45a5-b46a-ca02c3e4f0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-ddeaf204-0d39-44c6-b954-4ed3607f4a52,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-47900842-09ff-48d8-9729-89b41ee26bb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2052934489-172.17.0.21-1597306592352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34455,DS-bbbffcc1-582d-4993-8ede-e214ebc98ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-7b4d40bf-d83d-437a-9246-41f89ab3386d,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-57803d6d-e441-480d-b49e-f772a0e69c56,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-13e8a8a4-2767-43cf-8127-6e2971a4001a,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-a26cbc99-1ee7-4741-9845-d311913666c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38586,DS-bc2d9d52-08f1-45a5-b46a-ca02c3e4f0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-ddeaf204-0d39-44c6-b954-4ed3607f4a52,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-47900842-09ff-48d8-9729-89b41ee26bb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-338855285-172.17.0.21-1597307174184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37464,DS-d9c60d94-7394-4ef3-8e46-da5aedf73e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-8eb43834-911f-4561-9050-4a1d6a9727e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-ba95d9f9-5d29-42c0-b6da-c253b6cabf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-0bf46aa0-0337-4fda-a4db-b21d56ec7c95,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-aa7d2c0c-ceb0-49e0-a0af-bce48d26a9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-03e9aeeb-cba0-46c4-b44f-1a94d778d345,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-285604f0-a583-4a6f-9196-58ef01fbf010,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-6802e938-5b2c-45c5-ad06-bc3b30b4fbb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-338855285-172.17.0.21-1597307174184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37464,DS-d9c60d94-7394-4ef3-8e46-da5aedf73e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-8eb43834-911f-4561-9050-4a1d6a9727e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36736,DS-ba95d9f9-5d29-42c0-b6da-c253b6cabf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-0bf46aa0-0337-4fda-a4db-b21d56ec7c95,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-aa7d2c0c-ceb0-49e0-a0af-bce48d26a9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-03e9aeeb-cba0-46c4-b44f-1a94d778d345,DISK], DatanodeInfoWithStorage[127.0.0.1:44555,DS-285604f0-a583-4a6f-9196-58ef01fbf010,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-6802e938-5b2c-45c5-ad06-bc3b30b4fbb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1399928223-172.17.0.21-1597307349827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44888,DS-893b45d9-8256-4c8e-b1d1-cbf55aef58ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-6bd5a7bb-83c1-47bb-9b51-a629e5e07a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-db6c8b1d-8730-4936-a6f0-3a7f405fd094,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-7ca62764-5499-4ffd-a9d6-4d7ef52d889b,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-99636d8e-b736-44ec-a3e6-03a057350541,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-46e8a933-cac3-4665-b3d0-49b5825fee09,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-cf3a903d-675b-426b-a443-a37943b3cd88,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-47f7f6b6-f40c-4204-bf2c-17862f2e7f54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1399928223-172.17.0.21-1597307349827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44888,DS-893b45d9-8256-4c8e-b1d1-cbf55aef58ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-6bd5a7bb-83c1-47bb-9b51-a629e5e07a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-db6c8b1d-8730-4936-a6f0-3a7f405fd094,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-7ca62764-5499-4ffd-a9d6-4d7ef52d889b,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-99636d8e-b736-44ec-a3e6-03a057350541,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-46e8a933-cac3-4665-b3d0-49b5825fee09,DISK], DatanodeInfoWithStorage[127.0.0.1:42103,DS-cf3a903d-675b-426b-a443-a37943b3cd88,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-47f7f6b6-f40c-4204-bf2c-17862f2e7f54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-317853737-172.17.0.21-1597307386565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37006,DS-f99ba770-7ded-4357-91ad-41d893108e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-5ad664cc-05cd-4933-a3be-93f71cd55f37,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-9e3b40b0-3385-46f4-9e28-cfcdbf12b136,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-7280a14b-f756-4bf3-af59-d5f843cd90c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-cadc23b7-c4d5-4c3c-a3bc-76cdc3fffe76,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-6e97db20-572f-41a9-9a79-673193d2611b,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-90ed5c0d-e510-4cb0-b2ad-8d0dd252e79e,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-6a70992e-81ba-4560-8200-7393a266dcea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-317853737-172.17.0.21-1597307386565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37006,DS-f99ba770-7ded-4357-91ad-41d893108e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-5ad664cc-05cd-4933-a3be-93f71cd55f37,DISK], DatanodeInfoWithStorage[127.0.0.1:35080,DS-9e3b40b0-3385-46f4-9e28-cfcdbf12b136,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-7280a14b-f756-4bf3-af59-d5f843cd90c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-cadc23b7-c4d5-4c3c-a3bc-76cdc3fffe76,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-6e97db20-572f-41a9-9a79-673193d2611b,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-90ed5c0d-e510-4cb0-b2ad-8d0dd252e79e,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-6a70992e-81ba-4560-8200-7393a266dcea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525017257-172.17.0.21-1597307864017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40890,DS-cb5ebf29-2b64-4156-9ce0-0cef22af68da,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-7f58c256-3872-4d1c-a505-9ceef327b1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-21095f65-8b13-4ece-94ad-a78aae3f747c,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-632a8589-538f-494c-a0b6-900458f31eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-b139b01f-b2fc-42a3-90fd-5670610002cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-726a13ee-8928-4c49-a522-e358b3c34082,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-9f36cd7f-8159-4697-87d3-4d773f860ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-3e5f998e-3437-4ff8-a7d1-7e9a9d8e208f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525017257-172.17.0.21-1597307864017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40890,DS-cb5ebf29-2b64-4156-9ce0-0cef22af68da,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-7f58c256-3872-4d1c-a505-9ceef327b1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-21095f65-8b13-4ece-94ad-a78aae3f747c,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-632a8589-538f-494c-a0b6-900458f31eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-b139b01f-b2fc-42a3-90fd-5670610002cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-726a13ee-8928-4c49-a522-e358b3c34082,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-9f36cd7f-8159-4697-87d3-4d773f860ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-3e5f998e-3437-4ff8-a7d1-7e9a9d8e208f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1443549937-172.17.0.21-1597308011223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45507,DS-ff79f142-3c1d-4fc3-9a50-1eb199a88774,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-17e32cd2-d1ad-48e4-b239-c1547f023b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-960dae55-0910-4278-9a11-72feb6ba0487,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-23439dcf-4d8c-44ad-840a-4cdec132de10,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-db474b1d-cf69-4d66-9c28-4404a1ca6b15,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-cae68c30-cf97-4a8e-bcef-a388ec945b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-dd270d9a-b6dc-4db8-b855-f6d1c35d3f63,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-58c4a975-74d7-427d-b5ac-4914e05f4d6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1443549937-172.17.0.21-1597308011223:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45507,DS-ff79f142-3c1d-4fc3-9a50-1eb199a88774,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-17e32cd2-d1ad-48e4-b239-c1547f023b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-960dae55-0910-4278-9a11-72feb6ba0487,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-23439dcf-4d8c-44ad-840a-4cdec132de10,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-db474b1d-cf69-4d66-9c28-4404a1ca6b15,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-cae68c30-cf97-4a8e-bcef-a388ec945b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-dd270d9a-b6dc-4db8-b855-f6d1c35d3f63,DISK], DatanodeInfoWithStorage[127.0.0.1:39048,DS-58c4a975-74d7-427d-b5ac-4914e05f4d6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-481398909-172.17.0.21-1597308272484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37902,DS-262a2f7d-3a24-43f3-aa38-08d372ac8ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-2951c589-329f-4e71-9842-284684674b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-de5c5ff8-91b1-448a-b142-2dc879fa6fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-5eea9d8e-d649-4e6e-bb83-efa99fee6821,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-e9c28dd1-0fff-4c20-86d3-6ac37d0f6bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-72a0b676-f2e0-4b45-9a6c-31e18a38f99b,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-6c8637a6-b256-4059-be70-efe2a4a9de8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-9d1e58bd-aefd-4ee3-8547-d7b61c7bfce1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-481398909-172.17.0.21-1597308272484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37902,DS-262a2f7d-3a24-43f3-aa38-08d372ac8ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-2951c589-329f-4e71-9842-284684674b6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-de5c5ff8-91b1-448a-b142-2dc879fa6fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-5eea9d8e-d649-4e6e-bb83-efa99fee6821,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-e9c28dd1-0fff-4c20-86d3-6ac37d0f6bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:39026,DS-72a0b676-f2e0-4b45-9a6c-31e18a38f99b,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-6c8637a6-b256-4059-be70-efe2a4a9de8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-9d1e58bd-aefd-4ee3-8547-d7b61c7bfce1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1456743386-172.17.0.21-1597308423204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33785,DS-3750d005-1c3a-4be8-a26c-56827b66250c,DISK], DatanodeInfoWithStorage[127.0.0.1:38206,DS-f5658cb1-8865-4a55-a5af-a4df18df57cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-1d325bd5-15bf-417b-89c6-69faee4e52a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-a4be4a8b-67c7-4c5b-bd4b-87c15f6ee3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-95d801d7-fce7-45df-af65-340b1d4bb55a,DISK], DatanodeInfoWithStorage[127.0.0.1:39103,DS-e11273f7-f167-448b-8bb6-5101d760cbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-8c5482ea-9d5d-4eea-a7a0-1172ffef9ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-ab2a6fb9-d5f9-46cf-a3bf-4afa36489888,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1456743386-172.17.0.21-1597308423204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33785,DS-3750d005-1c3a-4be8-a26c-56827b66250c,DISK], DatanodeInfoWithStorage[127.0.0.1:38206,DS-f5658cb1-8865-4a55-a5af-a4df18df57cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-1d325bd5-15bf-417b-89c6-69faee4e52a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-a4be4a8b-67c7-4c5b-bd4b-87c15f6ee3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-95d801d7-fce7-45df-af65-340b1d4bb55a,DISK], DatanodeInfoWithStorage[127.0.0.1:39103,DS-e11273f7-f167-448b-8bb6-5101d760cbc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34296,DS-8c5482ea-9d5d-4eea-a7a0-1172ffef9ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-ab2a6fb9-d5f9-46cf-a3bf-4afa36489888,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-734414616-172.17.0.21-1597308534430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39574,DS-de0e348a-e2e4-4b51-8dcd-e7a8d161d6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-b504bf28-ad87-461d-802d-ae578ab20a28,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-815e2f07-1fd5-4a63-b05c-a349c2ac0bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-4d3fef08-055a-4d65-8964-25e180cb37c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-43e49329-dd24-4f13-a264-07ae956ed91b,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-a60a1c6c-3a68-4a39-933e-42ad4d995935,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-7f9ae2eb-fc22-472c-ac03-e1f3a8bd3a88,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-da8041df-34eb-4183-b2de-0756a8895a30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-734414616-172.17.0.21-1597308534430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39574,DS-de0e348a-e2e4-4b51-8dcd-e7a8d161d6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-b504bf28-ad87-461d-802d-ae578ab20a28,DISK], DatanodeInfoWithStorage[127.0.0.1:46295,DS-815e2f07-1fd5-4a63-b05c-a349c2ac0bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-4d3fef08-055a-4d65-8964-25e180cb37c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43604,DS-43e49329-dd24-4f13-a264-07ae956ed91b,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-a60a1c6c-3a68-4a39-933e-42ad4d995935,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-7f9ae2eb-fc22-472c-ac03-e1f3a8bd3a88,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-da8041df-34eb-4183-b2de-0756a8895a30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1480353685-172.17.0.21-1597309232677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39155,DS-e1885732-27f5-4caf-bad3-5535d11b6ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-37e77a06-45ae-4ce6-a05f-cb00146496e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-b5c59199-108d-4484-970e-c6c798f04181,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-a1b0f2cf-e423-4910-a43a-1a7e84eba636,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-21e0d962-3566-4341-b8b9-a0d3432e44d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-a5f91f6a-8d54-4c71-a899-12a1634e73d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-e34b6919-a69c-436b-959a-d3f31dfb4034,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-4af84669-ad8f-46ca-8513-ab74f0161402,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1480353685-172.17.0.21-1597309232677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39155,DS-e1885732-27f5-4caf-bad3-5535d11b6ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-37e77a06-45ae-4ce6-a05f-cb00146496e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-b5c59199-108d-4484-970e-c6c798f04181,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-a1b0f2cf-e423-4910-a43a-1a7e84eba636,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-21e0d962-3566-4341-b8b9-a0d3432e44d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-a5f91f6a-8d54-4c71-a899-12a1634e73d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-e34b6919-a69c-436b-959a-d3f31dfb4034,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-4af84669-ad8f-46ca-8513-ab74f0161402,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1379261027-172.17.0.21-1597309423558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35364,DS-28a59b03-2a76-4a3a-922e-8cda0480a7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-9fff739c-baae-47f8-9e2e-91df0b73bb99,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-1b956fb6-8444-48e0-b9d1-285c211721f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-e40e5648-d09d-471d-acd3-b3b8965b7900,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-94f17eae-fc00-47c6-bb05-a3665e7a8e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-8b6d248a-fb0d-45dd-b317-e82ded7a4e98,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-1a69a5ab-8550-4926-a149-46d4af753642,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-7b01d839-2aab-4335-9dd5-d8eb1e3156d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1379261027-172.17.0.21-1597309423558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35364,DS-28a59b03-2a76-4a3a-922e-8cda0480a7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-9fff739c-baae-47f8-9e2e-91df0b73bb99,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-1b956fb6-8444-48e0-b9d1-285c211721f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-e40e5648-d09d-471d-acd3-b3b8965b7900,DISK], DatanodeInfoWithStorage[127.0.0.1:41569,DS-94f17eae-fc00-47c6-bb05-a3665e7a8e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-8b6d248a-fb0d-45dd-b317-e82ded7a4e98,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-1a69a5ab-8550-4926-a149-46d4af753642,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-7b01d839-2aab-4335-9dd5-d8eb1e3156d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-602770062-172.17.0.21-1597309757496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33891,DS-e7aadb8e-6fab-421d-b24d-ac4b603f8a92,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-f0ad7d86-d13c-4d02-b2d7-e9ff58759669,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-bce03522-3dd3-4d15-a97f-9d8a0cfbb634,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-7b2d7559-8ab1-46c2-9ceb-4538fabc40b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-695ac455-9ff7-4647-9cb9-3765622639f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-2b5df7bd-dcc9-4897-83a9-eb88251e3045,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-f58e2d4d-52e4-4b2c-b6d8-ce3c5ac6e708,DISK], DatanodeInfoWithStorage[127.0.0.1:35370,DS-7c258ad7-aa1d-47d6-9811-91fcc07a9ce1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-602770062-172.17.0.21-1597309757496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33891,DS-e7aadb8e-6fab-421d-b24d-ac4b603f8a92,DISK], DatanodeInfoWithStorage[127.0.0.1:41124,DS-f0ad7d86-d13c-4d02-b2d7-e9ff58759669,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-bce03522-3dd3-4d15-a97f-9d8a0cfbb634,DISK], DatanodeInfoWithStorage[127.0.0.1:42812,DS-7b2d7559-8ab1-46c2-9ceb-4538fabc40b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-695ac455-9ff7-4647-9cb9-3765622639f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40651,DS-2b5df7bd-dcc9-4897-83a9-eb88251e3045,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-f58e2d4d-52e4-4b2c-b6d8-ce3c5ac6e708,DISK], DatanodeInfoWithStorage[127.0.0.1:35370,DS-7c258ad7-aa1d-47d6-9811-91fcc07a9ce1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1475147729-172.17.0.21-1597310273139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41114,DS-20e31d2b-5884-4435-9c30-9e339282861c,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-e33223d2-3f0a-44cd-ab92-8fd7d94f8d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-3da6cb7a-9581-463d-9e4a-aea7fc7733d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-d76139be-5482-403a-9e90-bb0533901818,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-547157c9-6ca9-486e-8335-fdbb933973c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-18caa002-8d06-4c33-b6b5-4236d3f56f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-62b2be7d-cf08-4f48-a309-83b9bd9d4bee,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-2282302f-5887-4f83-b8b0-5ac0d2c4a2aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1475147729-172.17.0.21-1597310273139:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41114,DS-20e31d2b-5884-4435-9c30-9e339282861c,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-e33223d2-3f0a-44cd-ab92-8fd7d94f8d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-3da6cb7a-9581-463d-9e4a-aea7fc7733d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-d76139be-5482-403a-9e90-bb0533901818,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-547157c9-6ca9-486e-8335-fdbb933973c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-18caa002-8d06-4c33-b6b5-4236d3f56f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-62b2be7d-cf08-4f48-a309-83b9bd9d4bee,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-2282302f-5887-4f83-b8b0-5ac0d2c4a2aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1023906754-172.17.0.21-1597310955741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38570,DS-092e7840-fe3b-4bed-a036-4b65453f38f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-71b61433-d1fd-437b-8a1e-122acca239ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-7eac2a1d-030f-4046-bf86-d0d4847cc8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-cf13ea24-1959-414a-922f-a831d878d0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-4fd0df25-93ba-4deb-ae8a-6d22a7d461ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-52b56dd8-ba73-46e9-ae60-14f447b0be11,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-c868e61d-770d-46e8-a620-01135b2552a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-3d562bfb-a2cf-4815-9963-36b80c165f28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1023906754-172.17.0.21-1597310955741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38570,DS-092e7840-fe3b-4bed-a036-4b65453f38f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-71b61433-d1fd-437b-8a1e-122acca239ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-7eac2a1d-030f-4046-bf86-d0d4847cc8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-cf13ea24-1959-414a-922f-a831d878d0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40534,DS-4fd0df25-93ba-4deb-ae8a-6d22a7d461ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36252,DS-52b56dd8-ba73-46e9-ae60-14f447b0be11,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-c868e61d-770d-46e8-a620-01135b2552a5,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-3d562bfb-a2cf-4815-9963-36b80c165f28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-732751557-172.17.0.21-1597311035731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39890,DS-bc104ead-81dd-4c64-ab83-2d431d862803,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-db40d211-fa0a-46f4-b02b-bea8b54d78b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-088370ea-ab03-4437-b13e-a243d0ba1601,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-9082e376-e32e-4f98-abbc-bc8c0d21c9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-17caf995-2ef8-49c1-b22e-4500119ec044,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-134fad04-7031-4255-9c4a-b195469ed479,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-44ad6c67-403d-486d-854f-fcdb4e051ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-4a62fec3-ed6c-4089-b04b-1c58a3f7b463,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-732751557-172.17.0.21-1597311035731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39890,DS-bc104ead-81dd-4c64-ab83-2d431d862803,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-db40d211-fa0a-46f4-b02b-bea8b54d78b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-088370ea-ab03-4437-b13e-a243d0ba1601,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-9082e376-e32e-4f98-abbc-bc8c0d21c9d6,DISK], DatanodeInfoWithStorage[127.0.0.1:32848,DS-17caf995-2ef8-49c1-b22e-4500119ec044,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-134fad04-7031-4255-9c4a-b195469ed479,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-44ad6c67-403d-486d-854f-fcdb4e051ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-4a62fec3-ed6c-4089-b04b-1c58a3f7b463,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-350793514-172.17.0.21-1597311156041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43786,DS-51ba2f22-0ee6-452d-b9e6-f9dc0cd61e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-5f298ab5-9ae1-4f3d-89d1-b15f91e5d44e,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-6fcd1315-9d6d-4a8a-a00a-5689db940ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-40aec028-c257-4054-aa4d-acccdfa02181,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-c80f704b-697d-4939-abeb-3da52edba9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-660000ec-53bd-44f0-9f64-dbe2f65295c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-6ba9de76-81a9-4e64-94fc-3fa7692dd249,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-4dc37062-4819-4b63-894f-13f7a79fbc89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-350793514-172.17.0.21-1597311156041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43786,DS-51ba2f22-0ee6-452d-b9e6-f9dc0cd61e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-5f298ab5-9ae1-4f3d-89d1-b15f91e5d44e,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-6fcd1315-9d6d-4a8a-a00a-5689db940ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-40aec028-c257-4054-aa4d-acccdfa02181,DISK], DatanodeInfoWithStorage[127.0.0.1:44986,DS-c80f704b-697d-4939-abeb-3da52edba9a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43564,DS-660000ec-53bd-44f0-9f64-dbe2f65295c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40457,DS-6ba9de76-81a9-4e64-94fc-3fa7692dd249,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-4dc37062-4819-4b63-894f-13f7a79fbc89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.num.extra.edits.retained
component: hdfs:NameNode
v1: 2000000
v2: 1000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2106324678-172.17.0.21-1597311437278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46760,DS-fce558fa-7202-412e-8e99-f1ddb98f8d93,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-6f85148d-bd0c-4c9c-b2d8-5b2cab601529,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-43bab24c-830f-4780-bccf-e75e1be93228,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-e6feb8c9-b641-44c7-9c16-3bc4b68776ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-185a6b84-918b-4679-856f-55a7eda5760c,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-db66841a-3214-491c-a96a-0c430d98b4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-a8bb4ba1-18fb-48dc-b0b8-66509cb55957,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-09c68681-6cec-4c8c-92af-a23047d1ae80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2106324678-172.17.0.21-1597311437278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46760,DS-fce558fa-7202-412e-8e99-f1ddb98f8d93,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-6f85148d-bd0c-4c9c-b2d8-5b2cab601529,DISK], DatanodeInfoWithStorage[127.0.0.1:41693,DS-43bab24c-830f-4780-bccf-e75e1be93228,DISK], DatanodeInfoWithStorage[127.0.0.1:41416,DS-e6feb8c9-b641-44c7-9c16-3bc4b68776ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-185a6b84-918b-4679-856f-55a7eda5760c,DISK], DatanodeInfoWithStorage[127.0.0.1:46363,DS-db66841a-3214-491c-a96a-0c430d98b4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35186,DS-a8bb4ba1-18fb-48dc-b0b8-66509cb55957,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-09c68681-6cec-4c8c-92af-a23047d1ae80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5724
