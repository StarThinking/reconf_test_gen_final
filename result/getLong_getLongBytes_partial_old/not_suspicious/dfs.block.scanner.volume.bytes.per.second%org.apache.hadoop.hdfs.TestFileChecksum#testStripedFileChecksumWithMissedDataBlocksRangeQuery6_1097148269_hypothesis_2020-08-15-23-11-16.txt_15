reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-299014292-172.17.0.15-1597533133608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41177,DS-c9399dcf-0d05-4dcd-ae00-d600869d17db,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-fee5a459-a834-4bb6-ab88-90a380480436,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-e3c3b6e3-62f0-439b-ac5b-e3f4b49fde97,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-ced1a870-a008-4c15-b69c-18105387ff37,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-241fa140-09ef-4940-902f-a3510efa7d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-351f9737-1d42-4a7b-9f13-47d7c08b6296,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-5269d207-5d09-45b9-b8b1-42a3b18b9c52,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-336379c9-982f-4c43-b620-7bca73f6a50a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-299014292-172.17.0.15-1597533133608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41177,DS-c9399dcf-0d05-4dcd-ae00-d600869d17db,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-fee5a459-a834-4bb6-ab88-90a380480436,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-e3c3b6e3-62f0-439b-ac5b-e3f4b49fde97,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-ced1a870-a008-4c15-b69c-18105387ff37,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-241fa140-09ef-4940-902f-a3510efa7d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38741,DS-351f9737-1d42-4a7b-9f13-47d7c08b6296,DISK], DatanodeInfoWithStorage[127.0.0.1:33115,DS-5269d207-5d09-45b9-b8b1-42a3b18b9c52,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-336379c9-982f-4c43-b620-7bca73f6a50a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-412955456-172.17.0.15-1597533462663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34078,DS-601d3848-6383-4cae-9e1e-c4698b82af77,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-7d922613-16f5-4070-90fa-8f675fb54c06,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-3390c58b-f051-4ada-8c37-8bad360a1c91,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-e0962c22-e1fa-4493-8214-30d027af9bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-c21cd9a7-3041-4e7f-8338-4b19299b0f84,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-cea7e491-6244-419b-b662-897eef1d2bce,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-e5782e95-dcdf-4ae1-b900-3d3246113a54,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-31d77575-7bc7-4c47-b2ee-3305f61e591b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-412955456-172.17.0.15-1597533462663:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34078,DS-601d3848-6383-4cae-9e1e-c4698b82af77,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-7d922613-16f5-4070-90fa-8f675fb54c06,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-3390c58b-f051-4ada-8c37-8bad360a1c91,DISK], DatanodeInfoWithStorage[127.0.0.1:40328,DS-e0962c22-e1fa-4493-8214-30d027af9bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-c21cd9a7-3041-4e7f-8338-4b19299b0f84,DISK], DatanodeInfoWithStorage[127.0.0.1:33529,DS-cea7e491-6244-419b-b662-897eef1d2bce,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-e5782e95-dcdf-4ae1-b900-3d3246113a54,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-31d77575-7bc7-4c47-b2ee-3305f61e591b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2021868604-172.17.0.15-1597533504303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35313,DS-31a4b205-fd9c-4bc2-80db-8bc79bd998b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-37b33017-465e-4d48-b407-9ba73c8e01b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-264b2575-4e3c-4910-b9e2-c37dd86951a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-736e09e8-488e-4377-8527-321257ecd325,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-073a69ad-c0b8-481c-8f9f-f30d4e0d1c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-5d3bd6dd-89b4-498d-8cf7-1140f74be2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-83691c9a-141f-4d2a-a682-c2a83eb5b18e,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-faaf1169-01b1-4412-80c7-9e82af4dd519,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2021868604-172.17.0.15-1597533504303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35313,DS-31a4b205-fd9c-4bc2-80db-8bc79bd998b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-37b33017-465e-4d48-b407-9ba73c8e01b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-264b2575-4e3c-4910-b9e2-c37dd86951a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-736e09e8-488e-4377-8527-321257ecd325,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-073a69ad-c0b8-481c-8f9f-f30d4e0d1c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-5d3bd6dd-89b4-498d-8cf7-1140f74be2ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-83691c9a-141f-4d2a-a682-c2a83eb5b18e,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-faaf1169-01b1-4412-80c7-9e82af4dd519,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-801846332-172.17.0.15-1597533540254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37559,DS-d7edf891-2fe2-4017-a80c-107106cd72b4,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-7c95a889-caed-4b9a-aea5-eacd98b2a930,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-9d5a18ac-9b5f-4a0c-804a-655234d71908,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-0a9fd29c-371a-4126-a44e-9a4124522e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-17b1939a-c4b1-4c3b-842e-443ef57dc4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-685ea138-49c2-4ac5-8e42-0b2dd87e2749,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-3de70a07-4d37-461a-9ce8-264ba24e3011,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-8256ced6-3e17-439e-92b3-0d6f28bbd285,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-801846332-172.17.0.15-1597533540254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37559,DS-d7edf891-2fe2-4017-a80c-107106cd72b4,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-7c95a889-caed-4b9a-aea5-eacd98b2a930,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-9d5a18ac-9b5f-4a0c-804a-655234d71908,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-0a9fd29c-371a-4126-a44e-9a4124522e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39751,DS-17b1939a-c4b1-4c3b-842e-443ef57dc4e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-685ea138-49c2-4ac5-8e42-0b2dd87e2749,DISK], DatanodeInfoWithStorage[127.0.0.1:35881,DS-3de70a07-4d37-461a-9ce8-264ba24e3011,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-8256ced6-3e17-439e-92b3-0d6f28bbd285,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1768069472-172.17.0.15-1597533652697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42661,DS-a00f4d3d-777c-4e02-a6c3-5b22a9abd128,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-1e12d4ed-227e-461d-9f2c-18c98e322993,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-efa6e640-a717-46c7-9e26-57a30db0db02,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-fc63fe9a-a3d5-40d4-b13e-f6034267b9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-087d512d-2f27-4b1b-9f64-27dc2b571617,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-2dba3d64-143d-4acc-9ccd-0874df872643,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-15e5c19c-754b-4fe0-a341-dbf0acec58a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-bc66cc48-f9b2-4d55-bd99-1d38a3efaac9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1768069472-172.17.0.15-1597533652697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42661,DS-a00f4d3d-777c-4e02-a6c3-5b22a9abd128,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-1e12d4ed-227e-461d-9f2c-18c98e322993,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-efa6e640-a717-46c7-9e26-57a30db0db02,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-fc63fe9a-a3d5-40d4-b13e-f6034267b9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-087d512d-2f27-4b1b-9f64-27dc2b571617,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-2dba3d64-143d-4acc-9ccd-0874df872643,DISK], DatanodeInfoWithStorage[127.0.0.1:38452,DS-15e5c19c-754b-4fe0-a341-dbf0acec58a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-bc66cc48-f9b2-4d55-bd99-1d38a3efaac9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-485521790-172.17.0.15-1597533809680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34646,DS-90e82cbd-6838-4e86-b62c-17f97c29bcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-a06948a0-e58a-4476-b811-b76c61d75c23,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-c5b9a73e-19b2-471e-80b1-9aed2755df70,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-6ce3cc89-fb58-47be-90b2-32b3fcad0f07,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-a54d730c-d0e2-4006-8217-87f01a8f16dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-5dfedb1c-c644-45df-8dc9-ac7437110498,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-f6518c0c-89a5-4536-9d71-e178ab464b88,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-04a71662-06da-48b4-922a-6f645e5daed7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-485521790-172.17.0.15-1597533809680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34646,DS-90e82cbd-6838-4e86-b62c-17f97c29bcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-a06948a0-e58a-4476-b811-b76c61d75c23,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-c5b9a73e-19b2-471e-80b1-9aed2755df70,DISK], DatanodeInfoWithStorage[127.0.0.1:46423,DS-6ce3cc89-fb58-47be-90b2-32b3fcad0f07,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-a54d730c-d0e2-4006-8217-87f01a8f16dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-5dfedb1c-c644-45df-8dc9-ac7437110498,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-f6518c0c-89a5-4536-9d71-e178ab464b88,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-04a71662-06da-48b4-922a-6f645e5daed7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-168254754-172.17.0.15-1597533894901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38183,DS-4ccc2d31-dde0-42ee-97cd-9a0589cad6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-72e7da6a-9595-49e9-b7ae-8555fbee062b,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-223b955b-9966-492e-9506-3e6549b751f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-3551e95b-b585-484d-900a-432d90184996,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-1ce85b24-22dc-4912-bd9c-9e377f2a5de6,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-93653b55-ce60-419d-8c11-ddec7bc0447b,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-47ea2391-4e2c-4fdc-abc6-c2cd3d43a980,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-06ce9d51-0f3e-438e-a1e5-9ad7a9758b2c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-168254754-172.17.0.15-1597533894901:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38183,DS-4ccc2d31-dde0-42ee-97cd-9a0589cad6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-72e7da6a-9595-49e9-b7ae-8555fbee062b,DISK], DatanodeInfoWithStorage[127.0.0.1:35832,DS-223b955b-9966-492e-9506-3e6549b751f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-3551e95b-b585-484d-900a-432d90184996,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-1ce85b24-22dc-4912-bd9c-9e377f2a5de6,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-93653b55-ce60-419d-8c11-ddec7bc0447b,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-47ea2391-4e2c-4fdc-abc6-c2cd3d43a980,DISK], DatanodeInfoWithStorage[127.0.0.1:38614,DS-06ce9d51-0f3e-438e-a1e5-9ad7a9758b2c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1065116913-172.17.0.15-1597534208474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40705,DS-6a314ffa-7376-4003-8bfe-f80e3fbe9494,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-58282bed-abd5-4887-a9b0-10c874d5fe9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-6478abcc-5795-48fb-b1fe-dad5ac2d7a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-4d7b7041-ddc8-485a-86f1-1543d40f15c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-4c6d608f-3b23-4d86-b4f1-a48cab2b1841,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-07f2640c-d205-42b5-8f42-add10f6df0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-d03e64fa-e377-4b2e-a433-ea384220df7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-63326dbc-a437-4da9-b632-820025ebfde6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1065116913-172.17.0.15-1597534208474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40705,DS-6a314ffa-7376-4003-8bfe-f80e3fbe9494,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-58282bed-abd5-4887-a9b0-10c874d5fe9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-6478abcc-5795-48fb-b1fe-dad5ac2d7a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-4d7b7041-ddc8-485a-86f1-1543d40f15c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46638,DS-4c6d608f-3b23-4d86-b4f1-a48cab2b1841,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-07f2640c-d205-42b5-8f42-add10f6df0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41143,DS-d03e64fa-e377-4b2e-a433-ea384220df7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43223,DS-63326dbc-a437-4da9-b632-820025ebfde6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1867377407-172.17.0.15-1597534247575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44855,DS-ebcc38aa-facf-4e71-a8f5-37b7f97871df,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-534a115b-812c-4a56-a35c-156abd244d47,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-98cf26f3-95dc-496f-90e5-3fb266a9a534,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-c7d50819-1f52-4f7d-986b-5ae577aba9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-db908d81-4a04-4549-9bc8-b5465d74d39d,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-f43bfb5b-6c61-458b-b3c2-d12e13a54ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-038118e0-7f54-4d00-af6e-c25a66b33cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-aa117788-aa50-4a1b-b94a-dfbac6eda1c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1867377407-172.17.0.15-1597534247575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44855,DS-ebcc38aa-facf-4e71-a8f5-37b7f97871df,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-534a115b-812c-4a56-a35c-156abd244d47,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-98cf26f3-95dc-496f-90e5-3fb266a9a534,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-c7d50819-1f52-4f7d-986b-5ae577aba9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-db908d81-4a04-4549-9bc8-b5465d74d39d,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-f43bfb5b-6c61-458b-b3c2-d12e13a54ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-038118e0-7f54-4d00-af6e-c25a66b33cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-aa117788-aa50-4a1b-b94a-dfbac6eda1c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598260064-172.17.0.15-1597534369120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34887,DS-a022ec38-a747-495b-8f10-68e4f62288e6,DISK], DatanodeInfoWithStorage[127.0.0.1:32999,DS-f9961178-ca14-4e32-81be-aa6e5178e378,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-bf3983d6-b0a8-4e0a-9848-16510a9cc931,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-f913fe9a-717a-4d73-ae64-afd8a03451dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-0560b6b2-85f2-498f-8a09-d9cbc12f8363,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-8d1d2475-210f-4c6a-9681-dd2be2fe2a89,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-70cd8f28-2d45-44d0-8f0c-223f8982d026,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-2e69c166-0a50-4bf1-81f2-1c664e20cf27,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598260064-172.17.0.15-1597534369120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34887,DS-a022ec38-a747-495b-8f10-68e4f62288e6,DISK], DatanodeInfoWithStorage[127.0.0.1:32999,DS-f9961178-ca14-4e32-81be-aa6e5178e378,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-bf3983d6-b0a8-4e0a-9848-16510a9cc931,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-f913fe9a-717a-4d73-ae64-afd8a03451dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-0560b6b2-85f2-498f-8a09-d9cbc12f8363,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-8d1d2475-210f-4c6a-9681-dd2be2fe2a89,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-70cd8f28-2d45-44d0-8f0c-223f8982d026,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-2e69c166-0a50-4bf1-81f2-1c664e20cf27,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178785171-172.17.0.15-1597534530900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45768,DS-91c0b3d7-1881-492b-b25b-96dc4eb6e53b,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-4d10607e-ecef-44f7-bb41-c9f3556543b8,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-ba2def94-0e1b-46f5-8817-6bee77035d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-87092e78-5486-464e-adb2-477d351d1721,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-c1a43095-3383-4911-80cb-d16254b64235,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-0c79fe4b-35ef-41bc-bfe9-9907eeb0a7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-8c4ddb86-c4e5-4d7d-9f9e-7e6e5a4d2f48,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-11ea226e-e72d-4359-b15e-536b2f5a9a86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178785171-172.17.0.15-1597534530900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45768,DS-91c0b3d7-1881-492b-b25b-96dc4eb6e53b,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-4d10607e-ecef-44f7-bb41-c9f3556543b8,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-ba2def94-0e1b-46f5-8817-6bee77035d4c,DISK], DatanodeInfoWithStorage[127.0.0.1:46580,DS-87092e78-5486-464e-adb2-477d351d1721,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-c1a43095-3383-4911-80cb-d16254b64235,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-0c79fe4b-35ef-41bc-bfe9-9907eeb0a7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-8c4ddb86-c4e5-4d7d-9f9e-7e6e5a4d2f48,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-11ea226e-e72d-4359-b15e-536b2f5a9a86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192413416-172.17.0.15-1597534613604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35704,DS-f9407fbd-e6b2-4a90-b2c4-a4473dbfa6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-946ec112-6745-47d4-ab7d-48200dd4675e,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-caf8b93e-e530-4ea7-95c2-cee4759d053b,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-28161efa-6546-4c96-ab4d-c46ff83b3c64,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-c0760336-41d4-4a9c-9d40-c29342bec511,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-7cffde06-deea-48b9-8f82-1169a043dec9,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-c58e7c96-40cc-4730-b9d2-3c33a5042944,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-748dd3d0-b020-4ddd-b687-cd2533ae6b39,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192413416-172.17.0.15-1597534613604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35704,DS-f9407fbd-e6b2-4a90-b2c4-a4473dbfa6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-946ec112-6745-47d4-ab7d-48200dd4675e,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-caf8b93e-e530-4ea7-95c2-cee4759d053b,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-28161efa-6546-4c96-ab4d-c46ff83b3c64,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-c0760336-41d4-4a9c-9d40-c29342bec511,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-7cffde06-deea-48b9-8f82-1169a043dec9,DISK], DatanodeInfoWithStorage[127.0.0.1:37217,DS-c58e7c96-40cc-4730-b9d2-3c33a5042944,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-748dd3d0-b020-4ddd-b687-cd2533ae6b39,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-403338647-172.17.0.15-1597535109858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41044,DS-38e35f11-892c-4022-817a-213c9266dd75,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-2a9ad9ea-8b13-461f-8df2-32f500dc9afa,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-d3a1c4aa-00d6-44fa-b1ed-29a15a97221f,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-b291aea7-6cf9-4ba4-afb4-f43532d1b633,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-3b93acf5-eb1a-4eb6-b024-0cd4b3c781f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-948f5a28-576e-411e-b377-fb63c10b0c25,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-8c16310a-2d4a-4ffc-8481-b53f60c96155,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-1e9f7664-71b6-4934-ab32-ed90ba02c584,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-403338647-172.17.0.15-1597535109858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41044,DS-38e35f11-892c-4022-817a-213c9266dd75,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-2a9ad9ea-8b13-461f-8df2-32f500dc9afa,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-d3a1c4aa-00d6-44fa-b1ed-29a15a97221f,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-b291aea7-6cf9-4ba4-afb4-f43532d1b633,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-3b93acf5-eb1a-4eb6-b024-0cd4b3c781f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-948f5a28-576e-411e-b377-fb63c10b0c25,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-8c16310a-2d4a-4ffc-8481-b53f60c96155,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-1e9f7664-71b6-4934-ab32-ed90ba02c584,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-900933213-172.17.0.15-1597535359947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45583,DS-363f36d3-0bfd-4011-af38-35eeae907ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-d3fcce22-b163-4c6f-b770-23ddc6fab619,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-3210e110-cfe0-4280-9057-036fe5f50031,DISK], DatanodeInfoWithStorage[127.0.0.1:46106,DS-eb6ae392-8a0a-435e-88dc-d943dc7034d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-22f36035-f57e-4c38-b296-2ebe8f41165a,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-132cacf4-7bbb-498c-9060-33c449fad98b,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-025bcf9a-e90a-46ca-9a6c-d8b3d31b99a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-ac68f29b-409f-465b-9989-1362a3db4020,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-900933213-172.17.0.15-1597535359947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45583,DS-363f36d3-0bfd-4011-af38-35eeae907ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-d3fcce22-b163-4c6f-b770-23ddc6fab619,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-3210e110-cfe0-4280-9057-036fe5f50031,DISK], DatanodeInfoWithStorage[127.0.0.1:46106,DS-eb6ae392-8a0a-435e-88dc-d943dc7034d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-22f36035-f57e-4c38-b296-2ebe8f41165a,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-132cacf4-7bbb-498c-9060-33c449fad98b,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-025bcf9a-e90a-46ca-9a6c-d8b3d31b99a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-ac68f29b-409f-465b-9989-1362a3db4020,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-257783362-172.17.0.15-1597536012029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33835,DS-96343fa4-7ec2-4b1d-bc79-1d567ef61750,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-7e84f0b2-b39b-49ee-9ccc-bddc6be1e0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-a518b943-ca7c-4f9d-83b2-6b35c4e09dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-b2e625ed-b89d-4bcc-9ec2-546a5f17f3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-b35cefdf-d246-47eb-ac90-08213f5d5d38,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-6917c764-0afa-4d50-b8f5-b29f7d8062b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-c02edc2e-5ec2-4337-a1f1-440f5c4b3ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-ae341165-d288-49db-bcce-4714fcab88a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-257783362-172.17.0.15-1597536012029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33835,DS-96343fa4-7ec2-4b1d-bc79-1d567ef61750,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-7e84f0b2-b39b-49ee-9ccc-bddc6be1e0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33956,DS-a518b943-ca7c-4f9d-83b2-6b35c4e09dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36524,DS-b2e625ed-b89d-4bcc-9ec2-546a5f17f3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-b35cefdf-d246-47eb-ac90-08213f5d5d38,DISK], DatanodeInfoWithStorage[127.0.0.1:38525,DS-6917c764-0afa-4d50-b8f5-b29f7d8062b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-c02edc2e-5ec2-4337-a1f1-440f5c4b3ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-ae341165-d288-49db-bcce-4714fcab88a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1131797870-172.17.0.15-1597536250717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35230,DS-4eb7d531-e88f-4b90-9f2c-f7b2f3d7432f,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-575e6cfc-0f7d-443d-9153-dd02e0805f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-8b36f862-2863-47f2-8eec-4bbe85bb93a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-200d9863-643c-42cd-b243-23987b09c102,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-06ac7c1a-c3e1-4282-8a11-8de54421b948,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-537d6c49-d669-455e-a13a-c4cbb14869ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-2a9b3f4a-cb8f-40d0-ad81-2a40ed60b424,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-96932d83-860b-4734-a137-64d118516b01,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1131797870-172.17.0.15-1597536250717:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35230,DS-4eb7d531-e88f-4b90-9f2c-f7b2f3d7432f,DISK], DatanodeInfoWithStorage[127.0.0.1:45961,DS-575e6cfc-0f7d-443d-9153-dd02e0805f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44191,DS-8b36f862-2863-47f2-8eec-4bbe85bb93a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-200d9863-643c-42cd-b243-23987b09c102,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-06ac7c1a-c3e1-4282-8a11-8de54421b948,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-537d6c49-d669-455e-a13a-c4cbb14869ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-2a9b3f4a-cb8f-40d0-ad81-2a40ed60b424,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-96932d83-860b-4734-a137-64d118516b01,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914072309-172.17.0.15-1597536619589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46184,DS-8df63b45-41e8-4d1c-b6c4-4a1bcf8c1ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-27ecd765-0509-4dff-a6cb-6016b0aa2f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-222eb005-f2b2-49ad-9eb7-92844658666f,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-1d86ca0f-7ccf-43fa-afdf-421828203e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-9d93d173-e014-45c3-a4a2-233518ef5d48,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-12064f18-d7be-4909-9f0f-4020b32f0ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-9e9aa630-f88a-40e6-9b31-09dd451a4da0,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-c980b1e3-bfb6-4bff-b79b-b27feadf3ad4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1914072309-172.17.0.15-1597536619589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46184,DS-8df63b45-41e8-4d1c-b6c4-4a1bcf8c1ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-27ecd765-0509-4dff-a6cb-6016b0aa2f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46821,DS-222eb005-f2b2-49ad-9eb7-92844658666f,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-1d86ca0f-7ccf-43fa-afdf-421828203e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-9d93d173-e014-45c3-a4a2-233518ef5d48,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-12064f18-d7be-4909-9f0f-4020b32f0ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-9e9aa630-f88a-40e6-9b31-09dd451a4da0,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-c980b1e3-bfb6-4bff-b79b-b27feadf3ad4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1750571533-172.17.0.15-1597536693384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33633,DS-5ea92037-8b04-4ddb-83e0-d5a9798f9610,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-ea21993e-26f8-4c7a-8f3b-ad6fb0ec740f,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-574ab1c3-2f36-4b92-bfbb-e74bba2cd0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-00b70ab9-55cd-4258-a9cd-0e916f4c29a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-98f62a4e-539d-4c0f-86de-898bbe112709,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-2a0bb695-79e7-4887-bcc9-aada2032f28b,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-fb440282-cd77-46ae-8cbe-0da64188dd17,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-75f743b0-c9ff-4759-80ca-f563724c83e3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1750571533-172.17.0.15-1597536693384:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33633,DS-5ea92037-8b04-4ddb-83e0-d5a9798f9610,DISK], DatanodeInfoWithStorage[127.0.0.1:46532,DS-ea21993e-26f8-4c7a-8f3b-ad6fb0ec740f,DISK], DatanodeInfoWithStorage[127.0.0.1:37942,DS-574ab1c3-2f36-4b92-bfbb-e74bba2cd0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-00b70ab9-55cd-4258-a9cd-0e916f4c29a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-98f62a4e-539d-4c0f-86de-898bbe112709,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-2a0bb695-79e7-4887-bcc9-aada2032f28b,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-fb440282-cd77-46ae-8cbe-0da64188dd17,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-75f743b0-c9ff-4759-80ca-f563724c83e3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245232164-172.17.0.15-1597536855768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45710,DS-f7e7d7ea-bb98-4b6a-8aad-1a3f09c7dadf,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-554191d5-5bdf-465c-ba12-023e3256dab8,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-237c732f-1c23-452d-bb36-bcbdd7399acc,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-f41b8bb1-54b9-46da-90b4-0394571cd1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45528,DS-9466feeb-2c08-46ce-a474-633dbb2dbf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-954343a7-3aaf-4cac-9868-e16223a001de,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-6d64a87c-8c95-4afc-ad99-678c2830d69d,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-55a7ce20-a797-4d40-b381-48f0a6d1bb55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245232164-172.17.0.15-1597536855768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45710,DS-f7e7d7ea-bb98-4b6a-8aad-1a3f09c7dadf,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-554191d5-5bdf-465c-ba12-023e3256dab8,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-237c732f-1c23-452d-bb36-bcbdd7399acc,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-f41b8bb1-54b9-46da-90b4-0394571cd1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45528,DS-9466feeb-2c08-46ce-a474-633dbb2dbf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-954343a7-3aaf-4cac-9868-e16223a001de,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-6d64a87c-8c95-4afc-ad99-678c2830d69d,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-55a7ce20-a797-4d40-b381-48f0a6d1bb55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1733039150-172.17.0.15-1597536935056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45429,DS-3f95431b-d4d8-4a1e-aac0-56bf4b02f8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-7d261a48-4780-4057-ae55-bd57e11822d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-179766a8-de53-429a-a8bb-fdde2f72ad9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-641a42fe-2003-47e2-b37b-92a96227015b,DISK], DatanodeInfoWithStorage[127.0.0.1:45754,DS-a9eb1c2c-b119-4ade-9390-5edf170cf777,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-f6a80af7-7a97-4dbd-86b7-13e2825b0c54,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-c775ce59-849d-43aa-b046-fc49fb083054,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-a6b985d6-a30b-4e27-b7c1-7bf4df9dfc61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1733039150-172.17.0.15-1597536935056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45429,DS-3f95431b-d4d8-4a1e-aac0-56bf4b02f8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-7d261a48-4780-4057-ae55-bd57e11822d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-179766a8-de53-429a-a8bb-fdde2f72ad9e,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-641a42fe-2003-47e2-b37b-92a96227015b,DISK], DatanodeInfoWithStorage[127.0.0.1:45754,DS-a9eb1c2c-b119-4ade-9390-5edf170cf777,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-f6a80af7-7a97-4dbd-86b7-13e2825b0c54,DISK], DatanodeInfoWithStorage[127.0.0.1:32943,DS-c775ce59-849d-43aa-b046-fc49fb083054,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-a6b985d6-a30b-4e27-b7c1-7bf4df9dfc61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988188627-172.17.0.15-1597537296364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38772,DS-0b58780d-1739-40bf-8bfa-6bf88f18b916,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-b81ebefb-e319-4a91-b9c2-30ff1330831a,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-5f78ed69-b79b-4fa1-b757-d0c75b961f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-f2e0c8a8-eabf-4404-b8ee-a50c139b83ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-1ecd742e-b184-4c01-83c8-ca5fd56ee978,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-9a1ce8b5-3d31-4f25-a971-bb258d94f91b,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-07553646-1e27-45a3-b674-8739cc4e9ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-3135e919-8ed3-4025-8021-994cfc2abe12,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988188627-172.17.0.15-1597537296364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38772,DS-0b58780d-1739-40bf-8bfa-6bf88f18b916,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-b81ebefb-e319-4a91-b9c2-30ff1330831a,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-5f78ed69-b79b-4fa1-b757-d0c75b961f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-f2e0c8a8-eabf-4404-b8ee-a50c139b83ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-1ecd742e-b184-4c01-83c8-ca5fd56ee978,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-9a1ce8b5-3d31-4f25-a971-bb258d94f91b,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-07553646-1e27-45a3-b674-8739cc4e9ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-3135e919-8ed3-4025-8021-994cfc2abe12,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457342427-172.17.0.15-1597537418397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45756,DS-43809165-c99b-49c1-96cb-0ef7197ba306,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-ede3d9cd-adb9-41c4-978c-903058d45ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-9493dfeb-13a4-495e-8c47-ff1a0899d908,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-2d10c598-98f0-46fe-ad73-fb646a33ffa1,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-27795642-785e-440d-9bab-a110532bfdc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-e87a134a-e9ad-4018-b8e9-5a903ff623de,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-20715c90-cb43-4291-9fe0-460c5c914076,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-ac571c8e-a795-415d-8470-2fb5b5676306,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457342427-172.17.0.15-1597537418397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45756,DS-43809165-c99b-49c1-96cb-0ef7197ba306,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-ede3d9cd-adb9-41c4-978c-903058d45ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-9493dfeb-13a4-495e-8c47-ff1a0899d908,DISK], DatanodeInfoWithStorage[127.0.0.1:44101,DS-2d10c598-98f0-46fe-ad73-fb646a33ffa1,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-27795642-785e-440d-9bab-a110532bfdc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-e87a134a-e9ad-4018-b8e9-5a903ff623de,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-20715c90-cb43-4291-9fe0-460c5c914076,DISK], DatanodeInfoWithStorage[127.0.0.1:34666,DS-ac571c8e-a795-415d-8470-2fb5b5676306,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512295145-172.17.0.15-1597537497772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44065,DS-bd506fb8-8b2d-4a57-99f1-53735c2b2e53,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-1063173d-a3a0-4709-b6f6-0f3c941480fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-42bb54a6-afd0-433e-ad63-0942dd61fe02,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-4657dd18-d777-426c-bff6-ed23dd4c68c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-d3e93375-71cb-49b9-a54f-d7659a7fbb57,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-d2afa319-6958-4c97-85d6-11ffb866e5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-17875d61-3fc1-433d-bca4-00184c8d31e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-e2dc8041-60c9-4d6e-929a-a4bc801f9bf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512295145-172.17.0.15-1597537497772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44065,DS-bd506fb8-8b2d-4a57-99f1-53735c2b2e53,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-1063173d-a3a0-4709-b6f6-0f3c941480fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-42bb54a6-afd0-433e-ad63-0942dd61fe02,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-4657dd18-d777-426c-bff6-ed23dd4c68c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-d3e93375-71cb-49b9-a54f-d7659a7fbb57,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-d2afa319-6958-4c97-85d6-11ffb866e5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41788,DS-17875d61-3fc1-433d-bca4-00184c8d31e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-e2dc8041-60c9-4d6e-929a-a4bc801f9bf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1623498309-172.17.0.15-1597537590808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36476,DS-9a71753c-3048-4f9b-a522-3adce58fb248,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-885cf1d3-e2ea-46e5-b04a-eb02010752f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-ca70fefa-3420-408e-983e-eb2bd065a44c,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-82bb90aa-802a-4fcc-af0b-3de456fc6216,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-42669eec-4bb1-43c1-ba35-66d168b25066,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-9e9ec7c6-ff68-48b4-a080-b2680182974a,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-0f79379b-53f3-42c4-ade5-6e8675b2e345,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-c49a9cbd-af98-4135-a904-4cebb2fb2a08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1623498309-172.17.0.15-1597537590808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36476,DS-9a71753c-3048-4f9b-a522-3adce58fb248,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-885cf1d3-e2ea-46e5-b04a-eb02010752f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-ca70fefa-3420-408e-983e-eb2bd065a44c,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-82bb90aa-802a-4fcc-af0b-3de456fc6216,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-42669eec-4bb1-43c1-ba35-66d168b25066,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-9e9ec7c6-ff68-48b4-a080-b2680182974a,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-0f79379b-53f3-42c4-ade5-6e8675b2e345,DISK], DatanodeInfoWithStorage[127.0.0.1:35841,DS-c49a9cbd-af98-4135-a904-4cebb2fb2a08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518289788-172.17.0.15-1597537714898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33690,DS-2513963b-85d1-4ff5-9bb7-4d407d1184fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-4734c7a1-c251-4dce-b357-cfeba2aecb81,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-7c09d327-0044-4f60-980d-4948d295267d,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-67db52fa-e8fb-447f-85a5-1904083b02b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-a71ed205-a87b-47cc-bc3b-db1c0558407b,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-a0cb95c8-b050-44fe-ab86-38b6d35613c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-a090e7e3-4579-4921-9dbd-728ced9782e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-02cda9b6-6663-4100-9482-a85fac2e3df1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518289788-172.17.0.15-1597537714898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33690,DS-2513963b-85d1-4ff5-9bb7-4d407d1184fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-4734c7a1-c251-4dce-b357-cfeba2aecb81,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-7c09d327-0044-4f60-980d-4948d295267d,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-67db52fa-e8fb-447f-85a5-1904083b02b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35964,DS-a71ed205-a87b-47cc-bc3b-db1c0558407b,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-a0cb95c8-b050-44fe-ab86-38b6d35613c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-a090e7e3-4579-4921-9dbd-728ced9782e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37528,DS-02cda9b6-6663-4100-9482-a85fac2e3df1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1089750006-172.17.0.15-1597537790603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42391,DS-92e0a1c6-7bb1-4b73-8dd1-48d17a9e29ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-becd82e8-68f7-4a6b-a000-ac0091889ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-69df1b66-799c-4552-a639-7fb2129a290f,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-e94b839f-1cc7-4082-8333-dbbe3f45b672,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-e3ec063e-0549-48cf-b917-3b1fabd1be3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-f689e0d6-e614-4cde-beef-0cd0c2417e98,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-a7f528fe-0fcc-4e92-a418-763f15957676,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-ebee7a40-e567-4dc0-b00b-157655ba88bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1089750006-172.17.0.15-1597537790603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42391,DS-92e0a1c6-7bb1-4b73-8dd1-48d17a9e29ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-becd82e8-68f7-4a6b-a000-ac0091889ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:43655,DS-69df1b66-799c-4552-a639-7fb2129a290f,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-e94b839f-1cc7-4082-8333-dbbe3f45b672,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-e3ec063e-0549-48cf-b917-3b1fabd1be3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-f689e0d6-e614-4cde-beef-0cd0c2417e98,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-a7f528fe-0fcc-4e92-a418-763f15957676,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-ebee7a40-e567-4dc0-b00b-157655ba88bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689598481-172.17.0.15-1597537954359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39232,DS-d9e873e2-47aa-4ee6-ba9b-44586f265718,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-820bd646-0d39-469c-80ce-edb428979ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-54c5e8f7-12b8-4bbe-91fa-42543248c5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-7c148eb7-a476-431f-85e4-4f16961832a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-3bcd465b-a3b8-4513-99e7-a2f25455d101,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-d909ea68-c074-4e3a-b9a9-67c07485fa68,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-774f3fcf-3dab-4bbf-9662-3d75cb257a24,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-dac24914-2610-4c1b-8b7e-9178616faf1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689598481-172.17.0.15-1597537954359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39232,DS-d9e873e2-47aa-4ee6-ba9b-44586f265718,DISK], DatanodeInfoWithStorage[127.0.0.1:36686,DS-820bd646-0d39-469c-80ce-edb428979ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-54c5e8f7-12b8-4bbe-91fa-42543248c5ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-7c148eb7-a476-431f-85e4-4f16961832a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-3bcd465b-a3b8-4513-99e7-a2f25455d101,DISK], DatanodeInfoWithStorage[127.0.0.1:40992,DS-d909ea68-c074-4e3a-b9a9-67c07485fa68,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-774f3fcf-3dab-4bbf-9662-3d75cb257a24,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-dac24914-2610-4c1b-8b7e-9178616faf1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-352660728-172.17.0.15-1597538036261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44031,DS-1306bba1-5f3b-422b-8c88-ab17cffe17d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-73cba69b-4675-4031-83e5-58aeb7c1a0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-4155006a-f666-4eae-bd98-0fadef0646c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-a222d2cc-267f-4bbc-93f7-c149e6c38330,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-b80afcb0-7b37-4129-b0f0-d4115876df44,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-9f9c4e1a-0eb2-4fe2-bd4e-a84126c5df0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-60b98d7c-af14-4cb1-86d3-dc5716fb5354,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-5743996e-284a-4570-9187-23b9f366b05e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-352660728-172.17.0.15-1597538036261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44031,DS-1306bba1-5f3b-422b-8c88-ab17cffe17d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-73cba69b-4675-4031-83e5-58aeb7c1a0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-4155006a-f666-4eae-bd98-0fadef0646c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-a222d2cc-267f-4bbc-93f7-c149e6c38330,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-b80afcb0-7b37-4129-b0f0-d4115876df44,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-9f9c4e1a-0eb2-4fe2-bd4e-a84126c5df0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-60b98d7c-af14-4cb1-86d3-dc5716fb5354,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-5743996e-284a-4570-9187-23b9f366b05e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-741713923-172.17.0.15-1597538270612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34610,DS-08fef3c4-5246-42e1-89a5-17a50748e3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-37d46e4c-b636-4929-8a9c-faf3116037c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-e6055830-a74a-4ad6-8f14-2421eff3d3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-da37769d-e211-48ed-97df-d11e65edf85e,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-4aec25cf-ba50-4d3e-96f4-3a101797baaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-5b0d4a50-f842-479a-b489-9f49dce58625,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-ed4cca45-305b-44e0-b0ab-03329970b3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-d3a30c86-ad71-46f0-b052-da5ec2987390,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-741713923-172.17.0.15-1597538270612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34610,DS-08fef3c4-5246-42e1-89a5-17a50748e3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-37d46e4c-b636-4929-8a9c-faf3116037c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-e6055830-a74a-4ad6-8f14-2421eff3d3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45676,DS-da37769d-e211-48ed-97df-d11e65edf85e,DISK], DatanodeInfoWithStorage[127.0.0.1:41901,DS-4aec25cf-ba50-4d3e-96f4-3a101797baaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36272,DS-5b0d4a50-f842-479a-b489-9f49dce58625,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-ed4cca45-305b-44e0-b0ab-03329970b3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-d3a30c86-ad71-46f0-b052-da5ec2987390,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1157550142-172.17.0.15-1597538342574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41511,DS-b0faec9d-8495-48ad-8bc1-197d441c7d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-36af58b0-fb10-4bb2-8245-f391c36ded71,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-b67465d8-2682-4d9f-8c32-bcd1a098d41c,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-eb4b4ffe-66ad-4f68-a7d6-ac6302be5a72,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-750175e8-540c-49ce-900e-d382eb459925,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-a6f4dbc4-3fef-4eed-a0c5-44e0967a95d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-61550ab5-6aba-4721-9108-8be30d124977,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-73e65c05-c5bb-4dea-ba6b-e8cffc86654e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1157550142-172.17.0.15-1597538342574:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41511,DS-b0faec9d-8495-48ad-8bc1-197d441c7d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-36af58b0-fb10-4bb2-8245-f391c36ded71,DISK], DatanodeInfoWithStorage[127.0.0.1:38361,DS-b67465d8-2682-4d9f-8c32-bcd1a098d41c,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-eb4b4ffe-66ad-4f68-a7d6-ac6302be5a72,DISK], DatanodeInfoWithStorage[127.0.0.1:44081,DS-750175e8-540c-49ce-900e-d382eb459925,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-a6f4dbc4-3fef-4eed-a0c5-44e0967a95d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-61550ab5-6aba-4721-9108-8be30d124977,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-73e65c05-c5bb-4dea-ba6b-e8cffc86654e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-169604993-172.17.0.15-1597538388597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41746,DS-4361b4cd-8adb-4c15-b729-41e26b45c43b,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-68cf0f21-7d14-40ad-bbc6-55404c657bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-5ddb349a-d5b8-40ce-a2cd-debad91689b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-3dc83a39-a568-4984-99c2-9ab17342aa1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-f1105ef2-ae04-4978-bdbc-29deb46b489f,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-2eaa69f9-a8da-47a6-8425-0406507d4775,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-a32838a0-0ee7-4ee4-b053-94822c31653b,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-ebdc7111-94c2-46e3-bcf3-b3de71cc591e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-169604993-172.17.0.15-1597538388597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41746,DS-4361b4cd-8adb-4c15-b729-41e26b45c43b,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-68cf0f21-7d14-40ad-bbc6-55404c657bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-5ddb349a-d5b8-40ce-a2cd-debad91689b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-3dc83a39-a568-4984-99c2-9ab17342aa1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-f1105ef2-ae04-4978-bdbc-29deb46b489f,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-2eaa69f9-a8da-47a6-8425-0406507d4775,DISK], DatanodeInfoWithStorage[127.0.0.1:34454,DS-a32838a0-0ee7-4ee4-b053-94822c31653b,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-ebdc7111-94c2-46e3-bcf3-b3de71cc591e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257203498-172.17.0.15-1597538472814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41161,DS-c077a56d-260a-431c-907d-823f02d0bdbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-c4d5705d-5eb6-4217-93f7-186dc238f845,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-40881ac9-4a28-4407-a350-437da59d2587,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-1ec928ab-1326-4f7c-8577-fb42ffa85ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-5f048c89-e832-432d-a598-3064534a8d45,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-c189ec72-f866-41ff-9cd9-80b0778e49e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-f9de40ec-aaa4-4001-9a2e-ce28e02561f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-0ee754cc-bea9-4995-91ef-fddcce9a9632,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1257203498-172.17.0.15-1597538472814:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41161,DS-c077a56d-260a-431c-907d-823f02d0bdbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-c4d5705d-5eb6-4217-93f7-186dc238f845,DISK], DatanodeInfoWithStorage[127.0.0.1:37296,DS-40881ac9-4a28-4407-a350-437da59d2587,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-1ec928ab-1326-4f7c-8577-fb42ffa85ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-5f048c89-e832-432d-a598-3064534a8d45,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-c189ec72-f866-41ff-9cd9-80b0778e49e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-f9de40ec-aaa4-4001-9a2e-ce28e02561f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-0ee754cc-bea9-4995-91ef-fddcce9a9632,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633006304-172.17.0.15-1597538589915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33604,DS-81d6256c-4faf-4c43-90b0-a66752a6129c,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-40fbd1af-9281-40d5-8772-3330435a1bee,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-74cb473f-c775-4607-aa49-3da40fc70461,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-737aad0b-c42b-4bf5-b1ca-ea03de74019a,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-b49ae6a1-d7e6-4873-8b9c-86ace8682ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-cb15bb96-bd1e-4fc1-ba0d-f321b1fe4def,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-6e037f4c-8dac-46d4-b6e4-3b95bd66c245,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-d6459e5a-25a3-4374-b196-a389ed2955e2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633006304-172.17.0.15-1597538589915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33604,DS-81d6256c-4faf-4c43-90b0-a66752a6129c,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-40fbd1af-9281-40d5-8772-3330435a1bee,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-74cb473f-c775-4607-aa49-3da40fc70461,DISK], DatanodeInfoWithStorage[127.0.0.1:46581,DS-737aad0b-c42b-4bf5-b1ca-ea03de74019a,DISK], DatanodeInfoWithStorage[127.0.0.1:40756,DS-b49ae6a1-d7e6-4873-8b9c-86ace8682ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-cb15bb96-bd1e-4fc1-ba0d-f321b1fe4def,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-6e037f4c-8dac-46d4-b6e4-3b95bd66c245,DISK], DatanodeInfoWithStorage[127.0.0.1:46342,DS-d6459e5a-25a3-4374-b196-a389ed2955e2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1637046178-172.17.0.15-1597538669879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40812,DS-c88b54e2-e0d4-477b-a6fd-25590ccc1fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-d03f351b-1ad9-448a-8e1e-28a297ea1409,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-6a1aeb41-8fcf-40f9-8a8c-72c68631e524,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-4488eb6a-3b04-4c11-900e-9fa77c2ebc42,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-13d68eeb-0a77-44e8-9794-5e45021c179c,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-dca506d0-24d8-4b2d-a51f-a51f8f47610e,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-dfc498c8-3bd4-4023-a34c-3fed5e5da3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-e1bc696c-467c-4926-8e64-8c36e5e2d6ef,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1637046178-172.17.0.15-1597538669879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40812,DS-c88b54e2-e0d4-477b-a6fd-25590ccc1fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-d03f351b-1ad9-448a-8e1e-28a297ea1409,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-6a1aeb41-8fcf-40f9-8a8c-72c68631e524,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-4488eb6a-3b04-4c11-900e-9fa77c2ebc42,DISK], DatanodeInfoWithStorage[127.0.0.1:43905,DS-13d68eeb-0a77-44e8-9794-5e45021c179c,DISK], DatanodeInfoWithStorage[127.0.0.1:44072,DS-dca506d0-24d8-4b2d-a51f-a51f8f47610e,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-dfc498c8-3bd4-4023-a34c-3fed5e5da3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-e1bc696c-467c-4926-8e64-8c36e5e2d6ef,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 6072
