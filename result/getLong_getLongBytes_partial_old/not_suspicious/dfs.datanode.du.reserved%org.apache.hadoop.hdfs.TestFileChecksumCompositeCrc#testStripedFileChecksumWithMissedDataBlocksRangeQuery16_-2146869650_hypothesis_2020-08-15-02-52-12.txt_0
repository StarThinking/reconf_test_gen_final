reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1079525087-172.17.0.7-1597460058846:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34022,DS-2c95e973-309c-4618-82dc-f640a1f8381d,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-d2aaaf02-73cd-43a5-8d19-73e999e9b5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-dbed2b26-c505-4985-a1db-59d8366ed802,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-5eac2832-fcc2-48f3-b3ae-44849453085e,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-e430d07b-9819-444b-a7dc-0b99134fa029,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-2ecbb7d6-e727-4ed7-8470-33224790e507,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-153b5904-0008-491c-a130-67c37fc340a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-2d129fa4-c54e-43cd-b098-0e8f8f052022,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1079525087-172.17.0.7-1597460058846:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34022,DS-2c95e973-309c-4618-82dc-f640a1f8381d,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-d2aaaf02-73cd-43a5-8d19-73e999e9b5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-dbed2b26-c505-4985-a1db-59d8366ed802,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-5eac2832-fcc2-48f3-b3ae-44849453085e,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-e430d07b-9819-444b-a7dc-0b99134fa029,DISK], DatanodeInfoWithStorage[127.0.0.1:38629,DS-2ecbb7d6-e727-4ed7-8470-33224790e507,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-153b5904-0008-491c-a130-67c37fc340a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38056,DS-2d129fa4-c54e-43cd-b098-0e8f8f052022,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-622769245-172.17.0.7-1597460613196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43235,DS-257833c8-bec9-4d73-ad7f-a2fa9a858ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-b1334948-b9c9-4243-8c82-4e950e55ec12,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-fa89243a-2e27-4f13-8ab1-4c4449f66f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-5d743b96-0d74-4b9f-a87b-a25ac38d3203,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-56f97983-169f-42a7-976b-2737372d612e,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-c183e578-bb1e-4c70-83d0-ad3087222f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-292b1d66-0355-453b-b05f-e8a993e5161a,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-d058e6f8-b230-456f-8307-a4236c311099,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-622769245-172.17.0.7-1597460613196:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43235,DS-257833c8-bec9-4d73-ad7f-a2fa9a858ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:42050,DS-b1334948-b9c9-4243-8c82-4e950e55ec12,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-fa89243a-2e27-4f13-8ab1-4c4449f66f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41354,DS-5d743b96-0d74-4b9f-a87b-a25ac38d3203,DISK], DatanodeInfoWithStorage[127.0.0.1:41024,DS-56f97983-169f-42a7-976b-2737372d612e,DISK], DatanodeInfoWithStorage[127.0.0.1:38775,DS-c183e578-bb1e-4c70-83d0-ad3087222f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-292b1d66-0355-453b-b05f-e8a993e5161a,DISK], DatanodeInfoWithStorage[127.0.0.1:40076,DS-d058e6f8-b230-456f-8307-a4236c311099,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2114185472-172.17.0.7-1597460650836:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36628,DS-ec969dcc-0a23-478b-90e1-9ee893221182,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-80607685-c92a-4e04-92aa-f1fed2da9ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-88fe1e88-c2d0-4a07-a8bb-1f600e2d5cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-3ac85bc0-1db1-4890-be36-0fd51a61e4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-182a4b56-bcba-44aa-b95a-4fda58c24a68,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-927a31e1-3a05-4502-806a-2644128d5328,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-6b50d8bb-d63d-4ff5-af42-584583915fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-9a238bb4-8077-4a46-9698-ea46e8bf4c78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2114185472-172.17.0.7-1597460650836:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36628,DS-ec969dcc-0a23-478b-90e1-9ee893221182,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-80607685-c92a-4e04-92aa-f1fed2da9ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-88fe1e88-c2d0-4a07-a8bb-1f600e2d5cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-3ac85bc0-1db1-4890-be36-0fd51a61e4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-182a4b56-bcba-44aa-b95a-4fda58c24a68,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-927a31e1-3a05-4502-806a-2644128d5328,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-6b50d8bb-d63d-4ff5-af42-584583915fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-9a238bb4-8077-4a46-9698-ea46e8bf4c78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-635480783-172.17.0.7-1597460693238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37060,DS-7be583e5-cb1f-40b2-a6c2-d9b199205a37,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-37d9b4bb-b45e-4737-8dbc-770c2a601d33,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-28515169-4eda-4536-b92e-0061547751f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-88f537ea-b7d2-4a7d-bc1c-a3f8d557ab6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-e3d370f3-c35e-48b4-96e9-4a105b0b5587,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-6a7b6959-7d54-4c31-89c2-bd6fd43ed466,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-345cf275-e83b-49eb-bffe-9bb8982ec76b,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-f3fc7900-ad21-422e-aecb-d3aaf5d30b61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-635480783-172.17.0.7-1597460693238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37060,DS-7be583e5-cb1f-40b2-a6c2-d9b199205a37,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-37d9b4bb-b45e-4737-8dbc-770c2a601d33,DISK], DatanodeInfoWithStorage[127.0.0.1:41713,DS-28515169-4eda-4536-b92e-0061547751f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-88f537ea-b7d2-4a7d-bc1c-a3f8d557ab6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-e3d370f3-c35e-48b4-96e9-4a105b0b5587,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-6a7b6959-7d54-4c31-89c2-bd6fd43ed466,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-345cf275-e83b-49eb-bffe-9bb8982ec76b,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-f3fc7900-ad21-422e-aecb-d3aaf5d30b61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1987708927-172.17.0.7-1597460980176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43382,DS-0d484259-a903-4b86-89ba-efeb1e3446ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-675042aa-f2d3-4e90-8065-96b53a6bd630,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-53f53f28-f47e-4f54-aa5d-39ecf3caf13e,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-aaadfcce-b80b-4e9f-a74a-fa2f23483a18,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-613c78e1-074e-45cc-a777-797910034561,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-7ff522b3-e0ae-4cec-98aa-09829caa725e,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-cf1d991f-0c49-4c90-a320-a8232cc62f71,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-41ae0a86-cf95-44e5-bb25-e70d721c995c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1987708927-172.17.0.7-1597460980176:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43382,DS-0d484259-a903-4b86-89ba-efeb1e3446ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41540,DS-675042aa-f2d3-4e90-8065-96b53a6bd630,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-53f53f28-f47e-4f54-aa5d-39ecf3caf13e,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-aaadfcce-b80b-4e9f-a74a-fa2f23483a18,DISK], DatanodeInfoWithStorage[127.0.0.1:38506,DS-613c78e1-074e-45cc-a777-797910034561,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-7ff522b3-e0ae-4cec-98aa-09829caa725e,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-cf1d991f-0c49-4c90-a320-a8232cc62f71,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-41ae0a86-cf95-44e5-bb25-e70d721c995c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-118183412-172.17.0.7-1597461095881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32824,DS-ae1f5a12-cf7e-43c1-a628-e7f44006d1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-80e48a64-58e8-4ffa-a7b4-577079cda4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-c9d457c9-c5fe-4971-bcef-01dca423b67e,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-f8a77023-7dc6-4de1-91ee-1ff6aa128f14,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-b3f5a994-af1b-41df-b2c8-013f6f3a4098,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-8440233c-cb94-4020-ab0c-551668b7798c,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-7e353b19-0939-4cd7-9c29-1969026b252d,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-1f10162f-20f4-487b-add0-54b08d791339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-118183412-172.17.0.7-1597461095881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32824,DS-ae1f5a12-cf7e-43c1-a628-e7f44006d1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-80e48a64-58e8-4ffa-a7b4-577079cda4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-c9d457c9-c5fe-4971-bcef-01dca423b67e,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-f8a77023-7dc6-4de1-91ee-1ff6aa128f14,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-b3f5a994-af1b-41df-b2c8-013f6f3a4098,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-8440233c-cb94-4020-ab0c-551668b7798c,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-7e353b19-0939-4cd7-9c29-1969026b252d,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-1f10162f-20f4-487b-add0-54b08d791339,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-416825288-172.17.0.7-1597461587131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45751,DS-b1d2a7f5-d2c1-4076-8514-3ff7da314eee,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-66229538-2c9b-4008-9929-98a4407c727e,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-c947a358-119a-4aea-b0a6-5c9948399b02,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-f98894b9-d6cd-42a8-b96a-c74fd0f3f492,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-0e9fd39c-496d-4605-a38a-c94b7149236c,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-8c96e919-8874-474a-bc67-761589e71d99,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-08760f9b-dfcb-4f1c-a03b-16c6bc2e67d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-882372c5-3dd5-427e-a94f-5a22bb61c07a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-416825288-172.17.0.7-1597461587131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45751,DS-b1d2a7f5-d2c1-4076-8514-3ff7da314eee,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-66229538-2c9b-4008-9929-98a4407c727e,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-c947a358-119a-4aea-b0a6-5c9948399b02,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-f98894b9-d6cd-42a8-b96a-c74fd0f3f492,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-0e9fd39c-496d-4605-a38a-c94b7149236c,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-8c96e919-8874-474a-bc67-761589e71d99,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-08760f9b-dfcb-4f1c-a03b-16c6bc2e67d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46381,DS-882372c5-3dd5-427e-a94f-5a22bb61c07a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-530395249-172.17.0.7-1597462353009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39671,DS-39baa520-2f17-4475-8c4e-3c1882609b15,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-64ea9736-f614-4a59-8cc7-a9dfb54ef4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-d33b6b89-3aca-48b5-be03-4e4d67331052,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-b9288638-2994-464f-9fe1-d3c85884d63e,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-1164bb4b-0ea5-49fc-833a-8c106671d5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-c4158dfc-3707-4b97-a997-c919fed4a7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-a6477f63-31c9-49e1-91c9-cff2cc0f42e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-b8458538-7a81-4881-97c5-1b44ce325c80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-530395249-172.17.0.7-1597462353009:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39671,DS-39baa520-2f17-4475-8c4e-3c1882609b15,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-64ea9736-f614-4a59-8cc7-a9dfb54ef4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-d33b6b89-3aca-48b5-be03-4e4d67331052,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-b9288638-2994-464f-9fe1-d3c85884d63e,DISK], DatanodeInfoWithStorage[127.0.0.1:43966,DS-1164bb4b-0ea5-49fc-833a-8c106671d5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-c4158dfc-3707-4b97-a997-c919fed4a7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-a6477f63-31c9-49e1-91c9-cff2cc0f42e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-b8458538-7a81-4881-97c5-1b44ce325c80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-155839707-172.17.0.7-1597462899077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39144,DS-e3e99da5-6e9b-48e0-8d3e-66a5153f93ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-3a59abcc-0a0b-47de-85c5-ddbb90d34833,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-9bb715fb-3cae-4593-9572-efe8ee65f773,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-283feb8d-dde6-47b6-9772-f9cca407377c,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-e8a06130-9513-4dad-832f-52650b909e98,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-21819a5f-3c89-49f0-a796-4f257890c1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-0ef29235-92f8-41b4-a136-b54459ee5e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-15e1916d-dc4b-455b-87ad-77872a60661b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-155839707-172.17.0.7-1597462899077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39144,DS-e3e99da5-6e9b-48e0-8d3e-66a5153f93ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-3a59abcc-0a0b-47de-85c5-ddbb90d34833,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-9bb715fb-3cae-4593-9572-efe8ee65f773,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-283feb8d-dde6-47b6-9772-f9cca407377c,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-e8a06130-9513-4dad-832f-52650b909e98,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-21819a5f-3c89-49f0-a796-4f257890c1f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-0ef29235-92f8-41b4-a136-b54459ee5e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-15e1916d-dc4b-455b-87ad-77872a60661b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-495457515-172.17.0.7-1597463233144:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37637,DS-7399c5de-055b-4268-ab6b-9c640a14f9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-1677d661-0ef4-427b-9bf4-6246eb6716ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-7bf78548-df22-43a8-9062-ca949a13e1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-b7c87dc2-814a-4dce-a894-34276a2e1ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-0c57beaf-05d4-486a-b9df-c1dbd8f8db4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-b8d9e790-8cf1-4592-a23a-d7550f81da2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-c353cca7-820e-48e4-bc90-fdfb47b231f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-d9aa65ee-a66e-4545-9839-b4d5c09f2b90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-495457515-172.17.0.7-1597463233144:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37637,DS-7399c5de-055b-4268-ab6b-9c640a14f9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-1677d661-0ef4-427b-9bf4-6246eb6716ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-7bf78548-df22-43a8-9062-ca949a13e1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-b7c87dc2-814a-4dce-a894-34276a2e1ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-0c57beaf-05d4-486a-b9df-c1dbd8f8db4d,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-b8d9e790-8cf1-4592-a23a-d7550f81da2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-c353cca7-820e-48e4-bc90-fdfb47b231f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-d9aa65ee-a66e-4545-9839-b4d5c09f2b90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-129925236-172.17.0.7-1597463449241:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41911,DS-9d958eee-4c53-4eb4-8aa1-853269ac08d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-22e1d906-4d95-4ebd-a9cb-4b66cd923125,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-38d37b6f-1630-4bbc-985d-77eb8e611f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-bfbf2cb7-a094-4b28-b9a0-763bfed6af82,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-dccc5252-23bf-4e83-b64a-a9d1e476ee1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-b3cc28fe-2539-4aa3-94b8-6fde53ee4ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-16be3730-1607-4c89-a05d-a6f80553cd91,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-c14f68ee-5f37-44a2-838d-63e2d38e35c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-129925236-172.17.0.7-1597463449241:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41911,DS-9d958eee-4c53-4eb4-8aa1-853269ac08d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-22e1d906-4d95-4ebd-a9cb-4b66cd923125,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-38d37b6f-1630-4bbc-985d-77eb8e611f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-bfbf2cb7-a094-4b28-b9a0-763bfed6af82,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-dccc5252-23bf-4e83-b64a-a9d1e476ee1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-b3cc28fe-2539-4aa3-94b8-6fde53ee4ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:43446,DS-16be3730-1607-4c89-a05d-a6f80553cd91,DISK], DatanodeInfoWithStorage[127.0.0.1:45183,DS-c14f68ee-5f37-44a2-838d-63e2d38e35c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-434909683-172.17.0.7-1597463532380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46312,DS-97881c82-b296-4a8b-bab9-24e8a92f46f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-775b9b27-e804-43b3-a8b6-55e53ffa3426,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-4f98e839-08bb-4284-9acb-be295d4e3abc,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-684c98bf-4cb4-48ef-9961-401dfd2dc392,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-cc61e411-8c60-40d6-b024-57b6a52f2bca,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-c9b890a6-47bb-4ca1-b4f0-18b32e5b34d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-ef38b12e-d639-4593-92b8-649cf10b6439,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-f8541222-5daf-43c1-9544-43df77ff4f13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-434909683-172.17.0.7-1597463532380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46312,DS-97881c82-b296-4a8b-bab9-24e8a92f46f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-775b9b27-e804-43b3-a8b6-55e53ffa3426,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-4f98e839-08bb-4284-9acb-be295d4e3abc,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-684c98bf-4cb4-48ef-9961-401dfd2dc392,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-cc61e411-8c60-40d6-b024-57b6a52f2bca,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-c9b890a6-47bb-4ca1-b4f0-18b32e5b34d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-ef38b12e-d639-4593-92b8-649cf10b6439,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-f8541222-5daf-43c1-9544-43df77ff4f13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1211862160-172.17.0.7-1597463576783:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43640,DS-705e25f6-6b3a-49df-a1d3-002cfff80fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-be5f02ec-977c-4197-bcf7-25e9b2e0dfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-22d71398-a13c-4a4f-8bcf-2da09363f2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-1c00e825-d403-4fb8-bfec-5db16ab35ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-467a4cd9-a587-402b-b598-0521ea5729af,DISK], DatanodeInfoWithStorage[127.0.0.1:38868,DS-a0ab552b-99bc-4e5a-91e8-5fb68f49e5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-8681343a-b03d-4059-bccf-6b5d5bb42d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-30893c2a-4334-4cb0-8225-b035fa16b3a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1211862160-172.17.0.7-1597463576783:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43640,DS-705e25f6-6b3a-49df-a1d3-002cfff80fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-be5f02ec-977c-4197-bcf7-25e9b2e0dfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40403,DS-22d71398-a13c-4a4f-8bcf-2da09363f2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-1c00e825-d403-4fb8-bfec-5db16ab35ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-467a4cd9-a587-402b-b598-0521ea5729af,DISK], DatanodeInfoWithStorage[127.0.0.1:38868,DS-a0ab552b-99bc-4e5a-91e8-5fb68f49e5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42102,DS-8681343a-b03d-4059-bccf-6b5d5bb42d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-30893c2a-4334-4cb0-8225-b035fa16b3a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-958340129-172.17.0.7-1597463876665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42314,DS-5f0940ff-23da-491e-9ff8-30fa0a90de84,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-a0fa6956-5380-478c-8e30-60913408ec2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-33da2997-e8cb-4b6b-8930-8c7b60ed428b,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-c5d3d102-8901-4595-923d-4c85a9f6b169,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-23f02f23-7278-48cc-9910-bd7c5b57d976,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-0f01516b-7c9f-4c4a-800f-5d3d56f24787,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-dca81ef5-c7b5-4c1f-a1c8-c08d892ad20d,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-f0329b20-e314-40b3-a815-72d115aba9c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-958340129-172.17.0.7-1597463876665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42314,DS-5f0940ff-23da-491e-9ff8-30fa0a90de84,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-a0fa6956-5380-478c-8e30-60913408ec2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-33da2997-e8cb-4b6b-8930-8c7b60ed428b,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-c5d3d102-8901-4595-923d-4c85a9f6b169,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-23f02f23-7278-48cc-9910-bd7c5b57d976,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-0f01516b-7c9f-4c4a-800f-5d3d56f24787,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-dca81ef5-c7b5-4c1f-a1c8-c08d892ad20d,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-f0329b20-e314-40b3-a815-72d115aba9c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-938922797-172.17.0.7-1597463980699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41953,DS-7c2dd797-97fb-4dd8-86e4-9ffe208546cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-8639dfc6-0d20-40e2-aa88-d412e55b6a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-5301a302-da4e-4f7a-a837-3a9fec44cf04,DISK], DatanodeInfoWithStorage[127.0.0.1:46582,DS-c3f8a93b-1758-4444-9155-6cccc1bdf5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-7b887098-7137-4a8b-a3ab-318bdcb0360d,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-96c8fb77-76cd-4a97-bb1d-6d2a7c12951b,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-1d8697e7-35cb-45db-abc2-d96ace90e74c,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-8761f5b5-e19c-4ff8-af92-48f7a9470797,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-938922797-172.17.0.7-1597463980699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41953,DS-7c2dd797-97fb-4dd8-86e4-9ffe208546cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36914,DS-8639dfc6-0d20-40e2-aa88-d412e55b6a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:32843,DS-5301a302-da4e-4f7a-a837-3a9fec44cf04,DISK], DatanodeInfoWithStorage[127.0.0.1:46582,DS-c3f8a93b-1758-4444-9155-6cccc1bdf5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-7b887098-7137-4a8b-a3ab-318bdcb0360d,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-96c8fb77-76cd-4a97-bb1d-6d2a7c12951b,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-1d8697e7-35cb-45db-abc2-d96ace90e74c,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-8761f5b5-e19c-4ff8-af92-48f7a9470797,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1305199024-172.17.0.7-1597464017799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39614,DS-6aeb0617-247b-418e-a52f-36e7e1ccc423,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-6ffa72f8-88a8-4365-867d-949d50897ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-4dce6886-c936-4293-86f1-de92de6fc8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-d3586efd-d7de-4a53-9166-34eeaaa58c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-0a48cfc8-adab-4166-a1ba-d9c38b6b8895,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-2c02b6df-3491-401f-aab0-73130056b0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-01c96349-36cd-4289-acdf-b63481d79ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-3ea5e157-8ddb-4ba3-919f-3a04e6af125e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1305199024-172.17.0.7-1597464017799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39614,DS-6aeb0617-247b-418e-a52f-36e7e1ccc423,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-6ffa72f8-88a8-4365-867d-949d50897ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-4dce6886-c936-4293-86f1-de92de6fc8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-d3586efd-d7de-4a53-9166-34eeaaa58c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37342,DS-0a48cfc8-adab-4166-a1ba-d9c38b6b8895,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-2c02b6df-3491-401f-aab0-73130056b0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-01c96349-36cd-4289-acdf-b63481d79ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:40171,DS-3ea5e157-8ddb-4ba3-919f-3a04e6af125e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-8809617-172.17.0.7-1597464227160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40488,DS-fd49833e-a2cc-4fd2-92ce-f81eb7e5d4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-353d8718-8688-403e-bdf4-1a9a9cf2c573,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-0be75e32-0f02-4232-a254-22561d4b6c00,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-a732aa2b-187d-4960-9f5d-aaf44c9ca290,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-75db3926-7185-4c8d-b839-0a5e41b9ae16,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-5f7f6e1d-5b72-48bc-962e-e38fa660e0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-2202a4df-e9cb-4baf-a617-8ccadb653746,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-a0c2e876-7961-41cd-8e70-e6d99aa30d7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-8809617-172.17.0.7-1597464227160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40488,DS-fd49833e-a2cc-4fd2-92ce-f81eb7e5d4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-353d8718-8688-403e-bdf4-1a9a9cf2c573,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-0be75e32-0f02-4232-a254-22561d4b6c00,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-a732aa2b-187d-4960-9f5d-aaf44c9ca290,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-75db3926-7185-4c8d-b839-0a5e41b9ae16,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-5f7f6e1d-5b72-48bc-962e-e38fa660e0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35315,DS-2202a4df-e9cb-4baf-a617-8ccadb653746,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-a0c2e876-7961-41cd-8e70-e6d99aa30d7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-142078175-172.17.0.7-1597465066735:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46029,DS-d0bc3c54-2264-4e5c-822f-f059d5156cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-7a1e4a31-8ffa-4632-b6a8-04fc963f6d02,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-a4b2f015-9bc6-4662-b0ae-e46ceb9bd2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-d96c644b-cbae-463c-bff6-304bf1e7699e,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-111a2afa-d8d1-4383-886b-283ea320d18e,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-f3698610-683e-47bb-89bc-0f93e508d4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-31bf1bd1-87d5-4cf2-8c3f-9a8fc6e9f6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-f24b2d2e-cde3-4f88-9799-5a2dd0d05777,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-142078175-172.17.0.7-1597465066735:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46029,DS-d0bc3c54-2264-4e5c-822f-f059d5156cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-7a1e4a31-8ffa-4632-b6a8-04fc963f6d02,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-a4b2f015-9bc6-4662-b0ae-e46ceb9bd2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-d96c644b-cbae-463c-bff6-304bf1e7699e,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-111a2afa-d8d1-4383-886b-283ea320d18e,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-f3698610-683e-47bb-89bc-0f93e508d4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-31bf1bd1-87d5-4cf2-8c3f-9a8fc6e9f6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-f24b2d2e-cde3-4f88-9799-5a2dd0d05777,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5521
