reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 30000000
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 30000000
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954009867-172.17.0.16-1597401037509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40311,DS-2241ab46-0753-40b6-b9a7-de8883aba950,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-ac69496a-e8e5-4481-972c-094599bdcf60,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-e563a462-6dd1-4634-894e-2874354b2c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-7b12d712-2d2d-474b-8b4d-8159544948ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-204da28e-eeaa-4536-be60-b78269c8e422,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-a313cdf3-40ff-43aa-8115-8e51bc92dc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-a45c80dd-b666-40c4-91cf-3dae2beedd25,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-dbb84df6-a415-41e1-b282-e2b287158ce8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954009867-172.17.0.16-1597401037509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40311,DS-2241ab46-0753-40b6-b9a7-de8883aba950,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-ac69496a-e8e5-4481-972c-094599bdcf60,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-e563a462-6dd1-4634-894e-2874354b2c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37658,DS-7b12d712-2d2d-474b-8b4d-8159544948ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-204da28e-eeaa-4536-be60-b78269c8e422,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-a313cdf3-40ff-43aa-8115-8e51bc92dc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43497,DS-a45c80dd-b666-40c4-91cf-3dae2beedd25,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-dbb84df6-a415-41e1-b282-e2b287158ce8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 30000000
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619826127-172.17.0.16-1597401159431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40017,DS-478f42af-c2b0-459d-8db7-73558902c024,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-201102f9-e54d-4360-91e2-aa05c6e9cc19,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-4018040f-d199-4132-aeaf-265e5f6673cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-e350e38b-8479-4e2f-a9a7-7f8a71fdd7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-89fcaaf5-0f40-4eaa-8c9b-c000861f5e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-d3366ed5-22b8-4445-9a64-64ed3168207b,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-53b8c122-5800-4f2a-99b4-b20edb2056f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-d9cdeecc-baa1-4aa1-9c0a-5c6684276b3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619826127-172.17.0.16-1597401159431:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40017,DS-478f42af-c2b0-459d-8db7-73558902c024,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-201102f9-e54d-4360-91e2-aa05c6e9cc19,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-4018040f-d199-4132-aeaf-265e5f6673cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-e350e38b-8479-4e2f-a9a7-7f8a71fdd7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-89fcaaf5-0f40-4eaa-8c9b-c000861f5e7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-d3366ed5-22b8-4445-9a64-64ed3168207b,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-53b8c122-5800-4f2a-99b4-b20edb2056f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-d9cdeecc-baa1-4aa1-9c0a-5c6684276b3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 30000000
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-741162242-172.17.0.16-1597401234217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36096,DS-0b2e9f76-45df-40b7-b975-d8606fc3f1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-effc6ce2-fae1-4da2-8797-6180b0f9e8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-0c335cf0-0387-40d5-912f-19fb415a1ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-0eb9b118-57d8-42de-8d5b-ecfa122e9e92,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-3c009c6f-70f8-4ca2-8857-8247887f9b66,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-df819e64-1786-49ca-87cc-469b6deef171,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-b84f4b3d-d5a9-427d-b294-44ada9ac12cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-c68da87a-5b06-43ac-94a0-8b687e23eedc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-741162242-172.17.0.16-1597401234217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36096,DS-0b2e9f76-45df-40b7-b975-d8606fc3f1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39780,DS-effc6ce2-fae1-4da2-8797-6180b0f9e8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40538,DS-0c335cf0-0387-40d5-912f-19fb415a1ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:42283,DS-0eb9b118-57d8-42de-8d5b-ecfa122e9e92,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-3c009c6f-70f8-4ca2-8857-8247887f9b66,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-df819e64-1786-49ca-87cc-469b6deef171,DISK], DatanodeInfoWithStorage[127.0.0.1:40334,DS-b84f4b3d-d5a9-427d-b294-44ada9ac12cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44671,DS-c68da87a-5b06-43ac-94a0-8b687e23eedc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 30000000
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1736901899-172.17.0.16-1597401689263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39443,DS-f2c39758-b1e6-4051-b655-00057068191a,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-041f0211-6db1-474d-9780-2372316c7a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-4d1f6ea7-67ff-4d4f-b948-7f817018141e,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-25ced14e-5882-4eb1-a199-822020eb3c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-498c6fd4-2b1b-4392-8f5c-92349302cf18,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-8c735f80-86b1-4067-8daf-23ed70f364ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-8bd1db43-63c0-4084-832f-f850e19af8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-90a864c6-cb64-4efc-a0ec-ab52f628f50b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1736901899-172.17.0.16-1597401689263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39443,DS-f2c39758-b1e6-4051-b655-00057068191a,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-041f0211-6db1-474d-9780-2372316c7a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-4d1f6ea7-67ff-4d4f-b948-7f817018141e,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-25ced14e-5882-4eb1-a199-822020eb3c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-498c6fd4-2b1b-4392-8f5c-92349302cf18,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-8c735f80-86b1-4067-8daf-23ed70f364ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45913,DS-8bd1db43-63c0-4084-832f-f850e19af8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-90a864c6-cb64-4efc-a0ec-ab52f628f50b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 30000000
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-529630853-172.17.0.16-1597401812968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36443,DS-7dfaaaa2-0102-418d-961d-608b56d30784,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-48248650-f1d2-4031-80ad-95d664065050,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-df6f1590-a2a6-4e37-aebe-1a382272a494,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-49f674a5-ad72-4dc7-8041-630bc8aed1db,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-9b255b35-91da-4553-a11c-b5e279d07060,DISK], DatanodeInfoWithStorage[127.0.0.1:34770,DS-f2d993da-177b-4e75-945e-c50ee3eefe3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-3bd15b01-9895-4a58-b7cd-bbe1edee5a02,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-dcd63a62-1653-46fd-aa9d-afb745929ea6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-529630853-172.17.0.16-1597401812968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36443,DS-7dfaaaa2-0102-418d-961d-608b56d30784,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-48248650-f1d2-4031-80ad-95d664065050,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-df6f1590-a2a6-4e37-aebe-1a382272a494,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-49f674a5-ad72-4dc7-8041-630bc8aed1db,DISK], DatanodeInfoWithStorage[127.0.0.1:45901,DS-9b255b35-91da-4553-a11c-b5e279d07060,DISK], DatanodeInfoWithStorage[127.0.0.1:34770,DS-f2d993da-177b-4e75-945e-c50ee3eefe3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-3bd15b01-9895-4a58-b7cd-bbe1edee5a02,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-dcd63a62-1653-46fd-aa9d-afb745929ea6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 30000000
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161606313-172.17.0.16-1597401852610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44140,DS-bb2fc07e-7090-43da-bb37-09dac6696d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42568,DS-d042ad83-3058-4cc2-8a3e-123eea7cfcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-2043163c-2fff-40aa-a005-1735b7eba705,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-b79e1fa3-8b90-4251-a6cd-3cb8ef1e2f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-f680a9e0-6415-433e-9cde-5ec2b159a516,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-f7aa0fe6-f800-4b1e-8b15-f4182d028739,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-dab6fe82-e530-4c46-9573-50958b5822ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-55437ff1-a702-46c3-8eb1-271663bc2131,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-161606313-172.17.0.16-1597401852610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44140,DS-bb2fc07e-7090-43da-bb37-09dac6696d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42568,DS-d042ad83-3058-4cc2-8a3e-123eea7cfcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-2043163c-2fff-40aa-a005-1735b7eba705,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-b79e1fa3-8b90-4251-a6cd-3cb8ef1e2f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-f680a9e0-6415-433e-9cde-5ec2b159a516,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-f7aa0fe6-f800-4b1e-8b15-f4182d028739,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-dab6fe82-e530-4c46-9573-50958b5822ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36782,DS-55437ff1-a702-46c3-8eb1-271663bc2131,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 30000000
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-791753493-172.17.0.16-1597402321859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41571,DS-89359f47-1ea4-49ec-9e3a-d52920f94087,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-b4757c5e-d67b-4f16-bbdc-6bacfe2b78e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-d604a8f3-10f0-474c-b4b4-66807a241481,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-5894e981-bd29-4f82-a94c-3fc761a33a24,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-8a385c3f-8f0e-4b84-9e9b-e3ab484a42bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-0df61a26-f2bb-453e-ae13-ea2fef67d8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-e6a076ce-7241-4cee-b8c9-637cd23c872c,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-a66c85c7-bec2-451d-a549-e942d0a78e9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-791753493-172.17.0.16-1597402321859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41571,DS-89359f47-1ea4-49ec-9e3a-d52920f94087,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-b4757c5e-d67b-4f16-bbdc-6bacfe2b78e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-d604a8f3-10f0-474c-b4b4-66807a241481,DISK], DatanodeInfoWithStorage[127.0.0.1:42515,DS-5894e981-bd29-4f82-a94c-3fc761a33a24,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-8a385c3f-8f0e-4b84-9e9b-e3ab484a42bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-0df61a26-f2bb-453e-ae13-ea2fef67d8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-e6a076ce-7241-4cee-b8c9-637cd23c872c,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-a66c85c7-bec2-451d-a549-e942d0a78e9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 30000000
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-212124594-172.17.0.16-1597402354714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34115,DS-177b3cc1-327a-477b-987e-942d57951d45,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-d463095b-8ed8-4ef9-b00e-21e02bc2c1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-93e4495a-2846-448c-b4f3-bd072b260408,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-5b00072b-5d40-4bd1-a875-0f4932b7669d,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-7c4fb23e-443a-41ea-99ca-034986411181,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-8c500d00-9032-4d96-97b6-bb11292930f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-a4e9021a-0e06-4eea-9e96-5571beabe387,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-ae6f416b-e336-4096-acef-3760f6c5ab6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-212124594-172.17.0.16-1597402354714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34115,DS-177b3cc1-327a-477b-987e-942d57951d45,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-d463095b-8ed8-4ef9-b00e-21e02bc2c1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-93e4495a-2846-448c-b4f3-bd072b260408,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-5b00072b-5d40-4bd1-a875-0f4932b7669d,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-7c4fb23e-443a-41ea-99ca-034986411181,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-8c500d00-9032-4d96-97b6-bb11292930f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42872,DS-a4e9021a-0e06-4eea-9e96-5571beabe387,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-ae6f416b-e336-4096-acef-3760f6c5ab6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 30000000
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1600780542-172.17.0.16-1597403051294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33066,DS-101c1e43-9f86-4c49-96ab-72e74c78135b,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-723fdd17-f154-452c-9e0f-04427806113f,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-f90e5cc7-b995-4ece-a9c1-e4d533fc153d,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-75d23944-7270-46b9-9eaf-2a74f2a700ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-de4ff273-da6f-4857-9abf-0d43d539be92,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-491e4722-87e6-4070-8bef-5d790702374a,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-7f4dab6a-e119-4c89-980c-74372b26179d,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-d1142109-a9c5-4ff3-8e03-23fc43e6178f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1600780542-172.17.0.16-1597403051294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33066,DS-101c1e43-9f86-4c49-96ab-72e74c78135b,DISK], DatanodeInfoWithStorage[127.0.0.1:44935,DS-723fdd17-f154-452c-9e0f-04427806113f,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-f90e5cc7-b995-4ece-a9c1-e4d533fc153d,DISK], DatanodeInfoWithStorage[127.0.0.1:33457,DS-75d23944-7270-46b9-9eaf-2a74f2a700ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-de4ff273-da6f-4857-9abf-0d43d539be92,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-491e4722-87e6-4070-8bef-5d790702374a,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-7f4dab6a-e119-4c89-980c-74372b26179d,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-d1142109-a9c5-4ff3-8e03-23fc43e6178f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 30000000
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121075400-172.17.0.16-1597403593172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36193,DS-77df3a67-d43e-42d2-9e36-4dc8eb0e5720,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-10465234-cf7b-40cc-8cf5-b32e5247da6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-28c48943-d87d-4f30-9382-396b5747c500,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-426b7c9d-e5f2-41d5-8a0f-43fcd3f81d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-70e9981a-8d6b-4f5b-bc81-cf0d0fa8015c,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-e16c84dd-603f-42c9-9b37-22ff1e0c29c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-af6c2c89-0535-41a6-a67b-019f31b420bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-f5ad2a8e-c8b2-4a07-864b-83e6ac04d734,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-121075400-172.17.0.16-1597403593172:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36193,DS-77df3a67-d43e-42d2-9e36-4dc8eb0e5720,DISK], DatanodeInfoWithStorage[127.0.0.1:32956,DS-10465234-cf7b-40cc-8cf5-b32e5247da6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33282,DS-28c48943-d87d-4f30-9382-396b5747c500,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-426b7c9d-e5f2-41d5-8a0f-43fcd3f81d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-70e9981a-8d6b-4f5b-bc81-cf0d0fa8015c,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-e16c84dd-603f-42c9-9b37-22ff1e0c29c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-af6c2c89-0535-41a6-a67b-019f31b420bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-f5ad2a8e-c8b2-4a07-864b-83e6ac04d734,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 30000000
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-299096475-172.17.0.16-1597404123680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35037,DS-074036bd-3f00-4863-b620-8b6d06154e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-1145dfb3-3059-4fc9-b7c5-63e40cf26cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38047,DS-46772ac7-f11c-45c2-876d-1dafba55c0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-8fd8c2b2-37d6-4b14-aaae-83312dd83f00,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-a862ba6c-0925-4803-bf89-c659649a7843,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-0dc090d6-10fc-484b-8787-49dd7c0ad0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-46849ba0-7530-4374-9e84-d7079a1bf70b,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-2e26c12a-1e59-4cac-9664-32b1f2d4ec8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-299096475-172.17.0.16-1597404123680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35037,DS-074036bd-3f00-4863-b620-8b6d06154e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-1145dfb3-3059-4fc9-b7c5-63e40cf26cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38047,DS-46772ac7-f11c-45c2-876d-1dafba55c0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39312,DS-8fd8c2b2-37d6-4b14-aaae-83312dd83f00,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-a862ba6c-0925-4803-bf89-c659649a7843,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-0dc090d6-10fc-484b-8787-49dd7c0ad0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-46849ba0-7530-4374-9e84-d7079a1bf70b,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-2e26c12a-1e59-4cac-9664-32b1f2d4ec8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 30000000
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1101939257-172.17.0.16-1597404683484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36979,DS-c79135ee-526e-4407-8c54-ca7090f8879c,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-bd276289-0994-429f-927f-63ba1f24865b,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-489920fa-ae25-48e9-b74d-e0ae2ab98829,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-f8d3a459-f201-42c7-ac9e-5514829b0a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-1a2db37e-1664-4333-a884-ccc54b8746f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-e6e27f6a-f919-439b-bc94-8c9c124eee57,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-99c9d464-dcb8-4d86-b4ef-4225eefd838b,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-4951132f-bb0f-4787-b5da-a5d3f7dd0d53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1101939257-172.17.0.16-1597404683484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36979,DS-c79135ee-526e-4407-8c54-ca7090f8879c,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-bd276289-0994-429f-927f-63ba1f24865b,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-489920fa-ae25-48e9-b74d-e0ae2ab98829,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-f8d3a459-f201-42c7-ac9e-5514829b0a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-1a2db37e-1664-4333-a884-ccc54b8746f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-e6e27f6a-f919-439b-bc94-8c9c124eee57,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-99c9d464-dcb8-4d86-b4ef-4225eefd838b,DISK], DatanodeInfoWithStorage[127.0.0.1:39344,DS-4951132f-bb0f-4787-b5da-a5d3f7dd0d53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 30000000
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-131068456-172.17.0.16-1597404847109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44062,DS-e0ac5214-cf0a-4ccc-ade9-788004867967,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-eb013047-7057-49b6-bc18-68cd98867693,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-23723979-0379-420b-87b5-065554d94fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-a2d95805-71a2-4f61-85b9-4f2b31b5165a,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-5319c836-3f5d-497c-b5f6-885f008e22a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-edc1f84a-d5bc-4826-8389-9296d98eddbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-193f63d1-9811-4cc8-8845-b6c2a4d4c265,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-9141c60a-3e91-4949-a19e-920495409271,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-131068456-172.17.0.16-1597404847109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44062,DS-e0ac5214-cf0a-4ccc-ade9-788004867967,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-eb013047-7057-49b6-bc18-68cd98867693,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-23723979-0379-420b-87b5-065554d94fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38104,DS-a2d95805-71a2-4f61-85b9-4f2b31b5165a,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-5319c836-3f5d-497c-b5f6-885f008e22a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-edc1f84a-d5bc-4826-8389-9296d98eddbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-193f63d1-9811-4cc8-8845-b6c2a4d4c265,DISK], DatanodeInfoWithStorage[127.0.0.1:37505,DS-9141c60a-3e91-4949-a19e-920495409271,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 30000000
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-651815070-172.17.0.16-1597405871953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33971,DS-9b11b1ca-a637-4006-a26d-f8ddd5d88765,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-fb3daf44-44de-4d21-a593-aa2d32fa3e65,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-41fde321-6e42-401f-860d-9b99a26db53b,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-32f7ba3b-7c22-4e33-8de2-6febf7fcf611,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-1ca0ab33-4f48-4105-940a-66b9b2659785,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-6ca3f156-d81e-4704-a394-f4c12ba747cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-9f9c0dc7-8cda-42e7-8136-b57d379ea591,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-f0394402-d8f0-4a6d-b66b-9f79886be4ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-651815070-172.17.0.16-1597405871953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33971,DS-9b11b1ca-a637-4006-a26d-f8ddd5d88765,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-fb3daf44-44de-4d21-a593-aa2d32fa3e65,DISK], DatanodeInfoWithStorage[127.0.0.1:33363,DS-41fde321-6e42-401f-860d-9b99a26db53b,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-32f7ba3b-7c22-4e33-8de2-6febf7fcf611,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-1ca0ab33-4f48-4105-940a-66b9b2659785,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-6ca3f156-d81e-4704-a394-f4c12ba747cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-9f9c0dc7-8cda-42e7-8136-b57d379ea591,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-f0394402-d8f0-4a6d-b66b-9f79886be4ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 30000000
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-735507823-172.17.0.16-1597405906115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45565,DS-d2859580-1c81-4126-aed3-f05fab69ac48,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-87c43c1b-d293-4677-8c33-ca90c1930d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-edb8827c-3204-4a59-92d0-6a79079129cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-9d798f13-d77e-4362-90f0-0f50f03e8fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-f2e452f5-144d-44ff-91ca-179a4a39fcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-efa0ae42-f2b9-41dc-afcb-c4adaa721feb,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-0606fc75-7ff4-48c2-a99f-c5732f533a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-0328c230-5ed2-4a9f-bd4c-7e43f45b1663,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-735507823-172.17.0.16-1597405906115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45565,DS-d2859580-1c81-4126-aed3-f05fab69ac48,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-87c43c1b-d293-4677-8c33-ca90c1930d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-edb8827c-3204-4a59-92d0-6a79079129cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-9d798f13-d77e-4362-90f0-0f50f03e8fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:46486,DS-f2e452f5-144d-44ff-91ca-179a4a39fcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-efa0ae42-f2b9-41dc-afcb-c4adaa721feb,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-0606fc75-7ff4-48c2-a99f-c5732f533a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-0328c230-5ed2-4a9f-bd4c-7e43f45b1663,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 30000000
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-397924134-172.17.0.16-1597406370142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42334,DS-daffc5f2-bbde-4a88-9583-54a8971194e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-ff660514-4491-4eac-8731-a4bafc564e92,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-d34cf5ba-f404-4f92-ae4c-eea36577084b,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-5e6ec949-77a8-4ba3-aff5-0ce57f45a891,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-22d823b7-7a14-4a09-ba4d-b20f20907bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-2a7b7034-0ec2-4965-a210-89dcb5af68cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-f18c114d-13e9-4970-b551-cd400d6e6dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-f7893760-999a-4820-8a92-ea5e57a1d2dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-397924134-172.17.0.16-1597406370142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42334,DS-daffc5f2-bbde-4a88-9583-54a8971194e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-ff660514-4491-4eac-8731-a4bafc564e92,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-d34cf5ba-f404-4f92-ae4c-eea36577084b,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-5e6ec949-77a8-4ba3-aff5-0ce57f45a891,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-22d823b7-7a14-4a09-ba4d-b20f20907bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-2a7b7034-0ec2-4965-a210-89dcb5af68cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-f18c114d-13e9-4970-b551-cd400d6e6dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-f7893760-999a-4820-8a92-ea5e57a1d2dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 30000000
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1174235501-172.17.0.16-1597406665424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35228,DS-3c2bf1a5-3264-4cde-b114-bc4362689a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-c85f8926-0bc4-4b19-af11-7c0a5a6f16fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-c56893f6-7eb5-459b-af9e-26416a064a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-7bfe0337-4c54-486c-ac3b-0080e66720be,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-4dd388a2-8c79-4927-a3c0-69f4c9a3c1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-c461b2b4-e5a8-42c5-9e9b-b3914fb0b6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-30dc956d-c566-4d82-80d3-3f2702f8f71f,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-e4a3fdf7-74e8-4eff-98fc-7f5caebaae45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1174235501-172.17.0.16-1597406665424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35228,DS-3c2bf1a5-3264-4cde-b114-bc4362689a4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-c85f8926-0bc4-4b19-af11-7c0a5a6f16fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-c56893f6-7eb5-459b-af9e-26416a064a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34013,DS-7bfe0337-4c54-486c-ac3b-0080e66720be,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-4dd388a2-8c79-4927-a3c0-69f4c9a3c1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-c461b2b4-e5a8-42c5-9e9b-b3914fb0b6cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-30dc956d-c566-4d82-80d3-3f2702f8f71f,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-e4a3fdf7-74e8-4eff-98fc-7f5caebaae45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 30000000
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-825152896-172.17.0.16-1597406707053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36197,DS-6edc17d4-6810-425c-8f21-4f81586289b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-90751074-102e-4e6e-881f-44bc387f0099,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-d609cb64-4fa2-4b81-a30a-5686772cbd06,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-ed232ebb-43a6-4a2b-94eb-b2d0f8839220,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-5d16cc6c-7bba-41ee-aa92-dc9120a42232,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-62e80a3f-2b44-466b-9189-4b1153ba83b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-722af8b2-63be-4509-a682-c7881b004afe,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-292a67f0-5a4c-4449-a4d3-f04dbf1cb53a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-825152896-172.17.0.16-1597406707053:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36197,DS-6edc17d4-6810-425c-8f21-4f81586289b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-90751074-102e-4e6e-881f-44bc387f0099,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-d609cb64-4fa2-4b81-a30a-5686772cbd06,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-ed232ebb-43a6-4a2b-94eb-b2d0f8839220,DISK], DatanodeInfoWithStorage[127.0.0.1:40294,DS-5d16cc6c-7bba-41ee-aa92-dc9120a42232,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-62e80a3f-2b44-466b-9189-4b1153ba83b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-722af8b2-63be-4509-a682-c7881b004afe,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-292a67f0-5a4c-4449-a4d3-f04dbf1cb53a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.intervalMsec
component: hdfs:DataNode
v1: 30000000
v2: 21600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-217585167-172.17.0.16-1597406752308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41684,DS-2cbb7cb0-8a39-48ce-be04-21b303d1fd17,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-059d8373-314b-4198-a0be-e923319025eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-8a77040a-3b6d-4dd8-a0d1-3eabaaf6878e,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-017bc5a5-6e82-4b13-8b30-7fe777c32d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-8d8574c4-d525-4898-9241-7133df8e253a,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-d06d9c70-9dc5-4559-a000-56858a3405d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-073de9ac-e30c-40e3-b442-07ac3fd2f677,DISK], DatanodeInfoWithStorage[127.0.0.1:42796,DS-05995da1-01a8-4637-8560-373c5dc609ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-217585167-172.17.0.16-1597406752308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41684,DS-2cbb7cb0-8a39-48ce-be04-21b303d1fd17,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-059d8373-314b-4198-a0be-e923319025eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-8a77040a-3b6d-4dd8-a0d1-3eabaaf6878e,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-017bc5a5-6e82-4b13-8b30-7fe777c32d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-8d8574c4-d525-4898-9241-7133df8e253a,DISK], DatanodeInfoWithStorage[127.0.0.1:46672,DS-d06d9c70-9dc5-4559-a000-56858a3405d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-073de9ac-e30c-40e3-b442-07ac3fd2f677,DISK], DatanodeInfoWithStorage[127.0.0.1:42796,DS-05995da1-01a8-4637-8560-373c5dc609ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5949
