reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1793158104-172.17.0.6-1597286024928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34853,DS-8c30a720-6b8d-41da-b25e-9dba82839789,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-e9eb6ce2-e879-41f9-8d6f-c35b45f3f7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-e3376157-069b-4f4c-92be-d3a4bf581c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-85f30f42-8ffa-41ae-8acb-7ea54ab3f846,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-a4304e42-fe92-406a-902a-9e8514ad414f,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-93b37a2b-f927-4732-bb93-b7db2221a076,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-26dd9fa1-4c8d-46ae-be00-f7f7c11f4e86,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-31fc0c4e-275b-4ce3-affb-ecc004d0a3b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1793158104-172.17.0.6-1597286024928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34853,DS-8c30a720-6b8d-41da-b25e-9dba82839789,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-e9eb6ce2-e879-41f9-8d6f-c35b45f3f7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-e3376157-069b-4f4c-92be-d3a4bf581c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-85f30f42-8ffa-41ae-8acb-7ea54ab3f846,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-a4304e42-fe92-406a-902a-9e8514ad414f,DISK], DatanodeInfoWithStorage[127.0.0.1:36143,DS-93b37a2b-f927-4732-bb93-b7db2221a076,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-26dd9fa1-4c8d-46ae-be00-f7f7c11f4e86,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-31fc0c4e-275b-4ce3-affb-ecc004d0a3b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567953406-172.17.0.6-1597286094470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40507,DS-03d844a8-09a1-4c37-a7b7-ba587f13ffc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-4f6a950c-cdfd-4525-8a55-b4769d1a90df,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-15b2b4c1-f1ad-45c0-9a53-6dea3f59dde6,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-66217c16-9cf7-4ccc-9963-53f49bc8d933,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-7a1d4c6a-2d0e-4694-9a8a-c4f383245718,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-87d6cd2e-4243-4faf-8f3e-4d29b191d9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-807087dd-ea3a-44af-8e87-e9925664ce33,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-ac75cce4-4eed-4281-a771-82fa690fabfd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567953406-172.17.0.6-1597286094470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40507,DS-03d844a8-09a1-4c37-a7b7-ba587f13ffc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-4f6a950c-cdfd-4525-8a55-b4769d1a90df,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-15b2b4c1-f1ad-45c0-9a53-6dea3f59dde6,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-66217c16-9cf7-4ccc-9963-53f49bc8d933,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-7a1d4c6a-2d0e-4694-9a8a-c4f383245718,DISK], DatanodeInfoWithStorage[127.0.0.1:40150,DS-87d6cd2e-4243-4faf-8f3e-4d29b191d9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45900,DS-807087dd-ea3a-44af-8e87-e9925664ce33,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-ac75cce4-4eed-4281-a771-82fa690fabfd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1365880535-172.17.0.6-1597286674379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41970,DS-78bb9e59-5411-4c2a-b3f4-c9488e2441e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-522bbf0f-51b7-4d41-bb4f-272ad6f0b221,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-21b35e9d-ecd8-41bf-9a6b-779f73ffef3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-be9ffc61-f835-46b3-bc7d-f646a026d592,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-0eb7cb8c-0168-429a-98d3-9e713287198b,DISK], DatanodeInfoWithStorage[127.0.0.1:43618,DS-8438ad61-5ec5-4a34-acfe-7afcafcce27e,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-f84d82b7-09d5-43fa-965a-51babbae6162,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-b460d66c-bb37-47e7-adc0-5aa94f4abccd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1365880535-172.17.0.6-1597286674379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41970,DS-78bb9e59-5411-4c2a-b3f4-c9488e2441e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-522bbf0f-51b7-4d41-bb4f-272ad6f0b221,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-21b35e9d-ecd8-41bf-9a6b-779f73ffef3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-be9ffc61-f835-46b3-bc7d-f646a026d592,DISK], DatanodeInfoWithStorage[127.0.0.1:33662,DS-0eb7cb8c-0168-429a-98d3-9e713287198b,DISK], DatanodeInfoWithStorage[127.0.0.1:43618,DS-8438ad61-5ec5-4a34-acfe-7afcafcce27e,DISK], DatanodeInfoWithStorage[127.0.0.1:45890,DS-f84d82b7-09d5-43fa-965a-51babbae6162,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-b460d66c-bb37-47e7-adc0-5aa94f4abccd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-955590112-172.17.0.6-1597286779351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45029,DS-8d34f216-9c24-42c4-b3e0-af6901f99715,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-a2fdf692-2e39-4ee9-9b04-1259c09f2461,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-a31f0de4-b96a-4d0c-ae59-aeaa87fa8920,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-8dd9bd6a-c5ba-4ea8-b973-b7e0472f16f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-ac0b0fce-d5a0-44f2-8da7-783cf70a6598,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-3631a5b5-db07-403e-844b-02b08894afe4,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-0eb5e37d-d5e4-4052-bf4a-89addc0168a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-a98752a7-c8aa-4b31-bfe7-7b7d817b939a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-955590112-172.17.0.6-1597286779351:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45029,DS-8d34f216-9c24-42c4-b3e0-af6901f99715,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-a2fdf692-2e39-4ee9-9b04-1259c09f2461,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-a31f0de4-b96a-4d0c-ae59-aeaa87fa8920,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-8dd9bd6a-c5ba-4ea8-b973-b7e0472f16f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-ac0b0fce-d5a0-44f2-8da7-783cf70a6598,DISK], DatanodeInfoWithStorage[127.0.0.1:43919,DS-3631a5b5-db07-403e-844b-02b08894afe4,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-0eb5e37d-d5e4-4052-bf4a-89addc0168a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35083,DS-a98752a7-c8aa-4b31-bfe7-7b7d817b939a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-14976645-172.17.0.6-1597286818587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43298,DS-01645576-3240-414a-8d19-d13630070bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-7d8a5e7c-853e-42e0-a5c5-6f4ebd9c7399,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-568d32c2-a4b6-4d49-810e-cccc41af42d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-813ef2e3-831a-4e8c-a5e4-ba32bf530bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-3f5d04f4-0a84-4439-bf2c-667550424e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-ff4c35fc-0204-4c65-947d-d4403eb344b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-c72b52c0-cfe7-4989-8177-2a828c5c2760,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-802cc097-e120-4636-864e-f64e9a636aa6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-14976645-172.17.0.6-1597286818587:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43298,DS-01645576-3240-414a-8d19-d13630070bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43587,DS-7d8a5e7c-853e-42e0-a5c5-6f4ebd9c7399,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-568d32c2-a4b6-4d49-810e-cccc41af42d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-813ef2e3-831a-4e8c-a5e4-ba32bf530bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-3f5d04f4-0a84-4439-bf2c-667550424e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-ff4c35fc-0204-4c65-947d-d4403eb344b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-c72b52c0-cfe7-4989-8177-2a828c5c2760,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-802cc097-e120-4636-864e-f64e9a636aa6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-887670266-172.17.0.6-1597286951816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38736,DS-80766e2c-9cd9-4b4e-9d0b-b409ea20967a,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-cf5cb3ae-ddeb-4e6a-aa33-bee76e54f212,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-6b107c5f-5f17-4c7e-8d93-a6148a86ed67,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-81fd0b18-e2b6-402e-ae24-07758d3a1b93,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-41abb239-818d-4736-85e2-70099b2bea7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-b38c16ad-4348-4970-8cff-97a708f05651,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-a03da5c4-f0ce-47ab-8a0d-154d3bef5277,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-037794b8-6909-4645-9b0a-294a4e966ae5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-887670266-172.17.0.6-1597286951816:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38736,DS-80766e2c-9cd9-4b4e-9d0b-b409ea20967a,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-cf5cb3ae-ddeb-4e6a-aa33-bee76e54f212,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-6b107c5f-5f17-4c7e-8d93-a6148a86ed67,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-81fd0b18-e2b6-402e-ae24-07758d3a1b93,DISK], DatanodeInfoWithStorage[127.0.0.1:35699,DS-41abb239-818d-4736-85e2-70099b2bea7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44843,DS-b38c16ad-4348-4970-8cff-97a708f05651,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-a03da5c4-f0ce-47ab-8a0d-154d3bef5277,DISK], DatanodeInfoWithStorage[127.0.0.1:33241,DS-037794b8-6909-4645-9b0a-294a4e966ae5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1573898171-172.17.0.6-1597287729178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38020,DS-30c858f0-0014-4fd4-871e-3205caf6f68c,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-4047f26b-a5ca-415f-aa1e-4736395bfd20,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-f4b6d48a-c06e-4e96-ad47-97c3e7d9e703,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-f984a991-5756-4a6b-838d-7e7dc61917f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-c1ed262d-308f-43ae-8245-e3ac05860934,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-82802a8e-10d9-4e14-9898-8195ac8b2392,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-5a4e2f76-3807-4d16-969c-599b75e0bd71,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-c03a2c0e-cf4a-4edc-967d-ce118ff865ed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1573898171-172.17.0.6-1597287729178:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38020,DS-30c858f0-0014-4fd4-871e-3205caf6f68c,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-4047f26b-a5ca-415f-aa1e-4736395bfd20,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-f4b6d48a-c06e-4e96-ad47-97c3e7d9e703,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-f984a991-5756-4a6b-838d-7e7dc61917f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-c1ed262d-308f-43ae-8245-e3ac05860934,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-82802a8e-10d9-4e14-9898-8195ac8b2392,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-5a4e2f76-3807-4d16-969c-599b75e0bd71,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-c03a2c0e-cf4a-4edc-967d-ce118ff865ed,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1170389633-172.17.0.6-1597287769640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32796,DS-adf2deed-362f-4cbb-a652-b5773105290c,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-c313eb27-d108-4e35-8a57-4436406c3e66,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-b45b5361-820c-4a96-8bab-a60b032e01ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-440725a6-8b38-4502-9078-b9da05469a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-6f27701d-899a-495f-9f83-dde9ecf0c7da,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-9fcf012b-8b99-4c4e-ba47-ea22d431d920,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-ca7db9c3-9ea5-4773-93e5-fcfe3d34cff1,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-919440e0-02dd-4f79-9f69-eee7041f91a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1170389633-172.17.0.6-1597287769640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32796,DS-adf2deed-362f-4cbb-a652-b5773105290c,DISK], DatanodeInfoWithStorage[127.0.0.1:35667,DS-c313eb27-d108-4e35-8a57-4436406c3e66,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-b45b5361-820c-4a96-8bab-a60b032e01ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45145,DS-440725a6-8b38-4502-9078-b9da05469a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-6f27701d-899a-495f-9f83-dde9ecf0c7da,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-9fcf012b-8b99-4c4e-ba47-ea22d431d920,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-ca7db9c3-9ea5-4773-93e5-fcfe3d34cff1,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-919440e0-02dd-4f79-9f69-eee7041f91a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122628457-172.17.0.6-1597287801898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36090,DS-db36732e-0d56-4ed7-9eab-9bd1158f2d04,DISK], DatanodeInfoWithStorage[127.0.0.1:45323,DS-6c7c4b95-2c28-4581-bcc3-c9bd2eadea66,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-b8a87c3c-fd32-40b8-a1ad-27f2aad6ca86,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-1aad7fe4-ca10-4919-8e96-ee07fdb7b81a,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-cbaa7f09-fed4-419c-b07b-591795c25540,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-e1ccd059-6a91-49dc-99ae-9a3993790a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-85c9143c-c429-47bd-bd13-f9d1e50cd3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-b621d55c-4178-41fe-ab6e-593f286e6dee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122628457-172.17.0.6-1597287801898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36090,DS-db36732e-0d56-4ed7-9eab-9bd1158f2d04,DISK], DatanodeInfoWithStorage[127.0.0.1:45323,DS-6c7c4b95-2c28-4581-bcc3-c9bd2eadea66,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-b8a87c3c-fd32-40b8-a1ad-27f2aad6ca86,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-1aad7fe4-ca10-4919-8e96-ee07fdb7b81a,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-cbaa7f09-fed4-419c-b07b-591795c25540,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-e1ccd059-6a91-49dc-99ae-9a3993790a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-85c9143c-c429-47bd-bd13-f9d1e50cd3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-b621d55c-4178-41fe-ab6e-593f286e6dee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976949723-172.17.0.6-1597287844545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34902,DS-fe982ebf-d133-4818-8527-fce157dff80e,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-30f70879-3d6f-41f8-955c-f223fa5b1bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-410990f0-d574-49b1-9be9-d6fcd80a6bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-01ef31b1-bea2-487c-8b79-0fcf1e8f5e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-24cab0fa-620c-4cbd-b9f0-e6be7d983a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-9571e531-a0fd-4b74-b5be-bfc94afddbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-35887764-02f6-4b76-b28c-6ef6c802283b,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-fca860d7-736f-4e38-8840-7a87c57b85e0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1976949723-172.17.0.6-1597287844545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34902,DS-fe982ebf-d133-4818-8527-fce157dff80e,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-30f70879-3d6f-41f8-955c-f223fa5b1bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:32835,DS-410990f0-d574-49b1-9be9-d6fcd80a6bcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-01ef31b1-bea2-487c-8b79-0fcf1e8f5e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-24cab0fa-620c-4cbd-b9f0-e6be7d983a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37515,DS-9571e531-a0fd-4b74-b5be-bfc94afddbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-35887764-02f6-4b76-b28c-6ef6c802283b,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-fca860d7-736f-4e38-8840-7a87c57b85e0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059249774-172.17.0.6-1597288127407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35662,DS-87452052-4a4e-44ba-bce0-ecc76750b9df,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-7f9e22de-4993-4dec-b2d1-4741214715d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-1d957cb2-5282-489d-a1ca-505af055bdc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34640,DS-19bd4dee-592a-49fd-88d9-bb560c5a2563,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-27228a26-9d1d-412a-94bb-21c808e6d24c,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-73af9edb-6dae-430c-b965-b1db9e920ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-207f21b3-b206-4883-9775-c5c9de3e4917,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-a8dc5cff-eaff-43ba-9f59-37f39215c02a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059249774-172.17.0.6-1597288127407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35662,DS-87452052-4a4e-44ba-bce0-ecc76750b9df,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-7f9e22de-4993-4dec-b2d1-4741214715d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-1d957cb2-5282-489d-a1ca-505af055bdc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34640,DS-19bd4dee-592a-49fd-88d9-bb560c5a2563,DISK], DatanodeInfoWithStorage[127.0.0.1:46017,DS-27228a26-9d1d-412a-94bb-21c808e6d24c,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-73af9edb-6dae-430c-b965-b1db9e920ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-207f21b3-b206-4883-9775-c5c9de3e4917,DISK], DatanodeInfoWithStorage[127.0.0.1:40244,DS-a8dc5cff-eaff-43ba-9f59-37f39215c02a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1938196257-172.17.0.6-1597288316169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43133,DS-ee09b94e-32f2-4a33-99f5-8b8218bc9e09,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-88155474-5ef3-4200-bcda-4a789c62bdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-6172cd01-abfd-4b09-85c2-85ada9d38372,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-13ddcaf1-9d95-4a50-8d95-01e5435aff0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-010abeda-d8cf-4981-a946-5cff7d657f11,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-69030a08-aaa8-4720-98e6-96daed8a5ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-5ee8403d-b9bb-413b-8b69-d5cc1e506aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-87170db8-c7ea-40d2-844b-22ed3f9c1ec7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1938196257-172.17.0.6-1597288316169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43133,DS-ee09b94e-32f2-4a33-99f5-8b8218bc9e09,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-88155474-5ef3-4200-bcda-4a789c62bdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-6172cd01-abfd-4b09-85c2-85ada9d38372,DISK], DatanodeInfoWithStorage[127.0.0.1:39850,DS-13ddcaf1-9d95-4a50-8d95-01e5435aff0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-010abeda-d8cf-4981-a946-5cff7d657f11,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-69030a08-aaa8-4720-98e6-96daed8a5ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-5ee8403d-b9bb-413b-8b69-d5cc1e506aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37762,DS-87170db8-c7ea-40d2-844b-22ed3f9c1ec7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211695260-172.17.0.6-1597288388593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37117,DS-8571e0f0-07aa-46ec-8337-a941f8d4a380,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-97271f27-ecac-49c2-9744-202be2e062ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-2ea4c53c-0022-40e7-a8ce-80fbc0073958,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-50bd3414-3324-4ee4-8f77-e48f2cf0fb67,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-c7f9fd02-3b4d-4965-aec3-7bd4baa4849d,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-a90d822e-251b-4059-823a-9804a6395cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-0766dcfb-9aff-4c0d-a924-524311890300,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-321dc4f9-cccd-44cf-8591-86b666cff900,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-211695260-172.17.0.6-1597288388593:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37117,DS-8571e0f0-07aa-46ec-8337-a941f8d4a380,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-97271f27-ecac-49c2-9744-202be2e062ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-2ea4c53c-0022-40e7-a8ce-80fbc0073958,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-50bd3414-3324-4ee4-8f77-e48f2cf0fb67,DISK], DatanodeInfoWithStorage[127.0.0.1:33659,DS-c7f9fd02-3b4d-4965-aec3-7bd4baa4849d,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-a90d822e-251b-4059-823a-9804a6395cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33938,DS-0766dcfb-9aff-4c0d-a924-524311890300,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-321dc4f9-cccd-44cf-8591-86b666cff900,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507585969-172.17.0.6-1597288710786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33258,DS-f9121743-743a-4e1f-aeba-a2d70171a855,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-9f25f6dc-3dce-41ff-afb7-b6fea86d4a29,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-3976481f-5d9b-4f8f-b56a-f4b3ce8b67bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-7a8e9d69-bee1-49a7-a6b1-24792dec394f,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-12812b3b-4408-4b80-a13d-89af08f8ad96,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-45fdcdfc-d094-4fa5-9ebc-361f3284b87a,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-0dac618d-7a09-4288-a57e-52e0d744ab91,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-0c700de8-93c7-47b2-980e-7b37e8f34060,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507585969-172.17.0.6-1597288710786:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33258,DS-f9121743-743a-4e1f-aeba-a2d70171a855,DISK], DatanodeInfoWithStorage[127.0.0.1:34236,DS-9f25f6dc-3dce-41ff-afb7-b6fea86d4a29,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-3976481f-5d9b-4f8f-b56a-f4b3ce8b67bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-7a8e9d69-bee1-49a7-a6b1-24792dec394f,DISK], DatanodeInfoWithStorage[127.0.0.1:36446,DS-12812b3b-4408-4b80-a13d-89af08f8ad96,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-45fdcdfc-d094-4fa5-9ebc-361f3284b87a,DISK], DatanodeInfoWithStorage[127.0.0.1:46626,DS-0dac618d-7a09-4288-a57e-52e0d744ab91,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-0c700de8-93c7-47b2-980e-7b37e8f34060,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822269545-172.17.0.6-1597288896834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37279,DS-25b651c2-2396-4145-ae4c-d87076563d21,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-f280bc56-43f0-4752-8d12-8e604691137a,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-3a5edcde-135e-4717-a944-b9ff43866876,DISK], DatanodeInfoWithStorage[127.0.0.1:34030,DS-05a47b66-5c7f-443e-a1be-07bfdcc53418,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-a9ea9ccb-55bd-4fd4-8406-a466faadb761,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-0d914d19-e9be-4957-a29a-2c4010a04ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-46046aa3-ebea-47c9-ab64-6a2fe7f13206,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-4f53e5fc-e17a-4df9-9c5d-e98a6492f149,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1822269545-172.17.0.6-1597288896834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37279,DS-25b651c2-2396-4145-ae4c-d87076563d21,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-f280bc56-43f0-4752-8d12-8e604691137a,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-3a5edcde-135e-4717-a944-b9ff43866876,DISK], DatanodeInfoWithStorage[127.0.0.1:34030,DS-05a47b66-5c7f-443e-a1be-07bfdcc53418,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-a9ea9ccb-55bd-4fd4-8406-a466faadb761,DISK], DatanodeInfoWithStorage[127.0.0.1:35305,DS-0d914d19-e9be-4957-a29a-2c4010a04ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-46046aa3-ebea-47c9-ab64-6a2fe7f13206,DISK], DatanodeInfoWithStorage[127.0.0.1:38220,DS-4f53e5fc-e17a-4df9-9c5d-e98a6492f149,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2074518380-172.17.0.6-1597289255259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41520,DS-12a0f273-36a3-4f8d-b6a7-ff5b36b52d63,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-62e11ecf-cb48-4ebc-a36f-31adceaaaacc,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-ecb72366-294a-4ffc-abaf-a5a62155308e,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-13f1ab75-86e1-4ac4-96e6-2030efd68d70,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-1229cee3-4151-4091-9565-e125fb117a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-547d5376-f1b6-4ca4-a303-e2c1559a0ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-6582eadf-a685-473d-bb43-a33f6497c2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-37f8247a-ca23-4d23-a827-6b9aec49fdf7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2074518380-172.17.0.6-1597289255259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41520,DS-12a0f273-36a3-4f8d-b6a7-ff5b36b52d63,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-62e11ecf-cb48-4ebc-a36f-31adceaaaacc,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-ecb72366-294a-4ffc-abaf-a5a62155308e,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-13f1ab75-86e1-4ac4-96e6-2030efd68d70,DISK], DatanodeInfoWithStorage[127.0.0.1:37821,DS-1229cee3-4151-4091-9565-e125fb117a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-547d5376-f1b6-4ca4-a303-e2c1559a0ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-6582eadf-a685-473d-bb43-a33f6497c2c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-37f8247a-ca23-4d23-a827-6b9aec49fdf7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-96047218-172.17.0.6-1597289325007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42830,DS-eb33caeb-3d09-4163-b0f8-6100b3afb60c,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-02638942-11c4-4769-ba35-77ffebf372ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-becee4af-9a2d-4b4e-adbe-64c2cf391118,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-b27439fc-3d92-4167-8fb2-c0bc2bf8ab74,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-013c87fe-6ea7-4d96-b3e7-a37a2c865d35,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-4b1fdb81-997a-4b0c-8ad9-8d6703bdf2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-08ae7a15-051a-49e4-b709-8dc7ba036fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-4fb73866-f7f8-4ef4-9422-acda1b7bcdc6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-96047218-172.17.0.6-1597289325007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42830,DS-eb33caeb-3d09-4163-b0f8-6100b3afb60c,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-02638942-11c4-4769-ba35-77ffebf372ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-becee4af-9a2d-4b4e-adbe-64c2cf391118,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-b27439fc-3d92-4167-8fb2-c0bc2bf8ab74,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-013c87fe-6ea7-4d96-b3e7-a37a2c865d35,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-4b1fdb81-997a-4b0c-8ad9-8d6703bdf2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-08ae7a15-051a-49e4-b709-8dc7ba036fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41956,DS-4fb73866-f7f8-4ef4-9422-acda1b7bcdc6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1971543636-172.17.0.6-1597289525339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37359,DS-0be4c01b-e437-4eae-a52b-db94d008cb14,DISK], DatanodeInfoWithStorage[127.0.0.1:43215,DS-7bb2fed0-2845-4fda-a498-f7d1c01597ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-1cc5b6bd-6ecd-4f0f-b98a-4b291be3cbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-18ba13d3-e64f-4892-b175-ea23a04125c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-741bf551-f13d-4405-9d46-ea5f1cc4cdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-f01ed1e6-be15-42c6-b7b5-211410a51fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-59fa088b-91d6-4611-aeb7-b0c4f7971b51,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-8fcfdaf1-26c6-4158-8b45-802e9fa91103,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1971543636-172.17.0.6-1597289525339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37359,DS-0be4c01b-e437-4eae-a52b-db94d008cb14,DISK], DatanodeInfoWithStorage[127.0.0.1:43215,DS-7bb2fed0-2845-4fda-a498-f7d1c01597ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-1cc5b6bd-6ecd-4f0f-b98a-4b291be3cbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-18ba13d3-e64f-4892-b175-ea23a04125c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34258,DS-741bf551-f13d-4405-9d46-ea5f1cc4cdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-f01ed1e6-be15-42c6-b7b5-211410a51fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-59fa088b-91d6-4611-aeb7-b0c4f7971b51,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-8fcfdaf1-26c6-4158-8b45-802e9fa91103,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1009893690-172.17.0.6-1597289774740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40148,DS-f3590764-3261-446b-9433-05f1cc759871,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-2060710a-f154-4629-a7e4-8e1d008c4754,DISK], DatanodeInfoWithStorage[127.0.0.1:32913,DS-1c6fa4da-f82b-49a3-92ec-5045a6b186c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-482eb786-2ca7-4124-9dd1-9d1945e0f375,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-734d2a75-f8e6-492b-b400-4bc74886df8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36288,DS-b0256ffb-0bf3-4075-b15e-ad30d48c394e,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-4cf96751-1183-41a8-98d1-c3aa72b252e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-fad11256-f212-41b0-98f3-6dbda2ea054a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1009893690-172.17.0.6-1597289774740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40148,DS-f3590764-3261-446b-9433-05f1cc759871,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-2060710a-f154-4629-a7e4-8e1d008c4754,DISK], DatanodeInfoWithStorage[127.0.0.1:32913,DS-1c6fa4da-f82b-49a3-92ec-5045a6b186c2,DISK], DatanodeInfoWithStorage[127.0.0.1:40284,DS-482eb786-2ca7-4124-9dd1-9d1945e0f375,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-734d2a75-f8e6-492b-b400-4bc74886df8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36288,DS-b0256ffb-0bf3-4075-b15e-ad30d48c394e,DISK], DatanodeInfoWithStorage[127.0.0.1:35813,DS-4cf96751-1183-41a8-98d1-c3aa72b252e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42853,DS-fad11256-f212-41b0-98f3-6dbda2ea054a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1436590193-172.17.0.6-1597290293691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38414,DS-551f72ce-7458-4c04-a701-2c5e80117312,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-b7fe83d0-6d8a-40a0-b14a-3d337cb06e54,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-344ec14d-46a1-4078-acdf-d4cb719483c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-3f9aedf1-34ae-444e-959a-f9cca9314d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36902,DS-920b009a-4750-461e-864c-a9cdd10589cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-f7e15a09-cdb2-4c77-83b4-bf64daeab8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-c75dc29d-4c83-4150-95b0-44b9660b555e,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-ba2633f8-4b70-48f2-8037-4ef7ec145d98,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1436590193-172.17.0.6-1597290293691:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38414,DS-551f72ce-7458-4c04-a701-2c5e80117312,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-b7fe83d0-6d8a-40a0-b14a-3d337cb06e54,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-344ec14d-46a1-4078-acdf-d4cb719483c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-3f9aedf1-34ae-444e-959a-f9cca9314d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36902,DS-920b009a-4750-461e-864c-a9cdd10589cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37733,DS-f7e15a09-cdb2-4c77-83b4-bf64daeab8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38820,DS-c75dc29d-4c83-4150-95b0-44b9660b555e,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-ba2633f8-4b70-48f2-8037-4ef7ec145d98,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1971007371-172.17.0.6-1597290685766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42947,DS-c026fc99-2843-406d-b72b-348d9f0a039f,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-94e6dc79-a80c-423f-976b-9929db4023fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-216bac0e-94a4-458c-95c9-85629ede5e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-c8221e11-a719-421c-a128-328f2c5cce34,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-cd12a3a7-00c8-42e0-a0ae-c6cddd3622b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-370ed600-b6f2-4698-832a-924b3fff5a75,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-a56f9e12-6c88-4c7b-9743-82b7d149c3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-db7922a2-e546-4443-b521-5224c8751660,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1971007371-172.17.0.6-1597290685766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42947,DS-c026fc99-2843-406d-b72b-348d9f0a039f,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-94e6dc79-a80c-423f-976b-9929db4023fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-216bac0e-94a4-458c-95c9-85629ede5e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-c8221e11-a719-421c-a128-328f2c5cce34,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-cd12a3a7-00c8-42e0-a0ae-c6cddd3622b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-370ed600-b6f2-4698-832a-924b3fff5a75,DISK], DatanodeInfoWithStorage[127.0.0.1:34199,DS-a56f9e12-6c88-4c7b-9743-82b7d149c3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-db7922a2-e546-4443-b521-5224c8751660,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1484021418-172.17.0.6-1597291311302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39715,DS-9b540e18-fcda-43a8-8df1-2755528a8f02,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-c6539d70-2603-4af2-8e60-15a1d2a2ed95,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-ce8c1245-d051-4fad-992e-222c18dda228,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-938220f6-b188-4075-a8d4-64cc868574e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-6086bc7c-441d-4830-b641-3d1d8c67ec83,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-c341ad46-17a3-4a15-91de-fe26bc6eb4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-c5810352-b2f5-4fa9-8774-3e1bb1f588f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-085e8252-55ad-4af2-830d-d648343cd13d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1484021418-172.17.0.6-1597291311302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39715,DS-9b540e18-fcda-43a8-8df1-2755528a8f02,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-c6539d70-2603-4af2-8e60-15a1d2a2ed95,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-ce8c1245-d051-4fad-992e-222c18dda228,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-938220f6-b188-4075-a8d4-64cc868574e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-6086bc7c-441d-4830-b641-3d1d8c67ec83,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-c341ad46-17a3-4a15-91de-fe26bc6eb4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-c5810352-b2f5-4fa9-8774-3e1bb1f588f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-085e8252-55ad-4af2-830d-d648343cd13d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-973499558-172.17.0.6-1597291431257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40243,DS-0d8f80de-4b77-45c9-b497-8fc2e3db7761,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-9ee020fc-2245-4bf1-8f0d-b92295716cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-570c4787-870f-4d75-a219-3167ae6458e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-779d5099-27d7-498d-b9b9-179adf5e635b,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-21cf1173-cf1b-4947-86d7-c9baa1c0e1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34646,DS-80798989-6d63-4d25-9022-0000f663784c,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-0b30f75e-ea2d-40b3-a66c-519b8b7caa6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-134ef3db-6f18-42ef-a7ed-120984c50d50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-973499558-172.17.0.6-1597291431257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40243,DS-0d8f80de-4b77-45c9-b497-8fc2e3db7761,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-9ee020fc-2245-4bf1-8f0d-b92295716cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-570c4787-870f-4d75-a219-3167ae6458e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-779d5099-27d7-498d-b9b9-179adf5e635b,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-21cf1173-cf1b-4947-86d7-c9baa1c0e1c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34646,DS-80798989-6d63-4d25-9022-0000f663784c,DISK], DatanodeInfoWithStorage[127.0.0.1:38201,DS-0b30f75e-ea2d-40b3-a66c-519b8b7caa6b,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-134ef3db-6f18-42ef-a7ed-120984c50d50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5565
