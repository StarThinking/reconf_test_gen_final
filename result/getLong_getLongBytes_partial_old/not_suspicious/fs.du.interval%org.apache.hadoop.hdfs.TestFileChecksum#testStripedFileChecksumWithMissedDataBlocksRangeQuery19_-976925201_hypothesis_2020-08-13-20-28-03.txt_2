reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1818364088-172.17.0.3-1597350631293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33243,DS-1d9dd3ae-a67c-4718-82f7-a431367850f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-bc22bbdd-46d1-4131-80e4-7dddba827a60,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-c2a6fa7b-7723-4402-a779-aee3c2a556f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-2546c4fd-4f79-47a8-bfe5-4f0f2fed5b51,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-6672c14c-6805-49ff-9c65-3e7143044010,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-6217fee4-f11f-4c39-b51b-0a199cef0713,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-5b62b8d2-e93a-44f6-b868-d84c8d797df9,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-e8bbd211-8c7c-44a1-a6f8-90f803f9a193,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1818364088-172.17.0.3-1597350631293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33243,DS-1d9dd3ae-a67c-4718-82f7-a431367850f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35612,DS-bc22bbdd-46d1-4131-80e4-7dddba827a60,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-c2a6fa7b-7723-4402-a779-aee3c2a556f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-2546c4fd-4f79-47a8-bfe5-4f0f2fed5b51,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-6672c14c-6805-49ff-9c65-3e7143044010,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-6217fee4-f11f-4c39-b51b-0a199cef0713,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-5b62b8d2-e93a-44f6-b868-d84c8d797df9,DISK], DatanodeInfoWithStorage[127.0.0.1:35449,DS-e8bbd211-8c7c-44a1-a6f8-90f803f9a193,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1855603937-172.17.0.3-1597350737967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34412,DS-505e9b88-b4ec-40e1-9d57-9829a123b54f,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-bd906309-98ae-4bd8-ba09-58a783d7770e,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-b3c955e2-b00c-4354-a783-df75bdc81ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-afa6fd67-00a8-4094-a1cc-39d7973a08dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-fe5daf0a-ea03-41a5-85ed-0d360e1f2630,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-1d109032-8228-4851-8967-9a4b442c85e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-b09bb3b9-a583-4f94-90bb-a88106bfe0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-8cd2849b-9ec0-4365-ac9f-a4ca29f26c75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1855603937-172.17.0.3-1597350737967:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34412,DS-505e9b88-b4ec-40e1-9d57-9829a123b54f,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-bd906309-98ae-4bd8-ba09-58a783d7770e,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-b3c955e2-b00c-4354-a783-df75bdc81ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-afa6fd67-00a8-4094-a1cc-39d7973a08dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-fe5daf0a-ea03-41a5-85ed-0d360e1f2630,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-1d109032-8228-4851-8967-9a4b442c85e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-b09bb3b9-a583-4f94-90bb-a88106bfe0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37826,DS-8cd2849b-9ec0-4365-ac9f-a4ca29f26c75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2122754778-172.17.0.3-1597350777279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40230,DS-2528b210-b176-4e1f-affb-d87633dc424c,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-c7b37e98-93b9-4c00-8e7a-0ff28a437c23,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-a52d4863-7bf5-46da-b97b-822ac62cf78a,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-6488365a-fc02-494c-bcdc-c862269b9eab,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-07f70f4c-406a-4145-84c0-621dfb8005cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-ef2b5110-f5ec-4dce-b37b-dfdc40bef56f,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-d34bb86d-f86c-46ab-b561-6abe71b808f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-8e78467e-90b3-4f5a-ae79-c6044d12c7a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2122754778-172.17.0.3-1597350777279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40230,DS-2528b210-b176-4e1f-affb-d87633dc424c,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-c7b37e98-93b9-4c00-8e7a-0ff28a437c23,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-a52d4863-7bf5-46da-b97b-822ac62cf78a,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-6488365a-fc02-494c-bcdc-c862269b9eab,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-07f70f4c-406a-4145-84c0-621dfb8005cf,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-ef2b5110-f5ec-4dce-b37b-dfdc40bef56f,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-d34bb86d-f86c-46ab-b561-6abe71b808f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-8e78467e-90b3-4f5a-ae79-c6044d12c7a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-279535120-172.17.0.3-1597350895028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41583,DS-f25cf7fe-005c-4878-8a43-fb88ed5e4b55,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-ce04ad2f-1aeb-4c43-8d19-2587fdaddedb,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-b952e5a8-db43-4cf9-a325-a7351efaa7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-ca9dbd19-b00e-48bd-8c2a-38bf03c0e099,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-ce517865-0ce6-4930-b0f9-beb8d42bfc39,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-50063ee8-15b6-451e-9166-50eba973f4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-98c4e8b8-3269-459f-970d-e72d4dece149,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-95f15fb9-8ce7-4d07-b737-8d9c2a5e831a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-279535120-172.17.0.3-1597350895028:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41583,DS-f25cf7fe-005c-4878-8a43-fb88ed5e4b55,DISK], DatanodeInfoWithStorage[127.0.0.1:42880,DS-ce04ad2f-1aeb-4c43-8d19-2587fdaddedb,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-b952e5a8-db43-4cf9-a325-a7351efaa7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-ca9dbd19-b00e-48bd-8c2a-38bf03c0e099,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-ce517865-0ce6-4930-b0f9-beb8d42bfc39,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-50063ee8-15b6-451e-9166-50eba973f4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-98c4e8b8-3269-459f-970d-e72d4dece149,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-95f15fb9-8ce7-4d07-b737-8d9c2a5e831a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-264429564-172.17.0.3-1597351273637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46049,DS-f4c3e2f2-b546-43d5-9e88-9ac02e2bc030,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-f208e61c-38df-40f7-89c8-f66f334de208,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-b2d93bea-d990-4da4-8f14-146d606ad7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-2967514a-7428-4f0c-af24-1df2910728bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-274f83bd-faa2-4bac-95ef-665fb50bb53b,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-c00fa61e-7da9-491c-a614-2560f4f9859c,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-70e41a8d-3421-498a-bbb7-a30db6358582,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-351d72d7-ad07-4d8f-9f64-dc24a09e38b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-264429564-172.17.0.3-1597351273637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46049,DS-f4c3e2f2-b546-43d5-9e88-9ac02e2bc030,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-f208e61c-38df-40f7-89c8-f66f334de208,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-b2d93bea-d990-4da4-8f14-146d606ad7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-2967514a-7428-4f0c-af24-1df2910728bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-274f83bd-faa2-4bac-95ef-665fb50bb53b,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-c00fa61e-7da9-491c-a614-2560f4f9859c,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-70e41a8d-3421-498a-bbb7-a30db6358582,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-351d72d7-ad07-4d8f-9f64-dc24a09e38b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1362960277-172.17.0.3-1597351423100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44280,DS-4a6a47c6-bf5a-46f6-ab85-892dc0d10ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-18efefbe-7b5f-49b9-b929-75568cb8ee87,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-76e04bb2-85cd-4ef5-a8df-30c0c00f6c17,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-aa65ca0d-8c1c-4548-86c1-ee5ed3c0d10e,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-35dfd9cf-c947-41c6-ad9f-0f764a0ca060,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-b79885a4-fb20-4e5f-abcc-cef265d841fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-639a88e4-8a1e-498f-8864-e0dfb6d41e21,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-882ee1f8-0f8d-47de-96d4-dbd6cb5acc84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1362960277-172.17.0.3-1597351423100:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44280,DS-4a6a47c6-bf5a-46f6-ab85-892dc0d10ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-18efefbe-7b5f-49b9-b929-75568cb8ee87,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-76e04bb2-85cd-4ef5-a8df-30c0c00f6c17,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-aa65ca0d-8c1c-4548-86c1-ee5ed3c0d10e,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-35dfd9cf-c947-41c6-ad9f-0f764a0ca060,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-b79885a4-fb20-4e5f-abcc-cef265d841fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-639a88e4-8a1e-498f-8864-e0dfb6d41e21,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-882ee1f8-0f8d-47de-96d4-dbd6cb5acc84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-251275137-172.17.0.3-1597351492510:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45642,DS-b5d12ad8-7998-4626-999e-d09552320740,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-29bd2617-16f7-4605-b76a-6d52b84e9475,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-04ef53a4-73c9-4f0f-9248-ccfac7b18372,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-707fa517-d99d-44b7-b829-973fea752dff,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-9ab63d44-47c0-40ec-b2b9-26ea9548071d,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-cfce9e79-8042-432d-9929-0a670c084f08,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-3c6cc202-4b06-43d3-9c90-2feb396cb394,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-16486b4a-61e8-43e2-a435-00fb0fd56e1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-251275137-172.17.0.3-1597351492510:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45642,DS-b5d12ad8-7998-4626-999e-d09552320740,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-29bd2617-16f7-4605-b76a-6d52b84e9475,DISK], DatanodeInfoWithStorage[127.0.0.1:38200,DS-04ef53a4-73c9-4f0f-9248-ccfac7b18372,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-707fa517-d99d-44b7-b829-973fea752dff,DISK], DatanodeInfoWithStorage[127.0.0.1:42150,DS-9ab63d44-47c0-40ec-b2b9-26ea9548071d,DISK], DatanodeInfoWithStorage[127.0.0.1:43772,DS-cfce9e79-8042-432d-9929-0a670c084f08,DISK], DatanodeInfoWithStorage[127.0.0.1:38412,DS-3c6cc202-4b06-43d3-9c90-2feb396cb394,DISK], DatanodeInfoWithStorage[127.0.0.1:42999,DS-16486b4a-61e8-43e2-a435-00fb0fd56e1e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1797789440-172.17.0.3-1597351532803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40180,DS-790f9a82-1dd1-4890-b39e-555c35076cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-595d2e87-837d-42b3-b005-073410cf551b,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-da63e68e-2ea5-4702-ac1c-a60c49cdcf07,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-697ac4ac-fcdd-4c4a-a04d-77609178140b,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-2dc5276f-2bf6-4f11-8634-1d387efe94b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-57f35ea9-ad73-4002-b144-0cb3bfb25e94,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-c8947309-dc5c-42c2-9d29-af05289e62c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-d3669dca-458b-40b4-b53f-6b443796f1c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1797789440-172.17.0.3-1597351532803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40180,DS-790f9a82-1dd1-4890-b39e-555c35076cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:39491,DS-595d2e87-837d-42b3-b005-073410cf551b,DISK], DatanodeInfoWithStorage[127.0.0.1:45718,DS-da63e68e-2ea5-4702-ac1c-a60c49cdcf07,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-697ac4ac-fcdd-4c4a-a04d-77609178140b,DISK], DatanodeInfoWithStorage[127.0.0.1:45038,DS-2dc5276f-2bf6-4f11-8634-1d387efe94b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-57f35ea9-ad73-4002-b144-0cb3bfb25e94,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-c8947309-dc5c-42c2-9d29-af05289e62c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45598,DS-d3669dca-458b-40b4-b53f-6b443796f1c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-502879712-172.17.0.3-1597352651248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39758,DS-10ea93cf-25cd-4bf5-aaaa-d9528a609bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-28dd3758-ca19-46ca-b59d-1a16abba5bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-74fd2112-70c6-4879-bc09-4fc3adde264a,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-ae324897-4ff4-4b4e-9556-a8601b6f4f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-c9df4a44-97ea-4a47-a6c4-d9b5d7b126a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-974671aa-f36a-4a14-80c2-fcbee07bb070,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-247ad1ab-4a6b-4e70-826b-e6f21bc17f56,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-036ab75f-db47-40b8-add5-67919087f356,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-502879712-172.17.0.3-1597352651248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39758,DS-10ea93cf-25cd-4bf5-aaaa-d9528a609bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-28dd3758-ca19-46ca-b59d-1a16abba5bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-74fd2112-70c6-4879-bc09-4fc3adde264a,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-ae324897-4ff4-4b4e-9556-a8601b6f4f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:34090,DS-c9df4a44-97ea-4a47-a6c4-d9b5d7b126a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-974671aa-f36a-4a14-80c2-fcbee07bb070,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-247ad1ab-4a6b-4e70-826b-e6f21bc17f56,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-036ab75f-db47-40b8-add5-67919087f356,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-728480903-172.17.0.3-1597352827669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46638,DS-aa15913b-bc19-4da2-bd21-5df245255e13,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-8cdef1b9-39f0-4221-aa58-fbf4a9587321,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-a85e8f86-bb29-4851-8951-0301e65996e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-1bf78576-8801-4335-8f8e-f648a2b1b15a,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-b6baf193-67a2-4ed8-9e27-1de3fb2362ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-58a871bb-983a-49a8-9c93-97cb91544aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-828358e0-41dd-4d5c-8a13-712436d2c069,DISK], DatanodeInfoWithStorage[127.0.0.1:41974,DS-97983d3e-495c-4e2e-b697-7494b58ddae4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-728480903-172.17.0.3-1597352827669:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46638,DS-aa15913b-bc19-4da2-bd21-5df245255e13,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-8cdef1b9-39f0-4221-aa58-fbf4a9587321,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-a85e8f86-bb29-4851-8951-0301e65996e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-1bf78576-8801-4335-8f8e-f648a2b1b15a,DISK], DatanodeInfoWithStorage[127.0.0.1:36907,DS-b6baf193-67a2-4ed8-9e27-1de3fb2362ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-58a871bb-983a-49a8-9c93-97cb91544aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-828358e0-41dd-4d5c-8a13-712436d2c069,DISK], DatanodeInfoWithStorage[127.0.0.1:41974,DS-97983d3e-495c-4e2e-b697-7494b58ddae4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2016982610-172.17.0.3-1597352902185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43144,DS-4512b646-59ae-4de3-96d3-0b7dbfda5537,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-d1e634bd-bb6f-4c1e-8103-e1ef32007aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-d25f0f54-d076-4b05-8800-39a85597d789,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-79e56aab-05d0-4d0b-89c3-aa4ecdce2a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-637297a4-addf-4d04-9d09-42b9d029c443,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-46905348-f4a1-42e0-864a-2197ccd31d41,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-d24db3a6-a977-4537-87a9-0f0c55acdbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-260ff409-338b-47dd-bd31-7c7fd3b2ed25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2016982610-172.17.0.3-1597352902185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43144,DS-4512b646-59ae-4de3-96d3-0b7dbfda5537,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-d1e634bd-bb6f-4c1e-8103-e1ef32007aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-d25f0f54-d076-4b05-8800-39a85597d789,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-79e56aab-05d0-4d0b-89c3-aa4ecdce2a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-637297a4-addf-4d04-9d09-42b9d029c443,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-46905348-f4a1-42e0-864a-2197ccd31d41,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-d24db3a6-a977-4537-87a9-0f0c55acdbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-260ff409-338b-47dd-bd31-7c7fd3b2ed25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1480189994-172.17.0.3-1597353189943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42657,DS-290d091b-563c-4e4c-b182-c0d4450e4695,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-83b8511a-a262-475b-8c13-dac0e17ebd29,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-1680c948-b2c0-403c-9d46-0137bcc85ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-de5559a8-4e22-4773-8e46-50f11ed443df,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-a4ec04a6-b697-4d14-aca6-50b15627ca8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-84ca8f16-fb29-439b-9c4c-691d48ad09da,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-9297b5dc-f67c-45be-883a-14f44be4a86e,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-56d7cca9-f70a-4218-bd6b-48cebbe69249,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1480189994-172.17.0.3-1597353189943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42657,DS-290d091b-563c-4e4c-b182-c0d4450e4695,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-83b8511a-a262-475b-8c13-dac0e17ebd29,DISK], DatanodeInfoWithStorage[127.0.0.1:40557,DS-1680c948-b2c0-403c-9d46-0137bcc85ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-de5559a8-4e22-4773-8e46-50f11ed443df,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-a4ec04a6-b697-4d14-aca6-50b15627ca8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-84ca8f16-fb29-439b-9c4c-691d48ad09da,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-9297b5dc-f67c-45be-883a-14f44be4a86e,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-56d7cca9-f70a-4218-bd6b-48cebbe69249,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1505764825-172.17.0.3-1597353255670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42680,DS-e9a8b0ec-3fe0-4c08-b0c9-43998cbafae4,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-90139be0-4cff-4620-a557-10f2834ebab6,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-8ee8a61d-b324-4b63-afae-71c644c91be2,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-10e26e01-497e-4356-ad3a-10d6f555c0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-d3a028f0-2242-4bf4-80ee-da7831785937,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-eb2fdd3f-30ee-44ce-a930-8794c276d5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-e7cb3df6-d132-49fe-8aae-1d4b0c3810d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-60e2aeb7-8deb-49df-83c0-934e17792aa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1505764825-172.17.0.3-1597353255670:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42680,DS-e9a8b0ec-3fe0-4c08-b0c9-43998cbafae4,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-90139be0-4cff-4620-a557-10f2834ebab6,DISK], DatanodeInfoWithStorage[127.0.0.1:45614,DS-8ee8a61d-b324-4b63-afae-71c644c91be2,DISK], DatanodeInfoWithStorage[127.0.0.1:39657,DS-10e26e01-497e-4356-ad3a-10d6f555c0c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-d3a028f0-2242-4bf4-80ee-da7831785937,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-eb2fdd3f-30ee-44ce-a930-8794c276d5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-e7cb3df6-d132-49fe-8aae-1d4b0c3810d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-60e2aeb7-8deb-49df-83c0-934e17792aa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1944004267-172.17.0.3-1597353461401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41695,DS-9327fe4c-e7bb-4017-bea0-32e22eb0d10f,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-6032befa-4ca8-4144-a426-fa1e609e1e43,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-33de72c8-b030-494d-8653-572762a0d590,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-89c7d0c0-7d2c-4210-bc32-b0e608d9cc53,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-bf57fda5-ecba-40f8-81d9-7687fadb550a,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-16abd8f6-ae60-462f-babc-02c7dfac956b,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-a41e81d9-9922-44cd-b717-c70d20cb68c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-21d3e61a-892f-4086-a883-2d9d77c66df6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1944004267-172.17.0.3-1597353461401:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41695,DS-9327fe4c-e7bb-4017-bea0-32e22eb0d10f,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-6032befa-4ca8-4144-a426-fa1e609e1e43,DISK], DatanodeInfoWithStorage[127.0.0.1:32839,DS-33de72c8-b030-494d-8653-572762a0d590,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-89c7d0c0-7d2c-4210-bc32-b0e608d9cc53,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-bf57fda5-ecba-40f8-81d9-7687fadb550a,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-16abd8f6-ae60-462f-babc-02c7dfac956b,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-a41e81d9-9922-44cd-b717-c70d20cb68c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-21d3e61a-892f-4086-a883-2d9d77c66df6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-736268940-172.17.0.3-1597353541361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38785,DS-4af4096f-9048-4c68-a4d0-31e9157470d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-b962947b-b8cc-41ca-b380-14b9d8d6ba2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-c62fca64-6395-4afa-9890-3c883e6285a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-0dfa46b7-c51a-4584-abb7-32e09e63efc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-edcd54b0-1218-4cdf-afbd-4ff3f3181456,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-f182676f-860d-4db7-a3d1-71983ae5afb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-f86b19cb-9265-4695-bd96-dcf8c2d20e68,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-c8dd0d75-4f4f-4c7d-bf6c-788fa2aed508,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-736268940-172.17.0.3-1597353541361:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38785,DS-4af4096f-9048-4c68-a4d0-31e9157470d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-b962947b-b8cc-41ca-b380-14b9d8d6ba2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42325,DS-c62fca64-6395-4afa-9890-3c883e6285a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-0dfa46b7-c51a-4584-abb7-32e09e63efc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-edcd54b0-1218-4cdf-afbd-4ff3f3181456,DISK], DatanodeInfoWithStorage[127.0.0.1:34998,DS-f182676f-860d-4db7-a3d1-71983ae5afb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-f86b19cb-9265-4695-bd96-dcf8c2d20e68,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-c8dd0d75-4f4f-4c7d-bf6c-788fa2aed508,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-281861121-172.17.0.3-1597354029544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46293,DS-923e3e23-1741-47bb-b730-9c829d3f0216,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-fc95584a-cf08-4ce2-b6fa-0474d72ea73c,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-5a6c161e-502d-4d9b-b9da-fa7f98234427,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-357223b1-dd37-4fe3-8ef1-653ad9080623,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-4b928722-aff8-41b9-8e29-3a650f876d72,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-5124e9cb-5044-4cf7-b2d7-153202b84d83,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-23e20335-664e-48c4-8c2d-a02d3ea857d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-c62094bf-7ae7-4957-8c1d-5c9db34d2bcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-281861121-172.17.0.3-1597354029544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46293,DS-923e3e23-1741-47bb-b730-9c829d3f0216,DISK], DatanodeInfoWithStorage[127.0.0.1:39464,DS-fc95584a-cf08-4ce2-b6fa-0474d72ea73c,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-5a6c161e-502d-4d9b-b9da-fa7f98234427,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-357223b1-dd37-4fe3-8ef1-653ad9080623,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-4b928722-aff8-41b9-8e29-3a650f876d72,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-5124e9cb-5044-4cf7-b2d7-153202b84d83,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-23e20335-664e-48c4-8c2d-a02d3ea857d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-c62094bf-7ae7-4957-8c1d-5c9db34d2bcd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1677132510-172.17.0.3-1597354067441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34289,DS-cc2d5d14-9163-4bd1-aca9-8630ded65bde,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-ed9f7b96-7b72-43fa-9b57-73283f582203,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-0b9131d3-c4ed-42a2-94eb-89b4519377a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-d057ef05-dd2e-4601-ab29-a77b4dadc414,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-41ecb1c4-b003-4cb1-aa3f-6217abbab45f,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-83ab7f6e-9ead-4cec-bb39-b7887be1d480,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-6f63680d-5df6-4585-a161-dc40124377be,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-f24d014e-3e4e-4bcf-a283-6dad4e476686,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1677132510-172.17.0.3-1597354067441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34289,DS-cc2d5d14-9163-4bd1-aca9-8630ded65bde,DISK], DatanodeInfoWithStorage[127.0.0.1:42264,DS-ed9f7b96-7b72-43fa-9b57-73283f582203,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-0b9131d3-c4ed-42a2-94eb-89b4519377a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-d057ef05-dd2e-4601-ab29-a77b4dadc414,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-41ecb1c4-b003-4cb1-aa3f-6217abbab45f,DISK], DatanodeInfoWithStorage[127.0.0.1:42539,DS-83ab7f6e-9ead-4cec-bb39-b7887be1d480,DISK], DatanodeInfoWithStorage[127.0.0.1:44504,DS-6f63680d-5df6-4585-a161-dc40124377be,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-f24d014e-3e4e-4bcf-a283-6dad4e476686,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2079713536-172.17.0.3-1597354277737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40220,DS-f5585456-3e1a-4e4e-87f6-63970cf26019,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-668b0210-bf33-4c2b-8969-55e6921f0ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-0852caed-7f29-4af2-8843-74360df36720,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-1dd71c09-cc4d-44de-9569-27466d5d9091,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-12a7e8e9-63bf-4b9e-856d-9274e97ffc93,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-c843cdcc-7a2c-420e-b4e9-e7941cf9ef7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-d8b01883-3cf7-4ee0-9c78-caca8dadd2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-a8a66788-1b17-4128-839e-1285d22f21c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2079713536-172.17.0.3-1597354277737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40220,DS-f5585456-3e1a-4e4e-87f6-63970cf26019,DISK], DatanodeInfoWithStorage[127.0.0.1:35727,DS-668b0210-bf33-4c2b-8969-55e6921f0ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:33787,DS-0852caed-7f29-4af2-8843-74360df36720,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-1dd71c09-cc4d-44de-9569-27466d5d9091,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-12a7e8e9-63bf-4b9e-856d-9274e97ffc93,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-c843cdcc-7a2c-420e-b4e9-e7941cf9ef7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-d8b01883-3cf7-4ee0-9c78-caca8dadd2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-a8a66788-1b17-4128-839e-1285d22f21c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-795199368-172.17.0.3-1597354483678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39765,DS-922dbb70-91dc-4269-a22b-240e1716f323,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-f33970a5-fcb8-42ca-af01-24f31b8600df,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-c451e6a1-e470-4df8-8c5e-3139d2ba9d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-18ef0df5-b6ea-484a-9402-608a82f7cd41,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-398a5f35-331a-4cd5-ae4d-0fcace096e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-0e3da97e-4de0-4bcf-985f-bff03675c646,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-02c986ba-1793-47c6-ac5b-dda372e6d5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-195e4b62-a5ff-4a57-bc3e-d093dc6de197,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-795199368-172.17.0.3-1597354483678:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39765,DS-922dbb70-91dc-4269-a22b-240e1716f323,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-f33970a5-fcb8-42ca-af01-24f31b8600df,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-c451e6a1-e470-4df8-8c5e-3139d2ba9d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-18ef0df5-b6ea-484a-9402-608a82f7cd41,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-398a5f35-331a-4cd5-ae4d-0fcace096e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-0e3da97e-4de0-4bcf-985f-bff03675c646,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-02c986ba-1793-47c6-ac5b-dda372e6d5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35136,DS-195e4b62-a5ff-4a57-bc3e-d093dc6de197,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-817925661-172.17.0.3-1597354621919:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44401,DS-999d2542-be0b-4b96-9a53-e4c3da33cc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-1ac18ad8-70f8-41a6-b515-b85d9aa9e080,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-5dbae7f4-7dc7-487c-9b54-c9895d6a0010,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-96e9e47d-0caf-4cb3-8d2a-b3db3f119fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-313686b3-c7f4-4dbd-8a98-b221b41688f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-55d7ad1f-a596-4780-8684-0f20215786dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-36d0448a-d2cb-4913-9e5f-2c0c32c16318,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-2b79f13f-b032-4f17-bf73-fda0b5288993,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-817925661-172.17.0.3-1597354621919:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44401,DS-999d2542-be0b-4b96-9a53-e4c3da33cc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-1ac18ad8-70f8-41a6-b515-b85d9aa9e080,DISK], DatanodeInfoWithStorage[127.0.0.1:40144,DS-5dbae7f4-7dc7-487c-9b54-c9895d6a0010,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-96e9e47d-0caf-4cb3-8d2a-b3db3f119fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-313686b3-c7f4-4dbd-8a98-b221b41688f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-55d7ad1f-a596-4780-8684-0f20215786dc,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-36d0448a-d2cb-4913-9e5f-2c0c32c16318,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-2b79f13f-b032-4f17-bf73-fda0b5288993,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1251819158-172.17.0.3-1597354661530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32789,DS-da743eb6-b844-436d-9f56-bb7bfe7b176c,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-90e1ddc2-05d0-45a6-9d8b-d1c0afd4e0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-d1c85bd9-d7d1-477a-959f-5bb5814a992d,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-2e8a5b26-d350-4bd0-ab0c-3ca935eae143,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-747e81cf-6e5a-4f97-879f-bca4aa4edadf,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-28a9d218-2ec6-4b17-a640-39f10fef5e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-c78790ab-900e-4608-bbbb-74ecde147628,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-63779b61-4cc3-4ad4-97cb-6d193f0393ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1251819158-172.17.0.3-1597354661530:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32789,DS-da743eb6-b844-436d-9f56-bb7bfe7b176c,DISK], DatanodeInfoWithStorage[127.0.0.1:45803,DS-90e1ddc2-05d0-45a6-9d8b-d1c0afd4e0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-d1c85bd9-d7d1-477a-959f-5bb5814a992d,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-2e8a5b26-d350-4bd0-ab0c-3ca935eae143,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-747e81cf-6e5a-4f97-879f-bca4aa4edadf,DISK], DatanodeInfoWithStorage[127.0.0.1:42755,DS-28a9d218-2ec6-4b17-a640-39f10fef5e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-c78790ab-900e-4608-bbbb-74ecde147628,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-63779b61-4cc3-4ad4-97cb-6d193f0393ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-571728047-172.17.0.3-1597355234681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42344,DS-dff2173e-8827-436b-b5a2-44e3f5877d12,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-2163fa4a-5cd7-4ee1-82af-01a2cdd522de,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-57ed76a2-cc04-4507-94b3-dd28b983ecc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-d8ad1533-db88-40a7-8e5e-3bd228229860,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-93271151-5db3-4808-bbe0-162b2bb16dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-4d63bafe-784e-4e13-96cd-797bb98b8cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-71fa3c5f-b70c-446d-ab5d-77413932931a,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-b58db16b-2589-418b-ad4c-b913b3f24007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-571728047-172.17.0.3-1597355234681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42344,DS-dff2173e-8827-436b-b5a2-44e3f5877d12,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-2163fa4a-5cd7-4ee1-82af-01a2cdd522de,DISK], DatanodeInfoWithStorage[127.0.0.1:36845,DS-57ed76a2-cc04-4507-94b3-dd28b983ecc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-d8ad1533-db88-40a7-8e5e-3bd228229860,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-93271151-5db3-4808-bbe0-162b2bb16dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-4d63bafe-784e-4e13-96cd-797bb98b8cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-71fa3c5f-b70c-446d-ab5d-77413932931a,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-b58db16b-2589-418b-ad4c-b913b3f24007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1917853360-172.17.0.3-1597355674532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39269,DS-12060c15-6e22-4ed6-93bb-60e23b6e14fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-7abb29d8-fffb-43fc-a223-86dffe89ae8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-e07fdf77-0fe5-4339-9a6b-a048ceb78f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-bad60dab-fd45-4ca0-a732-0c5d8f9b3069,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-6bd6a369-d453-42ca-87c0-31f85c7589f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-31bfb13f-ccc5-44a5-b2d7-13b78536d491,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-e39cc64b-8a3b-4f86-827c-3644b9e5faee,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-370e9e00-224d-4de0-b36f-f066711aab79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1917853360-172.17.0.3-1597355674532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39269,DS-12060c15-6e22-4ed6-93bb-60e23b6e14fd,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-7abb29d8-fffb-43fc-a223-86dffe89ae8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37600,DS-e07fdf77-0fe5-4339-9a6b-a048ceb78f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-bad60dab-fd45-4ca0-a732-0c5d8f9b3069,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-6bd6a369-d453-42ca-87c0-31f85c7589f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42972,DS-31bfb13f-ccc5-44a5-b2d7-13b78536d491,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-e39cc64b-8a3b-4f86-827c-3644b9e5faee,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-370e9e00-224d-4de0-b36f-f066711aab79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1064815612-172.17.0.3-1597355814484:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32774,DS-c5d0b0f4-0fee-4a89-90b3-816bc3a7d2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-3ba4897a-86d1-48cb-aff6-abdb0966b18c,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-26425b1b-7788-4b25-a2ae-f319453ba535,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-c26ca8c1-875e-479a-86b7-4fdd75f9c539,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-19a8c250-05b7-469d-a905-a206b4d3cd81,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-af649096-7158-41b9-bcf4-77de2b0d3df7,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-3f35f237-2d29-446f-b48e-f3c89c8651e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-d0131644-d585-44bb-b4b5-3c97068d2b7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1064815612-172.17.0.3-1597355814484:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32774,DS-c5d0b0f4-0fee-4a89-90b3-816bc3a7d2f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-3ba4897a-86d1-48cb-aff6-abdb0966b18c,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-26425b1b-7788-4b25-a2ae-f319453ba535,DISK], DatanodeInfoWithStorage[127.0.0.1:45799,DS-c26ca8c1-875e-479a-86b7-4fdd75f9c539,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-19a8c250-05b7-469d-a905-a206b4d3cd81,DISK], DatanodeInfoWithStorage[127.0.0.1:36260,DS-af649096-7158-41b9-bcf4-77de2b0d3df7,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-3f35f237-2d29-446f-b48e-f3c89c8651e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-d0131644-d585-44bb-b4b5-3c97068d2b7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5386
