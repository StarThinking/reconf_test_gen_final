reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1923259306-172.17.0.14-1597304729350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38799,DS-cad44e5d-48e1-4005-a134-e808b371ccb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-a2708cf4-4e35-4a90-b5eb-5068d526b3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-73a714ec-f832-423e-961c-770e20c3a432,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-475bf623-2100-4315-9809-e974e520cfde,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-8136fb0f-d173-430c-aa93-3745834a778a,DISK], DatanodeInfoWithStorage[127.0.0.1:37304,DS-689fe1a7-0974-45dd-8bda-99b4792a5a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-25721ea6-07ec-4379-881d-d762fffdb391,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-58fe3193-6fb7-4b4e-a1f3-a8ec4f93711c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1923259306-172.17.0.14-1597304729350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38799,DS-cad44e5d-48e1-4005-a134-e808b371ccb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-a2708cf4-4e35-4a90-b5eb-5068d526b3ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46286,DS-73a714ec-f832-423e-961c-770e20c3a432,DISK], DatanodeInfoWithStorage[127.0.0.1:45374,DS-475bf623-2100-4315-9809-e974e520cfde,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-8136fb0f-d173-430c-aa93-3745834a778a,DISK], DatanodeInfoWithStorage[127.0.0.1:37304,DS-689fe1a7-0974-45dd-8bda-99b4792a5a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-25721ea6-07ec-4379-881d-d762fffdb391,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-58fe3193-6fb7-4b4e-a1f3-a8ec4f93711c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2041344030-172.17.0.14-1597304812158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37591,DS-d4c0361e-29e9-4866-89a4-ff2011d218f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-09200f4e-e1df-4951-a821-9715ccff51d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-4614a377-fa6a-49f6-bce6-0511619e6163,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-a831ac9b-1dfb-4af8-a03f-6dcdb7a50a43,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-b5a8930a-76e2-43f9-b918-645b1b7d3fff,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-fd887f49-c125-4821-8411-4050448afd48,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-5f06062d-62cf-48a2-b6e8-0719888bfa46,DISK], DatanodeInfoWithStorage[127.0.0.1:38851,DS-dea5a6f6-ea66-4ce9-a2bc-f07863441f3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2041344030-172.17.0.14-1597304812158:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37591,DS-d4c0361e-29e9-4866-89a4-ff2011d218f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-09200f4e-e1df-4951-a821-9715ccff51d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45404,DS-4614a377-fa6a-49f6-bce6-0511619e6163,DISK], DatanodeInfoWithStorage[127.0.0.1:46294,DS-a831ac9b-1dfb-4af8-a03f-6dcdb7a50a43,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-b5a8930a-76e2-43f9-b918-645b1b7d3fff,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-fd887f49-c125-4821-8411-4050448afd48,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-5f06062d-62cf-48a2-b6e8-0719888bfa46,DISK], DatanodeInfoWithStorage[127.0.0.1:38851,DS-dea5a6f6-ea66-4ce9-a2bc-f07863441f3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096283386-172.17.0.14-1597305324977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35144,DS-5ac94f7a-c500-4a19-a57c-9c79ea91b0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-eb4966d4-e1b0-4d69-af34-b2a69f80e8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-3996ec61-141b-4af4-9a68-03499f7ea356,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-cb589bbf-a8c8-47e7-a0d5-105825016600,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-accd9c74-1eee-4cc2-8992-8f900e2df566,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-4d4226e9-521f-4604-a53f-ce86aa028f17,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-7dc385b9-8fd6-4d99-abf0-6b259594add2,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-1949b27e-e57a-4e88-a066-59a8a8d7ebbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096283386-172.17.0.14-1597305324977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35144,DS-5ac94f7a-c500-4a19-a57c-9c79ea91b0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-eb4966d4-e1b0-4d69-af34-b2a69f80e8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-3996ec61-141b-4af4-9a68-03499f7ea356,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-cb589bbf-a8c8-47e7-a0d5-105825016600,DISK], DatanodeInfoWithStorage[127.0.0.1:43042,DS-accd9c74-1eee-4cc2-8992-8f900e2df566,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-4d4226e9-521f-4604-a53f-ce86aa028f17,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-7dc385b9-8fd6-4d99-abf0-6b259594add2,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-1949b27e-e57a-4e88-a066-59a8a8d7ebbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1137523382-172.17.0.14-1597305407283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42125,DS-824c294d-524c-449f-b749-9e999655a9db,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-17bdfe3a-a453-4f71-8979-a888d8566440,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-52125042-155e-4046-936e-0a984e196f34,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-f551b8c1-cf37-4b77-a742-ee63cbf6de60,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-fc9ae9ee-b2d1-42b5-a0e0-d9d8c915ebeb,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-76ee6830-85db-4767-8f41-64feb8e4cfad,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-3051164e-ba06-4593-828c-48a3e146e1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-6b76e269-8055-4e78-bbad-5e2809d5e606,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1137523382-172.17.0.14-1597305407283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42125,DS-824c294d-524c-449f-b749-9e999655a9db,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-17bdfe3a-a453-4f71-8979-a888d8566440,DISK], DatanodeInfoWithStorage[127.0.0.1:37420,DS-52125042-155e-4046-936e-0a984e196f34,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-f551b8c1-cf37-4b77-a742-ee63cbf6de60,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-fc9ae9ee-b2d1-42b5-a0e0-d9d8c915ebeb,DISK], DatanodeInfoWithStorage[127.0.0.1:42732,DS-76ee6830-85db-4767-8f41-64feb8e4cfad,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-3051164e-ba06-4593-828c-48a3e146e1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-6b76e269-8055-4e78-bbad-5e2809d5e606,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-175503428-172.17.0.14-1597305803357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38237,DS-78dc23f5-a6f7-4338-a738-b07079878044,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-99175a6d-9a9c-4ecc-a1df-dc9d8230d451,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-2f60829b-86fb-411e-a245-545e48f84283,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-3c462d8a-a8b2-42a3-8cd4-ebf32c21049f,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-dba0e71d-bcf0-4c73-8046-393efcc6a1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-c8ccad44-3b6a-42e2-a717-ee579db9705f,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-02dfac6b-7594-491c-8dd5-acc079943ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-c5659317-4128-4db6-9630-21322eb92d2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-175503428-172.17.0.14-1597305803357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38237,DS-78dc23f5-a6f7-4338-a738-b07079878044,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-99175a6d-9a9c-4ecc-a1df-dc9d8230d451,DISK], DatanodeInfoWithStorage[127.0.0.1:39424,DS-2f60829b-86fb-411e-a245-545e48f84283,DISK], DatanodeInfoWithStorage[127.0.0.1:40348,DS-3c462d8a-a8b2-42a3-8cd4-ebf32c21049f,DISK], DatanodeInfoWithStorage[127.0.0.1:42493,DS-dba0e71d-bcf0-4c73-8046-393efcc6a1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45955,DS-c8ccad44-3b6a-42e2-a717-ee579db9705f,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-02dfac6b-7594-491c-8dd5-acc079943ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-c5659317-4128-4db6-9630-21322eb92d2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1614523633-172.17.0.14-1597306039858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38509,DS-56245702-8946-4f33-bdf3-41f0426d663a,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-b37ed2a7-8534-4077-920a-78cabcfbd0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-e31c4424-a3a3-455c-9544-5b522cdbb625,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-ceeababa-9f39-4106-ba28-24ad0952a077,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-684ffb17-00c8-4f7f-bd34-07c57997dcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-b3372645-e9ef-4656-99cf-901a935e5787,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-b7899067-3aae-4c17-9ac4-414210410e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-1390b220-c15a-47fc-b30b-1f6fda62d056,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1614523633-172.17.0.14-1597306039858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38509,DS-56245702-8946-4f33-bdf3-41f0426d663a,DISK], DatanodeInfoWithStorage[127.0.0.1:33881,DS-b37ed2a7-8534-4077-920a-78cabcfbd0ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-e31c4424-a3a3-455c-9544-5b522cdbb625,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-ceeababa-9f39-4106-ba28-24ad0952a077,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-684ffb17-00c8-4f7f-bd34-07c57997dcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-b3372645-e9ef-4656-99cf-901a935e5787,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-b7899067-3aae-4c17-9ac4-414210410e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-1390b220-c15a-47fc-b30b-1f6fda62d056,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-653628475-172.17.0.14-1597306519845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40986,DS-99baae90-a08c-4286-9f63-95b85977db41,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-d5dac172-74ef-4b8e-8339-cc98b96af95d,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-6f8fe042-5a83-4c35-aacc-d6c8677e6e54,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-cf3f7aa8-5ec1-43d1-a763-e0cfb4519262,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-bc90acb9-baf8-498a-b395-6fe26f892e33,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-4d574ce5-5497-4b1b-8347-477a5bda490d,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-10b108de-32b8-4843-bac9-fcb4fd861b98,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-5073100e-c310-4e4c-8d46-ea10ab9c1095,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-653628475-172.17.0.14-1597306519845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40986,DS-99baae90-a08c-4286-9f63-95b85977db41,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-d5dac172-74ef-4b8e-8339-cc98b96af95d,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-6f8fe042-5a83-4c35-aacc-d6c8677e6e54,DISK], DatanodeInfoWithStorage[127.0.0.1:33586,DS-cf3f7aa8-5ec1-43d1-a763-e0cfb4519262,DISK], DatanodeInfoWithStorage[127.0.0.1:40167,DS-bc90acb9-baf8-498a-b395-6fe26f892e33,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-4d574ce5-5497-4b1b-8347-477a5bda490d,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-10b108de-32b8-4843-bac9-fcb4fd861b98,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-5073100e-c310-4e4c-8d46-ea10ab9c1095,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1744989301-172.17.0.14-1597306923522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45877,DS-61442efb-5697-44b6-b0eb-1c9adcdc88f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-9bd9e787-8dc4-465e-9858-c4cca09426a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-156a0367-995d-4f80-bd4c-0f1ca33386e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-4ea5cbf2-a6d3-4f64-a34e-0bbf72673a78,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-3320a008-d077-4ceb-8754-61cd0531a853,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-5589f478-b734-4b29-800b-02cc252f54d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-9734f77e-e51b-42ac-8df9-c2083173b244,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-92451bfe-16ab-4659-8336-c2475eb42aff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1744989301-172.17.0.14-1597306923522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45877,DS-61442efb-5697-44b6-b0eb-1c9adcdc88f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-9bd9e787-8dc4-465e-9858-c4cca09426a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-156a0367-995d-4f80-bd4c-0f1ca33386e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-4ea5cbf2-a6d3-4f64-a34e-0bbf72673a78,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-3320a008-d077-4ceb-8754-61cd0531a853,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-5589f478-b734-4b29-800b-02cc252f54d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-9734f77e-e51b-42ac-8df9-c2083173b244,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-92451bfe-16ab-4659-8336-c2475eb42aff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-785871069-172.17.0.14-1597307085197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40152,DS-c9b34209-98c5-42b1-ac64-975b5aeb4ece,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-8dbc3846-271d-4151-bc69-74599c574787,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-1de69980-8bde-485c-8b75-234cb5978648,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-f93f745c-15d1-43d5-b845-94c8f9f0181f,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-d9eca802-3e36-496e-a8bf-91147da24d56,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-2d40162b-8a89-44db-99a9-9d21151fb568,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-1d325bac-bce5-41fe-a8ab-d7a0eecedcec,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-0131390d-46d1-4a09-b091-ad672c68fb08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-785871069-172.17.0.14-1597307085197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40152,DS-c9b34209-98c5-42b1-ac64-975b5aeb4ece,DISK], DatanodeInfoWithStorage[127.0.0.1:34566,DS-8dbc3846-271d-4151-bc69-74599c574787,DISK], DatanodeInfoWithStorage[127.0.0.1:40153,DS-1de69980-8bde-485c-8b75-234cb5978648,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-f93f745c-15d1-43d5-b845-94c8f9f0181f,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-d9eca802-3e36-496e-a8bf-91147da24d56,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-2d40162b-8a89-44db-99a9-9d21151fb568,DISK], DatanodeInfoWithStorage[127.0.0.1:33972,DS-1d325bac-bce5-41fe-a8ab-d7a0eecedcec,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-0131390d-46d1-4a09-b091-ad672c68fb08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1710249240-172.17.0.14-1597307469217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35710,DS-95f7947a-0ee4-4341-9ec2-bea05e5a6b67,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-5d098277-07fc-49b0-a6d5-48581a162062,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-ba16f525-2303-4445-bcfa-9ea77f6df7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-454fbd41-f98d-40b9-a376-e59c0b506e16,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-0ba437de-4f8f-421c-9375-332dbff0d524,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-4533d4e6-7c8a-41ff-bb3a-05a0a3e31628,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-55a9b153-88ec-4ae0-abf3-50928a453af6,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-4b64cf3c-1758-4069-a80f-1c089aacbee0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1710249240-172.17.0.14-1597307469217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35710,DS-95f7947a-0ee4-4341-9ec2-bea05e5a6b67,DISK], DatanodeInfoWithStorage[127.0.0.1:38628,DS-5d098277-07fc-49b0-a6d5-48581a162062,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-ba16f525-2303-4445-bcfa-9ea77f6df7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-454fbd41-f98d-40b9-a376-e59c0b506e16,DISK], DatanodeInfoWithStorage[127.0.0.1:45970,DS-0ba437de-4f8f-421c-9375-332dbff0d524,DISK], DatanodeInfoWithStorage[127.0.0.1:40082,DS-4533d4e6-7c8a-41ff-bb3a-05a0a3e31628,DISK], DatanodeInfoWithStorage[127.0.0.1:39240,DS-55a9b153-88ec-4ae0-abf3-50928a453af6,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-4b64cf3c-1758-4069-a80f-1c089aacbee0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1311781405-172.17.0.14-1597307509510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43759,DS-45782ac2-ed6c-4c62-92fe-fa276df595bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-44ebc97e-6719-44fc-8a34-8436bc9a1a70,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-c2db8b44-14e2-4407-918d-6a69df13ff82,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-e710c7b3-e2d0-4210-8a95-161819a8017d,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-53150685-8105-492b-a3c4-894d2ef99d26,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-f9d7807d-9446-40bf-a03b-25c2cf81de66,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-6a7e1416-dcae-4078-b8d7-018493abd79e,DISK], DatanodeInfoWithStorage[127.0.0.1:45528,DS-62ede7d1-0844-4617-8ca3-10fb906942df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1311781405-172.17.0.14-1597307509510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43759,DS-45782ac2-ed6c-4c62-92fe-fa276df595bb,DISK], DatanodeInfoWithStorage[127.0.0.1:38433,DS-44ebc97e-6719-44fc-8a34-8436bc9a1a70,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-c2db8b44-14e2-4407-918d-6a69df13ff82,DISK], DatanodeInfoWithStorage[127.0.0.1:44693,DS-e710c7b3-e2d0-4210-8a95-161819a8017d,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-53150685-8105-492b-a3c4-894d2ef99d26,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-f9d7807d-9446-40bf-a03b-25c2cf81de66,DISK], DatanodeInfoWithStorage[127.0.0.1:37567,DS-6a7e1416-dcae-4078-b8d7-018493abd79e,DISK], DatanodeInfoWithStorage[127.0.0.1:45528,DS-62ede7d1-0844-4617-8ca3-10fb906942df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-687202597-172.17.0.14-1597308134428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45572,DS-fe92c198-c2ad-4701-9f07-273be6073f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-ca25266c-8ee8-4912-8f82-935d1ddd39a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-8ad2209e-764b-4f18-873a-4924c8cf3dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-d04e90e3-f88b-420f-a2d0-c65a631866e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-5b259c0c-155a-471a-b9d4-a8ff152aece4,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-7d73aaad-c7e2-416b-bb3d-fded38c9181f,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-618e2c92-0bde-4aea-a423-10afb62b42e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-78243b5f-7454-4375-94b9-4c3c46aca51d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-687202597-172.17.0.14-1597308134428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45572,DS-fe92c198-c2ad-4701-9f07-273be6073f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37912,DS-ca25266c-8ee8-4912-8f82-935d1ddd39a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-8ad2209e-764b-4f18-873a-4924c8cf3dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-d04e90e3-f88b-420f-a2d0-c65a631866e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-5b259c0c-155a-471a-b9d4-a8ff152aece4,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-7d73aaad-c7e2-416b-bb3d-fded38c9181f,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-618e2c92-0bde-4aea-a423-10afb62b42e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-78243b5f-7454-4375-94b9-4c3c46aca51d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-32547543-172.17.0.14-1597308621639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37749,DS-72fd6639-ae58-455c-bb5b-80b4fbb409dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-8e39eae4-a86b-4d6e-8179-6a57451aa706,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-0664ad42-0351-42f3-9bea-f54d1e2a3e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-51702305-25e6-45a8-9ce5-7d1272a8b5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-1dcb505b-4c75-49d5-80af-5d1287313e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-23ed7284-dd93-4829-a555-fad293ddf1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-9ed2b33e-636b-42d1-a03c-7d581d2e7ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-c723adf5-0b66-4d3c-900d-bfbd69bef954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-32547543-172.17.0.14-1597308621639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37749,DS-72fd6639-ae58-455c-bb5b-80b4fbb409dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-8e39eae4-a86b-4d6e-8179-6a57451aa706,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-0664ad42-0351-42f3-9bea-f54d1e2a3e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-51702305-25e6-45a8-9ce5-7d1272a8b5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-1dcb505b-4c75-49d5-80af-5d1287313e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35500,DS-23ed7284-dd93-4829-a555-fad293ddf1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43541,DS-9ed2b33e-636b-42d1-a03c-7d581d2e7ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-c723adf5-0b66-4d3c-900d-bfbd69bef954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1399014728-172.17.0.14-1597308779751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42110,DS-74df4eeb-07a9-4568-a55a-cb7c70305a38,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-0c457474-f6f9-45c2-acd9-327ee53fe003,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-7f7df1cd-411c-4d5f-9433-0f2c42442f20,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-0d56a7c7-94d2-4243-bb15-f5f5344823b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44306,DS-ad79d927-ebee-473a-9372-45851e2a1cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-1428f7e1-de20-428f-83f6-35874e0922fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-0c898454-452c-46f2-962c-7bf4d5759607,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-64f77486-18cf-4d2b-93b1-4460632f4900,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1399014728-172.17.0.14-1597308779751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42110,DS-74df4eeb-07a9-4568-a55a-cb7c70305a38,DISK], DatanodeInfoWithStorage[127.0.0.1:46576,DS-0c457474-f6f9-45c2-acd9-327ee53fe003,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-7f7df1cd-411c-4d5f-9433-0f2c42442f20,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-0d56a7c7-94d2-4243-bb15-f5f5344823b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44306,DS-ad79d927-ebee-473a-9372-45851e2a1cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-1428f7e1-de20-428f-83f6-35874e0922fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-0c898454-452c-46f2-962c-7bf4d5759607,DISK], DatanodeInfoWithStorage[127.0.0.1:40323,DS-64f77486-18cf-4d2b-93b1-4460632f4900,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1552021039-172.17.0.14-1597309157549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33884,DS-535e6f4d-c307-4e79-bca3-651ca68e55dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-7d9fc3ff-6b5e-4ccc-b211-ed5c774e809f,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-2a0107d4-4ba2-4dbe-a418-d8a709e2ad4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-2f384a5e-44dd-4fbc-8a96-d6faec8fcee9,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-681f6d41-7010-4842-955f-8a8ad1bebb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-f5c8283f-0ce2-4998-ae6f-c1cc7f517c86,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-c9ccc423-10de-452e-b8d6-2139568077fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-3db908d3-0d2c-4ec4-8611-2ea05c97f174,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1552021039-172.17.0.14-1597309157549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33884,DS-535e6f4d-c307-4e79-bca3-651ca68e55dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35436,DS-7d9fc3ff-6b5e-4ccc-b211-ed5c774e809f,DISK], DatanodeInfoWithStorage[127.0.0.1:44480,DS-2a0107d4-4ba2-4dbe-a418-d8a709e2ad4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38094,DS-2f384a5e-44dd-4fbc-8a96-d6faec8fcee9,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-681f6d41-7010-4842-955f-8a8ad1bebb0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33455,DS-f5c8283f-0ce2-4998-ae6f-c1cc7f517c86,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-c9ccc423-10de-452e-b8d6-2139568077fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-3db908d3-0d2c-4ec4-8611-2ea05c97f174,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2013235468-172.17.0.14-1597309430665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43810,DS-44b79885-738f-4ca0-b619-8f1b39411378,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-5db474dd-4afb-4c02-8dfb-ff4a74c92cff,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-f53046b4-633e-46ab-a7ba-6bbd6eb72611,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-02efc7a6-42e1-48e5-8092-c7f88d40eab6,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-fca93ec4-75a3-49f1-a3a3-a8030ddc5cce,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-da0963de-e08e-4d12-bf23-be8801efc9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-be0af343-a98c-4c80-aece-92693bd163cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-47922fbf-988f-457d-bc08-10829beedbf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2013235468-172.17.0.14-1597309430665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43810,DS-44b79885-738f-4ca0-b619-8f1b39411378,DISK], DatanodeInfoWithStorage[127.0.0.1:38491,DS-5db474dd-4afb-4c02-8dfb-ff4a74c92cff,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-f53046b4-633e-46ab-a7ba-6bbd6eb72611,DISK], DatanodeInfoWithStorage[127.0.0.1:43088,DS-02efc7a6-42e1-48e5-8092-c7f88d40eab6,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-fca93ec4-75a3-49f1-a3a3-a8030ddc5cce,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-da0963de-e08e-4d12-bf23-be8801efc9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34704,DS-be0af343-a98c-4c80-aece-92693bd163cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-47922fbf-988f-457d-bc08-10829beedbf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5875
