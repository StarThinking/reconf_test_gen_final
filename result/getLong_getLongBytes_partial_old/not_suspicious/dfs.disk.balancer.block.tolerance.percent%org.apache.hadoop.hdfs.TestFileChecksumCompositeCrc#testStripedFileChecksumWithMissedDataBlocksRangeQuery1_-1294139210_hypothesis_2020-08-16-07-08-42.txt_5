reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1171007091-172.17.0.8-1597562236683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42867,DS-50a677d3-1529-40e8-b1df-7ea370190ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-ec3f1864-8153-4845-9dc7-6286074f4868,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-5bad1557-0a92-4977-ba4e-1941f1c558dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-a93b85fd-c668-46b7-baff-190f32bbed42,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-6aa935ec-19f8-4c76-a824-597daeaabb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-2abd2320-d97c-4544-807c-615cfacb2d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-bc4ace88-95d2-4280-836d-85b5fef0d6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-3f00e8b0-509c-4be3-8657-20602a46564e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1171007091-172.17.0.8-1597562236683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42867,DS-50a677d3-1529-40e8-b1df-7ea370190ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-ec3f1864-8153-4845-9dc7-6286074f4868,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-5bad1557-0a92-4977-ba4e-1941f1c558dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-a93b85fd-c668-46b7-baff-190f32bbed42,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-6aa935ec-19f8-4c76-a824-597daeaabb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-2abd2320-d97c-4544-807c-615cfacb2d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-bc4ace88-95d2-4280-836d-85b5fef0d6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34896,DS-3f00e8b0-509c-4be3-8657-20602a46564e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851819127-172.17.0.8-1597562325454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32794,DS-7d0d4ac5-b338-495e-b9d4-2691e392ce64,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-494a731d-5cf3-4cf2-bbb4-6d8d0055d4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-a0c365fa-b7da-451e-9c54-8192d077348a,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-fd15d4b1-e129-40e8-8d33-6ec71e0fca8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-f4a4c8ee-d38e-4371-9db6-5981cc7ad0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-3f82998b-4d0d-4498-9aa0-ad23bf0082d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-662763ac-7ce8-4d4f-a638-5427829ede86,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-2099c04c-1897-45c4-83bb-3863dcc7784b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851819127-172.17.0.8-1597562325454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32794,DS-7d0d4ac5-b338-495e-b9d4-2691e392ce64,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-494a731d-5cf3-4cf2-bbb4-6d8d0055d4d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-a0c365fa-b7da-451e-9c54-8192d077348a,DISK], DatanodeInfoWithStorage[127.0.0.1:37875,DS-fd15d4b1-e129-40e8-8d33-6ec71e0fca8f,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-f4a4c8ee-d38e-4371-9db6-5981cc7ad0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-3f82998b-4d0d-4498-9aa0-ad23bf0082d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-662763ac-7ce8-4d4f-a638-5427829ede86,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-2099c04c-1897-45c4-83bb-3863dcc7784b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1818061263-172.17.0.8-1597562480212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35739,DS-ee5e1189-a278-4bdf-9754-e358ace17a42,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-de29f9c8-def5-415e-b289-b94ba7387b62,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-c672544e-251a-4d9e-b683-e1196f18c89b,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-c9204581-78b3-4553-b887-c4996ca79cee,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-cf324554-dab4-4fc6-b46a-538e1fc82aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-56bc4e1e-5db7-40ca-b928-1b0ed88c4ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-e985bd2a-1b7f-457c-a12d-f47f73b7fbe2,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-6c81d927-bd37-499c-9289-3bbade00a266,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1818061263-172.17.0.8-1597562480212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35739,DS-ee5e1189-a278-4bdf-9754-e358ace17a42,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-de29f9c8-def5-415e-b289-b94ba7387b62,DISK], DatanodeInfoWithStorage[127.0.0.1:33940,DS-c672544e-251a-4d9e-b683-e1196f18c89b,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-c9204581-78b3-4553-b887-c4996ca79cee,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-cf324554-dab4-4fc6-b46a-538e1fc82aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:43084,DS-56bc4e1e-5db7-40ca-b928-1b0ed88c4ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-e985bd2a-1b7f-457c-a12d-f47f73b7fbe2,DISK], DatanodeInfoWithStorage[127.0.0.1:43686,DS-6c81d927-bd37-499c-9289-3bbade00a266,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1248252126-172.17.0.8-1597562667797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37470,DS-8906ab89-64d8-4fbd-ab81-b6798e463f51,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-e00722b9-e0bb-4684-8ed4-1d8f580e7fac,DISK], DatanodeInfoWithStorage[127.0.0.1:43824,DS-82e97f03-378c-445d-ba68-d5cb32994be6,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-0b43e6fb-0464-4f9e-8cd4-d4838b6dd6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-75a43bb2-d7ec-4c36-8138-0dc8158f44be,DISK], DatanodeInfoWithStorage[127.0.0.1:33838,DS-5735c4c5-38c7-4021-8fce-2cdf5c7b8cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-a6ac9483-afb7-4f83-85bc-e09dc41c2ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-00fdd1c1-c1e0-4fa6-9cdc-12bb78aaeccf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1248252126-172.17.0.8-1597562667797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37470,DS-8906ab89-64d8-4fbd-ab81-b6798e463f51,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-e00722b9-e0bb-4684-8ed4-1d8f580e7fac,DISK], DatanodeInfoWithStorage[127.0.0.1:43824,DS-82e97f03-378c-445d-ba68-d5cb32994be6,DISK], DatanodeInfoWithStorage[127.0.0.1:38043,DS-0b43e6fb-0464-4f9e-8cd4-d4838b6dd6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-75a43bb2-d7ec-4c36-8138-0dc8158f44be,DISK], DatanodeInfoWithStorage[127.0.0.1:33838,DS-5735c4c5-38c7-4021-8fce-2cdf5c7b8cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-a6ac9483-afb7-4f83-85bc-e09dc41c2ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-00fdd1c1-c1e0-4fa6-9cdc-12bb78aaeccf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-540301208-172.17.0.8-1597562787497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46202,DS-8ec106df-562c-48c4-ab41-23a0a66c9f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-0038eed4-df6c-48a3-968d-48f197240d63,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-2e0030d1-0d51-40a8-9c71-5375d736dad2,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-4a5c6e35-1895-4359-9662-eca44ebc9f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-0df2e6fd-3186-4fcd-b51b-9206a9a3bee1,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-187129d9-fa7b-4525-b9aa-28def4956de1,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-3c73f6ba-d3c1-434e-9d6e-d78e34847213,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-29d52bc9-7f23-4022-8e64-2b233ff86449,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-540301208-172.17.0.8-1597562787497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46202,DS-8ec106df-562c-48c4-ab41-23a0a66c9f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-0038eed4-df6c-48a3-968d-48f197240d63,DISK], DatanodeInfoWithStorage[127.0.0.1:43006,DS-2e0030d1-0d51-40a8-9c71-5375d736dad2,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-4a5c6e35-1895-4359-9662-eca44ebc9f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44503,DS-0df2e6fd-3186-4fcd-b51b-9206a9a3bee1,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-187129d9-fa7b-4525-b9aa-28def4956de1,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-3c73f6ba-d3c1-434e-9d6e-d78e34847213,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-29d52bc9-7f23-4022-8e64-2b233ff86449,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1127535826-172.17.0.8-1597563041389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35755,DS-0bbbb685-e804-476c-b1b3-af608c8f3d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-f9beb47c-6c4a-4b2d-b15e-bf93528c3494,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-8ebe9925-fd61-444b-aec8-e59d47383972,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-e60c7f95-783c-48c0-96f3-fd254e07e3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-31ed05e2-c371-40d1-b971-825a63769bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-9003388d-716e-4814-9a61-0f3fefed1173,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-77407e23-a98b-4a51-b43a-85c2a9668251,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-5937759a-d544-4351-a9da-20e6279d2e82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1127535826-172.17.0.8-1597563041389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35755,DS-0bbbb685-e804-476c-b1b3-af608c8f3d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-f9beb47c-6c4a-4b2d-b15e-bf93528c3494,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-8ebe9925-fd61-444b-aec8-e59d47383972,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-e60c7f95-783c-48c0-96f3-fd254e07e3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-31ed05e2-c371-40d1-b971-825a63769bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-9003388d-716e-4814-9a61-0f3fefed1173,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-77407e23-a98b-4a51-b43a-85c2a9668251,DISK], DatanodeInfoWithStorage[127.0.0.1:37827,DS-5937759a-d544-4351-a9da-20e6279d2e82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439019959-172.17.0.8-1597563298611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46791,DS-2863558a-b632-4b86-85ae-7a6276973cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-f71c3858-c0e8-4029-bab7-91868ce608ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-144687ce-7146-40f3-8ed5-c42254c0d4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-e7a50865-1a5f-4f95-b46b-8d4abf82c213,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-b607fb04-e748-41e3-af89-43fa3539f677,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-63b0b142-6537-4b84-bec3-9c6c7f6bd450,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-f7fb55aa-1bbd-4725-ae7d-3849c20a39fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-07295d57-8f99-4f37-b2f1-3da59611bc83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439019959-172.17.0.8-1597563298611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46791,DS-2863558a-b632-4b86-85ae-7a6276973cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-f71c3858-c0e8-4029-bab7-91868ce608ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-144687ce-7146-40f3-8ed5-c42254c0d4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-e7a50865-1a5f-4f95-b46b-8d4abf82c213,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-b607fb04-e748-41e3-af89-43fa3539f677,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-63b0b142-6537-4b84-bec3-9c6c7f6bd450,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-f7fb55aa-1bbd-4725-ae7d-3849c20a39fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36148,DS-07295d57-8f99-4f37-b2f1-3da59611bc83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-681246461-172.17.0.8-1597563570454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40064,DS-c50716dc-c0aa-408f-bd85-afda42b703f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-4ea10903-740f-4f36-914c-ce94299a15a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-7f1ebb8b-2549-4ac7-9bbc-ed0ecd4f592f,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-8bdd4c9b-771f-45c2-a882-32d6156ab327,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-c9cee83f-4753-4199-bcd8-2bdf478add4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-ee087627-9ce2-4a41-8b9e-486ac7649b41,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-12b0e074-cd86-4fc0-989f-14e59b19cfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-e35aed21-f9db-4c89-9e83-aea162c32848,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-681246461-172.17.0.8-1597563570454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40064,DS-c50716dc-c0aa-408f-bd85-afda42b703f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-4ea10903-740f-4f36-914c-ce94299a15a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-7f1ebb8b-2549-4ac7-9bbc-ed0ecd4f592f,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-8bdd4c9b-771f-45c2-a882-32d6156ab327,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-c9cee83f-4753-4199-bcd8-2bdf478add4b,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-ee087627-9ce2-4a41-8b9e-486ac7649b41,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-12b0e074-cd86-4fc0-989f-14e59b19cfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-e35aed21-f9db-4c89-9e83-aea162c32848,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961929227-172.17.0.8-1597563824918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46036,DS-b480d277-a74c-4b55-95a9-1ffc821883eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-ca72e61d-6e61-4237-b093-7a6a88c68f15,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-d26f4332-af55-418a-8479-4523bc8fab47,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-6c941f16-2590-4e2a-ab73-5fce44f7c3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-e69c6e0f-2dbf-464b-abe8-816d8d55df0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-1fc89ad1-0834-4fbb-9991-41c82da05f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-67c83172-b655-44c8-b9b0-c035f0f5ee69,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-386b9fbf-8c33-4b98-9fbc-7086d9b9d811,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-961929227-172.17.0.8-1597563824918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46036,DS-b480d277-a74c-4b55-95a9-1ffc821883eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-ca72e61d-6e61-4237-b093-7a6a88c68f15,DISK], DatanodeInfoWithStorage[127.0.0.1:45254,DS-d26f4332-af55-418a-8479-4523bc8fab47,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-6c941f16-2590-4e2a-ab73-5fce44f7c3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42535,DS-e69c6e0f-2dbf-464b-abe8-816d8d55df0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-1fc89ad1-0834-4fbb-9991-41c82da05f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-67c83172-b655-44c8-b9b0-c035f0f5ee69,DISK], DatanodeInfoWithStorage[127.0.0.1:38154,DS-386b9fbf-8c33-4b98-9fbc-7086d9b9d811,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2071586510-172.17.0.8-1597564013704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46584,DS-5a276584-3404-4ab6-9e37-83fc39d0fa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-766bf110-bd24-478e-b3df-92849bbe472e,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-c8a6afa2-e5f1-4ab0-a00d-a00cce50984c,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-2ff6767d-6dc1-48fa-994e-db30654cf305,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-dd19525d-16b1-43f2-8971-4e9eca32bcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-f57f2e5d-648b-430f-9723-dd86d90b9432,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-660de4ef-13fe-4a34-9a13-f838c1dde12a,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-13f20df4-4993-49e3-8309-20d28ef50d01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2071586510-172.17.0.8-1597564013704:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46584,DS-5a276584-3404-4ab6-9e37-83fc39d0fa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-766bf110-bd24-478e-b3df-92849bbe472e,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-c8a6afa2-e5f1-4ab0-a00d-a00cce50984c,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-2ff6767d-6dc1-48fa-994e-db30654cf305,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-dd19525d-16b1-43f2-8971-4e9eca32bcaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41916,DS-f57f2e5d-648b-430f-9723-dd86d90b9432,DISK], DatanodeInfoWithStorage[127.0.0.1:44708,DS-660de4ef-13fe-4a34-9a13-f838c1dde12a,DISK], DatanodeInfoWithStorage[127.0.0.1:45821,DS-13f20df4-4993-49e3-8309-20d28ef50d01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1481710953-172.17.0.8-1597564958683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34102,DS-0b99c9be-f02e-4f5e-aaed-531106c30286,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-f0c74f3b-d81f-4630-bf68-80cdde59acd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-0f029f5d-e14b-4715-91bc-71d5ed0642f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-70a997fe-b8e6-496e-9775-33693b524763,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-291be1a7-ead0-4729-a502-db9ea1fa6da4,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-31372165-87a9-4297-a676-1f535e3d6197,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-3ffb4fd3-3439-40cd-9f5d-08f95532032c,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-6e584514-4a89-45c8-b961-a74c4c06d9db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1481710953-172.17.0.8-1597564958683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34102,DS-0b99c9be-f02e-4f5e-aaed-531106c30286,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-f0c74f3b-d81f-4630-bf68-80cdde59acd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-0f029f5d-e14b-4715-91bc-71d5ed0642f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45441,DS-70a997fe-b8e6-496e-9775-33693b524763,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-291be1a7-ead0-4729-a502-db9ea1fa6da4,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-31372165-87a9-4297-a676-1f535e3d6197,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-3ffb4fd3-3439-40cd-9f5d-08f95532032c,DISK], DatanodeInfoWithStorage[127.0.0.1:37879,DS-6e584514-4a89-45c8-b961-a74c4c06d9db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63668854-172.17.0.8-1597565356555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39259,DS-9c7264bf-e967-49de-8c2a-d9ee727a3075,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-abeceb1a-0d9f-478a-bea1-6a48600c4ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-8e5db1b3-6148-4a81-abaf-a40157d6cbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-232c3d2a-1856-4f52-9342-8a79cf8cccaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-3f71acce-659e-4d21-9dde-787ddf10726c,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-21faff0b-69b4-41b1-8640-2a085a0e1cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-a9779b6f-e704-4e9d-94e8-3f7e47f7155d,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-d890d567-1147-48aa-84b0-9ecdc75c295e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63668854-172.17.0.8-1597565356555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39259,DS-9c7264bf-e967-49de-8c2a-d9ee727a3075,DISK], DatanodeInfoWithStorage[127.0.0.1:44995,DS-abeceb1a-0d9f-478a-bea1-6a48600c4ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-8e5db1b3-6148-4a81-abaf-a40157d6cbe9,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-232c3d2a-1856-4f52-9342-8a79cf8cccaf,DISK], DatanodeInfoWithStorage[127.0.0.1:34406,DS-3f71acce-659e-4d21-9dde-787ddf10726c,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-21faff0b-69b4-41b1-8640-2a085a0e1cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-a9779b6f-e704-4e9d-94e8-3f7e47f7155d,DISK], DatanodeInfoWithStorage[127.0.0.1:40414,DS-d890d567-1147-48aa-84b0-9ecdc75c295e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568675310-172.17.0.8-1597565506442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43395,DS-2505469e-50de-4648-a13f-9b0980dda59e,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-d9bc0db7-ea39-4492-b71f-38f374f68e77,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-f79f41ef-5ec7-473e-ad71-98422734174b,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-c5c49ad0-5c41-487c-8297-fa7ddb02f9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-94a07214-e2cf-4e79-8756-46519c5de985,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-847ffe7e-77bc-4be4-b481-01c9b869f632,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-b8bac125-4e13-4149-905f-c3691cfb995d,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-a4728989-0d79-4234-ad2a-0b5f0e1eed91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1568675310-172.17.0.8-1597565506442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43395,DS-2505469e-50de-4648-a13f-9b0980dda59e,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-d9bc0db7-ea39-4492-b71f-38f374f68e77,DISK], DatanodeInfoWithStorage[127.0.0.1:40262,DS-f79f41ef-5ec7-473e-ad71-98422734174b,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-c5c49ad0-5c41-487c-8297-fa7ddb02f9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40522,DS-94a07214-e2cf-4e79-8756-46519c5de985,DISK], DatanodeInfoWithStorage[127.0.0.1:35608,DS-847ffe7e-77bc-4be4-b481-01c9b869f632,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-b8bac125-4e13-4149-905f-c3691cfb995d,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-a4728989-0d79-4234-ad2a-0b5f0e1eed91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846574543-172.17.0.8-1597566136150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33360,DS-e8a927a1-498f-4588-bd09-cd7d602d0ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-d347a58e-703d-47b4-96e5-e397e4114ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-cf9392c9-c523-48fc-87bd-e90b765af0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-e96c4bba-d4f4-450c-8163-3a7dd69ae9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-82237116-0f4b-4620-90b6-d6bd3b9f8eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-e6e6a489-cda7-487b-8058-2e0a8c905a62,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-c0c54435-9443-4b3d-a5e4-7d2eab42455b,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-fa1b044a-4b62-49df-ade8-7f70c6f31934,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846574543-172.17.0.8-1597566136150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33360,DS-e8a927a1-498f-4588-bd09-cd7d602d0ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-d347a58e-703d-47b4-96e5-e397e4114ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-cf9392c9-c523-48fc-87bd-e90b765af0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-e96c4bba-d4f4-450c-8163-3a7dd69ae9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-82237116-0f4b-4620-90b6-d6bd3b9f8eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-e6e6a489-cda7-487b-8058-2e0a8c905a62,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-c0c54435-9443-4b3d-a5e4-7d2eab42455b,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-fa1b044a-4b62-49df-ade8-7f70c6f31934,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1856298908-172.17.0.8-1597567020957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35428,DS-ae168656-070d-4e4b-9a97-ebad0cf95e69,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-a04e2699-9b94-4316-9e49-abb9c4883a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-8612bee0-8deb-4391-ab00-d32cb1b2bcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-5a589dd1-cb2b-4cff-a877-36cd0f55d88d,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-a3c39373-7fa5-4300-92dd-767d9bc37f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-8c8a124d-b6ed-41eb-93ce-9a098d2e6c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-e6f87164-c500-4477-a3cd-c995bbe4287a,DISK], DatanodeInfoWithStorage[127.0.0.1:41019,DS-66a706f5-ca71-4210-be1e-1204df17c7a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1856298908-172.17.0.8-1597567020957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35428,DS-ae168656-070d-4e4b-9a97-ebad0cf95e69,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-a04e2699-9b94-4316-9e49-abb9c4883a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-8612bee0-8deb-4391-ab00-d32cb1b2bcc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-5a589dd1-cb2b-4cff-a877-36cd0f55d88d,DISK], DatanodeInfoWithStorage[127.0.0.1:39404,DS-a3c39373-7fa5-4300-92dd-767d9bc37f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-8c8a124d-b6ed-41eb-93ce-9a098d2e6c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-e6f87164-c500-4477-a3cd-c995bbe4287a,DISK], DatanodeInfoWithStorage[127.0.0.1:41019,DS-66a706f5-ca71-4210-be1e-1204df17c7a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.block.tolerance.percent
component: hdfs:DataNode
v1: 10
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599437788-172.17.0.8-1597567300806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46782,DS-36b6c14f-55ef-4543-af32-d6dd4563cae4,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-246b732e-53f4-4647-8b7e-0ca819fdcbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-7d6e8c48-525b-4e5d-b2c5-03926018d620,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-14a6028b-57bd-4985-8f7e-f2cdd54892ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45984,DS-448df0ad-1c10-4c98-a190-79ebeabdcfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-c207bbe9-dcbd-4171-a296-bc1ca905cc61,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-77f35888-bde6-4ecd-9c6b-111e5a074cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-54466151-676f-4197-a3b5-54b7d344d7f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-599437788-172.17.0.8-1597567300806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46782,DS-36b6c14f-55ef-4543-af32-d6dd4563cae4,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-246b732e-53f4-4647-8b7e-0ca819fdcbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37444,DS-7d6e8c48-525b-4e5d-b2c5-03926018d620,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-14a6028b-57bd-4985-8f7e-f2cdd54892ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45984,DS-448df0ad-1c10-4c98-a190-79ebeabdcfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-c207bbe9-dcbd-4171-a296-bc1ca905cc61,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-77f35888-bde6-4ecd-9c6b-111e5a074cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-54466151-676f-4197-a3b5-54b7d344d7f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5854
