reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-125051173-172.17.0.14-1597309706585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38272,DS-5d5cf1e4-04b2-4ab3-9fa5-8ffe25e9c4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-88c7b0bd-6b75-42ce-a153-6d3d4f81f0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-8bc23265-7341-401a-8627-e84145a506dc,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-9b02696a-8fe8-4583-a623-6d967d986ece,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-db257fec-37f0-4eee-9660-bd2caa231f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-01899609-6295-4f7f-b2ae-ce9c7d923ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-58565405-d8b8-490f-8286-ae7675bd05cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-6729f398-4704-4769-8120-b63bd4b2751d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-125051173-172.17.0.14-1597309706585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38272,DS-5d5cf1e4-04b2-4ab3-9fa5-8ffe25e9c4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-88c7b0bd-6b75-42ce-a153-6d3d4f81f0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-8bc23265-7341-401a-8627-e84145a506dc,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-9b02696a-8fe8-4583-a623-6d967d986ece,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-db257fec-37f0-4eee-9660-bd2caa231f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-01899609-6295-4f7f-b2ae-ce9c7d923ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-58565405-d8b8-490f-8286-ae7675bd05cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46141,DS-6729f398-4704-4769-8120-b63bd4b2751d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1414618090-172.17.0.14-1597309861668:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40616,DS-7850df65-4966-4ca2-b117-cab89ed5f12c,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-06f640ac-0abe-4c2e-8f8b-f80dd805505c,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-cca06b93-5ef6-462f-b1d1-292362097800,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-8f44fcb8-1b50-42d0-a432-e93d3203a52e,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-a5327708-b16b-4637-a830-3a5398b5e76e,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-f2bd64d7-d5fe-4ee6-bbb4-cb295ec4c315,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-f8cf9f74-7079-455d-8d89-cf29c4e05995,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-9d12c373-7c03-4fa0-abbb-9379e30ce3ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1414618090-172.17.0.14-1597309861668:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40616,DS-7850df65-4966-4ca2-b117-cab89ed5f12c,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-06f640ac-0abe-4c2e-8f8b-f80dd805505c,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-cca06b93-5ef6-462f-b1d1-292362097800,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-8f44fcb8-1b50-42d0-a432-e93d3203a52e,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-a5327708-b16b-4637-a830-3a5398b5e76e,DISK], DatanodeInfoWithStorage[127.0.0.1:43072,DS-f2bd64d7-d5fe-4ee6-bbb4-cb295ec4c315,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-f8cf9f74-7079-455d-8d89-cf29c4e05995,DISK], DatanodeInfoWithStorage[127.0.0.1:42838,DS-9d12c373-7c03-4fa0-abbb-9379e30ce3ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1330889874-172.17.0.14-1597309897051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40663,DS-6341a683-99e1-4bb1-934c-c9da0f073131,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-d74e0bb4-afe2-4462-9c91-3cdb9de48d65,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-9d7f34ee-ea5c-4d7e-9274-96681ab26683,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-8e0f2092-db9d-4338-a30e-3aaf3bc2ca51,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-84532b08-cd22-46cf-b782-e68a8507563a,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-6904e90c-e94a-4e5b-ae1b-61921f12dffd,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-d6007747-4bbc-4641-8879-a7c7c7cbae6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-4dce3bb1-8a51-4384-abf0-4c518f15a220,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1330889874-172.17.0.14-1597309897051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40663,DS-6341a683-99e1-4bb1-934c-c9da0f073131,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-d74e0bb4-afe2-4462-9c91-3cdb9de48d65,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-9d7f34ee-ea5c-4d7e-9274-96681ab26683,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-8e0f2092-db9d-4338-a30e-3aaf3bc2ca51,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-84532b08-cd22-46cf-b782-e68a8507563a,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-6904e90c-e94a-4e5b-ae1b-61921f12dffd,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-d6007747-4bbc-4641-8879-a7c7c7cbae6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-4dce3bb1-8a51-4384-abf0-4c518f15a220,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1815244295-172.17.0.14-1597310094595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39055,DS-b2e70e47-57ff-4ebd-bcf5-ad0217b1f28b,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-139122bb-27ad-4caf-9114-517a356fdb38,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-df49fe5c-c9fb-4186-b81e-e793a55b4383,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-cf8e3d8c-647e-4a7a-9376-7e11423e92f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-171f1e60-1968-4af6-a289-14b28e47cb71,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-7fc88d86-3637-4662-87b9-2f9afbfac6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-12df5dc0-3a74-43a8-baab-a05dc68c60a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-92db962a-0420-459b-9f1b-295992dacc38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1815244295-172.17.0.14-1597310094595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39055,DS-b2e70e47-57ff-4ebd-bcf5-ad0217b1f28b,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-139122bb-27ad-4caf-9114-517a356fdb38,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-df49fe5c-c9fb-4186-b81e-e793a55b4383,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-cf8e3d8c-647e-4a7a-9376-7e11423e92f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-171f1e60-1968-4af6-a289-14b28e47cb71,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-7fc88d86-3637-4662-87b9-2f9afbfac6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-12df5dc0-3a74-43a8-baab-a05dc68c60a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41172,DS-92db962a-0420-459b-9f1b-295992dacc38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1262216428-172.17.0.14-1597310241469:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32992,DS-b15919ea-4ea1-40c4-bad7-003bcb5e9574,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-1631865e-5a90-43c6-b9e5-9ce5b29283be,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-237d6029-349c-4094-8a9e-60405b8002e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-924f41f5-e715-4cb2-ad12-c8991739faf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-6cc187ad-138f-4478-8bb1-145384dd1b53,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-c5368232-c20b-414d-be35-f145de352794,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-1aa30786-7248-4c8b-8128-9e5822756c97,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-f2758b0e-f32a-4376-ba59-5d0cc6e05a54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1262216428-172.17.0.14-1597310241469:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32992,DS-b15919ea-4ea1-40c4-bad7-003bcb5e9574,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-1631865e-5a90-43c6-b9e5-9ce5b29283be,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-237d6029-349c-4094-8a9e-60405b8002e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42015,DS-924f41f5-e715-4cb2-ad12-c8991739faf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-6cc187ad-138f-4478-8bb1-145384dd1b53,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-c5368232-c20b-414d-be35-f145de352794,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-1aa30786-7248-4c8b-8128-9e5822756c97,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-f2758b0e-f32a-4376-ba59-5d0cc6e05a54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2024132766-172.17.0.14-1597310727380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33025,DS-4f3448b5-0f5b-4f94-9ba9-308296dd2833,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-44ceb2b0-fd4c-46f0-b926-5c02b6e98023,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-1f10b0ff-cb1c-487c-afe8-74bbe0fdfb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-ea458f3d-a1f8-4606-833f-f87c39fd7eee,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-4bd75e16-f3e1-46eb-a768-7cf92b53c08e,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-2a220238-e417-40e5-8966-b7825fe6f3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-b789be98-0f00-48af-96f2-58aaca3a37db,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-30e12868-ad70-4d54-82b5-adba4a8c3768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2024132766-172.17.0.14-1597310727380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33025,DS-4f3448b5-0f5b-4f94-9ba9-308296dd2833,DISK], DatanodeInfoWithStorage[127.0.0.1:46035,DS-44ceb2b0-fd4c-46f0-b926-5c02b6e98023,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-1f10b0ff-cb1c-487c-afe8-74bbe0fdfb3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-ea458f3d-a1f8-4606-833f-f87c39fd7eee,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-4bd75e16-f3e1-46eb-a768-7cf92b53c08e,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-2a220238-e417-40e5-8966-b7825fe6f3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38251,DS-b789be98-0f00-48af-96f2-58aaca3a37db,DISK], DatanodeInfoWithStorage[127.0.0.1:36114,DS-30e12868-ad70-4d54-82b5-adba4a8c3768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-392455098-172.17.0.14-1597311656818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41071,DS-280259fc-0d01-4f94-8e2a-b158440b071e,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-c21b0d5b-c3d6-4e5b-b5cb-9d5c331aa85c,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-f44bf86b-dccf-4ed5-8a2c-80f5bc72c6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-89a2cdb6-6447-48fd-bdd4-7b3b920cc644,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-b0c0e9cb-67a8-4068-b723-6abda51c894b,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-c3d1216b-154a-4292-a857-11b5a8a2234f,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-7312bdf7-bf73-4593-8672-8f025b009d29,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-c256ef9a-40ab-42aa-849c-ca9ef3d075fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-392455098-172.17.0.14-1597311656818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41071,DS-280259fc-0d01-4f94-8e2a-b158440b071e,DISK], DatanodeInfoWithStorage[127.0.0.1:34217,DS-c21b0d5b-c3d6-4e5b-b5cb-9d5c331aa85c,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-f44bf86b-dccf-4ed5-8a2c-80f5bc72c6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-89a2cdb6-6447-48fd-bdd4-7b3b920cc644,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-b0c0e9cb-67a8-4068-b723-6abda51c894b,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-c3d1216b-154a-4292-a857-11b5a8a2234f,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-7312bdf7-bf73-4593-8672-8f025b009d29,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-c256ef9a-40ab-42aa-849c-ca9ef3d075fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-649238002-172.17.0.14-1597311734292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46021,DS-10bff42d-0ca1-4348-83f3-6150fd807468,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-33d8d0f6-1ce6-4962-a891-cb699c00dd93,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-bbca0f70-9692-4aaf-90bf-edf5eff1f97b,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-6ec5d80e-30e6-4d8a-8760-070478365490,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-58b398aa-d9b3-46fe-a5e7-bdc9ae33dfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-6f006b4b-1814-41de-b7c3-6e08f987367f,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-2d10fb02-3ce9-4d3c-8a13-4152495f2a97,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-21d1e25c-3465-4b98-80de-09233c369cdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-649238002-172.17.0.14-1597311734292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46021,DS-10bff42d-0ca1-4348-83f3-6150fd807468,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-33d8d0f6-1ce6-4962-a891-cb699c00dd93,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-bbca0f70-9692-4aaf-90bf-edf5eff1f97b,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-6ec5d80e-30e6-4d8a-8760-070478365490,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-58b398aa-d9b3-46fe-a5e7-bdc9ae33dfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-6f006b4b-1814-41de-b7c3-6e08f987367f,DISK], DatanodeInfoWithStorage[127.0.0.1:40972,DS-2d10fb02-3ce9-4d3c-8a13-4152495f2a97,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-21d1e25c-3465-4b98-80de-09233c369cdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-24771001-172.17.0.14-1597312069449:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44444,DS-8f04057a-e36a-4ff5-942e-8165e7c84164,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-6d3e8994-0d5e-426c-817d-5cec82cf9c55,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-4d89c759-da18-4791-b76e-890bbf74057d,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-aa0df4cc-7eaa-4253-977c-47760e67133e,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-28608d3a-04df-492a-a6e6-aed02c5ed860,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-58111505-4c61-4c51-979e-b5a1d663314b,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-3b68cb49-c164-402c-b6eb-c00fb98e7e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-ec289752-9fc3-4f7d-93c2-fde59065292c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-24771001-172.17.0.14-1597312069449:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44444,DS-8f04057a-e36a-4ff5-942e-8165e7c84164,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-6d3e8994-0d5e-426c-817d-5cec82cf9c55,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-4d89c759-da18-4791-b76e-890bbf74057d,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-aa0df4cc-7eaa-4253-977c-47760e67133e,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-28608d3a-04df-492a-a6e6-aed02c5ed860,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-58111505-4c61-4c51-979e-b5a1d663314b,DISK], DatanodeInfoWithStorage[127.0.0.1:39451,DS-3b68cb49-c164-402c-b6eb-c00fb98e7e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-ec289752-9fc3-4f7d-93c2-fde59065292c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1070370556-172.17.0.14-1597312114001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41149,DS-cd0d5137-8f16-488b-b307-26992a309921,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-a7f55574-c37b-4f33-a541-e4d4a0d413b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-7225c745-5a20-45d6-997a-692fd459481d,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-3db84ee7-ff50-452b-b71b-ce97ab005865,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-a0d80aaa-e5da-4a73-983e-bf58a0d45e38,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-6dca868f-f4ff-4957-8e30-6a09e6ddada7,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-ae755a8a-8a77-4f73-9d99-c6dcfc1b53d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-b3a0e6f4-9826-4077-a356-940ffaba4ac7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1070370556-172.17.0.14-1597312114001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41149,DS-cd0d5137-8f16-488b-b307-26992a309921,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-a7f55574-c37b-4f33-a541-e4d4a0d413b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-7225c745-5a20-45d6-997a-692fd459481d,DISK], DatanodeInfoWithStorage[127.0.0.1:44955,DS-3db84ee7-ff50-452b-b71b-ce97ab005865,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-a0d80aaa-e5da-4a73-983e-bf58a0d45e38,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-6dca868f-f4ff-4957-8e30-6a09e6ddada7,DISK], DatanodeInfoWithStorage[127.0.0.1:41696,DS-ae755a8a-8a77-4f73-9d99-c6dcfc1b53d5,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-b3a0e6f4-9826-4077-a356-940ffaba4ac7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-235728680-172.17.0.14-1597312307148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46024,DS-5ff0a99e-2b9d-4c50-a320-08862a0b993e,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-699afa27-8619-42ca-8f25-71fcd785ba37,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-46783b32-8e50-42c4-91cb-e2c07cee9bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-d25d4e0c-dc1a-438c-9335-7f14f56cfa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-345ea171-448f-4e1c-a6ac-c2d6ee5643d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-1b3eef15-da53-431f-8eac-0b9cb233d0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-85b32152-fc71-4c0e-ae3c-1e87a0ee6be3,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-fa14ae4d-f38d-4280-a773-f40544513a3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-235728680-172.17.0.14-1597312307148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46024,DS-5ff0a99e-2b9d-4c50-a320-08862a0b993e,DISK], DatanodeInfoWithStorage[127.0.0.1:34788,DS-699afa27-8619-42ca-8f25-71fcd785ba37,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-46783b32-8e50-42c4-91cb-e2c07cee9bbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-d25d4e0c-dc1a-438c-9335-7f14f56cfa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-345ea171-448f-4e1c-a6ac-c2d6ee5643d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-1b3eef15-da53-431f-8eac-0b9cb233d0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-85b32152-fc71-4c0e-ae3c-1e87a0ee6be3,DISK], DatanodeInfoWithStorage[127.0.0.1:37443,DS-fa14ae4d-f38d-4280-a773-f40544513a3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-676153714-172.17.0.14-1597313130811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34418,DS-5bf3909a-c67a-48dd-9cc6-d0f46ced8b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-ad613802-2a96-4e1d-9c38-61948265e759,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-62de0eeb-0df3-42c3-a659-b7c3a8ee4030,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-6885b0aa-33bf-4c00-bfde-0bd54213bf91,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-b1604096-c323-4fd7-a3c4-a83d712bfb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-de27af8a-4c13-4507-a883-90f2ee4ac6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-14fb9f25-9678-4b6b-b135-822e86a8e50d,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-a688c773-bf23-45e2-96c7-f5dccd6dc12e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-676153714-172.17.0.14-1597313130811:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34418,DS-5bf3909a-c67a-48dd-9cc6-d0f46ced8b2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-ad613802-2a96-4e1d-9c38-61948265e759,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-62de0eeb-0df3-42c3-a659-b7c3a8ee4030,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-6885b0aa-33bf-4c00-bfde-0bd54213bf91,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-b1604096-c323-4fd7-a3c4-a83d712bfb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-de27af8a-4c13-4507-a883-90f2ee4ac6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-14fb9f25-9678-4b6b-b135-822e86a8e50d,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-a688c773-bf23-45e2-96c7-f5dccd6dc12e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-375832885-172.17.0.14-1597313897075:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37095,DS-f47d2214-045c-4f1d-8c5c-23cd31399f26,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-3eb95ae4-c3ae-423c-9d74-8b5d7f7ef2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-41d3d2ea-3670-4a1a-8a4d-397be036a953,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-5e88cb38-4d2e-466b-aa23-3e6cce416335,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-c40ec584-17a4-4d45-aff9-c2a0cf5c43a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-41fe9533-24a5-4854-8073-02d41ba898cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-e49fb99e-6c1b-4f3f-9833-527ca27a33b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-775ed0c9-7abf-4f71-a990-c83c745ba6ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-375832885-172.17.0.14-1597313897075:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37095,DS-f47d2214-045c-4f1d-8c5c-23cd31399f26,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-3eb95ae4-c3ae-423c-9d74-8b5d7f7ef2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-41d3d2ea-3670-4a1a-8a4d-397be036a953,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-5e88cb38-4d2e-466b-aa23-3e6cce416335,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-c40ec584-17a4-4d45-aff9-c2a0cf5c43a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-41fe9533-24a5-4854-8073-02d41ba898cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-e49fb99e-6c1b-4f3f-9833-527ca27a33b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46720,DS-775ed0c9-7abf-4f71-a990-c83c745ba6ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 0
v2: 0s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1960657167-172.17.0.14-1597314327043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41319,DS-e3efac27-a4f8-47ad-b115-cb889f04a0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-5507bb93-238e-4e0e-91d0-76039cd45057,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-447fc3fc-e7e0-4dac-a90d-31a620537904,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-5879b631-cf54-4322-9c12-f0b2a7a70e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-9dbaaa5f-d08f-4363-94f5-a82190357b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-b611d874-789e-428b-b1ce-a333d427b682,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-9701d5de-f483-4c70-b8a1-f6e26b578233,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-7a0e9dee-fac9-4bf6-9ed5-03fb18848236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1960657167-172.17.0.14-1597314327043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41319,DS-e3efac27-a4f8-47ad-b115-cb889f04a0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-5507bb93-238e-4e0e-91d0-76039cd45057,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-447fc3fc-e7e0-4dac-a90d-31a620537904,DISK], DatanodeInfoWithStorage[127.0.0.1:37598,DS-5879b631-cf54-4322-9c12-f0b2a7a70e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:38242,DS-9dbaaa5f-d08f-4363-94f5-a82190357b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40879,DS-b611d874-789e-428b-b1ce-a333d427b682,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-9701d5de-f483-4c70-b8a1-f6e26b578233,DISK], DatanodeInfoWithStorage[127.0.0.1:46577,DS-7a0e9dee-fac9-4bf6-9ed5-03fb18848236,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5727
