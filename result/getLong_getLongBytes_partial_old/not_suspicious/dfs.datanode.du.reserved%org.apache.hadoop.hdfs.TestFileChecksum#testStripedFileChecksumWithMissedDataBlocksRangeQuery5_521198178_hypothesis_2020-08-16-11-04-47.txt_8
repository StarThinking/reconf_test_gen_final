reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302931949-172.17.0.9-1597576447631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35507,DS-eb1bd967-be42-4b70-a067-fed4db298089,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-f98717ba-9c6c-4be2-890b-5239d8715255,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-7568782d-2f8f-4682-9c9b-b01012ac60b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-7f0a89e0-93fe-485a-9e41-de4eb3cb1917,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-903a3722-5d08-4318-82e5-35cc3fe41a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-a11c64a8-4b11-4918-a6c1-46156353a5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-7b4e67c4-cea0-44e0-a982-b312ba81ea16,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-4cc90148-71c3-436a-afc2-4b1f3a5ecfbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302931949-172.17.0.9-1597576447631:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35507,DS-eb1bd967-be42-4b70-a067-fed4db298089,DISK], DatanodeInfoWithStorage[127.0.0.1:34529,DS-f98717ba-9c6c-4be2-890b-5239d8715255,DISK], DatanodeInfoWithStorage[127.0.0.1:33451,DS-7568782d-2f8f-4682-9c9b-b01012ac60b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-7f0a89e0-93fe-485a-9e41-de4eb3cb1917,DISK], DatanodeInfoWithStorage[127.0.0.1:44071,DS-903a3722-5d08-4318-82e5-35cc3fe41a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-a11c64a8-4b11-4918-a6c1-46156353a5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-7b4e67c4-cea0-44e0-a982-b312ba81ea16,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-4cc90148-71c3-436a-afc2-4b1f3a5ecfbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1003185082-172.17.0.9-1597576838410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35376,DS-d72ba379-4b6f-4ffd-92c8-9463c70484e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-452dd6ee-c55c-4cda-b9bc-593a92e134fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-3b5e85f5-ece1-4d8b-a0db-e664a1a66a54,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-e67ea664-0099-438d-b37d-ad81c303e61e,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-ba03452b-82ea-41a9-b649-96bc072abf38,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-388e5b6a-095a-4973-b4b4-0b64cbbfa220,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-c1470381-6831-40d7-9a46-f44e28b68093,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-d6e5422a-ef89-440f-84f9-5d3ac77e4605,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1003185082-172.17.0.9-1597576838410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35376,DS-d72ba379-4b6f-4ffd-92c8-9463c70484e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-452dd6ee-c55c-4cda-b9bc-593a92e134fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-3b5e85f5-ece1-4d8b-a0db-e664a1a66a54,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-e67ea664-0099-438d-b37d-ad81c303e61e,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-ba03452b-82ea-41a9-b649-96bc072abf38,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-388e5b6a-095a-4973-b4b4-0b64cbbfa220,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-c1470381-6831-40d7-9a46-f44e28b68093,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-d6e5422a-ef89-440f-84f9-5d3ac77e4605,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-59102804-172.17.0.9-1597576906169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33268,DS-dbbaa732-d2cc-42f0-a196-153d71886ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-d7fc4f69-929d-42d1-9594-b4da4ecf5c64,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-cd07c7da-07bc-4d71-8f47-fc9ef962f368,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-1be5a64c-67a6-4362-bd5e-d1130f24dfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-c5806494-04d6-4bfc-82d5-44975adc8de3,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-e3866d8f-7732-471e-ad97-5346010a51c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-3c26c491-c2e2-48ce-9f28-72afbe01d20e,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-f859cebe-aef9-4ecb-bd32-f042cc956985,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-59102804-172.17.0.9-1597576906169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33268,DS-dbbaa732-d2cc-42f0-a196-153d71886ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-d7fc4f69-929d-42d1-9594-b4da4ecf5c64,DISK], DatanodeInfoWithStorage[127.0.0.1:38509,DS-cd07c7da-07bc-4d71-8f47-fc9ef962f368,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-1be5a64c-67a6-4362-bd5e-d1130f24dfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-c5806494-04d6-4bfc-82d5-44975adc8de3,DISK], DatanodeInfoWithStorage[127.0.0.1:39685,DS-e3866d8f-7732-471e-ad97-5346010a51c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-3c26c491-c2e2-48ce-9f28-72afbe01d20e,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-f859cebe-aef9-4ecb-bd32-f042cc956985,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-678564415-172.17.0.9-1597576946436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39149,DS-be7df464-f98f-46e1-b239-11a27093ac0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37390,DS-4f417f6d-f566-496b-b290-6cdf61590233,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-6bec5bf7-aa1d-4aa3-8859-b50fad1500d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-20d71d17-754b-40be-8215-357c18bbd41b,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-98aa40d0-8e88-43bf-bd85-a0c40883bdb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-c71b5b01-a067-478d-bd94-5290a51a2022,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-142aeea6-362c-4e6d-bc95-fd4ebd5357d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-1017cec1-e838-4433-9f4f-1533e039a85e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-678564415-172.17.0.9-1597576946436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39149,DS-be7df464-f98f-46e1-b239-11a27093ac0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37390,DS-4f417f6d-f566-496b-b290-6cdf61590233,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-6bec5bf7-aa1d-4aa3-8859-b50fad1500d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38840,DS-20d71d17-754b-40be-8215-357c18bbd41b,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-98aa40d0-8e88-43bf-bd85-a0c40883bdb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-c71b5b01-a067-478d-bd94-5290a51a2022,DISK], DatanodeInfoWithStorage[127.0.0.1:39532,DS-142aeea6-362c-4e6d-bc95-fd4ebd5357d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38534,DS-1017cec1-e838-4433-9f4f-1533e039a85e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1296311170-172.17.0.9-1597577128363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36170,DS-25f9efa5-0bad-4b8f-afd0-8c7a255aae4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-9930fda1-36c4-4afe-be51-2c89ba030a30,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-7f752fe1-dd3c-4a23-98d8-b5ba3d3f6411,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-8c466a50-5e3e-49d4-96a3-f04415c37196,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-be3c3be6-31da-4419-8581-56cbfb3157a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-76cceb16-422b-4a22-a8d5-93b0d7a64ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-cf156f6c-07dc-4319-ae76-b51f3a639513,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-878aba0e-f880-4e96-91e0-2be6df198d16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1296311170-172.17.0.9-1597577128363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36170,DS-25f9efa5-0bad-4b8f-afd0-8c7a255aae4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-9930fda1-36c4-4afe-be51-2c89ba030a30,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-7f752fe1-dd3c-4a23-98d8-b5ba3d3f6411,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-8c466a50-5e3e-49d4-96a3-f04415c37196,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-be3c3be6-31da-4419-8581-56cbfb3157a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44425,DS-76cceb16-422b-4a22-a8d5-93b0d7a64ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-cf156f6c-07dc-4319-ae76-b51f3a639513,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-878aba0e-f880-4e96-91e0-2be6df198d16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-467913994-172.17.0.9-1597577685535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42014,DS-d9fc8ad5-116f-44ea-aa90-202b3ce67311,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-b9f4fc49-86fa-4fa4-a965-d4d39a4b391c,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-3f2296f3-3480-4555-ba5d-9ec74c4f1a63,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-785babf6-76c1-4dd7-b044-8caf4291dfaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-4df8e947-db5d-434a-a854-618a43587f99,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-0bd0f4d4-ce78-4565-be5a-491f7943d98d,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-e48eb43f-473d-4097-970d-46c9e5fa7e85,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-e9b1dbf9-14dd-4e99-93d7-e0adadef6896,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-467913994-172.17.0.9-1597577685535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42014,DS-d9fc8ad5-116f-44ea-aa90-202b3ce67311,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-b9f4fc49-86fa-4fa4-a965-d4d39a4b391c,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-3f2296f3-3480-4555-ba5d-9ec74c4f1a63,DISK], DatanodeInfoWithStorage[127.0.0.1:43717,DS-785babf6-76c1-4dd7-b044-8caf4291dfaa,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-4df8e947-db5d-434a-a854-618a43587f99,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-0bd0f4d4-ce78-4565-be5a-491f7943d98d,DISK], DatanodeInfoWithStorage[127.0.0.1:42719,DS-e48eb43f-473d-4097-970d-46c9e5fa7e85,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-e9b1dbf9-14dd-4e99-93d7-e0adadef6896,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-411267601-172.17.0.9-1597577725726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38895,DS-6ce98793-d644-4156-85a8-68bb75a941bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-bcc226ea-06b0-4302-8959-788ece68a4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-b2d227d0-e8e5-42cc-8f6b-ed6297057c48,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-b0754c66-a2aa-43a4-8bd4-edd287dd0c82,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-07a9b8ff-98ac-4025-8823-060da2133a96,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-b1a4229a-6947-4e7f-b21d-7220c6ca2d97,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-b573452e-76ca-4093-95dc-84191bbd351e,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-6e6d3241-e2dc-4029-acc2-8b14c810d389,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-411267601-172.17.0.9-1597577725726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38895,DS-6ce98793-d644-4156-85a8-68bb75a941bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35760,DS-bcc226ea-06b0-4302-8959-788ece68a4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-b2d227d0-e8e5-42cc-8f6b-ed6297057c48,DISK], DatanodeInfoWithStorage[127.0.0.1:33731,DS-b0754c66-a2aa-43a4-8bd4-edd287dd0c82,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-07a9b8ff-98ac-4025-8823-060da2133a96,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-b1a4229a-6947-4e7f-b21d-7220c6ca2d97,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-b573452e-76ca-4093-95dc-84191bbd351e,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-6e6d3241-e2dc-4029-acc2-8b14c810d389,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2101014058-172.17.0.9-1597578106261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33822,DS-33f5e936-3a11-45e0-958d-850e283c99b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-2b444ca3-204b-4cfa-a187-0f06ab9c10a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-a0ceb381-864b-4e8a-a209-dd5b22bcf930,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-94076ecc-24a2-4f47-9008-0954369989f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-6e569768-b67a-426b-a538-0ccd15b67378,DISK], DatanodeInfoWithStorage[127.0.0.1:41376,DS-8fe54181-20c4-4f0e-b408-44ec343fc2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-1209e4c3-73ce-4f4f-a8ef-667e2987e7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-0766ec13-db73-49dd-8cc4-5c65d38980f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2101014058-172.17.0.9-1597578106261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33822,DS-33f5e936-3a11-45e0-958d-850e283c99b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-2b444ca3-204b-4cfa-a187-0f06ab9c10a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-a0ceb381-864b-4e8a-a209-dd5b22bcf930,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-94076ecc-24a2-4f47-9008-0954369989f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-6e569768-b67a-426b-a538-0ccd15b67378,DISK], DatanodeInfoWithStorage[127.0.0.1:41376,DS-8fe54181-20c4-4f0e-b408-44ec343fc2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42230,DS-1209e4c3-73ce-4f4f-a8ef-667e2987e7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38845,DS-0766ec13-db73-49dd-8cc4-5c65d38980f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1426463428-172.17.0.9-1597578541217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40461,DS-0ada7b8d-a4f8-4fcf-978f-7574e0a5a19d,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-78d5ce5c-4e60-430b-a753-190647592c66,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-6384a1ef-744e-4210-abeb-19d364916201,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-4a9c1e67-0f19-421f-be0b-0ec83d14a234,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-87b2821f-5d18-4c5a-bfae-c9e7d44afafd,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-eba3a97b-8fbc-4605-b132-02df5ef08a62,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-cf4224ef-f46d-4f3b-88af-701e662d52d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-72f251c5-2df0-4a5d-8146-9627837c2c3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1426463428-172.17.0.9-1597578541217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40461,DS-0ada7b8d-a4f8-4fcf-978f-7574e0a5a19d,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-78d5ce5c-4e60-430b-a753-190647592c66,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-6384a1ef-744e-4210-abeb-19d364916201,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-4a9c1e67-0f19-421f-be0b-0ec83d14a234,DISK], DatanodeInfoWithStorage[127.0.0.1:44909,DS-87b2821f-5d18-4c5a-bfae-c9e7d44afafd,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-eba3a97b-8fbc-4605-b132-02df5ef08a62,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-cf4224ef-f46d-4f3b-88af-701e662d52d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-72f251c5-2df0-4a5d-8146-9627837c2c3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-530375404-172.17.0.9-1597579048209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37590,DS-5f3cc568-3896-4014-8f9e-d1a50a94084e,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-42b0bcf6-521d-4dd1-8583-221492a683c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-3b88e1b9-4c90-4854-aff8-8e8683959bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-d60cf8f1-6156-4ea7-97c1-2744fdcbc5be,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-a56c3477-38d4-4959-a48b-04e4318119bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-1172e3f2-1990-4b51-a42a-e0c76cf59229,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-52ba33e2-d0ea-4196-979b-26d7f08bfc36,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-3b460747-3352-430c-9077-f36653c14408,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-530375404-172.17.0.9-1597579048209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37590,DS-5f3cc568-3896-4014-8f9e-d1a50a94084e,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-42b0bcf6-521d-4dd1-8583-221492a683c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-3b88e1b9-4c90-4854-aff8-8e8683959bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-d60cf8f1-6156-4ea7-97c1-2744fdcbc5be,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-a56c3477-38d4-4959-a48b-04e4318119bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33762,DS-1172e3f2-1990-4b51-a42a-e0c76cf59229,DISK], DatanodeInfoWithStorage[127.0.0.1:44574,DS-52ba33e2-d0ea-4196-979b-26d7f08bfc36,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-3b460747-3352-430c-9077-f36653c14408,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 4 out of 50
result: might be true error
Total execution time in seconds : 4750
