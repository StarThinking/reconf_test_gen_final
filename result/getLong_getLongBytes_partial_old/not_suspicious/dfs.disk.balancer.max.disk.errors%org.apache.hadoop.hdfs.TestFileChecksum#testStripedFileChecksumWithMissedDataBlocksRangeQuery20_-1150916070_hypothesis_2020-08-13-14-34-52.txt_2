reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1591856661-172.17.0.11-1597329673008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45022,DS-241b8818-65c7-4a0b-ae09-ec4b73ee5003,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-fb1b5378-7c49-42ff-8c49-d627c3dbfb95,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-51229751-3932-4a39-8370-e96ca1a8c041,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-7267d860-2969-4030-beda-8a6be0030888,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-29795050-3673-4131-9a5e-65351d249fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-ffba3a33-0799-4598-bfe4-726ff6d80228,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-29d2996e-5949-4e99-8ced-c3b0813eef06,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-8147b93a-aa7a-4790-ab63-d339d3964a5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1591856661-172.17.0.11-1597329673008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45022,DS-241b8818-65c7-4a0b-ae09-ec4b73ee5003,DISK], DatanodeInfoWithStorage[127.0.0.1:43629,DS-fb1b5378-7c49-42ff-8c49-d627c3dbfb95,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-51229751-3932-4a39-8370-e96ca1a8c041,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-7267d860-2969-4030-beda-8a6be0030888,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-29795050-3673-4131-9a5e-65351d249fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-ffba3a33-0799-4598-bfe4-726ff6d80228,DISK], DatanodeInfoWithStorage[127.0.0.1:41314,DS-29d2996e-5949-4e99-8ced-c3b0813eef06,DISK], DatanodeInfoWithStorage[127.0.0.1:45497,DS-8147b93a-aa7a-4790-ab63-d339d3964a5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-811397311-172.17.0.11-1597330222762:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37512,DS-be453b6c-76be-4e4e-9d23-0983c77d354e,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-61b15a26-22cc-4c9f-9c41-1d537ea5cf88,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-89004b10-4867-498b-82e6-e88f773af6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-b52ee6ff-221f-47f2-9009-ee086a278cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-d59ae573-bec4-4542-974a-c20018053da0,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-070bcc38-5f42-48dd-8bfd-5092a857f4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-83559256-42fe-4d23-8eca-1feee3f7b2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-a217eb33-bef0-4aa0-a156-64262b46bf07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-811397311-172.17.0.11-1597330222762:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37512,DS-be453b6c-76be-4e4e-9d23-0983c77d354e,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-61b15a26-22cc-4c9f-9c41-1d537ea5cf88,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-89004b10-4867-498b-82e6-e88f773af6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-b52ee6ff-221f-47f2-9009-ee086a278cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-d59ae573-bec4-4542-974a-c20018053da0,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-070bcc38-5f42-48dd-8bfd-5092a857f4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-83559256-42fe-4d23-8eca-1feee3f7b2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-a217eb33-bef0-4aa0-a156-64262b46bf07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2015228827-172.17.0.11-1597330442019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35755,DS-c46643c3-c9c7-4441-90c4-d5b5f12363a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-36de7a2f-fd8f-4982-9130-2236e3267bab,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-c0db92f5-2a38-4fe5-b016-9da28afccfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-02e943ef-3195-4cd1-ac4a-7249272cd64d,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-d0d2d29b-4333-4abe-8487-2824b9467a93,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-1c0dbfed-f049-4e78-8e6e-cce520e8b598,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-30d95469-ba74-4944-b370-612c33829fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-f160fcd1-1afa-4edd-b308-5556a89a7a0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2015228827-172.17.0.11-1597330442019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35755,DS-c46643c3-c9c7-4441-90c4-d5b5f12363a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-36de7a2f-fd8f-4982-9130-2236e3267bab,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-c0db92f5-2a38-4fe5-b016-9da28afccfc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-02e943ef-3195-4cd1-ac4a-7249272cd64d,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-d0d2d29b-4333-4abe-8487-2824b9467a93,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-1c0dbfed-f049-4e78-8e6e-cce520e8b598,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-30d95469-ba74-4944-b370-612c33829fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-f160fcd1-1afa-4edd-b308-5556a89a7a0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1517436562-172.17.0.11-1597330887452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38038,DS-4da9f738-4633-49cc-b98d-bc63dd183e62,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-92b5f80b-0c11-40db-b787-caed395427c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-b9dfd8ec-fcc4-4df9-86cb-3511f41aa55d,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-c924abce-78e5-4aa1-8466-531a9f512d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-962146ac-330a-44ff-8500-b56c602d2d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-7bb9b75d-436d-47f7-8fe1-5626d7ef1332,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-e54630ad-b4cb-4002-903f-4f408eb4efec,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-81f1903e-4f81-49b8-a7cb-9919fcbbe568,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1517436562-172.17.0.11-1597330887452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38038,DS-4da9f738-4633-49cc-b98d-bc63dd183e62,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-92b5f80b-0c11-40db-b787-caed395427c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-b9dfd8ec-fcc4-4df9-86cb-3511f41aa55d,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-c924abce-78e5-4aa1-8466-531a9f512d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36460,DS-962146ac-330a-44ff-8500-b56c602d2d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-7bb9b75d-436d-47f7-8fe1-5626d7ef1332,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-e54630ad-b4cb-4002-903f-4f408eb4efec,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-81f1903e-4f81-49b8-a7cb-9919fcbbe568,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1956894573-172.17.0.11-1597331098554:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44728,DS-b2603fe7-aa52-40d0-951e-b280201aa75d,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-8744c288-0a07-452c-aa3b-6e4339ae0dae,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-c6a339bf-5ac8-4a8d-9e79-eb79f5ec449c,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-2441324d-cb0f-436e-a40f-e8dda0a45443,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-996a8e24-6715-4a93-a5d9-ec904e77cd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-72e04265-d8df-4c99-b143-8fe6c093c6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-add81bd5-f15f-4565-90fe-c6ba26f59d19,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-d672f1e6-0d74-4882-a150-7468f8e2679a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1956894573-172.17.0.11-1597331098554:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44728,DS-b2603fe7-aa52-40d0-951e-b280201aa75d,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-8744c288-0a07-452c-aa3b-6e4339ae0dae,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-c6a339bf-5ac8-4a8d-9e79-eb79f5ec449c,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-2441324d-cb0f-436e-a40f-e8dda0a45443,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-996a8e24-6715-4a93-a5d9-ec904e77cd9f,DISK], DatanodeInfoWithStorage[127.0.0.1:44410,DS-72e04265-d8df-4c99-b143-8fe6c093c6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-add81bd5-f15f-4565-90fe-c6ba26f59d19,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-d672f1e6-0d74-4882-a150-7468f8e2679a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-716844006-172.17.0.11-1597331166700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46228,DS-2d18d3e1-848e-4a8a-a98b-461fe96b2b91,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-269e1a82-f4e7-4dd3-afd9-2b62cbe62f68,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-b2152540-043d-4bc9-b23e-ba4b0a910d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-b2a15c16-1acb-42ae-bfe9-b5ca31204a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-1eb75e1e-50db-4fd8-a0bf-f83b32a67850,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-236c5f38-a140-4146-89ee-f81f033aed91,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-cee8703a-0ce5-473f-8c14-9076331393c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-338b4661-4e48-4057-9941-e8089e7179ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-716844006-172.17.0.11-1597331166700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46228,DS-2d18d3e1-848e-4a8a-a98b-461fe96b2b91,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-269e1a82-f4e7-4dd3-afd9-2b62cbe62f68,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-b2152540-043d-4bc9-b23e-ba4b0a910d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-b2a15c16-1acb-42ae-bfe9-b5ca31204a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41411,DS-1eb75e1e-50db-4fd8-a0bf-f83b32a67850,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-236c5f38-a140-4146-89ee-f81f033aed91,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-cee8703a-0ce5-473f-8c14-9076331393c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-338b4661-4e48-4057-9941-e8089e7179ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1761692343-172.17.0.11-1597331412490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34016,DS-55149dc1-5c8d-47a5-b28f-d2d5eaf6003d,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-a3db8f62-1a7b-4e98-98e3-8f4602e429e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-959080d3-835e-4171-83bb-b52b21ee752c,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-6eff8912-ea17-4679-87fd-87edcdc07bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-6c95978b-39ae-4094-b652-b61b25a28a06,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-8869f54f-933f-4bc0-8d57-56c1d2c0593b,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-c936391c-cf1f-466b-a3ee-f6d4572aaae7,DISK], DatanodeInfoWithStorage[127.0.0.1:39291,DS-c39b7150-2163-44af-8bee-0bafcb5e4d3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1761692343-172.17.0.11-1597331412490:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34016,DS-55149dc1-5c8d-47a5-b28f-d2d5eaf6003d,DISK], DatanodeInfoWithStorage[127.0.0.1:34624,DS-a3db8f62-1a7b-4e98-98e3-8f4602e429e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-959080d3-835e-4171-83bb-b52b21ee752c,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-6eff8912-ea17-4679-87fd-87edcdc07bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-6c95978b-39ae-4094-b652-b61b25a28a06,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-8869f54f-933f-4bc0-8d57-56c1d2c0593b,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-c936391c-cf1f-466b-a3ee-f6d4572aaae7,DISK], DatanodeInfoWithStorage[127.0.0.1:39291,DS-c39b7150-2163-44af-8bee-0bafcb5e4d3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1124856166-172.17.0.11-1597331557818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45433,DS-b8a15374-e907-46f8-b432-8902a02ba4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-79d7edbb-ce31-4470-9e32-4cf7bd9061df,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-663ae023-b76c-43b4-b5f2-6989c0a4e7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-004b3560-9722-46fb-abc8-aff53d71fe71,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-e326ad1b-08ec-472c-818a-f1dbee71b9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-fa7e444f-7ff8-4c92-9137-dcf82ef3333f,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-18c3e97f-1b99-4ba8-8ba1-4b363e9fd012,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-37a5ebb0-951d-46a2-907b-6eb79fef6ca6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1124856166-172.17.0.11-1597331557818:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45433,DS-b8a15374-e907-46f8-b432-8902a02ba4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-79d7edbb-ce31-4470-9e32-4cf7bd9061df,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-663ae023-b76c-43b4-b5f2-6989c0a4e7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-004b3560-9722-46fb-abc8-aff53d71fe71,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-e326ad1b-08ec-472c-818a-f1dbee71b9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-fa7e444f-7ff8-4c92-9137-dcf82ef3333f,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-18c3e97f-1b99-4ba8-8ba1-4b363e9fd012,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-37a5ebb0-951d-46a2-907b-6eb79fef6ca6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1990350589-172.17.0.11-1597331816582:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33391,DS-7c8f45ec-7a35-4f44-b81c-5292f0353b10,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-124dac6b-b488-4dfc-95f8-2a8fc60eb6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-f3cb3493-90ab-4508-95b7-da3845a41d99,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-d0778cfa-a521-49cc-aeef-72efb9435d73,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-cc261d1e-94f6-4907-bed8-bad9adecf062,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-7621d615-3b4b-4af1-9008-8ae78c423ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-5486478e-32d7-4e4a-b381-bb94d9f6602e,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-1bdc950e-bc4d-47d7-aa3d-0f39539fcf0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1990350589-172.17.0.11-1597331816582:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33391,DS-7c8f45ec-7a35-4f44-b81c-5292f0353b10,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-124dac6b-b488-4dfc-95f8-2a8fc60eb6ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-f3cb3493-90ab-4508-95b7-da3845a41d99,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-d0778cfa-a521-49cc-aeef-72efb9435d73,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-cc261d1e-94f6-4907-bed8-bad9adecf062,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-7621d615-3b4b-4af1-9008-8ae78c423ebf,DISK], DatanodeInfoWithStorage[127.0.0.1:38904,DS-5486478e-32d7-4e4a-b381-bb94d9f6602e,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-1bdc950e-bc4d-47d7-aa3d-0f39539fcf0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1994796326-172.17.0.11-1597332723079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40118,DS-d383a111-71eb-4284-8ea9-ea9a564f0777,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-1f3de3f1-6e9b-45ef-a890-98125077c6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-ef8fbe0a-ace9-44e9-b2e2-be121012e23b,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-a4bbf686-c4e7-4aa7-b0c3-3e27d2c530dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-9a168b2c-9d96-435b-bc70-71b0abbb4c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-1c1c1e77-a34e-40be-94c0-6e276219bfbd,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-59f0a5fc-88bb-45e1-aa77-9841f3326261,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-11d29c70-db2b-4ab5-afcc-71b5504762fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1994796326-172.17.0.11-1597332723079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40118,DS-d383a111-71eb-4284-8ea9-ea9a564f0777,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-1f3de3f1-6e9b-45ef-a890-98125077c6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42236,DS-ef8fbe0a-ace9-44e9-b2e2-be121012e23b,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-a4bbf686-c4e7-4aa7-b0c3-3e27d2c530dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-9a168b2c-9d96-435b-bc70-71b0abbb4c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37710,DS-1c1c1e77-a34e-40be-94c0-6e276219bfbd,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-59f0a5fc-88bb-45e1-aa77-9841f3326261,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-11d29c70-db2b-4ab5-afcc-71b5504762fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1395657698-172.17.0.11-1597332922305:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42316,DS-e0c01cfc-b6df-42ef-a7bb-29b0b1187e63,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-5941666b-6dea-4d82-a0f3-867a5637c973,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-324c7c9d-4288-4be2-b2e9-1f2a3110e08c,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-f449b356-2ffd-4655-8236-227d8772bc98,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-7d58483e-1af9-4dd6-882e-a6a4cd2ece71,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-7ec0dca0-dbc9-433c-b6ca-7c6f4fac7af5,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-881e4750-444d-48b6-8b12-eec2e40830f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33560,DS-9f84441e-9760-46bf-b3ae-689fab5c2f74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1395657698-172.17.0.11-1597332922305:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42316,DS-e0c01cfc-b6df-42ef-a7bb-29b0b1187e63,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-5941666b-6dea-4d82-a0f3-867a5637c973,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-324c7c9d-4288-4be2-b2e9-1f2a3110e08c,DISK], DatanodeInfoWithStorage[127.0.0.1:43810,DS-f449b356-2ffd-4655-8236-227d8772bc98,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-7d58483e-1af9-4dd6-882e-a6a4cd2ece71,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-7ec0dca0-dbc9-433c-b6ca-7c6f4fac7af5,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-881e4750-444d-48b6-8b12-eec2e40830f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33560,DS-9f84441e-9760-46bf-b3ae-689fab5c2f74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-606959282-172.17.0.11-1597334027304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35003,DS-5ce58c46-5446-4df7-9c56-2c80e28d75f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-d54a54c9-2119-44e8-bce8-1d527f8adb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-501f6795-943b-4d95-b968-ea3b9a67ddb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-f63f674c-3bfe-42e6-9658-e59ef8e32761,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-7d1b067d-1be9-4af8-abdf-7698752b2e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-1165a8d7-26ff-421b-a37f-5e803e3d55a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-b764fb77-e6e2-4053-9931-d782cd5ea98e,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-25b46d0d-d1f5-4413-b979-2349f7755822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-606959282-172.17.0.11-1597334027304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35003,DS-5ce58c46-5446-4df7-9c56-2c80e28d75f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-d54a54c9-2119-44e8-bce8-1d527f8adb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-501f6795-943b-4d95-b968-ea3b9a67ddb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-f63f674c-3bfe-42e6-9658-e59ef8e32761,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-7d1b067d-1be9-4af8-abdf-7698752b2e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39976,DS-1165a8d7-26ff-421b-a37f-5e803e3d55a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-b764fb77-e6e2-4053-9931-d782cd5ea98e,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-25b46d0d-d1f5-4413-b979-2349f7755822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-11406764-172.17.0.11-1597334096748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38549,DS-2a2ef98f-34e0-422e-afe6-7724504084b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-c165b11a-7cd4-488f-89c8-afd0f73b6ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-62099857-5da1-4326-99ca-c77e012a435a,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-a47f7610-b68c-4ebd-9150-b58303eae42d,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-1edf8f31-86f3-4412-8c1d-900b2f9e923b,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-03ae9ccd-f6e0-493d-987a-b87e2b554ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-b88aea25-2c78-4a3c-b9ee-5cbb75397deb,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-e484b61f-4322-4c83-830b-04247a7bea21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-11406764-172.17.0.11-1597334096748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38549,DS-2a2ef98f-34e0-422e-afe6-7724504084b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-c165b11a-7cd4-488f-89c8-afd0f73b6ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-62099857-5da1-4326-99ca-c77e012a435a,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-a47f7610-b68c-4ebd-9150-b58303eae42d,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-1edf8f31-86f3-4412-8c1d-900b2f9e923b,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-03ae9ccd-f6e0-493d-987a-b87e2b554ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-b88aea25-2c78-4a3c-b9ee-5cbb75397deb,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-e484b61f-4322-4c83-830b-04247a7bea21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5399
