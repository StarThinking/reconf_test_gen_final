reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1938708517-172.17.0.4-1597512306927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43683,DS-265ce4f2-4d3f-4327-9540-b9d948749ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-0c5e4f17-7780-4426-8526-28c4ea8468b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-fb39eb91-4b3c-4bcf-9b5b-79cb6f750c89,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-cd8e4f8b-cd97-4ff0-8899-b21d546650d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-869a776f-3c4c-4d16-a7e9-08afd15d9ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-b59f446b-7031-458a-8dd6-3a7064805388,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-b3644423-6e7b-42db-bfce-8c8ab4929469,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-583f30ad-76f9-4938-bf71-b91ae829cf68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1938708517-172.17.0.4-1597512306927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43683,DS-265ce4f2-4d3f-4327-9540-b9d948749ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:45576,DS-0c5e4f17-7780-4426-8526-28c4ea8468b4,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-fb39eb91-4b3c-4bcf-9b5b-79cb6f750c89,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-cd8e4f8b-cd97-4ff0-8899-b21d546650d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38197,DS-869a776f-3c4c-4d16-a7e9-08afd15d9ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-b59f446b-7031-458a-8dd6-3a7064805388,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-b3644423-6e7b-42db-bfce-8c8ab4929469,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-583f30ad-76f9-4938-bf71-b91ae829cf68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-437177051-172.17.0.4-1597512537137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36040,DS-b8762082-39ea-4c0d-90ac-714b2d31ae08,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-0bcd0222-4f52-4b9d-87f4-41cad6e63045,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-44d8e959-1305-4b6a-9866-d0dc4f65aefb,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-53facd47-7a2d-4de5-9ff3-ad88b3366d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-443596fb-9840-4781-926e-ff5a77d032b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-68af7df9-f625-4c11-8750-86c48a49fcef,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-bcee9427-8598-4531-b9a4-ce3a94198ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-7e68adab-f1e1-4f72-b339-c7b23bf3244f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-437177051-172.17.0.4-1597512537137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36040,DS-b8762082-39ea-4c0d-90ac-714b2d31ae08,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-0bcd0222-4f52-4b9d-87f4-41cad6e63045,DISK], DatanodeInfoWithStorage[127.0.0.1:41028,DS-44d8e959-1305-4b6a-9866-d0dc4f65aefb,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-53facd47-7a2d-4de5-9ff3-ad88b3366d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-443596fb-9840-4781-926e-ff5a77d032b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-68af7df9-f625-4c11-8750-86c48a49fcef,DISK], DatanodeInfoWithStorage[127.0.0.1:35931,DS-bcee9427-8598-4531-b9a4-ce3a94198ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-7e68adab-f1e1-4f72-b339-c7b23bf3244f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638717958-172.17.0.4-1597513648546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38320,DS-a5ae6cd4-9017-4b10-bf80-223cb224ecb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-53664f30-7ec4-4c33-ac92-6fb71267960d,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-5b559f21-40c3-4d26-aca4-dd1669c012a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-5aec2622-6ead-4cbf-836a-1a21f6d0e17d,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-72d294c7-44dd-4fb5-9286-f9fa9d1e0567,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-1a2decfb-673a-424b-8627-32fec2f643a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-4697b807-f008-4c41-95a6-927819e90dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-6d1ea62a-0866-4d51-83a6-79c47fe0b666,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-638717958-172.17.0.4-1597513648546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38320,DS-a5ae6cd4-9017-4b10-bf80-223cb224ecb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-53664f30-7ec4-4c33-ac92-6fb71267960d,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-5b559f21-40c3-4d26-aca4-dd1669c012a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-5aec2622-6ead-4cbf-836a-1a21f6d0e17d,DISK], DatanodeInfoWithStorage[127.0.0.1:45767,DS-72d294c7-44dd-4fb5-9286-f9fa9d1e0567,DISK], DatanodeInfoWithStorage[127.0.0.1:39664,DS-1a2decfb-673a-424b-8627-32fec2f643a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-4697b807-f008-4c41-95a6-927819e90dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35580,DS-6d1ea62a-0866-4d51-83a6-79c47fe0b666,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1309546880-172.17.0.4-1597514111125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36502,DS-e08d42b6-fc89-4b31-b562-5da89c9f0da4,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-b5d002cf-be42-4919-91b6-010ff204ca50,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-e39853bf-e1af-42d2-a2be-b36e1200a4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-f427d08d-d95b-4724-8ff3-420a99050847,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-480ac088-8e2d-4593-9af2-5ce104873070,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-81ab000e-fcf4-4612-8bd6-92d6d7f7cae0,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-b4b9b27c-4db7-45c1-8e12-d336b685dd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-c0b75d28-3a0f-4219-9b02-0af4e2225a63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1309546880-172.17.0.4-1597514111125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36502,DS-e08d42b6-fc89-4b31-b562-5da89c9f0da4,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-b5d002cf-be42-4919-91b6-010ff204ca50,DISK], DatanodeInfoWithStorage[127.0.0.1:34430,DS-e39853bf-e1af-42d2-a2be-b36e1200a4bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44554,DS-f427d08d-d95b-4724-8ff3-420a99050847,DISK], DatanodeInfoWithStorage[127.0.0.1:35983,DS-480ac088-8e2d-4593-9af2-5ce104873070,DISK], DatanodeInfoWithStorage[127.0.0.1:41558,DS-81ab000e-fcf4-4612-8bd6-92d6d7f7cae0,DISK], DatanodeInfoWithStorage[127.0.0.1:45621,DS-b4b9b27c-4db7-45c1-8e12-d336b685dd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-c0b75d28-3a0f-4219-9b02-0af4e2225a63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-724207672-172.17.0.4-1597514247669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42982,DS-32a5c56b-d050-4e0e-a1c2-e8c138245974,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-1ba7dbe1-b193-45f9-b6fa-5b7fffa40ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-591fd9c5-c239-431d-8fc4-cb4a016ea4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-05b3dd5b-c9e7-4f0b-bc3c-d6bccc840ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-88cda2b3-0b30-4da4-9c76-200a4315462b,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-621acc48-3385-4f51-8820-efcc5740f2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-e318163a-9f82-4daf-856f-86e81e380f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-ba64288d-4b8c-4b3b-b3b0-fbd427e8a6b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-724207672-172.17.0.4-1597514247669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42982,DS-32a5c56b-d050-4e0e-a1c2-e8c138245974,DISK], DatanodeInfoWithStorage[127.0.0.1:36864,DS-1ba7dbe1-b193-45f9-b6fa-5b7fffa40ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-591fd9c5-c239-431d-8fc4-cb4a016ea4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-05b3dd5b-c9e7-4f0b-bc3c-d6bccc840ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-88cda2b3-0b30-4da4-9c76-200a4315462b,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-621acc48-3385-4f51-8820-efcc5740f2d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-e318163a-9f82-4daf-856f-86e81e380f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-ba64288d-4b8c-4b3b-b3b0-fbd427e8a6b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-369642231-172.17.0.4-1597514508810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42568,DS-0203f3fa-4ede-40a7-8d49-cc4204605ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-178491c2-3776-451c-ae2a-5d85c4112f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-81e7b4bc-adf8-429b-bd97-080b97d2ba5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-21c2f450-4c74-47bf-bc41-93f66f851756,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-58e278a0-7522-4669-ac7b-56d44958d6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-d8da73fd-836b-4d39-b9e9-787a23893c79,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-1e806f8c-b76f-4712-9251-024159c9628c,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-33f9ce0f-3873-4748-95d9-77d2e2463ce1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-369642231-172.17.0.4-1597514508810:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42568,DS-0203f3fa-4ede-40a7-8d49-cc4204605ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-178491c2-3776-451c-ae2a-5d85c4112f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-81e7b4bc-adf8-429b-bd97-080b97d2ba5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-21c2f450-4c74-47bf-bc41-93f66f851756,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-58e278a0-7522-4669-ac7b-56d44958d6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-d8da73fd-836b-4d39-b9e9-787a23893c79,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-1e806f8c-b76f-4712-9251-024159c9628c,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-33f9ce0f-3873-4748-95d9-77d2e2463ce1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1093395565-172.17.0.4-1597515281423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40129,DS-c5d629f3-0496-449c-9d51-eb3d90d731de,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-95ed6f95-6966-4efd-b3a9-71a2925fd237,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-b6ed3516-eaa0-4903-9a2f-4b06711f97c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-a99329b0-f7e9-49f5-a2f7-a6dbce1abbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-bcd8f4e9-566d-469b-b802-086f3d23e982,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-7d89985f-022f-4635-809e-8759309c2c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-3e6bc33b-3966-430f-8950-7abbf837cb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-b71753e7-5439-494a-b089-02b7d1a2bed1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1093395565-172.17.0.4-1597515281423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40129,DS-c5d629f3-0496-449c-9d51-eb3d90d731de,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-95ed6f95-6966-4efd-b3a9-71a2925fd237,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-b6ed3516-eaa0-4903-9a2f-4b06711f97c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-a99329b0-f7e9-49f5-a2f7-a6dbce1abbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-bcd8f4e9-566d-469b-b802-086f3d23e982,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-7d89985f-022f-4635-809e-8759309c2c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-3e6bc33b-3966-430f-8950-7abbf837cb6f,DISK], DatanodeInfoWithStorage[127.0.0.1:45098,DS-b71753e7-5439-494a-b089-02b7d1a2bed1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1947027526-172.17.0.4-1597515356414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45971,DS-12cee87d-332f-4c03-84b2-b4fd543f0b16,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-499faa71-88ed-420a-a8a3-11a059795012,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-77a531ef-3ee0-49c3-abee-0b33ad0df9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-b50ff50a-a1d1-4f34-a755-4fb9a6ca4880,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-6de9ddf9-8dc5-4e3d-843d-1b93dca2907f,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-33d7067e-39d1-4815-9028-342397dcec86,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-37408ca8-519c-4c4e-a3c6-deb89553ec21,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-d78873b5-9b16-4ae3-9222-38443c9ea60f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1947027526-172.17.0.4-1597515356414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45971,DS-12cee87d-332f-4c03-84b2-b4fd543f0b16,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-499faa71-88ed-420a-a8a3-11a059795012,DISK], DatanodeInfoWithStorage[127.0.0.1:39003,DS-77a531ef-3ee0-49c3-abee-0b33ad0df9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:32786,DS-b50ff50a-a1d1-4f34-a755-4fb9a6ca4880,DISK], DatanodeInfoWithStorage[127.0.0.1:33344,DS-6de9ddf9-8dc5-4e3d-843d-1b93dca2907f,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-33d7067e-39d1-4815-9028-342397dcec86,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-37408ca8-519c-4c4e-a3c6-deb89553ec21,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-d78873b5-9b16-4ae3-9222-38443c9ea60f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1919260872-172.17.0.4-1597515586683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44508,DS-812e6391-417d-4e9c-8e8e-6b73a9b1036e,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-e96fc293-afe1-4c13-9419-abf5d7619fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-18ddfe3f-5ae7-49a3-94a1-8242d4f1a43c,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-78ba917c-c973-421c-ab0b-faf7e7747230,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-14affb41-4f30-48a9-8580-892efc8113ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-67960db3-2d02-495a-b26f-aefd2436ac8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-97f57e2c-055b-404b-bf02-c1c73d940642,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-550dbe31-e63e-43b3-9151-91d2f38b4c17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1919260872-172.17.0.4-1597515586683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44508,DS-812e6391-417d-4e9c-8e8e-6b73a9b1036e,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-e96fc293-afe1-4c13-9419-abf5d7619fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43933,DS-18ddfe3f-5ae7-49a3-94a1-8242d4f1a43c,DISK], DatanodeInfoWithStorage[127.0.0.1:44560,DS-78ba917c-c973-421c-ab0b-faf7e7747230,DISK], DatanodeInfoWithStorage[127.0.0.1:46359,DS-14affb41-4f30-48a9-8580-892efc8113ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-67960db3-2d02-495a-b26f-aefd2436ac8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-97f57e2c-055b-404b-bf02-c1c73d940642,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-550dbe31-e63e-43b3-9151-91d2f38b4c17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1439379172-172.17.0.4-1597515724603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44318,DS-b52ea2c8-3beb-43b1-8d91-60972286ebf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-5318e749-d1a4-417e-96b6-221bab8ea793,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-4d6061ff-73f6-4812-9676-a8b45daf546e,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-c834df6e-44a7-4a04-9826-3a949c410620,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-cc49bdb3-23b6-428f-b72d-5c23dffea202,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-445370eb-6251-4aba-80ef-fc87a0f8da9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-a26dafeb-21e6-43d1-bfc4-5c4e488cad02,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-b3dd87d5-165a-4f66-a031-1f938bf83754,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1439379172-172.17.0.4-1597515724603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44318,DS-b52ea2c8-3beb-43b1-8d91-60972286ebf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-5318e749-d1a4-417e-96b6-221bab8ea793,DISK], DatanodeInfoWithStorage[127.0.0.1:35545,DS-4d6061ff-73f6-4812-9676-a8b45daf546e,DISK], DatanodeInfoWithStorage[127.0.0.1:43124,DS-c834df6e-44a7-4a04-9826-3a949c410620,DISK], DatanodeInfoWithStorage[127.0.0.1:34853,DS-cc49bdb3-23b6-428f-b72d-5c23dffea202,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-445370eb-6251-4aba-80ef-fc87a0f8da9b,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-a26dafeb-21e6-43d1-bfc4-5c4e488cad02,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-b3dd87d5-165a-4f66-a031-1f938bf83754,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1378227790-172.17.0.4-1597515782701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33160,DS-aac46aeb-6107-4395-a49c-e344e76d6029,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-845b88cd-38ce-45b0-9801-3ac9ce855685,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-42a34b0e-601d-4def-961e-91ff6856bf30,DISK], DatanodeInfoWithStorage[127.0.0.1:39652,DS-debfb776-fa30-472f-8de2-658cb7954c08,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-7f5ffd23-e869-4718-9d78-a83f3620cb05,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-369b5d5f-855a-4330-88fa-edef43974365,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-3f6f9a62-5afd-4e7d-baec-42a049441930,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-cfc15c9a-e61e-4be0-b2a1-54371d0e4843,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1378227790-172.17.0.4-1597515782701:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33160,DS-aac46aeb-6107-4395-a49c-e344e76d6029,DISK], DatanodeInfoWithStorage[127.0.0.1:45848,DS-845b88cd-38ce-45b0-9801-3ac9ce855685,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-42a34b0e-601d-4def-961e-91ff6856bf30,DISK], DatanodeInfoWithStorage[127.0.0.1:39652,DS-debfb776-fa30-472f-8de2-658cb7954c08,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-7f5ffd23-e869-4718-9d78-a83f3620cb05,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-369b5d5f-855a-4330-88fa-edef43974365,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-3f6f9a62-5afd-4e7d-baec-42a049441930,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-cfc15c9a-e61e-4be0-b2a1-54371d0e4843,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2131182175-172.17.0.4-1597515907843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42002,DS-dc57b4a2-8ad5-4287-9441-0c6c72e5f7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-06c0b5f6-a259-482a-8e65-2b7ef431021a,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-8ddc6590-c85c-4ab8-9396-6eab79814524,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-4e93e429-750d-4ebd-bd76-cf747c158821,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-5b528fdc-61e4-4fc6-90be-ea8e206aab6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-bb52963c-79d0-441a-900f-c539a2f48eba,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-207414d4-91d8-4d14-a657-75dd5e22a0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-1ff1917c-469f-468b-9a17-eb78983afd31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2131182175-172.17.0.4-1597515907843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42002,DS-dc57b4a2-8ad5-4287-9441-0c6c72e5f7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-06c0b5f6-a259-482a-8e65-2b7ef431021a,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-8ddc6590-c85c-4ab8-9396-6eab79814524,DISK], DatanodeInfoWithStorage[127.0.0.1:40090,DS-4e93e429-750d-4ebd-bd76-cf747c158821,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-5b528fdc-61e4-4fc6-90be-ea8e206aab6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-bb52963c-79d0-441a-900f-c539a2f48eba,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-207414d4-91d8-4d14-a657-75dd5e22a0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-1ff1917c-469f-468b-9a17-eb78983afd31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-755305031-172.17.0.4-1597516482747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32984,DS-0af68ed1-7eea-4a2a-8461-b58912383cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-a31f7f57-5a70-4534-b90e-dd2bc39dd0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-587b0ace-7ca8-4f23-9144-0327f75afea5,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-afd334fe-a98d-45c2-8432-13e217fa92f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-a431cf3c-e5e7-4652-aeb0-22469ae2b8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-41474ce7-0a9f-4105-a00b-bc997506ef6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-bf11cf3b-6600-48d9-a60e-318130f55f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-2a84851d-0c17-42e7-89e5-ad75d2b6d7cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-755305031-172.17.0.4-1597516482747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32984,DS-0af68ed1-7eea-4a2a-8461-b58912383cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-a31f7f57-5a70-4534-b90e-dd2bc39dd0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-587b0ace-7ca8-4f23-9144-0327f75afea5,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-afd334fe-a98d-45c2-8432-13e217fa92f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-a431cf3c-e5e7-4652-aeb0-22469ae2b8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36192,DS-41474ce7-0a9f-4105-a00b-bc997506ef6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-bf11cf3b-6600-48d9-a60e-318130f55f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-2a84851d-0c17-42e7-89e5-ad75d2b6d7cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22599983-172.17.0.4-1597516777864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39971,DS-dc5790bc-9819-4aaf-aa29-4f99b2af1b59,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-5d191c90-9297-45af-8219-c2e161179d72,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-c21cf5b7-3b54-4a57-a583-1901121dea28,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-25f5f055-c892-42a8-8593-a50100625f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-08ae2549-c190-433b-8c2b-1650815e966b,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-87a8de0b-c7fd-47e1-910e-1c0577b8e947,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-3eebbd9e-74c8-4266-ba61-e142273ac965,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-dd9d4e26-99d2-4769-a64e-eb2c902875f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22599983-172.17.0.4-1597516777864:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39971,DS-dc5790bc-9819-4aaf-aa29-4f99b2af1b59,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-5d191c90-9297-45af-8219-c2e161179d72,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-c21cf5b7-3b54-4a57-a583-1901121dea28,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-25f5f055-c892-42a8-8593-a50100625f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-08ae2549-c190-433b-8c2b-1650815e966b,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-87a8de0b-c7fd-47e1-910e-1c0577b8e947,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-3eebbd9e-74c8-4266-ba61-e142273ac965,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-dd9d4e26-99d2-4769-a64e-eb2c902875f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1007740807-172.17.0.4-1597516867364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34030,DS-11552d75-82c4-46a0-96ec-f3380dab78fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-beef13e1-e1e9-42df-9b23-113646ffeaca,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-54b9ed88-fa25-4971-9d6a-feacf402200b,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-454a71c9-0c8d-40b6-a3b4-8bc5e966ae3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-240d373c-b876-4cf2-9f33-31dd7f91b20d,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-687429dc-6dea-4ed8-90e9-8b8dd2a7c63c,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-edf1ba68-5561-43a8-8e61-61e7728d21da,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-35172ba8-f56d-4dfd-be7a-55aee3a65a9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1007740807-172.17.0.4-1597516867364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34030,DS-11552d75-82c4-46a0-96ec-f3380dab78fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43096,DS-beef13e1-e1e9-42df-9b23-113646ffeaca,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-54b9ed88-fa25-4971-9d6a-feacf402200b,DISK], DatanodeInfoWithStorage[127.0.0.1:44657,DS-454a71c9-0c8d-40b6-a3b4-8bc5e966ae3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-240d373c-b876-4cf2-9f33-31dd7f91b20d,DISK], DatanodeInfoWithStorage[127.0.0.1:35338,DS-687429dc-6dea-4ed8-90e9-8b8dd2a7c63c,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-edf1ba68-5561-43a8-8e61-61e7728d21da,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-35172ba8-f56d-4dfd-be7a-55aee3a65a9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1269311761-172.17.0.4-1597517064818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41873,DS-c7ec0eb9-4002-45b5-a737-f1d1de7643a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-f1343a0b-0753-4631-925d-be8a6139a117,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-0e1479c1-3ba2-4ecf-a33e-3203c2dc3977,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-a2143cb2-3e7f-449d-9694-9149543d399b,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-0e9fefb0-c0bf-4bfe-b9bd-9b72cd9482f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-41eb48e4-c939-49d6-82f9-ef1268049f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-084f8eac-3b97-451a-a030-dbda54298d06,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-efc13501-0174-4f57-9eab-da6d36b0b7d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1269311761-172.17.0.4-1597517064818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41873,DS-c7ec0eb9-4002-45b5-a737-f1d1de7643a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-f1343a0b-0753-4631-925d-be8a6139a117,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-0e1479c1-3ba2-4ecf-a33e-3203c2dc3977,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-a2143cb2-3e7f-449d-9694-9149543d399b,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-0e9fefb0-c0bf-4bfe-b9bd-9b72cd9482f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33482,DS-41eb48e4-c939-49d6-82f9-ef1268049f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-084f8eac-3b97-451a-a030-dbda54298d06,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-efc13501-0174-4f57-9eab-da6d36b0b7d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542102021-172.17.0.4-1597517325248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45689,DS-a0846190-6a08-45a6-af9f-d39267d8c880,DISK], DatanodeInfoWithStorage[127.0.0.1:36700,DS-c3c09938-fbd3-436a-a245-a3c99b6d794e,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-579053c0-8ce4-4f10-b7f0-a6f6e11edfb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-c1576220-99d8-4222-954f-3c6f6e57b392,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-a9dc462c-78dd-4972-8cf5-857e871d2c32,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-cba6db78-4525-49f9-9d79-ef6ad51ccef6,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-9b6d2b92-98a1-4211-8e25-d1375e9ff813,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-a941dd27-d2ff-4841-9a72-a201260096c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542102021-172.17.0.4-1597517325248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45689,DS-a0846190-6a08-45a6-af9f-d39267d8c880,DISK], DatanodeInfoWithStorage[127.0.0.1:36700,DS-c3c09938-fbd3-436a-a245-a3c99b6d794e,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-579053c0-8ce4-4f10-b7f0-a6f6e11edfb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-c1576220-99d8-4222-954f-3c6f6e57b392,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-a9dc462c-78dd-4972-8cf5-857e871d2c32,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-cba6db78-4525-49f9-9d79-ef6ad51ccef6,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-9b6d2b92-98a1-4211-8e25-d1375e9ff813,DISK], DatanodeInfoWithStorage[127.0.0.1:39810,DS-a941dd27-d2ff-4841-9a72-a201260096c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1586995538-172.17.0.4-1597517551742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37160,DS-55de5c77-6220-41bd-af8b-4923974cb494,DISK], DatanodeInfoWithStorage[127.0.0.1:36787,DS-bfeadc53-818d-4749-9d1d-c95564dbf99a,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-fd257d19-086a-4dea-94c2-79a13c9b8c01,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-9a200ed3-91e6-4a0c-a55f-0922022a87d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-d49843b6-23b0-4729-b1a4-75f36503389c,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-e12137c8-e78f-4637-ac9b-6fc94824b854,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-1bd81c6a-687f-4aae-b3db-6df52aa8b497,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-26f775df-1ae5-4e56-9a6d-5fba80e886f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1586995538-172.17.0.4-1597517551742:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37160,DS-55de5c77-6220-41bd-af8b-4923974cb494,DISK], DatanodeInfoWithStorage[127.0.0.1:36787,DS-bfeadc53-818d-4749-9d1d-c95564dbf99a,DISK], DatanodeInfoWithStorage[127.0.0.1:37203,DS-fd257d19-086a-4dea-94c2-79a13c9b8c01,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-9a200ed3-91e6-4a0c-a55f-0922022a87d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-d49843b6-23b0-4729-b1a4-75f36503389c,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-e12137c8-e78f-4637-ac9b-6fc94824b854,DISK], DatanodeInfoWithStorage[127.0.0.1:40936,DS-1bd81c6a-687f-4aae-b3db-6df52aa8b497,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-26f775df-1ae5-4e56-9a6d-5fba80e886f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.key.update.interval
component: hdfs:NameNode
v1: 6
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954450076-172.17.0.4-1597518567060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32975,DS-35c9af22-fb9a-4583-9530-13e0b7e6be4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-e9ea5f2a-3522-43ca-a3b1-de02de67d871,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-bdcfb290-9703-4791-9f82-54368e7e3d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-20dcc65d-c524-407d-912f-21336e10e164,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-b88860b4-3a5d-46e8-b5c4-aca30be5a3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-7fd4e736-67ea-407a-bebd-c35b1c10f354,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-c574a774-e66b-43e6-9ea1-840417c2d73a,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-3ef714b1-7d5a-4994-a801-ee7bc4dc61a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1954450076-172.17.0.4-1597518567060:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32975,DS-35c9af22-fb9a-4583-9530-13e0b7e6be4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-e9ea5f2a-3522-43ca-a3b1-de02de67d871,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-bdcfb290-9703-4791-9f82-54368e7e3d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-20dcc65d-c524-407d-912f-21336e10e164,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-b88860b4-3a5d-46e8-b5c4-aca30be5a3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-7fd4e736-67ea-407a-bebd-c35b1c10f354,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-c574a774-e66b-43e6-9ea1-840417c2d73a,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-3ef714b1-7d5a-4994-a801-ee7bc4dc61a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6939
