reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1461774530-172.17.0.8-1597338185457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39917,DS-1d98f6f2-83fc-4db9-b886-3b0f32d07824,DISK], DatanodeInfoWithStorage[127.0.0.1:41254,DS-4a0c6de1-0d1f-4f5b-bda6-dbbaa23d396e,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-9e1c6586-4bfc-4c33-9234-db00c3c37199,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-ebf73717-c571-43bd-a46b-f46c4ca101b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-5d342c34-fadc-48d6-be35-9f2c9bf5d467,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-a94c7b0e-8071-491f-a4e6-57cd6632e431,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-3776e88c-1316-4f00-9f7b-c35782c19905,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-513478dc-c702-4cb7-8379-061092012b3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1461774530-172.17.0.8-1597338185457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39917,DS-1d98f6f2-83fc-4db9-b886-3b0f32d07824,DISK], DatanodeInfoWithStorage[127.0.0.1:41254,DS-4a0c6de1-0d1f-4f5b-bda6-dbbaa23d396e,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-9e1c6586-4bfc-4c33-9234-db00c3c37199,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-ebf73717-c571-43bd-a46b-f46c4ca101b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-5d342c34-fadc-48d6-be35-9f2c9bf5d467,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-a94c7b0e-8071-491f-a4e6-57cd6632e431,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-3776e88c-1316-4f00-9f7b-c35782c19905,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-513478dc-c702-4cb7-8379-061092012b3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1621935862-172.17.0.8-1597338995207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43904,DS-ba197ce3-6d54-4fd3-920a-d94d9544af51,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-0278cc4d-3679-4533-934d-8ce11789d169,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-945f0e92-f187-4944-b092-6c67ef9b81d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-7699e89f-5452-4d46-ba4e-35c7b3da8396,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-ee14e063-6d9d-43ff-beb3-08b2671280ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-c532a9c2-57e3-4e8a-aa6f-6cda91fbeb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-aae883a7-b632-4894-9a37-50e3df973124,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-9f6e6870-d11a-49ce-ae94-c15c27039f34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1621935862-172.17.0.8-1597338995207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43904,DS-ba197ce3-6d54-4fd3-920a-d94d9544af51,DISK], DatanodeInfoWithStorage[127.0.0.1:36707,DS-0278cc4d-3679-4533-934d-8ce11789d169,DISK], DatanodeInfoWithStorage[127.0.0.1:40639,DS-945f0e92-f187-4944-b092-6c67ef9b81d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-7699e89f-5452-4d46-ba4e-35c7b3da8396,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-ee14e063-6d9d-43ff-beb3-08b2671280ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-c532a9c2-57e3-4e8a-aa6f-6cda91fbeb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-aae883a7-b632-4894-9a37-50e3df973124,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-9f6e6870-d11a-49ce-ae94-c15c27039f34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1657189771-172.17.0.8-1597339091686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40111,DS-2dbee5d9-5e16-4447-bf60-f974d83a1592,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-915e8b7e-ca3f-4bfc-904a-fb4cc355d512,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-5ea780c9-27ea-4a44-9844-536a0f3d1f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-418733d7-396f-4c99-b303-aec4f98eb386,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-68784595-d61b-4166-ac42-84075655563c,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-85f9df80-5d5a-4582-aa8d-cdcedfb1aa43,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-b47d6e3b-16b5-44e4-bac4-189b9e049534,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-aa330e5a-3b00-42f7-a630-272a15449593,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1657189771-172.17.0.8-1597339091686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40111,DS-2dbee5d9-5e16-4447-bf60-f974d83a1592,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-915e8b7e-ca3f-4bfc-904a-fb4cc355d512,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-5ea780c9-27ea-4a44-9844-536a0f3d1f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-418733d7-396f-4c99-b303-aec4f98eb386,DISK], DatanodeInfoWithStorage[127.0.0.1:38771,DS-68784595-d61b-4166-ac42-84075655563c,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-85f9df80-5d5a-4582-aa8d-cdcedfb1aa43,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-b47d6e3b-16b5-44e4-bac4-189b9e049534,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-aa330e5a-3b00-42f7-a630-272a15449593,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1587489198-172.17.0.8-1597339934542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45658,DS-3ad7d9fd-658c-4aa1-ac5b-2456b4a4f2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-ea610287-21f7-47d8-9381-469957324b43,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-0f8778e4-d31b-4e46-923a-f3fc96857b26,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-3f9a43fa-0efd-42a4-bf0c-0d8a9752b889,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-265d7e53-aff2-4f3d-b896-fcca93361356,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-cc289d8f-fbb8-4af1-af3f-a634d2894cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-ac180bfa-e5a8-47eb-ae4c-fb1cad234f29,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-43a19797-798b-4f37-8068-cbc59dacf408,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1587489198-172.17.0.8-1597339934542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45658,DS-3ad7d9fd-658c-4aa1-ac5b-2456b4a4f2dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-ea610287-21f7-47d8-9381-469957324b43,DISK], DatanodeInfoWithStorage[127.0.0.1:39220,DS-0f8778e4-d31b-4e46-923a-f3fc96857b26,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-3f9a43fa-0efd-42a4-bf0c-0d8a9752b889,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-265d7e53-aff2-4f3d-b896-fcca93361356,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-cc289d8f-fbb8-4af1-af3f-a634d2894cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45566,DS-ac180bfa-e5a8-47eb-ae4c-fb1cad234f29,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-43a19797-798b-4f37-8068-cbc59dacf408,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1347822501-172.17.0.8-1597340178899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44560,DS-9d9110f8-6898-4a5a-ab68-df4a0e9af3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-976f9d76-236f-4468-af3d-3f58792adeed,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-9ab379d4-6ced-40e6-812d-e8e2b98e7885,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-03ae8d0f-55a7-441a-89b1-dd535c66b493,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-455d02c5-6867-47e2-bae9-21b31f89cd62,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-b5561263-f2b2-4af1-9445-75e4b386f2be,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-bd0bb440-77d4-4195-8da9-989280649e72,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-28370f66-e55d-4473-9872-7ea7d81fdf64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1347822501-172.17.0.8-1597340178899:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44560,DS-9d9110f8-6898-4a5a-ab68-df4a0e9af3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-976f9d76-236f-4468-af3d-3f58792adeed,DISK], DatanodeInfoWithStorage[127.0.0.1:36294,DS-9ab379d4-6ced-40e6-812d-e8e2b98e7885,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-03ae8d0f-55a7-441a-89b1-dd535c66b493,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-455d02c5-6867-47e2-bae9-21b31f89cd62,DISK], DatanodeInfoWithStorage[127.0.0.1:34166,DS-b5561263-f2b2-4af1-9445-75e4b386f2be,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-bd0bb440-77d4-4195-8da9-989280649e72,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-28370f66-e55d-4473-9872-7ea7d81fdf64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-625348904-172.17.0.8-1597340935565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41585,DS-c1e976a9-0f88-4ff1-9e37-68142601ea77,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-40e29849-8563-4b19-9382-ebcdf1cdd70a,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-a8f5ab30-7f65-4580-ae76-4d28f2eba00b,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-19fd9239-dc47-4173-94d8-f2807f631de8,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-0942def6-a34d-464e-9b02-9c23095dd52f,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-cabcfd6f-b2c9-4043-a1dc-bdde855978ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-12bf2c3b-13b0-4dea-92f2-0edc043214f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-77e4dc4d-d28a-4932-858f-a1f9ce722fe2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-625348904-172.17.0.8-1597340935565:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41585,DS-c1e976a9-0f88-4ff1-9e37-68142601ea77,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-40e29849-8563-4b19-9382-ebcdf1cdd70a,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-a8f5ab30-7f65-4580-ae76-4d28f2eba00b,DISK], DatanodeInfoWithStorage[127.0.0.1:44682,DS-19fd9239-dc47-4173-94d8-f2807f631de8,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-0942def6-a34d-464e-9b02-9c23095dd52f,DISK], DatanodeInfoWithStorage[127.0.0.1:39654,DS-cabcfd6f-b2c9-4043-a1dc-bdde855978ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-12bf2c3b-13b0-4dea-92f2-0edc043214f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-77e4dc4d-d28a-4932-858f-a1f9ce722fe2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1381838966-172.17.0.8-1597341969912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38736,DS-15486d0e-2a69-487b-b6d4-d4fb1973cde2,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-8574ba8a-ada5-4a77-a665-8b8e8d8548f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-c99419b7-4f6a-4f33-b1c7-4607691ba942,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-2a7890c9-c72f-4282-a557-25091650b30a,DISK], DatanodeInfoWithStorage[127.0.0.1:42528,DS-87bf28c7-c3a4-4809-9cb2-bb9c43c13691,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-ee22bf35-0ab8-4d99-82e6-dc1548deb09c,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-d7faa3a0-41d6-4500-8433-9ae8e855ddb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-0f08438b-fc11-4e72-a642-289f0ba44fa6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1381838966-172.17.0.8-1597341969912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38736,DS-15486d0e-2a69-487b-b6d4-d4fb1973cde2,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-8574ba8a-ada5-4a77-a665-8b8e8d8548f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-c99419b7-4f6a-4f33-b1c7-4607691ba942,DISK], DatanodeInfoWithStorage[127.0.0.1:33992,DS-2a7890c9-c72f-4282-a557-25091650b30a,DISK], DatanodeInfoWithStorage[127.0.0.1:42528,DS-87bf28c7-c3a4-4809-9cb2-bb9c43c13691,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-ee22bf35-0ab8-4d99-82e6-dc1548deb09c,DISK], DatanodeInfoWithStorage[127.0.0.1:43543,DS-d7faa3a0-41d6-4500-8433-9ae8e855ddb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-0f08438b-fc11-4e72-a642-289f0ba44fa6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1230816550-172.17.0.8-1597342016540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44550,DS-ed61051a-e2b6-4102-b256-0b0409dd1372,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-d1abb688-bdd1-4f2f-972d-70c41e555364,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-a1008088-0d9e-4cbd-be37-c0e4a27135bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-2bd71ba8-2308-46e6-a00b-2cea47d560cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-00f854c5-49ce-4adb-ba44-b16ca0a82259,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-892dc3e1-3f3c-45a0-a6e8-b233cdda1af0,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-f969cd8d-dae3-4461-823c-d78e63441c66,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-d91015f8-1a96-435c-ae73-dc6d85be9215,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1230816550-172.17.0.8-1597342016540:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44550,DS-ed61051a-e2b6-4102-b256-0b0409dd1372,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-d1abb688-bdd1-4f2f-972d-70c41e555364,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-a1008088-0d9e-4cbd-be37-c0e4a27135bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-2bd71ba8-2308-46e6-a00b-2cea47d560cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-00f854c5-49ce-4adb-ba44-b16ca0a82259,DISK], DatanodeInfoWithStorage[127.0.0.1:38931,DS-892dc3e1-3f3c-45a0-a6e8-b233cdda1af0,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-f969cd8d-dae3-4461-823c-d78e63441c66,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-d91015f8-1a96-435c-ae73-dc6d85be9215,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1937251583-172.17.0.8-1597342271383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42564,DS-2da211f4-2b3a-481f-83fd-4671bdf87343,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-5af7678d-9204-4f04-bc44-3b4b30ceea08,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-c53e9fc1-5633-4a50-a98b-6d34d02d3231,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-4e7d5a93-fc1c-472d-b185-78ef4bcc0658,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-8c12a465-b892-43ee-81ba-d87fac13b6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-bf8c9c1a-c8e3-4a8e-8315-c8c7fb067306,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-5cdf7768-fafd-4b39-92bf-f41be347b26b,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-5e606adc-aabc-40fb-91d8-8836a3388834,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1937251583-172.17.0.8-1597342271383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42564,DS-2da211f4-2b3a-481f-83fd-4671bdf87343,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-5af7678d-9204-4f04-bc44-3b4b30ceea08,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-c53e9fc1-5633-4a50-a98b-6d34d02d3231,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-4e7d5a93-fc1c-472d-b185-78ef4bcc0658,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-8c12a465-b892-43ee-81ba-d87fac13b6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-bf8c9c1a-c8e3-4a8e-8315-c8c7fb067306,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-5cdf7768-fafd-4b39-92bf-f41be347b26b,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-5e606adc-aabc-40fb-91d8-8836a3388834,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-482845180-172.17.0.8-1597342457647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45824,DS-b2c74358-178f-4dfe-b36e-b218b8a135d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-3d7bcb74-e091-4510-bb1b-39aaadd8b90b,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-adaea8be-eb35-45ff-9726-bf9bf7a29e60,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-7924ec33-7788-4bc9-972b-fcd9af850788,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-d46637cb-302d-4d6a-a9b5-0d9072070016,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-dbe9f2b2-493c-4e21-8b01-86adcfa0996c,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-95cdc77f-15c5-457a-a188-6bc9acf95961,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-386ed2a9-f443-4c01-bebc-9171a99a072c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-482845180-172.17.0.8-1597342457647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45824,DS-b2c74358-178f-4dfe-b36e-b218b8a135d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-3d7bcb74-e091-4510-bb1b-39aaadd8b90b,DISK], DatanodeInfoWithStorage[127.0.0.1:34045,DS-adaea8be-eb35-45ff-9726-bf9bf7a29e60,DISK], DatanodeInfoWithStorage[127.0.0.1:40808,DS-7924ec33-7788-4bc9-972b-fcd9af850788,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-d46637cb-302d-4d6a-a9b5-0d9072070016,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-dbe9f2b2-493c-4e21-8b01-86adcfa0996c,DISK], DatanodeInfoWithStorage[127.0.0.1:46629,DS-95cdc77f-15c5-457a-a188-6bc9acf95961,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-386ed2a9-f443-4c01-bebc-9171a99a072c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-663196929-172.17.0.8-1597343530128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43425,DS-8071bc7f-c76c-41cf-847d-35e5a8a70f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-4ca727d4-0f95-4588-8ce8-6bb01605e7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-896561e0-7605-46e2-840d-99bfd3d37fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-90745572-d9ee-44f8-bbd0-0d075a666cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-d43ddbd9-5d6a-4763-844a-1a33aed0d20f,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-c20b2acd-7767-4696-a464-89519fafe45d,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-c0fec557-ed1c-49c6-b0c7-2120397976f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-6365246a-3f40-4c8a-9784-06694b273d6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-663196929-172.17.0.8-1597343530128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43425,DS-8071bc7f-c76c-41cf-847d-35e5a8a70f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-4ca727d4-0f95-4588-8ce8-6bb01605e7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-896561e0-7605-46e2-840d-99bfd3d37fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-90745572-d9ee-44f8-bbd0-0d075a666cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-d43ddbd9-5d6a-4763-844a-1a33aed0d20f,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-c20b2acd-7767-4696-a464-89519fafe45d,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-c0fec557-ed1c-49c6-b0c7-2120397976f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39069,DS-6365246a-3f40-4c8a-9784-06694b273d6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1803952580-172.17.0.8-1597343961407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38493,DS-266bb668-08a8-49f8-8de8-a1af0da3b638,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-a53a849f-5a10-4525-80ce-115e3b046838,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-8d25a2ea-3cb3-4959-902f-3ba90fb9f5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-3ca313b2-5285-4db4-9651-150f09877bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-47fba298-e2bd-4662-9d20-15ef161bf6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-2081a08f-4f7f-4fe3-af49-e95a6c4e34cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-71ca3892-7eb1-4ecd-b88a-d1b78c5687c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-f973f350-f3ab-47ba-a2e3-81994b0bef7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1803952580-172.17.0.8-1597343961407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38493,DS-266bb668-08a8-49f8-8de8-a1af0da3b638,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-a53a849f-5a10-4525-80ce-115e3b046838,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-8d25a2ea-3cb3-4959-902f-3ba90fb9f5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-3ca313b2-5285-4db4-9651-150f09877bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-47fba298-e2bd-4662-9d20-15ef161bf6b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37545,DS-2081a08f-4f7f-4fe3-af49-e95a6c4e34cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-71ca3892-7eb1-4ecd-b88a-d1b78c5687c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-f973f350-f3ab-47ba-a2e3-81994b0bef7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 20000
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2095147686-172.17.0.8-1597344310495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42803,DS-c62acacb-df5b-49b3-adcb-03c7bd43a16c,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-05cfaddc-9348-4b2c-a18a-e76f0bf2ebc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-29e660c3-e2b3-4ded-934e-a879e76e843e,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-5ff10205-55ce-4398-b101-f44556a0c904,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-623fa7ba-ea47-4787-93e0-898092e5ddb1,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-5148e803-cec1-421f-948f-a7f8202ed6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-26336925-6637-4aa5-851f-be035ee07374,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-26ed49d0-16da-4829-8b37-4e06f92f7a2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2095147686-172.17.0.8-1597344310495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42803,DS-c62acacb-df5b-49b3-adcb-03c7bd43a16c,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-05cfaddc-9348-4b2c-a18a-e76f0bf2ebc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40704,DS-29e660c3-e2b3-4ded-934e-a879e76e843e,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-5ff10205-55ce-4398-b101-f44556a0c904,DISK], DatanodeInfoWithStorage[127.0.0.1:42718,DS-623fa7ba-ea47-4787-93e0-898092e5ddb1,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-5148e803-cec1-421f-948f-a7f8202ed6d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-26336925-6637-4aa5-851f-be035ee07374,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-26ed49d0-16da-4829-8b37-4e06f92f7a2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 6976
