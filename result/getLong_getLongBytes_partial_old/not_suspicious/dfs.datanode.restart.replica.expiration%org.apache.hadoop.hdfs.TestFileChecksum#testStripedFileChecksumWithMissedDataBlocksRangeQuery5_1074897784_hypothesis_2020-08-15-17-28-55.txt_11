reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-785801656-172.17.0.19-1597512836509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42549,DS-29b2356d-fa8b-4261-aa7c-c97cbd8ad113,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-194d42b2-9792-4f3e-89c5-9f16556e90d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-30b953cc-2fae-4b27-9048-48a7d016765a,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-b6074380-b201-4b52-8d2d-cfb6afe3443f,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-a34763c7-13a8-4761-aa62-d8ab78799dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-bfebd2d5-b0d3-4597-a294-59e1d2db2a85,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-a2029aee-2529-4f28-bce1-dd53a135acb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-e050353a-4c32-4229-b0fd-4e4ae3db60ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-785801656-172.17.0.19-1597512836509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42549,DS-29b2356d-fa8b-4261-aa7c-c97cbd8ad113,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-194d42b2-9792-4f3e-89c5-9f16556e90d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-30b953cc-2fae-4b27-9048-48a7d016765a,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-b6074380-b201-4b52-8d2d-cfb6afe3443f,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-a34763c7-13a8-4761-aa62-d8ab78799dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-bfebd2d5-b0d3-4597-a294-59e1d2db2a85,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-a2029aee-2529-4f28-bce1-dd53a135acb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-e050353a-4c32-4229-b0fd-4e4ae3db60ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-342591438-172.17.0.19-1597513106367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41007,DS-6fb8b1fc-5300-428e-be89-ed106423105c,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-e4261431-1734-4a0c-baf9-c440fed5f330,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-97ae9a34-7392-46ca-89f3-90506e440977,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-7c00b2ad-02e5-4d62-b494-92ae0adcad7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-1e0ce28d-babb-4eee-bd62-d28003576e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-982f871e-514a-4c34-b753-1b5c500e9873,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-f57ac5af-957c-43ab-8a21-3cac3518748e,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-8b7aa69f-750e-49ec-b57f-f43995577650,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-342591438-172.17.0.19-1597513106367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41007,DS-6fb8b1fc-5300-428e-be89-ed106423105c,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-e4261431-1734-4a0c-baf9-c440fed5f330,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-97ae9a34-7392-46ca-89f3-90506e440977,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-7c00b2ad-02e5-4d62-b494-92ae0adcad7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-1e0ce28d-babb-4eee-bd62-d28003576e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-982f871e-514a-4c34-b753-1b5c500e9873,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-f57ac5af-957c-43ab-8a21-3cac3518748e,DISK], DatanodeInfoWithStorage[127.0.0.1:32795,DS-8b7aa69f-750e-49ec-b57f-f43995577650,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-119623178-172.17.0.19-1597513720838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43571,DS-d24a93c9-5925-4cb2-bb9a-1b820b4aa686,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-99582ad5-d68e-4960-b816-b09e80d81d43,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-ca170dd4-e28c-4512-920e-ae701c590681,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-c834af4c-1f26-47e0-b8b1-b9036ba4abeb,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-7bd0a262-ab3a-4d9c-a7cf-83585c7d087c,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-c08aec5e-8720-4102-87ad-d22140e50d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-b8d9d7ea-34c0-44f4-a648-d494fa312653,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-ea706032-9161-44ea-9f20-1c346bf42d7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-119623178-172.17.0.19-1597513720838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43571,DS-d24a93c9-5925-4cb2-bb9a-1b820b4aa686,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-99582ad5-d68e-4960-b816-b09e80d81d43,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-ca170dd4-e28c-4512-920e-ae701c590681,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-c834af4c-1f26-47e0-b8b1-b9036ba4abeb,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-7bd0a262-ab3a-4d9c-a7cf-83585c7d087c,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-c08aec5e-8720-4102-87ad-d22140e50d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-b8d9d7ea-34c0-44f4-a648-d494fa312653,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-ea706032-9161-44ea-9f20-1c346bf42d7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-374339966-172.17.0.19-1597513964303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44969,DS-10141a52-300a-4e67-bc6d-e7111ba2b79d,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-63e6dc32-2a1a-4126-9474-e035ab684adf,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-2f11cff8-8498-41bc-a701-99bff7568cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-2b447fca-68fb-47f6-846c-e7ab29e9057c,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-578db864-1255-4e6c-aa8a-5854bccb3e86,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-65d3089d-63ad-43ac-a8df-1899012a9107,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-83b72f92-4a2b-4112-84a2-9d9d22b5ecc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-fa7342ba-4d75-4588-8376-4017d43d0d19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-374339966-172.17.0.19-1597513964303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44969,DS-10141a52-300a-4e67-bc6d-e7111ba2b79d,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-63e6dc32-2a1a-4126-9474-e035ab684adf,DISK], DatanodeInfoWithStorage[127.0.0.1:46396,DS-2f11cff8-8498-41bc-a701-99bff7568cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-2b447fca-68fb-47f6-846c-e7ab29e9057c,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-578db864-1255-4e6c-aa8a-5854bccb3e86,DISK], DatanodeInfoWithStorage[127.0.0.1:36961,DS-65d3089d-63ad-43ac-a8df-1899012a9107,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-83b72f92-4a2b-4112-84a2-9d9d22b5ecc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-fa7342ba-4d75-4588-8376-4017d43d0d19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2084379066-172.17.0.19-1597514458637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37137,DS-e06c5b67-f45c-44a0-82a2-027793519509,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-48caab42-51eb-480c-b443-045f7b07de3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-19701b90-f774-4db0-802c-cc37feb34119,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-ced75930-9b81-4ece-abed-f1cff3ebae42,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-8b6978a5-bad0-413e-8099-292c4cd5cb98,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-0c618580-3f29-4147-a003-3ba9c77c5b94,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-252a926b-4029-4806-8ed9-b1db4f8c1fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-bc1dfdbe-32c2-46f6-b2d9-9883add2e873,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2084379066-172.17.0.19-1597514458637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37137,DS-e06c5b67-f45c-44a0-82a2-027793519509,DISK], DatanodeInfoWithStorage[127.0.0.1:43327,DS-48caab42-51eb-480c-b443-045f7b07de3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-19701b90-f774-4db0-802c-cc37feb34119,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-ced75930-9b81-4ece-abed-f1cff3ebae42,DISK], DatanodeInfoWithStorage[127.0.0.1:34558,DS-8b6978a5-bad0-413e-8099-292c4cd5cb98,DISK], DatanodeInfoWithStorage[127.0.0.1:37963,DS-0c618580-3f29-4147-a003-3ba9c77c5b94,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-252a926b-4029-4806-8ed9-b1db4f8c1fd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34757,DS-bc1dfdbe-32c2-46f6-b2d9-9883add2e873,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-260101137-172.17.0.19-1597514829931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45181,DS-10abd030-fb7a-423e-8c3f-1fd265155cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-e141d851-761b-4cc7-8ce8-c91178195f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-c0f1ce53-2122-43ae-81aa-85c69a1ad278,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-307498ea-bf59-4f74-8f70-bfd990bbb5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-cb78a9ef-68bf-4330-99d5-82bcbdb00d54,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-3f3b8e10-c78a-4b2d-9e85-14d489974203,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-61e55e87-6e16-4bc8-88f2-e3d1db250f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-b5c2d071-b8bf-48dd-8c85-382d54294fd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-260101137-172.17.0.19-1597514829931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45181,DS-10abd030-fb7a-423e-8c3f-1fd265155cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:34773,DS-e141d851-761b-4cc7-8ce8-c91178195f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-c0f1ce53-2122-43ae-81aa-85c69a1ad278,DISK], DatanodeInfoWithStorage[127.0.0.1:34180,DS-307498ea-bf59-4f74-8f70-bfd990bbb5d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-cb78a9ef-68bf-4330-99d5-82bcbdb00d54,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-3f3b8e10-c78a-4b2d-9e85-14d489974203,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-61e55e87-6e16-4bc8-88f2-e3d1db250f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-b5c2d071-b8bf-48dd-8c85-382d54294fd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1478985460-172.17.0.19-1597515377904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33279,DS-5b343130-de97-4c19-9b79-1ded5b27a597,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-94011a8e-c122-4eaf-8eec-20249677bf03,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-9484321b-7481-428f-8e2f-0228c433c50f,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-65a6fef1-5649-4dae-a5da-517f62429b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-18097980-aac0-42f0-9f2a-23a4ec44d83e,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-c192f296-22a6-4e7d-8a6e-2c2999aae210,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-a387aa76-ed54-4967-8d12-5388ff1e27d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-de40e133-e965-4260-90e7-3449e5c8bf74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1478985460-172.17.0.19-1597515377904:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33279,DS-5b343130-de97-4c19-9b79-1ded5b27a597,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-94011a8e-c122-4eaf-8eec-20249677bf03,DISK], DatanodeInfoWithStorage[127.0.0.1:38437,DS-9484321b-7481-428f-8e2f-0228c433c50f,DISK], DatanodeInfoWithStorage[127.0.0.1:38609,DS-65a6fef1-5649-4dae-a5da-517f62429b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-18097980-aac0-42f0-9f2a-23a4ec44d83e,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-c192f296-22a6-4e7d-8a6e-2c2999aae210,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-a387aa76-ed54-4967-8d12-5388ff1e27d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-de40e133-e965-4260-90e7-3449e5c8bf74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700482098-172.17.0.19-1597515501873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35676,DS-dfa2de3c-7280-4418-ae38-07cfc4de3e10,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-ebc8b5b9-a039-4024-b563-9d1efe53e6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-2a9cdf09-19c3-4d34-b28c-bf904a917c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-bb29b139-2db3-46e4-a4b9-cc4e513496e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-dc096818-8e2e-4cf3-ba3d-54c3c197ac60,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-dbf7a3cb-0806-4025-af17-fd55df38c0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-3334f86a-b316-422a-bbe8-8d8df1f04f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-d4a9507b-bd9b-4692-85c3-02152afd35a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700482098-172.17.0.19-1597515501873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35676,DS-dfa2de3c-7280-4418-ae38-07cfc4de3e10,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-ebc8b5b9-a039-4024-b563-9d1efe53e6e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-2a9cdf09-19c3-4d34-b28c-bf904a917c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-bb29b139-2db3-46e4-a4b9-cc4e513496e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-dc096818-8e2e-4cf3-ba3d-54c3c197ac60,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-dbf7a3cb-0806-4025-af17-fd55df38c0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-3334f86a-b316-422a-bbe8-8d8df1f04f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-d4a9507b-bd9b-4692-85c3-02152afd35a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1505106371-172.17.0.19-1597515733339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36884,DS-2b6cc3db-cfcc-4310-b831-634bdb441d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-da99cefb-9d5f-43d5-9e23-0b3a8b14e7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-3e32faa4-9735-40e8-ab56-529b98cf4e75,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-8c1a0c35-80f8-40db-a168-28ab18453264,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-ff42feba-d512-4d84-8123-c162e7099e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-14573e41-33fb-4bc3-8998-f8f1927a725e,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-06fb6476-33db-4d24-b6e5-4f8a306fca7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-92c3c6a8-565a-4d77-9494-61d672e13255,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1505106371-172.17.0.19-1597515733339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36884,DS-2b6cc3db-cfcc-4310-b831-634bdb441d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-da99cefb-9d5f-43d5-9e23-0b3a8b14e7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-3e32faa4-9735-40e8-ab56-529b98cf4e75,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-8c1a0c35-80f8-40db-a168-28ab18453264,DISK], DatanodeInfoWithStorage[127.0.0.1:43241,DS-ff42feba-d512-4d84-8123-c162e7099e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45104,DS-14573e41-33fb-4bc3-8998-f8f1927a725e,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-06fb6476-33db-4d24-b6e5-4f8a306fca7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-92c3c6a8-565a-4d77-9494-61d672e13255,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1285890613-172.17.0.19-1597516183065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46107,DS-064810b8-85ea-422e-bbd1-2ea9fdd6cfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35584,DS-67544696-305c-4318-8930-9c239dfb20b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-b6efb933-0ec6-414e-a538-1774d063c43d,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-9927b8a7-9e43-4090-bd35-196c1931f77c,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-5dd35565-5c1b-41b7-a06c-aba8d5cc3ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-b03d57f4-606f-48c7-bf0d-82219fa709ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-42d314ea-0038-4d4a-bb5a-f713593a4102,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-1a5d1d2e-01ef-475a-b269-8a058a2b1c6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1285890613-172.17.0.19-1597516183065:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46107,DS-064810b8-85ea-422e-bbd1-2ea9fdd6cfb9,DISK], DatanodeInfoWithStorage[127.0.0.1:35584,DS-67544696-305c-4318-8930-9c239dfb20b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-b6efb933-0ec6-414e-a538-1774d063c43d,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-9927b8a7-9e43-4090-bd35-196c1931f77c,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-5dd35565-5c1b-41b7-a06c-aba8d5cc3ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-b03d57f4-606f-48c7-bf0d-82219fa709ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-42d314ea-0038-4d4a-bb5a-f713593a4102,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-1a5d1d2e-01ef-475a-b269-8a058a2b1c6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056431898-172.17.0.19-1597516220405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33638,DS-4bc5bb4a-5050-4cd2-ad5b-11ff26af901c,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-d1275b8f-57ea-469d-9fad-30070faa7154,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-0b54821c-46b9-4470-bb1e-40758536deb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-9b4a8192-da39-4674-8089-5d5530071441,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-7d6d014d-67ed-470f-9d5e-6a8986cfc59f,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-22004173-b189-4d89-a612-5d418105edf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-bdf0c19b-2050-4d1d-86e0-3d885f2c598e,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-25517bad-f0b4-4a16-a76e-98e9e0b157d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056431898-172.17.0.19-1597516220405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33638,DS-4bc5bb4a-5050-4cd2-ad5b-11ff26af901c,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-d1275b8f-57ea-469d-9fad-30070faa7154,DISK], DatanodeInfoWithStorage[127.0.0.1:33467,DS-0b54821c-46b9-4470-bb1e-40758536deb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38429,DS-9b4a8192-da39-4674-8089-5d5530071441,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-7d6d014d-67ed-470f-9d5e-6a8986cfc59f,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-22004173-b189-4d89-a612-5d418105edf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33513,DS-bdf0c19b-2050-4d1d-86e0-3d885f2c598e,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-25517bad-f0b4-4a16-a76e-98e9e0b157d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689112011-172.17.0.19-1597516484978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33703,DS-f4e41d05-b34f-4741-90b5-37d2f9029a67,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-65148bbb-4b61-4c2b-bdb3-f8562cef9311,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-3e42aa1e-4388-4809-8d44-e5e045a60e97,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-0b7c5143-4c92-45f5-b6cc-3cb264a09489,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-90086eda-4045-4717-baf0-3a025293748a,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-9af12661-42f6-4076-bfd5-783079367a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-f419bb84-0994-4ebc-9ce1-cc7a8360f875,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-88282de6-e570-4118-8251-8bf130340898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689112011-172.17.0.19-1597516484978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33703,DS-f4e41d05-b34f-4741-90b5-37d2f9029a67,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-65148bbb-4b61-4c2b-bdb3-f8562cef9311,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-3e42aa1e-4388-4809-8d44-e5e045a60e97,DISK], DatanodeInfoWithStorage[127.0.0.1:46613,DS-0b7c5143-4c92-45f5-b6cc-3cb264a09489,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-90086eda-4045-4717-baf0-3a025293748a,DISK], DatanodeInfoWithStorage[127.0.0.1:45302,DS-9af12661-42f6-4076-bfd5-783079367a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37853,DS-f419bb84-0994-4ebc-9ce1-cc7a8360f875,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-88282de6-e570-4118-8251-8bf130340898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-69216290-172.17.0.19-1597516994756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43377,DS-e91e8bba-29c0-47c7-a1f3-f59f65c4eab0,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-e6d3c2cb-601f-4b94-90aa-9f6200ee51ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-30f3a402-0e6b-4075-9fed-fe65671e28d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-2d361b79-e7be-41ce-bd71-6672d96f7495,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-90d9f99f-3bda-4e59-8077-7463a8cbee1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-d37e051a-0048-4474-9ca3-47d512e0f6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-3238104d-ee09-47fd-a713-bd0b98f0f07b,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-6d403569-836c-49dc-83f6-0cc5a07e11fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-69216290-172.17.0.19-1597516994756:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43377,DS-e91e8bba-29c0-47c7-a1f3-f59f65c4eab0,DISK], DatanodeInfoWithStorage[127.0.0.1:43371,DS-e6d3c2cb-601f-4b94-90aa-9f6200ee51ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-30f3a402-0e6b-4075-9fed-fe65671e28d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-2d361b79-e7be-41ce-bd71-6672d96f7495,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-90d9f99f-3bda-4e59-8077-7463a8cbee1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-d37e051a-0048-4474-9ca3-47d512e0f6f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-3238104d-ee09-47fd-a713-bd0b98f0f07b,DISK], DatanodeInfoWithStorage[127.0.0.1:34309,DS-6d403569-836c-49dc-83f6-0cc5a07e11fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1098830930-172.17.0.19-1597517066542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43841,DS-ab7acec9-2f68-482c-b501-079d01b7e153,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-71d98beb-ca07-4e2c-a9a9-ff5114da5640,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-887418c8-57f6-411b-96cd-1020b52ee599,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-56d226b7-991e-40b8-ae87-5d3f4ad27d59,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-39f5fb31-e3dd-422d-8fee-9589c28000cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-141ad2b8-18ba-4bfc-b1a8-2aa3d77a62d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-a2f2c8c3-f27a-4073-b317-1ec4d36637af,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-2a4dfda2-196b-4c02-a006-21db3673aa73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1098830930-172.17.0.19-1597517066542:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43841,DS-ab7acec9-2f68-482c-b501-079d01b7e153,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-71d98beb-ca07-4e2c-a9a9-ff5114da5640,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-887418c8-57f6-411b-96cd-1020b52ee599,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-56d226b7-991e-40b8-ae87-5d3f4ad27d59,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-39f5fb31-e3dd-422d-8fee-9589c28000cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34206,DS-141ad2b8-18ba-4bfc-b1a8-2aa3d77a62d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-a2f2c8c3-f27a-4073-b317-1ec4d36637af,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-2a4dfda2-196b-4c02-a006-21db3673aa73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-633863174-172.17.0.19-1597517419259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36865,DS-108d7028-285c-478a-9a98-0d3937f0d14f,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-c7764779-c99a-4f75-8a8d-34cf406a58d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-b9885b5e-5026-471a-9244-505b83599fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-13cf3d52-d50b-4ea1-8bae-775571b08e87,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-2b07a9a8-4868-4aa1-8c05-558b7b20ca0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-7cef6056-aba2-42ae-b34c-2111cc42e962,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-d7b64239-bdce-4e0d-89ee-753afe3f0b49,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-420b47e8-e3c5-4a15-8c14-064946ee1afc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-633863174-172.17.0.19-1597517419259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36865,DS-108d7028-285c-478a-9a98-0d3937f0d14f,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-c7764779-c99a-4f75-8a8d-34cf406a58d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-b9885b5e-5026-471a-9244-505b83599fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-13cf3d52-d50b-4ea1-8bae-775571b08e87,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-2b07a9a8-4868-4aa1-8c05-558b7b20ca0e,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-7cef6056-aba2-42ae-b34c-2111cc42e962,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-d7b64239-bdce-4e0d-89ee-753afe3f0b49,DISK], DatanodeInfoWithStorage[127.0.0.1:46233,DS-420b47e8-e3c5-4a15-8c14-064946ee1afc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1646520303-172.17.0.19-1597517503313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40573,DS-0fb63e0a-8779-46f2-815d-4a08acf3420a,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-e04c3ca2-f04b-4bc1-82a4-95e7d025e9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-7076043b-773e-43f7-ad31-9bf000e6f370,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-a94e450e-3c0b-42d8-9a4d-455483351da6,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-3691b4f2-dc9c-4d21-a74a-462666802da5,DISK], DatanodeInfoWithStorage[127.0.0.1:43109,DS-f427c03d-0809-40e9-9e15-99fe3194ba90,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-a16d2492-6156-4c8c-b0c9-067463823123,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-2468fd90-b220-447a-ac84-8f424517244c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1646520303-172.17.0.19-1597517503313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40573,DS-0fb63e0a-8779-46f2-815d-4a08acf3420a,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-e04c3ca2-f04b-4bc1-82a4-95e7d025e9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44312,DS-7076043b-773e-43f7-ad31-9bf000e6f370,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-a94e450e-3c0b-42d8-9a4d-455483351da6,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-3691b4f2-dc9c-4d21-a74a-462666802da5,DISK], DatanodeInfoWithStorage[127.0.0.1:43109,DS-f427c03d-0809-40e9-9e15-99fe3194ba90,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-a16d2492-6156-4c8c-b0c9-067463823123,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-2468fd90-b220-447a-ac84-8f424517244c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1845233332-172.17.0.19-1597517739407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45059,DS-c7fbe6a2-a5cb-4620-aa40-52372dbfc120,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-f83340d0-43ac-4b6d-a2f3-88e62ddf8c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-93d587e2-bb0d-436c-a31b-1b3cd93de7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-1b064ba8-a0f7-47b3-855e-391c2dbae8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-c2b3a352-ecfc-4c81-a230-1c6cd2a2c7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-1ee631b8-8550-4817-a96c-b4d8f1ecef41,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-5dc1a1fa-ff24-43bd-9cbc-d374f01e2d05,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-8fa67ee7-d6c3-431c-99a4-4772d6243fe2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1845233332-172.17.0.19-1597517739407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45059,DS-c7fbe6a2-a5cb-4620-aa40-52372dbfc120,DISK], DatanodeInfoWithStorage[127.0.0.1:39960,DS-f83340d0-43ac-4b6d-a2f3-88e62ddf8c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-93d587e2-bb0d-436c-a31b-1b3cd93de7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-1b064ba8-a0f7-47b3-855e-391c2dbae8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-c2b3a352-ecfc-4c81-a230-1c6cd2a2c7bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-1ee631b8-8550-4817-a96c-b4d8f1ecef41,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-5dc1a1fa-ff24-43bd-9cbc-d374f01e2d05,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-8fa67ee7-d6c3-431c-99a4-4772d6243fe2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 100
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1270640319-172.17.0.19-1597518013095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44994,DS-584920d8-8788-4a46-91be-11dcdb9c6c97,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-b19baa55-d135-4314-8393-200d24b7f698,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-b5767ac4-5dde-4e3b-a4e2-2cb910581770,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-2b309257-32b6-4ede-b00d-ddc23deed7ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-cf4c902e-1f04-482b-82d0-8bcf132dc94c,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-68b95a2c-f37f-4c9e-b495-b7736c68b503,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-307c1f75-c38e-44b1-967e-40a1a36eaabb,DISK], DatanodeInfoWithStorage[127.0.0.1:33279,DS-5e59d850-7070-47b4-b799-41c7dc642739,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1270640319-172.17.0.19-1597518013095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44994,DS-584920d8-8788-4a46-91be-11dcdb9c6c97,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-b19baa55-d135-4314-8393-200d24b7f698,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-b5767ac4-5dde-4e3b-a4e2-2cb910581770,DISK], DatanodeInfoWithStorage[127.0.0.1:42976,DS-2b309257-32b6-4ede-b00d-ddc23deed7ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-cf4c902e-1f04-482b-82d0-8bcf132dc94c,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-68b95a2c-f37f-4c9e-b495-b7736c68b503,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-307c1f75-c38e-44b1-967e-40a1a36eaabb,DISK], DatanodeInfoWithStorage[127.0.0.1:33279,DS-5e59d850-7070-47b4-b799-41c7dc642739,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5778
