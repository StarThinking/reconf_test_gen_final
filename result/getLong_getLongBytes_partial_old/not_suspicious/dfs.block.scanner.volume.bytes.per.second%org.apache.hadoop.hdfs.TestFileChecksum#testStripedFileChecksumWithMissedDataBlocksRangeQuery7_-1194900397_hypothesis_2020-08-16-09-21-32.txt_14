reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1096116316-172.17.0.10-1597570527365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38211,DS-9e1c8ece-46bc-4a92-a0b3-772cb03ee954,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-2882cdeb-ffc3-4949-bf42-7bde49085943,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-68287d8f-9705-4686-8ec6-88dea66e298f,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-a7dfc963-54b4-441c-a11f-6d429c154f13,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-d1b2812b-8a2d-4e49-b7a8-e229839d0e72,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-63ef8c4e-1c25-4bdd-a83f-b5e74bb8d1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-1f2b02a3-d439-49aa-a661-78e92398539b,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-8d1be574-5e92-4ddf-9796-b893925d4bd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1096116316-172.17.0.10-1597570527365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38211,DS-9e1c8ece-46bc-4a92-a0b3-772cb03ee954,DISK], DatanodeInfoWithStorage[127.0.0.1:41214,DS-2882cdeb-ffc3-4949-bf42-7bde49085943,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-68287d8f-9705-4686-8ec6-88dea66e298f,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-a7dfc963-54b4-441c-a11f-6d429c154f13,DISK], DatanodeInfoWithStorage[127.0.0.1:43182,DS-d1b2812b-8a2d-4e49-b7a8-e229839d0e72,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-63ef8c4e-1c25-4bdd-a83f-b5e74bb8d1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:41369,DS-1f2b02a3-d439-49aa-a661-78e92398539b,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-8d1be574-5e92-4ddf-9796-b893925d4bd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1607297718-172.17.0.10-1597570665037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40911,DS-df7a41ad-e6eb-4f79-97b0-d3889931eb85,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-4026fbbf-94b3-4e8a-8c31-82527feae61a,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-48ea3f54-cc74-4f9f-81d1-773c849ee776,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-82342fa7-f15b-4a2b-acfa-64d695c78476,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-8f0f8a83-fc3a-49f9-bc43-2756896ef3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-5c58e3da-31f1-44c5-8b42-1a48b1785eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-b4d7fdaf-38f3-464f-b157-5b79e360ca08,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-21993265-e8ab-4dcc-8f29-65a9ec2aaff7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1607297718-172.17.0.10-1597570665037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40911,DS-df7a41ad-e6eb-4f79-97b0-d3889931eb85,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-4026fbbf-94b3-4e8a-8c31-82527feae61a,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-48ea3f54-cc74-4f9f-81d1-773c849ee776,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-82342fa7-f15b-4a2b-acfa-64d695c78476,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-8f0f8a83-fc3a-49f9-bc43-2756896ef3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-5c58e3da-31f1-44c5-8b42-1a48b1785eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35418,DS-b4d7fdaf-38f3-464f-b157-5b79e360ca08,DISK], DatanodeInfoWithStorage[127.0.0.1:43769,DS-21993265-e8ab-4dcc-8f29-65a9ec2aaff7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056284271-172.17.0.10-1597570894019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46329,DS-9db1f943-13c3-4223-ad7f-61e5d01abc1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-a68e480b-8276-47e2-a258-f228957c965b,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-f41dcf1f-bc15-482c-a251-215b778a4943,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-b5fe07e6-44c5-4461-9d2c-af285457e18f,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-c3e85c29-b869-4adc-bf08-ccb95940931c,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-8725d2c4-e1e8-4bf8-a067-2b9901c630da,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-4214d26d-b9c3-4534-83cc-3d5f8c8c9579,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-fd9eeac0-093d-4d2d-b21c-ef79232d975f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2056284271-172.17.0.10-1597570894019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46329,DS-9db1f943-13c3-4223-ad7f-61e5d01abc1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39435,DS-a68e480b-8276-47e2-a258-f228957c965b,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-f41dcf1f-bc15-482c-a251-215b778a4943,DISK], DatanodeInfoWithStorage[127.0.0.1:36813,DS-b5fe07e6-44c5-4461-9d2c-af285457e18f,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-c3e85c29-b869-4adc-bf08-ccb95940931c,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-8725d2c4-e1e8-4bf8-a067-2b9901c630da,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-4214d26d-b9c3-4534-83cc-3d5f8c8c9579,DISK], DatanodeInfoWithStorage[127.0.0.1:44835,DS-fd9eeac0-093d-4d2d-b21c-ef79232d975f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-350904598-172.17.0.10-1597571136434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33491,DS-7cd30381-7fb6-4f77-b54d-623042e3dfd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-70dc87a7-01d2-420f-a081-cd3b664cc3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-97e7756a-18fe-45ff-89ea-43c2960b5e97,DISK], DatanodeInfoWithStorage[127.0.0.1:34538,DS-ded535ad-5448-40b2-83d5-634d080ee6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-9faba0e0-f097-4dd4-a08b-846dba39e560,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-8d02defc-a3c8-4391-a9a0-b49a7974a196,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-f25420e0-e267-49b4-a48a-803070431c74,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-6b768c0a-4688-4754-9f3a-af5b77a18e80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-350904598-172.17.0.10-1597571136434:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33491,DS-7cd30381-7fb6-4f77-b54d-623042e3dfd5,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-70dc87a7-01d2-420f-a081-cd3b664cc3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-97e7756a-18fe-45ff-89ea-43c2960b5e97,DISK], DatanodeInfoWithStorage[127.0.0.1:34538,DS-ded535ad-5448-40b2-83d5-634d080ee6e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-9faba0e0-f097-4dd4-a08b-846dba39e560,DISK], DatanodeInfoWithStorage[127.0.0.1:44271,DS-8d02defc-a3c8-4391-a9a0-b49a7974a196,DISK], DatanodeInfoWithStorage[127.0.0.1:41080,DS-f25420e0-e267-49b4-a48a-803070431c74,DISK], DatanodeInfoWithStorage[127.0.0.1:42690,DS-6b768c0a-4688-4754-9f3a-af5b77a18e80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1014854549-172.17.0.10-1597571286332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38522,DS-64a853d3-4024-4926-91d1-3874b813dbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-6834c53d-3790-47ed-9502-beadec53c443,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-dce17ab9-754e-472b-9fae-1af39022d3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-f2bcb586-e610-4d35-9d09-adc74140a84e,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-047e3787-0c65-4d3f-befa-68860f6577fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-4215081d-4cb8-4e5c-8289-b9f5145c60f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-6b813ad1-809b-409b-8f22-2e571b84a3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-4dd8d7f0-fc01-4d76-963f-3bf89d7a13f0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1014854549-172.17.0.10-1597571286332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38522,DS-64a853d3-4024-4926-91d1-3874b813dbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:44624,DS-6834c53d-3790-47ed-9502-beadec53c443,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-dce17ab9-754e-472b-9fae-1af39022d3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-f2bcb586-e610-4d35-9d09-adc74140a84e,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-047e3787-0c65-4d3f-befa-68860f6577fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38753,DS-4215081d-4cb8-4e5c-8289-b9f5145c60f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-6b813ad1-809b-409b-8f22-2e571b84a3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44419,DS-4dd8d7f0-fc01-4d76-963f-3bf89d7a13f0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1543808232-172.17.0.10-1597571318546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33469,DS-5d04ef6d-1026-4512-8329-ce5c225806aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-d0ce99f5-52dd-4064-a6c7-bdc5088ec7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-16e123ff-7bdb-4294-b9d5-7ab7b7d80473,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-4a470d0e-2701-46db-9d15-d90da464a4af,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-547c3dab-df45-4ec1-89c7-e0e95dc3cc71,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-8c168238-b83d-48ec-840a-79775f28eec3,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-b340aecd-69c6-46c2-8e31-48afe33816da,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-691b96a7-715f-48d6-a8f4-28cb39f95955,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1543808232-172.17.0.10-1597571318546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33469,DS-5d04ef6d-1026-4512-8329-ce5c225806aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-d0ce99f5-52dd-4064-a6c7-bdc5088ec7e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-16e123ff-7bdb-4294-b9d5-7ab7b7d80473,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-4a470d0e-2701-46db-9d15-d90da464a4af,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-547c3dab-df45-4ec1-89c7-e0e95dc3cc71,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-8c168238-b83d-48ec-840a-79775f28eec3,DISK], DatanodeInfoWithStorage[127.0.0.1:38784,DS-b340aecd-69c6-46c2-8e31-48afe33816da,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-691b96a7-715f-48d6-a8f4-28cb39f95955,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-375539583-172.17.0.10-1597571724541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40067,DS-55251707-2857-49fb-9951-66d26c773262,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-b2307e5d-9c09-4cdf-8f45-08e56064b1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-de21180f-a26c-49c0-aeb4-cab3ad161647,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-f62a0773-1053-4d7e-a74f-4a7039826450,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-e0d29505-4e05-47da-8534-e21a3a2ec2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-04db325c-7f56-4cd5-839f-92e366980755,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-f41617f5-0566-4cbe-b717-ccecf787c0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35524,DS-06e08819-1048-4b28-bea0-902b4d33c8f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-375539583-172.17.0.10-1597571724541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40067,DS-55251707-2857-49fb-9951-66d26c773262,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-b2307e5d-9c09-4cdf-8f45-08e56064b1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43386,DS-de21180f-a26c-49c0-aeb4-cab3ad161647,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-f62a0773-1053-4d7e-a74f-4a7039826450,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-e0d29505-4e05-47da-8534-e21a3a2ec2fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45654,DS-04db325c-7f56-4cd5-839f-92e366980755,DISK], DatanodeInfoWithStorage[127.0.0.1:44713,DS-f41617f5-0566-4cbe-b717-ccecf787c0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35524,DS-06e08819-1048-4b28-bea0-902b4d33c8f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1378335490-172.17.0.10-1597572065407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36045,DS-3da08d5e-a843-478f-9793-1928a18e4686,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-207d2e1a-809a-46c2-a551-fdf2e58e7dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-794edc19-7a51-44a4-b76d-99864f00b04f,DISK], DatanodeInfoWithStorage[127.0.0.1:35916,DS-e3e65cf3-263d-4c4d-affa-c65dab74c333,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-a556c788-9e2b-42fa-be0b-2b39e66e98aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-a74c0861-203d-48a5-b927-25d8987ccce4,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-9e8593c6-72ab-433e-9060-a8d37f44d0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-86cc0e77-44cd-4676-935e-aa0d9f0e75b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1378335490-172.17.0.10-1597572065407:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36045,DS-3da08d5e-a843-478f-9793-1928a18e4686,DISK], DatanodeInfoWithStorage[127.0.0.1:46023,DS-207d2e1a-809a-46c2-a551-fdf2e58e7dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-794edc19-7a51-44a4-b76d-99864f00b04f,DISK], DatanodeInfoWithStorage[127.0.0.1:35916,DS-e3e65cf3-263d-4c4d-affa-c65dab74c333,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-a556c788-9e2b-42fa-be0b-2b39e66e98aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-a74c0861-203d-48a5-b927-25d8987ccce4,DISK], DatanodeInfoWithStorage[127.0.0.1:39439,DS-9e8593c6-72ab-433e-9060-a8d37f44d0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-86cc0e77-44cd-4676-935e-aa0d9f0e75b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234211357-172.17.0.10-1597572426752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43775,DS-67115d9e-c3ff-48fe-bffb-366a455eec2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-8943a46c-0ec6-4000-99fb-b39512f15abb,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-14ac7d63-bb70-4345-9e20-4c8020ff70f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-2a1e2295-fac3-4ea8-bd8d-ed536f1235e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42752,DS-a873dc48-385e-4d15-bf37-b4ee1d0fc09c,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-6d431196-cc79-4e92-9de7-b5aebfb0663b,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-e74022d4-4723-4901-8c06-f83f0ab7b60a,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-41a594c0-5a2f-42e4-bf8d-efb458cffbd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234211357-172.17.0.10-1597572426752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43775,DS-67115d9e-c3ff-48fe-bffb-366a455eec2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-8943a46c-0ec6-4000-99fb-b39512f15abb,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-14ac7d63-bb70-4345-9e20-4c8020ff70f9,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-2a1e2295-fac3-4ea8-bd8d-ed536f1235e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42752,DS-a873dc48-385e-4d15-bf37-b4ee1d0fc09c,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-6d431196-cc79-4e92-9de7-b5aebfb0663b,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-e74022d4-4723-4901-8c06-f83f0ab7b60a,DISK], DatanodeInfoWithStorage[127.0.0.1:36064,DS-41a594c0-5a2f-42e4-bf8d-efb458cffbd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1759853970-172.17.0.10-1597572550298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33320,DS-48b0788c-a275-412c-9444-a95c9faed3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-79e5a081-509d-4fc5-996c-c392a51ec01a,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-de748d43-f1fb-4edf-916d-42f42528e1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-dece0d14-7402-4dac-a36c-053c061271bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-5b9e4bc4-630a-4a6a-8406-3a18626ce2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-1d3a3ab9-3822-4363-9d0c-ef5ab50541d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-fdcfb076-de74-4b25-9e16-04bbacbbc3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-2095aa03-66d8-4eb6-a8a1-7aa573d36264,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1759853970-172.17.0.10-1597572550298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33320,DS-48b0788c-a275-412c-9444-a95c9faed3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-79e5a081-509d-4fc5-996c-c392a51ec01a,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-de748d43-f1fb-4edf-916d-42f42528e1b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-dece0d14-7402-4dac-a36c-053c061271bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-5b9e4bc4-630a-4a6a-8406-3a18626ce2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34744,DS-1d3a3ab9-3822-4363-9d0c-ef5ab50541d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-fdcfb076-de74-4b25-9e16-04bbacbbc3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-2095aa03-66d8-4eb6-a8a1-7aa573d36264,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-434062886-172.17.0.10-1597572747418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41574,DS-9631a037-ee3e-4e1d-810b-5daa498a1f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-ca2f3e91-409f-4adb-9cf2-d09fb92b33da,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-860b7d47-13ae-41b0-bb29-03fd56d80829,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-1ba2e99d-affa-46f7-a00d-334113d74e82,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-b69175c1-0185-43e7-8efd-1c1a9e4f0bce,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-0455cc59-fe4b-435f-811e-b7d2536f276e,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-c1e1c18a-5242-4e50-a8d7-4746fd66a4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-45c8b517-ea20-43cd-84b3-13781577f04e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-434062886-172.17.0.10-1597572747418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41574,DS-9631a037-ee3e-4e1d-810b-5daa498a1f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46843,DS-ca2f3e91-409f-4adb-9cf2-d09fb92b33da,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-860b7d47-13ae-41b0-bb29-03fd56d80829,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-1ba2e99d-affa-46f7-a00d-334113d74e82,DISK], DatanodeInfoWithStorage[127.0.0.1:36517,DS-b69175c1-0185-43e7-8efd-1c1a9e4f0bce,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-0455cc59-fe4b-435f-811e-b7d2536f276e,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-c1e1c18a-5242-4e50-a8d7-4746fd66a4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36002,DS-45c8b517-ea20-43cd-84b3-13781577f04e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781395443-172.17.0.10-1597572948240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40310,DS-6bbe4b23-1cfc-43fb-88a7-316d92740da0,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-25c9d544-ec8a-4c6d-88d8-abba7b59a610,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-92f5600d-8782-47db-8bff-c1e82da965d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-bfbc3047-ea04-4d56-a189-9a75ddd37e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-ef8dae09-a43e-4093-8818-44f487200c00,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-c8b2e01c-eb53-487e-9add-6ca87b396ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-8ed3da83-6d06-4b11-933e-de5d0b525076,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-56404c1f-e4f1-4653-893e-662d24a0ef24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781395443-172.17.0.10-1597572948240:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40310,DS-6bbe4b23-1cfc-43fb-88a7-316d92740da0,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-25c9d544-ec8a-4c6d-88d8-abba7b59a610,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-92f5600d-8782-47db-8bff-c1e82da965d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-bfbc3047-ea04-4d56-a189-9a75ddd37e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-ef8dae09-a43e-4093-8818-44f487200c00,DISK], DatanodeInfoWithStorage[127.0.0.1:35062,DS-c8b2e01c-eb53-487e-9add-6ca87b396ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-8ed3da83-6d06-4b11-933e-de5d0b525076,DISK], DatanodeInfoWithStorage[127.0.0.1:42328,DS-56404c1f-e4f1-4653-893e-662d24a0ef24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397542055-172.17.0.10-1597572982376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34244,DS-751b1482-0162-4101-846e-e3a03fd53038,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-09df8a58-9692-4bf7-bf1e-957c31a2daca,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-f25a8261-76f3-44ff-bd98-a1eb49ca5b71,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-4e2dbcee-5977-48b9-bc2e-045c7fd077cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-50c6e004-88fd-4837-aec9-70c9fd0d1005,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-c364e992-9150-45aa-8248-040a73b6d45c,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-4d05cb2f-52cb-47d5-ac61-c380bc0d1d79,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-bbc6b998-7250-401c-969e-dcd8674d52b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1397542055-172.17.0.10-1597572982376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34244,DS-751b1482-0162-4101-846e-e3a03fd53038,DISK], DatanodeInfoWithStorage[127.0.0.1:45827,DS-09df8a58-9692-4bf7-bf1e-957c31a2daca,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-f25a8261-76f3-44ff-bd98-a1eb49ca5b71,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-4e2dbcee-5977-48b9-bc2e-045c7fd077cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-50c6e004-88fd-4837-aec9-70c9fd0d1005,DISK], DatanodeInfoWithStorage[127.0.0.1:36407,DS-c364e992-9150-45aa-8248-040a73b6d45c,DISK], DatanodeInfoWithStorage[127.0.0.1:37961,DS-4d05cb2f-52cb-47d5-ac61-c380bc0d1d79,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-bbc6b998-7250-401c-969e-dcd8674d52b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2121446130-172.17.0.10-1597573131307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35403,DS-7c0c9ee3-5102-4145-a392-f8ca9bbeb64a,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-64bb6ebd-1eec-4c07-9e93-7b7e3d9f0f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-ffa1d3dc-e656-4bd4-abdf-28387af83454,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-0f5fed9b-3739-43ae-ae20-79efcca4b548,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-d396f3e9-4135-471a-8483-d05dbe1d0371,DISK], DatanodeInfoWithStorage[127.0.0.1:43207,DS-f6c8b73a-8ca5-49b2-9cb0-401b0ab27aab,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-f872d769-705f-4d18-bfec-8ca480e7ec07,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-2bad0b8f-7d53-486a-8f7c-b91badc37a83,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2121446130-172.17.0.10-1597573131307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35403,DS-7c0c9ee3-5102-4145-a392-f8ca9bbeb64a,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-64bb6ebd-1eec-4c07-9e93-7b7e3d9f0f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-ffa1d3dc-e656-4bd4-abdf-28387af83454,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-0f5fed9b-3739-43ae-ae20-79efcca4b548,DISK], DatanodeInfoWithStorage[127.0.0.1:32803,DS-d396f3e9-4135-471a-8483-d05dbe1d0371,DISK], DatanodeInfoWithStorage[127.0.0.1:43207,DS-f6c8b73a-8ca5-49b2-9cb0-401b0ab27aab,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-f872d769-705f-4d18-bfec-8ca480e7ec07,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-2bad0b8f-7d53-486a-8f7c-b91badc37a83,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884802968-172.17.0.10-1597573318200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33485,DS-ca87e415-4cdc-4840-937e-6da51ddd1f26,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-749cf016-f68e-4311-ac68-252094b7469d,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-db536038-b709-4d6d-bf96-fbe663c23349,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-17e7fc25-66a6-46a3-bf09-3be730c31cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-30b58f49-b68a-481c-80d0-1ab365e739c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-8d9474c0-d169-4d61-ad45-646a6f537330,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-996719b6-7644-42b0-a8ff-b9266165baae,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-ae1cb61e-0623-4fc3-91fb-438ff228734d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1884802968-172.17.0.10-1597573318200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33485,DS-ca87e415-4cdc-4840-937e-6da51ddd1f26,DISK], DatanodeInfoWithStorage[127.0.0.1:41790,DS-749cf016-f68e-4311-ac68-252094b7469d,DISK], DatanodeInfoWithStorage[127.0.0.1:39941,DS-db536038-b709-4d6d-bf96-fbe663c23349,DISK], DatanodeInfoWithStorage[127.0.0.1:38732,DS-17e7fc25-66a6-46a3-bf09-3be730c31cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-30b58f49-b68a-481c-80d0-1ab365e739c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46062,DS-8d9474c0-d169-4d61-ad45-646a6f537330,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-996719b6-7644-42b0-a8ff-b9266165baae,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-ae1cb61e-0623-4fc3-91fb-438ff228734d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167024135-172.17.0.10-1597573532477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43018,DS-a288165c-fd49-4c96-bc4f-cf487e1a4f15,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-104396e7-9dd8-492e-a1f7-fcff1552e7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-e975bf00-d4ee-41e1-9776-ae04bad2cb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-9a8c2dac-a5f1-4a61-a39a-a3a35f959f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-72fa0006-ef56-4984-833e-8f4bbd541fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-b4b4aa9f-a609-4381-b02c-fa96a8f9cf3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-2d591ea0-0b46-48ac-bf3f-89792c7d0a40,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-ed8f9e3d-ddf5-4248-82c9-3320bdffec52,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-167024135-172.17.0.10-1597573532477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43018,DS-a288165c-fd49-4c96-bc4f-cf487e1a4f15,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-104396e7-9dd8-492e-a1f7-fcff1552e7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42931,DS-e975bf00-d4ee-41e1-9776-ae04bad2cb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46723,DS-9a8c2dac-a5f1-4a61-a39a-a3a35f959f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-72fa0006-ef56-4984-833e-8f4bbd541fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40181,DS-b4b4aa9f-a609-4381-b02c-fa96a8f9cf3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-2d591ea0-0b46-48ac-bf3f-89792c7d0a40,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-ed8f9e3d-ddf5-4248-82c9-3320bdffec52,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-867275460-172.17.0.10-1597573693267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39942,DS-9e8dcccf-93d3-4782-aa13-8be648991d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-098bf75b-21bb-46b2-bccb-642c6e4eca31,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-09f3b3de-1fe4-468e-98c7-a4e0ea9f1b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-f492ed4b-8475-419a-98c2-b28e9104549b,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-0c57ce78-6616-4f4a-bcbe-f43dc16b3211,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-f48ce937-42ae-488c-99b5-2c7cfa40fbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-d458cabc-db38-4135-8d40-1e3b7d196040,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-86e45423-6a7d-41c1-99ab-53c6867bbd92,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-867275460-172.17.0.10-1597573693267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39942,DS-9e8dcccf-93d3-4782-aa13-8be648991d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37211,DS-098bf75b-21bb-46b2-bccb-642c6e4eca31,DISK], DatanodeInfoWithStorage[127.0.0.1:39834,DS-09f3b3de-1fe4-468e-98c7-a4e0ea9f1b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-f492ed4b-8475-419a-98c2-b28e9104549b,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-0c57ce78-6616-4f4a-bcbe-f43dc16b3211,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-f48ce937-42ae-488c-99b5-2c7cfa40fbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-d458cabc-db38-4135-8d40-1e3b7d196040,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-86e45423-6a7d-41c1-99ab-53c6867bbd92,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2117185214-172.17.0.10-1597573759930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44064,DS-b38b9a51-73fc-4b7a-80e9-add77c101443,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-a684d35f-5c85-4e1e-b225-79dd1e0f8cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-d658b918-cbd5-48fd-a3b2-fbb2c4896b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-a192e560-4cef-4246-acd1-bba2eee6910b,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-6177ab51-daf0-4b0f-b7d5-11e99bdc1cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-260223b1-7607-4a4b-b6c2-4b3182af6bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-b923404c-4831-4803-a312-f89cafbd3af8,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-27440b89-ddd1-4ad9-b54d-6aad3503d625,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2117185214-172.17.0.10-1597573759930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44064,DS-b38b9a51-73fc-4b7a-80e9-add77c101443,DISK], DatanodeInfoWithStorage[127.0.0.1:43294,DS-a684d35f-5c85-4e1e-b225-79dd1e0f8cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-d658b918-cbd5-48fd-a3b2-fbb2c4896b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-a192e560-4cef-4246-acd1-bba2eee6910b,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-6177ab51-daf0-4b0f-b7d5-11e99bdc1cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-260223b1-7607-4a4b-b6c2-4b3182af6bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-b923404c-4831-4803-a312-f89cafbd3af8,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-27440b89-ddd1-4ad9-b54d-6aad3503d625,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1927433197-172.17.0.10-1597573949107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43658,DS-955ffcec-f61b-4b1c-a9e8-9621f1cf9493,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-5dacfcce-d6ff-43c0-b4ea-a0e3491ec0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-efc03146-fde0-447d-bc6e-d9dd7703ad33,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-413f2f3f-c3b0-4a6d-8cd3-70294ce132b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-5737bcda-65c5-42be-9642-dd4b573f5adf,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-0ef13281-44da-4367-9996-49e5546ddbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-f5d8afb3-c72d-460a-8608-a239eaaca24c,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-a9ea47b8-68c5-4f83-8b28-fe23c1073913,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1927433197-172.17.0.10-1597573949107:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43658,DS-955ffcec-f61b-4b1c-a9e8-9621f1cf9493,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-5dacfcce-d6ff-43c0-b4ea-a0e3491ec0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43156,DS-efc03146-fde0-447d-bc6e-d9dd7703ad33,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-413f2f3f-c3b0-4a6d-8cd3-70294ce132b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-5737bcda-65c5-42be-9642-dd4b573f5adf,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-0ef13281-44da-4367-9996-49e5546ddbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-f5d8afb3-c72d-460a-8608-a239eaaca24c,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-a9ea47b8-68c5-4f83-8b28-fe23c1073913,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089141797-172.17.0.10-1597574415804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33672,DS-7f5f6c28-faec-465a-a3a4-cd5c0b6339f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-19232af0-b6c1-4b9e-b503-170f1f0fcde7,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-866ad0e5-78ae-4713-8d41-b489601ff1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-9262847b-9433-4624-93c7-bb0e8f2852e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-f031fbac-a389-4e13-b5f4-d668d1766e90,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-57927c41-03c2-478b-aa47-03b51ce41057,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-0484bd77-f48e-4082-9270-05cf3be035c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-d9729ee4-a30c-495a-8910-fdb901b14715,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089141797-172.17.0.10-1597574415804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33672,DS-7f5f6c28-faec-465a-a3a4-cd5c0b6339f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-19232af0-b6c1-4b9e-b503-170f1f0fcde7,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-866ad0e5-78ae-4713-8d41-b489601ff1f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-9262847b-9433-4624-93c7-bb0e8f2852e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35343,DS-f031fbac-a389-4e13-b5f4-d668d1766e90,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-57927c41-03c2-478b-aa47-03b51ce41057,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-0484bd77-f48e-4082-9270-05cf3be035c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-d9729ee4-a30c-495a-8910-fdb901b14715,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-995585644-172.17.0.10-1597574492195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40775,DS-a3e8cae2-dd6a-4497-8771-489a4ba0ca01,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-330ccd99-70a7-494d-b08b-e1c9a72ec838,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-d0813bfa-5347-4873-9f03-20c46735dd42,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-28a596eb-e9fd-4ceb-b116-6237f80ade5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-8a76f626-0951-45c2-9eaf-852b12775acd,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-f8530ed7-a77c-4e60-a0a2-d768cefdc727,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-9315140a-dd54-4bec-90d3-8ee59cae6860,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-6dde046c-4a8f-4eea-bc71-ac6b33751ad0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-995585644-172.17.0.10-1597574492195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40775,DS-a3e8cae2-dd6a-4497-8771-489a4ba0ca01,DISK], DatanodeInfoWithStorage[127.0.0.1:35498,DS-330ccd99-70a7-494d-b08b-e1c9a72ec838,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-d0813bfa-5347-4873-9f03-20c46735dd42,DISK], DatanodeInfoWithStorage[127.0.0.1:43729,DS-28a596eb-e9fd-4ceb-b116-6237f80ade5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-8a76f626-0951-45c2-9eaf-852b12775acd,DISK], DatanodeInfoWithStorage[127.0.0.1:46076,DS-f8530ed7-a77c-4e60-a0a2-d768cefdc727,DISK], DatanodeInfoWithStorage[127.0.0.1:38290,DS-9315140a-dd54-4bec-90d3-8ee59cae6860,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-6dde046c-4a8f-4eea-bc71-ac6b33751ad0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-755469587-172.17.0.10-1597574807417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35608,DS-14e6f5ad-9084-4dee-b6c3-3d4bcd591c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-ea201942-db14-4301-9d7c-e0861622b0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-64627a45-4f65-49e8-a4d0-23b47d39ba38,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-63b65d98-2a15-4d5b-830e-faefff943376,DISK], DatanodeInfoWithStorage[127.0.0.1:44956,DS-4486527a-d482-49e8-8018-42ce468192db,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-41e5f7f1-b389-48d3-87b9-6e131f903998,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-9d89e5e1-5377-4e00-9b38-e48f279f4b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-92d0da03-352c-4e80-942f-e0724cd05a86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-755469587-172.17.0.10-1597574807417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35608,DS-14e6f5ad-9084-4dee-b6c3-3d4bcd591c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-ea201942-db14-4301-9d7c-e0861622b0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-64627a45-4f65-49e8-a4d0-23b47d39ba38,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-63b65d98-2a15-4d5b-830e-faefff943376,DISK], DatanodeInfoWithStorage[127.0.0.1:44956,DS-4486527a-d482-49e8-8018-42ce468192db,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-41e5f7f1-b389-48d3-87b9-6e131f903998,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-9d89e5e1-5377-4e00-9b38-e48f279f4b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44152,DS-92d0da03-352c-4e80-942f-e0724cd05a86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1586361142-172.17.0.10-1597575041845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39461,DS-b0325f4f-0e71-4930-bdeb-48768b5dea5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-04d967b8-0721-4ef9-9458-ba16807528bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-eb0d37ca-e1c5-4ef9-8ebe-2886756e998d,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-67ed5e3a-9062-4a83-a690-098195ddc7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46820,DS-b109c7e6-e22a-48aa-9d00-17ee10b7b043,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-f66d3124-e827-4225-a962-2a9ac0d09020,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-b1cb3cb0-c3fa-47c9-8166-633aa128b322,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-1b712548-2dc8-4bee-8780-485c0bbbd9fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1586361142-172.17.0.10-1597575041845:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39461,DS-b0325f4f-0e71-4930-bdeb-48768b5dea5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36948,DS-04d967b8-0721-4ef9-9458-ba16807528bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-eb0d37ca-e1c5-4ef9-8ebe-2886756e998d,DISK], DatanodeInfoWithStorage[127.0.0.1:39858,DS-67ed5e3a-9062-4a83-a690-098195ddc7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46820,DS-b109c7e6-e22a-48aa-9d00-17ee10b7b043,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-f66d3124-e827-4225-a962-2a9ac0d09020,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-b1cb3cb0-c3fa-47c9-8166-633aa128b322,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-1b712548-2dc8-4bee-8780-485c0bbbd9fe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939202509-172.17.0.10-1597575078128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45910,DS-8c60a474-26bd-4dba-a723-d1c2ca9176c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-b1522a5a-233d-4fa6-9d3d-ef924420db80,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-10e4a3b8-077d-4a30-8508-42afb9a043ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-a8a70a0b-ba95-4ce7-a1a5-8c1df2d4a157,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-20e70c3a-db29-4e34-a393-227faaa9537d,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-69f56ec2-3464-466d-9696-b63d9e14561d,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-6aeb4bf4-f63f-4f43-b90b-a8408724d0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-f17c6f51-b76e-42d6-b1d5-21f68669aeb5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939202509-172.17.0.10-1597575078128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45910,DS-8c60a474-26bd-4dba-a723-d1c2ca9176c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37927,DS-b1522a5a-233d-4fa6-9d3d-ef924420db80,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-10e4a3b8-077d-4a30-8508-42afb9a043ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-a8a70a0b-ba95-4ce7-a1a5-8c1df2d4a157,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-20e70c3a-db29-4e34-a393-227faaa9537d,DISK], DatanodeInfoWithStorage[127.0.0.1:42066,DS-69f56ec2-3464-466d-9696-b63d9e14561d,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-6aeb4bf4-f63f-4f43-b90b-a8408724d0bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-f17c6f51-b76e-42d6-b1d5-21f68669aeb5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 134217728
v2: 1048576
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597319530-172.17.0.10-1597575215584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33211,DS-d5a685ae-46aa-437e-ba80-339a40e6e863,DISK], DatanodeInfoWithStorage[127.0.0.1:32929,DS-ea2b8e09-fef3-42aa-ad50-7a4cbb5ae33d,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-eb1ad6ac-c333-4353-8e99-a86054a1cc43,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-babcdd49-831a-47c4-a08e-9cf82ef5f77b,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-e0d534a7-59fd-42e3-ab40-a3aa8da4d51d,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-5b2c06fd-7ea3-4c1d-88b7-6677b19b76ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-151b58fb-8806-4cfa-8e79-0ad04a878038,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-2340b6ef-bbc6-47cd-a38b-edc93b1772d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1597319530-172.17.0.10-1597575215584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33211,DS-d5a685ae-46aa-437e-ba80-339a40e6e863,DISK], DatanodeInfoWithStorage[127.0.0.1:32929,DS-ea2b8e09-fef3-42aa-ad50-7a4cbb5ae33d,DISK], DatanodeInfoWithStorage[127.0.0.1:39284,DS-eb1ad6ac-c333-4353-8e99-a86054a1cc43,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-babcdd49-831a-47c4-a08e-9cf82ef5f77b,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-e0d534a7-59fd-42e3-ab40-a3aa8da4d51d,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-5b2c06fd-7ea3-4c1d-88b7-6677b19b76ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-151b58fb-8806-4cfa-8e79-0ad04a878038,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-2340b6ef-bbc6-47cd-a38b-edc93b1772d9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5618
