reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997615857-172.17.0.20-1597323601573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44645,DS-3f29b27a-850e-4363-ac7b-aa63fb7fa7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-aa68b95d-79e3-48d6-9100-4b5128cca97c,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-ebe45312-eff3-4903-aee5-d3605adb191c,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-0c10d5a6-0d52-4ccb-a468-94677fbb9775,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-a94581e7-a3db-4d21-81f8-3a117e11bf2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-90d635f4-373b-4e54-b992-0ce8e7e15a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-a61e2c34-526f-4d2f-9646-42e91286cda6,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-b6cc5726-590e-41fe-9084-48748fcd1031,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997615857-172.17.0.20-1597323601573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44645,DS-3f29b27a-850e-4363-ac7b-aa63fb7fa7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37053,DS-aa68b95d-79e3-48d6-9100-4b5128cca97c,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-ebe45312-eff3-4903-aee5-d3605adb191c,DISK], DatanodeInfoWithStorage[127.0.0.1:36785,DS-0c10d5a6-0d52-4ccb-a468-94677fbb9775,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-a94581e7-a3db-4d21-81f8-3a117e11bf2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-90d635f4-373b-4e54-b992-0ce8e7e15a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-a61e2c34-526f-4d2f-9646-42e91286cda6,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-b6cc5726-590e-41fe-9084-48748fcd1031,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110759249-172.17.0.20-1597323836980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40401,DS-0a77868e-e2e7-45f5-99d9-b29efefda144,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-f115f53e-6e97-4b6a-8446-c9755b13e84c,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-fb1c4c38-90e7-4e8b-98a6-e26e99117c57,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-8bc9e7db-bff3-4ede-a72e-d21c75bf0222,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-0b5ea1cb-b9d6-49d2-afdb-52505c2a30b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-5cec9e97-f238-48e2-8596-197436775913,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-78b78b88-8187-4a77-9923-2d7f8d90a710,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-4f87eab9-19e8-43fd-b9b4-5a689639bf9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1110759249-172.17.0.20-1597323836980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40401,DS-0a77868e-e2e7-45f5-99d9-b29efefda144,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-f115f53e-6e97-4b6a-8446-c9755b13e84c,DISK], DatanodeInfoWithStorage[127.0.0.1:34316,DS-fb1c4c38-90e7-4e8b-98a6-e26e99117c57,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-8bc9e7db-bff3-4ede-a72e-d21c75bf0222,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-0b5ea1cb-b9d6-49d2-afdb-52505c2a30b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-5cec9e97-f238-48e2-8596-197436775913,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-78b78b88-8187-4a77-9923-2d7f8d90a710,DISK], DatanodeInfoWithStorage[127.0.0.1:33639,DS-4f87eab9-19e8-43fd-b9b4-5a689639bf9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-837654165-172.17.0.20-1597324731512:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46009,DS-fd5cda35-c30f-499a-a3fc-81f5b1be1406,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-53875d47-bf95-4bc5-b5d3-9fcd0c5875a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-7b9d27fc-6176-4eaa-b8da-561b0f57346f,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-3cccab72-5597-4000-b790-6b74aae3f607,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-370aa0b4-7516-40af-b304-a6329147ac59,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-43faaea6-5b5e-4ecc-898a-eba70f3fb4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-60926d7c-8a10-410d-a26d-a151712f86ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-a2e07c18-fc39-448a-9afc-f7bfe6064811,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-837654165-172.17.0.20-1597324731512:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46009,DS-fd5cda35-c30f-499a-a3fc-81f5b1be1406,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-53875d47-bf95-4bc5-b5d3-9fcd0c5875a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-7b9d27fc-6176-4eaa-b8da-561b0f57346f,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-3cccab72-5597-4000-b790-6b74aae3f607,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-370aa0b4-7516-40af-b304-a6329147ac59,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-43faaea6-5b5e-4ecc-898a-eba70f3fb4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-60926d7c-8a10-410d-a26d-a151712f86ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-a2e07c18-fc39-448a-9afc-f7bfe6064811,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418960608-172.17.0.20-1597325108591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37977,DS-e19b50e4-8940-44ec-9379-e601f22c40e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-ebaf9aff-0a2a-409c-ab09-e65afd56fab1,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-e2b7fb6e-9be5-4e87-b3a8-172b272b6fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-12486834-4df6-4e40-9bd7-1a07881867fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-ce4c85b0-545f-48fd-8521-c6d619ade5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-7b7d7ab2-79f0-43c9-b73f-656b757ffedd,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-9a03ad41-77f5-4799-9a57-ca3ac409ad31,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-ab60fb46-24e9-4de7-b25a-9ec7320762ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1418960608-172.17.0.20-1597325108591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37977,DS-e19b50e4-8940-44ec-9379-e601f22c40e8,DISK], DatanodeInfoWithStorage[127.0.0.1:43140,DS-ebaf9aff-0a2a-409c-ab09-e65afd56fab1,DISK], DatanodeInfoWithStorage[127.0.0.1:44338,DS-e2b7fb6e-9be5-4e87-b3a8-172b272b6fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-12486834-4df6-4e40-9bd7-1a07881867fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-ce4c85b0-545f-48fd-8521-c6d619ade5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-7b7d7ab2-79f0-43c9-b73f-656b757ffedd,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-9a03ad41-77f5-4799-9a57-ca3ac409ad31,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-ab60fb46-24e9-4de7-b25a-9ec7320762ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688438028-172.17.0.20-1597325951265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40264,DS-b7c3f457-53e9-4585-928d-dee5783dc310,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-540ffc5c-d0b3-496f-902b-65d521d2e843,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-69443610-74ba-478f-a0fb-6389596a3a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-96770f36-ca89-4249-b0a2-05c1df51000f,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-13fd00e5-b8d9-48fb-a79f-5a25e5783f23,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-0e6a16ef-18ca-4487-b7af-17185282956d,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-671a6af0-6174-40de-87ca-e1e391ee8843,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-5e03f868-998c-48f9-88ec-f4341d8d422f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688438028-172.17.0.20-1597325951265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40264,DS-b7c3f457-53e9-4585-928d-dee5783dc310,DISK], DatanodeInfoWithStorage[127.0.0.1:35772,DS-540ffc5c-d0b3-496f-902b-65d521d2e843,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-69443610-74ba-478f-a0fb-6389596a3a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-96770f36-ca89-4249-b0a2-05c1df51000f,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-13fd00e5-b8d9-48fb-a79f-5a25e5783f23,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-0e6a16ef-18ca-4487-b7af-17185282956d,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-671a6af0-6174-40de-87ca-e1e391ee8843,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-5e03f868-998c-48f9-88ec-f4341d8d422f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-678735833-172.17.0.20-1597326024527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35804,DS-b973420b-8bd3-4b21-b5c1-99704ac829a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-cf83c369-3ffc-40d8-b9a4-35bbe480937e,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-2cebaf89-5436-446d-b3af-0b3760e14614,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-078519e3-8cd7-4121-9f8f-e476671a65c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-3fd7f138-0417-49cb-8c0b-f1c29f3bfb09,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-3d21edb7-b8fe-443e-a71a-cb0862974756,DISK], DatanodeInfoWithStorage[127.0.0.1:41762,DS-262c2f55-a9a0-4741-858f-41de0caefa97,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-9c778e6a-b29e-401e-914a-a638d3419a40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-678735833-172.17.0.20-1597326024527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35804,DS-b973420b-8bd3-4b21-b5c1-99704ac829a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-cf83c369-3ffc-40d8-b9a4-35bbe480937e,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-2cebaf89-5436-446d-b3af-0b3760e14614,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-078519e3-8cd7-4121-9f8f-e476671a65c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42433,DS-3fd7f138-0417-49cb-8c0b-f1c29f3bfb09,DISK], DatanodeInfoWithStorage[127.0.0.1:39255,DS-3d21edb7-b8fe-443e-a71a-cb0862974756,DISK], DatanodeInfoWithStorage[127.0.0.1:41762,DS-262c2f55-a9a0-4741-858f-41de0caefa97,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-9c778e6a-b29e-401e-914a-a638d3419a40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-216098871-172.17.0.20-1597326404681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46704,DS-1ee95d35-a15a-4ae0-983d-6d3b8658489f,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-661fe8f1-9e25-48e2-84e4-cdea75c67a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-ffbf85fa-8eca-4e62-8e0e-97f9930ac225,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-c2f4e99f-ea08-4fde-935b-f7ab70bb6574,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-3e917f1c-4286-494c-b43f-c083b3d39c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-fbca88aa-862a-45ba-81c9-4b450c52e6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-875051df-d24f-428b-94c4-ab1d1f7452be,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-fd3c8762-84f0-45c7-b7ac-7cc8b5d5f949,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-216098871-172.17.0.20-1597326404681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46704,DS-1ee95d35-a15a-4ae0-983d-6d3b8658489f,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-661fe8f1-9e25-48e2-84e4-cdea75c67a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35481,DS-ffbf85fa-8eca-4e62-8e0e-97f9930ac225,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-c2f4e99f-ea08-4fde-935b-f7ab70bb6574,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-3e917f1c-4286-494c-b43f-c083b3d39c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36653,DS-fbca88aa-862a-45ba-81c9-4b450c52e6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-875051df-d24f-428b-94c4-ab1d1f7452be,DISK], DatanodeInfoWithStorage[127.0.0.1:39533,DS-fd3c8762-84f0-45c7-b7ac-7cc8b5d5f949,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-743330497-172.17.0.20-1597326732548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35629,DS-ddc8db2d-6bf2-4faf-8fd2-9bd269820ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-b47abf28-d70e-4028-bf38-376846be7d78,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-bebbbeda-3aa2-4209-af79-5aea050941a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-36eabda4-52a4-4fe3-a507-ca75d103d3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-615c2d83-1241-47d8-bd04-91855b252b54,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-bc1aad0e-3998-4477-aa5f-996386b0c0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-07c20ae1-917e-47bc-8ff8-5c5f391a1514,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-0b217255-0a87-4702-aba4-8d9834a13fea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-743330497-172.17.0.20-1597326732548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35629,DS-ddc8db2d-6bf2-4faf-8fd2-9bd269820ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-b47abf28-d70e-4028-bf38-376846be7d78,DISK], DatanodeInfoWithStorage[127.0.0.1:44830,DS-bebbbeda-3aa2-4209-af79-5aea050941a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45516,DS-36eabda4-52a4-4fe3-a507-ca75d103d3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-615c2d83-1241-47d8-bd04-91855b252b54,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-bc1aad0e-3998-4477-aa5f-996386b0c0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-07c20ae1-917e-47bc-8ff8-5c5f391a1514,DISK], DatanodeInfoWithStorage[127.0.0.1:33220,DS-0b217255-0a87-4702-aba4-8d9834a13fea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122656086-172.17.0.20-1597326770293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45908,DS-fb399074-8ad5-447a-a4e1-0f8ae0ea6baf,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-c88cfeb2-3ee4-4890-bda2-9153051c8359,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-b4eda601-c078-4fea-bbf5-73b291834776,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-33059f8a-ba77-4924-9eae-7b284543f766,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-fffd2e63-ebb8-4adb-817b-967592240757,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-ce147603-3094-4529-98db-53f88d8cd7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-aad04d71-2b1b-4c76-bd6c-0328746c3ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-174924e1-73e2-4d64-954d-eeac4f228983,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1122656086-172.17.0.20-1597326770293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45908,DS-fb399074-8ad5-447a-a4e1-0f8ae0ea6baf,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-c88cfeb2-3ee4-4890-bda2-9153051c8359,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-b4eda601-c078-4fea-bbf5-73b291834776,DISK], DatanodeInfoWithStorage[127.0.0.1:40761,DS-33059f8a-ba77-4924-9eae-7b284543f766,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-fffd2e63-ebb8-4adb-817b-967592240757,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-ce147603-3094-4529-98db-53f88d8cd7f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-aad04d71-2b1b-4c76-bd6c-0328746c3ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-174924e1-73e2-4d64-954d-eeac4f228983,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-170022613-172.17.0.20-1597327169767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40525,DS-1d71021c-13b6-4948-a23d-082feed46692,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-ccf04832-8ea9-49ad-8506-ce06379f3edf,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-140fb4fc-0fac-45cd-a4b7-490a45d07741,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-6b0ee3c1-93cd-478e-a1c1-51ba730e8a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-07f564d7-a0b4-4682-89a8-76b379e974e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-3b4106b2-502d-4e02-aae2-02349cd77f85,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-68db2c8c-f9b7-486e-b297-945621ed2eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-56c05805-455d-4fd0-97a6-55e3de760b6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-170022613-172.17.0.20-1597327169767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40525,DS-1d71021c-13b6-4948-a23d-082feed46692,DISK], DatanodeInfoWithStorage[127.0.0.1:38510,DS-ccf04832-8ea9-49ad-8506-ce06379f3edf,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-140fb4fc-0fac-45cd-a4b7-490a45d07741,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-6b0ee3c1-93cd-478e-a1c1-51ba730e8a5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44585,DS-07f564d7-a0b4-4682-89a8-76b379e974e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-3b4106b2-502d-4e02-aae2-02349cd77f85,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-68db2c8c-f9b7-486e-b297-945621ed2eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38511,DS-56c05805-455d-4fd0-97a6-55e3de760b6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-175091278-172.17.0.20-1597327347859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39276,DS-87dacdb3-50d1-4fe2-9370-96b370f02bde,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-1afbdba4-0bb7-49bb-9489-f24187c78080,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-af3c4038-2fab-48df-8b73-4caccf36f3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-ab02eaf3-bef6-41af-b672-15d50c5c6d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-83e6c0e3-576d-4f85-807a-f504c8be4df9,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-9104d08e-2809-4b44-98d8-4083b9b9bde8,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-b4f9a1d2-1e3d-442d-b560-bc5a0292f1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35630,DS-03a8c440-5eee-4faa-8d7b-b68f8142bd1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-175091278-172.17.0.20-1597327347859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39276,DS-87dacdb3-50d1-4fe2-9370-96b370f02bde,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-1afbdba4-0bb7-49bb-9489-f24187c78080,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-af3c4038-2fab-48df-8b73-4caccf36f3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-ab02eaf3-bef6-41af-b672-15d50c5c6d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-83e6c0e3-576d-4f85-807a-f504c8be4df9,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-9104d08e-2809-4b44-98d8-4083b9b9bde8,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-b4f9a1d2-1e3d-442d-b560-bc5a0292f1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35630,DS-03a8c440-5eee-4faa-8d7b-b68f8142bd1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1778469718-172.17.0.20-1597327525073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45282,DS-91330652-e6c3-4d61-9a5e-a458a4e4f93d,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-1cb5f33d-e4de-46fc-84e8-e860fa4f05ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-7f38df24-d556-4d5c-9326-085a5972adfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-44d8e0e2-e14d-41a6-b670-cbf7526a5e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-ae699982-953e-4a3b-bc76-0efd6b27a336,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-f85f8613-fda2-468d-8228-c95dd4ad20fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-574ed590-169b-4dea-b64d-189c47c709d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-687e4a86-bf5e-403d-8396-c23c0e8f6af5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1778469718-172.17.0.20-1597327525073:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45282,DS-91330652-e6c3-4d61-9a5e-a458a4e4f93d,DISK], DatanodeInfoWithStorage[127.0.0.1:45615,DS-1cb5f33d-e4de-46fc-84e8-e860fa4f05ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-7f38df24-d556-4d5c-9326-085a5972adfe,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-44d8e0e2-e14d-41a6-b670-cbf7526a5e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-ae699982-953e-4a3b-bc76-0efd6b27a336,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-f85f8613-fda2-468d-8228-c95dd4ad20fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-574ed590-169b-4dea-b64d-189c47c709d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-687e4a86-bf5e-403d-8396-c23c0e8f6af5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-462666100-172.17.0.20-1597328004664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37972,DS-dfd74238-438f-4a86-a07a-4585e612b120,DISK], DatanodeInfoWithStorage[127.0.0.1:38318,DS-b8aed8cd-25aa-4c2b-943f-97bfad4e88fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34010,DS-9cc91353-0e09-405c-848d-815530e5f54e,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-14bf9492-dbf3-45de-8af2-fcb09e284a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-7e3604ce-f9b1-4e0f-8921-45f29e290b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-b608224e-30f2-418f-964d-a641a5750fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-8cd404ef-c450-4244-abee-15afc6ae4d71,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-74d2d303-e9f1-4221-9ebf-ba22464d1850,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-462666100-172.17.0.20-1597328004664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37972,DS-dfd74238-438f-4a86-a07a-4585e612b120,DISK], DatanodeInfoWithStorage[127.0.0.1:38318,DS-b8aed8cd-25aa-4c2b-943f-97bfad4e88fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34010,DS-9cc91353-0e09-405c-848d-815530e5f54e,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-14bf9492-dbf3-45de-8af2-fcb09e284a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45748,DS-7e3604ce-f9b1-4e0f-8921-45f29e290b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35818,DS-b608224e-30f2-418f-964d-a641a5750fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-8cd404ef-c450-4244-abee-15afc6ae4d71,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-74d2d303-e9f1-4221-9ebf-ba22464d1850,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-76594536-172.17.0.20-1597328423811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35736,DS-2fee0986-20d5-41fa-8d67-c56e64b9f599,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-3c549f95-98e9-4a42-983d-02464e1bb2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-438dbc40-3589-46cd-bb34-ab0fe92d2a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-2a5aadfe-4a87-403f-b6f7-868d4262bf0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-2aadca2b-8f10-4713-9e5a-6f5eebddc461,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-c97b53b2-b1b1-4808-97d0-2dd1039d4d14,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-3e38206c-724f-4e1e-b255-3d2f04988965,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-688afe22-ae26-4a54-b9d3-8c00888ec14d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-76594536-172.17.0.20-1597328423811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35736,DS-2fee0986-20d5-41fa-8d67-c56e64b9f599,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-3c549f95-98e9-4a42-983d-02464e1bb2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-438dbc40-3589-46cd-bb34-ab0fe92d2a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41401,DS-2a5aadfe-4a87-403f-b6f7-868d4262bf0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-2aadca2b-8f10-4713-9e5a-6f5eebddc461,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-c97b53b2-b1b1-4808-97d0-2dd1039d4d14,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-3e38206c-724f-4e1e-b255-3d2f04988965,DISK], DatanodeInfoWithStorage[127.0.0.1:42358,DS-688afe22-ae26-4a54-b9d3-8c00888ec14d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330828753-172.17.0.20-1597328506602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41347,DS-ec2b766d-330d-4672-9a17-c64d7a25d980,DISK], DatanodeInfoWithStorage[127.0.0.1:46800,DS-8ec72a6e-b028-4179-b73a-ed2032a7c639,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-9966153c-a32a-460f-91bb-4feb65eaec3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33492,DS-57653349-fe82-4cad-be25-27652eb2a942,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-b5ab4a81-559c-4122-9303-59273276231a,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-b6558195-5afd-48c2-8da7-41e3736bb539,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-d13ec438-e567-4388-a77b-70172ee16f17,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-e31fca31-4a97-4346-b904-9eb6cb0bcfea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1330828753-172.17.0.20-1597328506602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41347,DS-ec2b766d-330d-4672-9a17-c64d7a25d980,DISK], DatanodeInfoWithStorage[127.0.0.1:46800,DS-8ec72a6e-b028-4179-b73a-ed2032a7c639,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-9966153c-a32a-460f-91bb-4feb65eaec3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33492,DS-57653349-fe82-4cad-be25-27652eb2a942,DISK], DatanodeInfoWithStorage[127.0.0.1:35339,DS-b5ab4a81-559c-4122-9303-59273276231a,DISK], DatanodeInfoWithStorage[127.0.0.1:43536,DS-b6558195-5afd-48c2-8da7-41e3736bb539,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-d13ec438-e567-4388-a77b-70172ee16f17,DISK], DatanodeInfoWithStorage[127.0.0.1:34607,DS-e31fca31-4a97-4346-b904-9eb6cb0bcfea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-593343311-172.17.0.20-1597328705980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41884,DS-25ba1501-b6f8-411b-a956-e3204c69895e,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-e154ef4c-9dba-4054-a1d6-05e869c5e8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-5408663a-3385-4b4f-aef5-63a6a7c0bee1,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-83e88c93-7909-46cf-9fb3-9db405e5ed24,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-ba87cc99-5c23-48bc-9458-6ee5a05e4ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-45702791-32cf-4aba-a4aa-a52ff182df6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-fd918c43-6845-4ccc-9d31-fb0342b66636,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-e9ac87d1-e197-4ed4-84bc-2da7c2cd72b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-593343311-172.17.0.20-1597328705980:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41884,DS-25ba1501-b6f8-411b-a956-e3204c69895e,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-e154ef4c-9dba-4054-a1d6-05e869c5e8c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-5408663a-3385-4b4f-aef5-63a6a7c0bee1,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-83e88c93-7909-46cf-9fb3-9db405e5ed24,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-ba87cc99-5c23-48bc-9458-6ee5a05e4ee3,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-45702791-32cf-4aba-a4aa-a52ff182df6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-fd918c43-6845-4ccc-9d31-fb0342b66636,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-e9ac87d1-e197-4ed4-84bc-2da7c2cd72b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-326298876-172.17.0.20-1597328785116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41485,DS-fbb87d73-3909-4531-83b6-d20c56b1b03b,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-e17c3440-0fc4-4908-a7bd-2a81c890f81c,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-cf96de52-f98d-48e2-bb82-736b3186d504,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-d61f15b5-7458-4cbe-a35e-cfb323782a12,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-2519d4f3-0344-45e1-a442-08079ecc76cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-c7fdb34f-0ebe-428c-8403-688ea28add1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-447f4925-e9aa-4238-9ecc-281a2077cba8,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-3d3c7bca-7754-4b1f-88cf-d091a582cfd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-326298876-172.17.0.20-1597328785116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41485,DS-fbb87d73-3909-4531-83b6-d20c56b1b03b,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-e17c3440-0fc4-4908-a7bd-2a81c890f81c,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-cf96de52-f98d-48e2-bb82-736b3186d504,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-d61f15b5-7458-4cbe-a35e-cfb323782a12,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-2519d4f3-0344-45e1-a442-08079ecc76cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-c7fdb34f-0ebe-428c-8403-688ea28add1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-447f4925-e9aa-4238-9ecc-281a2077cba8,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-3d3c7bca-7754-4b1f-88cf-d091a582cfd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blockreport.initialDelay
component: hdfs:DataNode
v1: 30s
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2134380071-172.17.0.20-1597328855468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41088,DS-0d3260c2-0eba-4acb-9418-f2332d1dfbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-d78bbb72-19d5-4d04-960c-b44c9c7ea9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-2163a7dc-260d-45fe-b8b9-43987e21f2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-05150a31-1cbd-4f58-be82-46ce71b599b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-785b7379-f607-489d-9fd6-9eed83bb05ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-06e90a79-4554-46d9-aff6-5a30bbef9ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-7472f852-eb85-42fa-a9d1-0319e6cd9ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-181710a0-5af6-4247-ab3b-efa16170c0dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2134380071-172.17.0.20-1597328855468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41088,DS-0d3260c2-0eba-4acb-9418-f2332d1dfbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-d78bbb72-19d5-4d04-960c-b44c9c7ea9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-2163a7dc-260d-45fe-b8b9-43987e21f2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-05150a31-1cbd-4f58-be82-46ce71b599b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39914,DS-785b7379-f607-489d-9fd6-9eed83bb05ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-06e90a79-4554-46d9-aff6-5a30bbef9ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:41047,DS-7472f852-eb85-42fa-a9d1-0319e6cd9ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-181710a0-5af6-4247-ab3b-efa16170c0dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5618
