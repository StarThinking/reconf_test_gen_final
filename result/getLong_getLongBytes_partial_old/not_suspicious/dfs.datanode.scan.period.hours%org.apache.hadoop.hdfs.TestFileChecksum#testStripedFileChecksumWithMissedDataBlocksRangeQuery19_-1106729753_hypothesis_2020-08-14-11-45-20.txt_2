reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-910840755-172.17.0.10-1597405757882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41735,DS-3b819ecc-e33c-4b27-9a93-69d5d940035d,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-ea717d73-7250-41f4-8606-1def01d7cb66,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-fcee3e85-1348-4b59-8727-fe90fdd19668,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-65957c40-d58c-4935-b610-8957ffee5f08,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-6315aa8b-536f-473d-a7f9-c154615a148f,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-104eec14-6511-4c45-896b-20a2ef4e53d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-b66b4fa1-902c-4669-80f3-7a557ebd4cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-3e20b245-2e64-4c51-a49d-bb2c0b11eb71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-910840755-172.17.0.10-1597405757882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41735,DS-3b819ecc-e33c-4b27-9a93-69d5d940035d,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-ea717d73-7250-41f4-8606-1def01d7cb66,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-fcee3e85-1348-4b59-8727-fe90fdd19668,DISK], DatanodeInfoWithStorage[127.0.0.1:39524,DS-65957c40-d58c-4935-b610-8957ffee5f08,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-6315aa8b-536f-473d-a7f9-c154615a148f,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-104eec14-6511-4c45-896b-20a2ef4e53d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-b66b4fa1-902c-4669-80f3-7a557ebd4cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40349,DS-3e20b245-2e64-4c51-a49d-bb2c0b11eb71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-30054404-172.17.0.10-1597406316786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33893,DS-5944a8a4-c9ab-49ef-8660-3c2bc9096715,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-c8862a75-b284-4627-8c36-79e322bfa622,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-3186926a-3fde-47f2-9888-ee15061fa943,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-92cde90a-c5c2-491c-8afd-3176207a06ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-33bd0452-bd4c-4cb2-b6e5-af5475df71d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-2b7f5e5c-8fda-4132-9f5a-bcafd53650c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-190c1153-bed9-4c5b-8517-d7b6e6fb4076,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-a00263b4-4b7d-4513-97bf-f064e3955957,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-30054404-172.17.0.10-1597406316786:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33893,DS-5944a8a4-c9ab-49ef-8660-3c2bc9096715,DISK], DatanodeInfoWithStorage[127.0.0.1:45308,DS-c8862a75-b284-4627-8c36-79e322bfa622,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-3186926a-3fde-47f2-9888-ee15061fa943,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-92cde90a-c5c2-491c-8afd-3176207a06ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-33bd0452-bd4c-4cb2-b6e5-af5475df71d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-2b7f5e5c-8fda-4132-9f5a-bcafd53650c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-190c1153-bed9-4c5b-8517-d7b6e6fb4076,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-a00263b4-4b7d-4513-97bf-f064e3955957,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2100338434-172.17.0.10-1597406654634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33741,DS-7494a3d3-e4d9-4240-8e83-1730d54feb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-c1f1d5be-98ab-4938-a442-45d009ec32d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-cc024d16-0957-4688-9294-9402ee34806d,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-eeb29856-1b48-42a8-bd7f-277432505287,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-d7a86517-280a-41f2-a33b-fe952006b7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-a28f8a88-6bf3-4af6-a373-c5346e806ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-91085b57-3595-487a-b1f2-2635deda37af,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-178d1f53-4941-4725-b874-8d1046c097b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2100338434-172.17.0.10-1597406654634:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33741,DS-7494a3d3-e4d9-4240-8e83-1730d54feb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-c1f1d5be-98ab-4938-a442-45d009ec32d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-cc024d16-0957-4688-9294-9402ee34806d,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-eeb29856-1b48-42a8-bd7f-277432505287,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-d7a86517-280a-41f2-a33b-fe952006b7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-a28f8a88-6bf3-4af6-a373-c5346e806ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-91085b57-3595-487a-b1f2-2635deda37af,DISK], DatanodeInfoWithStorage[127.0.0.1:36370,DS-178d1f53-4941-4725-b874-8d1046c097b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-58654423-172.17.0.10-1597407364272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41049,DS-c14d7b03-924d-4a07-98c1-a1af6c0abc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-6c0a0003-33a6-4da3-aedb-8222e262cfc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-f36a33af-27a3-42a2-9bea-fbc872e6d100,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-58e4fdc2-34ab-4263-844c-a17169b88860,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-60c383f8-b1dd-4241-bf4d-b1aeca458510,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-9843af9c-a054-4d3b-aad9-b47e5c9a01ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-b3507133-2188-4983-8760-c433c7282204,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-39d6de79-03f0-4f9f-bb1f-56568da5e553,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-58654423-172.17.0.10-1597407364272:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41049,DS-c14d7b03-924d-4a07-98c1-a1af6c0abc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-6c0a0003-33a6-4da3-aedb-8222e262cfc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-f36a33af-27a3-42a2-9bea-fbc872e6d100,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-58e4fdc2-34ab-4263-844c-a17169b88860,DISK], DatanodeInfoWithStorage[127.0.0.1:43898,DS-60c383f8-b1dd-4241-bf4d-b1aeca458510,DISK], DatanodeInfoWithStorage[127.0.0.1:42134,DS-9843af9c-a054-4d3b-aad9-b47e5c9a01ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-b3507133-2188-4983-8760-c433c7282204,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-39d6de79-03f0-4f9f-bb1f-56568da5e553,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-845696329-172.17.0.10-1597407828528:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35813,DS-9219993b-46ab-4044-a6ef-7f6dc8b82d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-b7b13f7d-064a-4998-a0ee-b0c68e06d52c,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-36327d19-a9ee-450d-b3b3-6b936b3da825,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-ca8662c5-bc33-4f1b-b76b-2cb28087d897,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-9267d7d7-43f0-4a90-a037-78f57532220c,DISK], DatanodeInfoWithStorage[127.0.0.1:35503,DS-cb9428c2-0884-4ec1-9477-8cf49fb81e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-9c6f0fe8-b3df-4fbc-954e-c0237559a8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-c556105f-a5c5-40e5-9c3c-60c1703f0783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-845696329-172.17.0.10-1597407828528:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35813,DS-9219993b-46ab-4044-a6ef-7f6dc8b82d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38807,DS-b7b13f7d-064a-4998-a0ee-b0c68e06d52c,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-36327d19-a9ee-450d-b3b3-6b936b3da825,DISK], DatanodeInfoWithStorage[127.0.0.1:40437,DS-ca8662c5-bc33-4f1b-b76b-2cb28087d897,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-9267d7d7-43f0-4a90-a037-78f57532220c,DISK], DatanodeInfoWithStorage[127.0.0.1:35503,DS-cb9428c2-0884-4ec1-9477-8cf49fb81e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-9c6f0fe8-b3df-4fbc-954e-c0237559a8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-c556105f-a5c5-40e5-9c3c-60c1703f0783,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1228267023-172.17.0.10-1597408666771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46353,DS-01c5eb59-821c-4da5-bd37-af641bfce7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-c01b2c5b-0fff-4fc0-8127-55cb71b70f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-d9d3d719-81a5-4cb6-a02b-49565c0ec959,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-6bf0cc9e-8e57-412b-a390-79f1600adc54,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-f6782f62-9f2f-489d-b395-7acf483460b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-f0d36609-2fe5-4638-929d-db7c51a7ea13,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-0d3472d7-0d10-4892-b1b4-80aa137cde51,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-1a16d28b-aa39-4fd8-bed5-e47965250e0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1228267023-172.17.0.10-1597408666771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46353,DS-01c5eb59-821c-4da5-bd37-af641bfce7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-c01b2c5b-0fff-4fc0-8127-55cb71b70f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:33463,DS-d9d3d719-81a5-4cb6-a02b-49565c0ec959,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-6bf0cc9e-8e57-412b-a390-79f1600adc54,DISK], DatanodeInfoWithStorage[127.0.0.1:39677,DS-f6782f62-9f2f-489d-b395-7acf483460b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-f0d36609-2fe5-4638-929d-db7c51a7ea13,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-0d3472d7-0d10-4892-b1b4-80aa137cde51,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-1a16d28b-aa39-4fd8-bed5-e47965250e0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1826143246-172.17.0.10-1597408809933:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41833,DS-b9fb54e1-f82b-4c71-a929-5842303d11e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-0ffa2a85-1328-42c2-9ef7-c24548977d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-79280ad7-17f7-475a-b6ae-2f087fcf3062,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-7d15d5a2-d7b2-48a6-80ff-63ddd61074ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-c67cffcc-662e-4b83-a994-59094b39bbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-a6e24506-8287-413d-a1eb-273661657ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-75ef52da-19ed-46ff-9d90-4cf906cacfc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-f9f835f8-db75-4152-a56c-f91982e88b46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1826143246-172.17.0.10-1597408809933:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41833,DS-b9fb54e1-f82b-4c71-a929-5842303d11e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-0ffa2a85-1328-42c2-9ef7-c24548977d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-79280ad7-17f7-475a-b6ae-2f087fcf3062,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-7d15d5a2-d7b2-48a6-80ff-63ddd61074ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-c67cffcc-662e-4b83-a994-59094b39bbf8,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-a6e24506-8287-413d-a1eb-273661657ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-75ef52da-19ed-46ff-9d90-4cf906cacfc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-f9f835f8-db75-4152-a56c-f91982e88b46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1163457871-172.17.0.10-1597409315082:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34251,DS-49f7a4a3-6b4d-477f-9c30-b9c8e8ecd480,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-095a6c93-9c32-47b9-97d6-37cf3483c756,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-b67384b8-e06b-4c8c-81e5-698cde8fda72,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-c1ac8e65-51e1-487a-8401-63138fbe124e,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-911aa836-a78f-41db-9cd3-84c59f1bef88,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-934f4d49-8dbe-44e1-ab76-f0817549cf0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-d616fa1a-1c45-4af8-b97b-0cbe534ebcee,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-fba94893-8083-43b5-9f09-d094897a10c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1163457871-172.17.0.10-1597409315082:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34251,DS-49f7a4a3-6b4d-477f-9c30-b9c8e8ecd480,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-095a6c93-9c32-47b9-97d6-37cf3483c756,DISK], DatanodeInfoWithStorage[127.0.0.1:43050,DS-b67384b8-e06b-4c8c-81e5-698cde8fda72,DISK], DatanodeInfoWithStorage[127.0.0.1:36386,DS-c1ac8e65-51e1-487a-8401-63138fbe124e,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-911aa836-a78f-41db-9cd3-84c59f1bef88,DISK], DatanodeInfoWithStorage[127.0.0.1:35972,DS-934f4d49-8dbe-44e1-ab76-f0817549cf0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44602,DS-d616fa1a-1c45-4af8-b97b-0cbe534ebcee,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-fba94893-8083-43b5-9f09-d094897a10c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1093890544-172.17.0.10-1597409465750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34519,DS-7e6044a1-f7c2-44a7-a99e-c091d93a99c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-5e5a1af4-4ff8-4f77-afb1-a85eb83e3bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-f7ab39b0-5ef2-4d8a-a711-1ebf2fb8bd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-4febda46-e673-4fc9-b5c4-cff4a813aeec,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-fd7ccc91-3c90-457f-a029-ae2d97397e91,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-811716dc-f47f-40b8-91bc-bea6b3c81244,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-815c7da1-e2b2-40f0-acc3-08ad938bd231,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-81ea9f8b-b4d3-4857-95a8-597f7761a0dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1093890544-172.17.0.10-1597409465750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34519,DS-7e6044a1-f7c2-44a7-a99e-c091d93a99c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-5e5a1af4-4ff8-4f77-afb1-a85eb83e3bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-f7ab39b0-5ef2-4d8a-a711-1ebf2fb8bd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45318,DS-4febda46-e673-4fc9-b5c4-cff4a813aeec,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-fd7ccc91-3c90-457f-a029-ae2d97397e91,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-811716dc-f47f-40b8-91bc-bea6b3c81244,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-815c7da1-e2b2-40f0-acc3-08ad938bd231,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-81ea9f8b-b4d3-4857-95a8-597f7761a0dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-56899172-172.17.0.10-1597409504799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46528,DS-c47e433e-920f-4f2b-a072-69a6dc27a8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-6af628ef-9820-45b5-86d4-548c59d5148c,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-a93b6054-bc75-4051-baac-8a0966aba60e,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-f09c7bcb-ada5-4349-9767-b933a2f9ce11,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-3f687160-2c9a-48ec-892a-1de554b046f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-3c344d7c-3d44-45c8-88d9-f00a6ab37d71,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-0dea9aad-dd5d-4cd3-83c8-bbddcfb4cfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-5eb83d0f-56be-4b6e-868c-786cf52b0c52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-56899172-172.17.0.10-1597409504799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46528,DS-c47e433e-920f-4f2b-a072-69a6dc27a8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-6af628ef-9820-45b5-86d4-548c59d5148c,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-a93b6054-bc75-4051-baac-8a0966aba60e,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-f09c7bcb-ada5-4349-9767-b933a2f9ce11,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-3f687160-2c9a-48ec-892a-1de554b046f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-3c344d7c-3d44-45c8-88d9-f00a6ab37d71,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-0dea9aad-dd5d-4cd3-83c8-bbddcfb4cfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-5eb83d0f-56be-4b6e-868c-786cf52b0c52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-489032492-172.17.0.10-1597409542441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44719,DS-1ee8f5e4-d77b-49e5-ac69-8cf7e7189085,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-8186ef48-4e08-4374-af4b-e09d6a16e1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-c5f2fe43-379b-46cc-a281-6b6dabb1ff71,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-0295a5bd-5a1d-4b68-88de-48b9c7f74387,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-2e4d3837-85b2-4e6b-919c-18f0e313f849,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-252a9d00-4df2-464f-ab27-ddb4ac46c2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-c77c1326-0b64-41db-9f3a-af9de7d28911,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-0d10cf0f-fd5f-423b-a783-fdfe595f92de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-489032492-172.17.0.10-1597409542441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44719,DS-1ee8f5e4-d77b-49e5-ac69-8cf7e7189085,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-8186ef48-4e08-4374-af4b-e09d6a16e1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-c5f2fe43-379b-46cc-a281-6b6dabb1ff71,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-0295a5bd-5a1d-4b68-88de-48b9c7f74387,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-2e4d3837-85b2-4e6b-919c-18f0e313f849,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-252a9d00-4df2-464f-ab27-ddb4ac46c2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37271,DS-c77c1326-0b64-41db-9f3a-af9de7d28911,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-0d10cf0f-fd5f-423b-a783-fdfe595f92de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-207562264-172.17.0.10-1597409871502:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41400,DS-e3f40b0b-2c65-478d-b4fd-3ccf1b66b7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-9d029ebd-ea51-45bd-bae9-6c937f760cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-3fa12894-a0fa-4709-bb8f-03ddc1943429,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-f127d548-144c-4065-842d-7e964b57a6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-1710b432-04ad-4c0e-9ed5-1b1555a4a05f,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-045ac2bb-70f0-462a-9edf-2f47e51a1e49,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-5cbeb962-5a93-401c-9c9b-428064d85fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-2ff74914-5c3e-486b-a06c-0ecef0cf8c6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-207562264-172.17.0.10-1597409871502:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41400,DS-e3f40b0b-2c65-478d-b4fd-3ccf1b66b7ad,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-9d029ebd-ea51-45bd-bae9-6c937f760cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-3fa12894-a0fa-4709-bb8f-03ddc1943429,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-f127d548-144c-4065-842d-7e964b57a6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-1710b432-04ad-4c0e-9ed5-1b1555a4a05f,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-045ac2bb-70f0-462a-9edf-2f47e51a1e49,DISK], DatanodeInfoWithStorage[127.0.0.1:44200,DS-5cbeb962-5a93-401c-9c9b-428064d85fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-2ff74914-5c3e-486b-a06c-0ecef0cf8c6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2065902578-172.17.0.10-1597409902876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42544,DS-f57dd0b1-b15b-4dde-a27b-00471524caf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-fa03aef7-2bef-46ae-8a41-b2b860e19645,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-82dfb545-7954-4a98-ae1f-564b8cbb93be,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-ad7096c2-d686-4534-94a8-85f366a2d460,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-6c9298f0-7f70-4047-ac7a-11f9bb34ec0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-3b9b25b7-76de-4af5-a4fb-a8cb3853c8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-de07ce17-0d3a-4806-a52b-37a129e2b583,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-846313ad-6150-417b-afbc-7027f0484208,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2065902578-172.17.0.10-1597409902876:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42544,DS-f57dd0b1-b15b-4dde-a27b-00471524caf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-fa03aef7-2bef-46ae-8a41-b2b860e19645,DISK], DatanodeInfoWithStorage[127.0.0.1:33597,DS-82dfb545-7954-4a98-ae1f-564b8cbb93be,DISK], DatanodeInfoWithStorage[127.0.0.1:46116,DS-ad7096c2-d686-4534-94a8-85f366a2d460,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-6c9298f0-7f70-4047-ac7a-11f9bb34ec0a,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-3b9b25b7-76de-4af5-a4fb-a8cb3853c8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-de07ce17-0d3a-4806-a52b-37a129e2b583,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-846313ad-6150-417b-afbc-7027f0484208,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-604341258-172.17.0.10-1597410661125:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44639,DS-16300822-3ac7-4c45-b14b-453f31f98cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-c89acb83-e6d5-4f1b-9316-b0f6b4f97723,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-1e0fdb4b-23c6-4a7e-861c-9857b8142b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-a82bb4da-ff32-4c6a-aea3-6c56e569340f,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-3a168765-a6a4-488c-a05d-54e394eaa0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-a466e6e5-e28d-4719-9c78-b49507bc7493,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-d0e79cec-8139-49d8-bc4d-e5af241b5ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-24f8df62-6e1e-4955-9b53-e976af1234b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-604341258-172.17.0.10-1597410661125:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44639,DS-16300822-3ac7-4c45-b14b-453f31f98cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36083,DS-c89acb83-e6d5-4f1b-9316-b0f6b4f97723,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-1e0fdb4b-23c6-4a7e-861c-9857b8142b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41320,DS-a82bb4da-ff32-4c6a-aea3-6c56e569340f,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-3a168765-a6a4-488c-a05d-54e394eaa0c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-a466e6e5-e28d-4719-9c78-b49507bc7493,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-d0e79cec-8139-49d8-bc4d-e5af241b5ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:46710,DS-24f8df62-6e1e-4955-9b53-e976af1234b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.scan.period.hours
component: hdfs:DataNode
v1: 504
v2: -1
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-861967153-172.17.0.10-1597410703731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33033,DS-f473718f-7478-485e-bd97-168341f40212,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-e000cbbc-af74-4c85-91ae-00277f44ee6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-005a3429-dc87-427b-8a6e-bb005fd72786,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-8d1ab12f-59c6-44d2-b08b-5a5566a324ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-6afa0c6a-d524-45e7-9463-2a2f4115d0af,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-b46802b6-0e91-4c26-b635-6d768a8756d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-a7a05835-9e6d-48e5-beba-04afec551469,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-4ef95202-543e-4d6c-b1a6-2f2d0fd11b4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-861967153-172.17.0.10-1597410703731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33033,DS-f473718f-7478-485e-bd97-168341f40212,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-e000cbbc-af74-4c85-91ae-00277f44ee6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40342,DS-005a3429-dc87-427b-8a6e-bb005fd72786,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-8d1ab12f-59c6-44d2-b08b-5a5566a324ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-6afa0c6a-d524-45e7-9463-2a2f4115d0af,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-b46802b6-0e91-4c26-b635-6d768a8756d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-a7a05835-9e6d-48e5-beba-04afec551469,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-4ef95202-543e-4d6c-b1a6-2f2d0fd11b4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5503
