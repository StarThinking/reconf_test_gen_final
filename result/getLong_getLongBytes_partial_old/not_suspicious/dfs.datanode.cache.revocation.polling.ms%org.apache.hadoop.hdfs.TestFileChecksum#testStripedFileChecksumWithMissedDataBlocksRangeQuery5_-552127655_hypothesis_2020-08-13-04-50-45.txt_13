reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1033529193-172.17.0.15-1597294570518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35257,DS-70885123-5613-4e10-b2a8-8be7a968c1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-dc677b84-0fcd-46bd-a1b6-128702db67ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-11366679-6bb9-4746-9f61-4279899c9d40,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-fdd5dec6-12d8-4d2a-812d-e7dd8af77032,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-f0327551-aa02-4c44-8837-f84f17a47e74,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-f83b4800-ba95-4ffe-8c41-048d03650974,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-f7ebd6ad-bbd6-4317-b0be-cb09c0c569c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-f33a85b1-dfb2-4d35-959b-11106553d2f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1033529193-172.17.0.15-1597294570518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35257,DS-70885123-5613-4e10-b2a8-8be7a968c1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-dc677b84-0fcd-46bd-a1b6-128702db67ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-11366679-6bb9-4746-9f61-4279899c9d40,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-fdd5dec6-12d8-4d2a-812d-e7dd8af77032,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-f0327551-aa02-4c44-8837-f84f17a47e74,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-f83b4800-ba95-4ffe-8c41-048d03650974,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-f7ebd6ad-bbd6-4317-b0be-cb09c0c569c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-f33a85b1-dfb2-4d35-959b-11106553d2f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1228569696-172.17.0.15-1597295491437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39569,DS-39741a39-d36f-429f-a90e-ec0516c11f38,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-27b9cefc-aafc-4511-b36d-72d26def1c55,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-eb4b0ff5-b5b6-4336-8331-ac6dc8ab6e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-99eb56c1-776b-43fd-b289-28079c964b01,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-3435723d-b72f-4792-9c95-88b34c93b46b,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-f4f83cc8-cc40-4943-899f-2db34bcac02f,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-60f38bfb-0168-48f1-a892-86460be5b38a,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-8570b471-938b-48f5-ad23-8a4cb37309b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1228569696-172.17.0.15-1597295491437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39569,DS-39741a39-d36f-429f-a90e-ec0516c11f38,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-27b9cefc-aafc-4511-b36d-72d26def1c55,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-eb4b0ff5-b5b6-4336-8331-ac6dc8ab6e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-99eb56c1-776b-43fd-b289-28079c964b01,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-3435723d-b72f-4792-9c95-88b34c93b46b,DISK], DatanodeInfoWithStorage[127.0.0.1:39159,DS-f4f83cc8-cc40-4943-899f-2db34bcac02f,DISK], DatanodeInfoWithStorage[127.0.0.1:40618,DS-60f38bfb-0168-48f1-a892-86460be5b38a,DISK], DatanodeInfoWithStorage[127.0.0.1:38870,DS-8570b471-938b-48f5-ad23-8a4cb37309b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-530722423-172.17.0.15-1597296846364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36072,DS-1efd9187-742c-465f-8227-e8f4a2ea170a,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-66fc3da2-7782-47fd-b0cc-7cd2dfe2f968,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-9ef654df-d641-4f3f-92c3-bee36191c6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-e5a5282e-be97-4fe0-8b45-172be3a136ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-abe10a15-19c5-4bd2-9f6f-7e493446585b,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-00a0677a-d4dd-42b4-8a6a-d2acc2cc51a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-a8b6a562-7e49-4047-b7af-ece752787897,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-228d3b29-0989-4751-8ef8-34e1423dcc00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-530722423-172.17.0.15-1597296846364:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36072,DS-1efd9187-742c-465f-8227-e8f4a2ea170a,DISK], DatanodeInfoWithStorage[127.0.0.1:42866,DS-66fc3da2-7782-47fd-b0cc-7cd2dfe2f968,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-9ef654df-d641-4f3f-92c3-bee36191c6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-e5a5282e-be97-4fe0-8b45-172be3a136ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-abe10a15-19c5-4bd2-9f6f-7e493446585b,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-00a0677a-d4dd-42b4-8a6a-d2acc2cc51a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-a8b6a562-7e49-4047-b7af-ece752787897,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-228d3b29-0989-4751-8ef8-34e1423dcc00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1049362599-172.17.0.15-1597297117763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39031,DS-fd436242-6847-4f7f-b617-64df81fa06ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-dd81c761-dcae-4b80-836c-5064187b128a,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-dcfc9176-e5d6-441b-8736-3b5318aa68d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-183ce017-0363-4504-840f-f5be31739985,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-bec4d868-1d66-42c4-9c0d-95c8ac01dc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-3b1ea639-13bd-4794-b614-3cfb43609394,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-cb7d522b-8561-4480-87fe-6ee1d9e158fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-e3ea3acf-09d5-47db-acd6-83dc62fea31f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1049362599-172.17.0.15-1597297117763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39031,DS-fd436242-6847-4f7f-b617-64df81fa06ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-dd81c761-dcae-4b80-836c-5064187b128a,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-dcfc9176-e5d6-441b-8736-3b5318aa68d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-183ce017-0363-4504-840f-f5be31739985,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-bec4d868-1d66-42c4-9c0d-95c8ac01dc9e,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-3b1ea639-13bd-4794-b614-3cfb43609394,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-cb7d522b-8561-4480-87fe-6ee1d9e158fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-e3ea3acf-09d5-47db-acd6-83dc62fea31f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675523844-172.17.0.15-1597297157659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36017,DS-2ea69674-1db7-4a4e-b812-f574204c830e,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-343f9090-11a7-44ee-8f63-83232e98fb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-70a6410f-8f08-435f-a045-383dbbc79345,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-bf851b0d-9084-415b-a5c3-8e6d93fd2b24,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-5713c5a5-f11c-4600-93d9-4eb979771160,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-1e81fff2-7e25-4efb-88be-bec4913a302c,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-51dc98a3-370d-493b-af1d-5342d06e9c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-45dea45f-2fe3-44cc-a70b-41c555cb27da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675523844-172.17.0.15-1597297157659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36017,DS-2ea69674-1db7-4a4e-b812-f574204c830e,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-343f9090-11a7-44ee-8f63-83232e98fb3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40398,DS-70a6410f-8f08-435f-a045-383dbbc79345,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-bf851b0d-9084-415b-a5c3-8e6d93fd2b24,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-5713c5a5-f11c-4600-93d9-4eb979771160,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-1e81fff2-7e25-4efb-88be-bec4913a302c,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-51dc98a3-370d-493b-af1d-5342d06e9c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-45dea45f-2fe3-44cc-a70b-41c555cb27da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308851412-172.17.0.15-1597297354662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45740,DS-961e4150-62ca-4c15-ad53-79008592a39c,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-e09a3acb-dc33-4f5f-9030-3334901ea7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-87047f51-78df-4dcf-b10a-a6ff512aa46c,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-1adc2605-6d01-4fee-9268-6ca7b710373a,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-90648a75-2699-4b40-bc01-c4cfbf9a0aff,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-76f1838b-d112-4921-9df8-b0c49250bebe,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-3d69d7cd-19d0-4a62-9578-73ec7649c0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33373,DS-72d38fd7-9df9-483f-8c81-43c2703f6d16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308851412-172.17.0.15-1597297354662:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45740,DS-961e4150-62ca-4c15-ad53-79008592a39c,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-e09a3acb-dc33-4f5f-9030-3334901ea7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-87047f51-78df-4dcf-b10a-a6ff512aa46c,DISK], DatanodeInfoWithStorage[127.0.0.1:38004,DS-1adc2605-6d01-4fee-9268-6ca7b710373a,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-90648a75-2699-4b40-bc01-c4cfbf9a0aff,DISK], DatanodeInfoWithStorage[127.0.0.1:37248,DS-76f1838b-d112-4921-9df8-b0c49250bebe,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-3d69d7cd-19d0-4a62-9578-73ec7649c0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33373,DS-72d38fd7-9df9-483f-8c81-43c2703f6d16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1054809286-172.17.0.15-1597297866672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36027,DS-b3a5a2c1-c04b-42e4-988a-60a7b9c2b129,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-6016eb02-7092-4cee-83d4-5a3c76a63758,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-d97f3462-c431-4299-95fa-442c9622286a,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-1e82251d-bbde-4d49-9826-ddb85f8c5ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-478cda30-23d2-434f-bbca-776862b802f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-ee7dd3be-f0d6-437d-98c6-292988a7f1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-e3c65a8d-c5e5-4e87-90ea-7acb2483e2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-8135462c-26d5-4697-838a-b9a59e9e3b93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1054809286-172.17.0.15-1597297866672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36027,DS-b3a5a2c1-c04b-42e4-988a-60a7b9c2b129,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-6016eb02-7092-4cee-83d4-5a3c76a63758,DISK], DatanodeInfoWithStorage[127.0.0.1:39373,DS-d97f3462-c431-4299-95fa-442c9622286a,DISK], DatanodeInfoWithStorage[127.0.0.1:41452,DS-1e82251d-bbde-4d49-9826-ddb85f8c5ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-478cda30-23d2-434f-bbca-776862b802f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-ee7dd3be-f0d6-437d-98c6-292988a7f1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-e3c65a8d-c5e5-4e87-90ea-7acb2483e2b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-8135462c-26d5-4697-838a-b9a59e9e3b93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310770016-172.17.0.15-1597298191632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32786,DS-b7393913-0be2-4f04-a3fd-b381a734d5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-d70684f1-0216-4d1a-9809-50625ca29c13,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-08b12896-c644-47f5-976a-b9516892fa71,DISK], DatanodeInfoWithStorage[127.0.0.1:46758,DS-cfe17e31-eb75-4c8c-8486-b3084fb6d5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-44cd627e-14c2-4035-adab-1c9fc3f9ea0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-6c181ead-3911-491e-9deb-121c69c7b96d,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-02c3de09-9eb1-46b7-86f2-8fc419e0c361,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-f08ccdeb-0514-4973-9a42-3ecabf3f4e4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-310770016-172.17.0.15-1597298191632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32786,DS-b7393913-0be2-4f04-a3fd-b381a734d5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45105,DS-d70684f1-0216-4d1a-9809-50625ca29c13,DISK], DatanodeInfoWithStorage[127.0.0.1:40524,DS-08b12896-c644-47f5-976a-b9516892fa71,DISK], DatanodeInfoWithStorage[127.0.0.1:46758,DS-cfe17e31-eb75-4c8c-8486-b3084fb6d5e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-44cd627e-14c2-4035-adab-1c9fc3f9ea0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37470,DS-6c181ead-3911-491e-9deb-121c69c7b96d,DISK], DatanodeInfoWithStorage[127.0.0.1:43481,DS-02c3de09-9eb1-46b7-86f2-8fc419e0c361,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-f08ccdeb-0514-4973-9a42-3ecabf3f4e4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960848693-172.17.0.15-1597298270569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43366,DS-ddd0cd93-6304-4891-aaf8-72032ef6c0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-8f68dd90-ef9d-4d08-856a-fc6aaf5423e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-4d45a416-47b6-4a82-a98d-09d960f366a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-861aec1b-80c3-4807-9c8f-d3a6f78b6fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-5b0f9995-aeac-45f7-9e5e-47af89461750,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-63d57bc3-e9d6-4138-9d8d-9c29acd43826,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-8b33c962-35ce-41d1-859b-ecf85005c475,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-8ce66569-3c96-432a-acaa-450aa86e6af0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960848693-172.17.0.15-1597298270569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43366,DS-ddd0cd93-6304-4891-aaf8-72032ef6c0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-8f68dd90-ef9d-4d08-856a-fc6aaf5423e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-4d45a416-47b6-4a82-a98d-09d960f366a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40329,DS-861aec1b-80c3-4807-9c8f-d3a6f78b6fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39476,DS-5b0f9995-aeac-45f7-9e5e-47af89461750,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-63d57bc3-e9d6-4138-9d8d-9c29acd43826,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-8b33c962-35ce-41d1-859b-ecf85005c475,DISK], DatanodeInfoWithStorage[127.0.0.1:46206,DS-8ce66569-3c96-432a-acaa-450aa86e6af0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109333383-172.17.0.15-1597298949124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33617,DS-d8b6ab2b-9949-42eb-b1f1-fdf6fc329a41,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-41aed453-7232-470f-89b8-d32ea3984b18,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-b1ac2519-1eb1-4362-a796-7e3585852f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-61eae8c3-cd3b-486d-b92c-fdc29ef4a54e,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-54b418d3-fe7b-4b03-8083-16037e5a7475,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-aa7a5470-e287-4e0e-b990-ac4c3d6d6234,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-8b4629eb-0b7f-4687-99a2-fdd6a18e2ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-52eee831-d876-46f3-b439-8220d072630a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109333383-172.17.0.15-1597298949124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33617,DS-d8b6ab2b-9949-42eb-b1f1-fdf6fc329a41,DISK], DatanodeInfoWithStorage[127.0.0.1:43556,DS-41aed453-7232-470f-89b8-d32ea3984b18,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-b1ac2519-1eb1-4362-a796-7e3585852f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-61eae8c3-cd3b-486d-b92c-fdc29ef4a54e,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-54b418d3-fe7b-4b03-8083-16037e5a7475,DISK], DatanodeInfoWithStorage[127.0.0.1:40311,DS-aa7a5470-e287-4e0e-b990-ac4c3d6d6234,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-8b4629eb-0b7f-4687-99a2-fdd6a18e2ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-52eee831-d876-46f3-b439-8220d072630a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1807295042-172.17.0.15-1597298983345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40836,DS-1782b3f5-c7ac-47ad-ac46-4878579df9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-1417a295-85c2-477d-8f74-e28ca9880a48,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-af640234-ad1a-4d83-97a6-01825b7b99b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-dd013c80-4ce8-463d-9569-69fd5794b46d,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-514d561c-babf-41eb-b977-057266b067db,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-5214c1be-467a-4d4d-833d-85fc1b959b82,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-99a19cef-3d86-42dd-a4d0-453943a2f2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-a1f26ab7-ac74-4084-b063-4cbfbec43588,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1807295042-172.17.0.15-1597298983345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40836,DS-1782b3f5-c7ac-47ad-ac46-4878579df9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-1417a295-85c2-477d-8f74-e28ca9880a48,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-af640234-ad1a-4d83-97a6-01825b7b99b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-dd013c80-4ce8-463d-9569-69fd5794b46d,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-514d561c-babf-41eb-b977-057266b067db,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-5214c1be-467a-4d4d-833d-85fc1b959b82,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-99a19cef-3d86-42dd-a4d0-453943a2f2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-a1f26ab7-ac74-4084-b063-4cbfbec43588,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-318644003-172.17.0.15-1597299023254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43005,DS-ef3a1111-f95f-42dd-ab04-f69978b8bf12,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-3da23ab5-2e76-49bb-901f-43492858f5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-719814f6-bfa3-4e45-8f7e-7aa214f21b12,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-2e03cf8e-dd1e-4c08-8507-2fa7a929aa23,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-dd083fc1-7bc7-4fdd-8c35-8e5c0bf7d442,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-72a2120f-6c63-4750-b888-73f3ea777e03,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-6892da89-2588-44d3-aaee-22eb0aa72198,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-155dc3d0-1c50-4ef9-be0f-3ef262c7d386,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-318644003-172.17.0.15-1597299023254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43005,DS-ef3a1111-f95f-42dd-ab04-f69978b8bf12,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-3da23ab5-2e76-49bb-901f-43492858f5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-719814f6-bfa3-4e45-8f7e-7aa214f21b12,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-2e03cf8e-dd1e-4c08-8507-2fa7a929aa23,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-dd083fc1-7bc7-4fdd-8c35-8e5c0bf7d442,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-72a2120f-6c63-4750-b888-73f3ea777e03,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-6892da89-2588-44d3-aaee-22eb0aa72198,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-155dc3d0-1c50-4ef9-be0f-3ef262c7d386,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-262201219-172.17.0.15-1597299098256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36835,DS-de49201b-4948-487f-997d-9a3d174686f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-780982d1-b252-47a2-9549-64288ac34852,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-b4f7579c-62a6-4c2a-b59a-59743bf18412,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-ff0794ec-8278-43b3-b87a-e4fa7f3065ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-9ad3644f-700e-442d-b2ba-c3151c27e328,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-6048589e-56e9-4303-a5db-8f0061c4f645,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-88889b0e-fc9b-46d1-a766-4585d84fe41d,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-0ff34a94-facb-49ad-ab5e-899e9d973ecb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-262201219-172.17.0.15-1597299098256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36835,DS-de49201b-4948-487f-997d-9a3d174686f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-780982d1-b252-47a2-9549-64288ac34852,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-b4f7579c-62a6-4c2a-b59a-59743bf18412,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-ff0794ec-8278-43b3-b87a-e4fa7f3065ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-9ad3644f-700e-442d-b2ba-c3151c27e328,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-6048589e-56e9-4303-a5db-8f0061c4f645,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-88889b0e-fc9b-46d1-a766-4585d84fe41d,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-0ff34a94-facb-49ad-ab5e-899e9d973ecb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-668231342-172.17.0.15-1597299247664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34520,DS-80ce8cfb-14e0-4580-9c83-17c057ced35a,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-524ecb62-4420-4395-9581-42a1b0b01504,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-474f823d-fa8a-49f1-8c36-83cfedf83675,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-d38628f0-10e7-4ea8-b945-21bc238d66a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-5aede9e1-7688-4315-ac1e-7303d77b1d93,DISK], DatanodeInfoWithStorage[127.0.0.1:42887,DS-330667b4-8765-4f12-9eb9-3c6a08d88d45,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-15636b43-ad93-40ac-810a-b3089d1f678e,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-a124cc0c-d365-4828-8363-4cec4410cbed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-668231342-172.17.0.15-1597299247664:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34520,DS-80ce8cfb-14e0-4580-9c83-17c057ced35a,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-524ecb62-4420-4395-9581-42a1b0b01504,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-474f823d-fa8a-49f1-8c36-83cfedf83675,DISK], DatanodeInfoWithStorage[127.0.0.1:34681,DS-d38628f0-10e7-4ea8-b945-21bc238d66a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-5aede9e1-7688-4315-ac1e-7303d77b1d93,DISK], DatanodeInfoWithStorage[127.0.0.1:42887,DS-330667b4-8765-4f12-9eb9-3c6a08d88d45,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-15636b43-ad93-40ac-810a-b3089d1f678e,DISK], DatanodeInfoWithStorage[127.0.0.1:46752,DS-a124cc0c-d365-4828-8363-4cec4410cbed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5704
