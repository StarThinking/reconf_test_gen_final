reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238805624-172.17.0.17-1597421497499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44235,DS-32da6354-f6b5-4704-a9ff-acc3cf358652,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-148a1028-5e4e-4768-9050-683de15de15c,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-8ddb0cf4-a6d4-4a4e-9be0-736454890f13,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-3894e692-ff66-4979-b069-341c2691c1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-15d8a2d1-600f-4334-ad6e-bef1814d6df7,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-f3813205-3ce4-4ce5-80d6-272f8883e488,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-57855434-859e-4b2c-ac89-10080499fa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-9c407390-3a78-4fa0-bce5-71f4d84f191b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1238805624-172.17.0.17-1597421497499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44235,DS-32da6354-f6b5-4704-a9ff-acc3cf358652,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-148a1028-5e4e-4768-9050-683de15de15c,DISK], DatanodeInfoWithStorage[127.0.0.1:38777,DS-8ddb0cf4-a6d4-4a4e-9be0-736454890f13,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-3894e692-ff66-4979-b069-341c2691c1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-15d8a2d1-600f-4334-ad6e-bef1814d6df7,DISK], DatanodeInfoWithStorage[127.0.0.1:32989,DS-f3813205-3ce4-4ce5-80d6-272f8883e488,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-57855434-859e-4b2c-ac89-10080499fa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-9c407390-3a78-4fa0-bce5-71f4d84f191b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1992958966-172.17.0.17-1597421698712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38962,DS-3adf7af8-81ab-4b2a-92bd-bc4722e359e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-add30bc3-d33c-4351-a7ca-5c0aae41c775,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-247aaaf2-f827-4b72-aa20-645e6bbdfde9,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-823f07e3-d15b-4ac0-b55c-1a6f69b77229,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-e88578b9-1c37-4bb1-85b3-81b49a1d9595,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-f4e703ae-f3e0-4842-9157-7179c77e3315,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-0883f62e-3cbe-45b6-a3da-f828f9d0865b,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-6806083a-b57f-49f0-80e6-ff2a8e31ff3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1992958966-172.17.0.17-1597421698712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38962,DS-3adf7af8-81ab-4b2a-92bd-bc4722e359e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-add30bc3-d33c-4351-a7ca-5c0aae41c775,DISK], DatanodeInfoWithStorage[127.0.0.1:41979,DS-247aaaf2-f827-4b72-aa20-645e6bbdfde9,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-823f07e3-d15b-4ac0-b55c-1a6f69b77229,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-e88578b9-1c37-4bb1-85b3-81b49a1d9595,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-f4e703ae-f3e0-4842-9157-7179c77e3315,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-0883f62e-3cbe-45b6-a3da-f828f9d0865b,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-6806083a-b57f-49f0-80e6-ff2a8e31ff3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-990166415-172.17.0.17-1597421864782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37218,DS-40c6786c-e45d-44c8-b06e-43e9904d07de,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-ad58d1bc-cb72-4590-9c6a-c9f843111048,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-f52bb998-2083-4311-b72f-8c7b724460de,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-74bda381-f7bc-48f0-bf8e-66d271bfdb52,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-69bcf790-d745-4784-9bcf-9908aeefde19,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-5ad2480f-a58d-4ffc-bc06-1c3ea9bbb27e,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-8ade9d4b-cfb9-4f08-b3e3-dbf42bfb97d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-28ff4633-683a-418c-bda1-40b7b276463e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-990166415-172.17.0.17-1597421864782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37218,DS-40c6786c-e45d-44c8-b06e-43e9904d07de,DISK], DatanodeInfoWithStorage[127.0.0.1:45273,DS-ad58d1bc-cb72-4590-9c6a-c9f843111048,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-f52bb998-2083-4311-b72f-8c7b724460de,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-74bda381-f7bc-48f0-bf8e-66d271bfdb52,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-69bcf790-d745-4784-9bcf-9908aeefde19,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-5ad2480f-a58d-4ffc-bc06-1c3ea9bbb27e,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-8ade9d4b-cfb9-4f08-b3e3-dbf42bfb97d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-28ff4633-683a-418c-bda1-40b7b276463e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-207730674-172.17.0.17-1597422300620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44406,DS-050a2848-5d88-4f8e-8746-062033426903,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-6146fb45-be85-45fb-8de0-b44776f5021c,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-3e9b8f8b-39cf-43e2-8ca6-ea209c5aa201,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-9f0d140b-e2d1-4f9c-9c8a-7b87f94af4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-a36bfce9-e694-4722-a394-0af1c58ddbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-2bdf00c3-f0e9-44b9-93ed-b353a914868c,DISK], DatanodeInfoWithStorage[127.0.0.1:40882,DS-b0a4b035-5f78-4192-9a90-3a9d3a1b9ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-91524381-5aa7-4d53-b514-af06c8441c49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-207730674-172.17.0.17-1597422300620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44406,DS-050a2848-5d88-4f8e-8746-062033426903,DISK], DatanodeInfoWithStorage[127.0.0.1:44080,DS-6146fb45-be85-45fb-8de0-b44776f5021c,DISK], DatanodeInfoWithStorage[127.0.0.1:39152,DS-3e9b8f8b-39cf-43e2-8ca6-ea209c5aa201,DISK], DatanodeInfoWithStorage[127.0.0.1:34648,DS-9f0d140b-e2d1-4f9c-9c8a-7b87f94af4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-a36bfce9-e694-4722-a394-0af1c58ddbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-2bdf00c3-f0e9-44b9-93ed-b353a914868c,DISK], DatanodeInfoWithStorage[127.0.0.1:40882,DS-b0a4b035-5f78-4192-9a90-3a9d3a1b9ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-91524381-5aa7-4d53-b514-af06c8441c49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-427853608-172.17.0.17-1597422818252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37080,DS-efcbc8e0-20e3-496d-8964-04152723685a,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-b729aaf1-85f4-46f9-ba66-394946e0d41a,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-a77a6ef3-b1b4-4467-9a76-7c840b3a85ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-2e8baa78-4f91-4b44-907d-04fe91389f12,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-26b8c84d-ea0d-486f-9d46-eede350ff993,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-70e8fc35-67c3-4656-9516-78495da2900e,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-2338df06-7ce6-414b-b1b1-76826be344a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-ecdc7704-258b-4dfa-b001-2aced1b72e94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-427853608-172.17.0.17-1597422818252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37080,DS-efcbc8e0-20e3-496d-8964-04152723685a,DISK], DatanodeInfoWithStorage[127.0.0.1:39849,DS-b729aaf1-85f4-46f9-ba66-394946e0d41a,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-a77a6ef3-b1b4-4467-9a76-7c840b3a85ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-2e8baa78-4f91-4b44-907d-04fe91389f12,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-26b8c84d-ea0d-486f-9d46-eede350ff993,DISK], DatanodeInfoWithStorage[127.0.0.1:45774,DS-70e8fc35-67c3-4656-9516-78495da2900e,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-2338df06-7ce6-414b-b1b1-76826be344a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33109,DS-ecdc7704-258b-4dfa-b001-2aced1b72e94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1336479845-172.17.0.17-1597423342573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40934,DS-88d16dc1-bed9-45dd-9f68-4a24a04b7064,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-6731c796-bfd4-4818-9200-9cee04788f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-59af165e-a1dd-47c5-83d8-db3436f083ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-001856cf-e20d-4df9-b83e-ed3edda37aba,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-744cf833-1559-4c3b-9c10-fa6503a1fc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-a47b2f38-2465-4679-b4b3-37465e912c15,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-60d4e94f-bc9f-4a96-be6f-24e1b094d21b,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-7452883f-7128-442f-9519-f9406afec7a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1336479845-172.17.0.17-1597423342573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40934,DS-88d16dc1-bed9-45dd-9f68-4a24a04b7064,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-6731c796-bfd4-4818-9200-9cee04788f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-59af165e-a1dd-47c5-83d8-db3436f083ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-001856cf-e20d-4df9-b83e-ed3edda37aba,DISK], DatanodeInfoWithStorage[127.0.0.1:39571,DS-744cf833-1559-4c3b-9c10-fa6503a1fc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-a47b2f38-2465-4679-b4b3-37465e912c15,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-60d4e94f-bc9f-4a96-be6f-24e1b094d21b,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-7452883f-7128-442f-9519-f9406afec7a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980789222-172.17.0.17-1597424588608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33778,DS-85f341ba-0219-41e9-9f2d-08eba6e8cfa0,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-929a7824-a931-4aec-a10e-7da14202d254,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-8b0bbc17-0922-4929-8b58-2fe102d5dd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-9f142a92-d265-4682-845e-1c8848c79e63,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-d71ec512-89be-4f83-a259-0dcdcde2b8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-86e9f0e5-be02-44bb-b06e-447d9cb71df1,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-5bce27e0-da7f-4d5f-af74-3fbfe068bc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-24259119-70ee-46db-a6f1-a3022a3ee6b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980789222-172.17.0.17-1597424588608:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33778,DS-85f341ba-0219-41e9-9f2d-08eba6e8cfa0,DISK], DatanodeInfoWithStorage[127.0.0.1:38255,DS-929a7824-a931-4aec-a10e-7da14202d254,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-8b0bbc17-0922-4929-8b58-2fe102d5dd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-9f142a92-d265-4682-845e-1c8848c79e63,DISK], DatanodeInfoWithStorage[127.0.0.1:39723,DS-d71ec512-89be-4f83-a259-0dcdcde2b8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33716,DS-86e9f0e5-be02-44bb-b06e-447d9cb71df1,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-5bce27e0-da7f-4d5f-af74-3fbfe068bc0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42390,DS-24259119-70ee-46db-a6f1-a3022a3ee6b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-728572564-172.17.0.17-1597424791657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42664,DS-7a27fa39-cca1-44d9-b077-034c7a8e6736,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-d5b9b886-3720-4a5c-88f8-faa249af0de6,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-5429ebe2-30f3-4de7-8632-a5ac84f9906e,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-ff97d0ac-3638-4d44-90fe-7be8047ef701,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-400caffc-9b75-4962-8b69-bcef6f07f403,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-e4904cbe-6550-4eb2-abb0-55fcf149f162,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-25e0ae1d-30e9-45eb-a013-df3edb60e16f,DISK], DatanodeInfoWithStorage[127.0.0.1:32929,DS-7685ed11-a15e-47da-9648-872f9405545c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-728572564-172.17.0.17-1597424791657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42664,DS-7a27fa39-cca1-44d9-b077-034c7a8e6736,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-d5b9b886-3720-4a5c-88f8-faa249af0de6,DISK], DatanodeInfoWithStorage[127.0.0.1:37119,DS-5429ebe2-30f3-4de7-8632-a5ac84f9906e,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-ff97d0ac-3638-4d44-90fe-7be8047ef701,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-400caffc-9b75-4962-8b69-bcef6f07f403,DISK], DatanodeInfoWithStorage[127.0.0.1:46670,DS-e4904cbe-6550-4eb2-abb0-55fcf149f162,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-25e0ae1d-30e9-45eb-a013-df3edb60e16f,DISK], DatanodeInfoWithStorage[127.0.0.1:32929,DS-7685ed11-a15e-47da-9648-872f9405545c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-216796720-172.17.0.17-1597424937956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42376,DS-d8dc1f22-b1e1-4470-91e8-003d70254c30,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-d8bb8c96-8570-4e78-84e9-59b947e8f948,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-18548fc3-b6f1-4b0c-9b4d-0f6778851c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-e9f334a2-7454-43d7-bfa7-7a182f8346b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-740352a7-bede-4b84-8a24-3efaad587278,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-e0c138b0-512e-4d50-b04e-10c63039eedd,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-730fdfa7-2850-4381-a85a-b24b9812e656,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-8ab0da8b-a774-4158-acd8-f92e876a6adc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-216796720-172.17.0.17-1597424937956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42376,DS-d8dc1f22-b1e1-4470-91e8-003d70254c30,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-d8bb8c96-8570-4e78-84e9-59b947e8f948,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-18548fc3-b6f1-4b0c-9b4d-0f6778851c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-e9f334a2-7454-43d7-bfa7-7a182f8346b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-740352a7-bede-4b84-8a24-3efaad587278,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-e0c138b0-512e-4d50-b04e-10c63039eedd,DISK], DatanodeInfoWithStorage[127.0.0.1:44188,DS-730fdfa7-2850-4381-a85a-b24b9812e656,DISK], DatanodeInfoWithStorage[127.0.0.1:45908,DS-8ab0da8b-a774-4158-acd8-f92e876a6adc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-242007424-172.17.0.17-1597425048304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40455,DS-eff05bcb-a296-4e7d-b29c-bb5a8bdf1664,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-c833f0ee-e76d-450a-865d-5fe8304d25c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-2263e98b-4c37-4116-ada8-1caba9a57a67,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-461667f1-7635-4d20-b932-486048a0147d,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-2e1506a1-580b-4548-aa96-a9febc901cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34365,DS-e1e98f6b-4d1a-4dd3-9a42-10e7bd8909bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-5f8ce1fe-79a1-453c-9ec0-8937a3ab266b,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-d506a23b-f5bc-4c51-bc24-3833934dba3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-242007424-172.17.0.17-1597425048304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40455,DS-eff05bcb-a296-4e7d-b29c-bb5a8bdf1664,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-c833f0ee-e76d-450a-865d-5fe8304d25c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-2263e98b-4c37-4116-ada8-1caba9a57a67,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-461667f1-7635-4d20-b932-486048a0147d,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-2e1506a1-580b-4548-aa96-a9febc901cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:34365,DS-e1e98f6b-4d1a-4dd3-9a42-10e7bd8909bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-5f8ce1fe-79a1-453c-9ec0-8937a3ab266b,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-d506a23b-f5bc-4c51-bc24-3833934dba3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545305458-172.17.0.17-1597426603844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43700,DS-31958ef3-73af-4af1-8a8b-f2ed30aa6849,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-21b9bcf7-f55d-4e68-9dc1-beeb06ef90cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-9faa06ed-7833-4dd9-a262-0d92bd833a85,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-20ef3b21-7c45-4ada-8133-1520b03eec7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-8108c211-9eae-486c-81bc-d2d59389c586,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-e8881a12-0444-41fb-99ce-203b14dccfac,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-dc344e66-2690-4f86-a3f8-5c122173bac7,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-78bef4d8-8362-471b-8534-2d518131fbde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545305458-172.17.0.17-1597426603844:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43700,DS-31958ef3-73af-4af1-8a8b-f2ed30aa6849,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-21b9bcf7-f55d-4e68-9dc1-beeb06ef90cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-9faa06ed-7833-4dd9-a262-0d92bd833a85,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-20ef3b21-7c45-4ada-8133-1520b03eec7f,DISK], DatanodeInfoWithStorage[127.0.0.1:44065,DS-8108c211-9eae-486c-81bc-d2d59389c586,DISK], DatanodeInfoWithStorage[127.0.0.1:38107,DS-e8881a12-0444-41fb-99ce-203b14dccfac,DISK], DatanodeInfoWithStorage[127.0.0.1:38635,DS-dc344e66-2690-4f86-a3f8-5c122173bac7,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-78bef4d8-8362-471b-8534-2d518131fbde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1060561667-172.17.0.17-1597426835433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39668,DS-4f2f00ca-3096-4f9b-b63a-174ec0072744,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-97d22587-8acb-44e6-bdf5-52c4e1c8d23a,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-bbe51a40-27c7-425b-b989-ffb1a25ddcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-b9987901-b709-469a-b7aa-f95ec2d843cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-985bdf4a-02b3-4988-b431-75be07d74a18,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-2ba719ba-cd9f-48aa-924b-fad957890611,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-56a5ee93-2213-4335-a07d-2f4030332a17,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-1a9353b9-34b6-45e7-b36f-5b5e9d4c79ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1060561667-172.17.0.17-1597426835433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39668,DS-4f2f00ca-3096-4f9b-b63a-174ec0072744,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-97d22587-8acb-44e6-bdf5-52c4e1c8d23a,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-bbe51a40-27c7-425b-b989-ffb1a25ddcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-b9987901-b709-469a-b7aa-f95ec2d843cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-985bdf4a-02b3-4988-b431-75be07d74a18,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-2ba719ba-cd9f-48aa-924b-fad957890611,DISK], DatanodeInfoWithStorage[127.0.0.1:39434,DS-56a5ee93-2213-4335-a07d-2f4030332a17,DISK], DatanodeInfoWithStorage[127.0.0.1:35268,DS-1a9353b9-34b6-45e7-b36f-5b5e9d4c79ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514194130-172.17.0.17-1597426883186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44757,DS-e4501159-2844-4158-9ba6-9a8c3440d35d,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-f215c46e-d40a-44b6-b40f-73bfe8ce79af,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-d85114d9-ac61-4e98-89de-8d60bfd1afe3,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-4d496750-6928-4df8-a3e9-bb9b9ff3490c,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-d0f5bcdc-2e6c-4f24-97c7-fd3486345f08,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-9c002678-0e75-438c-8b45-59d882725c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-e3b29a64-e13e-4e93-8841-7ea7600550cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-692a5214-21b1-4a1c-911a-cf6b7e18d493,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514194130-172.17.0.17-1597426883186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44757,DS-e4501159-2844-4158-9ba6-9a8c3440d35d,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-f215c46e-d40a-44b6-b40f-73bfe8ce79af,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-d85114d9-ac61-4e98-89de-8d60bfd1afe3,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-4d496750-6928-4df8-a3e9-bb9b9ff3490c,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-d0f5bcdc-2e6c-4f24-97c7-fd3486345f08,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-9c002678-0e75-438c-8b45-59d882725c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-e3b29a64-e13e-4e93-8841-7ea7600550cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-692a5214-21b1-4a1c-911a-cf6b7e18d493,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-844984904-172.17.0.17-1597427281576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38720,DS-79b154f2-19cb-4dbd-99c3-73c06f0d3aea,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-ba7c1446-5100-435d-93c3-3b865b951510,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-45fa8d22-f13b-407c-8509-1f9e97ca7566,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-e0188e58-a595-4271-b5f7-c993eea76e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-f18f0d2d-968f-4bae-9b5a-246e3d0bcda3,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-89cda0e1-e788-48ee-91f2-260652ed437f,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-66247c5e-4e52-4497-b09f-e87ee4ec2a68,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-c376ff2d-464a-4529-b75d-0112fe6a1d65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-844984904-172.17.0.17-1597427281576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38720,DS-79b154f2-19cb-4dbd-99c3-73c06f0d3aea,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-ba7c1446-5100-435d-93c3-3b865b951510,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-45fa8d22-f13b-407c-8509-1f9e97ca7566,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-e0188e58-a595-4271-b5f7-c993eea76e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45985,DS-f18f0d2d-968f-4bae-9b5a-246e3d0bcda3,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-89cda0e1-e788-48ee-91f2-260652ed437f,DISK], DatanodeInfoWithStorage[127.0.0.1:45926,DS-66247c5e-4e52-4497-b09f-e87ee4ec2a68,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-c376ff2d-464a-4529-b75d-0112fe6a1d65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1447235062-172.17.0.17-1597427376129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46254,DS-c93a32e9-5cf8-4d7a-8453-93a9c428f269,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-f424425d-d1a9-45c8-b099-3d6150149ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-da241b30-9ee6-4bc9-bb4b-3cd55d9e883e,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-e8893e49-1e9a-41bd-9a83-57192401db90,DISK], DatanodeInfoWithStorage[127.0.0.1:34870,DS-af947b1f-31c7-4494-9160-406a44f9f987,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-a7d0d4e0-05cd-4cb3-af58-f95123b522d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-b014c91b-b2eb-4f67-accb-ec229813c33b,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-9cef1ec6-88de-4363-9591-703a57f0a49d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1447235062-172.17.0.17-1597427376129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46254,DS-c93a32e9-5cf8-4d7a-8453-93a9c428f269,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-f424425d-d1a9-45c8-b099-3d6150149ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-da241b30-9ee6-4bc9-bb4b-3cd55d9e883e,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-e8893e49-1e9a-41bd-9a83-57192401db90,DISK], DatanodeInfoWithStorage[127.0.0.1:34870,DS-af947b1f-31c7-4494-9160-406a44f9f987,DISK], DatanodeInfoWithStorage[127.0.0.1:38019,DS-a7d0d4e0-05cd-4cb3-af58-f95123b522d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44422,DS-b014c91b-b2eb-4f67-accb-ec229813c33b,DISK], DatanodeInfoWithStorage[127.0.0.1:41810,DS-9cef1ec6-88de-4363-9591-703a57f0a49d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997183606-172.17.0.17-1597427498458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34863,DS-9856a043-552d-4b07-8b0a-cb1bb1f12290,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-818882ae-6f64-419f-9c4a-dfef17257e64,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-2d429a6c-980d-482e-9d63-2552299e9a67,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-e3fceda1-96c4-4856-8164-5b96ec9d1d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-73a34c45-4910-4e1e-b143-e78696e5ceed,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-773c380d-0624-471b-8952-22902b76f4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-b077b598-7714-4d57-9b54-6912da0226bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-468ec1df-54db-45ef-b6c2-159932b6e579,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997183606-172.17.0.17-1597427498458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34863,DS-9856a043-552d-4b07-8b0a-cb1bb1f12290,DISK], DatanodeInfoWithStorage[127.0.0.1:41006,DS-818882ae-6f64-419f-9c4a-dfef17257e64,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-2d429a6c-980d-482e-9d63-2552299e9a67,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-e3fceda1-96c4-4856-8164-5b96ec9d1d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-73a34c45-4910-4e1e-b143-e78696e5ceed,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-773c380d-0624-471b-8952-22902b76f4a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45757,DS-b077b598-7714-4d57-9b54-6912da0226bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-468ec1df-54db-45ef-b6c2-159932b6e579,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-98441740-172.17.0.17-1597427832137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37567,DS-f610bcc0-922d-42ea-906d-91d067df8c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-5c0bcb91-fa7b-45f0-aa8b-a1239eb0cb13,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-b5aa5951-7410-48cd-bdc5-87373dc45d96,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-742a079a-ab0d-483e-a203-d8d0708cf3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-fb8cbd5b-e97a-4350-bd1e-02bb82923334,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-fdf785c7-67fe-4a99-a82f-e45abfda954f,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-b7dc2cba-b247-4948-83df-c087c909d07b,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-79c1c713-b108-451e-b9d5-bb8988b9589f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-98441740-172.17.0.17-1597427832137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37567,DS-f610bcc0-922d-42ea-906d-91d067df8c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-5c0bcb91-fa7b-45f0-aa8b-a1239eb0cb13,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-b5aa5951-7410-48cd-bdc5-87373dc45d96,DISK], DatanodeInfoWithStorage[127.0.0.1:44824,DS-742a079a-ab0d-483e-a203-d8d0708cf3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-fb8cbd5b-e97a-4350-bd1e-02bb82923334,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-fdf785c7-67fe-4a99-a82f-e45abfda954f,DISK], DatanodeInfoWithStorage[127.0.0.1:42988,DS-b7dc2cba-b247-4948-83df-c087c909d07b,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-79c1c713-b108-451e-b9d5-bb8988b9589f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1624002035-172.17.0.17-1597428282618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43544,DS-8c14649e-ceba-442c-91ec-fb3c707b3cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-dca697f6-7cb7-437b-895b-f0e8f6dfbaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-062d5143-7e5d-4fd4-b6d6-5a1e85ac9b20,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-0828ccb6-c929-4718-8db0-36d7a14359a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-11f2826a-d213-4b7e-b1de-b9aeb0b85e45,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-193f0147-84f2-42e0-94c5-20e7a55832fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-d5935863-16ce-4ca0-a13b-4ca1d14e6ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-41d2a9ef-1bf3-42a7-833a-e80a590262aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1624002035-172.17.0.17-1597428282618:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43544,DS-8c14649e-ceba-442c-91ec-fb3c707b3cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-dca697f6-7cb7-437b-895b-f0e8f6dfbaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-062d5143-7e5d-4fd4-b6d6-5a1e85ac9b20,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-0828ccb6-c929-4718-8db0-36d7a14359a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-11f2826a-d213-4b7e-b1de-b9aeb0b85e45,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-193f0147-84f2-42e0-94c5-20e7a55832fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-d5935863-16ce-4ca0-a13b-4ca1d14e6ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-41d2a9ef-1bf3-42a7-833a-e80a590262aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.key.update-interval
component: hdfs:NameNode
v1: 10
v2: 86400000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2020779344-172.17.0.17-1597428484939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35779,DS-8d6456a2-782a-4f75-bf91-8ba443eb532d,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-e689678f-35f0-404c-8d83-2239a0406d80,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-4e6ad237-e08a-4ab0-8984-fd7e18c741ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-7b103ac1-7279-42ce-a6fc-c721290d38b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-7a5b23b7-3bfc-4c91-aeeb-55f14d081b12,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-4b7d540b-01d0-489b-ae3a-ac6de59bcafe,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-fb8984e9-e0b7-409f-868d-5cb4d7e5b0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-db8eeff3-48bb-4659-93c0-862dd90cac41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2020779344-172.17.0.17-1597428484939:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35779,DS-8d6456a2-782a-4f75-bf91-8ba443eb532d,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-e689678f-35f0-404c-8d83-2239a0406d80,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-4e6ad237-e08a-4ab0-8984-fd7e18c741ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-7b103ac1-7279-42ce-a6fc-c721290d38b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46724,DS-7a5b23b7-3bfc-4c91-aeeb-55f14d081b12,DISK], DatanodeInfoWithStorage[127.0.0.1:42806,DS-4b7d540b-01d0-489b-ae3a-ac6de59bcafe,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-fb8984e9-e0b7-409f-868d-5cb4d7e5b0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-db8eeff3-48bb-4659-93c0-862dd90cac41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 7449
