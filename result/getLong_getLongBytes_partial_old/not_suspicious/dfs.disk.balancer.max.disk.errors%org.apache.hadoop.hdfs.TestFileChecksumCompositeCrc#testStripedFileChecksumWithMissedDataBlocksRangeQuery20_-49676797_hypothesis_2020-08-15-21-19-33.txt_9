reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-72752935-172.17.0.7-1597526708776:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35458,DS-b414ca53-887f-4544-a7f5-14fa6d8b69f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-97499839-1027-445b-96e4-285ac91955d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-e25ca821-7d6c-4757-9fb3-380e9b35f497,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-c45602b5-09f8-4609-bdaa-301d0db994b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-2e33461e-21dd-47eb-a0d7-7a030f7c7c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-1b6aa21c-96c9-4f5c-8a40-3a625cc4ef15,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-56b79a58-23f7-4770-9051-cf8981045b15,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-cb01c3d0-4450-45c5-92af-0bf5e5b5db03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-72752935-172.17.0.7-1597526708776:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35458,DS-b414ca53-887f-4544-a7f5-14fa6d8b69f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-97499839-1027-445b-96e4-285ac91955d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-e25ca821-7d6c-4757-9fb3-380e9b35f497,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-c45602b5-09f8-4609-bdaa-301d0db994b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-2e33461e-21dd-47eb-a0d7-7a030f7c7c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43989,DS-1b6aa21c-96c9-4f5c-8a40-3a625cc4ef15,DISK], DatanodeInfoWithStorage[127.0.0.1:34422,DS-56b79a58-23f7-4770-9051-cf8981045b15,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-cb01c3d0-4450-45c5-92af-0bf5e5b5db03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-569594633-172.17.0.7-1597526783803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43375,DS-1a9f8188-b34d-4943-821f-b18553c07928,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-ed8b8b62-af57-4104-a85e-0678dfbe4b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-f95c4af7-c4e3-4c51-9750-4cad12be4b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-63309d99-6562-4486-899b-1106defe7c91,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-0ca16b12-1378-46d8-9bad-9cbc09bcd433,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-fe805f6d-bf4d-4499-94d4-392c7b168ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-2991d10a-9cb2-49ab-88cd-4edc358d4deb,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-069bf329-576b-4284-b2b5-837a6e24eb47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-569594633-172.17.0.7-1597526783803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43375,DS-1a9f8188-b34d-4943-821f-b18553c07928,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-ed8b8b62-af57-4104-a85e-0678dfbe4b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45728,DS-f95c4af7-c4e3-4c51-9750-4cad12be4b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40219,DS-63309d99-6562-4486-899b-1106defe7c91,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-0ca16b12-1378-46d8-9bad-9cbc09bcd433,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-fe805f6d-bf4d-4499-94d4-392c7b168ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:38563,DS-2991d10a-9cb2-49ab-88cd-4edc358d4deb,DISK], DatanodeInfoWithStorage[127.0.0.1:40820,DS-069bf329-576b-4284-b2b5-837a6e24eb47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1845271017-172.17.0.7-1597527329253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44362,DS-b215f34b-756d-4001-89cd-debbf2c4270e,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-303ae6bc-bfa6-4abc-ade0-e30a39c3361b,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-ae2d145c-822d-459c-add4-6dac6bb032b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-bbd33b28-a80c-4db0-84d9-89e5353443af,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-8e09a567-75ee-46cd-82e3-bb8b10b76aad,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-5a1e4454-4ced-4215-8f2e-94ad25a2ff71,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-64a12800-82cf-4c02-a8bd-f01e7d11efff,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-55a7716a-aa7e-4763-8b68-b76e8f4cb6a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1845271017-172.17.0.7-1597527329253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44362,DS-b215f34b-756d-4001-89cd-debbf2c4270e,DISK], DatanodeInfoWithStorage[127.0.0.1:45764,DS-303ae6bc-bfa6-4abc-ade0-e30a39c3361b,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-ae2d145c-822d-459c-add4-6dac6bb032b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-bbd33b28-a80c-4db0-84d9-89e5353443af,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-8e09a567-75ee-46cd-82e3-bb8b10b76aad,DISK], DatanodeInfoWithStorage[127.0.0.1:37490,DS-5a1e4454-4ced-4215-8f2e-94ad25a2ff71,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-64a12800-82cf-4c02-a8bd-f01e7d11efff,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-55a7716a-aa7e-4763-8b68-b76e8f4cb6a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-901891946-172.17.0.7-1597527411855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44089,DS-1e2f6a7f-4110-4915-89c5-66c34fde3937,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-50571498-5847-453d-8aa6-84c4131b7fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-2ff4e134-2151-4ab4-9895-6f88b4648a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-71491f41-a715-4e33-9002-05fcf71172a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-3987a2d4-cde4-46e5-86f5-333d34efaa33,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-f81a5b98-7a21-47a9-bfeb-8add4cedac40,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-14d1e3df-122d-4808-aef9-1afc76bad2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-7579e886-3ae4-4f4b-9747-50d6247c97b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-901891946-172.17.0.7-1597527411855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44089,DS-1e2f6a7f-4110-4915-89c5-66c34fde3937,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-50571498-5847-453d-8aa6-84c4131b7fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:40730,DS-2ff4e134-2151-4ab4-9895-6f88b4648a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-71491f41-a715-4e33-9002-05fcf71172a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-3987a2d4-cde4-46e5-86f5-333d34efaa33,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-f81a5b98-7a21-47a9-bfeb-8add4cedac40,DISK], DatanodeInfoWithStorage[127.0.0.1:37500,DS-14d1e3df-122d-4808-aef9-1afc76bad2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-7579e886-3ae4-4f4b-9747-50d6247c97b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1141647453-172.17.0.7-1597527688132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45410,DS-3afd540c-3b2e-466a-9d7d-6630a4ca316d,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-02d32087-d3ce-43af-8288-e58850b8001e,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-d3615d8d-d0ab-469b-89a9-f2d2d6453020,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-8b84fe4e-2794-45a5-9a28-172d4edb4daa,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-e447537e-c1c4-4597-811c-fc9e56c04e51,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-356d5a6d-ad0e-4973-bb40-69643d71020c,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-908a0e4c-35ab-4067-b5d7-0d651810bffa,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-67bbca37-7b83-4c98-b256-56085a99f713,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1141647453-172.17.0.7-1597527688132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45410,DS-3afd540c-3b2e-466a-9d7d-6630a4ca316d,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-02d32087-d3ce-43af-8288-e58850b8001e,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-d3615d8d-d0ab-469b-89a9-f2d2d6453020,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-8b84fe4e-2794-45a5-9a28-172d4edb4daa,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-e447537e-c1c4-4597-811c-fc9e56c04e51,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-356d5a6d-ad0e-4973-bb40-69643d71020c,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-908a0e4c-35ab-4067-b5d7-0d651810bffa,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-67bbca37-7b83-4c98-b256-56085a99f713,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402083098-172.17.0.7-1597527883418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44603,DS-10bd7cf5-368d-447e-a235-68a59f1454e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-35d0c433-7753-44c6-b060-19dc62cc979a,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-6f8050b0-252d-46a7-9900-e4b3e1ac9eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-e01f5651-bc01-49e3-91cf-bbc60619e830,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-1105d327-ae62-40a0-a9ac-0ec272ec4017,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-6e641123-8dda-42bc-8bf8-1f6c5e7cf9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-04fd1df9-ecd1-4a3e-9ac7-81b66ff2839d,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-85bf0839-1769-4253-b126-b2707e65e56a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402083098-172.17.0.7-1597527883418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44603,DS-10bd7cf5-368d-447e-a235-68a59f1454e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-35d0c433-7753-44c6-b060-19dc62cc979a,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-6f8050b0-252d-46a7-9900-e4b3e1ac9eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35873,DS-e01f5651-bc01-49e3-91cf-bbc60619e830,DISK], DatanodeInfoWithStorage[127.0.0.1:35953,DS-1105d327-ae62-40a0-a9ac-0ec272ec4017,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-6e641123-8dda-42bc-8bf8-1f6c5e7cf9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-04fd1df9-ecd1-4a3e-9ac7-81b66ff2839d,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-85bf0839-1769-4253-b126-b2707e65e56a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-778656134-172.17.0.7-1597527923960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35886,DS-27dbcc08-3f57-49b6-b806-62ad9cb53df6,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-dedc32f2-8f29-41b4-805c-6fad1a988749,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-5208331c-ad06-4958-83e0-951a53b6bb17,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-00a2a0df-e48e-40d9-a2e2-e2649029dd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-ed675eea-b2dd-49cf-a75a-cccb84f8aaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-3977174f-2485-4e1e-938e-5f50f07cc51f,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-8d25d132-774c-4582-bf56-215918e6f7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33531,DS-fc5c2fc2-cc61-4a6c-a704-65f4e7847d60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-778656134-172.17.0.7-1597527923960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35886,DS-27dbcc08-3f57-49b6-b806-62ad9cb53df6,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-dedc32f2-8f29-41b4-805c-6fad1a988749,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-5208331c-ad06-4958-83e0-951a53b6bb17,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-00a2a0df-e48e-40d9-a2e2-e2649029dd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-ed675eea-b2dd-49cf-a75a-cccb84f8aaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-3977174f-2485-4e1e-938e-5f50f07cc51f,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-8d25d132-774c-4582-bf56-215918e6f7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33531,DS-fc5c2fc2-cc61-4a6c-a704-65f4e7847d60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1352582482-172.17.0.7-1597528261316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38005,DS-5f77005c-df59-47c2-a6a7-49304626752d,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-83f682fc-34db-40c3-a32b-c47cf3aa1547,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-73b597be-1bd9-4755-97ee-4b4851e67508,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-5173255d-8fd1-45dd-b9d3-13ac00506885,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-d1acb825-03e1-4964-a95f-9684b50630a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-9ed2b60f-da37-4da8-b254-fe5c8428888a,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-bbfbcc09-7595-42df-9392-fef2797050d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-3cccea75-dace-43c8-8b21-c9cedf4dd462,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1352582482-172.17.0.7-1597528261316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38005,DS-5f77005c-df59-47c2-a6a7-49304626752d,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-83f682fc-34db-40c3-a32b-c47cf3aa1547,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-73b597be-1bd9-4755-97ee-4b4851e67508,DISK], DatanodeInfoWithStorage[127.0.0.1:34980,DS-5173255d-8fd1-45dd-b9d3-13ac00506885,DISK], DatanodeInfoWithStorage[127.0.0.1:34756,DS-d1acb825-03e1-4964-a95f-9684b50630a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-9ed2b60f-da37-4da8-b254-fe5c8428888a,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-bbfbcc09-7595-42df-9392-fef2797050d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-3cccea75-dace-43c8-8b21-c9cedf4dd462,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2052894541-172.17.0.7-1597528898987:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46554,DS-217f16c4-7071-46f3-a409-cd36c89b6473,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-8b1c8e7a-b81d-4b84-85fd-8823fe9bee5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-88cab8a2-efa0-406a-b6ae-ce92d5e0f3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-c065e220-6103-4584-9f32-c7202b64e996,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-0ef42ef3-0e60-4d34-9ffc-3946d9df23a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-08cf8983-8673-4a54-b619-dbe22cc1b5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-0d3b760a-eb11-408c-abed-6641d3937517,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-e13fa742-ce58-456a-8e02-072f6fef01da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2052894541-172.17.0.7-1597528898987:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46554,DS-217f16c4-7071-46f3-a409-cd36c89b6473,DISK], DatanodeInfoWithStorage[127.0.0.1:39803,DS-8b1c8e7a-b81d-4b84-85fd-8823fe9bee5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-88cab8a2-efa0-406a-b6ae-ce92d5e0f3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-c065e220-6103-4584-9f32-c7202b64e996,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-0ef42ef3-0e60-4d34-9ffc-3946d9df23a7,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-08cf8983-8673-4a54-b619-dbe22cc1b5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33213,DS-0d3b760a-eb11-408c-abed-6641d3937517,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-e13fa742-ce58-456a-8e02-072f6fef01da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-400725480-172.17.0.7-1597529639460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45100,DS-7ce602c0-3409-4264-9655-1c68b37478e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-013a8133-3434-4ca3-9f08-10305dbd59ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-785462bb-40aa-42fd-8a01-63ec8e44b4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-2a17c49e-e8a9-4be5-8bf5-34683a255fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-55f6d6fd-623b-42c8-88b4-e68e2b026cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-403d7262-8ea4-4c8b-b617-4f8ea5b13cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-45063118-74e0-4e79-922d-651866b6cc95,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-bd63c278-b8c5-4c9e-998a-25f6847b7857,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-400725480-172.17.0.7-1597529639460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45100,DS-7ce602c0-3409-4264-9655-1c68b37478e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-013a8133-3434-4ca3-9f08-10305dbd59ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-785462bb-40aa-42fd-8a01-63ec8e44b4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-2a17c49e-e8a9-4be5-8bf5-34683a255fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:39333,DS-55f6d6fd-623b-42c8-88b4-e68e2b026cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-403d7262-8ea4-4c8b-b617-4f8ea5b13cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-45063118-74e0-4e79-922d-651866b6cc95,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-bd63c278-b8c5-4c9e-998a-25f6847b7857,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2029934929-172.17.0.7-1597530035221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36918,DS-caac1998-05d3-47df-ae11-bdf712575107,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-9e38d2eb-832e-4e73-8fea-8630059c516a,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-b1108bf9-c710-4884-a227-1ee24ec5169d,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-02bd7ac4-edad-4400-b86a-23f33d55f613,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-2f71ac08-8b2f-48f7-99af-44052e635320,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-8c6afa3f-c539-47e7-ab83-325a3f871470,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-3affebad-dd42-47b5-80f0-0608dfc6fa52,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-c1cd0489-ed31-4918-87dc-9ae344ac65c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2029934929-172.17.0.7-1597530035221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36918,DS-caac1998-05d3-47df-ae11-bdf712575107,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-9e38d2eb-832e-4e73-8fea-8630059c516a,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-b1108bf9-c710-4884-a227-1ee24ec5169d,DISK], DatanodeInfoWithStorage[127.0.0.1:40062,DS-02bd7ac4-edad-4400-b86a-23f33d55f613,DISK], DatanodeInfoWithStorage[127.0.0.1:46849,DS-2f71ac08-8b2f-48f7-99af-44052e635320,DISK], DatanodeInfoWithStorage[127.0.0.1:35340,DS-8c6afa3f-c539-47e7-ab83-325a3f871470,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-3affebad-dd42-47b5-80f0-0608dfc6fa52,DISK], DatanodeInfoWithStorage[127.0.0.1:37349,DS-c1cd0489-ed31-4918-87dc-9ae344ac65c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1064969375-172.17.0.7-1597530104707:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33675,DS-ae9d2e97-d568-481e-9243-ea9df9e389bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-c23a22df-3575-4f0f-82a1-68e7d20595c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-e21da7d6-6c9a-4139-ba26-76bf4e66bf8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-ff10f727-27a7-4a40-a86e-957e771e3674,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-ea0d32e7-d171-4ca3-a616-9069bdc576c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-21cf7957-0da0-477d-a609-2d65b3e33e63,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-ccc6f299-2238-4789-a711-ad95bbb8ee4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-ffdc7e1f-0e41-441b-9bce-c749741aca9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1064969375-172.17.0.7-1597530104707:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33675,DS-ae9d2e97-d568-481e-9243-ea9df9e389bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-c23a22df-3575-4f0f-82a1-68e7d20595c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40565,DS-e21da7d6-6c9a-4139-ba26-76bf4e66bf8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-ff10f727-27a7-4a40-a86e-957e771e3674,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-ea0d32e7-d171-4ca3-a616-9069bdc576c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-21cf7957-0da0-477d-a609-2d65b3e33e63,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-ccc6f299-2238-4789-a711-ad95bbb8ee4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-ffdc7e1f-0e41-441b-9bce-c749741aca9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-834431364-172.17.0.7-1597530574089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44844,DS-a889655d-0575-4734-8e82-5b3b8b8e19bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-ff0607d5-6599-4f44-8110-ea3b21b3e473,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-63126bcc-45f0-4ea1-bfba-6b017a68ec4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-680938e7-f433-4b6b-bd2c-6bab6dfaaf42,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-b7d2078c-095b-432e-bf8f-546167d1707d,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-884ebec6-2868-4cce-adfb-427ee185fd8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-73edec5f-98e5-45be-bd92-18cd0404d1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-6edbd85b-a566-42e6-981f-c133dface96a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-834431364-172.17.0.7-1597530574089:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44844,DS-a889655d-0575-4734-8e82-5b3b8b8e19bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-ff0607d5-6599-4f44-8110-ea3b21b3e473,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-63126bcc-45f0-4ea1-bfba-6b017a68ec4c,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-680938e7-f433-4b6b-bd2c-6bab6dfaaf42,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-b7d2078c-095b-432e-bf8f-546167d1707d,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-884ebec6-2868-4cce-adfb-427ee185fd8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-73edec5f-98e5-45be-bd92-18cd0404d1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-6edbd85b-a566-42e6-981f-c133dface96a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1201999991-172.17.0.7-1597531022273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38236,DS-54dc53ec-063d-4b43-bd19-7611354750a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-a8d32033-e3d2-487f-ad66-96125da7ec86,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-e51f7fe6-09b7-457f-9655-e65abb8b8e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-3b28ff6d-5db9-4b92-a029-258f1737de1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-a7ecc93a-1aa4-4185-86de-4c095f9b6e38,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-8c0ce9b6-6e3b-40d4-b901-a98fa6d4cad9,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-f4694a8c-f7e4-498e-b5de-ab6322af2d44,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-014335f2-89f3-4924-86b7-0253de62ba05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1201999991-172.17.0.7-1597531022273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38236,DS-54dc53ec-063d-4b43-bd19-7611354750a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-a8d32033-e3d2-487f-ad66-96125da7ec86,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-e51f7fe6-09b7-457f-9655-e65abb8b8e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-3b28ff6d-5db9-4b92-a029-258f1737de1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35744,DS-a7ecc93a-1aa4-4185-86de-4c095f9b6e38,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-8c0ce9b6-6e3b-40d4-b901-a98fa6d4cad9,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-f4694a8c-f7e4-498e-b5de-ab6322af2d44,DISK], DatanodeInfoWithStorage[127.0.0.1:34616,DS-014335f2-89f3-4924-86b7-0253de62ba05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-572289678-172.17.0.7-1597531226265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46521,DS-12d3d451-14e3-4dcd-9476-af49d0fb8796,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-36686d40-d269-47ac-9455-99afb2a1e92b,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-eaf87f2c-4e5c-43ed-b61e-252b704e59d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-8c8a0418-839c-4bbf-9b7c-9a4eb9a9333a,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-5888b8e4-5ee1-4bf9-af36-224f1e81374c,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-9e1fa53c-ea14-4f58-8f7f-d0e3d337bd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-9dbb6ac6-2178-4c6b-8071-b63457fb3526,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-fcaadf13-3add-4282-bd27-980eabb749da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-572289678-172.17.0.7-1597531226265:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46521,DS-12d3d451-14e3-4dcd-9476-af49d0fb8796,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-36686d40-d269-47ac-9455-99afb2a1e92b,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-eaf87f2c-4e5c-43ed-b61e-252b704e59d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-8c8a0418-839c-4bbf-9b7c-9a4eb9a9333a,DISK], DatanodeInfoWithStorage[127.0.0.1:40405,DS-5888b8e4-5ee1-4bf9-af36-224f1e81374c,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-9e1fa53c-ea14-4f58-8f7f-d0e3d337bd9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-9dbb6ac6-2178-4c6b-8071-b63457fb3526,DISK], DatanodeInfoWithStorage[127.0.0.1:36081,DS-fcaadf13-3add-4282-bd27-980eabb749da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 5
v2: 5000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-110782141-172.17.0.7-1597531699981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42435,DS-3f900aca-52e6-47f2-9344-13bebbf1c337,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-1071f230-6233-470d-a94c-4ecde999806e,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-2b9fa8c1-bb45-4a53-9d2d-9faa4e2258e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-00eb5302-4862-4e7f-91bd-df9d1473b58a,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-7a2ea729-46fd-4a9b-8aaa-bec390d11a24,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-02c4d51e-5e94-47d1-ad8c-2794dccf1977,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-d05cf160-39c1-461b-a4e7-bc7b9db1107e,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-b790e77c-c9c3-41d5-8ae2-9d57fd65dd68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-110782141-172.17.0.7-1597531699981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42435,DS-3f900aca-52e6-47f2-9344-13bebbf1c337,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-1071f230-6233-470d-a94c-4ecde999806e,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-2b9fa8c1-bb45-4a53-9d2d-9faa4e2258e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-00eb5302-4862-4e7f-91bd-df9d1473b58a,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-7a2ea729-46fd-4a9b-8aaa-bec390d11a24,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-02c4d51e-5e94-47d1-ad8c-2794dccf1977,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-d05cf160-39c1-461b-a4e7-bc7b9db1107e,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-b790e77c-c9c3-41d5-8ae2-9d57fd65dd68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5640
