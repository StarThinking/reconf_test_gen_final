reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1075044293-172.17.0.11-1597549641294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41731,DS-a40eaca4-51ef-44c1-a753-e69481096559,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-b6602cbd-ed78-438a-bfe8-c0c1cea07dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-b09e21b7-5142-4a7f-b60c-190dfa95db5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-74897f1e-b710-4c74-a510-38ce5bf1cd50,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-471f7754-90e7-44ad-a023-676cde737803,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-e1b1818d-7403-4bd2-803b-968f4ecef43c,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-e2146177-8cdb-413c-9451-1ba8a8ce0c78,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-43fbcd3a-20d1-4e63-858c-632ec9af57bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1075044293-172.17.0.11-1597549641294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41731,DS-a40eaca4-51ef-44c1-a753-e69481096559,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-b6602cbd-ed78-438a-bfe8-c0c1cea07dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-b09e21b7-5142-4a7f-b60c-190dfa95db5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-74897f1e-b710-4c74-a510-38ce5bf1cd50,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-471f7754-90e7-44ad-a023-676cde737803,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-e1b1818d-7403-4bd2-803b-968f4ecef43c,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-e2146177-8cdb-413c-9451-1ba8a8ce0c78,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-43fbcd3a-20d1-4e63-858c-632ec9af57bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-17887086-172.17.0.11-1597550403599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33445,DS-0b589f81-f989-4676-a4e8-3a4217bee73e,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-aeea12ce-6c36-4677-bd7e-166e1810df59,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-edd5ad11-206d-4070-a65b-2266342c7b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-3c8b6946-eb35-4356-ac10-2709d98dc400,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-a0602c15-eeda-4fd1-98c1-f58e4e1ce8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34771,DS-5172f75d-216e-468c-8c8e-eef0488df4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-26f4e610-2318-4e5d-8654-8ae0e3f8dc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-d876286c-878d-4cbe-a992-31d65ab15ae6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-17887086-172.17.0.11-1597550403599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33445,DS-0b589f81-f989-4676-a4e8-3a4217bee73e,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-aeea12ce-6c36-4677-bd7e-166e1810df59,DISK], DatanodeInfoWithStorage[127.0.0.1:33292,DS-edd5ad11-206d-4070-a65b-2266342c7b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-3c8b6946-eb35-4356-ac10-2709d98dc400,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-a0602c15-eeda-4fd1-98c1-f58e4e1ce8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34771,DS-5172f75d-216e-468c-8c8e-eef0488df4f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-26f4e610-2318-4e5d-8654-8ae0e3f8dc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-d876286c-878d-4cbe-a992-31d65ab15ae6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673183016-172.17.0.11-1597551343954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34669,DS-a19622dc-0ad9-41c4-afa6-096ca5c54da4,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-3fb6a484-07ed-46cc-b823-6fc6cd243602,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-078c1f8b-2b2a-4e6e-ae82-eb008b2b548e,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-3cde68b9-13f5-4fb0-9cf5-36e17607c10a,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-d81a9825-12ce-4051-a1c1-dababc0217e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-8b8ba0c3-3fe2-454e-95e6-9d63085801fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-bb366338-346b-4eb4-904b-1fb944e6db2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-fbd05ffc-3e04-494e-93a9-1a76ee41cf22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673183016-172.17.0.11-1597551343954:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34669,DS-a19622dc-0ad9-41c4-afa6-096ca5c54da4,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-3fb6a484-07ed-46cc-b823-6fc6cd243602,DISK], DatanodeInfoWithStorage[127.0.0.1:34248,DS-078c1f8b-2b2a-4e6e-ae82-eb008b2b548e,DISK], DatanodeInfoWithStorage[127.0.0.1:44943,DS-3cde68b9-13f5-4fb0-9cf5-36e17607c10a,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-d81a9825-12ce-4051-a1c1-dababc0217e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-8b8ba0c3-3fe2-454e-95e6-9d63085801fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-bb366338-346b-4eb4-904b-1fb944e6db2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-fbd05ffc-3e04-494e-93a9-1a76ee41cf22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846426548-172.17.0.11-1597551388546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41779,DS-4dc50733-27d2-4e92-b9c8-560e832722f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-4e79dc8a-a19f-4e7c-b50a-2032d77a1e29,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-08dda90d-4d0f-4260-b205-78b8a7b4a7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-40faa0eb-01d9-432b-8a0a-ae662cb910b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-9954fd36-1d5f-4cb0-834c-088dcf45e2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-e1166339-e81f-4ac1-ba69-80328e2dcf90,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-33c2a07f-db53-4c00-815b-bf408e6a1fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-b98b2098-a427-4e5b-ae7a-4245464a07a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846426548-172.17.0.11-1597551388546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41779,DS-4dc50733-27d2-4e92-b9c8-560e832722f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33356,DS-4e79dc8a-a19f-4e7c-b50a-2032d77a1e29,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-08dda90d-4d0f-4260-b205-78b8a7b4a7cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-40faa0eb-01d9-432b-8a0a-ae662cb910b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41425,DS-9954fd36-1d5f-4cb0-834c-088dcf45e2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42121,DS-e1166339-e81f-4ac1-ba69-80328e2dcf90,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-33c2a07f-db53-4c00-815b-bf408e6a1fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-b98b2098-a427-4e5b-ae7a-4245464a07a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417421446-172.17.0.11-1597551463767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45068,DS-15d66137-7bd1-4278-af22-f35598d21fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-af3b5c1b-10b7-4f99-a6b4-f00110bed285,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-13d7ea4b-f7d4-446a-b1a4-c049995143c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-3e68fcb7-8104-4fe4-b331-d1a9bd1d826f,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-e7b3f8c1-db27-448a-bf6c-3ac76881b5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-861284af-460f-4fc4-a122-a605858d1bad,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-c11eca80-fa06-44d9-8da5-ebd20bba98f7,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-1fabc004-9f6b-439f-9bee-feb179c35a41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-417421446-172.17.0.11-1597551463767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45068,DS-15d66137-7bd1-4278-af22-f35598d21fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44880,DS-af3b5c1b-10b7-4f99-a6b4-f00110bed285,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-13d7ea4b-f7d4-446a-b1a4-c049995143c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-3e68fcb7-8104-4fe4-b331-d1a9bd1d826f,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-e7b3f8c1-db27-448a-bf6c-3ac76881b5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-861284af-460f-4fc4-a122-a605858d1bad,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-c11eca80-fa06-44d9-8da5-ebd20bba98f7,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-1fabc004-9f6b-439f-9bee-feb179c35a41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2107813956-172.17.0.11-1597551579304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37320,DS-076e5c93-63a8-49c0-a784-5379d31b0b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-9b821194-a4fb-4c5e-9b0b-55d5935b3a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-4827a7a6-537a-4808-8eef-39f578831f98,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-e1c78f9f-4b67-47a9-9c90-5022ac4adb33,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-9b8e0710-e165-43b5-9f73-87445c9551be,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-60c1548d-1ba7-4b39-9065-c910f43cae5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-4cb10449-21ea-4ebf-9e1c-92698e84d343,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-c476ac6c-6d45-4d32-be5a-b7580a779ff9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2107813956-172.17.0.11-1597551579304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37320,DS-076e5c93-63a8-49c0-a784-5379d31b0b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-9b821194-a4fb-4c5e-9b0b-55d5935b3a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34834,DS-4827a7a6-537a-4808-8eef-39f578831f98,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-e1c78f9f-4b67-47a9-9c90-5022ac4adb33,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-9b8e0710-e165-43b5-9f73-87445c9551be,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-60c1548d-1ba7-4b39-9065-c910f43cae5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-4cb10449-21ea-4ebf-9e1c-92698e84d343,DISK], DatanodeInfoWithStorage[127.0.0.1:38037,DS-c476ac6c-6d45-4d32-be5a-b7580a779ff9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-14565254-172.17.0.11-1597552792714:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46355,DS-31f63ce0-25b0-4843-b8ac-4776fe4195c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-2595d610-95c0-4f48-bdec-5fdc880619ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-b25e8858-e2bf-4c35-b1ef-9e059ac0f818,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-7d80d314-cc1e-4bf0-8177-83327c1fc38b,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-a12a34ab-e016-4b03-abfc-80c2ebfde98f,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-0b880516-3cc7-40d9-aacb-d0f10a349688,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-cc582679-7a29-4804-9c14-139bfc23f4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-4bd8037b-b447-4ad2-a4c6-982e5e535e23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-14565254-172.17.0.11-1597552792714:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46355,DS-31f63ce0-25b0-4843-b8ac-4776fe4195c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-2595d610-95c0-4f48-bdec-5fdc880619ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-b25e8858-e2bf-4c35-b1ef-9e059ac0f818,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-7d80d314-cc1e-4bf0-8177-83327c1fc38b,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-a12a34ab-e016-4b03-abfc-80c2ebfde98f,DISK], DatanodeInfoWithStorage[127.0.0.1:45017,DS-0b880516-3cc7-40d9-aacb-d0f10a349688,DISK], DatanodeInfoWithStorage[127.0.0.1:36496,DS-cc582679-7a29-4804-9c14-139bfc23f4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-4bd8037b-b447-4ad2-a4c6-982e5e535e23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609626457-172.17.0.11-1597553032216:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36309,DS-4cd3d4e0-bd50-4c9e-b07a-187362bb60cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-4c8c807d-d4c5-4b19-ae1f-ea08d473452d,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-32eaa744-87a1-459d-bfb1-edeade22d32e,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-28ca0a74-9fea-4fc4-b5e6-d0dba4e3c05b,DISK], DatanodeInfoWithStorage[127.0.0.1:43534,DS-3188f9aa-af3f-4737-9a67-d841fff9e2db,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-bcd49793-b1e8-47b9-b008-0e8569b01490,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-6929d614-bae3-49ba-9f34-e55a0c789093,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-fdb62046-58bd-4882-a690-9c262af1f0f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609626457-172.17.0.11-1597553032216:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36309,DS-4cd3d4e0-bd50-4c9e-b07a-187362bb60cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-4c8c807d-d4c5-4b19-ae1f-ea08d473452d,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-32eaa744-87a1-459d-bfb1-edeade22d32e,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-28ca0a74-9fea-4fc4-b5e6-d0dba4e3c05b,DISK], DatanodeInfoWithStorage[127.0.0.1:43534,DS-3188f9aa-af3f-4737-9a67-d841fff9e2db,DISK], DatanodeInfoWithStorage[127.0.0.1:45986,DS-bcd49793-b1e8-47b9-b008-0e8569b01490,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-6929d614-bae3-49ba-9f34-e55a0c789093,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-fdb62046-58bd-4882-a690-9c262af1f0f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1657408038-172.17.0.11-1597553306600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42926,DS-c37e96e2-821d-4e1e-8c2a-b3fee4ae111b,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-ef0c7251-3403-43e0-b4bb-d0406b69c24b,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-0f03c015-ce90-43de-a0ef-8f9e3877214d,DISK], DatanodeInfoWithStorage[127.0.0.1:45323,DS-6d5e12f8-e463-4bc8-a7a8-983740f216ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-bb95ec78-0c8a-40e3-9b51-008a6d8c534b,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-bb970c4d-2088-4cbe-b04a-4e0e6d711991,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-63cc407b-8106-4995-9cd7-90711df3f71f,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-ca79ee60-6355-4cdc-9073-066c87ea3dc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1657408038-172.17.0.11-1597553306600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42926,DS-c37e96e2-821d-4e1e-8c2a-b3fee4ae111b,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-ef0c7251-3403-43e0-b4bb-d0406b69c24b,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-0f03c015-ce90-43de-a0ef-8f9e3877214d,DISK], DatanodeInfoWithStorage[127.0.0.1:45323,DS-6d5e12f8-e463-4bc8-a7a8-983740f216ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-bb95ec78-0c8a-40e3-9b51-008a6d8c534b,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-bb970c4d-2088-4cbe-b04a-4e0e6d711991,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-63cc407b-8106-4995-9cd7-90711df3f71f,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-ca79ee60-6355-4cdc-9073-066c87ea3dc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015599258-172.17.0.11-1597553527973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37475,DS-8580dc0b-03e5-4afa-b604-f05c0f0f6b15,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-874221ec-8dea-47f5-bea8-091f165cb215,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-20625456-ee92-46f2-8231-864e0bf7ee4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-78e6c4d9-c4b7-47d7-89e4-56008aa660ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-c70b7de3-4cbe-40ae-99d6-231bebd18716,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-72cccfd6-f6b5-425f-a8d1-3281e90fd42b,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-2971b8a8-dd30-434d-8688-54b8a98788ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-b1b3527c-0c00-48b4-8edf-14b1d066ed61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015599258-172.17.0.11-1597553527973:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37475,DS-8580dc0b-03e5-4afa-b604-f05c0f0f6b15,DISK], DatanodeInfoWithStorage[127.0.0.1:32998,DS-874221ec-8dea-47f5-bea8-091f165cb215,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-20625456-ee92-46f2-8231-864e0bf7ee4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46063,DS-78e6c4d9-c4b7-47d7-89e4-56008aa660ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-c70b7de3-4cbe-40ae-99d6-231bebd18716,DISK], DatanodeInfoWithStorage[127.0.0.1:40440,DS-72cccfd6-f6b5-425f-a8d1-3281e90fd42b,DISK], DatanodeInfoWithStorage[127.0.0.1:41827,DS-2971b8a8-dd30-434d-8688-54b8a98788ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-b1b3527c-0c00-48b4-8edf-14b1d066ed61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-936675608-172.17.0.11-1597553569629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40583,DS-8d5dc439-1d65-400a-af8a-a9dd9033e9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-919a3440-e4aa-4ca6-9c51-0fe554cc9924,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-9773eb84-fa6a-44f0-991a-a8b3b1f83d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-de08b4b8-7b03-4c4f-8039-f1e91a48d2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-996eab61-e5f5-4853-9824-9a5065a4a900,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-bffd4ed7-aecd-45e5-88ff-ce9355c14362,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-78cf913b-7026-4e7a-8244-5ac93cecae83,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-4f376339-052f-4d3f-ae41-19b7e4147b13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-936675608-172.17.0.11-1597553569629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40583,DS-8d5dc439-1d65-400a-af8a-a9dd9033e9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-919a3440-e4aa-4ca6-9c51-0fe554cc9924,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-9773eb84-fa6a-44f0-991a-a8b3b1f83d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44919,DS-de08b4b8-7b03-4c4f-8039-f1e91a48d2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36421,DS-996eab61-e5f5-4853-9824-9a5065a4a900,DISK], DatanodeInfoWithStorage[127.0.0.1:34115,DS-bffd4ed7-aecd-45e5-88ff-ce9355c14362,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-78cf913b-7026-4e7a-8244-5ac93cecae83,DISK], DatanodeInfoWithStorage[127.0.0.1:39662,DS-4f376339-052f-4d3f-ae41-19b7e4147b13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1955541557-172.17.0.11-1597553954479:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42414,DS-1079e4d6-b04d-4648-b6dd-b4d8c19a1a50,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-fe330f16-c0c2-433f-9f8d-83f31253c015,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-e5e874ff-9d96-4cc2-8fb2-d6623303c603,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-34264232-973d-44f9-827a-d0e952148c50,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-7f4e0d95-15b3-45ab-b60a-caa774406127,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-852e0969-ccaa-4d59-95d0-bbea015bd922,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-fde56e61-020c-4bff-abea-7959b4ed8ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-463383e8-4261-41b5-8a97-b7626bbdb793,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1955541557-172.17.0.11-1597553954479:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42414,DS-1079e4d6-b04d-4648-b6dd-b4d8c19a1a50,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-fe330f16-c0c2-433f-9f8d-83f31253c015,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-e5e874ff-9d96-4cc2-8fb2-d6623303c603,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-34264232-973d-44f9-827a-d0e952148c50,DISK], DatanodeInfoWithStorage[127.0.0.1:36744,DS-7f4e0d95-15b3-45ab-b60a-caa774406127,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-852e0969-ccaa-4d59-95d0-bbea015bd922,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-fde56e61-020c-4bff-abea-7959b4ed8ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:39273,DS-463383e8-4261-41b5-8a97-b7626bbdb793,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-941478095-172.17.0.11-1597554194662:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46440,DS-babe8565-d7cb-4ec2-ace1-b80b4e8f2f57,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-fa7784b8-aa93-4f6f-aaf9-8d5749eecec9,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-c96d2e35-1ff5-4aa5-a3fa-61cd183275dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-70686443-163d-49e6-9f48-64932764ff59,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-fdc8ad98-b391-4662-a3ea-f4a1e08a0e97,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-5de3ebbf-f9d2-4d7b-82d7-060592f164ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-a0bfd06a-8ec6-47f1-b0f4-586d38e1045f,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-85dffd03-4d04-4acf-a95e-8368d8b60ea1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-941478095-172.17.0.11-1597554194662:blk_-9223372036854775792_1001; getBlockSize()=377487360; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46440,DS-babe8565-d7cb-4ec2-ace1-b80b4e8f2f57,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-fa7784b8-aa93-4f6f-aaf9-8d5749eecec9,DISK], DatanodeInfoWithStorage[127.0.0.1:37282,DS-c96d2e35-1ff5-4aa5-a3fa-61cd183275dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-70686443-163d-49e6-9f48-64932764ff59,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-fdc8ad98-b391-4662-a3ea-f4a1e08a0e97,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-5de3ebbf-f9d2-4d7b-82d7-060592f164ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-a0bfd06a-8ec6-47f1-b0f4-586d38e1045f,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-85dffd03-4d04-4acf-a95e-8368d8b60ea1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.blocksize
component: hdfs:DataNode
v1: 6291456
v2: 536870912
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692573248-172.17.0.11-1597554471622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38788,DS-0e6a0ee3-573e-448a-9182-3e371b349adb,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-f0ccf461-ee1b-4e54-8547-579956b48e65,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-8ac15f39-91af-444b-adb3-aa36dd4c5906,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-ccb1729b-27cb-4aa8-91b1-7a0924e80f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-995387f1-ebfa-464a-a825-9489c961574e,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-af26faa1-5f02-427e-a11e-ff0c07973f92,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-d11beff0-e306-41e7-b91d-bcc0110b04d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-d83868f4-b11c-4352-ab14-48c07fd2e68a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692573248-172.17.0.11-1597554471622:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38788,DS-0e6a0ee3-573e-448a-9182-3e371b349adb,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-f0ccf461-ee1b-4e54-8547-579956b48e65,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-8ac15f39-91af-444b-adb3-aa36dd4c5906,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-ccb1729b-27cb-4aa8-91b1-7a0924e80f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:34791,DS-995387f1-ebfa-464a-a825-9489c961574e,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-af26faa1-5f02-427e-a11e-ff0c07973f92,DISK], DatanodeInfoWithStorage[127.0.0.1:38821,DS-d11beff0-e306-41e7-b91d-bcc0110b04d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-d83868f4-b11c-4352-ab14-48c07fd2e68a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5788
