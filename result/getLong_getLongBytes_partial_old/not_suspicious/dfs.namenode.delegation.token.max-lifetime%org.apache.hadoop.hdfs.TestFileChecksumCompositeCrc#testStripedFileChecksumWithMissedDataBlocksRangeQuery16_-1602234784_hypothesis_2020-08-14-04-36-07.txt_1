reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1379874108-172.17.0.9-1597379820277:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37385,DS-cde20276-0255-4e39-b490-60220f01f0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-bce13fce-b937-491a-8ca8-e0464e70edf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-aca3a407-f712-48a3-ae18-3b183c831e95,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-9d0c2ee6-321b-4486-a749-87ddc613e0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-dd43dfbb-c379-43ca-ab76-9117927ef370,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-434ae949-2b6d-45c6-b691-55b82c53db73,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-8e08c090-0d88-4f3b-bfcd-f0b27fb8de47,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-1f198140-9791-47ac-996e-9d2e9661bb1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1379874108-172.17.0.9-1597379820277:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37385,DS-cde20276-0255-4e39-b490-60220f01f0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-bce13fce-b937-491a-8ca8-e0464e70edf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-aca3a407-f712-48a3-ae18-3b183c831e95,DISK], DatanodeInfoWithStorage[127.0.0.1:46499,DS-9d0c2ee6-321b-4486-a749-87ddc613e0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-dd43dfbb-c379-43ca-ab76-9117927ef370,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-434ae949-2b6d-45c6-b691-55b82c53db73,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-8e08c090-0d88-4f3b-bfcd-f0b27fb8de47,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-1f198140-9791-47ac-996e-9d2e9661bb1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1793670046-172.17.0.9-1597379943943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34713,DS-5ac187c6-abd6-4238-bc84-134d105d3188,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-eb52cc6c-0f98-4ec9-9f38-6f72b51dcd69,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-e0ab8b91-47a1-4c8f-ad47-bebf72baf5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40688,DS-28f0d9b8-ed67-45cf-aa64-88db19f24730,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-5f574030-4efb-4285-99d3-21255d74937e,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-a13f3da8-273e-47de-9dc2-eb9cd039f264,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-dd7b325c-fbb5-4fe9-b6b9-206033f37b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-8f703246-a422-46d7-b3ea-c6089ef79c59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1793670046-172.17.0.9-1597379943943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34713,DS-5ac187c6-abd6-4238-bc84-134d105d3188,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-eb52cc6c-0f98-4ec9-9f38-6f72b51dcd69,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-e0ab8b91-47a1-4c8f-ad47-bebf72baf5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40688,DS-28f0d9b8-ed67-45cf-aa64-88db19f24730,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-5f574030-4efb-4285-99d3-21255d74937e,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-a13f3da8-273e-47de-9dc2-eb9cd039f264,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-dd7b325c-fbb5-4fe9-b6b9-206033f37b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-8f703246-a422-46d7-b3ea-c6089ef79c59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1024367367-172.17.0.9-1597380016412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38288,DS-83515e34-05d9-4567-8116-db56347ba8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-1366de54-bb6b-4866-8292-238951232c07,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-53877154-7a4b-4ecc-88e7-e1bc6ea54cca,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-ff919efb-2dec-4b98-9e61-d1e30b9ec4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-f754bb48-fbde-4d17-baac-4419cb1ccb7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38047,DS-3009e28e-e8c0-4e36-be0f-d2ae33cf4fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-e1a24c94-8e0a-46c8-879b-55357346d498,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-a0bf7d1a-31de-4a93-a2a2-6b8e5e97143f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1024367367-172.17.0.9-1597380016412:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38288,DS-83515e34-05d9-4567-8116-db56347ba8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-1366de54-bb6b-4866-8292-238951232c07,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-53877154-7a4b-4ecc-88e7-e1bc6ea54cca,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-ff919efb-2dec-4b98-9e61-d1e30b9ec4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35023,DS-f754bb48-fbde-4d17-baac-4419cb1ccb7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38047,DS-3009e28e-e8c0-4e36-be0f-d2ae33cf4fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:37087,DS-e1a24c94-8e0a-46c8-879b-55357346d498,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-a0bf7d1a-31de-4a93-a2a2-6b8e5e97143f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-891005607-172.17.0.9-1597380105141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39705,DS-db8351c1-587b-45c0-a480-0169bc737c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-739fde37-cdd3-4491-977c-6cda792f5d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-b3ba879d-ca6c-495c-a610-028fcd5c127d,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-5ccec6cc-1644-4e3d-816d-fd71f7b4b6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-9f2ce3d6-cea4-4228-9339-a82f44be8fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-792b7895-8933-4dcc-9621-850d9a138437,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-546889c0-5666-4e65-8e1f-be2419a2c095,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-763ebe79-001a-4c07-bf51-d9e722b79600,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-891005607-172.17.0.9-1597380105141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39705,DS-db8351c1-587b-45c0-a480-0169bc737c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-739fde37-cdd3-4491-977c-6cda792f5d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-b3ba879d-ca6c-495c-a610-028fcd5c127d,DISK], DatanodeInfoWithStorage[127.0.0.1:42082,DS-5ccec6cc-1644-4e3d-816d-fd71f7b4b6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-9f2ce3d6-cea4-4228-9339-a82f44be8fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-792b7895-8933-4dcc-9621-850d9a138437,DISK], DatanodeInfoWithStorage[127.0.0.1:39499,DS-546889c0-5666-4e65-8e1f-be2419a2c095,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-763ebe79-001a-4c07-bf51-d9e722b79600,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1154281418-172.17.0.9-1597381834843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45759,DS-b3f3eecc-ae54-4dc4-9374-615a929966e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-976d33ce-0c69-4e09-9ed1-cff302ea3744,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-7151d358-6fbb-4ecf-b313-f37c170f49fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-f8a19ea1-126d-469b-90fc-140dd7143d29,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-c83c8ac0-e99f-49ff-aeed-d0d506de82e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-5ebe17db-c7d3-44a1-9ddf-d1f83b27b0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-86ff2c81-a482-45d7-bfd1-2f89bd8ed628,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-074c690f-2ee0-4bcb-8162-ac15147405a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1154281418-172.17.0.9-1597381834843:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45759,DS-b3f3eecc-ae54-4dc4-9374-615a929966e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44659,DS-976d33ce-0c69-4e09-9ed1-cff302ea3744,DISK], DatanodeInfoWithStorage[127.0.0.1:42447,DS-7151d358-6fbb-4ecf-b313-f37c170f49fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-f8a19ea1-126d-469b-90fc-140dd7143d29,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-c83c8ac0-e99f-49ff-aeed-d0d506de82e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-5ebe17db-c7d3-44a1-9ddf-d1f83b27b0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35015,DS-86ff2c81-a482-45d7-bfd1-2f89bd8ed628,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-074c690f-2ee0-4bcb-8162-ac15147405a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1965006372-172.17.0.9-1597381881392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37536,DS-891ef02d-24cc-4fc1-91cc-28475b96d65a,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-27bcf444-af8f-4cd9-809d-f1d8b9ef9bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-98cd0a8c-5d90-4989-ba67-110069619173,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-7ba7113b-b612-40f8-9694-9ec18b9b314f,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-79ff4874-3df7-4215-83e3-2f755ef74138,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-0c28793d-b597-414c-a3e6-089a6bc49671,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-6cb1e290-2b86-489b-86a5-2933fd184844,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-6e59b67c-e8fa-4db1-8d60-1f4d9f4e5df2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1965006372-172.17.0.9-1597381881392:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37536,DS-891ef02d-24cc-4fc1-91cc-28475b96d65a,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-27bcf444-af8f-4cd9-809d-f1d8b9ef9bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:46065,DS-98cd0a8c-5d90-4989-ba67-110069619173,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-7ba7113b-b612-40f8-9694-9ec18b9b314f,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-79ff4874-3df7-4215-83e3-2f755ef74138,DISK], DatanodeInfoWithStorage[127.0.0.1:40368,DS-0c28793d-b597-414c-a3e6-089a6bc49671,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-6cb1e290-2b86-489b-86a5-2933fd184844,DISK], DatanodeInfoWithStorage[127.0.0.1:34359,DS-6e59b67c-e8fa-4db1-8d60-1f4d9f4e5df2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1678547160-172.17.0.9-1597381968441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36551,DS-aa7dcb07-5e4a-4904-9c0b-ea674cb3e408,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-41f71d36-0ad1-4d5f-9ba8-34de7a58373e,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-8ca933f5-f9c6-4c7b-98cc-3a0d0fedfd75,DISK], DatanodeInfoWithStorage[127.0.0.1:43498,DS-6770f5bb-84ad-4cbf-9b42-76699face4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-72a27f58-7b1a-464e-a3da-a678cd37530c,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-1314fa59-2e6a-40fe-bfcb-086dac10ea98,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-1b4d21e2-3811-4f45-8de4-2b14472d55bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-f60de302-8df9-41a8-963e-5ad23a9c75de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1678547160-172.17.0.9-1597381968441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36551,DS-aa7dcb07-5e4a-4904-9c0b-ea674cb3e408,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-41f71d36-0ad1-4d5f-9ba8-34de7a58373e,DISK], DatanodeInfoWithStorage[127.0.0.1:40194,DS-8ca933f5-f9c6-4c7b-98cc-3a0d0fedfd75,DISK], DatanodeInfoWithStorage[127.0.0.1:43498,DS-6770f5bb-84ad-4cbf-9b42-76699face4eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34298,DS-72a27f58-7b1a-464e-a3da-a678cd37530c,DISK], DatanodeInfoWithStorage[127.0.0.1:41211,DS-1314fa59-2e6a-40fe-bfcb-086dac10ea98,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-1b4d21e2-3811-4f45-8de4-2b14472d55bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-f60de302-8df9-41a8-963e-5ad23a9c75de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-132905829-172.17.0.9-1597382332495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41874,DS-443383df-d126-47fa-9301-a633385d8e82,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-e022f6b4-c9c4-4b05-a7c3-8de0655f5ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-87356822-2570-41ed-b519-c8a6833f45a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-098a34c3-95db-4c2c-9102-a12ab78d69b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-67606a7e-86bb-4500-abf1-5c515313db6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-2ba58e08-87a0-48e0-bd54-0b8390e992bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-4225a4ef-f20c-48af-a440-e8c56e257422,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-d5879097-0940-465a-ab86-f99064d25b75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-132905829-172.17.0.9-1597382332495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41874,DS-443383df-d126-47fa-9301-a633385d8e82,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-e022f6b4-c9c4-4b05-a7c3-8de0655f5ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-87356822-2570-41ed-b519-c8a6833f45a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-098a34c3-95db-4c2c-9102-a12ab78d69b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-67606a7e-86bb-4500-abf1-5c515313db6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-2ba58e08-87a0-48e0-bd54-0b8390e992bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-4225a4ef-f20c-48af-a440-e8c56e257422,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-d5879097-0940-465a-ab86-f99064d25b75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-245540494-172.17.0.9-1597382714864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33024,DS-fc3bd8c4-ee48-490b-864e-93a55962402b,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-33fb75b8-c56c-4ed5-af99-ebe3e6630207,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-aed10f9e-bcb2-4ee3-93d1-3f76e79c8ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-01a88d37-fd97-4294-bb01-33ebbeb30f48,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-ea14e2d5-e754-401b-aedb-80dfbb8e27c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-ad53bed2-afb9-4a2f-9419-42b605c46a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-7862e09e-61a0-4664-b4c7-689114310d96,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-464b7ef6-f982-4039-8371-1b5b3958b77f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-245540494-172.17.0.9-1597382714864:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33024,DS-fc3bd8c4-ee48-490b-864e-93a55962402b,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-33fb75b8-c56c-4ed5-af99-ebe3e6630207,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-aed10f9e-bcb2-4ee3-93d1-3f76e79c8ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-01a88d37-fd97-4294-bb01-33ebbeb30f48,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-ea14e2d5-e754-401b-aedb-80dfbb8e27c6,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-ad53bed2-afb9-4a2f-9419-42b605c46a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-7862e09e-61a0-4664-b4c7-689114310d96,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-464b7ef6-f982-4039-8371-1b5b3958b77f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1901319649-172.17.0.9-1597382853544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33841,DS-3d16d6fc-79fc-4e08-8d00-bafd4c48d71e,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-41747880-4fd5-4992-917c-564caa2e2ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-8270f6bd-1e5b-494a-afbe-4f955aeed21e,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-b6dddd1b-5d91-44bd-bf37-ef107f960e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-c880340f-d2af-4c3c-a10c-744468cde29a,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-23527d70-c1d7-4bae-bd70-aa09f1cca3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-df8e4cc7-d6b2-4a94-968a-652f26960983,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-4f10127f-be8d-41f0-837e-b9fd68b576da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1901319649-172.17.0.9-1597382853544:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33841,DS-3d16d6fc-79fc-4e08-8d00-bafd4c48d71e,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-41747880-4fd5-4992-917c-564caa2e2ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-8270f6bd-1e5b-494a-afbe-4f955aeed21e,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-b6dddd1b-5d91-44bd-bf37-ef107f960e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-c880340f-d2af-4c3c-a10c-744468cde29a,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-23527d70-c1d7-4bae-bd70-aa09f1cca3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-df8e4cc7-d6b2-4a94-968a-652f26960983,DISK], DatanodeInfoWithStorage[127.0.0.1:43366,DS-4f10127f-be8d-41f0-837e-b9fd68b576da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2066412556-172.17.0.9-1597382893397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45053,DS-29791135-a238-41c1-8cd6-ed29286dbc36,DISK], DatanodeInfoWithStorage[127.0.0.1:39408,DS-c3cbc606-950b-4f20-a12f-6e95b6a4ef26,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-77435163-10e0-4fcc-839a-65e37232ed25,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-466f07ca-2f1e-4012-8248-93aab677cfa9,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-edafc56e-1c68-4d2a-8879-5b44de21d4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-770efa23-70e0-4f17-a086-7acfebf7badd,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-9d306ac5-aa12-4279-848e-2bae4e605d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-eb7fee7c-cb84-408f-b18c-eee7329c4949,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2066412556-172.17.0.9-1597382893397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45053,DS-29791135-a238-41c1-8cd6-ed29286dbc36,DISK], DatanodeInfoWithStorage[127.0.0.1:39408,DS-c3cbc606-950b-4f20-a12f-6e95b6a4ef26,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-77435163-10e0-4fcc-839a-65e37232ed25,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-466f07ca-2f1e-4012-8248-93aab677cfa9,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-edafc56e-1c68-4d2a-8879-5b44de21d4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-770efa23-70e0-4f17-a086-7acfebf7badd,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-9d306ac5-aa12-4279-848e-2bae4e605d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-eb7fee7c-cb84-408f-b18c-eee7329c4949,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-957382646-172.17.0.9-1597383499635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43342,DS-aba48a66-9fc3-4dd8-860d-ddfa528ef9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-36060f6c-bd0a-49d2-9e8a-9c0d7ff8786f,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-9bbd7e1f-5b24-46ba-9253-1afafef7eb43,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-fdeb6e84-5597-4743-bb56-0a52ad778abe,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-1bbfe01a-d499-48b4-ab9a-01693aa3b156,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-7514fe49-0f94-4927-986e-42b889019a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-dd44d214-1f5b-4c68-9b1b-4d9f26e5c35a,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-957e9ee4-cea5-40a9-a6c7-2acf057af42f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-957382646-172.17.0.9-1597383499635:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43342,DS-aba48a66-9fc3-4dd8-860d-ddfa528ef9f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41750,DS-36060f6c-bd0a-49d2-9e8a-9c0d7ff8786f,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-9bbd7e1f-5b24-46ba-9253-1afafef7eb43,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-fdeb6e84-5597-4743-bb56-0a52ad778abe,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-1bbfe01a-d499-48b4-ab9a-01693aa3b156,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-7514fe49-0f94-4927-986e-42b889019a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-dd44d214-1f5b-4c68-9b1b-4d9f26e5c35a,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-957e9ee4-cea5-40a9-a6c7-2acf057af42f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1826333534-172.17.0.9-1597383639647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39607,DS-abbf4e6b-84bc-4746-a8cf-f75f1ff9178d,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-8abf2607-8376-473a-87c8-c47e54940303,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-7af7814f-a6f3-4328-bdcf-da17352c5e56,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-41e98052-5ff6-4c1f-b7a5-68259bf339c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-58f2cf4b-78d0-4138-9dd9-3424c6c8a952,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-b4787728-8c87-4210-8e4a-9e18b8c7cd29,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-94b86138-4032-40eb-980d-c3b64fc874d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-7c2b8f0f-d532-4f15-a7a7-0b693fa02fbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1826333534-172.17.0.9-1597383639647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39607,DS-abbf4e6b-84bc-4746-a8cf-f75f1ff9178d,DISK], DatanodeInfoWithStorage[127.0.0.1:41966,DS-8abf2607-8376-473a-87c8-c47e54940303,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-7af7814f-a6f3-4328-bdcf-da17352c5e56,DISK], DatanodeInfoWithStorage[127.0.0.1:43961,DS-41e98052-5ff6-4c1f-b7a5-68259bf339c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-58f2cf4b-78d0-4138-9dd9-3424c6c8a952,DISK], DatanodeInfoWithStorage[127.0.0.1:39965,DS-b4787728-8c87-4210-8e4a-9e18b8c7cd29,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-94b86138-4032-40eb-980d-c3b64fc874d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-7c2b8f0f-d532-4f15-a7a7-0b693fa02fbc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1088084406-172.17.0.9-1597384250570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34554,DS-a6448769-b4e3-454f-b35e-3053e3100906,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-44796c96-2e9f-415c-8956-2878fbda36d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-c43bb511-516e-493a-a2b3-dbce67be0f09,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-1019d66f-dbba-4738-993d-6c2d3cc24aee,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-e02b17e7-02b2-4f93-b1a5-103150ac730c,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-14d67d35-23ce-442c-b46c-e9170ca54b20,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-f8575cce-3aa0-4bdb-8aed-3c1924fa2c76,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-3ef7fab7-ae9e-4669-bc72-34b0d000adbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1088084406-172.17.0.9-1597384250570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34554,DS-a6448769-b4e3-454f-b35e-3053e3100906,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-44796c96-2e9f-415c-8956-2878fbda36d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-c43bb511-516e-493a-a2b3-dbce67be0f09,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-1019d66f-dbba-4738-993d-6c2d3cc24aee,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-e02b17e7-02b2-4f93-b1a5-103150ac730c,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-14d67d35-23ce-442c-b46c-e9170ca54b20,DISK], DatanodeInfoWithStorage[127.0.0.1:40477,DS-f8575cce-3aa0-4bdb-8aed-3c1924fa2c76,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-3ef7fab7-ae9e-4669-bc72-34b0d000adbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1588586808-172.17.0.9-1597384435898:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43135,DS-8e8a67ff-7fe0-464d-824c-0263bb0ad448,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-3298cc2f-f526-4f64-aa08-53f63b88d198,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-c34f656a-d27e-4873-bf3e-475afca144d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-420f37ea-4de7-41d2-aa0d-ba1e5a64974e,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-bca0db60-dba4-436d-b7bb-e962c46c88f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-94e59d70-06c2-44db-b741-b2f4139d2399,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-5f3db710-fcf1-41c4-b63e-4a0413ab0cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-d16e921f-7983-4ab0-ab13-19b94b8c5104,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1588586808-172.17.0.9-1597384435898:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43135,DS-8e8a67ff-7fe0-464d-824c-0263bb0ad448,DISK], DatanodeInfoWithStorage[127.0.0.1:45040,DS-3298cc2f-f526-4f64-aa08-53f63b88d198,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-c34f656a-d27e-4873-bf3e-475afca144d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-420f37ea-4de7-41d2-aa0d-ba1e5a64974e,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-bca0db60-dba4-436d-b7bb-e962c46c88f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-94e59d70-06c2-44db-b741-b2f4139d2399,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-5f3db710-fcf1-41c4-b63e-4a0413ab0cd2,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-d16e921f-7983-4ab0-ab13-19b94b8c5104,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-753399479-172.17.0.9-1597384763715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44874,DS-acd37290-2deb-45e5-a8c9-5dcda76c6d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-e7492eac-a724-4b5e-b6be-73e6e29d4b11,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-f3c0c366-27a8-4012-9b3e-f4334cf710ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-82de4413-c399-4c8f-9c32-db08f6331539,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-8b3e1c92-cb86-4549-92dd-e1831700618b,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-2a8fbb47-a61f-444e-b1ca-a337b71c8f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-920f8c50-7613-4482-b1c0-003bc379aa92,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-dcc469ca-beb6-4bcf-97b8-1bfd20f8a95a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-753399479-172.17.0.9-1597384763715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44874,DS-acd37290-2deb-45e5-a8c9-5dcda76c6d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-e7492eac-a724-4b5e-b6be-73e6e29d4b11,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-f3c0c366-27a8-4012-9b3e-f4334cf710ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33587,DS-82de4413-c399-4c8f-9c32-db08f6331539,DISK], DatanodeInfoWithStorage[127.0.0.1:46406,DS-8b3e1c92-cb86-4549-92dd-e1831700618b,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-2a8fbb47-a61f-444e-b1ca-a337b71c8f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46874,DS-920f8c50-7613-4482-b1c0-003bc379aa92,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-dcc469ca-beb6-4bcf-97b8-1bfd20f8a95a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-972569310-172.17.0.9-1597385030347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42155,DS-f3d473e0-1b17-4498-bdce-406bfc2ece9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-3edae6c6-2e61-4581-85a1-e6b8c6e682cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-6842bc35-b247-4b23-b662-ce81730eb630,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-de650791-a21a-4443-abaf-384a55a9fead,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-53c03ead-284c-4e60-bbc7-aa9c2f34226b,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-fa9c3ecc-832b-410f-bb30-281afada2ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-617c5a50-8be4-48a1-ba3e-7102483c0054,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-a61f5abd-ed0a-403c-ba4e-08312e81776b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-972569310-172.17.0.9-1597385030347:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42155,DS-f3d473e0-1b17-4498-bdce-406bfc2ece9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34668,DS-3edae6c6-2e61-4581-85a1-e6b8c6e682cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-6842bc35-b247-4b23-b662-ce81730eb630,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-de650791-a21a-4443-abaf-384a55a9fead,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-53c03ead-284c-4e60-bbc7-aa9c2f34226b,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-fa9c3ecc-832b-410f-bb30-281afada2ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-617c5a50-8be4-48a1-ba3e-7102483c0054,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-a61f5abd-ed0a-403c-ba4e-08312e81776b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-766294109-172.17.0.9-1597385883086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42925,DS-a0122a1d-1878-4cc4-a21e-21a907133a19,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-777c0a48-28d7-4883-bf83-e5f10d3b50ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-ff906eae-c701-4b79-a5e6-b92f12f4382f,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-cfd84277-3b27-4f11-bd86-299e421518d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-cecc1931-11f2-409d-9dd2-9baaff4cf14e,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-45972899-e901-49c7-be62-045800693446,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-0d8b3a88-d167-4862-ae34-525f596a5cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-8b247c7c-6801-44e2-afe8-d18f85165533,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-766294109-172.17.0.9-1597385883086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42925,DS-a0122a1d-1878-4cc4-a21e-21a907133a19,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-777c0a48-28d7-4883-bf83-e5f10d3b50ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-ff906eae-c701-4b79-a5e6-b92f12f4382f,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-cfd84277-3b27-4f11-bd86-299e421518d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-cecc1931-11f2-409d-9dd2-9baaff4cf14e,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-45972899-e901-49c7-be62-045800693446,DISK], DatanodeInfoWithStorage[127.0.0.1:35785,DS-0d8b3a88-d167-4862-ae34-525f596a5cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-8b247c7c-6801-44e2-afe8-d18f85165533,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.max-lifetime
component: hdfs:NameNode
v1: 604800000
v2: 10
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-951049623-172.17.0.9-1597386023291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46054,DS-d3957c7e-e2cd-401b-90d5-4520e441781e,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-37576a2a-1c77-464f-819e-1a62f0211a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40172,DS-18224d30-5d9a-48a0-b155-fa1ab1224372,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-5e88e945-fb83-4b95-a0b8-967047fa005f,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-9fc8daef-5a75-49ee-8640-a6b5e9cbf305,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-bde46b50-102f-48b9-9e9e-4fa1de88bcc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-0e860e3c-2977-4437-a917-48a0a884d8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-96c7659c-dda1-4d71-be58-408eb5086d1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-951049623-172.17.0.9-1597386023291:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46054,DS-d3957c7e-e2cd-401b-90d5-4520e441781e,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-37576a2a-1c77-464f-819e-1a62f0211a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40172,DS-18224d30-5d9a-48a0-b155-fa1ab1224372,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-5e88e945-fb83-4b95-a0b8-967047fa005f,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-9fc8daef-5a75-49ee-8640-a6b5e9cbf305,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-bde46b50-102f-48b9-9e9e-4fa1de88bcc3,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-0e860e3c-2977-4437-a917-48a0a884d8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-96c7659c-dda1-4d71-be58-408eb5086d1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 6676
