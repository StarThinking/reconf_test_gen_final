reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1783882679-172.17.0.11-1597424239209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43501,DS-5ed807f6-cf31-4bd8-8799-92db4b028b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-884c0a01-64f7-4f72-bf8e-b11cb3545334,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-a3865f88-ed15-4b7a-a373-7836e03767d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-b81f66e9-5e02-4bc1-b62e-606291761099,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-fdf8345c-4bfb-4ede-90c6-e9e550cd39ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-8ab30b0b-0957-40a3-92e6-fe5ef05075a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-09c55e4b-1e89-402c-ba24-85a09d729659,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-c6d32d00-6a67-4d74-98a0-244e4ed3aaa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1783882679-172.17.0.11-1597424239209:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43501,DS-5ed807f6-cf31-4bd8-8799-92db4b028b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-884c0a01-64f7-4f72-bf8e-b11cb3545334,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-a3865f88-ed15-4b7a-a373-7836e03767d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-b81f66e9-5e02-4bc1-b62e-606291761099,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-fdf8345c-4bfb-4ede-90c6-e9e550cd39ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33401,DS-8ab30b0b-0957-40a3-92e6-fe5ef05075a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45349,DS-09c55e4b-1e89-402c-ba24-85a09d729659,DISK], DatanodeInfoWithStorage[127.0.0.1:39934,DS-c6d32d00-6a67-4d74-98a0-244e4ed3aaa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1779707676-172.17.0.11-1597424338626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44270,DS-f4f9e627-95a8-4958-b2ab-f277616f2302,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-58e22904-5410-48f0-9656-ff3e7a85269d,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-fe64b7d9-025b-492f-ae3d-37505eaf6786,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-be15f0e6-82e5-46db-a833-0caded3a0002,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-0967927f-f21d-41b9-b648-e186f0817e07,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-abb1e050-b689-44ff-befa-ff0b06c2c214,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-a5a09fd9-9972-403b-b149-ed5b23addd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-b3352dd5-eced-40dd-a8c8-09d76ddce352,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1779707676-172.17.0.11-1597424338626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44270,DS-f4f9e627-95a8-4958-b2ab-f277616f2302,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-58e22904-5410-48f0-9656-ff3e7a85269d,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-fe64b7d9-025b-492f-ae3d-37505eaf6786,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-be15f0e6-82e5-46db-a833-0caded3a0002,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-0967927f-f21d-41b9-b648-e186f0817e07,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-abb1e050-b689-44ff-befa-ff0b06c2c214,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-a5a09fd9-9972-403b-b149-ed5b23addd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40895,DS-b3352dd5-eced-40dd-a8c8-09d76ddce352,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-396165782-172.17.0.11-1597424382608:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44345,DS-e9eb9530-833a-444f-a5c9-9eb3d2202008,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-962e2cc1-12fe-48ed-aff6-491a802a33f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-de1f347d-8201-47d5-9384-d34409b7faa8,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-9c1a2186-b8ea-4882-9d77-ea9e4cac5900,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-91fd5651-14ad-47c0-90be-f2259cf0ff13,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-c1811dea-7714-4830-a94e-b7cd119c9554,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-6b523986-7789-4f62-81e0-a9963974496c,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-fc5a3684-3486-46bd-a224-eb921c122a7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-396165782-172.17.0.11-1597424382608:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44345,DS-e9eb9530-833a-444f-a5c9-9eb3d2202008,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-962e2cc1-12fe-48ed-aff6-491a802a33f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-de1f347d-8201-47d5-9384-d34409b7faa8,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-9c1a2186-b8ea-4882-9d77-ea9e4cac5900,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-91fd5651-14ad-47c0-90be-f2259cf0ff13,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-c1811dea-7714-4830-a94e-b7cd119c9554,DISK], DatanodeInfoWithStorage[127.0.0.1:32789,DS-6b523986-7789-4f62-81e0-a9963974496c,DISK], DatanodeInfoWithStorage[127.0.0.1:33318,DS-fc5a3684-3486-46bd-a224-eb921c122a7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1476201804-172.17.0.11-1597424564063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44467,DS-37a9f712-2635-45b6-bf00-152bd387a16f,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-3387a145-0fa9-45f6-a6d6-a3de626976fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-67df04c1-3b94-4cc6-9c3e-6f46caf072ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-0364d929-b65e-4da1-943a-c73d2720b294,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-29c8de31-cb18-466d-b2f0-f7bc1a28ba56,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-c10fa988-f797-4f25-9535-5cf5da7ce931,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-ced04bba-f0ff-4425-a56e-ddea99120ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-ffbf7eb2-41ec-4845-ab35-f1ce386d4cf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1476201804-172.17.0.11-1597424564063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44467,DS-37a9f712-2635-45b6-bf00-152bd387a16f,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-3387a145-0fa9-45f6-a6d6-a3de626976fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-67df04c1-3b94-4cc6-9c3e-6f46caf072ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-0364d929-b65e-4da1-943a-c73d2720b294,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-29c8de31-cb18-466d-b2f0-f7bc1a28ba56,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-c10fa988-f797-4f25-9535-5cf5da7ce931,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-ced04bba-f0ff-4425-a56e-ddea99120ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-ffbf7eb2-41ec-4845-ab35-f1ce386d4cf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-97245302-172.17.0.11-1597424787992:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41730,DS-b4d2acf0-9e27-4b36-85e0-aa3ba12a93c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-c4d0d59d-0c40-4df1-b26c-f05047fcc852,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-c11a151e-ac64-45f6-bbd5-d1424f55a511,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-e3a72a02-6640-4252-809e-8726c51bc071,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-b6ea8f87-d513-4078-9660-eea4e172bfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-d6f3959e-3eca-4ef2-92d1-e7028d0b91c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-13236269-f71d-420e-80d4-d927d9bcce1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-3cea19b2-2c64-436d-98fe-93b72741f0f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-97245302-172.17.0.11-1597424787992:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41730,DS-b4d2acf0-9e27-4b36-85e0-aa3ba12a93c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-c4d0d59d-0c40-4df1-b26c-f05047fcc852,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-c11a151e-ac64-45f6-bbd5-d1424f55a511,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-e3a72a02-6640-4252-809e-8726c51bc071,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-b6ea8f87-d513-4078-9660-eea4e172bfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-d6f3959e-3eca-4ef2-92d1-e7028d0b91c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-13236269-f71d-420e-80d4-d927d9bcce1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-3cea19b2-2c64-436d-98fe-93b72741f0f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2077798475-172.17.0.11-1597424839729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46111,DS-c618b2ab-922a-4429-b2ca-c366e58b1034,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-a5cce419-f953-46e3-a740-23ede140f2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-503ec8cf-e801-431a-806a-b7a079f631dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-c336e457-36a3-4181-bd24-5cd492a84dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-a0f415a3-0772-4665-a6f8-3f8cf1d6771b,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-bc4f647e-1552-40c0-ba4f-2231b6436f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-67577eb9-182a-44ea-826a-8d0969f32e34,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-8f0c9279-c566-459c-8026-6a32a2b334d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2077798475-172.17.0.11-1597424839729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46111,DS-c618b2ab-922a-4429-b2ca-c366e58b1034,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-a5cce419-f953-46e3-a740-23ede140f2f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37631,DS-503ec8cf-e801-431a-806a-b7a079f631dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34137,DS-c336e457-36a3-4181-bd24-5cd492a84dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35767,DS-a0f415a3-0772-4665-a6f8-3f8cf1d6771b,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-bc4f647e-1552-40c0-ba4f-2231b6436f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35494,DS-67577eb9-182a-44ea-826a-8d0969f32e34,DISK], DatanodeInfoWithStorage[127.0.0.1:39065,DS-8f0c9279-c566-459c-8026-6a32a2b334d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-992561487-172.17.0.11-1597425282756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44650,DS-2d518b90-546c-468a-b634-7acdf9356dde,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-0ef65582-f42c-4539-86b4-750bb512ee32,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-ac48a33d-c750-4850-a9a3-9fb222cca507,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-8b9b7a0e-5402-4979-b9fb-5b2463d2f262,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-3a7f18d4-5af9-4218-95fb-fb40841d4261,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-7b48bb93-e5a2-4910-b802-bc219826c716,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-a83caffe-eaa2-44af-9fc0-6eab395f8bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-72391cbe-4823-45ae-992e-4b93584d7d31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-992561487-172.17.0.11-1597425282756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44650,DS-2d518b90-546c-468a-b634-7acdf9356dde,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-0ef65582-f42c-4539-86b4-750bb512ee32,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-ac48a33d-c750-4850-a9a3-9fb222cca507,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-8b9b7a0e-5402-4979-b9fb-5b2463d2f262,DISK], DatanodeInfoWithStorage[127.0.0.1:42360,DS-3a7f18d4-5af9-4218-95fb-fb40841d4261,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-7b48bb93-e5a2-4910-b802-bc219826c716,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-a83caffe-eaa2-44af-9fc0-6eab395f8bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-72391cbe-4823-45ae-992e-4b93584d7d31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1521087544-172.17.0.11-1597425334313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46336,DS-e0668d68-0cc6-4a9c-8390-45759601e1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-37bd70bf-147c-4219-9f65-6980bad627d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-629c2cab-3c12-489d-b0b4-7d2dd3c7380f,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-4f31036b-1c65-488a-b564-20af5628ce55,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-2df27c6d-c26d-46d8-87cb-8ff0d6fc82b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-d6ed5569-d50a-46b5-a3b8-d601c9dfe03f,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-19974506-0cc8-4f6e-82fb-85736d163a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-68082559-244b-4595-8d15-154f45b17d75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1521087544-172.17.0.11-1597425334313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46336,DS-e0668d68-0cc6-4a9c-8390-45759601e1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45305,DS-37bd70bf-147c-4219-9f65-6980bad627d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-629c2cab-3c12-489d-b0b4-7d2dd3c7380f,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-4f31036b-1c65-488a-b564-20af5628ce55,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-2df27c6d-c26d-46d8-87cb-8ff0d6fc82b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-d6ed5569-d50a-46b5-a3b8-d601c9dfe03f,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-19974506-0cc8-4f6e-82fb-85736d163a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-68082559-244b-4595-8d15-154f45b17d75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1394256995-172.17.0.11-1597425594086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34263,DS-3c3fc531-9ea8-4782-95d1-c063338ec911,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-4bca1655-32f6-46f5-bcd7-3c748fd1fb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-3c02f044-4e74-4d06-b21e-95ab916d31f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-79f63021-d9bf-417f-b88b-4837dc37905f,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-3968eeb8-1ec6-4022-ae61-b87944cc4d84,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-d272236b-07a2-4e84-8ec4-94ffcecd9b07,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-bcecac8e-f222-461b-b29a-2404286f464d,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-b11948dc-c1ff-4f75-9828-1dbfc854207a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1394256995-172.17.0.11-1597425594086:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34263,DS-3c3fc531-9ea8-4782-95d1-c063338ec911,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-4bca1655-32f6-46f5-bcd7-3c748fd1fb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:36149,DS-3c02f044-4e74-4d06-b21e-95ab916d31f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46415,DS-79f63021-d9bf-417f-b88b-4837dc37905f,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-3968eeb8-1ec6-4022-ae61-b87944cc4d84,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-d272236b-07a2-4e84-8ec4-94ffcecd9b07,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-bcecac8e-f222-461b-b29a-2404286f464d,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-b11948dc-c1ff-4f75-9828-1dbfc854207a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1901095704-172.17.0.11-1597425781374:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38183,DS-152cd205-8367-4e22-b1ad-ced4519dad22,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-a2a7b937-1738-477d-a2b3-12a618d22fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-31e71e05-deac-4787-b53b-a9bf0a934a06,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-c9046735-7f49-4823-98e3-738ff595e5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39337,DS-c582f549-9876-444d-81cc-9af6f8e6eb16,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-99cbc778-dc20-4b24-9fe3-48b0e1cac1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-72ff8663-29b1-4b1c-ac50-1c75ef29ede3,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-afe954b3-4453-45e4-96e0-6988a2a7480d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1901095704-172.17.0.11-1597425781374:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38183,DS-152cd205-8367-4e22-b1ad-ced4519dad22,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-a2a7b937-1738-477d-a2b3-12a618d22fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38115,DS-31e71e05-deac-4787-b53b-a9bf0a934a06,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-c9046735-7f49-4823-98e3-738ff595e5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:39337,DS-c582f549-9876-444d-81cc-9af6f8e6eb16,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-99cbc778-dc20-4b24-9fe3-48b0e1cac1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-72ff8663-29b1-4b1c-ac50-1c75ef29ede3,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-afe954b3-4453-45e4-96e0-6988a2a7480d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1128702058-172.17.0.11-1597425873612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38075,DS-5cdbf5b9-7cac-49c4-a33a-1963f72f5288,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-da1551a7-a4a7-4adc-b514-7416a844a013,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-aa399227-55c9-4e23-9273-dada9302ad79,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-2eff95e1-fa2d-4053-b562-0146bb69b14c,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-23805ee1-caa5-477e-82d3-58aba76f532a,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-97d12b78-cb72-486f-96fe-49b24a78a340,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-717c2a7b-23cf-453a-8ed0-e67e8e118ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-2bba6188-89a8-4547-818b-5c68db831557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1128702058-172.17.0.11-1597425873612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38075,DS-5cdbf5b9-7cac-49c4-a33a-1963f72f5288,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-da1551a7-a4a7-4adc-b514-7416a844a013,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-aa399227-55c9-4e23-9273-dada9302ad79,DISK], DatanodeInfoWithStorage[127.0.0.1:35134,DS-2eff95e1-fa2d-4053-b562-0146bb69b14c,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-23805ee1-caa5-477e-82d3-58aba76f532a,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-97d12b78-cb72-486f-96fe-49b24a78a340,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-717c2a7b-23cf-453a-8ed0-e67e8e118ed9,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-2bba6188-89a8-4547-818b-5c68db831557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-342293198-172.17.0.11-1597426062096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40901,DS-f998c8e5-e8ce-4353-9136-4231c5dbdc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-468bd6b1-3dc0-40a5-9115-8a27f387b16f,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-180a1dfa-a2cb-4c27-afee-d08f5d613033,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-6e9cccae-2c35-4420-ab03-1cd7f5ff89c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-7a300b5f-cce1-4bac-89c7-195d0b122071,DISK], DatanodeInfoWithStorage[127.0.0.1:44603,DS-5fea697f-044e-442b-9858-a2c308c2cd90,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-a9a3f0a7-6c4c-4d21-9a62-4aa0787d6e38,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-70389f0c-29f3-433c-9843-31f16be38f14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-342293198-172.17.0.11-1597426062096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40901,DS-f998c8e5-e8ce-4353-9136-4231c5dbdc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:33092,DS-468bd6b1-3dc0-40a5-9115-8a27f387b16f,DISK], DatanodeInfoWithStorage[127.0.0.1:44356,DS-180a1dfa-a2cb-4c27-afee-d08f5d613033,DISK], DatanodeInfoWithStorage[127.0.0.1:40044,DS-6e9cccae-2c35-4420-ab03-1cd7f5ff89c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-7a300b5f-cce1-4bac-89c7-195d0b122071,DISK], DatanodeInfoWithStorage[127.0.0.1:44603,DS-5fea697f-044e-442b-9858-a2c308c2cd90,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-a9a3f0a7-6c4c-4d21-9a62-4aa0787d6e38,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-70389f0c-29f3-433c-9843-31f16be38f14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1043572050-172.17.0.11-1597426538966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40763,DS-3e634830-31c5-40bc-9632-f286ee158e40,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-d5ab507f-5401-4913-92c2-2b7a13134c76,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-3a994e80-a508-46f1-b9f3-f4fdf98fe5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-672abc2e-6c83-47a4-b958-8e0e17e308c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-4a63d2eb-9ebb-4e1e-b3fd-e986f555e4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-4d58612b-8c89-4f71-beda-4e4252ae8085,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-36669465-7844-4132-a47e-8f68abe57e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-91bc94dd-ffa4-4ce6-a791-14011de953d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1043572050-172.17.0.11-1597426538966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40763,DS-3e634830-31c5-40bc-9632-f286ee158e40,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-d5ab507f-5401-4913-92c2-2b7a13134c76,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-3a994e80-a508-46f1-b9f3-f4fdf98fe5cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-672abc2e-6c83-47a4-b958-8e0e17e308c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-4a63d2eb-9ebb-4e1e-b3fd-e986f555e4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-4d58612b-8c89-4f71-beda-4e4252ae8085,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-36669465-7844-4132-a47e-8f68abe57e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-91bc94dd-ffa4-4ce6-a791-14011de953d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1768875151-172.17.0.11-1597427914262:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37443,DS-770eb483-6b71-4533-88b6-2d85d5e26633,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-8b4b6316-5e08-4b6b-9223-dd1a5db3795c,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-f4f00960-3515-4205-84ab-74402b4ad55c,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-717d4f8c-aadc-4a02-81c1-2d786ee3f75e,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-8bcdc92a-0249-4d2c-8f83-fa53b8fe216c,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-3a8f1713-f90e-4de8-ab26-099f66a1d2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-de2e2051-55e8-4d08-8222-4856deb3ff47,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-e0b5debd-b0de-4c67-bf5e-2f6c4b4abdbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1768875151-172.17.0.11-1597427914262:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37443,DS-770eb483-6b71-4533-88b6-2d85d5e26633,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-8b4b6316-5e08-4b6b-9223-dd1a5db3795c,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-f4f00960-3515-4205-84ab-74402b4ad55c,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-717d4f8c-aadc-4a02-81c1-2d786ee3f75e,DISK], DatanodeInfoWithStorage[127.0.0.1:45527,DS-8bcdc92a-0249-4d2c-8f83-fa53b8fe216c,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-3a8f1713-f90e-4de8-ab26-099f66a1d2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-de2e2051-55e8-4d08-8222-4856deb3ff47,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-e0b5debd-b0de-4c67-bf5e-2f6c4b4abdbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1651933828-172.17.0.11-1597428196130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40012,DS-2a8dd03f-76a0-4ee7-8c85-65fadf107aec,DISK], DatanodeInfoWithStorage[127.0.0.1:40995,DS-577161b2-7370-4b54-ba6c-0c8936dbccd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-73109ebb-8eb9-47e8-9192-41251bc07ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-77cbba86-4e4f-4910-89ef-44faca6b2d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-93313fc3-07cd-4e04-9f64-f3f5e9b189ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-4c3e13d1-1027-4cde-9159-8fba2e38723d,DISK], DatanodeInfoWithStorage[127.0.0.1:36902,DS-4007e3c3-39b1-410d-91b1-9d4634acadf6,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-40f54d80-6352-490d-825e-7dd537228b16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1651933828-172.17.0.11-1597428196130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40012,DS-2a8dd03f-76a0-4ee7-8c85-65fadf107aec,DISK], DatanodeInfoWithStorage[127.0.0.1:40995,DS-577161b2-7370-4b54-ba6c-0c8936dbccd9,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-73109ebb-8eb9-47e8-9192-41251bc07ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-77cbba86-4e4f-4910-89ef-44faca6b2d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-93313fc3-07cd-4e04-9f64-f3f5e9b189ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-4c3e13d1-1027-4cde-9159-8fba2e38723d,DISK], DatanodeInfoWithStorage[127.0.0.1:36902,DS-4007e3c3-39b1-410d-91b1-9d4634acadf6,DISK], DatanodeInfoWithStorage[127.0.0.1:37575,DS-40f54d80-6352-490d-825e-7dd537228b16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1097783149-172.17.0.11-1597428286660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37931,DS-48898ba6-c657-483f-bf9c-90b3be12ffb6,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-9c6f7a7a-1a8b-4658-8645-fe4149682f01,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-a64837ed-faea-488d-8300-d548cae3302f,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-5ca68522-1878-4515-83c1-ab99ed7addfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-015d726a-6159-445a-b8ff-c2c2c13f5622,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-9b95bb61-78b0-4386-bd9c-d6e0476d20e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-815804aa-e07c-4a25-9d1c-ae827f5c45e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-d8f7303d-c381-4c1c-b74b-1d07176c3147,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1097783149-172.17.0.11-1597428286660:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37931,DS-48898ba6-c657-483f-bf9c-90b3be12ffb6,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-9c6f7a7a-1a8b-4658-8645-fe4149682f01,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-a64837ed-faea-488d-8300-d548cae3302f,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-5ca68522-1878-4515-83c1-ab99ed7addfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-015d726a-6159-445a-b8ff-c2c2c13f5622,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-9b95bb61-78b0-4386-bd9c-d6e0476d20e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40662,DS-815804aa-e07c-4a25-9d1c-ae827f5c45e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-d8f7303d-c381-4c1c-b74b-1d07176c3147,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.max.disk.errors
component: hdfs:DataNode
v1: 10
v2: 5
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1168122702-172.17.0.11-1597428626203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39502,DS-36d98d84-11b4-4a98-acdb-65e58a7d8875,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-ce3cb7bc-d7a4-4eca-ac7b-ea51d301e8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-5b009505-4f13-4546-86ce-3f9003957c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-63392337-06e8-4e52-b177-e5a485306073,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-f8c2143e-de9b-4e1d-8b2c-2e55c261766d,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-d35853e5-ce3f-4ba1-ae47-b3740fa00a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-7fce79fd-6e08-4d0f-84da-731e31354055,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-208b03d3-49bc-4412-958f-f9c4c9f5cd86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1168122702-172.17.0.11-1597428626203:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39502,DS-36d98d84-11b4-4a98-acdb-65e58a7d8875,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-ce3cb7bc-d7a4-4eca-ac7b-ea51d301e8fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35802,DS-5b009505-4f13-4546-86ce-3f9003957c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43697,DS-63392337-06e8-4e52-b177-e5a485306073,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-f8c2143e-de9b-4e1d-8b2c-2e55c261766d,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-d35853e5-ce3f-4ba1-ae47-b3740fa00a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-7fce79fd-6e08-4d0f-84da-731e31354055,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-208b03d3-49bc-4412-958f-f9c4c9f5cd86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5910
