reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 2500
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 2500
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-903441722-172.17.0.15-1597356887221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37615,DS-6d297fa5-c116-49a3-94c5-b073e2ecb340,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-966fe147-5908-4212-998c-1c8ebc76a975,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-d5438086-95bc-4640-a952-b413ba53cdea,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-eebf26a1-7121-4c3b-af17-7c8dc21ec116,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-9bf3f13a-fedd-41bd-8480-00deaa062af6,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-fcb2c6d2-41fb-4107-ab88-9f88e11bbc84,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-1ce8f355-78ca-428a-b066-ce82b34f2196,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-83e15ff0-91f4-4d81-905d-765ecfcc7b50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-903441722-172.17.0.15-1597356887221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37615,DS-6d297fa5-c116-49a3-94c5-b073e2ecb340,DISK], DatanodeInfoWithStorage[127.0.0.1:34038,DS-966fe147-5908-4212-998c-1c8ebc76a975,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-d5438086-95bc-4640-a952-b413ba53cdea,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-eebf26a1-7121-4c3b-af17-7c8dc21ec116,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-9bf3f13a-fedd-41bd-8480-00deaa062af6,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-fcb2c6d2-41fb-4107-ab88-9f88e11bbc84,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-1ce8f355-78ca-428a-b066-ce82b34f2196,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-83e15ff0-91f4-4d81-905d-765ecfcc7b50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 2500
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-910344872-172.17.0.15-1597357231146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34248,DS-38d5ac7a-47da-49a9-82e1-244bc801afb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-dade6ed7-9b65-496c-b28d-f1264370d661,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-eb598b89-0225-4d67-9e35-efff464e3d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-721225d9-cf95-40bf-abae-f577444bd56d,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-abfa847d-bbaa-4b92-a159-deb0d2a04fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-7efebe45-5911-4f2b-93d5-2834ff5df951,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-210cd6e3-ebde-4dc8-bc35-3197202ba75c,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-34bce47d-d627-41cf-a385-4e598a717cfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-910344872-172.17.0.15-1597357231146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34248,DS-38d5ac7a-47da-49a9-82e1-244bc801afb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-dade6ed7-9b65-496c-b28d-f1264370d661,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-eb598b89-0225-4d67-9e35-efff464e3d3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44643,DS-721225d9-cf95-40bf-abae-f577444bd56d,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-abfa847d-bbaa-4b92-a159-deb0d2a04fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:36974,DS-7efebe45-5911-4f2b-93d5-2834ff5df951,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-210cd6e3-ebde-4dc8-bc35-3197202ba75c,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-34bce47d-d627-41cf-a385-4e598a717cfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 2500
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-345439203-172.17.0.15-1597357454055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45814,DS-90b5dfab-6353-4b8a-9756-89c2a6b4f1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-e945a5ac-422b-479d-8606-4bdf470cfdfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-f9ef9f35-aadb-4532-8c6d-16403530ce18,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-9aca7d8b-1680-4c62-aa64-7b4263b796e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-86ec6589-603c-4430-8815-54e297b58af5,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-fc09b635-8abd-4c86-9374-08cf9609cc41,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-008467c2-220e-415a-a052-321b16bf3199,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-b483d221-785f-4018-a2c7-5fe9aed1449d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-345439203-172.17.0.15-1597357454055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45814,DS-90b5dfab-6353-4b8a-9756-89c2a6b4f1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-e945a5ac-422b-479d-8606-4bdf470cfdfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-f9ef9f35-aadb-4532-8c6d-16403530ce18,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-9aca7d8b-1680-4c62-aa64-7b4263b796e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-86ec6589-603c-4430-8815-54e297b58af5,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-fc09b635-8abd-4c86-9374-08cf9609cc41,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-008467c2-220e-415a-a052-321b16bf3199,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-b483d221-785f-4018-a2c7-5fe9aed1449d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 2500
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-495442924-172.17.0.15-1597357814570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46209,DS-50ef2439-e5f3-4967-849c-49e02a6e43ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-ac565229-815f-4c68-bff6-2ee526a552e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-09288797-eaea-4b9a-88ec-8b9f266a9415,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-7b7e11da-ac4e-495c-9b90-b74efe56507a,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-6129dc5c-d965-491c-a214-e5c0252cfa4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-82cd8c2f-4115-4c83-818b-94922719c20b,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-7f525d51-0ad5-4251-8469-d628c9bcbf2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-90074620-cbb6-4735-8e88-8feb5f17f57e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-495442924-172.17.0.15-1597357814570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46209,DS-50ef2439-e5f3-4967-849c-49e02a6e43ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-ac565229-815f-4c68-bff6-2ee526a552e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33375,DS-09288797-eaea-4b9a-88ec-8b9f266a9415,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-7b7e11da-ac4e-495c-9b90-b74efe56507a,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-6129dc5c-d965-491c-a214-e5c0252cfa4b,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-82cd8c2f-4115-4c83-818b-94922719c20b,DISK], DatanodeInfoWithStorage[127.0.0.1:38396,DS-7f525d51-0ad5-4251-8469-d628c9bcbf2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-90074620-cbb6-4735-8e88-8feb5f17f57e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 2500
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-593291700-172.17.0.15-1597357894151:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43043,DS-4e4652d8-3fc9-473a-8b00-eea8ce076124,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-496cefff-c4eb-474a-86ee-a9ae43f6d4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-538cda33-2718-4639-84ec-98ba28ce0c16,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-d24c7df4-6c59-4aa5-8853-16d35faa4c96,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-4b67be8d-5723-4ff6-88f4-2dc6d68cc06c,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-8c16f165-5008-402c-9d61-ae2cf61ced23,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-d64783f1-f2b6-4642-9081-89c6fd2acafb,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-fe0b36a9-87bc-4778-9557-2304de5dd94c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-593291700-172.17.0.15-1597357894151:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43043,DS-4e4652d8-3fc9-473a-8b00-eea8ce076124,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-496cefff-c4eb-474a-86ee-a9ae43f6d4c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-538cda33-2718-4639-84ec-98ba28ce0c16,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-d24c7df4-6c59-4aa5-8853-16d35faa4c96,DISK], DatanodeInfoWithStorage[127.0.0.1:39138,DS-4b67be8d-5723-4ff6-88f4-2dc6d68cc06c,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-8c16f165-5008-402c-9d61-ae2cf61ced23,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-d64783f1-f2b6-4642-9081-89c6fd2acafb,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-fe0b36a9-87bc-4778-9557-2304de5dd94c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 2500
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-220075457-172.17.0.15-1597358117269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36179,DS-335368d2-b62c-4572-ad65-25e470276ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-eb9270fd-715c-41c7-9ef0-15723c3dbd65,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-d1b923b9-8e93-49c8-a4bc-420336d9ae18,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-033179f7-33c9-4991-91ec-f60c3251ab7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-845a8efe-d85b-422e-ad58-ffa2c9b372d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-85e41e55-f925-43a9-81a1-b166822833ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-6cc3e4e2-c191-4d84-aa68-ad215b754e76,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-4831538e-d1ad-4770-8360-1e5c7d6eea1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-220075457-172.17.0.15-1597358117269:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36179,DS-335368d2-b62c-4572-ad65-25e470276ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-eb9270fd-715c-41c7-9ef0-15723c3dbd65,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-d1b923b9-8e93-49c8-a4bc-420336d9ae18,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-033179f7-33c9-4991-91ec-f60c3251ab7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-845a8efe-d85b-422e-ad58-ffa2c9b372d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-85e41e55-f925-43a9-81a1-b166822833ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-6cc3e4e2-c191-4d84-aa68-ad215b754e76,DISK], DatanodeInfoWithStorage[127.0.0.1:39122,DS-4831538e-d1ad-4770-8360-1e5c7d6eea1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 2500
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1065061049-172.17.0.15-1597358216422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40524,DS-45b27bf3-0153-4006-99ef-fb999f82fdf8,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-f83262a2-67a9-4791-9961-36b9a2447a79,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-46ef985f-03c5-44e7-94b3-cbe952022ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-435413eb-0e4e-47dd-9a34-0e123cb034a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-4adb00ac-837d-498f-8ed1-a4dc25b987ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46181,DS-c06ef2bc-b242-449b-91f6-c0f5b32725e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-2fade7ce-e792-4a8f-8df8-dc128a12c40d,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-5d526153-b35f-4de7-8334-e589a2a6cac9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1065061049-172.17.0.15-1597358216422:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40524,DS-45b27bf3-0153-4006-99ef-fb999f82fdf8,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-f83262a2-67a9-4791-9961-36b9a2447a79,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-46ef985f-03c5-44e7-94b3-cbe952022ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-435413eb-0e4e-47dd-9a34-0e123cb034a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-4adb00ac-837d-498f-8ed1-a4dc25b987ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46181,DS-c06ef2bc-b242-449b-91f6-c0f5b32725e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-2fade7ce-e792-4a8f-8df8-dc128a12c40d,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-5d526153-b35f-4de7-8334-e589a2a6cac9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 2500
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1041096578-172.17.0.15-1597358289056:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39107,DS-098c4eda-4a7f-4cf9-a59b-fbcacbb9d102,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-f2c3ea1b-a216-4d67-bb29-3b40b2a5d666,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-f79f1d75-e2cc-43ba-8e6a-06bde6270be1,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-d9031ce5-2c3b-48df-992f-402066f87907,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-6b7b5c39-6870-4103-9944-a3ca1015ac7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-905d6834-1572-44d1-ac7a-afa6bd541301,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-ab1cb847-c0e6-4367-9663-fef5d95c555b,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-03d74f06-e38e-4edb-9f8d-b6468d02bcd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1041096578-172.17.0.15-1597358289056:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39107,DS-098c4eda-4a7f-4cf9-a59b-fbcacbb9d102,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-f2c3ea1b-a216-4d67-bb29-3b40b2a5d666,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-f79f1d75-e2cc-43ba-8e6a-06bde6270be1,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-d9031ce5-2c3b-48df-992f-402066f87907,DISK], DatanodeInfoWithStorage[127.0.0.1:44777,DS-6b7b5c39-6870-4103-9944-a3ca1015ac7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-905d6834-1572-44d1-ac7a-afa6bd541301,DISK], DatanodeInfoWithStorage[127.0.0.1:40177,DS-ab1cb847-c0e6-4367-9663-fef5d95c555b,DISK], DatanodeInfoWithStorage[127.0.0.1:41390,DS-03d74f06-e38e-4edb-9f8d-b6468d02bcd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 2500
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-120777058-172.17.0.15-1597358963029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39008,DS-e5ad2856-8b64-4123-af14-fe9f68ed9330,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-a89e3edd-213c-4496-83d7-5805b275f4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-c4214651-b1e2-4877-beb8-c1cba2a19db8,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-76027185-4d44-4078-bb01-33d3fa1d8d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-5ad91e80-fa7b-466f-b167-0ed89c1a9e26,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-c96e2b6e-9cb1-4522-9f55-b835f11e7519,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-5f3eab02-1f04-49f8-99c7-8532837e287c,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-f8c19d6a-f494-414c-86b8-8cd5de84c10b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-120777058-172.17.0.15-1597358963029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39008,DS-e5ad2856-8b64-4123-af14-fe9f68ed9330,DISK], DatanodeInfoWithStorage[127.0.0.1:35642,DS-a89e3edd-213c-4496-83d7-5805b275f4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36573,DS-c4214651-b1e2-4877-beb8-c1cba2a19db8,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-76027185-4d44-4078-bb01-33d3fa1d8d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34185,DS-5ad91e80-fa7b-466f-b167-0ed89c1a9e26,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-c96e2b6e-9cb1-4522-9f55-b835f11e7519,DISK], DatanodeInfoWithStorage[127.0.0.1:33825,DS-5f3eab02-1f04-49f8-99c7-8532837e287c,DISK], DatanodeInfoWithStorage[127.0.0.1:41336,DS-f8c19d6a-f494-414c-86b8-8cd5de84c10b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 2500
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-836069196-172.17.0.15-1597359269990:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38567,DS-b9eba75b-f54f-4db5-9720-ad8353c92695,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-31755563-2962-4595-bdcd-8022b589dba2,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-b3073877-4878-4e3d-8afb-396b26735c88,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-68a7b2d8-a753-4799-b681-ebb5f2d6cece,DISK], DatanodeInfoWithStorage[127.0.0.1:44272,DS-525e6875-77b7-441e-82d4-690fd4087b03,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-41d5f893-f9ee-4384-ade5-dbd132371995,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-d2c12926-1898-4246-ba27-f6c5cd9ee300,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-2845717b-988a-4a9c-954b-68d108c9e60f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-836069196-172.17.0.15-1597359269990:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38567,DS-b9eba75b-f54f-4db5-9720-ad8353c92695,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-31755563-2962-4595-bdcd-8022b589dba2,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-b3073877-4878-4e3d-8afb-396b26735c88,DISK], DatanodeInfoWithStorage[127.0.0.1:37829,DS-68a7b2d8-a753-4799-b681-ebb5f2d6cece,DISK], DatanodeInfoWithStorage[127.0.0.1:44272,DS-525e6875-77b7-441e-82d4-690fd4087b03,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-41d5f893-f9ee-4384-ade5-dbd132371995,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-d2c12926-1898-4246-ba27-f6c5cd9ee300,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-2845717b-988a-4a9c-954b-68d108c9e60f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 2500
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1707697914-172.17.0.15-1597359716842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36188,DS-e3dc8b3e-c6c3-4a85-a621-556172c2472d,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-e38cc376-99cb-48cf-a8ac-2cefa6ec1525,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-183a740b-7fc1-4b56-a19d-8d7e98da5884,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-f0ec9d22-c394-4c2e-a55b-e86cf92588de,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-56a3e84e-4aff-4a73-a61a-7f2abb3a0172,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-9e1d0d54-4cea-458b-8775-fba29bcc9853,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-5ae2c252-d9dd-4f66-bcd7-6537041a199b,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-a68e3074-1341-4aa2-9e3a-02de91fbe3ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1707697914-172.17.0.15-1597359716842:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36188,DS-e3dc8b3e-c6c3-4a85-a621-556172c2472d,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-e38cc376-99cb-48cf-a8ac-2cefa6ec1525,DISK], DatanodeInfoWithStorage[127.0.0.1:40998,DS-183a740b-7fc1-4b56-a19d-8d7e98da5884,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-f0ec9d22-c394-4c2e-a55b-e86cf92588de,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-56a3e84e-4aff-4a73-a61a-7f2abb3a0172,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-9e1d0d54-4cea-458b-8775-fba29bcc9853,DISK], DatanodeInfoWithStorage[127.0.0.1:35300,DS-5ae2c252-d9dd-4f66-bcd7-6537041a199b,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-a68e3074-1341-4aa2-9e3a-02de91fbe3ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 2500
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752561327-172.17.0.15-1597359884894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37205,DS-a8515424-a3d8-4013-b9ae-e0689d018bba,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-c7e29a6b-53fe-434c-8dd3-4b1477666ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-67285b47-ad21-43db-82d3-1f9b19916d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-1752d4ca-8ee0-46ca-a3d5-f2737033136f,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-7004c36d-6e8e-49b1-8355-fd7833904726,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-b49a4017-bbd5-4af9-b22f-9b45f8a75633,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-a77d74be-d92c-4906-ac7f-926ad6c5ed33,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-7f62bf74-d984-43e6-99d6-f6b9f12a22b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1752561327-172.17.0.15-1597359884894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37205,DS-a8515424-a3d8-4013-b9ae-e0689d018bba,DISK], DatanodeInfoWithStorage[127.0.0.1:41720,DS-c7e29a6b-53fe-434c-8dd3-4b1477666ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:35029,DS-67285b47-ad21-43db-82d3-1f9b19916d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:33871,DS-1752d4ca-8ee0-46ca-a3d5-f2737033136f,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-7004c36d-6e8e-49b1-8355-fd7833904726,DISK], DatanodeInfoWithStorage[127.0.0.1:41032,DS-b49a4017-bbd5-4af9-b22f-9b45f8a75633,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-a77d74be-d92c-4906-ac7f-926ad6c5ed33,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-7f62bf74-d984-43e6-99d6-f6b9f12a22b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 2500
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2121302730-172.17.0.15-1597359926159:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43980,DS-03d8c5bf-4741-4405-bd16-13bcb253f37e,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-3e4312e9-3966-4e2c-99f9-a650f1dd2e84,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-30d60d46-e1c9-4e3a-ba19-a622c522e979,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-d70f7cd1-dce5-4943-a9ff-82dd53b232c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-a1550a20-6a1e-4907-89cf-1da1d3e6cb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-cd2fe7a7-9283-446a-b426-41665bac0612,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-b39b2fd3-94fe-48ff-8133-b3668e9e584d,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-e5bc65a1-d58e-42ad-94fa-c98b45634b09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2121302730-172.17.0.15-1597359926159:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43980,DS-03d8c5bf-4741-4405-bd16-13bcb253f37e,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-3e4312e9-3966-4e2c-99f9-a650f1dd2e84,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-30d60d46-e1c9-4e3a-ba19-a622c522e979,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-d70f7cd1-dce5-4943-a9ff-82dd53b232c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-a1550a20-6a1e-4907-89cf-1da1d3e6cb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-cd2fe7a7-9283-446a-b426-41665bac0612,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-b39b2fd3-94fe-48ff-8133-b3668e9e584d,DISK], DatanodeInfoWithStorage[127.0.0.1:41801,DS-e5bc65a1-d58e-42ad-94fa-c98b45634b09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 2500
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1565808867-172.17.0.15-1597360355116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36275,DS-262d5676-d426-4688-887e-9508f20e5d37,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-b30a3d44-c1b6-475e-bb13-da6444719f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-c4bbf857-887f-49fa-886c-6e2a46b1c734,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-c87b5642-f155-45d7-b283-4b6d896bb9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-6caa7d48-ef53-4f31-aae0-7d8a14e6939e,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-8142a38a-c055-4caa-8a38-1548b9f49a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-a679f238-cfe7-42a1-a110-c05ba63f9dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-fa559f77-2d7e-41c4-bd61-928d39a6c253,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1565808867-172.17.0.15-1597360355116:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36275,DS-262d5676-d426-4688-887e-9508f20e5d37,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-b30a3d44-c1b6-475e-bb13-da6444719f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-c4bbf857-887f-49fa-886c-6e2a46b1c734,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-c87b5642-f155-45d7-b283-4b6d896bb9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37865,DS-6caa7d48-ef53-4f31-aae0-7d8a14e6939e,DISK], DatanodeInfoWithStorage[127.0.0.1:35999,DS-8142a38a-c055-4caa-8a38-1548b9f49a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42684,DS-a679f238-cfe7-42a1-a110-c05ba63f9dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-fa559f77-2d7e-41c4-bd61-928d39a6c253,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 2500
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-800778145-172.17.0.15-1597360537959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37164,DS-d6d59e88-6dd6-43c4-9c74-d42fcf3fc73f,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-fb09a9e2-9e5d-44a2-acb4-05c867797606,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-0ac62311-ac47-4491-93f8-14848439d1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-38bfae8e-70f9-464e-af39-da28fc47fcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-128f09d8-6d33-4f06-bf8a-9d9a9a87d1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-ecf5350a-b3ff-4155-bbc8-aebd1c0ef120,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-19d96d4a-0954-42ca-9159-96113a254e77,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-9145c8c7-65a8-4676-b693-5ffecfd47591,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-800778145-172.17.0.15-1597360537959:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37164,DS-d6d59e88-6dd6-43c4-9c74-d42fcf3fc73f,DISK], DatanodeInfoWithStorage[127.0.0.1:46700,DS-fb09a9e2-9e5d-44a2-acb4-05c867797606,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-0ac62311-ac47-4491-93f8-14848439d1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-38bfae8e-70f9-464e-af39-da28fc47fcd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43768,DS-128f09d8-6d33-4f06-bf8a-9d9a9a87d1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36651,DS-ecf5350a-b3ff-4155-bbc8-aebd1c0ef120,DISK], DatanodeInfoWithStorage[127.0.0.1:46123,DS-19d96d4a-0954-42ca-9159-96113a254e77,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-9145c8c7-65a8-4676-b693-5ffecfd47591,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 2500
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-98135797-172.17.0.15-1597360981340:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35150,DS-0162f8fa-d051-4c8a-9b56-f3f16ff46173,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-68088c10-7298-43d2-8a0b-5eea4ac7f1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-214b957b-2888-415a-84ea-4411d95cad14,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-2961c971-6e79-445d-b6cf-80825777c426,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-57d87a3a-43f1-4688-a61a-c4ddc1c50c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-63837092-dea9-4eb9-9fff-7da745516c89,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-24f3ed50-9c26-4dbd-8b6e-8c68e5153284,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-fa72aaa0-ca62-4b96-86bb-5f9137ef2826,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-98135797-172.17.0.15-1597360981340:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35150,DS-0162f8fa-d051-4c8a-9b56-f3f16ff46173,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-68088c10-7298-43d2-8a0b-5eea4ac7f1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44431,DS-214b957b-2888-415a-84ea-4411d95cad14,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-2961c971-6e79-445d-b6cf-80825777c426,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-57d87a3a-43f1-4688-a61a-c4ddc1c50c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:34517,DS-63837092-dea9-4eb9-9fff-7da745516c89,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-24f3ed50-9c26-4dbd-8b6e-8c68e5153284,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-fa72aaa0-ca62-4b96-86bb-5f9137ef2826,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-lock-hold-to-release-lease-ms
component: hdfs:NameNode
v1: 2500
v2: 25
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1839328081-172.17.0.15-1597361200809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38049,DS-f7559a0b-7d1f-49f2-99cd-eb85e9a6330c,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-d1efb296-e411-43cc-9967-987e70208c53,DISK], DatanodeInfoWithStorage[127.0.0.1:38303,DS-24f7aff1-1646-4a6c-b4d6-2f1be48e3cef,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-4ad32d47-d16b-4f1a-a822-6bfce5f97bad,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-b9d03ff6-8589-40f5-bf86-246b72e6b58d,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-df6af065-d29a-4d84-96a9-a89388cc4e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-4f8c0446-5111-47a9-96a5-07ca251bed26,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-a4c5c443-238b-461d-8e8f-cccfa4ba27da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1839328081-172.17.0.15-1597361200809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38049,DS-f7559a0b-7d1f-49f2-99cd-eb85e9a6330c,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-d1efb296-e411-43cc-9967-987e70208c53,DISK], DatanodeInfoWithStorage[127.0.0.1:38303,DS-24f7aff1-1646-4a6c-b4d6-2f1be48e3cef,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-4ad32d47-d16b-4f1a-a822-6bfce5f97bad,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-b9d03ff6-8589-40f5-bf86-246b72e6b58d,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-df6af065-d29a-4d84-96a9-a89388cc4e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-4f8c0446-5111-47a9-96a5-07ca251bed26,DISK], DatanodeInfoWithStorage[127.0.0.1:38664,DS-a4c5c443-238b-461d-8e8f-cccfa4ba27da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5488
