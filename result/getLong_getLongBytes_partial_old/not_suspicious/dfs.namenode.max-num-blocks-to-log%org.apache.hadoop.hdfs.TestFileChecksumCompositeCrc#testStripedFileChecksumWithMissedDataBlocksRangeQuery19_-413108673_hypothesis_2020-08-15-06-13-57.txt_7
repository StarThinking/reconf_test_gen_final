reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-692058444-172.17.0.20-1597472291202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33842,DS-cd2c074b-834c-4a60-ba58-d1861eaa022c,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-6e6e53ea-c85a-4db4-a930-c9c1fec114ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-d65595b4-ff32-428f-831f-b2838347d131,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-213630c9-d954-4568-88f8-f5b47d3b3c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-7b672726-cc87-40c3-a108-0ebdbc712b04,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-5245a4b4-88ed-4397-bc0a-d777cc673329,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-79cd417e-cb0c-4f3c-82f3-04887a8efffa,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-afc0fc84-ae46-428e-9ccd-aae9b304774d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-692058444-172.17.0.20-1597472291202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33842,DS-cd2c074b-834c-4a60-ba58-d1861eaa022c,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-6e6e53ea-c85a-4db4-a930-c9c1fec114ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34508,DS-d65595b4-ff32-428f-831f-b2838347d131,DISK], DatanodeInfoWithStorage[127.0.0.1:35685,DS-213630c9-d954-4568-88f8-f5b47d3b3c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-7b672726-cc87-40c3-a108-0ebdbc712b04,DISK], DatanodeInfoWithStorage[127.0.0.1:46107,DS-5245a4b4-88ed-4397-bc0a-d777cc673329,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-79cd417e-cb0c-4f3c-82f3-04887a8efffa,DISK], DatanodeInfoWithStorage[127.0.0.1:45788,DS-afc0fc84-ae46-428e-9ccd-aae9b304774d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1309442405-172.17.0.20-1597472334274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46616,DS-d53e5e81-c98f-4b5a-aaff-87e37fe69057,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-e9ba5a58-c867-47e5-870f-c27af9296642,DISK], DatanodeInfoWithStorage[127.0.0.1:36616,DS-5f82f7cd-b76c-4eec-966e-629af65352c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-66986a73-913f-411a-ad66-d088d2a8eae3,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-4f459fa8-e92b-481e-b1cd-cfaf0a957674,DISK], DatanodeInfoWithStorage[127.0.0.1:35270,DS-6078c188-6c28-45af-9bb9-5995e4d042d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-0f10c5ff-8129-4935-92e3-65d07fca9d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-a275cb0a-f938-4c19-b336-f7d5bf8619fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1309442405-172.17.0.20-1597472334274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46616,DS-d53e5e81-c98f-4b5a-aaff-87e37fe69057,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-e9ba5a58-c867-47e5-870f-c27af9296642,DISK], DatanodeInfoWithStorage[127.0.0.1:36616,DS-5f82f7cd-b76c-4eec-966e-629af65352c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44156,DS-66986a73-913f-411a-ad66-d088d2a8eae3,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-4f459fa8-e92b-481e-b1cd-cfaf0a957674,DISK], DatanodeInfoWithStorage[127.0.0.1:35270,DS-6078c188-6c28-45af-9bb9-5995e4d042d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35558,DS-0f10c5ff-8129-4935-92e3-65d07fca9d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44707,DS-a275cb0a-f938-4c19-b336-f7d5bf8619fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1654661036-172.17.0.20-1597472530063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37800,DS-b9d4f14a-411b-46fd-b708-c3904ac2b900,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-70aaa8b3-b5b3-4bf9-99bd-be2df16d7345,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-5be1fcf7-2d99-43f9-8252-a3d0d021a249,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-17226c55-300f-44dd-99aa-23ac163b722b,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-075d3ab3-a73b-4eaf-b2de-1a5952a07043,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-28a34610-7f0a-4a05-b9ad-e4bbce6ecd93,DISK], DatanodeInfoWithStorage[127.0.0.1:39473,DS-87f2e03e-f9ab-4e3a-812f-20ce7336bd90,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-88bcc1f3-0aa3-4e88-b9c3-2499a9adf30e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1654661036-172.17.0.20-1597472530063:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37800,DS-b9d4f14a-411b-46fd-b708-c3904ac2b900,DISK], DatanodeInfoWithStorage[127.0.0.1:34580,DS-70aaa8b3-b5b3-4bf9-99bd-be2df16d7345,DISK], DatanodeInfoWithStorage[127.0.0.1:36748,DS-5be1fcf7-2d99-43f9-8252-a3d0d021a249,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-17226c55-300f-44dd-99aa-23ac163b722b,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-075d3ab3-a73b-4eaf-b2de-1a5952a07043,DISK], DatanodeInfoWithStorage[127.0.0.1:45782,DS-28a34610-7f0a-4a05-b9ad-e4bbce6ecd93,DISK], DatanodeInfoWithStorage[127.0.0.1:39473,DS-87f2e03e-f9ab-4e3a-812f-20ce7336bd90,DISK], DatanodeInfoWithStorage[127.0.0.1:40466,DS-88bcc1f3-0aa3-4e88-b9c3-2499a9adf30e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1463010744-172.17.0.20-1597472876922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38404,DS-01f75866-da5a-4b8e-964f-144b8b833f96,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-b081401b-dc8c-4a40-9009-43a2ea79ee5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-538c4ca2-82c7-49dc-a7cc-e848f9f7d69e,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-8ead3ab7-5a70-4e6b-8e45-8f443fb60369,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-98684720-a848-44ad-b7d4-70b4538f3517,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-1adeead1-4310-40da-8d6f-c317a0604ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-eca66b67-5146-48d1-adea-45807d450662,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-5bc650d4-9410-4d8b-8638-dffd2b456052,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1463010744-172.17.0.20-1597472876922:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38404,DS-01f75866-da5a-4b8e-964f-144b8b833f96,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-b081401b-dc8c-4a40-9009-43a2ea79ee5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-538c4ca2-82c7-49dc-a7cc-e848f9f7d69e,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-8ead3ab7-5a70-4e6b-8e45-8f443fb60369,DISK], DatanodeInfoWithStorage[127.0.0.1:41494,DS-98684720-a848-44ad-b7d4-70b4538f3517,DISK], DatanodeInfoWithStorage[127.0.0.1:40341,DS-1adeead1-4310-40da-8d6f-c317a0604ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-eca66b67-5146-48d1-adea-45807d450662,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-5bc650d4-9410-4d8b-8638-dffd2b456052,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1742553665-172.17.0.20-1597474135218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40332,DS-1c066201-6e95-46aa-8065-74fa2a3f745b,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-189b2e2c-7ed3-414f-851b-a13d69a10cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-9fd6dbab-ea29-491d-83dc-74d0c2d5b1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-b413b9e9-80db-44d8-a8d0-18255a7132a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-d968757e-0d99-4fa3-b6c1-f4810acc2b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-3499aaab-b08b-416a-b668-93bffb677c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-ae5ce809-9cef-4405-aaea-2269f2f15e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-5484e4e5-2fbb-4a6a-9c7a-19a191b9d589,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1742553665-172.17.0.20-1597474135218:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40332,DS-1c066201-6e95-46aa-8065-74fa2a3f745b,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-189b2e2c-7ed3-414f-851b-a13d69a10cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-9fd6dbab-ea29-491d-83dc-74d0c2d5b1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-b413b9e9-80db-44d8-a8d0-18255a7132a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-d968757e-0d99-4fa3-b6c1-f4810acc2b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-3499aaab-b08b-416a-b668-93bffb677c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-ae5ce809-9cef-4405-aaea-2269f2f15e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-5484e4e5-2fbb-4a6a-9c7a-19a191b9d589,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-382547197-172.17.0.20-1597474723657:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33079,DS-549f6b88-95e4-4eaa-8a78-19ff7199017e,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-de5a9803-9806-42d2-938d-7921ca146461,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-b5d76556-c7ab-46ee-9950-d6b8401356db,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-8067e863-82b4-47f2-9da5-2a6b8ac789c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-5612f875-2d9b-41c6-8a1b-502401f2b462,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-21993d41-d8b3-431e-acf6-c3cfe2c55bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-46663832-8d57-43e6-9219-3fc72f37a9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-dab3f113-9ab5-4891-a989-13592177c8ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-382547197-172.17.0.20-1597474723657:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33079,DS-549f6b88-95e4-4eaa-8a78-19ff7199017e,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-de5a9803-9806-42d2-938d-7921ca146461,DISK], DatanodeInfoWithStorage[127.0.0.1:38098,DS-b5d76556-c7ab-46ee-9950-d6b8401356db,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-8067e863-82b4-47f2-9da5-2a6b8ac789c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-5612f875-2d9b-41c6-8a1b-502401f2b462,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-21993d41-d8b3-431e-acf6-c3cfe2c55bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43048,DS-46663832-8d57-43e6-9219-3fc72f37a9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-dab3f113-9ab5-4891-a989-13592177c8ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1683028938-172.17.0.20-1597475539349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43396,DS-d4c7c93a-4043-4d27-b9cb-46e2b3e6ba6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-d118d6c7-c904-4c2d-9942-30eb9ac7a825,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-204b3aae-76a8-4a26-b668-30d5eeab6cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-ba131aa5-64b3-4d09-ab1b-3d5e7194ee58,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-12fdfabd-14f6-4c6e-b98d-48da5f62b3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-7e11fbe3-9cf1-4853-9825-b76de00b12f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-18ebc162-73aa-472c-b2bd-26f81f51d103,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-df2e1519-60b1-4cb0-8e31-5b446235be3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1683028938-172.17.0.20-1597475539349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43396,DS-d4c7c93a-4043-4d27-b9cb-46e2b3e6ba6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-d118d6c7-c904-4c2d-9942-30eb9ac7a825,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-204b3aae-76a8-4a26-b668-30d5eeab6cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:42937,DS-ba131aa5-64b3-4d09-ab1b-3d5e7194ee58,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-12fdfabd-14f6-4c6e-b98d-48da5f62b3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45031,DS-7e11fbe3-9cf1-4853-9825-b76de00b12f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-18ebc162-73aa-472c-b2bd-26f81f51d103,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-df2e1519-60b1-4cb0-8e31-5b446235be3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-691130351-172.17.0.20-1597475614706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39281,DS-a3ed5325-f38d-4941-a439-02ec9195291d,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-12e2aae9-d7d6-4c07-925f-7eb8bae00f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-730289b4-ac0f-4a9e-8ba7-5b93d3f040e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-e12394d5-edfa-47a9-851f-f98d8f7b7652,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-4cfe7101-c8d2-46f1-9055-ea43b94097b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-45fa984a-bc65-49e9-8215-60c32086187b,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-afc6d03e-562f-449f-b9be-a889330e95e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-f7a89c35-157e-4393-84e3-ae4964c1f378,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-691130351-172.17.0.20-1597475614706:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39281,DS-a3ed5325-f38d-4941-a439-02ec9195291d,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-12e2aae9-d7d6-4c07-925f-7eb8bae00f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-730289b4-ac0f-4a9e-8ba7-5b93d3f040e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-e12394d5-edfa-47a9-851f-f98d8f7b7652,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-4cfe7101-c8d2-46f1-9055-ea43b94097b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-45fa984a-bc65-49e9-8215-60c32086187b,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-afc6d03e-562f-449f-b9be-a889330e95e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36077,DS-f7a89c35-157e-4393-84e3-ae4964c1f378,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969024618-172.17.0.20-1597475652249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34457,DS-4a4517a4-1b2c-4083-aaed-518be9766aec,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-694242d8-642d-4324-8f17-7797539b3fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-b4563071-3053-4321-b4a5-6574e11defd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-886bb9eb-3fb3-4236-8ef4-0ccf519c07e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-09a398e6-d638-4664-9f27-9f2fdeb427dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-c292875d-07f7-4a4f-8ec3-e9246572f7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-5a0e7609-00be-4ac2-9734-dcaee3c1ae14,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-b5b814b3-2fbe-4e04-a92c-69a272514ac4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969024618-172.17.0.20-1597475652249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34457,DS-4a4517a4-1b2c-4083-aaed-518be9766aec,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-694242d8-642d-4324-8f17-7797539b3fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-b4563071-3053-4321-b4a5-6574e11defd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36326,DS-886bb9eb-3fb3-4236-8ef4-0ccf519c07e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-09a398e6-d638-4664-9f27-9f2fdeb427dd,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-c292875d-07f7-4a4f-8ec3-e9246572f7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-5a0e7609-00be-4ac2-9734-dcaee3c1ae14,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-b5b814b3-2fbe-4e04-a92c-69a272514ac4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1783527329-172.17.0.20-1597476318625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46397,DS-eff12204-73fa-48ea-9bf0-e05f4f9fbea4,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-8bf27cb2-5c0a-455a-8b48-ad21ff6fce20,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-ffc9bc6a-8155-4e0e-95da-76b249b6b88a,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-ae23327c-a8c4-445d-9a6e-cbd7e11d377d,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-de7b1b68-efa0-4298-b8b1-0049ac602531,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-cd284512-6b62-42e5-9f9e-0a3a1d6ee796,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-54834bd3-36e6-4d9d-903f-362452ae9ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-a349c626-b0ea-466e-ba9f-6e4724986cd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1783527329-172.17.0.20-1597476318625:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46397,DS-eff12204-73fa-48ea-9bf0-e05f4f9fbea4,DISK], DatanodeInfoWithStorage[127.0.0.1:40810,DS-8bf27cb2-5c0a-455a-8b48-ad21ff6fce20,DISK], DatanodeInfoWithStorage[127.0.0.1:43622,DS-ffc9bc6a-8155-4e0e-95da-76b249b6b88a,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-ae23327c-a8c4-445d-9a6e-cbd7e11d377d,DISK], DatanodeInfoWithStorage[127.0.0.1:37644,DS-de7b1b68-efa0-4298-b8b1-0049ac602531,DISK], DatanodeInfoWithStorage[127.0.0.1:39904,DS-cd284512-6b62-42e5-9f9e-0a3a1d6ee796,DISK], DatanodeInfoWithStorage[127.0.0.1:46460,DS-54834bd3-36e6-4d9d-903f-362452ae9ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-a349c626-b0ea-466e-ba9f-6e4724986cd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1990998195-172.17.0.20-1597476354024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41728,DS-8ffba922-d134-432c-b70d-62b9215c4c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-4be42b3a-9cc8-4a05-b38a-3b461adc2e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-f62c61bc-80c6-4fff-befb-5b3a74764ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-5ae69c50-ade2-4b88-a00a-df6a53649720,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-26a1c0b9-e793-4ec1-a324-9b46a1c6d2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-20320704-6204-47c7-a229-555d01c87da6,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-7a70ed74-f3de-47b7-b2d4-25294757d2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-954c8d64-0e2b-4250-8e3b-c57fa1871378,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1990998195-172.17.0.20-1597476354024:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41728,DS-8ffba922-d134-432c-b70d-62b9215c4c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-4be42b3a-9cc8-4a05-b38a-3b461adc2e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-f62c61bc-80c6-4fff-befb-5b3a74764ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:40929,DS-5ae69c50-ade2-4b88-a00a-df6a53649720,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-26a1c0b9-e793-4ec1-a324-9b46a1c6d2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-20320704-6204-47c7-a229-555d01c87da6,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-7a70ed74-f3de-47b7-b2d4-25294757d2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34689,DS-954c8d64-0e2b-4250-8e3b-c57fa1871378,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2005496333-172.17.0.20-1597476470040:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35290,DS-b3b587c4-4b69-4a2d-9085-822b3a2af5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-3a5e3772-28b8-4060-996d-30634df3c01e,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-d527917f-aeee-437a-bce6-316535167ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-e5ba63ad-6d2b-405f-b6b0-8c3226fd28e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-0dc388d4-ad5b-433d-8b2c-d163a5661088,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-fbccdc79-f047-43e6-b231-5b1fa44f3870,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-2d86efdd-ea31-4a35-ae84-3fc88798a1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-65eb6cb5-372d-4edf-9fa1-4f2ea47026bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2005496333-172.17.0.20-1597476470040:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35290,DS-b3b587c4-4b69-4a2d-9085-822b3a2af5b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-3a5e3772-28b8-4060-996d-30634df3c01e,DISK], DatanodeInfoWithStorage[127.0.0.1:36153,DS-d527917f-aeee-437a-bce6-316535167ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-e5ba63ad-6d2b-405f-b6b0-8c3226fd28e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-0dc388d4-ad5b-433d-8b2c-d163a5661088,DISK], DatanodeInfoWithStorage[127.0.0.1:42470,DS-fbccdc79-f047-43e6-b231-5b1fa44f3870,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-2d86efdd-ea31-4a35-ae84-3fc88798a1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-65eb6cb5-372d-4edf-9fa1-4f2ea47026bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1649947080-172.17.0.20-1597477101916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43615,DS-8e2fc553-9a72-4c80-9d1d-a9f73879785f,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-f1842704-8ed8-4d0e-ab56-730316dee5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-32813d13-cf18-4706-836b-37943e999fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-cf1f738f-d42b-4dac-9755-974de6e3d769,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-41d8642d-0f44-41d1-9034-d6a44f7b409a,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-63f1ce47-67a0-46db-8546-08cb03ea2c73,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-aaa3fe35-845a-4ee8-9f80-db72d9cf719f,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-884061da-7d33-4107-ba7e-0ca2654094a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1649947080-172.17.0.20-1597477101916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43615,DS-8e2fc553-9a72-4c80-9d1d-a9f73879785f,DISK], DatanodeInfoWithStorage[127.0.0.1:34331,DS-f1842704-8ed8-4d0e-ab56-730316dee5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-32813d13-cf18-4706-836b-37943e999fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42289,DS-cf1f738f-d42b-4dac-9755-974de6e3d769,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-41d8642d-0f44-41d1-9034-d6a44f7b409a,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-63f1ce47-67a0-46db-8546-08cb03ea2c73,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-aaa3fe35-845a-4ee8-9f80-db72d9cf719f,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-884061da-7d33-4107-ba7e-0ca2654094a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:NameNode
v1: 2000
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1909394902-172.17.0.20-1597477143828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46152,DS-d53f1cff-7a72-4d93-80cd-54bda1eebb82,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-54cd73a9-e2b3-4fc9-a061-3527cb21a10e,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-f45891ee-432c-4e5b-a257-8284bb9c2a25,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-1e03645d-92bd-47ea-8079-ba561937cc37,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-d44c7ad9-639e-40b6-99c0-c7009b5b13cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-f638667a-5619-4404-abd1-66a1a24f1c99,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-933ca364-e542-4520-a146-f84b32483abd,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-ea0fec01-6424-429b-99e2-53481918772c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1909394902-172.17.0.20-1597477143828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46152,DS-d53f1cff-7a72-4d93-80cd-54bda1eebb82,DISK], DatanodeInfoWithStorage[127.0.0.1:37704,DS-54cd73a9-e2b3-4fc9-a061-3527cb21a10e,DISK], DatanodeInfoWithStorage[127.0.0.1:43970,DS-f45891ee-432c-4e5b-a257-8284bb9c2a25,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-1e03645d-92bd-47ea-8079-ba561937cc37,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-d44c7ad9-639e-40b6-99c0-c7009b5b13cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-f638667a-5619-4404-abd1-66a1a24f1c99,DISK], DatanodeInfoWithStorage[127.0.0.1:41082,DS-933ca364-e542-4520-a146-f84b32483abd,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-ea0fec01-6424-429b-99e2-53481918772c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5689
