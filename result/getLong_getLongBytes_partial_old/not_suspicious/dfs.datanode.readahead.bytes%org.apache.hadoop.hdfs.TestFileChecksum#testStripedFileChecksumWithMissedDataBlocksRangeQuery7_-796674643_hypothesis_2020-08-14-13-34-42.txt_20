reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518361890-172.17.0.2-1597412143425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41443,DS-f559dd48-45e6-4c0c-aec5-e79437ecc926,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-661d1416-1f64-4f8f-961b-695b1358c3af,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-32b5af0d-6779-4984-afb7-4a58b7b74469,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-7f59007e-25fe-4fc2-bfda-2f0e35bcdd02,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-d8b0bb31-b773-44ec-b6fc-d05461dab886,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-f7bf7b7f-084d-4a47-8470-f7302b586735,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-a70c348d-e9aa-469e-94e5-78832399e3de,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-829cfe6c-8cec-4b5e-bf85-7eb9f6706a8e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518361890-172.17.0.2-1597412143425:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41443,DS-f559dd48-45e6-4c0c-aec5-e79437ecc926,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-661d1416-1f64-4f8f-961b-695b1358c3af,DISK], DatanodeInfoWithStorage[127.0.0.1:39160,DS-32b5af0d-6779-4984-afb7-4a58b7b74469,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-7f59007e-25fe-4fc2-bfda-2f0e35bcdd02,DISK], DatanodeInfoWithStorage[127.0.0.1:42908,DS-d8b0bb31-b773-44ec-b6fc-d05461dab886,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-f7bf7b7f-084d-4a47-8470-f7302b586735,DISK], DatanodeInfoWithStorage[127.0.0.1:40022,DS-a70c348d-e9aa-469e-94e5-78832399e3de,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-829cfe6c-8cec-4b5e-bf85-7eb9f6706a8e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2066733308-172.17.0.2-1597412188244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38702,DS-2c475fc6-2ef3-408a-8aca-b7d57523166d,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-ec843053-d82c-4df8-8bbb-e02fdb4ea96f,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-949701de-164f-4a62-af65-2a380b223014,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-97e884b7-e63d-426e-b2ca-84c83ed79e92,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-d62692d9-669e-4025-ad36-27903cbce988,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-2c332bbe-3551-43b7-ae2b-9e545e2f94f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-d9b6ddc4-3112-4438-97c9-6d4fb74428e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-fd23cb01-2c94-4219-ad52-c01b2923887d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2066733308-172.17.0.2-1597412188244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38702,DS-2c475fc6-2ef3-408a-8aca-b7d57523166d,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-ec843053-d82c-4df8-8bbb-e02fdb4ea96f,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-949701de-164f-4a62-af65-2a380b223014,DISK], DatanodeInfoWithStorage[127.0.0.1:43069,DS-97e884b7-e63d-426e-b2ca-84c83ed79e92,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-d62692d9-669e-4025-ad36-27903cbce988,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-2c332bbe-3551-43b7-ae2b-9e545e2f94f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-d9b6ddc4-3112-4438-97c9-6d4fb74428e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-fd23cb01-2c94-4219-ad52-c01b2923887d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-48097159-172.17.0.2-1597412403028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40423,DS-28f0bbb6-8fa8-47db-82ea-62c20289c74c,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-25900655-0b26-4aa5-b243-2153c9372d84,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-c504ce03-7c69-435c-a30e-64c849a6dc75,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-bf94ac80-a1f5-4d97-89bb-15de7f9c67a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-10f37713-e234-4474-b29b-21e9fe21cd64,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-7e83d1ca-dcce-4af3-85dd-2059fefaf90e,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-a1e57417-6e8d-4bf0-ab58-bee4b59781a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-f9683385-df8d-4cb0-b0be-e462f49c7989,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-48097159-172.17.0.2-1597412403028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40423,DS-28f0bbb6-8fa8-47db-82ea-62c20289c74c,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-25900655-0b26-4aa5-b243-2153c9372d84,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-c504ce03-7c69-435c-a30e-64c849a6dc75,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-bf94ac80-a1f5-4d97-89bb-15de7f9c67a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-10f37713-e234-4474-b29b-21e9fe21cd64,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-7e83d1ca-dcce-4af3-85dd-2059fefaf90e,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-a1e57417-6e8d-4bf0-ab58-bee4b59781a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-f9683385-df8d-4cb0-b0be-e462f49c7989,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1279788554-172.17.0.2-1597412536378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37016,DS-0fbb107a-6ead-437d-a18d-7a981703c7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-c90d291b-c4e0-43a4-acc7-8340b50f40d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-d6b558fe-5983-4914-b968-70512178e030,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-cba70344-2210-4285-9a92-e3b16fec79a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-c2bb653f-1f0b-4bee-b6f7-80c9f6ac965b,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-878afbe7-df50-4018-8fd1-f4193ad756d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-967e3061-c5bb-43e9-93d9-7af984004b56,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-7fde1f03-300c-4497-b649-e724d58d4746,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1279788554-172.17.0.2-1597412536378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37016,DS-0fbb107a-6ead-437d-a18d-7a981703c7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-c90d291b-c4e0-43a4-acc7-8340b50f40d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-d6b558fe-5983-4914-b968-70512178e030,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-cba70344-2210-4285-9a92-e3b16fec79a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-c2bb653f-1f0b-4bee-b6f7-80c9f6ac965b,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-878afbe7-df50-4018-8fd1-f4193ad756d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-967e3061-c5bb-43e9-93d9-7af984004b56,DISK], DatanodeInfoWithStorage[127.0.0.1:43901,DS-7fde1f03-300c-4497-b649-e724d58d4746,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1705293117-172.17.0.2-1597412673653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39874,DS-26b49e55-4fe7-499f-9d1c-e3f0ffd53954,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-bf4bd8b7-0a0e-4588-a602-5d6190059cce,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-9edb3f5b-3bd2-4dea-9743-793d3e8f8fea,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-aab5c1af-04b3-41a0-bd34-418d60dc67ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-da902600-2238-4641-92e0-c091ebb6782d,DISK], DatanodeInfoWithStorage[127.0.0.1:37382,DS-48096866-b2b1-4495-8571-8378addc1841,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-cea0883f-6d23-4cfd-b594-18a1ab2583f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-4c88add4-6f45-4370-9f3a-f6fa366cc19d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1705293117-172.17.0.2-1597412673653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39874,DS-26b49e55-4fe7-499f-9d1c-e3f0ffd53954,DISK], DatanodeInfoWithStorage[127.0.0.1:40540,DS-bf4bd8b7-0a0e-4588-a602-5d6190059cce,DISK], DatanodeInfoWithStorage[127.0.0.1:41158,DS-9edb3f5b-3bd2-4dea-9743-793d3e8f8fea,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-aab5c1af-04b3-41a0-bd34-418d60dc67ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-da902600-2238-4641-92e0-c091ebb6782d,DISK], DatanodeInfoWithStorage[127.0.0.1:37382,DS-48096866-b2b1-4495-8571-8378addc1841,DISK], DatanodeInfoWithStorage[127.0.0.1:33951,DS-cea0883f-6d23-4cfd-b594-18a1ab2583f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-4c88add4-6f45-4370-9f3a-f6fa366cc19d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948877032-172.17.0.2-1597412760659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41863,DS-96b6c81b-0d91-4caa-9528-680247a7fc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-ec648c3b-d1f6-4e9c-9c16-ef5b317f435d,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-c6b8664d-60a7-4bb1-abed-9d1882d005fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-c45114eb-eb1a-43e2-95b2-74bbcccfe5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-f70d54e7-2298-432d-831d-45823c56d69e,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-103f6296-441e-4466-a79b-1ffd490c94be,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-0909c9fd-f43b-43c8-a85a-f08eafc7c3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-946a6140-c2a7-4927-917b-f230c457d65e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948877032-172.17.0.2-1597412760659:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41863,DS-96b6c81b-0d91-4caa-9528-680247a7fc6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-ec648c3b-d1f6-4e9c-9c16-ef5b317f435d,DISK], DatanodeInfoWithStorage[127.0.0.1:37552,DS-c6b8664d-60a7-4bb1-abed-9d1882d005fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40490,DS-c45114eb-eb1a-43e2-95b2-74bbcccfe5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-f70d54e7-2298-432d-831d-45823c56d69e,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-103f6296-441e-4466-a79b-1ffd490c94be,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-0909c9fd-f43b-43c8-a85a-f08eafc7c3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-946a6140-c2a7-4927-917b-f230c457d65e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1385286416-172.17.0.2-1597412803683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36632,DS-3e66e32f-3a09-4c45-83c3-2f9eb12293a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-e2404586-0c77-4425-9937-c20fee8595d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43520,DS-69e20213-a728-4eff-a0e1-b5d6f96d0433,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-75aa1b64-05c1-4a4d-8ff9-ffed8cedd283,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-cef1264a-0428-4be7-b2bf-8d016600da15,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-0cd3def3-d283-47c7-ae77-78221f58c394,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-8d2174a8-195e-463a-aea3-ca4161b3e144,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-82d01bae-1444-4ce0-8c7c-9f2977daaf9d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1385286416-172.17.0.2-1597412803683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36632,DS-3e66e32f-3a09-4c45-83c3-2f9eb12293a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-e2404586-0c77-4425-9937-c20fee8595d0,DISK], DatanodeInfoWithStorage[127.0.0.1:43520,DS-69e20213-a728-4eff-a0e1-b5d6f96d0433,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-75aa1b64-05c1-4a4d-8ff9-ffed8cedd283,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-cef1264a-0428-4be7-b2bf-8d016600da15,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-0cd3def3-d283-47c7-ae77-78221f58c394,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-8d2174a8-195e-463a-aea3-ca4161b3e144,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-82d01bae-1444-4ce0-8c7c-9f2977daaf9d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648826258-172.17.0.2-1597412857570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37872,DS-d955807a-7175-4168-8875-229724f15ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-baae9fe3-90ba-4834-a808-f1a1f14e149a,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-91525fec-ad4b-4835-a327-14689e75d5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-8c9d8897-e239-4e44-8f89-9922b63e0a71,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-26551a93-163e-49ca-8a2d-2b14eeb35f95,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-9e75ef29-4b48-4811-93ee-41e890f153e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-6f974fe0-f5e0-44c4-a125-f98e90bb2aee,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-70edba47-5417-43ff-8506-3975c4b27b8a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-648826258-172.17.0.2-1597412857570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37872,DS-d955807a-7175-4168-8875-229724f15ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-baae9fe3-90ba-4834-a808-f1a1f14e149a,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-91525fec-ad4b-4835-a327-14689e75d5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34114,DS-8c9d8897-e239-4e44-8f89-9922b63e0a71,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-26551a93-163e-49ca-8a2d-2b14eeb35f95,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-9e75ef29-4b48-4811-93ee-41e890f153e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33964,DS-6f974fe0-f5e0-44c4-a125-f98e90bb2aee,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-70edba47-5417-43ff-8506-3975c4b27b8a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1746046386-172.17.0.2-1597412903377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37871,DS-ef19c603-2106-4777-b1de-6cdf665d1a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-a0517b63-a13f-4498-b968-c3b42b1f7736,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-e2a04bf2-0ca4-4c8e-86f0-4ca3eecd7334,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-6f9aeb81-a52b-47e9-a20d-bf897ce36337,DISK], DatanodeInfoWithStorage[127.0.0.1:45996,DS-20b6d61f-6aa6-4e5f-9c52-645ecccf2ade,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-e5019a85-b123-4008-a418-d3f632df7afc,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-e03adede-58c7-4163-97a2-561bc5dc904c,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-3b174ce1-7860-42a3-9773-9d6b4bc87d60,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1746046386-172.17.0.2-1597412903377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37871,DS-ef19c603-2106-4777-b1de-6cdf665d1a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46010,DS-a0517b63-a13f-4498-b968-c3b42b1f7736,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-e2a04bf2-0ca4-4c8e-86f0-4ca3eecd7334,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-6f9aeb81-a52b-47e9-a20d-bf897ce36337,DISK], DatanodeInfoWithStorage[127.0.0.1:45996,DS-20b6d61f-6aa6-4e5f-9c52-645ecccf2ade,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-e5019a85-b123-4008-a418-d3f632df7afc,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-e03adede-58c7-4163-97a2-561bc5dc904c,DISK], DatanodeInfoWithStorage[127.0.0.1:43685,DS-3b174ce1-7860-42a3-9773-9d6b4bc87d60,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1237086457-172.17.0.2-1597413265732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37316,DS-c3271d8e-1110-46d5-a892-00b2fa528640,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-fa5e2f2f-ee6a-4e7d-8740-909859fa9e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-fdbb99a9-2f58-4973-ba99-2f3be113e3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-60e63fb5-3bae-418b-9c36-a047bc10c2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-520e2e7b-db4a-407f-a9ab-0a38f72ebb55,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-b8236538-31d4-4531-98b9-327254e13b15,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-a167e2ee-ef61-4fd3-abc6-5094dd3ff03c,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-8fb6e85c-a15a-4860-96ec-a63a029d25c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1237086457-172.17.0.2-1597413265732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37316,DS-c3271d8e-1110-46d5-a892-00b2fa528640,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-fa5e2f2f-ee6a-4e7d-8740-909859fa9e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-fdbb99a9-2f58-4973-ba99-2f3be113e3a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-60e63fb5-3bae-418b-9c36-a047bc10c2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-520e2e7b-db4a-407f-a9ab-0a38f72ebb55,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-b8236538-31d4-4531-98b9-327254e13b15,DISK], DatanodeInfoWithStorage[127.0.0.1:32890,DS-a167e2ee-ef61-4fd3-abc6-5094dd3ff03c,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-8fb6e85c-a15a-4860-96ec-a63a029d25c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-406276841-172.17.0.2-1597413357159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38409,DS-319bf55a-397d-4f17-b034-28c6544e2788,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-3fecc834-5446-4cb3-89a9-2e009f815ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-359f5442-4f30-4e38-90cd-5adfba4f867e,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-97218798-07fc-40a9-bfe1-4af99d5efaf8,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-8e0c33dd-0708-4d2f-8119-b089a858d532,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-d680afbb-cdd4-4de1-b5dd-041e7190ecf6,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-ec3e8209-d8b2-4a25-bb47-372938684443,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-682462a4-bc54-46da-a3a0-9260aafb7a61,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-406276841-172.17.0.2-1597413357159:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38409,DS-319bf55a-397d-4f17-b034-28c6544e2788,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-3fecc834-5446-4cb3-89a9-2e009f815ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-359f5442-4f30-4e38-90cd-5adfba4f867e,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-97218798-07fc-40a9-bfe1-4af99d5efaf8,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-8e0c33dd-0708-4d2f-8119-b089a858d532,DISK], DatanodeInfoWithStorage[127.0.0.1:42526,DS-d680afbb-cdd4-4de1-b5dd-041e7190ecf6,DISK], DatanodeInfoWithStorage[127.0.0.1:36819,DS-ec3e8209-d8b2-4a25-bb47-372938684443,DISK], DatanodeInfoWithStorage[127.0.0.1:35627,DS-682462a4-bc54-46da-a3a0-9260aafb7a61,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2031620133-172.17.0.2-1597413400014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38255,DS-7daba085-c66b-42f1-ab84-5b55f80d37e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-de4e2db9-e795-47d1-8090-8ee2d1819e86,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-ed02943d-7f4d-4433-ae6b-c992e1ac4017,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-aaf1186a-a9f4-456a-8ff3-8c55c9745ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-b5aabd7b-1249-45e3-8b29-dd13c9e9d330,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-c88b556c-6609-4b57-95e1-22a9d1a86b37,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-ad37329d-7c52-4a9f-aabb-19a248957b88,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-491519d9-c01d-4bb7-aa21-ae75111133fb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2031620133-172.17.0.2-1597413400014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38255,DS-7daba085-c66b-42f1-ab84-5b55f80d37e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-de4e2db9-e795-47d1-8090-8ee2d1819e86,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-ed02943d-7f4d-4433-ae6b-c992e1ac4017,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-aaf1186a-a9f4-456a-8ff3-8c55c9745ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-b5aabd7b-1249-45e3-8b29-dd13c9e9d330,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-c88b556c-6609-4b57-95e1-22a9d1a86b37,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-ad37329d-7c52-4a9f-aabb-19a248957b88,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-491519d9-c01d-4bb7-aa21-ae75111133fb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1715754368-172.17.0.2-1597413489644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43405,DS-be0e1747-8360-40bc-925f-e62018e447c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-e8123ea9-52fe-4f3d-8e8b-ee8cb3b0dc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-9ba18e1f-05c7-4d38-b498-e57e2310b40a,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-9c190a31-7fd4-4630-87fa-32dfeab026f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-213c174d-0e46-42e1-95f5-bca5bd8f7c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-a559effb-a4e5-48fe-a08c-2459921a66dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-7b111915-e96c-46e7-83d1-1e53d3ea5b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-be38db46-e69e-492f-b5b8-d72bc840c6d0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1715754368-172.17.0.2-1597413489644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43405,DS-be0e1747-8360-40bc-925f-e62018e447c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-e8123ea9-52fe-4f3d-8e8b-ee8cb3b0dc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45925,DS-9ba18e1f-05c7-4d38-b498-e57e2310b40a,DISK], DatanodeInfoWithStorage[127.0.0.1:45153,DS-9c190a31-7fd4-4630-87fa-32dfeab026f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-213c174d-0e46-42e1-95f5-bca5bd8f7c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-a559effb-a4e5-48fe-a08c-2459921a66dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-7b111915-e96c-46e7-83d1-1e53d3ea5b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-be38db46-e69e-492f-b5b8-d72bc840c6d0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60166518-172.17.0.2-1597413738773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34011,DS-2f6ff5b0-79a1-498d-925d-79d525cce504,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-8c3a9ebc-d3bc-42e3-ac75-197a32c1087c,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-137aca1b-e6dd-4d89-a83f-626abd313d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-de9eecaf-84ba-4680-a22b-ec6770e0ef8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-d1a48de6-380e-4a02-9709-7b6b9e9e733d,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-04c658a3-f490-4347-b40a-c75eb4bf0625,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-5d6795ff-0cce-44b7-8fc4-f22819367ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-dc077561-1cd8-4604-9778-7d6936e156bf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60166518-172.17.0.2-1597413738773:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34011,DS-2f6ff5b0-79a1-498d-925d-79d525cce504,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-8c3a9ebc-d3bc-42e3-ac75-197a32c1087c,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-137aca1b-e6dd-4d89-a83f-626abd313d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45950,DS-de9eecaf-84ba-4680-a22b-ec6770e0ef8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38420,DS-d1a48de6-380e-4a02-9709-7b6b9e9e733d,DISK], DatanodeInfoWithStorage[127.0.0.1:45070,DS-04c658a3-f490-4347-b40a-c75eb4bf0625,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-5d6795ff-0cce-44b7-8fc4-f22819367ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:42165,DS-dc077561-1cd8-4604-9778-7d6936e156bf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1171465206-172.17.0.2-1597413962874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44353,DS-dfc47c88-ab8a-4220-897a-953c4af86572,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-d0e658ab-a5f3-4927-96bd-1e4bd2dc6cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-a52140fd-8d20-482f-aa59-48954ac5f925,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-d115c9a8-5547-40dc-bc1d-b8299c73feb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-5783b968-c8b0-40ee-8730-1a4589ca36d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-5039d44d-a18c-4cb2-b0f3-ad030543133f,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-9dc0526b-32a7-48c3-87b8-567216724e67,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-4ee0af79-a58d-4ffd-9410-dcc608fa9ec7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1171465206-172.17.0.2-1597413962874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44353,DS-dfc47c88-ab8a-4220-897a-953c4af86572,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-d0e658ab-a5f3-4927-96bd-1e4bd2dc6cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-a52140fd-8d20-482f-aa59-48954ac5f925,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-d115c9a8-5547-40dc-bc1d-b8299c73feb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-5783b968-c8b0-40ee-8730-1a4589ca36d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-5039d44d-a18c-4cb2-b0f3-ad030543133f,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-9dc0526b-32a7-48c3-87b8-567216724e67,DISK], DatanodeInfoWithStorage[127.0.0.1:37381,DS-4ee0af79-a58d-4ffd-9410-dcc608fa9ec7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2078697093-172.17.0.2-1597414411828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41501,DS-f74d0fdc-027a-4639-b8b1-a00c8d4b7fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-d5b48f84-85aa-4bde-bacd-a20bbeef0af6,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-c5a82d69-9ad4-418d-b2aa-a8ae810e3a49,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-8a8eba98-1503-43e7-bb6b-37c7226fb293,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-72d8309c-e313-4dfc-81a5-f65e18db565e,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-e5697809-8622-4f05-9e61-c36e97108f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35309,DS-74340c7d-3ecc-40cd-bda0-4c1b40798509,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-ae01be71-e929-47e2-9a72-546fe7f2fc11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2078697093-172.17.0.2-1597414411828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41501,DS-f74d0fdc-027a-4639-b8b1-a00c8d4b7fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-d5b48f84-85aa-4bde-bacd-a20bbeef0af6,DISK], DatanodeInfoWithStorage[127.0.0.1:36128,DS-c5a82d69-9ad4-418d-b2aa-a8ae810e3a49,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-8a8eba98-1503-43e7-bb6b-37c7226fb293,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-72d8309c-e313-4dfc-81a5-f65e18db565e,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-e5697809-8622-4f05-9e61-c36e97108f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35309,DS-74340c7d-3ecc-40cd-bda0-4c1b40798509,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-ae01be71-e929-47e2-9a72-546fe7f2fc11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-734743560-172.17.0.2-1597414869747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42699,DS-b7216c03-aa65-422f-9cec-3b4076e96367,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-5a131739-42ef-4cd6-850e-65bf6861657e,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-5a5c957e-9cbc-4a17-8c0a-c7d08f7c0234,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-50260bdf-1bed-457e-9b5c-aa802404cc71,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-1b726b62-2efd-4e2e-9587-08f4858c1239,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-84505d45-fae3-48c6-bc4d-4e6a267ed2da,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-98a94a00-9558-4395-9c60-3123825755a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-4d4acfd2-36cf-4f66-b368-5af9b7d38c9f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-734743560-172.17.0.2-1597414869747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42699,DS-b7216c03-aa65-422f-9cec-3b4076e96367,DISK], DatanodeInfoWithStorage[127.0.0.1:38550,DS-5a131739-42ef-4cd6-850e-65bf6861657e,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-5a5c957e-9cbc-4a17-8c0a-c7d08f7c0234,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-50260bdf-1bed-457e-9b5c-aa802404cc71,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-1b726b62-2efd-4e2e-9587-08f4858c1239,DISK], DatanodeInfoWithStorage[127.0.0.1:38423,DS-84505d45-fae3-48c6-bc4d-4e6a267ed2da,DISK], DatanodeInfoWithStorage[127.0.0.1:45055,DS-98a94a00-9558-4395-9c60-3123825755a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-4d4acfd2-36cf-4f66-b368-5af9b7d38c9f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1759493001-172.17.0.2-1597414953380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38003,DS-9590e202-b23b-48f8-ae9e-febfa02eb00d,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-0ffe7a7d-cc8f-434d-87c1-0123c3968a58,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-6a61b02c-689e-431b-930a-7ada5b5a6803,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-8ba2aa4f-c2f1-4531-a00d-8735c42b1c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-503ac61b-d28d-4681-bf80-040ef9ae2d88,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-fa816811-a926-421d-b9a9-bcf458e096ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-b4e926c1-f4ba-4ebb-a050-a541f3591bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-34cbc809-abdc-46c4-9b6b-a596d4e51692,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1759493001-172.17.0.2-1597414953380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38003,DS-9590e202-b23b-48f8-ae9e-febfa02eb00d,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-0ffe7a7d-cc8f-434d-87c1-0123c3968a58,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-6a61b02c-689e-431b-930a-7ada5b5a6803,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-8ba2aa4f-c2f1-4531-a00d-8735c42b1c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-503ac61b-d28d-4681-bf80-040ef9ae2d88,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-fa816811-a926-421d-b9a9-bcf458e096ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-b4e926c1-f4ba-4ebb-a050-a541f3591bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-34cbc809-abdc-46c4-9b6b-a596d4e51692,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223218752-172.17.0.2-1597415050267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45234,DS-db0d6be0-4114-4f12-8a6a-11aebf07f081,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-dbb8b894-25f0-49b4-92ec-62c25bafa6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-f1b71a1d-0e17-429a-93e9-e747d4984018,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-e9546fb9-d8f4-4f6c-8251-c723a3383695,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-79f29072-c6e6-4cc7-a7e4-6b562c22b216,DISK], DatanodeInfoWithStorage[127.0.0.1:44417,DS-c3cf275c-c8bc-43e2-a8cb-cd9536447f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-a2f33500-81fe-4f29-b31a-c2703281f3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-f3510c45-7ec2-40aa-be89-0b40a4e418d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1223218752-172.17.0.2-1597415050267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45234,DS-db0d6be0-4114-4f12-8a6a-11aebf07f081,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-dbb8b894-25f0-49b4-92ec-62c25bafa6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-f1b71a1d-0e17-429a-93e9-e747d4984018,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-e9546fb9-d8f4-4f6c-8251-c723a3383695,DISK], DatanodeInfoWithStorage[127.0.0.1:42234,DS-79f29072-c6e6-4cc7-a7e4-6b562c22b216,DISK], DatanodeInfoWithStorage[127.0.0.1:44417,DS-c3cf275c-c8bc-43e2-a8cb-cd9536447f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-a2f33500-81fe-4f29-b31a-c2703281f3e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-f3510c45-7ec2-40aa-be89-0b40a4e418d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563396268-172.17.0.2-1597415187818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43057,DS-6b6f2e06-7313-4592-a1aa-154b6f18ed36,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-cbedc931-ffc3-43b2-838c-5a258f738875,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-1cff5a52-ace7-4347-b66d-4eaf97450383,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-aeec99d0-dc2f-48fb-94e6-b1a8d08fb17b,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-3ca83ff9-1bfb-4196-8de7-ded03cfc5c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-839a04a5-7612-4cd2-b26c-a92b00db6ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-89ca799a-2daa-45d6-ba91-d96d313d1170,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-1ff536be-d09a-4be5-9d13-27c6acf38dfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563396268-172.17.0.2-1597415187818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43057,DS-6b6f2e06-7313-4592-a1aa-154b6f18ed36,DISK], DatanodeInfoWithStorage[127.0.0.1:36159,DS-cbedc931-ffc3-43b2-838c-5a258f738875,DISK], DatanodeInfoWithStorage[127.0.0.1:45211,DS-1cff5a52-ace7-4347-b66d-4eaf97450383,DISK], DatanodeInfoWithStorage[127.0.0.1:39805,DS-aeec99d0-dc2f-48fb-94e6-b1a8d08fb17b,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-3ca83ff9-1bfb-4196-8de7-ded03cfc5c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-839a04a5-7612-4cd2-b26c-a92b00db6ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-89ca799a-2daa-45d6-ba91-d96d313d1170,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-1ff536be-d09a-4be5-9d13-27c6acf38dfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255333150-172.17.0.2-1597415538931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33956,DS-bd42a69a-1ca5-4ae9-b1f2-63bc237821d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-68002184-88cb-47f1-bcd2-b3bd5d14ff93,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-4f29e4a8-6efe-4ac4-88d6-ff29d0c1e182,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-10177e8e-e956-4c10-ae19-e3621bc27572,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-015a7c32-b2f3-4f3c-9414-e3d8a926696d,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-4e7477be-a8a3-4417-a95b-f1b4e63ff24b,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-b71f75f3-712b-464e-8e2b-7541d229f643,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-c345f762-0932-40f5-a74b-1b4376d5ac17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255333150-172.17.0.2-1597415538931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33956,DS-bd42a69a-1ca5-4ae9-b1f2-63bc237821d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-68002184-88cb-47f1-bcd2-b3bd5d14ff93,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-4f29e4a8-6efe-4ac4-88d6-ff29d0c1e182,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-10177e8e-e956-4c10-ae19-e3621bc27572,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-015a7c32-b2f3-4f3c-9414-e3d8a926696d,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-4e7477be-a8a3-4417-a95b-f1b4e63ff24b,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-b71f75f3-712b-464e-8e2b-7541d229f643,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-c345f762-0932-40f5-a74b-1b4376d5ac17,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1139827552-172.17.0.2-1597415807385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34172,DS-1c823602-77a3-4430-937c-4484be8b7d79,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-fbf4cdfb-b7ef-452c-be45-29bd2a8e0b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-08e62cb9-100c-4913-86a5-2fa4898533be,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-9efeb1ee-3d88-49bc-a858-51af95cdd0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-1541ed1b-7531-4480-b4bb-947674520f84,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-4d1e3343-b508-453c-a3e4-29838f835b94,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-cfd04dcb-9a4d-48e1-9562-a0e3063fd856,DISK], DatanodeInfoWithStorage[127.0.0.1:39487,DS-820a98a3-44c4-4cc1-aa92-07df91328bce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1139827552-172.17.0.2-1597415807385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34172,DS-1c823602-77a3-4430-937c-4484be8b7d79,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-fbf4cdfb-b7ef-452c-be45-29bd2a8e0b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-08e62cb9-100c-4913-86a5-2fa4898533be,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-9efeb1ee-3d88-49bc-a858-51af95cdd0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-1541ed1b-7531-4480-b4bb-947674520f84,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-4d1e3343-b508-453c-a3e4-29838f835b94,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-cfd04dcb-9a4d-48e1-9562-a0e3063fd856,DISK], DatanodeInfoWithStorage[127.0.0.1:39487,DS-820a98a3-44c4-4cc1-aa92-07df91328bce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-425334127-172.17.0.2-1597415942303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45238,DS-2c54ab8b-5b5a-4abf-9280-94bdf49f2dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-00eaf84b-2811-4262-9fd1-b0511f0e0167,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-639c9034-7285-4caa-8f1a-12d42f498a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-5c34b9f5-619d-49e9-9006-dc3405dee14c,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-8ec54baa-3b9c-42fa-ab2e-599ac36925f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-964d1e10-efe8-42f0-b2c0-21590153ad1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-d50f5f72-a83a-4284-94d2-72538541ad96,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-48c0fdc9-5130-4376-9424-98c859034faf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-425334127-172.17.0.2-1597415942303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45238,DS-2c54ab8b-5b5a-4abf-9280-94bdf49f2dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:38470,DS-00eaf84b-2811-4262-9fd1-b0511f0e0167,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-639c9034-7285-4caa-8f1a-12d42f498a3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-5c34b9f5-619d-49e9-9006-dc3405dee14c,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-8ec54baa-3b9c-42fa-ab2e-599ac36925f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-964d1e10-efe8-42f0-b2c0-21590153ad1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-d50f5f72-a83a-4284-94d2-72538541ad96,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-48c0fdc9-5130-4376-9424-98c859034faf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910424202-172.17.0.2-1597415994007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41484,DS-ce8b60c7-765b-4a25-90dc-f8c09abd2144,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-586784de-3992-44a7-8a51-b75b811736a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-76848563-d770-4798-86d2-c07d33dc6240,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-6697a31c-2537-48ef-be34-afab1dcf7508,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-4daec99a-e561-476e-89e2-4b0ae06fe95f,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-0a3805e6-d533-4c04-90af-e867b91663f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-1c706b41-4922-4f28-a2cf-02761310100c,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-8035972c-79f3-4185-8299-09688d3ad0cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910424202-172.17.0.2-1597415994007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41484,DS-ce8b60c7-765b-4a25-90dc-f8c09abd2144,DISK], DatanodeInfoWithStorage[127.0.0.1:35274,DS-586784de-3992-44a7-8a51-b75b811736a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36239,DS-76848563-d770-4798-86d2-c07d33dc6240,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-6697a31c-2537-48ef-be34-afab1dcf7508,DISK], DatanodeInfoWithStorage[127.0.0.1:35716,DS-4daec99a-e561-476e-89e2-4b0ae06fe95f,DISK], DatanodeInfoWithStorage[127.0.0.1:39348,DS-0a3805e6-d533-4c04-90af-e867b91663f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-1c706b41-4922-4f28-a2cf-02761310100c,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-8035972c-79f3-4185-8299-09688d3ad0cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-810815658-172.17.0.2-1597416692686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34602,DS-f7a58821-f203-416a-91d0-18409a35ac7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-72650af2-6bbd-40ed-b136-1db0f2018392,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-4224b956-d2a2-4f61-90cd-f1936d5b872b,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-264be85e-809c-43a7-a0ff-1b22754aebee,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-3ed9132a-0f04-4402-b8d3-875cbf16bbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-5bc61c59-9d5d-4095-baac-b13b87aae936,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-fd3f7a0c-a0d4-4d4c-bdb1-873aee2102ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-240c9aa0-1374-4bff-96e7-fdd0c0b99c5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-810815658-172.17.0.2-1597416692686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34602,DS-f7a58821-f203-416a-91d0-18409a35ac7b,DISK], DatanodeInfoWithStorage[127.0.0.1:42413,DS-72650af2-6bbd-40ed-b136-1db0f2018392,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-4224b956-d2a2-4f61-90cd-f1936d5b872b,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-264be85e-809c-43a7-a0ff-1b22754aebee,DISK], DatanodeInfoWithStorage[127.0.0.1:33027,DS-3ed9132a-0f04-4402-b8d3-875cbf16bbd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-5bc61c59-9d5d-4095-baac-b13b87aae936,DISK], DatanodeInfoWithStorage[127.0.0.1:42571,DS-fd3f7a0c-a0d4-4d4c-bdb1-873aee2102ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-240c9aa0-1374-4bff-96e7-fdd0c0b99c5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1186819966-172.17.0.2-1597416743025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33880,DS-1d4fe88c-b948-4452-999f-141dd3aeed41,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-d0af5b6c-e751-4458-9a22-64a8b7bab305,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-77f50273-a82e-45af-af4e-df3317c7fe51,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-678c552f-d101-4637-bb68-c6a2d2e2fc05,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-b53b9439-dbaa-4ef0-928a-48d8d9e53350,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-3f6623e9-16a5-4214-8d8f-6c635b5fef94,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-04cffb5b-f349-4e17-b55d-3ca12622e9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-5f193c20-a786-42ab-bf68-f99380d55cca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1186819966-172.17.0.2-1597416743025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33880,DS-1d4fe88c-b948-4452-999f-141dd3aeed41,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-d0af5b6c-e751-4458-9a22-64a8b7bab305,DISK], DatanodeInfoWithStorage[127.0.0.1:45752,DS-77f50273-a82e-45af-af4e-df3317c7fe51,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-678c552f-d101-4637-bb68-c6a2d2e2fc05,DISK], DatanodeInfoWithStorage[127.0.0.1:40497,DS-b53b9439-dbaa-4ef0-928a-48d8d9e53350,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-3f6623e9-16a5-4214-8d8f-6c635b5fef94,DISK], DatanodeInfoWithStorage[127.0.0.1:40120,DS-04cffb5b-f349-4e17-b55d-3ca12622e9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:38706,DS-5f193c20-a786-42ab-bf68-f99380d55cca,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-341306050-172.17.0.2-1597416786522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46607,DS-704d688c-e4ea-4481-abf8-00cf831e1773,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-2b19408b-68bc-4525-a39f-6d5b34238396,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-dfb185b7-09a4-428e-97a9-26e260f530df,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-c8f42340-64c3-4f92-90a6-9f61eea13c80,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-778aef9e-a12e-44bd-890e-44a2afc49852,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-82ce15ad-15fd-4461-a196-6d031efe751b,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-685a6b0e-99f7-4659-bd7d-7228e0bc5da8,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-51658a92-642e-4bb0-86cb-41c2f77a9ae9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-341306050-172.17.0.2-1597416786522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46607,DS-704d688c-e4ea-4481-abf8-00cf831e1773,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-2b19408b-68bc-4525-a39f-6d5b34238396,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-dfb185b7-09a4-428e-97a9-26e260f530df,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-c8f42340-64c3-4f92-90a6-9f61eea13c80,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-778aef9e-a12e-44bd-890e-44a2afc49852,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-82ce15ad-15fd-4461-a196-6d031efe751b,DISK], DatanodeInfoWithStorage[127.0.0.1:33660,DS-685a6b0e-99f7-4659-bd7d-7228e0bc5da8,DISK], DatanodeInfoWithStorage[127.0.0.1:42677,DS-51658a92-642e-4bb0-86cb-41c2f77a9ae9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227405804-172.17.0.2-1597416894338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33836,DS-a8a5d185-88b7-44da-90be-cee7d3909a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-bf052915-219f-44b0-bfb8-700135dfe98b,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-087b0a21-0e62-4ac7-93aa-25bbd3657b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-b722fef5-e700-4dc0-aacb-e4360457ef6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-b6fec86c-3b43-4a2e-88c8-f5ddf493f6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41485,DS-a14731ac-e173-440c-b93e-99dc7005b960,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-0cba94d2-0af3-4b06-8fc6-ff1c8f7c40f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35739,DS-f1b0da3b-9d72-487f-bb4e-3262d15efb9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227405804-172.17.0.2-1597416894338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33836,DS-a8a5d185-88b7-44da-90be-cee7d3909a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-bf052915-219f-44b0-bfb8-700135dfe98b,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-087b0a21-0e62-4ac7-93aa-25bbd3657b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-b722fef5-e700-4dc0-aacb-e4360457ef6b,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-b6fec86c-3b43-4a2e-88c8-f5ddf493f6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41485,DS-a14731ac-e173-440c-b93e-99dc7005b960,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-0cba94d2-0af3-4b06-8fc6-ff1c8f7c40f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35739,DS-f1b0da3b-9d72-487f-bb4e-3262d15efb9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894163970-172.17.0.2-1597416990278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42446,DS-35b56395-9114-4435-8a24-6194b30a3c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-05553970-ff39-4a3f-a722-39bd59edd72a,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-86e4c8ab-515a-4f0b-8f38-0875b78920f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-550d29fa-0040-4b58-956c-951172ec7e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-caabd6dd-26fb-4554-80e9-96201bb33fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-8a8bc76d-bcf2-44bc-8f26-fb0b64ca8d63,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-b361c1d7-5456-46e3-89ea-8e484cd6d916,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-42271b14-908b-4567-8369-726972df37cb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894163970-172.17.0.2-1597416990278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42446,DS-35b56395-9114-4435-8a24-6194b30a3c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39104,DS-05553970-ff39-4a3f-a722-39bd59edd72a,DISK], DatanodeInfoWithStorage[127.0.0.1:36310,DS-86e4c8ab-515a-4f0b-8f38-0875b78920f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34469,DS-550d29fa-0040-4b58-956c-951172ec7e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42818,DS-caabd6dd-26fb-4554-80e9-96201bb33fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-8a8bc76d-bcf2-44bc-8f26-fb0b64ca8d63,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-b361c1d7-5456-46e3-89ea-8e484cd6d916,DISK], DatanodeInfoWithStorage[127.0.0.1:42530,DS-42271b14-908b-4567-8369-726972df37cb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1783460916-172.17.0.2-1597417088655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33565,DS-e1e9b2c7-526e-4c62-8698-1f7718c29ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-7ee11c8a-f624-4f5b-b866-05ba689a90a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-390bbfcb-a880-4144-a451-56dbb8570477,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-7b7a2d81-e665-4cff-b72b-cad6392ca3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-16d9653b-afaf-458c-83ad-9bf974a60b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-95dcb736-27d8-4b81-a6ee-8d12bc309ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-86147329-02d9-498e-956c-09ab87db0691,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-7872b6b6-1c9f-4cad-adbf-9bfca271831c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1783460916-172.17.0.2-1597417088655:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33565,DS-e1e9b2c7-526e-4c62-8698-1f7718c29ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-7ee11c8a-f624-4f5b-b866-05ba689a90a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34372,DS-390bbfcb-a880-4144-a451-56dbb8570477,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-7b7a2d81-e665-4cff-b72b-cad6392ca3ff,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-16d9653b-afaf-458c-83ad-9bf974a60b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38993,DS-95dcb736-27d8-4b81-a6ee-8d12bc309ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-86147329-02d9-498e-956c-09ab87db0691,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-7872b6b6-1c9f-4cad-adbf-9bfca271831c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1581305830-172.17.0.2-1597417440504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42142,DS-7bbe5a69-0a6a-46fb-90b7-0ea6eef55bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-f6a4ae99-72c4-4072-aa03-406bf7aed217,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-84bc950a-e0ee-4828-86c8-b82f9083324b,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-1c8b3e97-51cf-4f46-93be-2a959f4a6e94,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-e76fbecb-96e1-42c4-af6f-bcf2595e0374,DISK], DatanodeInfoWithStorage[127.0.0.1:46082,DS-e14eb71c-d054-4ed3-b0ea-a6a11085b37a,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-5676273d-daef-4890-8563-cef22eb2fbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-22e0f1c3-1977-4d5e-a8e2-c293f101514d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1581305830-172.17.0.2-1597417440504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42142,DS-7bbe5a69-0a6a-46fb-90b7-0ea6eef55bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-f6a4ae99-72c4-4072-aa03-406bf7aed217,DISK], DatanodeInfoWithStorage[127.0.0.1:33477,DS-84bc950a-e0ee-4828-86c8-b82f9083324b,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-1c8b3e97-51cf-4f46-93be-2a959f4a6e94,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-e76fbecb-96e1-42c4-af6f-bcf2595e0374,DISK], DatanodeInfoWithStorage[127.0.0.1:46082,DS-e14eb71c-d054-4ed3-b0ea-a6a11085b37a,DISK], DatanodeInfoWithStorage[127.0.0.1:42055,DS-5676273d-daef-4890-8563-cef22eb2fbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-22e0f1c3-1977-4d5e-a8e2-c293f101514d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106148203-172.17.0.2-1597417490707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34960,DS-5e0b235e-6da9-48ab-8290-1fb8a6320a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-fbe90dbf-9448-4989-ac16-03b192cf3eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-43716251-c731-411b-bf4f-6f210003bae9,DISK], DatanodeInfoWithStorage[127.0.0.1:38584,DS-f1b5d47d-35d4-480a-8aef-3cde31f4acaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-e2e45fa4-9e5c-44c1-b047-65fd86efcb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-be747819-0391-4d70-94b1-1141e7bc31d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-8746b2ea-0fe9-4822-939a-d4ca6513b2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-8f3af2cd-2476-4dc5-8022-b08c0e73096f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106148203-172.17.0.2-1597417490707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34960,DS-5e0b235e-6da9-48ab-8290-1fb8a6320a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-fbe90dbf-9448-4989-ac16-03b192cf3eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41852,DS-43716251-c731-411b-bf4f-6f210003bae9,DISK], DatanodeInfoWithStorage[127.0.0.1:38584,DS-f1b5d47d-35d4-480a-8aef-3cde31f4acaf,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-e2e45fa4-9e5c-44c1-b047-65fd86efcb6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-be747819-0391-4d70-94b1-1141e7bc31d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-8746b2ea-0fe9-4822-939a-d4ca6513b2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-8f3af2cd-2476-4dc5-8022-b08c0e73096f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316558165-172.17.0.2-1597417797027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34694,DS-4c0b8016-2c35-4ed2-a3be-570d33a6adbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-2dacac5f-4292-4b03-8a22-bc6e47cf52e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-4d248ef3-8c09-47d2-ade5-7dc78c72234a,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-95e564a9-2828-43cb-9e4f-592e88fd074a,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-a7f5e7fe-3dc8-40de-b899-2f6cd506b490,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-bade0e73-3cb1-40f3-8090-9b1dc3dc380b,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-e8d30670-717b-4d73-8aaa-983b76f38cef,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-6a76e06c-d9f6-4077-9616-75ba93cf54f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316558165-172.17.0.2-1597417797027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34694,DS-4c0b8016-2c35-4ed2-a3be-570d33a6adbb,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-2dacac5f-4292-4b03-8a22-bc6e47cf52e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-4d248ef3-8c09-47d2-ade5-7dc78c72234a,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-95e564a9-2828-43cb-9e4f-592e88fd074a,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-a7f5e7fe-3dc8-40de-b899-2f6cd506b490,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-bade0e73-3cb1-40f3-8090-9b1dc3dc380b,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-e8d30670-717b-4d73-8aaa-983b76f38cef,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-6a76e06c-d9f6-4077-9616-75ba93cf54f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-51738621-172.17.0.2-1597418024972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36481,DS-a5d6070e-f5be-49b7-91f2-b5be2717b239,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-705aa8b1-1c73-4ed6-bad4-d0acf643056e,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-e2037770-0c34-4a19-9410-f95be42f8239,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-ebf20c16-7004-4657-8fbf-817d1efe5f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-b081ef8c-0aeb-4900-b293-90ddd2e13e63,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-298dcbd2-7230-40be-807a-f9fd41bd9d79,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-8e3e0921-8a85-4991-8d23-021bdd5b183d,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-af9ef7e0-81c0-4a3b-8e5a-48ccb16f11ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-51738621-172.17.0.2-1597418024972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36481,DS-a5d6070e-f5be-49b7-91f2-b5be2717b239,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-705aa8b1-1c73-4ed6-bad4-d0acf643056e,DISK], DatanodeInfoWithStorage[127.0.0.1:36378,DS-e2037770-0c34-4a19-9410-f95be42f8239,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-ebf20c16-7004-4657-8fbf-817d1efe5f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-b081ef8c-0aeb-4900-b293-90ddd2e13e63,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-298dcbd2-7230-40be-807a-f9fd41bd9d79,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-8e3e0921-8a85-4991-8d23-021bdd5b183d,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-af9ef7e0-81c0-4a3b-8e5a-48ccb16f11ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1521006236-172.17.0.2-1597418235966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46709,DS-6aba11ff-29b4-4ae8-bb6d-51b3245f9824,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-3630b80f-e222-48de-b318-1e819c81a5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-0df3f51c-4084-4856-8d0c-653fe8f24db2,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-ea138870-a00c-4111-beb6-d09a88aaa1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-bd35c2f0-f3b2-44b8-9379-46d2afbb6275,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-8dd4bc48-a4ca-4791-955c-18372fab9491,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-a01838e5-75d1-4b6b-8b0f-99364b19d6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-fd0d7f3c-8f28-4bca-bd6b-e5e13249643a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1521006236-172.17.0.2-1597418235966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46709,DS-6aba11ff-29b4-4ae8-bb6d-51b3245f9824,DISK], DatanodeInfoWithStorage[127.0.0.1:40239,DS-3630b80f-e222-48de-b318-1e819c81a5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-0df3f51c-4084-4856-8d0c-653fe8f24db2,DISK], DatanodeInfoWithStorage[127.0.0.1:34344,DS-ea138870-a00c-4111-beb6-d09a88aaa1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-bd35c2f0-f3b2-44b8-9379-46d2afbb6275,DISK], DatanodeInfoWithStorage[127.0.0.1:35843,DS-8dd4bc48-a4ca-4791-955c-18372fab9491,DISK], DatanodeInfoWithStorage[127.0.0.1:46272,DS-a01838e5-75d1-4b6b-8b0f-99364b19d6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34569,DS-fd0d7f3c-8f28-4bca-bd6b-e5e13249643a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210415760-172.17.0.2-1597418382120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37789,DS-3c809bf0-46a5-40d7-b7a8-f44af623634c,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-62741382-f553-4188-8bce-84526dc3b720,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-9f32162a-8c70-4642-b6e6-37487dc97d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-028417c4-49a6-4bb3-9b32-c7d3d14c5ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-ce965283-a21c-461f-a763-bc9c0c278387,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-f5028f5b-dd11-480d-95e0-c349216e5a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-312139d0-a4d3-429c-8261-9811e3a1298f,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-24de44a3-9a60-4d4b-bb73-058b4dcd86ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210415760-172.17.0.2-1597418382120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37789,DS-3c809bf0-46a5-40d7-b7a8-f44af623634c,DISK], DatanodeInfoWithStorage[127.0.0.1:38991,DS-62741382-f553-4188-8bce-84526dc3b720,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-9f32162a-8c70-4642-b6e6-37487dc97d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-028417c4-49a6-4bb3-9b32-c7d3d14c5ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-ce965283-a21c-461f-a763-bc9c0c278387,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-f5028f5b-dd11-480d-95e0-c349216e5a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-312139d0-a4d3-429c-8261-9811e3a1298f,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-24de44a3-9a60-4d4b-bb73-058b4dcd86ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1468268578-172.17.0.2-1597418658226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37830,DS-75c0ab0a-6867-4865-96fa-7087cef379c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-27bbe4fd-ff60-4844-85ca-b7dd448357bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-f1cbee70-3c86-402c-ac6c-b28ea38e671f,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-a233b823-3183-40e4-a2a3-36c15b13903a,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-7e449141-05c6-45f2-bb42-ee1f16867a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-6beffc32-56a7-440f-bc6c-90689d9d926f,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-fc4b18cb-a205-49db-87d5-3ba083590d11,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-85b9320d-e03a-461c-aeb1-4a819a9e3438,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1468268578-172.17.0.2-1597418658226:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37830,DS-75c0ab0a-6867-4865-96fa-7087cef379c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33946,DS-27bbe4fd-ff60-4844-85ca-b7dd448357bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-f1cbee70-3c86-402c-ac6c-b28ea38e671f,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-a233b823-3183-40e4-a2a3-36c15b13903a,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-7e449141-05c6-45f2-bb42-ee1f16867a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-6beffc32-56a7-440f-bc6c-90689d9d926f,DISK], DatanodeInfoWithStorage[127.0.0.1:37619,DS-fc4b18cb-a205-49db-87d5-3ba083590d11,DISK], DatanodeInfoWithStorage[127.0.0.1:44343,DS-85b9320d-e03a-461c-aeb1-4a819a9e3438,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-186859548-172.17.0.2-1597418745308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45652,DS-030aaab6-6a3a-47ff-af66-4e7796c4032c,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-c7b6720f-5e8d-4edf-858f-508af01f4fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-15db5603-1ce6-4097-befc-662368986c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-a9bb2c8d-1e95-4aad-9a4d-fb9a9b375abc,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-056454d6-d82c-408c-9b1f-997d06bd5b00,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-823b394f-bc35-41c5-9b14-12fa05da170f,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-0e158774-2a5e-4e71-8177-3fd46fad3c12,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-076299ad-c6aa-4130-a300-951e4939f349,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-186859548-172.17.0.2-1597418745308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45652,DS-030aaab6-6a3a-47ff-af66-4e7796c4032c,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-c7b6720f-5e8d-4edf-858f-508af01f4fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-15db5603-1ce6-4097-befc-662368986c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-a9bb2c8d-1e95-4aad-9a4d-fb9a9b375abc,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-056454d6-d82c-408c-9b1f-997d06bd5b00,DISK], DatanodeInfoWithStorage[127.0.0.1:44958,DS-823b394f-bc35-41c5-9b14-12fa05da170f,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-0e158774-2a5e-4e71-8177-3fd46fad3c12,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-076299ad-c6aa-4130-a300-951e4939f349,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.readahead.bytes
component: hdfs:DataNode
v1: 512
v2: 4194304
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629996846-172.17.0.2-1597418827983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42979,DS-219b1b27-c60d-41df-b5b0-4f5983c7d875,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-d70b3f62-91e6-4f34-965d-16387738465e,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-f7b21baf-855c-4c4d-a9f7-f03d08738442,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-69833037-fde3-45de-9cb0-aec33f8bd459,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-24c82e02-f5b9-4b58-bb82-de39492df791,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-362a1719-4a7a-4499-bb30-8b23770a3477,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-55b1fa89-93cc-48fa-8e7f-7d8edc91b0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-2d296dbb-3750-4774-b2d7-090782e4a210,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629996846-172.17.0.2-1597418827983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42979,DS-219b1b27-c60d-41df-b5b0-4f5983c7d875,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-d70b3f62-91e6-4f34-965d-16387738465e,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-f7b21baf-855c-4c4d-a9f7-f03d08738442,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-69833037-fde3-45de-9cb0-aec33f8bd459,DISK], DatanodeInfoWithStorage[127.0.0.1:37975,DS-24c82e02-f5b9-4b58-bb82-de39492df791,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-362a1719-4a7a-4499-bb30-8b23770a3477,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-55b1fa89-93cc-48fa-8e7f-7d8edc91b0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-2d296dbb-3750-4774-b2d7-090782e4a210,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 25 out of 50
result: false positive !!!
Total execution time in seconds : 6867
