reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-304846010-172.17.0.3-1597283920541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34818,DS-858aec97-359d-4a32-8447-b85e374ff009,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-bb45c9f7-5d3a-489f-90f0-5b027487fdaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-aeb477cb-056d-455b-be6f-cd33c3830f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-8e113c0e-c6e3-4e4e-b6dc-7aa35f059a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-cd280a29-067c-4cad-9d8c-a1c7af066313,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-7a8e1b96-28f1-49f8-89ef-c25a50b79eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-bc50b7be-03aa-45bb-8efd-171ede482379,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-1cdee3d5-53e4-4979-9d42-d920844164b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-304846010-172.17.0.3-1597283920541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34818,DS-858aec97-359d-4a32-8447-b85e374ff009,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-bb45c9f7-5d3a-489f-90f0-5b027487fdaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-aeb477cb-056d-455b-be6f-cd33c3830f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-8e113c0e-c6e3-4e4e-b6dc-7aa35f059a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-cd280a29-067c-4cad-9d8c-a1c7af066313,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-7a8e1b96-28f1-49f8-89ef-c25a50b79eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-bc50b7be-03aa-45bb-8efd-171ede482379,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-1cdee3d5-53e4-4979-9d42-d920844164b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2138665043-172.17.0.3-1597284264186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39799,DS-01a06dc6-4064-4ffa-a9ea-b16bfc933964,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-308faa10-9db4-48be-bd6b-2ecba8804743,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-e9e427b5-9a79-441f-8a66-289c8e3c2cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-3abffa0b-d2f5-4c9e-aee7-54df371c98bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-07125624-0b55-49ea-be9e-54816ec870df,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-dd42db9c-7824-4dd6-9651-2c961a86f323,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-18125522-ae24-4283-afd7-6b18ce92c363,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-19a8f530-0f41-40d2-a2be-5fe8d458eb8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2138665043-172.17.0.3-1597284264186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39799,DS-01a06dc6-4064-4ffa-a9ea-b16bfc933964,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-308faa10-9db4-48be-bd6b-2ecba8804743,DISK], DatanodeInfoWithStorage[127.0.0.1:38567,DS-e9e427b5-9a79-441f-8a66-289c8e3c2cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-3abffa0b-d2f5-4c9e-aee7-54df371c98bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-07125624-0b55-49ea-be9e-54816ec870df,DISK], DatanodeInfoWithStorage[127.0.0.1:36789,DS-dd42db9c-7824-4dd6-9651-2c961a86f323,DISK], DatanodeInfoWithStorage[127.0.0.1:37683,DS-18125522-ae24-4283-afd7-6b18ce92c363,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-19a8f530-0f41-40d2-a2be-5fe8d458eb8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123620037-172.17.0.3-1597284557427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38136,DS-54549ed3-0284-4530-80f2-190b027110de,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-f244c3a0-f3e5-4331-a9b0-02123b594b28,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-9c1a8453-dc23-49c9-9202-9ba69f8c2ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-f1c00712-7b05-42ba-8998-cf849d731321,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-82f64639-6e06-4dec-8993-6ebe8a290d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-0a01aeb1-27fd-42c1-aeed-43fefc852818,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-37510fee-14df-420b-a23b-880eb133488a,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-0daa6858-ae8e-4497-a59f-157d8ac5395a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-123620037-172.17.0.3-1597284557427:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38136,DS-54549ed3-0284-4530-80f2-190b027110de,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-f244c3a0-f3e5-4331-a9b0-02123b594b28,DISK], DatanodeInfoWithStorage[127.0.0.1:40340,DS-9c1a8453-dc23-49c9-9202-9ba69f8c2ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-f1c00712-7b05-42ba-8998-cf849d731321,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-82f64639-6e06-4dec-8993-6ebe8a290d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-0a01aeb1-27fd-42c1-aeed-43fefc852818,DISK], DatanodeInfoWithStorage[127.0.0.1:46293,DS-37510fee-14df-420b-a23b-880eb133488a,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-0daa6858-ae8e-4497-a59f-157d8ac5395a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-977907422-172.17.0.3-1597284942123:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45503,DS-520f0e32-59e7-4370-8bb4-ba4f298e7643,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-f2969b56-f98d-4c32-9b1e-50c0ae87713b,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-c71fd796-b038-4720-98d3-7024e5b03368,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-c74895d5-ed9d-4954-a8c4-f26e8cd369b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-beebb17f-f686-44a3-aa2b-9318a99eaae5,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-cd055ad9-a786-48f9-8a35-89fa46d32f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-616c7e28-ff1f-4091-908c-1a2c278fadc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-76cdb6f0-f9d5-447b-891a-ff1af3cc342b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-977907422-172.17.0.3-1597284942123:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45503,DS-520f0e32-59e7-4370-8bb4-ba4f298e7643,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-f2969b56-f98d-4c32-9b1e-50c0ae87713b,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-c71fd796-b038-4720-98d3-7024e5b03368,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-c74895d5-ed9d-4954-a8c4-f26e8cd369b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44898,DS-beebb17f-f686-44a3-aa2b-9318a99eaae5,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-cd055ad9-a786-48f9-8a35-89fa46d32f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38020,DS-616c7e28-ff1f-4091-908c-1a2c278fadc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33138,DS-76cdb6f0-f9d5-447b-891a-ff1af3cc342b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214955820-172.17.0.3-1597285047400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36200,DS-4af006fc-beee-4af5-bd98-de3d7afce05a,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-134e8cc0-5c16-458f-9606-c4e12d181266,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-1da343f0-64ae-4512-b3df-08a6e2b2a7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-fe1de4de-40fa-40ee-ad7c-6d8f0a977f45,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-5d237fb1-c80c-4065-ac8c-de83c6eb7f52,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-6e3830b1-488b-4a2c-a6df-c09669f8e8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-affef3a2-4a3f-4e86-bb5e-385be0aeeadf,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-1c05deee-f969-453f-9c7c-9de1d264b5ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214955820-172.17.0.3-1597285047400:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36200,DS-4af006fc-beee-4af5-bd98-de3d7afce05a,DISK], DatanodeInfoWithStorage[127.0.0.1:36201,DS-134e8cc0-5c16-458f-9606-c4e12d181266,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-1da343f0-64ae-4512-b3df-08a6e2b2a7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-fe1de4de-40fa-40ee-ad7c-6d8f0a977f45,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-5d237fb1-c80c-4065-ac8c-de83c6eb7f52,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-6e3830b1-488b-4a2c-a6df-c09669f8e8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-affef3a2-4a3f-4e86-bb5e-385be0aeeadf,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-1c05deee-f969-453f-9c7c-9de1d264b5ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1989044186-172.17.0.3-1597285195731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35503,DS-812e68e4-b382-4952-abc6-e6a9cf9b5e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-180817b7-b2df-4e1b-b7b3-7d1ab1c49f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-eacea9c9-f9d8-48db-9cc4-f2f1286bfa92,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-c20be7a1-6811-4c26-9426-6c6a31b0a0be,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-ff1924b0-e3d6-4154-b709-0b3c7bd93817,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-eaa6b389-7573-4b63-b8b9-5ef48da1af0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-df4d6dac-40ac-4264-a2bb-646770e41741,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-7dd86cce-d82a-47f4-bf3e-e400e77fb3ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1989044186-172.17.0.3-1597285195731:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35503,DS-812e68e4-b382-4952-abc6-e6a9cf9b5e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-180817b7-b2df-4e1b-b7b3-7d1ab1c49f4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-eacea9c9-f9d8-48db-9cc4-f2f1286bfa92,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-c20be7a1-6811-4c26-9426-6c6a31b0a0be,DISK], DatanodeInfoWithStorage[127.0.0.1:36776,DS-ff1924b0-e3d6-4154-b709-0b3c7bd93817,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-eaa6b389-7573-4b63-b8b9-5ef48da1af0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43468,DS-df4d6dac-40ac-4264-a2bb-646770e41741,DISK], DatanodeInfoWithStorage[127.0.0.1:32897,DS-7dd86cce-d82a-47f4-bf3e-e400e77fb3ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299579367-172.17.0.3-1597285299668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40947,DS-2c618f22-54c0-487a-9da6-64dfb8f7dd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-602bcb80-6436-418a-909b-799cf2531f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-486eb53f-3000-4fed-9169-aa87b7cc8770,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-07555133-27d4-4acd-a0dd-42c2092b8318,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-c1854cfb-7545-42a8-adf8-e27e8a50d21d,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-2bad4405-d5bf-491b-8d53-1f32fa906777,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-8f8ed743-8ca4-43cf-9481-f96265a10d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-da76e7ff-20ff-48d9-9dcb-d6bbefa3f0e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299579367-172.17.0.3-1597285299668:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40947,DS-2c618f22-54c0-487a-9da6-64dfb8f7dd7e,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-602bcb80-6436-418a-909b-799cf2531f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-486eb53f-3000-4fed-9169-aa87b7cc8770,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-07555133-27d4-4acd-a0dd-42c2092b8318,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-c1854cfb-7545-42a8-adf8-e27e8a50d21d,DISK], DatanodeInfoWithStorage[127.0.0.1:36913,DS-2bad4405-d5bf-491b-8d53-1f32fa906777,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-8f8ed743-8ca4-43cf-9481-f96265a10d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:46387,DS-da76e7ff-20ff-48d9-9dcb-d6bbefa3f0e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1574725420-172.17.0.3-1597285840077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38222,DS-d880b081-7f5d-4403-a066-1f88208c8e33,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-13cd0209-05b6-4fba-9db3-ec36ed7933d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-c1ec66a2-4ce6-41d6-b934-00a6d1e6737d,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-b4725247-5494-49d6-a08b-5506940776a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-5e3373fd-7543-45de-a885-1419a48f138a,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-feff0bf8-bf34-46f7-a845-6d8973b268cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-f0c62093-8a9e-411d-860e-214968e1d458,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-6b60b733-3ec8-42b7-a8dd-9cdd8206e1cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1574725420-172.17.0.3-1597285840077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38222,DS-d880b081-7f5d-4403-a066-1f88208c8e33,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-13cd0209-05b6-4fba-9db3-ec36ed7933d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-c1ec66a2-4ce6-41d6-b934-00a6d1e6737d,DISK], DatanodeInfoWithStorage[127.0.0.1:41829,DS-b4725247-5494-49d6-a08b-5506940776a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-5e3373fd-7543-45de-a885-1419a48f138a,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-feff0bf8-bf34-46f7-a845-6d8973b268cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-f0c62093-8a9e-411d-860e-214968e1d458,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-6b60b733-3ec8-42b7-a8dd-9cdd8206e1cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-180550113-172.17.0.3-1597285993771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40450,DS-d47e79ac-cc02-4d44-962e-2469ab48dc14,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-3553cf8b-179a-4692-99e7-37914932f6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-592f64a2-bd0e-475e-90d1-ceb8baf90066,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-c29a0fc4-afda-4efc-92b9-96510920d9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-d7117666-135d-4026-a955-1b7e57051a61,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-0555341c-8ece-440e-9aa8-e8336a5beb92,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-298d79cd-bf2f-459c-ad17-270e33fc1d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-5e30e9f4-4942-44f6-9930-f356c247023e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-180550113-172.17.0.3-1597285993771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40450,DS-d47e79ac-cc02-4d44-962e-2469ab48dc14,DISK], DatanodeInfoWithStorage[127.0.0.1:32891,DS-3553cf8b-179a-4692-99e7-37914932f6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-592f64a2-bd0e-475e-90d1-ceb8baf90066,DISK], DatanodeInfoWithStorage[127.0.0.1:33162,DS-c29a0fc4-afda-4efc-92b9-96510920d9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-d7117666-135d-4026-a955-1b7e57051a61,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-0555341c-8ece-440e-9aa8-e8336a5beb92,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-298d79cd-bf2f-459c-ad17-270e33fc1d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-5e30e9f4-4942-44f6-9930-f356c247023e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-336073986-172.17.0.3-1597287395170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43024,DS-771c63a3-cc22-4014-9931-f316b7811740,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-af5a60ac-a6af-4abd-b31c-5ee286d1f8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-443a9249-59b5-42af-b22b-e27e3f29e7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-4901b04f-6b40-43a2-b50d-72a3ebce24ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-71bf0c8e-5dc4-4d90-ae05-22eb7755ff33,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-fc979c80-711d-4749-a3ec-b90634e5ef4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-d37318ef-ee97-47ad-8d0c-ab1fa8fc77da,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-bad92e03-ebc3-4377-b7db-94d2d07acd1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-336073986-172.17.0.3-1597287395170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43024,DS-771c63a3-cc22-4014-9931-f316b7811740,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-af5a60ac-a6af-4abd-b31c-5ee286d1f8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-443a9249-59b5-42af-b22b-e27e3f29e7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-4901b04f-6b40-43a2-b50d-72a3ebce24ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33780,DS-71bf0c8e-5dc4-4d90-ae05-22eb7755ff33,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-fc979c80-711d-4749-a3ec-b90634e5ef4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-d37318ef-ee97-47ad-8d0c-ab1fa8fc77da,DISK], DatanodeInfoWithStorage[127.0.0.1:44922,DS-bad92e03-ebc3-4377-b7db-94d2d07acd1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832072058-172.17.0.3-1597288489411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36911,DS-ff17e53a-0dc2-45ed-9ff9-42068e823da3,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-731ae735-822a-4e45-8399-be5ea6c3b014,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-5542a99c-3e19-4204-9d45-a166aa9bf314,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-03f60f8e-e1a2-4f40-b9b1-21532ecdccf5,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-b530ce92-12cf-4dd3-9be4-c69c99bbd0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-5da071bb-04a7-4e34-b11a-4fcb3943eefa,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-f9ee7a31-8c16-4255-ad38-bd1ceceae0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-a6a91dad-a434-46d4-893f-b0aff40d0ba0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832072058-172.17.0.3-1597288489411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36911,DS-ff17e53a-0dc2-45ed-9ff9-42068e823da3,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-731ae735-822a-4e45-8399-be5ea6c3b014,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-5542a99c-3e19-4204-9d45-a166aa9bf314,DISK], DatanodeInfoWithStorage[127.0.0.1:46231,DS-03f60f8e-e1a2-4f40-b9b1-21532ecdccf5,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-b530ce92-12cf-4dd3-9be4-c69c99bbd0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:41509,DS-5da071bb-04a7-4e34-b11a-4fcb3943eefa,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-f9ee7a31-8c16-4255-ad38-bd1ceceae0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39277,DS-a6a91dad-a434-46d4-893f-b0aff40d0ba0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 1073741824
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152233598-172.17.0.3-1597288843629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46571,DS-0a3a3092-8565-4826-a395-a88427a08656,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-c44e7907-54a1-4f0e-9a55-5a624ab55017,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-ff37fcde-8fe3-4dc7-aba8-04abe9fea223,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-f6a0a019-8f3f-48ed-9698-81da5ad36c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-2dfd310d-97c9-4b0d-88e3-c0a23170cdff,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-829f64ce-f144-4a04-bdbd-bc865cb01b75,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-25e076ed-b419-4b85-a10c-2db6c9391d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-2f4ead53-8388-4185-a87e-749a604ec391,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1152233598-172.17.0.3-1597288843629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46571,DS-0a3a3092-8565-4826-a395-a88427a08656,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-c44e7907-54a1-4f0e-9a55-5a624ab55017,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-ff37fcde-8fe3-4dc7-aba8-04abe9fea223,DISK], DatanodeInfoWithStorage[127.0.0.1:45314,DS-f6a0a019-8f3f-48ed-9698-81da5ad36c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44320,DS-2dfd310d-97c9-4b0d-88e3-c0a23170cdff,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-829f64ce-f144-4a04-bdbd-bc865cb01b75,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-25e076ed-b419-4b85-a10c-2db6c9391d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-2f4ead53-8388-4185-a87e-749a604ec391,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5656
