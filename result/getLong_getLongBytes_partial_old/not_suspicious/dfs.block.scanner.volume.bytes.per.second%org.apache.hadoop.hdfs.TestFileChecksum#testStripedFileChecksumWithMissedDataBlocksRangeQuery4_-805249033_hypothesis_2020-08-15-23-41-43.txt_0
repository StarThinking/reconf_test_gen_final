reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-826725678-172.17.0.15-1597535366013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37543,DS-c1da8976-89ed-4342-8299-d08ad4bc5dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-452d1178-7547-49c7-a47f-e6205f12f3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-822cd0f1-a494-48f6-a0ed-80a177b9f281,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-881e10c3-aaf0-4f0c-855f-f13860056698,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-b04425ce-d4cf-4f92-a881-825848d9b155,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-7a66233c-afac-4409-97c6-bc5d933ebf81,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-a397a8f8-5a61-4f87-882a-32d5f1257d55,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-71798ed8-b285-47a6-aeb9-8f0b0514905a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-826725678-172.17.0.15-1597535366013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37543,DS-c1da8976-89ed-4342-8299-d08ad4bc5dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-452d1178-7547-49c7-a47f-e6205f12f3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-822cd0f1-a494-48f6-a0ed-80a177b9f281,DISK], DatanodeInfoWithStorage[127.0.0.1:39403,DS-881e10c3-aaf0-4f0c-855f-f13860056698,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-b04425ce-d4cf-4f92-a881-825848d9b155,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-7a66233c-afac-4409-97c6-bc5d933ebf81,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-a397a8f8-5a61-4f87-882a-32d5f1257d55,DISK], DatanodeInfoWithStorage[127.0.0.1:38643,DS-71798ed8-b285-47a6-aeb9-8f0b0514905a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-433512073-172.17.0.15-1597535559908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45263,DS-85227cea-5e6b-4ad9-bdc0-5f3581f91bff,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-0e8ad652-e046-4b90-a6d8-75a76903944d,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-1a307dea-1507-4024-a0d8-157f1d2c0236,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-9cba6c01-5218-465b-9bb4-9f578e450928,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-97bef4aa-9d8c-4c79-a2fb-3d648d9e8ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-4a13bce2-cae8-46d5-8b83-a42154939996,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-4f30a1f5-27d1-4d23-9c43-86385f998bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-912c27f7-9bdc-4536-9e9e-2411a33e76c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-433512073-172.17.0.15-1597535559908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45263,DS-85227cea-5e6b-4ad9-bdc0-5f3581f91bff,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-0e8ad652-e046-4b90-a6d8-75a76903944d,DISK], DatanodeInfoWithStorage[127.0.0.1:33038,DS-1a307dea-1507-4024-a0d8-157f1d2c0236,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-9cba6c01-5218-465b-9bb4-9f578e450928,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-97bef4aa-9d8c-4c79-a2fb-3d648d9e8ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-4a13bce2-cae8-46d5-8b83-a42154939996,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-4f30a1f5-27d1-4d23-9c43-86385f998bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35640,DS-912c27f7-9bdc-4536-9e9e-2411a33e76c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1447000491-172.17.0.15-1597535894233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36956,DS-b7e36a9c-80cc-4cc9-8270-5ce77e3ab6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-ef21ab44-a091-4dfe-8fbf-8ab8f17893c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33831,DS-d429bdf4-2da6-44a7-afb8-65ee54716ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-232db555-48ea-4158-a458-d7cb1fdab43f,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-7eeb80d8-ffdc-430d-9564-1e101f42eb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-3456aeb1-5e6f-4f72-8c45-da7ee8755fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-6f3ae046-338f-43a0-b8a2-ce38c2de1d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-a7fe4723-0505-4fad-b298-569d5d15931f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1447000491-172.17.0.15-1597535894233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36956,DS-b7e36a9c-80cc-4cc9-8270-5ce77e3ab6f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-ef21ab44-a091-4dfe-8fbf-8ab8f17893c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33831,DS-d429bdf4-2da6-44a7-afb8-65ee54716ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-232db555-48ea-4158-a458-d7cb1fdab43f,DISK], DatanodeInfoWithStorage[127.0.0.1:36482,DS-7eeb80d8-ffdc-430d-9564-1e101f42eb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-3456aeb1-5e6f-4f72-8c45-da7ee8755fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-6f3ae046-338f-43a0-b8a2-ce38c2de1d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45681,DS-a7fe4723-0505-4fad-b298-569d5d15931f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-260651847-172.17.0.15-1597536228451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37224,DS-12864d41-325e-4e1f-acf5-160a27079058,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-ceb18a8b-0b09-481c-a0e0-8b865de42726,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-c53157cf-ae6b-43b1-9509-63d704735bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-b880c111-8af3-4d60-b9a1-eba2fe85e0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-7210fe3a-e66e-4e59-abec-414def81a9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-437ac424-71f3-46ba-bf11-47fe3578effb,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-6cc8febd-463a-4371-9ca5-3ec8ce0d2a91,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-59d844c6-1ff7-4376-b2be-5ce058055c4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-260651847-172.17.0.15-1597536228451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37224,DS-12864d41-325e-4e1f-acf5-160a27079058,DISK], DatanodeInfoWithStorage[127.0.0.1:44193,DS-ceb18a8b-0b09-481c-a0e0-8b865de42726,DISK], DatanodeInfoWithStorage[127.0.0.1:44490,DS-c53157cf-ae6b-43b1-9509-63d704735bdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-b880c111-8af3-4d60-b9a1-eba2fe85e0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37947,DS-7210fe3a-e66e-4e59-abec-414def81a9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36588,DS-437ac424-71f3-46ba-bf11-47fe3578effb,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-6cc8febd-463a-4371-9ca5-3ec8ce0d2a91,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-59d844c6-1ff7-4376-b2be-5ce058055c4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896013310-172.17.0.15-1597537171725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39068,DS-ec72ec01-394c-407d-8365-06f5c9e2c69b,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-2cd95f3e-07f3-418a-af6a-1e0b4637479b,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-d5c9a43e-5ad0-4b7c-99e3-f392685a0da7,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-4859480b-008a-4167-b26d-702d282b6f01,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-b23db7c6-7fdf-4b7b-99e4-e70dbc524c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-dde7222f-aa75-4783-8b4a-c0972cde3b14,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-48c109f6-7fb4-47da-ad81-ac35605cb134,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-bf6ab8e2-bf53-4773-8a25-9183c5ceca7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896013310-172.17.0.15-1597537171725:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39068,DS-ec72ec01-394c-407d-8365-06f5c9e2c69b,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-2cd95f3e-07f3-418a-af6a-1e0b4637479b,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-d5c9a43e-5ad0-4b7c-99e3-f392685a0da7,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-4859480b-008a-4167-b26d-702d282b6f01,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-b23db7c6-7fdf-4b7b-99e4-e70dbc524c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-dde7222f-aa75-4783-8b4a-c0972cde3b14,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-48c109f6-7fb4-47da-ad81-ac35605cb134,DISK], DatanodeInfoWithStorage[127.0.0.1:42613,DS-bf6ab8e2-bf53-4773-8a25-9183c5ceca7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1368456116-172.17.0.15-1597537391515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38917,DS-aa0916df-9be3-4f0a-a217-33c659df7a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-1e48dc9d-13f4-4269-a9fc-f49b3058a11b,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-bad4c3b8-dc86-402a-88dc-9932295b9ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-0e4ae191-fe08-4242-8d58-1593e6d7a3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-90b9bf44-b7ef-4ee0-a194-f7437d89b98c,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-f1eac67f-cbb7-49ca-8708-4e3687cd4fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-a9bbe48c-5d06-430e-967c-117bfa9ed375,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-1fc1d5dd-a811-421c-94b7-9c806159a0a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1368456116-172.17.0.15-1597537391515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38917,DS-aa0916df-9be3-4f0a-a217-33c659df7a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46876,DS-1e48dc9d-13f4-4269-a9fc-f49b3058a11b,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-bad4c3b8-dc86-402a-88dc-9932295b9ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-0e4ae191-fe08-4242-8d58-1593e6d7a3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44463,DS-90b9bf44-b7ef-4ee0-a194-f7437d89b98c,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-f1eac67f-cbb7-49ca-8708-4e3687cd4fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-a9bbe48c-5d06-430e-967c-117bfa9ed375,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-1fc1d5dd-a811-421c-94b7-9c806159a0a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1837819197-172.17.0.15-1597537537576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42740,DS-422176e5-dc1e-4581-ad3a-8452c8ca12f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-c0822d88-b695-42fe-aa3c-61bff223e78f,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-7a6352ad-9074-4f58-8ed8-3d14f61045c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-bc0f644a-2a38-4ea6-9514-522bcaaf9d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-fa98def6-da99-424e-b558-40eaf49e0f05,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-0dcb7f6d-8b25-4424-bef4-ca957e4c36da,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-3270b5c9-ef70-4e84-9f58-1cc61ec47966,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-d407ce9b-8a54-4c36-b837-20dc1733a3c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1837819197-172.17.0.15-1597537537576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42740,DS-422176e5-dc1e-4581-ad3a-8452c8ca12f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45033,DS-c0822d88-b695-42fe-aa3c-61bff223e78f,DISK], DatanodeInfoWithStorage[127.0.0.1:44012,DS-7a6352ad-9074-4f58-8ed8-3d14f61045c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-bc0f644a-2a38-4ea6-9514-522bcaaf9d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-fa98def6-da99-424e-b558-40eaf49e0f05,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-0dcb7f6d-8b25-4424-bef4-ca957e4c36da,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-3270b5c9-ef70-4e84-9f58-1cc61ec47966,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-d407ce9b-8a54-4c36-b837-20dc1733a3c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1615658092-172.17.0.15-1597538191999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42298,DS-cac97c0b-5fca-4e49-881c-0b0e5fb1819b,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-ac338ab7-aa2b-4e00-8d31-ad0bdeb4ddf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-bb9b6685-9dab-428f-b722-074697bfddad,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-04e5acdb-adce-4ba2-8533-722493d118b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-a07e96ab-81a6-43b2-aa2b-c638c04370ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-d06ed3a9-fe2c-490b-bf4f-ae1b6f1f30f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-bce23cfc-0247-48bd-8122-946b617f4184,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-874789be-9773-42dc-ab61-9f00917f087b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1615658092-172.17.0.15-1597538191999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42298,DS-cac97c0b-5fca-4e49-881c-0b0e5fb1819b,DISK], DatanodeInfoWithStorage[127.0.0.1:42132,DS-ac338ab7-aa2b-4e00-8d31-ad0bdeb4ddf6,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-bb9b6685-9dab-428f-b722-074697bfddad,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-04e5acdb-adce-4ba2-8533-722493d118b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38612,DS-a07e96ab-81a6-43b2-aa2b-c638c04370ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-d06ed3a9-fe2c-490b-bf4f-ae1b6f1f30f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34835,DS-bce23cfc-0247-48bd-8122-946b617f4184,DISK], DatanodeInfoWithStorage[127.0.0.1:36246,DS-874789be-9773-42dc-ab61-9f00917f087b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1908087202-172.17.0.15-1597538235292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38552,DS-c9867813-c9ac-45b7-bb28-fd4570dabe11,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-0fbd72d0-bf8c-4333-ba12-db0a294b2253,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-cc22a319-05e2-4570-b840-06cddbb4b199,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-28628d8e-ae04-47d1-a11a-3b419301db48,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-3ec01431-ddfb-4a39-a437-ca9b59702bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-22337673-a879-4747-a502-9c77462374fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-f7422539-9672-4ff1-8511-5a8e4cf21f20,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-82e10c56-9c0e-428e-90f5-62b906cf8748,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1908087202-172.17.0.15-1597538235292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38552,DS-c9867813-c9ac-45b7-bb28-fd4570dabe11,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-0fbd72d0-bf8c-4333-ba12-db0a294b2253,DISK], DatanodeInfoWithStorage[127.0.0.1:34551,DS-cc22a319-05e2-4570-b840-06cddbb4b199,DISK], DatanodeInfoWithStorage[127.0.0.1:33944,DS-28628d8e-ae04-47d1-a11a-3b419301db48,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-3ec01431-ddfb-4a39-a437-ca9b59702bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-22337673-a879-4747-a502-9c77462374fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-f7422539-9672-4ff1-8511-5a8e4cf21f20,DISK], DatanodeInfoWithStorage[127.0.0.1:45179,DS-82e10c56-9c0e-428e-90f5-62b906cf8748,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-511359932-172.17.0.15-1597538394621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43245,DS-7d7b60f1-bc74-465a-ac62-bbf5d558fad4,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-20192147-49aa-48d4-8ded-491da0b8fb70,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-eb78775b-3711-4986-a0fa-b3959fa711a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-315e4ea8-9129-4c80-9633-6b8644332f40,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-2373866e-ae45-43a3-a24a-374ade84596b,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-fceb0cac-ae8e-4c2e-858c-277f356c1e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-6bf4a26d-20b3-450e-a0b5-46a27f66aa2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-592d042e-a6c0-431b-baa5-eaf62ad16380,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-511359932-172.17.0.15-1597538394621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43245,DS-7d7b60f1-bc74-465a-ac62-bbf5d558fad4,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-20192147-49aa-48d4-8ded-491da0b8fb70,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-eb78775b-3711-4986-a0fa-b3959fa711a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-315e4ea8-9129-4c80-9633-6b8644332f40,DISK], DatanodeInfoWithStorage[127.0.0.1:37142,DS-2373866e-ae45-43a3-a24a-374ade84596b,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-fceb0cac-ae8e-4c2e-858c-277f356c1e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-6bf4a26d-20b3-450e-a0b5-46a27f66aa2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-592d042e-a6c0-431b-baa5-eaf62ad16380,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1476484633-172.17.0.15-1597538589968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45381,DS-c420bed4-e8ee-403e-a7fc-b38f1c887e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-e9a8114f-dd6a-47ad-a22e-2f8c5b6357db,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-288c470c-777e-4ce0-8438-f1bb046de373,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-10ed0a17-79d0-41b7-b4a1-38a73f10f729,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-3d5c3c27-8941-4408-bb38-90d062507fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-ffef1369-916a-46bb-9546-88012d2de80d,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-6576a974-95dc-41d7-8a60-3e6c4140b44e,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-edcc9089-2605-467b-92bc-470786bfac73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1476484633-172.17.0.15-1597538589968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45381,DS-c420bed4-e8ee-403e-a7fc-b38f1c887e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-e9a8114f-dd6a-47ad-a22e-2f8c5b6357db,DISK], DatanodeInfoWithStorage[127.0.0.1:34333,DS-288c470c-777e-4ce0-8438-f1bb046de373,DISK], DatanodeInfoWithStorage[127.0.0.1:35605,DS-10ed0a17-79d0-41b7-b4a1-38a73f10f729,DISK], DatanodeInfoWithStorage[127.0.0.1:37453,DS-3d5c3c27-8941-4408-bb38-90d062507fe5,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-ffef1369-916a-46bb-9546-88012d2de80d,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-6576a974-95dc-41d7-8a60-3e6c4140b44e,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-edcc9089-2605-467b-92bc-470786bfac73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39933612-172.17.0.15-1597538988582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43437,DS-750277c9-ff5c-4b04-b789-3122c8d8df3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-e4700541-a509-40ae-9ee3-52a55882b6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-0931ef48-44a4-4111-9eb9-faee1f293491,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-e3c1aecf-75d0-4c19-8bb0-67fb067aada5,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-b8c94dc7-baf5-4250-b071-ec160cee22fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-834c22b1-add7-42d4-9ba5-39e85c7f1e33,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-45e7ccc0-cf5e-452c-a447-061dae59e070,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-3194e8b2-7979-4250-a4ea-11e6e8a0608f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39933612-172.17.0.15-1597538988582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43437,DS-750277c9-ff5c-4b04-b789-3122c8d8df3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38493,DS-e4700541-a509-40ae-9ee3-52a55882b6bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-0931ef48-44a4-4111-9eb9-faee1f293491,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-e3c1aecf-75d0-4c19-8bb0-67fb067aada5,DISK], DatanodeInfoWithStorage[127.0.0.1:45846,DS-b8c94dc7-baf5-4250-b071-ec160cee22fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-834c22b1-add7-42d4-9ba5-39e85c7f1e33,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-45e7ccc0-cf5e-452c-a447-061dae59e070,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-3194e8b2-7979-4250-a4ea-11e6e8a0608f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1717014823-172.17.0.15-1597539270454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46556,DS-0093e131-f33f-4edc-ba6e-3f08a0c6d64f,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-9a96d3ec-e4cc-46b2-915d-984999604aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-7adc2491-43a2-4b6d-b5af-b3772a791007,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-62357a88-3953-4ce5-b150-10e6150dd0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-45b48bc1-d97a-4b88-b4a7-8c374c1f628d,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-543e5f62-6d59-414c-ad1c-fc5f7b361b34,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-f8dcc58a-e38d-415b-ae37-10e84b5d498d,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-ec92631a-2190-479d-b7e8-3adec5c96140,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1717014823-172.17.0.15-1597539270454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46556,DS-0093e131-f33f-4edc-ba6e-3f08a0c6d64f,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-9a96d3ec-e4cc-46b2-915d-984999604aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-7adc2491-43a2-4b6d-b5af-b3772a791007,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-62357a88-3953-4ce5-b150-10e6150dd0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-45b48bc1-d97a-4b88-b4a7-8c374c1f628d,DISK], DatanodeInfoWithStorage[127.0.0.1:34675,DS-543e5f62-6d59-414c-ad1c-fc5f7b361b34,DISK], DatanodeInfoWithStorage[127.0.0.1:40020,DS-f8dcc58a-e38d-415b-ae37-10e84b5d498d,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-ec92631a-2190-479d-b7e8-3adec5c96140,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1493264406-172.17.0.15-1597539578494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39918,DS-c6d74721-a22c-461a-9d4f-4adacbf552cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-88cd8a69-b8d0-4cb9-9f76-8fd83682be22,DISK], DatanodeInfoWithStorage[127.0.0.1:44524,DS-87a29671-0ea9-4703-adac-6d5c280ab6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-d5ea7303-d1c4-4415-9dcd-e7c67be5e7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-284c2e0b-e47f-4f2b-8d13-64b16c1294c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-904b220a-2cce-4e30-a8df-66954bfbd2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-af0bcca1-c335-46d8-a5b1-3b061bf9434a,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-591b798c-0c01-44c9-9259-6ecd736b81db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1493264406-172.17.0.15-1597539578494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39918,DS-c6d74721-a22c-461a-9d4f-4adacbf552cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-88cd8a69-b8d0-4cb9-9f76-8fd83682be22,DISK], DatanodeInfoWithStorage[127.0.0.1:44524,DS-87a29671-0ea9-4703-adac-6d5c280ab6ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-d5ea7303-d1c4-4415-9dcd-e7c67be5e7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-284c2e0b-e47f-4f2b-8d13-64b16c1294c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-904b220a-2cce-4e30-a8df-66954bfbd2a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-af0bcca1-c335-46d8-a5b1-3b061bf9434a,DISK], DatanodeInfoWithStorage[127.0.0.1:43707,DS-591b798c-0c01-44c9-9259-6ecd736b81db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-682697019-172.17.0.15-1597539617338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42583,DS-7cbb520f-0ff7-4255-abf7-a7cd1618985b,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-f6475f4c-90b1-4118-b5e0-d658e42be7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-25d1c5a4-6a78-4ef8-bcd4-d3b12b2d2d97,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-1c849b10-c71a-4d80-ac1b-b55143a98cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-ef7b4a93-e497-47ea-82e6-f33b6dfb273c,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-0e7186c7-6d79-4414-b50b-78afb6b4dacf,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-f02da22a-5542-4ce8-9ffe-8a00504585c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-d9e30b9b-9273-42ec-89a6-7d463ed84cb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-682697019-172.17.0.15-1597539617338:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42583,DS-7cbb520f-0ff7-4255-abf7-a7cd1618985b,DISK], DatanodeInfoWithStorage[127.0.0.1:46255,DS-f6475f4c-90b1-4118-b5e0-d658e42be7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-25d1c5a4-6a78-4ef8-bcd4-d3b12b2d2d97,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-1c849b10-c71a-4d80-ac1b-b55143a98cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-ef7b4a93-e497-47ea-82e6-f33b6dfb273c,DISK], DatanodeInfoWithStorage[127.0.0.1:43284,DS-0e7186c7-6d79-4414-b50b-78afb6b4dacf,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-f02da22a-5542-4ce8-9ffe-8a00504585c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46037,DS-d9e30b9b-9273-42ec-89a6-7d463ed84cb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-305365344-172.17.0.15-1597539962042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40854,DS-47cc6dd0-ff5e-49ed-b312-2717b77506c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-8a93265a-6515-4306-be91-31fdda100b45,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-f82e583d-12e8-41a2-a312-5323f6c00e71,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-86bd7f12-cf86-4ff2-afd2-7de6a3a9de9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-134745a8-c0b5-4d40-8867-26e7ad93a222,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-79cfcf01-4a27-4614-811f-4153229db237,DISK], DatanodeInfoWithStorage[127.0.0.1:37810,DS-d5fad9dc-0436-420f-9193-97c8dde025a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-a50a1b82-b7e3-470f-aea5-c8945739af0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-305365344-172.17.0.15-1597539962042:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40854,DS-47cc6dd0-ff5e-49ed-b312-2717b77506c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37745,DS-8a93265a-6515-4306-be91-31fdda100b45,DISK], DatanodeInfoWithStorage[127.0.0.1:42974,DS-f82e583d-12e8-41a2-a312-5323f6c00e71,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-86bd7f12-cf86-4ff2-afd2-7de6a3a9de9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45680,DS-134745a8-c0b5-4d40-8867-26e7ad93a222,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-79cfcf01-4a27-4614-811f-4153229db237,DISK], DatanodeInfoWithStorage[127.0.0.1:37810,DS-d5fad9dc-0436-420f-9193-97c8dde025a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-a50a1b82-b7e3-470f-aea5-c8945739af0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 134217728
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092218290-172.17.0.15-1597540289091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37131,DS-1b47e7b7-f43e-4257-a141-8c9c1561fa65,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-56a55868-4765-44b2-bbef-cfcfe8cf1b65,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-40e0b9b6-397b-4332-a644-4d1ccae11306,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-af331b80-3da6-4f2a-9d97-40b59dfba668,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-ba9140d0-988e-4347-b803-d6c4e0b61080,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-032d9966-0d83-4712-b7e8-236a234ae5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-bc0037c0-f96a-4fda-b281-4967a75fa15f,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-ab1996fd-01a1-4d1e-bc3e-9a5c8f9d2690,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092218290-172.17.0.15-1597540289091:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37131,DS-1b47e7b7-f43e-4257-a141-8c9c1561fa65,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-56a55868-4765-44b2-bbef-cfcfe8cf1b65,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-40e0b9b6-397b-4332-a644-4d1ccae11306,DISK], DatanodeInfoWithStorage[127.0.0.1:43466,DS-af331b80-3da6-4f2a-9d97-40b59dfba668,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-ba9140d0-988e-4347-b803-d6c4e0b61080,DISK], DatanodeInfoWithStorage[127.0.0.1:43652,DS-032d9966-0d83-4712-b7e8-236a234ae5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-bc0037c0-f96a-4fda-b281-4967a75fa15f,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-ab1996fd-01a1-4d1e-bc3e-9a5c8f9d2690,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5712
