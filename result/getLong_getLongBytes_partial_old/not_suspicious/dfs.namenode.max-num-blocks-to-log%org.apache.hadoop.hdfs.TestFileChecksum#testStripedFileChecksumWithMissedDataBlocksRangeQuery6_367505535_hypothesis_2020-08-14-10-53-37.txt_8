reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-364273726-172.17.0.14-1597402470268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41843,DS-478925d6-80a3-4a5e-888d-5c205a573da5,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-65664679-36ec-40df-b7c0-92d3e0fd0081,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-1c0b7eb7-c8d2-4559-81eb-e40f22c144f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-aaffa701-400c-4ca1-b652-54a85c74d6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-ebd5852f-d5e3-4324-a315-95ade5969395,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-2a82a884-3e0b-4ecb-81f5-bcbd28320940,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-d63c2cc5-2dc3-4175-9a91-b8879c42da65,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-adfa6cf6-d1d2-4404-af32-d921f59382c6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-364273726-172.17.0.14-1597402470268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41843,DS-478925d6-80a3-4a5e-888d-5c205a573da5,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-65664679-36ec-40df-b7c0-92d3e0fd0081,DISK], DatanodeInfoWithStorage[127.0.0.1:46398,DS-1c0b7eb7-c8d2-4559-81eb-e40f22c144f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41345,DS-aaffa701-400c-4ca1-b652-54a85c74d6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-ebd5852f-d5e3-4324-a315-95ade5969395,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-2a82a884-3e0b-4ecb-81f5-bcbd28320940,DISK], DatanodeInfoWithStorage[127.0.0.1:40824,DS-d63c2cc5-2dc3-4175-9a91-b8879c42da65,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-adfa6cf6-d1d2-4404-af32-d921f59382c6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-695861598-172.17.0.14-1597402499202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34340,DS-03a8e68e-bc87-4cd6-ba25-631a7d8dabf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-b12d7e8d-51a1-46cd-8a13-e6fc9e65ef7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-9d0649a3-96b9-4c72-8b11-4cfc618f3390,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-9d323b53-5dac-490b-b5e5-aba1de3f07ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-0eb9a14f-20e1-4bc3-a644-99a46b334226,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-b9cb87cc-3f7a-4e10-b93c-d9d463809be8,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-1c44671d-5e2b-4b96-8715-e27975bcd085,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-3950cba7-d568-4fee-a91c-6cba9c56e69b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-695861598-172.17.0.14-1597402499202:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34340,DS-03a8e68e-bc87-4cd6-ba25-631a7d8dabf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-b12d7e8d-51a1-46cd-8a13-e6fc9e65ef7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-9d0649a3-96b9-4c72-8b11-4cfc618f3390,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-9d323b53-5dac-490b-b5e5-aba1de3f07ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-0eb9a14f-20e1-4bc3-a644-99a46b334226,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-b9cb87cc-3f7a-4e10-b93c-d9d463809be8,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-1c44671d-5e2b-4b96-8715-e27975bcd085,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-3950cba7-d568-4fee-a91c-6cba9c56e69b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-306517919-172.17.0.14-1597402694595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38015,DS-8eedfe71-af0a-42ef-b87c-ed1c0dbcad76,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-a940885e-2a43-4caa-9f53-a15bf7e169b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-f585e142-fe5f-4e62-bf8a-3169614b7e56,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-7d471c9e-aa7e-4b72-9e94-d316b84860cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-6b3ed4e6-286e-4e29-b7d9-ee3db921b77b,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-79222e46-3874-4a18-8e54-2cef48d3ce78,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-117eea4b-3f4e-488f-b827-5c1c13b5050b,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-01da7c22-f6c9-4481-a32d-cfb1552941e2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-306517919-172.17.0.14-1597402694595:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38015,DS-8eedfe71-af0a-42ef-b87c-ed1c0dbcad76,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-a940885e-2a43-4caa-9f53-a15bf7e169b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-f585e142-fe5f-4e62-bf8a-3169614b7e56,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-7d471c9e-aa7e-4b72-9e94-d316b84860cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-6b3ed4e6-286e-4e29-b7d9-ee3db921b77b,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-79222e46-3874-4a18-8e54-2cef48d3ce78,DISK], DatanodeInfoWithStorage[127.0.0.1:35902,DS-117eea4b-3f4e-488f-b827-5c1c13b5050b,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-01da7c22-f6c9-4481-a32d-cfb1552941e2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1748494299-172.17.0.14-1597402862429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38756,DS-9dfbc438-3179-4ae1-a75f-07a2f61a3464,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-36b721da-0880-41dc-984d-b945f01176a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-99b9e567-8e6d-430b-bc79-6db3735aad46,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-5f083bc3-f6ed-4680-84d6-f5cbe0ee2912,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-4fed4d6c-6786-4623-8dc7-157c3c1b7f37,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-aceec326-0334-4f91-b3c4-c98a26397d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-1689c522-7a2e-4db9-b675-873394cd76f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-005ed40e-43c0-4430-bb91-448fd3e6621c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1748494299-172.17.0.14-1597402862429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38756,DS-9dfbc438-3179-4ae1-a75f-07a2f61a3464,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-36b721da-0880-41dc-984d-b945f01176a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-99b9e567-8e6d-430b-bc79-6db3735aad46,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-5f083bc3-f6ed-4680-84d6-f5cbe0ee2912,DISK], DatanodeInfoWithStorage[127.0.0.1:34570,DS-4fed4d6c-6786-4623-8dc7-157c3c1b7f37,DISK], DatanodeInfoWithStorage[127.0.0.1:42329,DS-aceec326-0334-4f91-b3c4-c98a26397d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:32914,DS-1689c522-7a2e-4db9-b675-873394cd76f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-005ed40e-43c0-4430-bb91-448fd3e6621c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-228547170-172.17.0.14-1597402934029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42216,DS-7674fb81-c96b-4c0a-9a40-e3def2e3a054,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-20e03015-9525-4726-98ba-40f0b10be228,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-0143cb28-0f11-4c35-9472-ef4fc6d2a53d,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-28afa944-9093-4f16-811a-1ba251e9e360,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-62f5e870-3cea-49e2-9bb8-21434517dbef,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-69feb207-9bc2-42cc-a51e-93b96e7b4a85,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-f788bf35-5a8c-42fc-b9e6-8ac58ac90ead,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-1f047a9b-7b2d-4563-b1a5-9ef8c1eadae7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-228547170-172.17.0.14-1597402934029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42216,DS-7674fb81-c96b-4c0a-9a40-e3def2e3a054,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-20e03015-9525-4726-98ba-40f0b10be228,DISK], DatanodeInfoWithStorage[127.0.0.1:38204,DS-0143cb28-0f11-4c35-9472-ef4fc6d2a53d,DISK], DatanodeInfoWithStorage[127.0.0.1:43414,DS-28afa944-9093-4f16-811a-1ba251e9e360,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-62f5e870-3cea-49e2-9bb8-21434517dbef,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-69feb207-9bc2-42cc-a51e-93b96e7b4a85,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-f788bf35-5a8c-42fc-b9e6-8ac58ac90ead,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-1f047a9b-7b2d-4563-b1a5-9ef8c1eadae7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1772665315-172.17.0.14-1597403198018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46730,DS-d3d9647b-45bd-4eb3-a4b4-7e74a4a03cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-ba6b0784-1de6-4c4d-9cd0-ba5bf4f14270,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-d9855e36-b499-47c0-b05f-fbfa9bf864ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-deda81e5-a0aa-41da-a98c-cf6bbbe42eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-fadf3c75-bef4-44d4-a9c7-8fe1abd02d82,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-6234ab2b-34a2-4338-aa81-7e8aaa28bd86,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-557c15ef-5081-471e-8d09-498612ad759a,DISK], DatanodeInfoWithStorage[127.0.0.1:41209,DS-354a8b19-9c76-4e53-87c0-c5c087abfef8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1772665315-172.17.0.14-1597403198018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46730,DS-d3d9647b-45bd-4eb3-a4b4-7e74a4a03cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:33284,DS-ba6b0784-1de6-4c4d-9cd0-ba5bf4f14270,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-d9855e36-b499-47c0-b05f-fbfa9bf864ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39201,DS-deda81e5-a0aa-41da-a98c-cf6bbbe42eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39374,DS-fadf3c75-bef4-44d4-a9c7-8fe1abd02d82,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-6234ab2b-34a2-4338-aa81-7e8aaa28bd86,DISK], DatanodeInfoWithStorage[127.0.0.1:33250,DS-557c15ef-5081-471e-8d09-498612ad759a,DISK], DatanodeInfoWithStorage[127.0.0.1:41209,DS-354a8b19-9c76-4e53-87c0-c5c087abfef8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-670986145-172.17.0.14-1597403553313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37169,DS-f0263ba0-73e2-4957-9ab3-b1382e47c052,DISK], DatanodeInfoWithStorage[127.0.0.1:43834,DS-1e843909-9405-4d80-8a58-96814fb2c074,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-5d7f29e3-b78c-4ff2-b3b5-da4ec489d4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-1f1d7638-421f-4a4a-b66f-fd2924a790b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-db8ee973-2cfd-4e33-8f42-aaea0aac30bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-41f27380-8471-4be0-ac7a-6efcc2e0743a,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-864340d5-28c4-425a-b6c7-6521cbcbf610,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-e2825f02-754e-44be-b956-be3dc7a11916,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-670986145-172.17.0.14-1597403553313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37169,DS-f0263ba0-73e2-4957-9ab3-b1382e47c052,DISK], DatanodeInfoWithStorage[127.0.0.1:43834,DS-1e843909-9405-4d80-8a58-96814fb2c074,DISK], DatanodeInfoWithStorage[127.0.0.1:44598,DS-5d7f29e3-b78c-4ff2-b3b5-da4ec489d4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-1f1d7638-421f-4a4a-b66f-fd2924a790b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37796,DS-db8ee973-2cfd-4e33-8f42-aaea0aac30bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-41f27380-8471-4be0-ac7a-6efcc2e0743a,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-864340d5-28c4-425a-b6c7-6521cbcbf610,DISK], DatanodeInfoWithStorage[127.0.0.1:44074,DS-e2825f02-754e-44be-b956-be3dc7a11916,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458827976-172.17.0.14-1597403780005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43163,DS-081c7813-fad6-4cf5-9ca1-979145f6bb10,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-c5d9cc69-f0a3-435c-b17f-065c4821088a,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-77b56c00-8277-4a03-929b-fa95fbe67ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-09eaec13-4c3a-4dd8-ad47-99a4bcfdd27a,DISK], DatanodeInfoWithStorage[127.0.0.1:39016,DS-2fc360db-b326-46de-8de2-75f10893693e,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-aec9c8a2-751e-4507-9b79-ab2c1e898195,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-e261bad4-2e58-43df-a7b6-2ee3f0dc8aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-592a70ec-ef58-4cb4-b010-423be142bef4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458827976-172.17.0.14-1597403780005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43163,DS-081c7813-fad6-4cf5-9ca1-979145f6bb10,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-c5d9cc69-f0a3-435c-b17f-065c4821088a,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-77b56c00-8277-4a03-929b-fa95fbe67ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-09eaec13-4c3a-4dd8-ad47-99a4bcfdd27a,DISK], DatanodeInfoWithStorage[127.0.0.1:39016,DS-2fc360db-b326-46de-8de2-75f10893693e,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-aec9c8a2-751e-4507-9b79-ab2c1e898195,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-e261bad4-2e58-43df-a7b6-2ee3f0dc8aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-592a70ec-ef58-4cb4-b010-423be142bef4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-135230621-172.17.0.14-1597403816008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45740,DS-89efe1b9-25bb-4540-bb85-7687b2edd870,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-fadcc848-c9b1-418f-bdcb-319dffba6021,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-4d0fef60-4012-49f9-8589-d8c980bec531,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-94c815ed-5874-419e-af72-2cda4a7385c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-ff8487a4-165a-4066-a153-64d42b985bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-37e7b7b3-e2e1-4405-891a-2aa317054c41,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-33d49405-e04b-42b9-b66d-36342cedbef2,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-b1cab865-9fb3-4ea9-a9bd-654d7f220f20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-135230621-172.17.0.14-1597403816008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45740,DS-89efe1b9-25bb-4540-bb85-7687b2edd870,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-fadcc848-c9b1-418f-bdcb-319dffba6021,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-4d0fef60-4012-49f9-8589-d8c980bec531,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-94c815ed-5874-419e-af72-2cda4a7385c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-ff8487a4-165a-4066-a153-64d42b985bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-37e7b7b3-e2e1-4405-891a-2aa317054c41,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-33d49405-e04b-42b9-b66d-36342cedbef2,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-b1cab865-9fb3-4ea9-a9bd-654d7f220f20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2036643289-172.17.0.14-1597404137245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46596,DS-19d7b372-3667-4958-8c26-f68a52414970,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-50979f42-cf51-4044-a08d-fdb280cbb9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-9812329a-c12b-4aec-84a3-69cf0a38c58e,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-da3ca391-35a3-4145-b011-e27e7045bd53,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-02c12470-0887-4036-95ef-2eb5e5c6598b,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-cef24481-a639-4285-b6d1-9b77d72cb4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-e6682205-6379-418d-b22e-97a74b50aa49,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-1d9742ee-3e13-4672-9fd9-cb2aba922dbd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2036643289-172.17.0.14-1597404137245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46596,DS-19d7b372-3667-4958-8c26-f68a52414970,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-50979f42-cf51-4044-a08d-fdb280cbb9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38398,DS-9812329a-c12b-4aec-84a3-69cf0a38c58e,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-da3ca391-35a3-4145-b011-e27e7045bd53,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-02c12470-0887-4036-95ef-2eb5e5c6598b,DISK], DatanodeInfoWithStorage[127.0.0.1:45537,DS-cef24481-a639-4285-b6d1-9b77d72cb4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:45643,DS-e6682205-6379-418d-b22e-97a74b50aa49,DISK], DatanodeInfoWithStorage[127.0.0.1:34593,DS-1d9742ee-3e13-4672-9fd9-cb2aba922dbd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-505368262-172.17.0.14-1597404171015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45517,DS-d6acd032-da56-44e7-b95f-6e12726cc5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-819ff4c2-5e54-44ef-bc03-8493ed46f07f,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-0aa223ad-da1c-4cc3-9553-f0e3a90ab7be,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-21ab0244-57f4-4f6d-a389-53967ee06e93,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-4f4fc16a-fb3e-458f-aa2a-2e356cf16407,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-5d86466a-dc60-431c-993c-4fb11adc6d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-231bd1da-80d7-4eb5-86fc-e19a194e8246,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-ad4ee49d-98f5-47af-9da2-94c63c6ab98e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-505368262-172.17.0.14-1597404171015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45517,DS-d6acd032-da56-44e7-b95f-6e12726cc5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-819ff4c2-5e54-44ef-bc03-8493ed46f07f,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-0aa223ad-da1c-4cc3-9553-f0e3a90ab7be,DISK], DatanodeInfoWithStorage[127.0.0.1:42070,DS-21ab0244-57f4-4f6d-a389-53967ee06e93,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-4f4fc16a-fb3e-458f-aa2a-2e356cf16407,DISK], DatanodeInfoWithStorage[127.0.0.1:34347,DS-5d86466a-dc60-431c-993c-4fb11adc6d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39998,DS-231bd1da-80d7-4eb5-86fc-e19a194e8246,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-ad4ee49d-98f5-47af-9da2-94c63c6ab98e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-705680908-172.17.0.14-1597404539341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37631,DS-d755a77e-d7c6-4ac4-86c4-1f9381c69015,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-fe232b69-b8a3-4820-8959-09ae2fba752e,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-8c065544-c708-4ac4-bedb-2422fd70f0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-70d1bf0d-e498-48e0-9e94-af742b7a87e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-50c2dc2e-d58b-4fa2-9fa9-5ee45756d792,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-4a559065-7733-4fd4-a534-ff2f1319a0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-2518e93b-4e50-4fae-8e2d-41a59c8b0684,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-946e8254-feb5-42dd-a5b2-d28346765fac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-705680908-172.17.0.14-1597404539341:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37631,DS-d755a77e-d7c6-4ac4-86c4-1f9381c69015,DISK], DatanodeInfoWithStorage[127.0.0.1:41196,DS-fe232b69-b8a3-4820-8959-09ae2fba752e,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-8c065544-c708-4ac4-bedb-2422fd70f0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-70d1bf0d-e498-48e0-9e94-af742b7a87e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33383,DS-50c2dc2e-d58b-4fa2-9fa9-5ee45756d792,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-4a559065-7733-4fd4-a534-ff2f1319a0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45062,DS-2518e93b-4e50-4fae-8e2d-41a59c8b0684,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-946e8254-feb5-42dd-a5b2-d28346765fac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-335096460-172.17.0.14-1597405117698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42967,DS-a13c58bd-5ea9-4830-87d4-12be05bbdf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-ff2856c4-f383-4ef2-8889-2a0ee66d8a76,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-76a0ac2c-ff58-4f36-b661-b38b81f76ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-aefaa112-ca8c-4d8b-929b-6cd589024bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-a503a1b5-7cbd-4677-978d-d26ae16f65ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-ae8120af-d22b-4f35-bdd0-e1f5aee062de,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-0c5cd690-05f7-43a2-9649-139c5af4deb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-fc6fdc59-1c41-44bd-97c0-6965aef83fd6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-335096460-172.17.0.14-1597405117698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42967,DS-a13c58bd-5ea9-4830-87d4-12be05bbdf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-ff2856c4-f383-4ef2-8889-2a0ee66d8a76,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-76a0ac2c-ff58-4f36-b661-b38b81f76ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-aefaa112-ca8c-4d8b-929b-6cd589024bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-a503a1b5-7cbd-4677-978d-d26ae16f65ad,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-ae8120af-d22b-4f35-bdd0-e1f5aee062de,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-0c5cd690-05f7-43a2-9649-139c5af4deb2,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-fc6fdc59-1c41-44bd-97c0-6965aef83fd6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636431231-172.17.0.14-1597405156952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34150,DS-d246f821-97f6-4cac-b469-10374cb150c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-939580ab-99ec-4114-a6da-80b8054989f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-3905caf0-be4a-4ae5-b883-c22e6a360f74,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-1838364d-4834-44c7-ad67-ec58eab99d89,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-b37efa45-75cd-4613-8ef3-2217f6c55a21,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-1842843f-9168-4517-85ef-aa268fdcbe63,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-47a2d1b7-dbda-49a4-b68b-b3387996b1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-83ffc5e1-a8b3-4946-8ff4-26d4daeb8bab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1636431231-172.17.0.14-1597405156952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34150,DS-d246f821-97f6-4cac-b469-10374cb150c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-939580ab-99ec-4114-a6da-80b8054989f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-3905caf0-be4a-4ae5-b883-c22e6a360f74,DISK], DatanodeInfoWithStorage[127.0.0.1:46252,DS-1838364d-4834-44c7-ad67-ec58eab99d89,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-b37efa45-75cd-4613-8ef3-2217f6c55a21,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-1842843f-9168-4517-85ef-aa268fdcbe63,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-47a2d1b7-dbda-49a4-b68b-b3387996b1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-83ffc5e1-a8b3-4946-8ff4-26d4daeb8bab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1284747579-172.17.0.14-1597405366750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44485,DS-28a8f19a-0675-4b84-9af2-8aa6ccacfb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-92aaab20-9485-47b5-b1d8-c7b672a88fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-c367cc27-14dc-488d-ba68-88cd6eb4c705,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-746090c4-bcf9-4427-81ff-0219e6687225,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-82b01db6-5f51-447e-9a1a-b711db0fc645,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-329d6392-5594-4b15-bf73-29f14ddb5e52,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-6f03eef0-c078-4298-82c7-73dc5ebebf98,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-d40f3a96-899e-4c22-a5c7-2e3f7f108469,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1284747579-172.17.0.14-1597405366750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44485,DS-28a8f19a-0675-4b84-9af2-8aa6ccacfb1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-92aaab20-9485-47b5-b1d8-c7b672a88fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42701,DS-c367cc27-14dc-488d-ba68-88cd6eb4c705,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-746090c4-bcf9-4427-81ff-0219e6687225,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-82b01db6-5f51-447e-9a1a-b711db0fc645,DISK], DatanodeInfoWithStorage[127.0.0.1:39722,DS-329d6392-5594-4b15-bf73-29f14ddb5e52,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-6f03eef0-c078-4298-82c7-73dc5ebebf98,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-d40f3a96-899e-4c22-a5c7-2e3f7f108469,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894725325-172.17.0.14-1597405635304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42850,DS-f0489110-2605-4c25-a797-27d793208f77,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-7fa6a2cb-9f5c-471b-b909-2e6f2237113e,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-e143d7ce-7634-4ee6-a8da-6723eb149c39,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-c2268556-f184-40c9-b3e5-3a374ee63fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-b1daa5db-ae05-4b67-9439-6495209034ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-95266ea6-7cb5-416c-b8bf-9d502a6163e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-17b90cff-52d2-4af9-8a03-f0bb3bf37538,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-5ca4bd1d-74bb-4ad4-b418-b8cd142b5ded,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894725325-172.17.0.14-1597405635304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42850,DS-f0489110-2605-4c25-a797-27d793208f77,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-7fa6a2cb-9f5c-471b-b909-2e6f2237113e,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-e143d7ce-7634-4ee6-a8da-6723eb149c39,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-c2268556-f184-40c9-b3e5-3a374ee63fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-b1daa5db-ae05-4b67-9439-6495209034ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-95266ea6-7cb5-416c-b8bf-9d502a6163e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-17b90cff-52d2-4af9-8a03-f0bb3bf37538,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-5ca4bd1d-74bb-4ad4-b418-b8cd142b5ded,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2018890407-172.17.0.14-1597405838862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39666,DS-f425e26d-5d22-4f28-86f6-e3b36d30facb,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-598bacef-b29f-4761-be01-a34f19ae4df0,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-b26c81e9-4414-490f-ab3b-e45590f1fb29,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-8f26a37b-6986-4f9d-a037-a64e858cc209,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-0b66c1cd-cb0b-402e-8550-70dc61f25140,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-3dd89c54-5e2a-40fd-bb13-22081fd74c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-9c7a6a4c-9866-4200-90eb-01c04ee7f99a,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-b1b50c92-dba1-4a82-9bf5-4beee6b61601,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2018890407-172.17.0.14-1597405838862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39666,DS-f425e26d-5d22-4f28-86f6-e3b36d30facb,DISK], DatanodeInfoWithStorage[127.0.0.1:41191,DS-598bacef-b29f-4761-be01-a34f19ae4df0,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-b26c81e9-4414-490f-ab3b-e45590f1fb29,DISK], DatanodeInfoWithStorage[127.0.0.1:45458,DS-8f26a37b-6986-4f9d-a037-a64e858cc209,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-0b66c1cd-cb0b-402e-8550-70dc61f25140,DISK], DatanodeInfoWithStorage[127.0.0.1:38046,DS-3dd89c54-5e2a-40fd-bb13-22081fd74c7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-9c7a6a4c-9866-4200-90eb-01c04ee7f99a,DISK], DatanodeInfoWithStorage[127.0.0.1:36141,DS-b1b50c92-dba1-4a82-9bf5-4beee6b61601,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299573850-172.17.0.14-1597405919395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40787,DS-442bf2b8-8068-421a-98bf-e8b1857bb3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-abeaab00-25bb-4a1e-a45c-1010ea4ca2df,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-2245bcdc-0efa-4d9f-8a4b-3073d989f2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-d3a25fa8-27ed-491b-9a08-10fd850ab134,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-79db958b-3875-4671-a833-2aa397d637f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-9fe81a0c-164b-4c72-9078-402f7221da5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-c9ef379f-2059-48f9-b0db-9c36f4cd011d,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-6a9d58c0-2690-4822-98b2-4e9a7e3ab281,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299573850-172.17.0.14-1597405919395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40787,DS-442bf2b8-8068-421a-98bf-e8b1857bb3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-abeaab00-25bb-4a1e-a45c-1010ea4ca2df,DISK], DatanodeInfoWithStorage[127.0.0.1:44964,DS-2245bcdc-0efa-4d9f-8a4b-3073d989f2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34059,DS-d3a25fa8-27ed-491b-9a08-10fd850ab134,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-79db958b-3875-4671-a833-2aa397d637f0,DISK], DatanodeInfoWithStorage[127.0.0.1:32916,DS-9fe81a0c-164b-4c72-9078-402f7221da5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-c9ef379f-2059-48f9-b0db-9c36f4cd011d,DISK], DatanodeInfoWithStorage[127.0.0.1:41615,DS-6a9d58c0-2690-4822-98b2-4e9a7e3ab281,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2079103113-172.17.0.14-1597406032824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40831,DS-62765ba2-f952-42fa-b69e-70f33798d26d,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-6f1dd570-81e7-43be-9787-973b33bb981c,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-6aae6f19-c2ca-4b1e-9e11-488ba6ea3c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-c0515d79-4577-4c4f-9993-f0d5dada34ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-3e7746ca-79bf-4319-9089-ee6a173525a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-7b8ea687-3a00-48e8-89a2-54e2d40443a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-20764077-b43a-420c-8e87-20a305be0f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-40197250-1c11-4ad7-ae72-46f9f79ff091,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2079103113-172.17.0.14-1597406032824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40831,DS-62765ba2-f952-42fa-b69e-70f33798d26d,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-6f1dd570-81e7-43be-9787-973b33bb981c,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-6aae6f19-c2ca-4b1e-9e11-488ba6ea3c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45324,DS-c0515d79-4577-4c4f-9993-f0d5dada34ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-3e7746ca-79bf-4319-9089-ee6a173525a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-7b8ea687-3a00-48e8-89a2-54e2d40443a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-20764077-b43a-420c-8e87-20a305be0f1e,DISK], DatanodeInfoWithStorage[127.0.0.1:35362,DS-40197250-1c11-4ad7-ae72-46f9f79ff091,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-592937923-172.17.0.14-1597406194470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35517,DS-1090ff7b-8b1e-4938-839f-920095ec08b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-8213bd79-0ec1-463c-bafb-ee3f9adfa5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34770,DS-721a830e-ef75-493c-a12f-f6e519915ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-90fb421a-d95f-4729-be8a-ab34a530b52b,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-044c51a2-0bdb-453a-b4ce-6ecbf375d542,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-47a33bc6-acd2-4de8-851e-3ad1cdbc2b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-47c6ca98-1635-4c63-b20a-9e6bd34ef2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-9b1f7e39-7687-4ec8-826b-36f3e3320d94,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-592937923-172.17.0.14-1597406194470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35517,DS-1090ff7b-8b1e-4938-839f-920095ec08b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-8213bd79-0ec1-463c-bafb-ee3f9adfa5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34770,DS-721a830e-ef75-493c-a12f-f6e519915ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-90fb421a-d95f-4729-be8a-ab34a530b52b,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-044c51a2-0bdb-453a-b4ce-6ecbf375d542,DISK], DatanodeInfoWithStorage[127.0.0.1:41949,DS-47a33bc6-acd2-4de8-851e-3ad1cdbc2b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-47c6ca98-1635-4c63-b20a-9e6bd34ef2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-9b1f7e39-7687-4ec8-826b-36f3e3320d94,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061029275-172.17.0.14-1597406819843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42672,DS-27894366-eac2-4717-a875-e95844a40fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43896,DS-f4ad769c-8aa6-4979-9911-3ded48a05c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-31c785e0-21bf-4cc9-95b0-f4163062bd53,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-3a63d4f7-b116-41c5-b9de-9d1c407f2183,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-3cd88373-195a-431a-ada3-2fb3b7656bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-d15e4248-58bf-4105-bf63-5911a7618b69,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-a3ca1ea9-c6ce-4d45-9986-5d5c41596eda,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-4cea69c0-d91d-4d4c-aac4-212fea1915f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2061029275-172.17.0.14-1597406819843:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42672,DS-27894366-eac2-4717-a875-e95844a40fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:43896,DS-f4ad769c-8aa6-4979-9911-3ded48a05c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43626,DS-31c785e0-21bf-4cc9-95b0-f4163062bd53,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-3a63d4f7-b116-41c5-b9de-9d1c407f2183,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-3cd88373-195a-431a-ada3-2fb3b7656bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-d15e4248-58bf-4105-bf63-5911a7618b69,DISK], DatanodeInfoWithStorage[127.0.0.1:35005,DS-a3ca1ea9-c6ce-4d45-9986-5d5c41596eda,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-4cea69c0-d91d-4d4c-aac4-212fea1915f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-275013271-172.17.0.14-1597407127772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45556,DS-29683e1b-7084-40d7-9340-21b717656379,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-a613d284-3930-4084-9f0f-8e4a32b21562,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-b577c9b9-8fee-477a-acf0-46dba3729559,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-b65a5bd8-b1b6-4836-a4f4-465e2a6bcda0,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-425d061f-e96b-402e-a57c-889ff7ffc5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-530b390f-405e-4a37-8ffd-55d8f90c22e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-f62f444a-6769-431c-85d1-c1fee5e9f821,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-4ac156f8-4e96-45cd-b101-2d3774e20866,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-275013271-172.17.0.14-1597407127772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45556,DS-29683e1b-7084-40d7-9340-21b717656379,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-a613d284-3930-4084-9f0f-8e4a32b21562,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-b577c9b9-8fee-477a-acf0-46dba3729559,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-b65a5bd8-b1b6-4836-a4f4-465e2a6bcda0,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-425d061f-e96b-402e-a57c-889ff7ffc5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-530b390f-405e-4a37-8ffd-55d8f90c22e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-f62f444a-6769-431c-85d1-c1fee5e9f821,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-4ac156f8-4e96-45cd-b101-2d3774e20866,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1534011543-172.17.0.14-1597407454428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37028,DS-38576195-f2e8-4c3e-931b-dd732c413c97,DISK], DatanodeInfoWithStorage[127.0.0.1:40749,DS-eb86b13e-a5b1-44db-bcc7-5f27deeede05,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-f64bb6ef-845c-4d77-a53f-c2aad0429e53,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-a96a4364-f8e3-499a-8a54-5e5ffecc1910,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-65c7bcee-eb48-42db-a044-f1e388b21f58,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-fbc80dfe-d656-46be-a041-9f711af47d52,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-ea4aac03-7688-4cbf-81e4-6ef900cc0d04,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-527a8ba2-1609-4c17-93b6-cca310dd99da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1534011543-172.17.0.14-1597407454428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37028,DS-38576195-f2e8-4c3e-931b-dd732c413c97,DISK], DatanodeInfoWithStorage[127.0.0.1:40749,DS-eb86b13e-a5b1-44db-bcc7-5f27deeede05,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-f64bb6ef-845c-4d77-a53f-c2aad0429e53,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-a96a4364-f8e3-499a-8a54-5e5ffecc1910,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-65c7bcee-eb48-42db-a044-f1e388b21f58,DISK], DatanodeInfoWithStorage[127.0.0.1:40302,DS-fbc80dfe-d656-46be-a041-9f711af47d52,DISK], DatanodeInfoWithStorage[127.0.0.1:38363,DS-ea4aac03-7688-4cbf-81e4-6ef900cc0d04,DISK], DatanodeInfoWithStorage[127.0.0.1:38646,DS-527a8ba2-1609-4c17-93b6-cca310dd99da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1189526404-172.17.0.14-1597407498645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44687,DS-9b86e9d6-54de-4272-92ed-69e770352d32,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-e6f5bf24-8a63-4df0-bf8b-891e09fa539f,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-56cc69ae-3533-49b4-891a-99eaabbb8b71,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-0739404b-54a8-4466-9722-714621782dff,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-a6124f2b-19d5-4bc3-a281-f6e711471950,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-1f62f9a8-257f-499b-b5a2-548e6183b2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-b1704001-5c9d-4e74-873e-93088f201f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-7d29654d-56ab-4473-9fe8-84948ca7857e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1189526404-172.17.0.14-1597407498645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44687,DS-9b86e9d6-54de-4272-92ed-69e770352d32,DISK], DatanodeInfoWithStorage[127.0.0.1:43003,DS-e6f5bf24-8a63-4df0-bf8b-891e09fa539f,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-56cc69ae-3533-49b4-891a-99eaabbb8b71,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-0739404b-54a8-4466-9722-714621782dff,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-a6124f2b-19d5-4bc3-a281-f6e711471950,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-1f62f9a8-257f-499b-b5a2-548e6183b2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-b1704001-5c9d-4e74-873e-93088f201f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-7d29654d-56ab-4473-9fe8-84948ca7857e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-977589342-172.17.0.14-1597407655669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34092,DS-faa3f3dc-3c84-48ee-9963-b511c0756307,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-79781050-cbef-4ef7-97ea-8120a21eaa80,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-aad77142-144a-4354-acfc-ced6be71f91f,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-aa87f671-c6d3-46d6-9bdc-d921797efdc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-56fdbcf4-3a31-4e58-8d90-40943e665530,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-7a2910ed-5c4b-4d62-ab91-fb44332cbe75,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-c378c8e7-955f-4569-ab2c-605305bd2f49,DISK], DatanodeInfoWithStorage[127.0.0.1:44956,DS-b50a02f1-415d-4181-b076-faa67ccca326,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-977589342-172.17.0.14-1597407655669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34092,DS-faa3f3dc-3c84-48ee-9963-b511c0756307,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-79781050-cbef-4ef7-97ea-8120a21eaa80,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-aad77142-144a-4354-acfc-ced6be71f91f,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-aa87f671-c6d3-46d6-9bdc-d921797efdc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-56fdbcf4-3a31-4e58-8d90-40943e665530,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-7a2910ed-5c4b-4d62-ab91-fb44332cbe75,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-c378c8e7-955f-4569-ab2c-605305bd2f49,DISK], DatanodeInfoWithStorage[127.0.0.1:44956,DS-b50a02f1-415d-4181-b076-faa67ccca326,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-501756119-172.17.0.14-1597407776507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44085,DS-43882099-63bd-43d4-a6ec-5ccd12724313,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-2f679a3b-3cf1-404b-b67f-7f3409e111de,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-e58276c2-8431-40d5-a05d-d3b364cddf34,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-cc84e164-f15c-452c-870d-a6312b8ac01a,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-a4be1fbd-e4d5-4b78-a6f0-70b2e7b327ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-b6742670-b3d2-472c-bdb6-dcc87d867bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-52b54f71-3609-4829-8c07-f4f7613c2023,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-7b22feb2-3664-49ca-81c2-af4ea6bd199f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-501756119-172.17.0.14-1597407776507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44085,DS-43882099-63bd-43d4-a6ec-5ccd12724313,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-2f679a3b-3cf1-404b-b67f-7f3409e111de,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-e58276c2-8431-40d5-a05d-d3b364cddf34,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-cc84e164-f15c-452c-870d-a6312b8ac01a,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-a4be1fbd-e4d5-4b78-a6f0-70b2e7b327ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-b6742670-b3d2-472c-bdb6-dcc87d867bd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40458,DS-52b54f71-3609-4829-8c07-f4f7613c2023,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-7b22feb2-3664-49ca-81c2-af4ea6bd199f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-863650081-172.17.0.14-1597408153316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38524,DS-baf93d1f-0f70-46b6-909d-3f355fec96dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-5f196ae2-c4fc-4424-964f-bf5c56f257c5,DISK], DatanodeInfoWithStorage[127.0.0.1:32782,DS-6e9d977a-5def-43bf-84ee-5c0b80c20719,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-62ebb172-7a6d-4db1-b729-2989361d93d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-ad09fa45-007f-49f6-b182-c82ec11afa5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-6889bd45-ae4e-474d-9555-4b3b1c0ff740,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-7a7238c3-a953-46b6-b5b8-847092310cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-a8fa80b8-989b-4f5f-bed1-efde8cac1d35,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-863650081-172.17.0.14-1597408153316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38524,DS-baf93d1f-0f70-46b6-909d-3f355fec96dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35773,DS-5f196ae2-c4fc-4424-964f-bf5c56f257c5,DISK], DatanodeInfoWithStorage[127.0.0.1:32782,DS-6e9d977a-5def-43bf-84ee-5c0b80c20719,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-62ebb172-7a6d-4db1-b729-2989361d93d8,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-ad09fa45-007f-49f6-b182-c82ec11afa5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-6889bd45-ae4e-474d-9555-4b3b1c0ff740,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-7a7238c3-a953-46b6-b5b8-847092310cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-a8fa80b8-989b-4f5f-bed1-efde8cac1d35,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.max-num-blocks-to-log
component: hdfs:DataNode
v1: 10
v2: 1000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-516151782-172.17.0.14-1597408189992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42158,DS-cfc3a28b-abbb-413a-b2f2-13c64125c65b,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-fd506cde-0d90-4e8f-b754-cf24e5404626,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-4b8bfab1-d56a-42c1-9a3b-c6ad669624d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-357438ff-be8b-43e8-ae04-75ba3c4ab5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-56428241-df34-48ed-9f98-a413b4d05d53,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-ceb224e1-a387-4aa9-840e-b07ef4404ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-766b739d-8883-4425-8199-94db5b17f399,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-dee46920-0bc9-48f8-a1a1-dd0de3e0a184,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-516151782-172.17.0.14-1597408189992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42158,DS-cfc3a28b-abbb-413a-b2f2-13c64125c65b,DISK], DatanodeInfoWithStorage[127.0.0.1:43073,DS-fd506cde-0d90-4e8f-b754-cf24e5404626,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-4b8bfab1-d56a-42c1-9a3b-c6ad669624d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-357438ff-be8b-43e8-ae04-75ba3c4ab5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-56428241-df34-48ed-9f98-a413b4d05d53,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-ceb224e1-a387-4aa9-840e-b07ef4404ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-766b739d-8883-4425-8199-94db5b17f399,DISK], DatanodeInfoWithStorage[127.0.0.1:33525,DS-dee46920-0bc9-48f8-a1a1-dd0de3e0a184,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 18 out of 50
result: false positive !!!
Total execution time in seconds : 5796
