reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-853132353-172.17.0.17-1597519116335:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38977,DS-6ebeb21c-e42b-4e39-8ffe-2db75aa5444b,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-1c6a7da8-5c3d-428a-8b91-5573e4c19bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-03f922b4-c263-4b46-a8b0-13fa8b8d226d,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-c337840c-7724-426f-aa95-cde9535c321d,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-b88c7a6e-c688-44c1-baa9-cbdd3d8892a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-182d1e9f-be60-47b9-8f7a-3cc170dfa5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-cd44e6cd-252a-4ff0-8bfb-4cb3ec3409e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-12ef36b3-c115-4c2b-bba9-b32a2feceeca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-853132353-172.17.0.17-1597519116335:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38977,DS-6ebeb21c-e42b-4e39-8ffe-2db75aa5444b,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-1c6a7da8-5c3d-428a-8b91-5573e4c19bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-03f922b4-c263-4b46-a8b0-13fa8b8d226d,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-c337840c-7724-426f-aa95-cde9535c321d,DISK], DatanodeInfoWithStorage[127.0.0.1:40126,DS-b88c7a6e-c688-44c1-baa9-cbdd3d8892a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-182d1e9f-be60-47b9-8f7a-3cc170dfa5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40187,DS-cd44e6cd-252a-4ff0-8bfb-4cb3ec3409e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-12ef36b3-c115-4c2b-bba9-b32a2feceeca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-324915427-172.17.0.17-1597519201633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45753,DS-1b4bf630-7804-484f-ae2f-4f6872760b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-f2743743-ae08-4744-bd77-15040f1b550c,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-d8fcc3b1-fbad-4e47-a4a9-d7283aa17529,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-a82f7139-7bcd-49e0-8a06-2951c4f1d792,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-0c146100-0894-4704-9621-896550f64fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-e1044ad2-dca5-4f8a-aefa-f6a0bb43247e,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-8aa4b79c-f966-471c-bfda-9c08f140bea4,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-e47dfbfd-0ef3-433e-a850-f655de883df6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-324915427-172.17.0.17-1597519201633:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45753,DS-1b4bf630-7804-484f-ae2f-4f6872760b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40585,DS-f2743743-ae08-4744-bd77-15040f1b550c,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-d8fcc3b1-fbad-4e47-a4a9-d7283aa17529,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-a82f7139-7bcd-49e0-8a06-2951c4f1d792,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-0c146100-0894-4704-9621-896550f64fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:40192,DS-e1044ad2-dca5-4f8a-aefa-f6a0bb43247e,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-8aa4b79c-f966-471c-bfda-9c08f140bea4,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-e47dfbfd-0ef3-433e-a850-f655de883df6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-910373082-172.17.0.17-1597520470486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38736,DS-2698b945-4909-4766-9242-f81ccc8b1698,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-ee176664-2c36-4d50-8c6e-1fba6fba1769,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-b8587134-d673-442a-925f-7a96b186d154,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-0ed1d097-3b3f-46d3-9920-04dc6d05f056,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-4221401d-548f-4696-ac48-7bc4c4e4ecf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-89f2e726-af39-4b62-8abd-d9bd11398d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-9a6f8c22-7e0a-4daa-9014-1904777c9929,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-27a4831d-1049-402f-9e87-8b183fa47037,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-910373082-172.17.0.17-1597520470486:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38736,DS-2698b945-4909-4766-9242-f81ccc8b1698,DISK], DatanodeInfoWithStorage[127.0.0.1:43080,DS-ee176664-2c36-4d50-8c6e-1fba6fba1769,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-b8587134-d673-442a-925f-7a96b186d154,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-0ed1d097-3b3f-46d3-9920-04dc6d05f056,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-4221401d-548f-4696-ac48-7bc4c4e4ecf2,DISK], DatanodeInfoWithStorage[127.0.0.1:39727,DS-89f2e726-af39-4b62-8abd-d9bd11398d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-9a6f8c22-7e0a-4daa-9014-1904777c9929,DISK], DatanodeInfoWithStorage[127.0.0.1:34665,DS-27a4831d-1049-402f-9e87-8b183fa47037,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-495359732-172.17.0.17-1597520610380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34449,DS-7b33d449-c0ab-4c2c-9e01-8d9fd0faa975,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-1d46e780-8b54-4b42-955a-2d73c8325052,DISK], DatanodeInfoWithStorage[127.0.0.1:43352,DS-b9ed9cc6-2b83-48c7-83c6-b0a426c5b846,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-02367561-742e-4585-aa1a-4b6078e22908,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-7192fbeb-bf74-41d8-8658-a836f38dd95b,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-d54f52cc-fe52-42ad-81f2-e06cfaaf880a,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-02aca2c8-a368-4bc3-9111-f5bffc94b853,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-d0e531da-8f36-4e93-bc11-6c6a1de12b89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-495359732-172.17.0.17-1597520610380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34449,DS-7b33d449-c0ab-4c2c-9e01-8d9fd0faa975,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-1d46e780-8b54-4b42-955a-2d73c8325052,DISK], DatanodeInfoWithStorage[127.0.0.1:43352,DS-b9ed9cc6-2b83-48c7-83c6-b0a426c5b846,DISK], DatanodeInfoWithStorage[127.0.0.1:36364,DS-02367561-742e-4585-aa1a-4b6078e22908,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-7192fbeb-bf74-41d8-8658-a836f38dd95b,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-d54f52cc-fe52-42ad-81f2-e06cfaaf880a,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-02aca2c8-a368-4bc3-9111-f5bffc94b853,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-d0e531da-8f36-4e93-bc11-6c6a1de12b89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1860154561-172.17.0.17-1597520744409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45514,DS-fe1dfaa3-4621-48b3-b007-87b8d55c1be0,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-2b68dca8-a2f6-4590-9e2e-f4fbd7aeee80,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-146a8177-770c-4344-806b-2398e1230de3,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-5f2b3675-f830-4009-8520-016623589c85,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-3d0921d3-f9b0-415d-a0b4-8cde7843b4db,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-d12a8e37-27ce-41ed-bd9c-98afe288fe29,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-4d2d39a7-47a1-4bc4-8f0a-71d3c7840587,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-651d2ed1-dd93-4e12-a576-fc0e62d8741d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1860154561-172.17.0.17-1597520744409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45514,DS-fe1dfaa3-4621-48b3-b007-87b8d55c1be0,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-2b68dca8-a2f6-4590-9e2e-f4fbd7aeee80,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-146a8177-770c-4344-806b-2398e1230de3,DISK], DatanodeInfoWithStorage[127.0.0.1:43216,DS-5f2b3675-f830-4009-8520-016623589c85,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-3d0921d3-f9b0-415d-a0b4-8cde7843b4db,DISK], DatanodeInfoWithStorage[127.0.0.1:33715,DS-d12a8e37-27ce-41ed-bd9c-98afe288fe29,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-4d2d39a7-47a1-4bc4-8f0a-71d3c7840587,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-651d2ed1-dd93-4e12-a576-fc0e62d8741d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-730731315-172.17.0.17-1597520841273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42560,DS-5b32ac45-ddc0-4c2f-b64f-e087fadd2b52,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-71e71669-9036-420c-b5b9-71bc9c4d09c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-3bcb2985-89c5-4b2e-a3b3-2a2619a0209a,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-30287af9-a359-44ae-a409-072729f5240c,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-4272d1d2-a63b-4f0f-af45-54b5bda76a79,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-5fef185c-29f1-4a4c-b6e5-716c399cb19d,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-1bac7bd9-b53a-4dac-88e2-b8fecabf2548,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-adee0505-98a7-4d6b-87b6-bd14a1b83af0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-730731315-172.17.0.17-1597520841273:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42560,DS-5b32ac45-ddc0-4c2f-b64f-e087fadd2b52,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-71e71669-9036-420c-b5b9-71bc9c4d09c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-3bcb2985-89c5-4b2e-a3b3-2a2619a0209a,DISK], DatanodeInfoWithStorage[127.0.0.1:42041,DS-30287af9-a359-44ae-a409-072729f5240c,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-4272d1d2-a63b-4f0f-af45-54b5bda76a79,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-5fef185c-29f1-4a4c-b6e5-716c399cb19d,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-1bac7bd9-b53a-4dac-88e2-b8fecabf2548,DISK], DatanodeInfoWithStorage[127.0.0.1:41728,DS-adee0505-98a7-4d6b-87b6-bd14a1b83af0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1518522074-172.17.0.17-1597520981912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45961,DS-05c8f613-8019-409c-9b93-50994692a3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-62191dd2-a00d-4f2e-946b-a2fe1c19e08f,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-e8a1f834-624f-467d-b8ad-f48d8f4b47a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-755add3b-3cf1-4f8d-89e7-a2a7839be5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-94e4a77c-31a0-44a6-97c2-1d31ccd97023,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-5fff1aaa-51e9-4454-afe9-de344f5c010d,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-42a5ad2d-063a-4477-a560-e4bbddee70e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-94e5eeda-2c50-4e3c-8fbf-6dcd063a1a93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1518522074-172.17.0.17-1597520981912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45961,DS-05c8f613-8019-409c-9b93-50994692a3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35036,DS-62191dd2-a00d-4f2e-946b-a2fe1c19e08f,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-e8a1f834-624f-467d-b8ad-f48d8f4b47a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-755add3b-3cf1-4f8d-89e7-a2a7839be5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34396,DS-94e4a77c-31a0-44a6-97c2-1d31ccd97023,DISK], DatanodeInfoWithStorage[127.0.0.1:36055,DS-5fff1aaa-51e9-4454-afe9-de344f5c010d,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-42a5ad2d-063a-4477-a560-e4bbddee70e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-94e5eeda-2c50-4e3c-8fbf-6dcd063a1a93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-119406798-172.17.0.17-1597521197468:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44323,DS-68787b68-fc84-4527-99bb-aeedb666b6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-1a89003b-7149-4793-8186-3b99e02d49d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-c36a5eac-526c-411a-8eb1-1734e0c9b8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-68c39b83-8555-4e58-a8c6-483c1903838e,DISK], DatanodeInfoWithStorage[127.0.0.1:40389,DS-bd882062-b7e6-4bf3-9b6d-7ed37e495cad,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-b4f85e52-6e63-47bf-9c3c-77eb296e4fee,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-4c0522b4-9590-4b23-be09-0c4d5a1c0a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-a7fe2e1d-901b-48a9-add4-b915da690dc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-119406798-172.17.0.17-1597521197468:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44323,DS-68787b68-fc84-4527-99bb-aeedb666b6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-1a89003b-7149-4793-8186-3b99e02d49d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-c36a5eac-526c-411a-8eb1-1734e0c9b8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-68c39b83-8555-4e58-a8c6-483c1903838e,DISK], DatanodeInfoWithStorage[127.0.0.1:40389,DS-bd882062-b7e6-4bf3-9b6d-7ed37e495cad,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-b4f85e52-6e63-47bf-9c3c-77eb296e4fee,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-4c0522b4-9590-4b23-be09-0c4d5a1c0a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-a7fe2e1d-901b-48a9-add4-b915da690dc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2023643098-172.17.0.17-1597521287215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33906,DS-084bc4f5-f079-4a03-b0ea-913601f11346,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-e6336a36-1857-4c8a-aec5-80e146666f21,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-6ac96d5e-24ae-4e19-8ee7-60d85c769831,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-6c1e2691-d33b-47e9-9ce8-c84b09f3de17,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-4586f80a-7744-4049-b9ef-887c0e099744,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-9cbb39b4-7d1a-45e3-9bae-1a9ac5d05fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-826f25dc-6930-46ed-abb4-c9673195dbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-dd60fc2a-535b-4ff8-b6ed-dcdf0957a9ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2023643098-172.17.0.17-1597521287215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33906,DS-084bc4f5-f079-4a03-b0ea-913601f11346,DISK], DatanodeInfoWithStorage[127.0.0.1:46360,DS-e6336a36-1857-4c8a-aec5-80e146666f21,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-6ac96d5e-24ae-4e19-8ee7-60d85c769831,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-6c1e2691-d33b-47e9-9ce8-c84b09f3de17,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-4586f80a-7744-4049-b9ef-887c0e099744,DISK], DatanodeInfoWithStorage[127.0.0.1:33274,DS-9cbb39b4-7d1a-45e3-9bae-1a9ac5d05fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-826f25dc-6930-46ed-abb4-c9673195dbb9,DISK], DatanodeInfoWithStorage[127.0.0.1:41306,DS-dd60fc2a-535b-4ff8-b6ed-dcdf0957a9ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1764049322-172.17.0.17-1597521934004:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39206,DS-db8fd144-7b95-4b1d-abd3-9297f0c34c29,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-96191961-aea4-43c5-afd4-11c773a24ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-59d5957c-af8b-42fe-a7f7-47d7dd31c7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-3266aa1b-754b-444e-8e50-a6ca2dd780b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-983f0e56-2537-403b-a21e-1d19a268af61,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-8ae307b2-b71b-47fb-a2a7-3b6133a3225a,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-50e4af92-ad88-4973-b7da-390465e5909e,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-83ce3a35-807b-4ff3-bff2-d147c0a30fbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1764049322-172.17.0.17-1597521934004:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39206,DS-db8fd144-7b95-4b1d-abd3-9297f0c34c29,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-96191961-aea4-43c5-afd4-11c773a24ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-59d5957c-af8b-42fe-a7f7-47d7dd31c7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37365,DS-3266aa1b-754b-444e-8e50-a6ca2dd780b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-983f0e56-2537-403b-a21e-1d19a268af61,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-8ae307b2-b71b-47fb-a2a7-3b6133a3225a,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-50e4af92-ad88-4973-b7da-390465e5909e,DISK], DatanodeInfoWithStorage[127.0.0.1:45309,DS-83ce3a35-807b-4ff3-bff2-d147c0a30fbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-10056801-172.17.0.17-1597522028094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37333,DS-ebed4fc8-fb0d-4c28-b51a-eaed71451258,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-4b3b2ec0-39d7-43a7-a243-0a3e888c49d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-2466b087-c168-4d73-add1-cc4897defd28,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-7ab7a76c-07f6-46f7-b2d6-a1bb8c3d2495,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-85c00763-a572-4ffc-80dd-219e2d65611f,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-3b52be51-8a1f-45b6-b137-50d7312a9c90,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-ec4cbeb6-0234-49fa-8ef9-2653fe973008,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-86da5d7a-666f-4da2-ab15-afe7967122d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-10056801-172.17.0.17-1597522028094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37333,DS-ebed4fc8-fb0d-4c28-b51a-eaed71451258,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-4b3b2ec0-39d7-43a7-a243-0a3e888c49d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-2466b087-c168-4d73-add1-cc4897defd28,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-7ab7a76c-07f6-46f7-b2d6-a1bb8c3d2495,DISK], DatanodeInfoWithStorage[127.0.0.1:35131,DS-85c00763-a572-4ffc-80dd-219e2d65611f,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-3b52be51-8a1f-45b6-b137-50d7312a9c90,DISK], DatanodeInfoWithStorage[127.0.0.1:39393,DS-ec4cbeb6-0234-49fa-8ef9-2653fe973008,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-86da5d7a-666f-4da2-ab15-afe7967122d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2010821068-172.17.0.17-1597522809330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35489,DS-4db298fb-229d-4db7-b270-7d8e36cf1cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-15228eed-b82b-4ddb-9895-81840a972932,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-ec599439-b805-4fb7-b3f8-f745e2142711,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-7e015f97-745d-4cfe-ba1e-28805b283765,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-0845d62d-028c-4988-8493-a62f117c0fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-b30b506d-1df1-4b36-9f60-7eb296402c72,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-b4aff70b-a10e-4bbf-a5e4-d450ef9cfbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-8180f724-ed79-4080-a8fa-c7a4663e4242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2010821068-172.17.0.17-1597522809330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35489,DS-4db298fb-229d-4db7-b270-7d8e36cf1cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-15228eed-b82b-4ddb-9895-81840a972932,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-ec599439-b805-4fb7-b3f8-f745e2142711,DISK], DatanodeInfoWithStorage[127.0.0.1:43855,DS-7e015f97-745d-4cfe-ba1e-28805b283765,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-0845d62d-028c-4988-8493-a62f117c0fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-b30b506d-1df1-4b36-9f60-7eb296402c72,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-b4aff70b-a10e-4bbf-a5e4-d450ef9cfbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-8180f724-ed79-4080-a8fa-c7a4663e4242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-269445620-172.17.0.17-1597523301877:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37233,DS-4830f5e7-0ec4-41f3-8cc9-82055e00b896,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-ac8b1ca1-427e-416e-86e7-4eb46e254998,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-03005d45-5605-45a7-8864-32bcc1a942ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-b2b2847d-39cf-4013-9184-6bca60be6471,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-ef10482d-405b-4214-b086-0ae71bd908bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-97ccc3c0-95ca-4ef8-bd21-d4271d26a204,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-36275e49-8b65-459f-aaaa-fdb292516f14,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-1ac9f347-426d-4131-ad06-c759ee5a127d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-269445620-172.17.0.17-1597523301877:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37233,DS-4830f5e7-0ec4-41f3-8cc9-82055e00b896,DISK], DatanodeInfoWithStorage[127.0.0.1:43990,DS-ac8b1ca1-427e-416e-86e7-4eb46e254998,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-03005d45-5605-45a7-8864-32bcc1a942ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-b2b2847d-39cf-4013-9184-6bca60be6471,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-ef10482d-405b-4214-b086-0ae71bd908bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34652,DS-97ccc3c0-95ca-4ef8-bd21-d4271d26a204,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-36275e49-8b65-459f-aaaa-fdb292516f14,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-1ac9f347-426d-4131-ad06-c759ee5a127d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-52376494-172.17.0.17-1597523736374:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33492,DS-fd89ac62-4db4-42be-954d-38af9396e91e,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-776c3cb8-1ec7-4611-80d7-18899da36c24,DISK], DatanodeInfoWithStorage[127.0.0.1:33835,DS-9320adfe-90ac-4be0-8b3c-9c857f90b748,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-5b1eb00e-707e-4378-bace-75a53ed1d463,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-04fa7fb2-c9cc-4c31-8d19-d55a5ff37750,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-d27b3c17-2764-49fa-aa7e-707f56440c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-16c4a1fa-dc9c-402a-afa1-f303fb9a4130,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-7d399e13-2a69-48d7-8639-fb9c34e6aeb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-52376494-172.17.0.17-1597523736374:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33492,DS-fd89ac62-4db4-42be-954d-38af9396e91e,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-776c3cb8-1ec7-4611-80d7-18899da36c24,DISK], DatanodeInfoWithStorage[127.0.0.1:33835,DS-9320adfe-90ac-4be0-8b3c-9c857f90b748,DISK], DatanodeInfoWithStorage[127.0.0.1:34933,DS-5b1eb00e-707e-4378-bace-75a53ed1d463,DISK], DatanodeInfoWithStorage[127.0.0.1:41253,DS-04fa7fb2-c9cc-4c31-8d19-d55a5ff37750,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-d27b3c17-2764-49fa-aa7e-707f56440c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-16c4a1fa-dc9c-402a-afa1-f303fb9a4130,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-7d399e13-2a69-48d7-8639-fb9c34e6aeb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1492747911-172.17.0.17-1597524244289:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34488,DS-b9f52dce-24f1-42a8-9cb0-3caebcf4b2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-46cf75c5-d92d-4c16-984d-af7f3edd57de,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-63b7d1d3-2e2e-44a0-b532-8e28767ddf83,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-cf67d7b4-de8c-4fd3-a337-3ddd7c08006a,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-79a2bdea-b3f2-42da-9017-05cb025bc10e,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-09021abf-384e-48bb-bc5c-e8369df7c96f,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-2901be63-f28b-4754-ac30-453f9491daa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-a137b3ad-3cf4-466f-a3fd-86714e7cba1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1492747911-172.17.0.17-1597524244289:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34488,DS-b9f52dce-24f1-42a8-9cb0-3caebcf4b2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35712,DS-46cf75c5-d92d-4c16-984d-af7f3edd57de,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-63b7d1d3-2e2e-44a0-b532-8e28767ddf83,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-cf67d7b4-de8c-4fd3-a337-3ddd7c08006a,DISK], DatanodeInfoWithStorage[127.0.0.1:45418,DS-79a2bdea-b3f2-42da-9017-05cb025bc10e,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-09021abf-384e-48bb-bc5c-e8369df7c96f,DISK], DatanodeInfoWithStorage[127.0.0.1:45583,DS-2901be63-f28b-4754-ac30-453f9491daa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41085,DS-a137b3ad-3cf4-466f-a3fd-86714e7cba1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1415311458-172.17.0.17-1597524844659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33915,DS-a791a0d7-c51c-40c2-ba2b-825665067b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-f24e8230-65f3-4b50-8a79-37a72a40234a,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-47d43097-b068-4b70-8b0e-0e6a7f11b8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-39d3ac04-6af8-4860-bfd6-84e7b31eb545,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-09a15414-f364-4af9-bb29-27499751babd,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-9256d879-bdae-4b7f-b29c-96fb2a97296c,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-3b5d953f-55bd-45d6-bdc2-3246b681c0a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-8e1a11bc-4e20-4712-99af-d011698ed65c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1415311458-172.17.0.17-1597524844659:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33915,DS-a791a0d7-c51c-40c2-ba2b-825665067b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42563,DS-f24e8230-65f3-4b50-8a79-37a72a40234a,DISK], DatanodeInfoWithStorage[127.0.0.1:34696,DS-47d43097-b068-4b70-8b0e-0e6a7f11b8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-39d3ac04-6af8-4860-bfd6-84e7b31eb545,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-09a15414-f364-4af9-bb29-27499751babd,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-9256d879-bdae-4b7f-b29c-96fb2a97296c,DISK], DatanodeInfoWithStorage[127.0.0.1:34893,DS-3b5d953f-55bd-45d6-bdc2-3246b681c0a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-8e1a11bc-4e20-4712-99af-d011698ed65c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-595739441-172.17.0.17-1597524977620:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34703,DS-73207621-536d-468a-b3a7-cf21188b3790,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-05e7faea-f621-42b4-8867-ed0e0576e943,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-18f95883-d5f7-4f59-a099-d1c851dfb19a,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-4cb269b0-529d-4447-84ea-f8961edc58f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-aa52976e-668a-4359-9bfc-57b22340fecc,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-e534c6ef-9e2c-4a59-9c56-d2dd801b4461,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-b8b3096f-aa65-4593-b7d7-6cdd656c4ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-38927d56-f89f-4b93-a648-45d67bfb3031,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-595739441-172.17.0.17-1597524977620:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34703,DS-73207621-536d-468a-b3a7-cf21188b3790,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-05e7faea-f621-42b4-8867-ed0e0576e943,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-18f95883-d5f7-4f59-a099-d1c851dfb19a,DISK], DatanodeInfoWithStorage[127.0.0.1:40787,DS-4cb269b0-529d-4447-84ea-f8961edc58f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-aa52976e-668a-4359-9bfc-57b22340fecc,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-e534c6ef-9e2c-4a59-9c56-d2dd801b4461,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-b8b3096f-aa65-4593-b7d7-6cdd656c4ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:38641,DS-38927d56-f89f-4b93-a648-45d67bfb3031,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-786443586-172.17.0.17-1597525114050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34990,DS-5a9c6b22-9467-4371-a5e1-bd08c7149027,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-9685f039-7a83-491f-9542-21cba14e99ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-1ea37cfd-21d9-4048-93ee-c385847eafa7,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-3eb843b6-fa99-4f0f-940a-7eb08ab9c67d,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-a91528ea-a7af-408e-8583-81ebd4d33500,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-6ddd282f-810d-4e06-a66f-9867e6d4235e,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-0e833a7f-a2e9-403c-825a-811f8843d94a,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-cc551767-d601-49e3-bc8c-efa8a487c267,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-786443586-172.17.0.17-1597525114050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34990,DS-5a9c6b22-9467-4371-a5e1-bd08c7149027,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-9685f039-7a83-491f-9542-21cba14e99ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40113,DS-1ea37cfd-21d9-4048-93ee-c385847eafa7,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-3eb843b6-fa99-4f0f-940a-7eb08ab9c67d,DISK], DatanodeInfoWithStorage[127.0.0.1:43861,DS-a91528ea-a7af-408e-8583-81ebd4d33500,DISK], DatanodeInfoWithStorage[127.0.0.1:33397,DS-6ddd282f-810d-4e06-a66f-9867e6d4235e,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-0e833a7f-a2e9-403c-825a-811f8843d94a,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-cc551767-d601-49e3-bc8c-efa8a487c267,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cache.revocation.polling.ms
component: hdfs:DataNode
v1: 50
v2: 500
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-29906886-172.17.0.17-1597525162810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46819,DS-8bb81046-b18a-42f7-8fab-7f2193107a25,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-f544cc3c-97ef-4187-a6e2-f3a3e2529802,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-f6c4082d-a935-44e6-9787-59fe97e7b568,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-fd43510d-ede1-484a-a387-b9da1917db20,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-a083e3fd-84dc-4d1a-9970-abc3285fb5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-0d525e8b-104c-49b3-be5c-51375249fd19,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-d03a4930-8c22-443d-a570-08621414254d,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-289c32e7-2cfc-468d-9eea-2130fdbde266,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-29906886-172.17.0.17-1597525162810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46819,DS-8bb81046-b18a-42f7-8fab-7f2193107a25,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-f544cc3c-97ef-4187-a6e2-f3a3e2529802,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-f6c4082d-a935-44e6-9787-59fe97e7b568,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-fd43510d-ede1-484a-a387-b9da1917db20,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-a083e3fd-84dc-4d1a-9970-abc3285fb5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-0d525e8b-104c-49b3-be5c-51375249fd19,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-d03a4930-8c22-443d-a570-08621414254d,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-289c32e7-2cfc-468d-9eea-2130fdbde266,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6853
