reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-849054947-172.17.0.4-1597468561825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35146,DS-007c2d3a-bae4-4e47-a48b-305a57889c60,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-577577c8-355c-4c1b-a5a5-e3937a684cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-38ae0a91-348e-411a-adef-411605365b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-2ea25052-766c-49ab-a0fc-92f7c76e4ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-ddb87550-41db-4490-8eb6-1b7011ed9d09,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-24b2eaed-154b-493d-9301-0a7029543c95,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-c7a74389-0fd5-402f-ac3f-ed90e3db6af9,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-a2a50b61-4612-4a80-89b9-acf2ab3889ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-849054947-172.17.0.4-1597468561825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35146,DS-007c2d3a-bae4-4e47-a48b-305a57889c60,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-577577c8-355c-4c1b-a5a5-e3937a684cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:37843,DS-38ae0a91-348e-411a-adef-411605365b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-2ea25052-766c-49ab-a0fc-92f7c76e4ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:35963,DS-ddb87550-41db-4490-8eb6-1b7011ed9d09,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-24b2eaed-154b-493d-9301-0a7029543c95,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-c7a74389-0fd5-402f-ac3f-ed90e3db6af9,DISK], DatanodeInfoWithStorage[127.0.0.1:42265,DS-a2a50b61-4612-4a80-89b9-acf2ab3889ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1155246906-172.17.0.4-1597468597160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38582,DS-f9f4b8d2-bf00-42ec-a62a-43dcadb9bef3,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-0b47a4ca-68e8-4505-9e31-9741f9e63c48,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-5cb3af1f-647c-4cf8-894a-de1a22469f60,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-e52d8f37-336d-4bd2-bd59-3b09735ec915,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-5edcb401-4092-47a6-bff0-7bd5dcf19782,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-84ab4b1c-724a-4995-bdc3-b06e43a2af18,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-90d6d140-6a59-42a6-a914-500c138f0188,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-49873fdd-e514-4cf0-8783-c3da2e723d24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1155246906-172.17.0.4-1597468597160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38582,DS-f9f4b8d2-bf00-42ec-a62a-43dcadb9bef3,DISK], DatanodeInfoWithStorage[127.0.0.1:39218,DS-0b47a4ca-68e8-4505-9e31-9741f9e63c48,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-5cb3af1f-647c-4cf8-894a-de1a22469f60,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-e52d8f37-336d-4bd2-bd59-3b09735ec915,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-5edcb401-4092-47a6-bff0-7bd5dcf19782,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-84ab4b1c-724a-4995-bdc3-b06e43a2af18,DISK], DatanodeInfoWithStorage[127.0.0.1:41689,DS-90d6d140-6a59-42a6-a914-500c138f0188,DISK], DatanodeInfoWithStorage[127.0.0.1:44120,DS-49873fdd-e514-4cf0-8783-c3da2e723d24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1857451307-172.17.0.4-1597469043804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44217,DS-a96ced09-99b8-48ed-841e-8323815e2b86,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-0968ace3-0fd7-4236-b18e-1afa23cce822,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-108f36e4-7054-4e95-b047-c05267d1601e,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-0f9ecc40-26fe-4128-bed0-5e208532e91e,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-03970d03-d8c9-42b7-b161-a245aebe14cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-d0b494a8-3645-4521-b86d-e46f34029d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-c9949e51-f445-4921-b89c-1cf9201eda7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-03fe5f1a-f5bf-4d89-bffa-cb6c947307f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1857451307-172.17.0.4-1597469043804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44217,DS-a96ced09-99b8-48ed-841e-8323815e2b86,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-0968ace3-0fd7-4236-b18e-1afa23cce822,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-108f36e4-7054-4e95-b047-c05267d1601e,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-0f9ecc40-26fe-4128-bed0-5e208532e91e,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-03970d03-d8c9-42b7-b161-a245aebe14cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-d0b494a8-3645-4521-b86d-e46f34029d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38998,DS-c9949e51-f445-4921-b89c-1cf9201eda7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-03fe5f1a-f5bf-4d89-bffa-cb6c947307f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-337025024-172.17.0.4-1597469790820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37108,DS-c3335719-b178-481c-8f5c-4b803cef088e,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-ab5bec2a-5cf9-4404-8410-01800bc1b183,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-35630250-a80a-44e5-aba0-388e9e1f84bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-99c371d7-3bc9-4322-adb1-ee92dad36d46,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-11996a54-83c9-45b0-8c4c-62cebce332e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-457f9c98-e925-42fd-8bb7-60d07115c814,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-7bb641f0-67ec-4559-a820-71c83b93d2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-51b676be-8424-4581-9a21-f4bdbe6b3780,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-337025024-172.17.0.4-1597469790820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37108,DS-c3335719-b178-481c-8f5c-4b803cef088e,DISK], DatanodeInfoWithStorage[127.0.0.1:34208,DS-ab5bec2a-5cf9-4404-8410-01800bc1b183,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-35630250-a80a-44e5-aba0-388e9e1f84bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-99c371d7-3bc9-4322-adb1-ee92dad36d46,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-11996a54-83c9-45b0-8c4c-62cebce332e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-457f9c98-e925-42fd-8bb7-60d07115c814,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-7bb641f0-67ec-4559-a820-71c83b93d2ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-51b676be-8424-4581-9a21-f4bdbe6b3780,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1217898257-172.17.0.4-1597469968604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35939,DS-e8ddabce-d2b2-47be-b782-05bb4e6b621e,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-8eb0a0fa-e940-4f98-97e9-b3578490817a,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-ac7d8e1f-087e-4693-8e4b-050e1caad8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-bc2aa783-5766-4a69-bc0a-5a657780c02f,DISK], DatanodeInfoWithStorage[127.0.0.1:45392,DS-d16f4700-ee25-4bb7-97be-7f42476b9216,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-5b1f211c-62a6-4473-8118-af588b42f21e,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-d133fe3f-619c-4ecb-acc3-73bcab7c40f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-bbbffbd6-8f19-4d04-8544-7bb638a1b894,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1217898257-172.17.0.4-1597469968604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35939,DS-e8ddabce-d2b2-47be-b782-05bb4e6b621e,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-8eb0a0fa-e940-4f98-97e9-b3578490817a,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-ac7d8e1f-087e-4693-8e4b-050e1caad8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38179,DS-bc2aa783-5766-4a69-bc0a-5a657780c02f,DISK], DatanodeInfoWithStorage[127.0.0.1:45392,DS-d16f4700-ee25-4bb7-97be-7f42476b9216,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-5b1f211c-62a6-4473-8118-af588b42f21e,DISK], DatanodeInfoWithStorage[127.0.0.1:41458,DS-d133fe3f-619c-4ecb-acc3-73bcab7c40f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-bbbffbd6-8f19-4d04-8544-7bb638a1b894,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006098271-172.17.0.4-1597469997621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34527,DS-eee83733-7b41-4fc4-939f-0ba7960ce934,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-b43422d7-6824-4466-99ed-48462ea301c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-ac90b53b-447a-43f6-a289-8c6af11b35ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-b9e351e7-99e2-4b98-b9a9-6ef5d1d34837,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-6fea3bac-e0f3-4cbf-b96c-ed90ab2414f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-5f4eac56-663b-42c0-9b89-37b48a396aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-52aaf88f-d9a5-415c-b96e-cfa2440a8b09,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-d02805f8-4c90-49ed-b27e-2a8628c055e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2006098271-172.17.0.4-1597469997621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34527,DS-eee83733-7b41-4fc4-939f-0ba7960ce934,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-b43422d7-6824-4466-99ed-48462ea301c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-ac90b53b-447a-43f6-a289-8c6af11b35ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36374,DS-b9e351e7-99e2-4b98-b9a9-6ef5d1d34837,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-6fea3bac-e0f3-4cbf-b96c-ed90ab2414f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-5f4eac56-663b-42c0-9b89-37b48a396aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-52aaf88f-d9a5-415c-b96e-cfa2440a8b09,DISK], DatanodeInfoWithStorage[127.0.0.1:46471,DS-d02805f8-4c90-49ed-b27e-2a8628c055e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-100990473-172.17.0.4-1597470115703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40255,DS-959ca6e5-9233-438f-b19c-aa4656b56372,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-31f0637f-11ed-4c45-83e7-dc3280409c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-a1097d5a-9b9d-4be5-9af4-6fb5df79f9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-d2b73469-0caf-44bb-91b9-8be1c8dc2e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-5ac688d4-9692-4bb5-9287-651724a06780,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-724baf03-6873-413a-855f-55c7d663bd10,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-f794ade3-8727-4bab-8bde-5d2e47bfe442,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-ccff3848-e5e9-4c4d-886d-2b63d8a37ca3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-100990473-172.17.0.4-1597470115703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40255,DS-959ca6e5-9233-438f-b19c-aa4656b56372,DISK], DatanodeInfoWithStorage[127.0.0.1:39900,DS-31f0637f-11ed-4c45-83e7-dc3280409c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-a1097d5a-9b9d-4be5-9af4-6fb5df79f9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-d2b73469-0caf-44bb-91b9-8be1c8dc2e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-5ac688d4-9692-4bb5-9287-651724a06780,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-724baf03-6873-413a-855f-55c7d663bd10,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-f794ade3-8727-4bab-8bde-5d2e47bfe442,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-ccff3848-e5e9-4c4d-886d-2b63d8a37ca3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1994888074-172.17.0.4-1597470476694:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38525,DS-48dcd661-92d2-4f00-a516-4371c78ff178,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-587460d3-6d4b-4145-b295-1f976644546b,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-e50a2488-fcf1-4952-84cc-25ab5fba5801,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-b4a80993-1f09-406e-8a0e-d666d6103381,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-90d425f2-8c21-44ad-88a6-b201c82c8828,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-f5bbceac-f781-43b2-9e74-804becd50c42,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-c68a9e6b-685d-4bf2-ad62-220891178e81,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-ca906fcf-59bb-4503-97de-827d29333c18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1994888074-172.17.0.4-1597470476694:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38525,DS-48dcd661-92d2-4f00-a516-4371c78ff178,DISK], DatanodeInfoWithStorage[127.0.0.1:40315,DS-587460d3-6d4b-4145-b295-1f976644546b,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-e50a2488-fcf1-4952-84cc-25ab5fba5801,DISK], DatanodeInfoWithStorage[127.0.0.1:46417,DS-b4a80993-1f09-406e-8a0e-d666d6103381,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-90d425f2-8c21-44ad-88a6-b201c82c8828,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-f5bbceac-f781-43b2-9e74-804becd50c42,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-c68a9e6b-685d-4bf2-ad62-220891178e81,DISK], DatanodeInfoWithStorage[127.0.0.1:36759,DS-ca906fcf-59bb-4503-97de-827d29333c18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1084260407-172.17.0.4-1597470627941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40526,DS-e928e8ab-587e-4521-aee7-2146d36a9ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-e855bbfc-5fd6-464c-9729-faf3aaa4b683,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-07c83d7f-29cd-4063-b94e-c890762f6ded,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-93c2f224-1d8f-454a-a449-7c71f0eb56ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-0047c0ee-0526-4875-9f5d-a3c80b823b13,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-8d8fbaae-c71f-4ed0-9ee4-84e25edae480,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-d6d94ee3-6a8b-4600-9632-6ac20d5a2792,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-1ad11a5a-dc86-49c8-801b-40a410196f01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1084260407-172.17.0.4-1597470627941:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40526,DS-e928e8ab-587e-4521-aee7-2146d36a9ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:41116,DS-e855bbfc-5fd6-464c-9729-faf3aaa4b683,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-07c83d7f-29cd-4063-b94e-c890762f6ded,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-93c2f224-1d8f-454a-a449-7c71f0eb56ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-0047c0ee-0526-4875-9f5d-a3c80b823b13,DISK], DatanodeInfoWithStorage[127.0.0.1:38959,DS-8d8fbaae-c71f-4ed0-9ee4-84e25edae480,DISK], DatanodeInfoWithStorage[127.0.0.1:35265,DS-d6d94ee3-6a8b-4600-9632-6ac20d5a2792,DISK], DatanodeInfoWithStorage[127.0.0.1:46647,DS-1ad11a5a-dc86-49c8-801b-40a410196f01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1921625431-172.17.0.4-1597470741450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37887,DS-4e71da0f-0720-49ad-971d-4b0858e6f22f,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-b193b788-1239-4391-a42d-121ca8d3f43a,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-10537c6e-9d28-4200-8f88-52910bc6fae5,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-799ee127-0a82-4e5a-b58f-c006dfe2a255,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-36f215e1-e4f0-4b52-994f-6208bddd0e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-582552e4-8026-491b-bd85-f5795fbf4542,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-bab7473c-9a54-459d-a729-ee2d37f07f34,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-cd1cbaa2-c395-43e8-9981-0d2ed7acc2be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1921625431-172.17.0.4-1597470741450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37887,DS-4e71da0f-0720-49ad-971d-4b0858e6f22f,DISK], DatanodeInfoWithStorage[127.0.0.1:40770,DS-b193b788-1239-4391-a42d-121ca8d3f43a,DISK], DatanodeInfoWithStorage[127.0.0.1:42054,DS-10537c6e-9d28-4200-8f88-52910bc6fae5,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-799ee127-0a82-4e5a-b58f-c006dfe2a255,DISK], DatanodeInfoWithStorage[127.0.0.1:41061,DS-36f215e1-e4f0-4b52-994f-6208bddd0e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-582552e4-8026-491b-bd85-f5795fbf4542,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-bab7473c-9a54-459d-a729-ee2d37f07f34,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-cd1cbaa2-c395-43e8-9981-0d2ed7acc2be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2117776061-172.17.0.4-1597470781609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41430,DS-5343fac2-3373-4a54-bc4a-89bf3a3e6e23,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-f83489a5-857c-48c3-af71-53c012013000,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-adc1d595-216a-4fdc-8191-2cda89a536b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-e541d6b0-7df6-4f9b-be3a-1c22df3318f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-36dbabf2-9bc0-41b3-8a3b-76a6b6afb834,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-5ea6e5de-7ec9-48ba-b84a-8d84a411fcca,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-e67e0d8e-8852-4539-9bc3-002d4c87e2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-c272f325-9312-4a85-8a3f-776e46e15e1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2117776061-172.17.0.4-1597470781609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41430,DS-5343fac2-3373-4a54-bc4a-89bf3a3e6e23,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-f83489a5-857c-48c3-af71-53c012013000,DISK], DatanodeInfoWithStorage[127.0.0.1:42367,DS-adc1d595-216a-4fdc-8191-2cda89a536b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44324,DS-e541d6b0-7df6-4f9b-be3a-1c22df3318f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-36dbabf2-9bc0-41b3-8a3b-76a6b6afb834,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-5ea6e5de-7ec9-48ba-b84a-8d84a411fcca,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-e67e0d8e-8852-4539-9bc3-002d4c87e2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39837,DS-c272f325-9312-4a85-8a3f-776e46e15e1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-369489813-172.17.0.4-1597471044047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42138,DS-d4a7ffa3-3eff-4e45-a26f-3a882e364147,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-acc8373a-36d4-4773-8f2e-dacb0ea8b0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41658,DS-b67957f8-06cd-447a-ba0e-3016cd00b446,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-f543327f-ceb7-4aef-9ce8-06385b1b07e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-7d5d6e21-21b1-4296-88fc-a1295d915151,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-1b78e146-d4aa-41fa-bf0b-6c9098244e95,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-1e976c8e-b239-44b4-8c82-a93952a4c2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-a6682fbc-e6b6-4c42-844d-214f58487174,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-369489813-172.17.0.4-1597471044047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42138,DS-d4a7ffa3-3eff-4e45-a26f-3a882e364147,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-acc8373a-36d4-4773-8f2e-dacb0ea8b0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41658,DS-b67957f8-06cd-447a-ba0e-3016cd00b446,DISK], DatanodeInfoWithStorage[127.0.0.1:40908,DS-f543327f-ceb7-4aef-9ce8-06385b1b07e9,DISK], DatanodeInfoWithStorage[127.0.0.1:40924,DS-7d5d6e21-21b1-4296-88fc-a1295d915151,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-1b78e146-d4aa-41fa-bf0b-6c9098244e95,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-1e976c8e-b239-44b4-8c82-a93952a4c2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-a6682fbc-e6b6-4c42-844d-214f58487174,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-559486338-172.17.0.4-1597471319191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46675,DS-00cae687-204a-4506-9dd2-11537cd46a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-64d488f5-08a8-456b-a7f6-f0db6d292298,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-b33310cc-416d-4fd0-ab65-c5e7860689e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-ea40f538-c8a9-4f9c-9b27-cfefad458f14,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-680042a5-5d7f-40b1-b1e3-bd5654fa0058,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-062cc7e3-f9cf-4526-85f0-e13256e8d96d,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-181b977f-ca6d-4d90-bf01-248937580e37,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-c46ad571-6be7-4d38-af34-b996b12cb70b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-559486338-172.17.0.4-1597471319191:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46675,DS-00cae687-204a-4506-9dd2-11537cd46a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:44374,DS-64d488f5-08a8-456b-a7f6-f0db6d292298,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-b33310cc-416d-4fd0-ab65-c5e7860689e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34442,DS-ea40f538-c8a9-4f9c-9b27-cfefad458f14,DISK], DatanodeInfoWithStorage[127.0.0.1:37199,DS-680042a5-5d7f-40b1-b1e3-bd5654fa0058,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-062cc7e3-f9cf-4526-85f0-e13256e8d96d,DISK], DatanodeInfoWithStorage[127.0.0.1:43767,DS-181b977f-ca6d-4d90-bf01-248937580e37,DISK], DatanodeInfoWithStorage[127.0.0.1:45480,DS-c46ad571-6be7-4d38-af34-b996b12cb70b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1809570792-172.17.0.4-1597471480388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37097,DS-642d6e79-9624-43b6-bae9-e471e631f01c,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-73708473-79f6-42c5-8160-07f6e997fd25,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-737c8d09-d376-465d-ad23-6b033c03f542,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-1f881a00-705d-41cb-9cb5-cdfa50938497,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-d32bfb13-f0d0-44cf-b3c4-6b30b00edf29,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-6593c675-d2e5-4956-8634-e4666fc8af97,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-f2efad9a-90fc-45a1-b81c-e751b115e0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-57c9c0d2-4e05-4891-8091-2c48719d9307,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1809570792-172.17.0.4-1597471480388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37097,DS-642d6e79-9624-43b6-bae9-e471e631f01c,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-73708473-79f6-42c5-8160-07f6e997fd25,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-737c8d09-d376-465d-ad23-6b033c03f542,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-1f881a00-705d-41cb-9cb5-cdfa50938497,DISK], DatanodeInfoWithStorage[127.0.0.1:44942,DS-d32bfb13-f0d0-44cf-b3c4-6b30b00edf29,DISK], DatanodeInfoWithStorage[127.0.0.1:39319,DS-6593c675-d2e5-4956-8634-e4666fc8af97,DISK], DatanodeInfoWithStorage[127.0.0.1:42135,DS-f2efad9a-90fc-45a1-b81c-e751b115e0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-57c9c0d2-4e05-4891-8091-2c48719d9307,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-668044397-172.17.0.4-1597471547467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42618,DS-8f500d6b-127c-4d2d-a151-68a967ed4f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-d1bfc2f1-d53d-4735-ab8c-b0cbc65ff2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-7ba6564c-d737-4dc8-940e-554654038d38,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-cfc07166-6097-4cef-8714-a9225f6b1688,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-ba8cfb52-94ee-408b-b51e-8aa29dc7a056,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-b935083e-5eb5-4bf0-94dd-09bcec62da5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-b6178f3d-ad04-495b-b4a7-a7a5f9f72e94,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-7f90a4d8-68c0-4242-b1ce-7e73b03b1f50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-668044397-172.17.0.4-1597471547467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42618,DS-8f500d6b-127c-4d2d-a151-68a967ed4f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-d1bfc2f1-d53d-4735-ab8c-b0cbc65ff2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-7ba6564c-d737-4dc8-940e-554654038d38,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-cfc07166-6097-4cef-8714-a9225f6b1688,DISK], DatanodeInfoWithStorage[127.0.0.1:38566,DS-ba8cfb52-94ee-408b-b51e-8aa29dc7a056,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-b935083e-5eb5-4bf0-94dd-09bcec62da5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-b6178f3d-ad04-495b-b4a7-a7a5f9f72e94,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-7f90a4d8-68c0-4242-b1ce-7e73b03b1f50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-929161654-172.17.0.4-1597471852924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44048,DS-e530af79-e6e3-4fbb-8bb0-314c7e36925f,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-846366d6-6c2f-405c-b354-332a070a231c,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-f52d685d-14cf-4da4-be55-97889202aa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-53a7bf47-cd8f-450f-9f8a-a8f3f2d63396,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-5203119f-2af6-4ac3-a774-4ea7692f83ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-11966609-222f-4460-a263-ac134307c144,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-5b79ae14-f9d7-4232-9ff5-c0482437f34f,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-dcf40c92-6096-4b3e-b97f-8dba9216c69d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-929161654-172.17.0.4-1597471852924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44048,DS-e530af79-e6e3-4fbb-8bb0-314c7e36925f,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-846366d6-6c2f-405c-b354-332a070a231c,DISK], DatanodeInfoWithStorage[127.0.0.1:41227,DS-f52d685d-14cf-4da4-be55-97889202aa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-53a7bf47-cd8f-450f-9f8a-a8f3f2d63396,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-5203119f-2af6-4ac3-a774-4ea7692f83ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-11966609-222f-4460-a263-ac134307c144,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-5b79ae14-f9d7-4232-9ff5-c0482437f34f,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-dcf40c92-6096-4b3e-b97f-8dba9216c69d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-54362642-172.17.0.4-1597472050944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37250,DS-6b3c8140-caf1-404d-875a-cf5e9b488e36,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-d3843734-0fa0-44ee-bec0-127a016c1429,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-e89a009b-d673-45f3-95d9-656e566d7395,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-5aad7d0d-ce88-4cb3-9e2a-20ea452d65ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-9ba0e7f0-8ee9-4a6b-92e8-b78ff65fe5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-7a8eab2e-31e0-4c02-b17e-bdf826e4a7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-40158fd8-5114-4f2c-b7f1-82fd7dbdd9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-d918b761-b634-4d34-9c55-d1177147864b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-54362642-172.17.0.4-1597472050944:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37250,DS-6b3c8140-caf1-404d-875a-cf5e9b488e36,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-d3843734-0fa0-44ee-bec0-127a016c1429,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-e89a009b-d673-45f3-95d9-656e566d7395,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-5aad7d0d-ce88-4cb3-9e2a-20ea452d65ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33837,DS-9ba0e7f0-8ee9-4a6b-92e8-b78ff65fe5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38824,DS-7a8eab2e-31e0-4c02-b17e-bdf826e4a7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-40158fd8-5114-4f2c-b7f1-82fd7dbdd9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-d918b761-b634-4d34-9c55-d1177147864b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-846663930-172.17.0.4-1597472313637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45579,DS-c8715a56-a764-4e96-99ff-af17a2c59051,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-98c54262-39ee-44d4-9c1e-af9c333716f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-f077fc11-d435-41ef-b45a-d7dd0fbd62f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-9c6eaf16-eaf2-4636-b59a-f3c16e320a30,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-7f8602b4-2066-4d96-9a3d-d438b525aa65,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-23065623-22f9-4280-892f-eea4e5d8d8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-d403a078-9c37-4147-b653-4b180d3546cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-f12ac900-1be7-4ae9-b8f8-d5de6781338b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-846663930-172.17.0.4-1597472313637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45579,DS-c8715a56-a764-4e96-99ff-af17a2c59051,DISK], DatanodeInfoWithStorage[127.0.0.1:40413,DS-98c54262-39ee-44d4-9c1e-af9c333716f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37126,DS-f077fc11-d435-41ef-b45a-d7dd0fbd62f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-9c6eaf16-eaf2-4636-b59a-f3c16e320a30,DISK], DatanodeInfoWithStorage[127.0.0.1:41433,DS-7f8602b4-2066-4d96-9a3d-d438b525aa65,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-23065623-22f9-4280-892f-eea4e5d8d8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-d403a078-9c37-4147-b653-4b180d3546cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-f12ac900-1be7-4ae9-b8f8-d5de6781338b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-198608092-172.17.0.4-1597472841611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42908,DS-899c0c68-bc6e-4737-8864-5335d9867562,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-cbb60552-2c5e-4f32-a5d9-3fb5b9d7dce2,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-920a05a9-1fbe-46d3-97b6-78862a9314eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-ad2a5cba-ebfc-4d79-b603-4d4a938dd507,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-9dfd9f5d-fe7d-4848-8922-4d1a41a2ebd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-f8392e30-15d5-48d2-a0d1-568b5699c54c,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-1c14e991-5bd9-4d89-8c14-ac9a4eeac9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-f74012a1-ea2e-4170-97a8-68f05da5f743,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-198608092-172.17.0.4-1597472841611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42908,DS-899c0c68-bc6e-4737-8864-5335d9867562,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-cbb60552-2c5e-4f32-a5d9-3fb5b9d7dce2,DISK], DatanodeInfoWithStorage[127.0.0.1:37914,DS-920a05a9-1fbe-46d3-97b6-78862a9314eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34470,DS-ad2a5cba-ebfc-4d79-b603-4d4a938dd507,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-9dfd9f5d-fe7d-4848-8922-4d1a41a2ebd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-f8392e30-15d5-48d2-a0d1-568b5699c54c,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-1c14e991-5bd9-4d89-8c14-ac9a4eeac9e6,DISK], DatanodeInfoWithStorage[127.0.0.1:44666,DS-f74012a1-ea2e-4170-97a8-68f05da5f743,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 20
v2: 20s
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2005506397-172.17.0.4-1597473659055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45637,DS-8eccb129-8a07-4104-8838-b0a591b4dc07,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-ced24593-ca13-4761-a3b9-da3458d45224,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-10b3fbbf-765c-49c4-b608-f9d93fe2283c,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-4ee9fa0e-5cf8-4350-917a-2eafc11719be,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-77869c75-476a-4886-b748-e5027e9024be,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-80bf322b-6bed-4812-a4bf-3c9f5ee0ef1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-4248a886-5530-4a94-a444-59d51a7f06b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-1e5e792c-05dc-4715-b09b-c0e549debb5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2005506397-172.17.0.4-1597473659055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45637,DS-8eccb129-8a07-4104-8838-b0a591b4dc07,DISK], DatanodeInfoWithStorage[127.0.0.1:32952,DS-ced24593-ca13-4761-a3b9-da3458d45224,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-10b3fbbf-765c-49c4-b608-f9d93fe2283c,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-4ee9fa0e-5cf8-4350-917a-2eafc11719be,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-77869c75-476a-4886-b748-e5027e9024be,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-80bf322b-6bed-4812-a4bf-3c9f5ee0ef1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-4248a886-5530-4a94-a444-59d51a7f06b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-1e5e792c-05dc-4715-b09b-c0e549debb5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5582
