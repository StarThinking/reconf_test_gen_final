reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 100
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 100
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1127662003-172.17.0.15-1597269613562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36055,DS-57be5d29-3f81-4dab-8fc4-6623aa58b8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-7e266ed6-8e8f-43a9-b279-af4ea3463a43,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-57a42081-c7b5-49b2-be72-dc16e3b89ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-1a5ed9dc-38c7-4307-89e2-1048b5482a53,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-7c9946fb-ad19-43e1-8328-eaf3e45f394e,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-92bb4d87-6534-4d2a-968a-1cadecfaa873,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-7c21dba5-da2a-4c9b-a4c4-33cbf1c3e9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-af1292a9-0de8-4422-989a-7f0c21abd19d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1127662003-172.17.0.15-1597269613562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36055,DS-57be5d29-3f81-4dab-8fc4-6623aa58b8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34714,DS-7e266ed6-8e8f-43a9-b279-af4ea3463a43,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-57a42081-c7b5-49b2-be72-dc16e3b89ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:35007,DS-1a5ed9dc-38c7-4307-89e2-1048b5482a53,DISK], DatanodeInfoWithStorage[127.0.0.1:37953,DS-7c9946fb-ad19-43e1-8328-eaf3e45f394e,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-92bb4d87-6534-4d2a-968a-1cadecfaa873,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-7c21dba5-da2a-4c9b-a4c4-33cbf1c3e9e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-af1292a9-0de8-4422-989a-7f0c21abd19d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 100
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-69000326-172.17.0.15-1597269689548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44411,DS-e32a5db0-b7cc-41e2-91c8-e417b01da9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-480ecd4b-8445-4459-96cf-c62ac219323f,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-1d8b855e-5853-4c9f-b372-3e1d91cb4762,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-71284903-5dc2-4925-b656-0e54427a7a02,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-61b6917c-ee04-4c9e-8002-1271c942c92a,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-67a6bfbb-ad0b-408d-8273-3be88fea8429,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-3d77e0df-8ee6-4d21-9da2-50491ebee984,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-f6d1c8ee-ee3d-4fbd-8691-7a2fbf89b28b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-69000326-172.17.0.15-1597269689548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44411,DS-e32a5db0-b7cc-41e2-91c8-e417b01da9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-480ecd4b-8445-4459-96cf-c62ac219323f,DISK], DatanodeInfoWithStorage[127.0.0.1:42332,DS-1d8b855e-5853-4c9f-b372-3e1d91cb4762,DISK], DatanodeInfoWithStorage[127.0.0.1:40703,DS-71284903-5dc2-4925-b656-0e54427a7a02,DISK], DatanodeInfoWithStorage[127.0.0.1:43236,DS-61b6917c-ee04-4c9e-8002-1271c942c92a,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-67a6bfbb-ad0b-408d-8273-3be88fea8429,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-3d77e0df-8ee6-4d21-9da2-50491ebee984,DISK], DatanodeInfoWithStorage[127.0.0.1:40320,DS-f6d1c8ee-ee3d-4fbd-8691-7a2fbf89b28b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 100
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1050353202-172.17.0.15-1597269915946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36482,DS-a73a7d26-563a-4f02-8bc5-a8e475244e44,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-5395a994-1404-4e2c-80c4-b3d74097d551,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-f6a42d34-c7b7-4764-b843-8e94dff58a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-9e6c3f4e-4718-4cea-a2bc-bd72c861f62c,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-e23297e8-e2de-4d29-8d15-cea4822a096e,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-7f275da9-adb0-459e-9613-92946852bcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-8d94b02c-d4d1-4043-be12-87ba1c544c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-a18dfbfd-80a7-4197-ba18-8492761e87fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1050353202-172.17.0.15-1597269915946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36482,DS-a73a7d26-563a-4f02-8bc5-a8e475244e44,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-5395a994-1404-4e2c-80c4-b3d74097d551,DISK], DatanodeInfoWithStorage[127.0.0.1:45012,DS-f6a42d34-c7b7-4764-b843-8e94dff58a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37040,DS-9e6c3f4e-4718-4cea-a2bc-bd72c861f62c,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-e23297e8-e2de-4d29-8d15-cea4822a096e,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-7f275da9-adb0-459e-9613-92946852bcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-8d94b02c-d4d1-4043-be12-87ba1c544c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40962,DS-a18dfbfd-80a7-4197-ba18-8492761e87fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 100
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-881180914-172.17.0.15-1597269989866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43252,DS-488484d1-5a3b-42ce-8faa-2a746e4cf828,DISK], DatanodeInfoWithStorage[127.0.0.1:39460,DS-e81cda6b-6c5f-4a53-a75a-97c058feff87,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-b410160c-327c-40b4-be7e-08b0f35a23c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-0cb03ff0-e802-464e-960c-11dc61159616,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-4334bda7-d1d8-46e9-a76a-dbf831745c07,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-7031b2d3-d3c5-4136-ab66-5c946316a43a,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-09781f2b-3a1d-456b-be66-e42c9edda255,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-b2a8ddd1-4e44-4c6a-9252-d2465a2c1f40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-881180914-172.17.0.15-1597269989866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43252,DS-488484d1-5a3b-42ce-8faa-2a746e4cf828,DISK], DatanodeInfoWithStorage[127.0.0.1:39460,DS-e81cda6b-6c5f-4a53-a75a-97c058feff87,DISK], DatanodeInfoWithStorage[127.0.0.1:38476,DS-b410160c-327c-40b4-be7e-08b0f35a23c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-0cb03ff0-e802-464e-960c-11dc61159616,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-4334bda7-d1d8-46e9-a76a-dbf831745c07,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-7031b2d3-d3c5-4136-ab66-5c946316a43a,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-09781f2b-3a1d-456b-be66-e42c9edda255,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-b2a8ddd1-4e44-4c6a-9252-d2465a2c1f40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 100
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-248931518-172.17.0.15-1597270334022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42456,DS-f7ca976e-77cc-4b18-8b4e-618c3da023e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-466b715f-0e1d-4344-8caa-e69ea4fe2157,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-262586d4-b9e6-4db1-81db-f19d864981a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-452ca7a1-ac17-4d40-a3db-0ba6987daf66,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-a25e614f-14fe-4b92-b954-acc30245cea8,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-16354966-5ba9-4db3-92c6-c99edb994768,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-08ecd6ab-a311-487b-997d-94f1afbd825a,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-6c2e04bc-8260-4a1a-9fd6-71356885a253,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-248931518-172.17.0.15-1597270334022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42456,DS-f7ca976e-77cc-4b18-8b4e-618c3da023e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32909,DS-466b715f-0e1d-4344-8caa-e69ea4fe2157,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-262586d4-b9e6-4db1-81db-f19d864981a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-452ca7a1-ac17-4d40-a3db-0ba6987daf66,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-a25e614f-14fe-4b92-b954-acc30245cea8,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-16354966-5ba9-4db3-92c6-c99edb994768,DISK], DatanodeInfoWithStorage[127.0.0.1:43766,DS-08ecd6ab-a311-487b-997d-94f1afbd825a,DISK], DatanodeInfoWithStorage[127.0.0.1:46232,DS-6c2e04bc-8260-4a1a-9fd6-71356885a253,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 100
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-807713407-172.17.0.15-1597270634462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38073,DS-75dad3f6-364e-4e85-b1ec-1053d21f11a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-6415c115-9029-4415-a671-d7b1ea7fac9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-bcdde38c-5593-4953-b327-51bad464529f,DISK], DatanodeInfoWithStorage[127.0.0.1:44845,DS-08b52d82-281e-4751-b4f4-169a9080e8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-af06de68-7e5c-4ccd-8f1a-bc850a80a3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-8cb4b41e-e9d5-46d1-b348-cfe200ea67b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-307a9eab-a71e-4028-bae0-a7129177e0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-53251d73-8d64-421e-be10-5c92d4afaf36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-807713407-172.17.0.15-1597270634462:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38073,DS-75dad3f6-364e-4e85-b1ec-1053d21f11a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33931,DS-6415c115-9029-4415-a671-d7b1ea7fac9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-bcdde38c-5593-4953-b327-51bad464529f,DISK], DatanodeInfoWithStorage[127.0.0.1:44845,DS-08b52d82-281e-4751-b4f4-169a9080e8fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37254,DS-af06de68-7e5c-4ccd-8f1a-bc850a80a3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-8cb4b41e-e9d5-46d1-b348-cfe200ea67b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-307a9eab-a71e-4028-bae0-a7129177e0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:32808,DS-53251d73-8d64-421e-be10-5c92d4afaf36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 100
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1234670448-172.17.0.15-1597270751079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44014,DS-aa035bb3-0a5e-4df7-b98b-a1da0e543ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-0dbe6cf5-2e11-46aa-b5a2-cdfb9bf7c616,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-a982db44-5128-477f-b161-150a69210475,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-b062685a-45e7-4680-8b2d-e7c5d1ee8b13,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-b7a17fbe-bd41-4e60-aaf0-b89cd0ca0c70,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-75e0a20b-4110-438a-a906-e3ea0317fa5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-daca8e6e-a738-4065-8254-44426d075b72,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-917e948a-26d2-4999-87e3-1469b30c58e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1234670448-172.17.0.15-1597270751079:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44014,DS-aa035bb3-0a5e-4df7-b98b-a1da0e543ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-0dbe6cf5-2e11-46aa-b5a2-cdfb9bf7c616,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-a982db44-5128-477f-b161-150a69210475,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-b062685a-45e7-4680-8b2d-e7c5d1ee8b13,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-b7a17fbe-bd41-4e60-aaf0-b89cd0ca0c70,DISK], DatanodeInfoWithStorage[127.0.0.1:36534,DS-75e0a20b-4110-438a-a906-e3ea0317fa5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-daca8e6e-a738-4065-8254-44426d075b72,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-917e948a-26d2-4999-87e3-1469b30c58e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 100
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-247159521-172.17.0.15-1597270829103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43711,DS-c2bdc48e-3901-408a-8133-5f25b146dfc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-999461e4-968a-43bd-a570-0d1d81ab62a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-cf0a5d65-a5fb-4ad3-977e-af99a5fdea53,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-3a3805ba-01bc-4a0b-86ad-57d80bac5904,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-a07d457d-cd20-4d13-bd93-5cf54bff4828,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-16651171-1575-4800-9b92-bb6f175923cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-86e9cc22-91be-4000-97ac-0204cb14a321,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-d000ba44-354a-4d18-b2fe-413adae7a168,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-247159521-172.17.0.15-1597270829103:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43711,DS-c2bdc48e-3901-408a-8133-5f25b146dfc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-999461e4-968a-43bd-a570-0d1d81ab62a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-cf0a5d65-a5fb-4ad3-977e-af99a5fdea53,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-3a3805ba-01bc-4a0b-86ad-57d80bac5904,DISK], DatanodeInfoWithStorage[127.0.0.1:34521,DS-a07d457d-cd20-4d13-bd93-5cf54bff4828,DISK], DatanodeInfoWithStorage[127.0.0.1:36708,DS-16651171-1575-4800-9b92-bb6f175923cc,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-86e9cc22-91be-4000-97ac-0204cb14a321,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-d000ba44-354a-4d18-b2fe-413adae7a168,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 100
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-920804723-172.17.0.15-1597271010202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33604,DS-c7cca01a-958e-4c33-8953-430f56bd4b46,DISK], DatanodeInfoWithStorage[127.0.0.1:39694,DS-5d5b4c1c-5216-489c-aa21-6c0c6d38182e,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-b2f2f8f1-88f5-49dc-b4b1-2ff12e43055c,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-4115537c-6e7a-409f-a84b-4cc0220958f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-1f097bd8-8ce4-4bb4-9485-ee48f0cf522a,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-f5cb64eb-211c-43f1-8fa4-096ccc51cdcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-98dbe5f9-79b3-4824-95aa-955a4e81688e,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-2647c7f6-555a-41a8-9e4a-9a15870b9457,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-920804723-172.17.0.15-1597271010202:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33604,DS-c7cca01a-958e-4c33-8953-430f56bd4b46,DISK], DatanodeInfoWithStorage[127.0.0.1:39694,DS-5d5b4c1c-5216-489c-aa21-6c0c6d38182e,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-b2f2f8f1-88f5-49dc-b4b1-2ff12e43055c,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-4115537c-6e7a-409f-a84b-4cc0220958f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-1f097bd8-8ce4-4bb4-9485-ee48f0cf522a,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-f5cb64eb-211c-43f1-8fa4-096ccc51cdcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-98dbe5f9-79b3-4824-95aa-955a4e81688e,DISK], DatanodeInfoWithStorage[127.0.0.1:42709,DS-2647c7f6-555a-41a8-9e4a-9a15870b9457,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 100
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1384901089-172.17.0.15-1597271118257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42295,DS-cd5467ce-85ad-4b97-9e5d-7815aaa0487c,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-06b58a97-428a-47f9-a1e0-0a82b0d2499e,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-74cbf1aa-98ec-4f5d-b863-df1aed8b0faf,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-15deb007-bec8-4d2f-97fc-803c7a825af4,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-260ff4a6-a90a-4f7d-9162-8d0e54530fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-b51eb1a0-c682-401d-8489-1aa19cb2d163,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-d3bf01f8-35dc-4d94-acc2-e0242d496a04,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-b26ec509-d97f-4eb6-966c-7d0502cdb00c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1384901089-172.17.0.15-1597271118257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42295,DS-cd5467ce-85ad-4b97-9e5d-7815aaa0487c,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-06b58a97-428a-47f9-a1e0-0a82b0d2499e,DISK], DatanodeInfoWithStorage[127.0.0.1:46308,DS-74cbf1aa-98ec-4f5d-b863-df1aed8b0faf,DISK], DatanodeInfoWithStorage[127.0.0.1:43844,DS-15deb007-bec8-4d2f-97fc-803c7a825af4,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-260ff4a6-a90a-4f7d-9162-8d0e54530fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-b51eb1a0-c682-401d-8489-1aa19cb2d163,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-d3bf01f8-35dc-4d94-acc2-e0242d496a04,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-b26ec509-d97f-4eb6-966c-7d0502cdb00c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 100
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-236928916-172.17.0.15-1597271235870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33802,DS-bcf7996c-d34d-4c7a-aa69-7c747ffe3161,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-d92f992e-3733-4a68-b7ea-4a1edf51d2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-a1ea5a9e-e0d2-4240-a8a3-c9e56a5bff63,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-289fc21f-6815-40d1-a772-6de651cc8583,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-b801bb70-7df8-4562-8a5e-aebbc4c4a166,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-588b842b-0c60-4ec1-b399-bc715caedfdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-4971cdc7-80c7-496f-be8a-c44e75be436e,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-05bb6b8e-a981-435a-849b-4fe920606b2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-236928916-172.17.0.15-1597271235870:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33802,DS-bcf7996c-d34d-4c7a-aa69-7c747ffe3161,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-d92f992e-3733-4a68-b7ea-4a1edf51d2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-a1ea5a9e-e0d2-4240-a8a3-c9e56a5bff63,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-289fc21f-6815-40d1-a772-6de651cc8583,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-b801bb70-7df8-4562-8a5e-aebbc4c4a166,DISK], DatanodeInfoWithStorage[127.0.0.1:32809,DS-588b842b-0c60-4ec1-b399-bc715caedfdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-4971cdc7-80c7-496f-be8a-c44e75be436e,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-05bb6b8e-a981-435a-849b-4fe920606b2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 100
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1398504684-172.17.0.15-1597272823215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40986,DS-af184208-b3fb-494c-8d35-9755218303e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-2a7abc15-1b38-4408-9562-21a28ffcaf56,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-5e84dce1-fdb8-4851-8f96-c48837ff75a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45370,DS-df6ea580-fb84-4a65-97c0-d1cfb0ab6e67,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-9f7dcbe4-57ef-44a6-a092-ff8c369a4d90,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-fc736e78-e4a3-4f9e-a523-185fce715de6,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-6d265d19-2d7b-4f15-8aa6-a219ee5809a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-ae4c5f59-5f40-4e1d-8b0a-e9f4bef0b439,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1398504684-172.17.0.15-1597272823215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40986,DS-af184208-b3fb-494c-8d35-9755218303e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-2a7abc15-1b38-4408-9562-21a28ffcaf56,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-5e84dce1-fdb8-4851-8f96-c48837ff75a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45370,DS-df6ea580-fb84-4a65-97c0-d1cfb0ab6e67,DISK], DatanodeInfoWithStorage[127.0.0.1:42906,DS-9f7dcbe4-57ef-44a6-a092-ff8c369a4d90,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-fc736e78-e4a3-4f9e-a523-185fce715de6,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-6d265d19-2d7b-4f15-8aa6-a219ee5809a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-ae4c5f59-5f40-4e1d-8b0a-e9f4bef0b439,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 100
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1808443625-172.17.0.15-1597272935756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39234,DS-7bd887ae-f44c-46fc-9e9d-28c98861ce17,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-b5a75b93-01b4-4973-b6aa-145e9d393f64,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-f408861e-a331-4d24-abf2-be380eab445c,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-f3f38439-2863-432d-964c-ea0c737b48bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-96a66cdd-7493-43ed-b7b4-2da2d51917fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-6e760bab-7beb-4933-ad13-0133040b5ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-b6ff4751-301e-40ba-9dbc-d81629e79ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-c9d8a8c0-f7dc-4b03-a002-a302bf002afa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1808443625-172.17.0.15-1597272935756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39234,DS-7bd887ae-f44c-46fc-9e9d-28c98861ce17,DISK], DatanodeInfoWithStorage[127.0.0.1:46389,DS-b5a75b93-01b4-4973-b6aa-145e9d393f64,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-f408861e-a331-4d24-abf2-be380eab445c,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-f3f38439-2863-432d-964c-ea0c737b48bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-96a66cdd-7493-43ed-b7b4-2da2d51917fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-6e760bab-7beb-4933-ad13-0133040b5ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-b6ff4751-301e-40ba-9dbc-d81629e79ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:37715,DS-c9d8a8c0-f7dc-4b03-a002-a302bf002afa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 100
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1628037683-172.17.0.15-1597272972041:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32868,DS-272dc7cd-0209-475a-9c1e-53ecbe5a3607,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-911bbb83-7783-4e2a-981c-797ac979d31c,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-cba3f3f2-5e1a-49b8-bd48-2cac1de30f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-e6026cb7-e693-48fe-93a2-bf42c1c11bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-8d1e927f-3ec4-4b18-8f5d-27d9952f6b61,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-0520ccb1-2021-4577-8993-2ccf0e708a00,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-04ca8785-d054-4e28-b73d-07b162b0544e,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-0ddc63f1-c831-4fef-b831-862bc0b213af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1628037683-172.17.0.15-1597272972041:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32868,DS-272dc7cd-0209-475a-9c1e-53ecbe5a3607,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-911bbb83-7783-4e2a-981c-797ac979d31c,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-cba3f3f2-5e1a-49b8-bd48-2cac1de30f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-e6026cb7-e693-48fe-93a2-bf42c1c11bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40029,DS-8d1e927f-3ec4-4b18-8f5d-27d9952f6b61,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-0520ccb1-2021-4577-8993-2ccf0e708a00,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-04ca8785-d054-4e28-b73d-07b162b0544e,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-0ddc63f1-c831-4fef-b831-862bc0b213af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 100
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-823203409-172.17.0.15-1597273086788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46054,DS-346a43bd-0d63-40af-98eb-e28afc3174a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-915a7963-c04e-48ee-9536-864e0e06618e,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-0ee8e47d-52f2-4a1d-b552-6405c20d2105,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-f3028e00-1826-4c6e-8c25-ac1546b9613c,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-ad914153-2aa0-4680-aecd-4d108c0e9bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-222cd54f-158e-4f9b-96a2-12d2db51a0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-c86fd806-59ee-44a5-a30c-9b5a6456deaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-c6ec61d3-934d-494e-a7cb-15d07045c13a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-823203409-172.17.0.15-1597273086788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46054,DS-346a43bd-0d63-40af-98eb-e28afc3174a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-915a7963-c04e-48ee-9536-864e0e06618e,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-0ee8e47d-52f2-4a1d-b552-6405c20d2105,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-f3028e00-1826-4c6e-8c25-ac1546b9613c,DISK], DatanodeInfoWithStorage[127.0.0.1:45286,DS-ad914153-2aa0-4680-aecd-4d108c0e9bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-222cd54f-158e-4f9b-96a2-12d2db51a0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38742,DS-c86fd806-59ee-44a5-a30c-9b5a6456deaf,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-c6ec61d3-934d-494e-a7cb-15d07045c13a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.storageinfo.defragment.interval.ms
component: hdfs:NameNode
v1: 100
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-953553140-172.17.0.15-1597273637550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37338,DS-b8d5875a-88f2-4fee-ba8d-1285c215ca8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-c31b6dde-a54a-468a-aaa3-f3f036d82d54,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-b88593b9-d39c-46fe-bb5e-d97ce89face8,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-3a95e906-e156-49d6-9db7-ebba73a0776d,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-6f7e1a97-10af-43af-9651-937df2322500,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-5500893e-2f88-4672-b40f-9eb211dad31f,DISK], DatanodeInfoWithStorage[127.0.0.1:36435,DS-348f7079-c147-4475-98c2-5210aa532680,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-e3ad2ca1-9297-4fec-8742-887eb533c7f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-953553140-172.17.0.15-1597273637550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37338,DS-b8d5875a-88f2-4fee-ba8d-1285c215ca8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-c31b6dde-a54a-468a-aaa3-f3f036d82d54,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-b88593b9-d39c-46fe-bb5e-d97ce89face8,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-3a95e906-e156-49d6-9db7-ebba73a0776d,DISK], DatanodeInfoWithStorage[127.0.0.1:37367,DS-6f7e1a97-10af-43af-9651-937df2322500,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-5500893e-2f88-4672-b40f-9eb211dad31f,DISK], DatanodeInfoWithStorage[127.0.0.1:36435,DS-348f7079-c147-4475-98c2-5210aa532680,DISK], DatanodeInfoWithStorage[127.0.0.1:42260,DS-e3ad2ca1-9297-4fec-8742-887eb533c7f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5641
