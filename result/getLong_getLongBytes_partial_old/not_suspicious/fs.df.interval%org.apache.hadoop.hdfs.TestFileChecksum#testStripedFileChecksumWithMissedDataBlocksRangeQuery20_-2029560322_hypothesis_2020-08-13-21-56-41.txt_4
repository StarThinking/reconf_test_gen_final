reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1641861478-172.17.0.8-1597355858562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41508,DS-736f980f-42d3-4bf9-aa72-4cf04e87260b,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-67052705-947c-4b2d-85de-cd84ae318a48,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-97df6dd6-596e-435e-a167-07df94bc46ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-72fde100-9656-46b4-91ae-cf136f1cfe31,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-fc99e441-faac-4939-b251-a75b87f72440,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-3a590535-ad16-4695-a750-527c9c85aebb,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-e59c1a1b-a382-4978-997d-073a899f27b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-d4cf683e-7284-4b5d-998d-860f7f02d7a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1641861478-172.17.0.8-1597355858562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41508,DS-736f980f-42d3-4bf9-aa72-4cf04e87260b,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-67052705-947c-4b2d-85de-cd84ae318a48,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-97df6dd6-596e-435e-a167-07df94bc46ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39512,DS-72fde100-9656-46b4-91ae-cf136f1cfe31,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-fc99e441-faac-4939-b251-a75b87f72440,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-3a590535-ad16-4695-a750-527c9c85aebb,DISK], DatanodeInfoWithStorage[127.0.0.1:34526,DS-e59c1a1b-a382-4978-997d-073a899f27b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-d4cf683e-7284-4b5d-998d-860f7f02d7a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1349675702-172.17.0.8-1597355998705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35668,DS-4623281c-4a9d-4ecb-80ae-ace88ea49cab,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-4f4ec2ce-e3bb-47f4-a125-c231d760d5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-87223880-0905-4aa9-a568-472da62c8f86,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-b981cc1f-a7fd-4dfc-bee1-9a12f2482f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-0f85e93c-565e-4bef-8252-2fe8fc0e7306,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-a7f0a19a-a492-4fa9-832e-85a35c4758b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-6cba992c-468e-4c15-b0a6-e01ae3e12d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-a687a3c4-25cd-4aaa-9d72-859e2f7d1afd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1349675702-172.17.0.8-1597355998705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35668,DS-4623281c-4a9d-4ecb-80ae-ace88ea49cab,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-4f4ec2ce-e3bb-47f4-a125-c231d760d5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40667,DS-87223880-0905-4aa9-a568-472da62c8f86,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-b981cc1f-a7fd-4dfc-bee1-9a12f2482f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-0f85e93c-565e-4bef-8252-2fe8fc0e7306,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-a7f0a19a-a492-4fa9-832e-85a35c4758b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33054,DS-6cba992c-468e-4c15-b0a6-e01ae3e12d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45695,DS-a687a3c4-25cd-4aaa-9d72-859e2f7d1afd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-470666882-172.17.0.8-1597356149575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42962,DS-b27139b1-e3f7-4eb2-80f6-955ac20bb9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-f58968b8-6560-4664-9c68-165549fb9fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-ef718682-9a1a-4964-83b7-dbe2facd1f70,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-2d7da23d-1974-4cad-84ec-7134140f0108,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-839bad1d-4c89-47d3-b71a-48473dc85210,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-e8e8a720-bf4c-4622-bb39-886357671735,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-368c6bee-2bff-4ff8-9f36-3465fc9689d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-e6667b43-b34a-4731-9260-677e4eaa98a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-470666882-172.17.0.8-1597356149575:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42962,DS-b27139b1-e3f7-4eb2-80f6-955ac20bb9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-f58968b8-6560-4664-9c68-165549fb9fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:39274,DS-ef718682-9a1a-4964-83b7-dbe2facd1f70,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-2d7da23d-1974-4cad-84ec-7134140f0108,DISK], DatanodeInfoWithStorage[127.0.0.1:38358,DS-839bad1d-4c89-47d3-b71a-48473dc85210,DISK], DatanodeInfoWithStorage[127.0.0.1:44368,DS-e8e8a720-bf4c-4622-bb39-886357671735,DISK], DatanodeInfoWithStorage[127.0.0.1:39878,DS-368c6bee-2bff-4ff8-9f36-3465fc9689d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-e6667b43-b34a-4731-9260-677e4eaa98a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-66909876-172.17.0.8-1597356184485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33246,DS-d9728892-a7fe-4f03-b811-47e2a3cd0dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-23c6af15-42f4-4174-8c75-d6fca0af9b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-2d8627b6-aafc-4796-8e20-2fba4fb90695,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-7ce85bbc-7873-4f63-995f-28be7d391794,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-a488e344-5760-4cf3-9bce-8f8357bce778,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-f7e17f41-fff5-4211-9e62-79951139a745,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-578bbbeb-c446-4d4d-b2a2-711f32215561,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-536edcbe-0fa3-40be-9212-43d076c5ff7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-66909876-172.17.0.8-1597356184485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33246,DS-d9728892-a7fe-4f03-b811-47e2a3cd0dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43053,DS-23c6af15-42f4-4174-8c75-d6fca0af9b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:36697,DS-2d8627b6-aafc-4796-8e20-2fba4fb90695,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-7ce85bbc-7873-4f63-995f-28be7d391794,DISK], DatanodeInfoWithStorage[127.0.0.1:46524,DS-a488e344-5760-4cf3-9bce-8f8357bce778,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-f7e17f41-fff5-4211-9e62-79951139a745,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-578bbbeb-c446-4d4d-b2a2-711f32215561,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-536edcbe-0fa3-40be-9212-43d076c5ff7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-516371060-172.17.0.8-1597356359207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39313,DS-0cfac6cb-aa79-4dbc-b993-917e0067f6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-0c96b995-6077-458e-a1bd-5a47fe0c3601,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-77bb6cf2-cc4e-4319-ba7a-6ac40cb0579b,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-7d9feabb-f045-4991-a169-51661875cebd,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-c96c1e9e-2e70-4952-a501-6eafcbf0c087,DISK], DatanodeInfoWithStorage[127.0.0.1:45754,DS-0cca4e2b-1484-43eb-8c99-d186ccc0f2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-632f4871-9712-4c66-be08-13a09cb18d95,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-4568642c-03d9-4daf-9e71-30572f6ab2ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-516371060-172.17.0.8-1597356359207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39313,DS-0cfac6cb-aa79-4dbc-b993-917e0067f6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-0c96b995-6077-458e-a1bd-5a47fe0c3601,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-77bb6cf2-cc4e-4319-ba7a-6ac40cb0579b,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-7d9feabb-f045-4991-a169-51661875cebd,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-c96c1e9e-2e70-4952-a501-6eafcbf0c087,DISK], DatanodeInfoWithStorage[127.0.0.1:45754,DS-0cca4e2b-1484-43eb-8c99-d186ccc0f2c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-632f4871-9712-4c66-be08-13a09cb18d95,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-4568642c-03d9-4daf-9e71-30572f6ab2ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-810092528-172.17.0.8-1597356502992:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45739,DS-5c9fe0f0-41f7-460e-8d01-2ae45ee90ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-1fd5ab91-e032-4eff-bb5c-ca68c5a920ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-2b05ea98-ddee-4b71-a63f-9eac133a30e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-504bc311-16dd-4cb6-91de-175a3341413b,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-a8a814b4-6211-4aa5-9787-33ce067b981a,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-7360b5cf-2b60-400a-8ccf-459fd8940f79,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-99d8af36-a8db-46db-b80e-54c9c9c347dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-632f3411-a1ad-498d-8bd4-dde5a61351a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-810092528-172.17.0.8-1597356502992:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45739,DS-5c9fe0f0-41f7-460e-8d01-2ae45ee90ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-1fd5ab91-e032-4eff-bb5c-ca68c5a920ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-2b05ea98-ddee-4b71-a63f-9eac133a30e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-504bc311-16dd-4cb6-91de-175a3341413b,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-a8a814b4-6211-4aa5-9787-33ce067b981a,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-7360b5cf-2b60-400a-8ccf-459fd8940f79,DISK], DatanodeInfoWithStorage[127.0.0.1:42704,DS-99d8af36-a8db-46db-b80e-54c9c9c347dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-632f3411-a1ad-498d-8bd4-dde5a61351a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-144590838-172.17.0.8-1597356568743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36910,DS-3a7fba40-cf91-418a-9a86-8b24f3f010b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-f5b83bf2-1cad-40a5-a7b3-c555590654cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-ddcbc008-b83d-440c-98a6-1d52772e553c,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-ad941dbf-2933-403e-b6e1-8836e12f5f65,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-6a52b59b-bb18-44bc-8615-c268b1be035a,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-ccc13fb2-200b-490c-a083-f560503fda40,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-20b2e526-8946-4fe4-941d-357bbced619f,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-a134943b-b018-488d-be75-6d9e7cd9498e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-144590838-172.17.0.8-1597356568743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36910,DS-3a7fba40-cf91-418a-9a86-8b24f3f010b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-f5b83bf2-1cad-40a5-a7b3-c555590654cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41579,DS-ddcbc008-b83d-440c-98a6-1d52772e553c,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-ad941dbf-2933-403e-b6e1-8836e12f5f65,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-6a52b59b-bb18-44bc-8615-c268b1be035a,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-ccc13fb2-200b-490c-a083-f560503fda40,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-20b2e526-8946-4fe4-941d-357bbced619f,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-a134943b-b018-488d-be75-6d9e7cd9498e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-46069700-172.17.0.8-1597356749784:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40331,DS-54825cd3-123f-4c76-8005-c3a99ab997c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-bbf7a9b8-f2a0-4b87-bdb8-92c4855d38dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-35ba3c97-eb89-4fdf-ba50-8bd655270f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-b0666398-f4f8-4d2c-b28b-010f476a04b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-5a4e578d-625e-446c-b0bc-65d0399b649b,DISK], DatanodeInfoWithStorage[127.0.0.1:38340,DS-c0a44739-f6c9-4802-9cfe-da37a26f522a,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-d23bb2fb-77c7-4ac4-898c-9d6509f5c113,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-bc99faa5-c2ea-499d-a6f5-f9d9116df97e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-46069700-172.17.0.8-1597356749784:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40331,DS-54825cd3-123f-4c76-8005-c3a99ab997c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-bbf7a9b8-f2a0-4b87-bdb8-92c4855d38dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-35ba3c97-eb89-4fdf-ba50-8bd655270f9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-b0666398-f4f8-4d2c-b28b-010f476a04b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-5a4e578d-625e-446c-b0bc-65d0399b649b,DISK], DatanodeInfoWithStorage[127.0.0.1:38340,DS-c0a44739-f6c9-4802-9cfe-da37a26f522a,DISK], DatanodeInfoWithStorage[127.0.0.1:36840,DS-d23bb2fb-77c7-4ac4-898c-9d6509f5c113,DISK], DatanodeInfoWithStorage[127.0.0.1:38285,DS-bc99faa5-c2ea-499d-a6f5-f9d9116df97e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1810291707-172.17.0.8-1597357161527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42148,DS-21d3017c-03f0-438d-9370-00fa282b748d,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-2ddf3da9-4e11-48fe-878d-f0d9af3df709,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-90e6c70c-4bb5-4910-a1f5-83acd2c924d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-8a2e9664-3c54-423c-b606-430a05e57cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-8b5e251c-ccc2-44c2-b24f-b9b50a5b2591,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-11831df2-85a1-4191-8292-0164626cef0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-9ea69d10-1b09-4c4c-8d92-ce6057555b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-a7aa73fe-76ab-44a3-a09d-854dd5791519,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1810291707-172.17.0.8-1597357161527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42148,DS-21d3017c-03f0-438d-9370-00fa282b748d,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-2ddf3da9-4e11-48fe-878d-f0d9af3df709,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-90e6c70c-4bb5-4910-a1f5-83acd2c924d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-8a2e9664-3c54-423c-b606-430a05e57cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-8b5e251c-ccc2-44c2-b24f-b9b50a5b2591,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-11831df2-85a1-4191-8292-0164626cef0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37623,DS-9ea69d10-1b09-4c4c-8d92-ce6057555b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42622,DS-a7aa73fe-76ab-44a3-a09d-854dd5791519,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1368354308-172.17.0.8-1597357569581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41178,DS-0b341ff2-9fda-4b34-ab1e-d7fdc485dc66,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-c8da78f8-dede-4654-851b-8f603f0d0b79,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-feeca92f-2e35-49ba-8769-33f9e7b27642,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-44f933ed-6aa1-4640-b1e6-124ca504e6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-8edf2585-278f-4e7d-9264-40c715105872,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-3080a534-59b5-4edb-a59a-5da0d9c324ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-e320b1aa-eef8-4ad2-a76f-317d9e41aa96,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-696259a7-aa92-438f-b7c1-76618437e98f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1368354308-172.17.0.8-1597357569581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41178,DS-0b341ff2-9fda-4b34-ab1e-d7fdc485dc66,DISK], DatanodeInfoWithStorage[127.0.0.1:33081,DS-c8da78f8-dede-4654-851b-8f603f0d0b79,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-feeca92f-2e35-49ba-8769-33f9e7b27642,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-44f933ed-6aa1-4640-b1e6-124ca504e6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-8edf2585-278f-4e7d-9264-40c715105872,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-3080a534-59b5-4edb-a59a-5da0d9c324ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-e320b1aa-eef8-4ad2-a76f-317d9e41aa96,DISK], DatanodeInfoWithStorage[127.0.0.1:43488,DS-696259a7-aa92-438f-b7c1-76618437e98f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-549133056-172.17.0.8-1597358053340:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38101,DS-b53615bd-f7d8-43a1-ba17-ce224f173de7,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-3326552f-0e83-410b-b357-e308e5a667f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-432dfcca-01b3-404c-8ca2-fb5144f9f8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-0e642d84-b5aa-4a38-bf7a-0d94bd53f808,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-6078922c-1dcb-4ae2-b518-6b60bc30530e,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-059f6135-9809-4b63-909b-fb4b6a066c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-85373a40-4c5c-405b-a423-e0fa5d987609,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-d57b9c36-f17c-4ffc-9f2a-493df55d7ebe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-549133056-172.17.0.8-1597358053340:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38101,DS-b53615bd-f7d8-43a1-ba17-ce224f173de7,DISK], DatanodeInfoWithStorage[127.0.0.1:45030,DS-3326552f-0e83-410b-b357-e308e5a667f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-432dfcca-01b3-404c-8ca2-fb5144f9f8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-0e642d84-b5aa-4a38-bf7a-0d94bd53f808,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-6078922c-1dcb-4ae2-b518-6b60bc30530e,DISK], DatanodeInfoWithStorage[127.0.0.1:36924,DS-059f6135-9809-4b63-909b-fb4b6a066c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44873,DS-85373a40-4c5c-405b-a423-e0fa5d987609,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-d57b9c36-f17c-4ffc-9f2a-493df55d7ebe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1359226347-172.17.0.8-1597358477484:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38628,DS-cc8a0c04-51be-4060-ba7b-0d104af387ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-6d6e8c00-6540-43c3-8f5d-938427a20ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-f3e6f8f3-53f3-48bd-9918-2b88b2c21cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-1a51469e-f5cd-47f4-83ba-0920968e6141,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-40cdd202-b3b9-418e-9436-8cbd1c6fdeae,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-578be0af-5fbe-4ac2-8ef9-d56b86fb5091,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-1a210ee4-f582-44dc-9847-c05e77614099,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-88a09854-d9dc-4ab8-bbe2-8e5b63edc76e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1359226347-172.17.0.8-1597358477484:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38628,DS-cc8a0c04-51be-4060-ba7b-0d104af387ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-6d6e8c00-6540-43c3-8f5d-938427a20ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:33350,DS-f3e6f8f3-53f3-48bd-9918-2b88b2c21cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-1a51469e-f5cd-47f4-83ba-0920968e6141,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-40cdd202-b3b9-418e-9436-8cbd1c6fdeae,DISK], DatanodeInfoWithStorage[127.0.0.1:34777,DS-578be0af-5fbe-4ac2-8ef9-d56b86fb5091,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-1a210ee4-f582-44dc-9847-c05e77614099,DISK], DatanodeInfoWithStorage[127.0.0.1:37065,DS-88a09854-d9dc-4ab8-bbe2-8e5b63edc76e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-579317307-172.17.0.8-1597358690410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36209,DS-4949680a-2879-4513-92b0-dc9979e7f037,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-5b6188bf-95c0-4c14-a3b7-63472ff1f453,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-1d4ef37f-c4b9-4f5e-b3fd-76e976d389ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-ea65e9b6-2938-454c-b319-08bd50017ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-7e921b53-5555-4413-aaa7-353ea4014292,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-59f09913-952d-4ef5-bd0b-c0e9b2f8a347,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-c18cf5e8-1d1e-4d39-abe8-c2cf5ad15400,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-4d3f8c6a-46db-4605-a08b-ded3050045c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-579317307-172.17.0.8-1597358690410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36209,DS-4949680a-2879-4513-92b0-dc9979e7f037,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-5b6188bf-95c0-4c14-a3b7-63472ff1f453,DISK], DatanodeInfoWithStorage[127.0.0.1:33924,DS-1d4ef37f-c4b9-4f5e-b3fd-76e976d389ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-ea65e9b6-2938-454c-b319-08bd50017ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-7e921b53-5555-4413-aaa7-353ea4014292,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-59f09913-952d-4ef5-bd0b-c0e9b2f8a347,DISK], DatanodeInfoWithStorage[127.0.0.1:34069,DS-c18cf5e8-1d1e-4d39-abe8-c2cf5ad15400,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-4d3f8c6a-46db-4605-a08b-ded3050045c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-661868465-172.17.0.8-1597358898327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34103,DS-e1be7b53-c918-4020-b7c2-ed8056159c99,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-651d2a7c-cc12-4580-9444-7db1cad86975,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-b3d078eb-db08-4613-9cab-7eb4c21e182c,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-a8b256b9-9d31-4834-9fd7-fa9255ec2912,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-0e020d29-fd55-46cf-9eff-ee2410f38a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-12a42649-96e0-49c8-a6c7-86a8c8dceaba,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-c7b630e1-23b0-4e24-a124-b856010edb21,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-cc3baf32-4a87-4839-a95e-b5d1c60217a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-661868465-172.17.0.8-1597358898327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34103,DS-e1be7b53-c918-4020-b7c2-ed8056159c99,DISK], DatanodeInfoWithStorage[127.0.0.1:39443,DS-651d2a7c-cc12-4580-9444-7db1cad86975,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-b3d078eb-db08-4613-9cab-7eb4c21e182c,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-a8b256b9-9d31-4834-9fd7-fa9255ec2912,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-0e020d29-fd55-46cf-9eff-ee2410f38a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-12a42649-96e0-49c8-a6c7-86a8c8dceaba,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-c7b630e1-23b0-4e24-a124-b856010edb21,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-cc3baf32-4a87-4839-a95e-b5d1c60217a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2105910275-172.17.0.8-1597358998830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34043,DS-83685cc7-365f-4045-9da1-0ea70fcf4718,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-ab96f3ab-9849-4018-af88-5a22dfb37b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-ab783872-528e-4ff9-a799-2343737b4f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-0de78985-4096-4276-b7d6-6b247685aa9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-5a39b727-0e64-4276-b46b-5608b3792fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-96238224-f75b-41aa-85ec-d3084c9fd047,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-8abb3bc5-e14f-4580-bb36-01b5f58633d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-02c846fc-1940-4eb3-87ad-ebaf8c708b69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2105910275-172.17.0.8-1597358998830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34043,DS-83685cc7-365f-4045-9da1-0ea70fcf4718,DISK], DatanodeInfoWithStorage[127.0.0.1:42162,DS-ab96f3ab-9849-4018-af88-5a22dfb37b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-ab783872-528e-4ff9-a799-2343737b4f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-0de78985-4096-4276-b7d6-6b247685aa9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-5a39b727-0e64-4276-b46b-5608b3792fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:34627,DS-96238224-f75b-41aa-85ec-d3084c9fd047,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-8abb3bc5-e14f-4580-bb36-01b5f58633d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42554,DS-02c846fc-1940-4eb3-87ad-ebaf8c708b69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-282540280-172.17.0.8-1597359852482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40062,DS-c43062f8-b65d-4281-a154-ed23c4e155ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-653ed208-ea81-4bfe-9504-29bbbe95ddd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-755ff2d1-016f-4765-9832-61f078de6846,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-675195ab-1fa9-4351-b9d8-78b2d90dde6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-c3e526ab-8991-455e-8343-fdc599aa509a,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-d58fde6b-cf2b-4d2e-8ac7-ceecb5088854,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-937aef13-b168-439c-bb2a-d748e4a33805,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-ffecb2d0-0218-430e-9beb-c8625316cf6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-282540280-172.17.0.8-1597359852482:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40062,DS-c43062f8-b65d-4281-a154-ed23c4e155ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-653ed208-ea81-4bfe-9504-29bbbe95ddd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42550,DS-755ff2d1-016f-4765-9832-61f078de6846,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-675195ab-1fa9-4351-b9d8-78b2d90dde6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-c3e526ab-8991-455e-8343-fdc599aa509a,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-d58fde6b-cf2b-4d2e-8ac7-ceecb5088854,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-937aef13-b168-439c-bb2a-d748e4a33805,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-ffecb2d0-0218-430e-9beb-c8625316cf6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-115515781-172.17.0.8-1597359892470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34107,DS-68cfbe6a-f45b-47f3-9e66-432a476f5e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-50c8bf61-0360-4e6f-80dd-a43496bb3f45,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-d6d9a42d-4dc1-4bc6-aabf-2f2eb6d69a80,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-eb7f5fd5-d513-4b67-851a-f54568ddd7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-6493f644-75b7-4d2a-8180-0de69b1382af,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-6ee587a7-fb8e-4afc-9cdf-17b57d3d08f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-bdd1ca6a-5299-4a21-b48e-25b071ec6f03,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-d1ee635f-9b15-4624-8127-472a183e841a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-115515781-172.17.0.8-1597359892470:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34107,DS-68cfbe6a-f45b-47f3-9e66-432a476f5e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39230,DS-50c8bf61-0360-4e6f-80dd-a43496bb3f45,DISK], DatanodeInfoWithStorage[127.0.0.1:43709,DS-d6d9a42d-4dc1-4bc6-aabf-2f2eb6d69a80,DISK], DatanodeInfoWithStorage[127.0.0.1:37968,DS-eb7f5fd5-d513-4b67-851a-f54568ddd7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33039,DS-6493f644-75b7-4d2a-8180-0de69b1382af,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-6ee587a7-fb8e-4afc-9cdf-17b57d3d08f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38246,DS-bdd1ca6a-5299-4a21-b48e-25b071ec6f03,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-d1ee635f-9b15-4624-8127-472a183e841a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308198856-172.17.0.8-1597359996815:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43760,DS-a995645a-cf9b-4083-9e0a-6e947b44025c,DISK], DatanodeInfoWithStorage[127.0.0.1:33853,DS-4872c471-b8c6-4f5d-8eab-fcecb46240a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-20211f57-7ad2-4cbd-89ab-40915268e59d,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-20d31839-7b4a-40e5-a577-96ebc01d9c70,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-93eab7a1-ddb6-41f6-b417-d4c614d66b53,DISK], DatanodeInfoWithStorage[127.0.0.1:34687,DS-bbfbbace-3251-4bfa-a990-0dd6e71a36ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-4abe8274-6728-4e79-a3ca-0e8f7ea38947,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-59efedda-5b7d-4edc-acf3-4844d585c2b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-308198856-172.17.0.8-1597359996815:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43760,DS-a995645a-cf9b-4083-9e0a-6e947b44025c,DISK], DatanodeInfoWithStorage[127.0.0.1:33853,DS-4872c471-b8c6-4f5d-8eab-fcecb46240a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-20211f57-7ad2-4cbd-89ab-40915268e59d,DISK], DatanodeInfoWithStorage[127.0.0.1:44710,DS-20d31839-7b4a-40e5-a577-96ebc01d9c70,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-93eab7a1-ddb6-41f6-b417-d4c614d66b53,DISK], DatanodeInfoWithStorage[127.0.0.1:34687,DS-bbfbbace-3251-4bfa-a990-0dd6e71a36ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-4abe8274-6728-4e79-a3ca-0e8f7ea38947,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-59efedda-5b7d-4edc-acf3-4844d585c2b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-669996616-172.17.0.8-1597360545170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40830,DS-6c6f5ac5-08dd-4ef5-83fd-a89936af582c,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-9ff56b39-632e-48ff-9f96-1463b5a555d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-b03f89a9-47d3-477c-a773-4815e6ebf602,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-b289802b-6d1c-4cb4-a5f5-584e4b0c8c07,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-85ffdd3b-00af-49be-ab93-e1d2772b3084,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-a68367f3-96c4-4650-8a12-3ad0aa1c3f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-4ac12f0c-d3d8-42ef-b885-214e8c8adaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-3bf41d5d-81bf-4cef-ae08-6f4e774ce359,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-669996616-172.17.0.8-1597360545170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40830,DS-6c6f5ac5-08dd-4ef5-83fd-a89936af582c,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-9ff56b39-632e-48ff-9f96-1463b5a555d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40430,DS-b03f89a9-47d3-477c-a773-4815e6ebf602,DISK], DatanodeInfoWithStorage[127.0.0.1:39237,DS-b289802b-6d1c-4cb4-a5f5-584e4b0c8c07,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-85ffdd3b-00af-49be-ab93-e1d2772b3084,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-a68367f3-96c4-4650-8a12-3ad0aa1c3f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-4ac12f0c-d3d8-42ef-b885-214e8c8adaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:37946,DS-3bf41d5d-81bf-4cef-ae08-6f4e774ce359,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1983221564-172.17.0.8-1597360647109:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41678,DS-82659be9-3d41-436c-9cd8-be7e3629086a,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-51988208-72f5-4aa9-98d9-6d790162c904,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-7b79f5d5-cd64-4d0e-8477-cda4cfd65af2,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-13b27791-4ae3-4a6d-b971-e54a05542c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-e8a1a54f-a761-43a8-8bcb-30793434854f,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-7f624fde-d642-4bbc-aa0e-873e8c39a1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-988a5afb-e621-4d17-a032-6d9b038c482a,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-eb907f3c-567e-462e-a8aa-4dc4ac5aa898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1983221564-172.17.0.8-1597360647109:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41678,DS-82659be9-3d41-436c-9cd8-be7e3629086a,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-51988208-72f5-4aa9-98d9-6d790162c904,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-7b79f5d5-cd64-4d0e-8477-cda4cfd65af2,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-13b27791-4ae3-4a6d-b971-e54a05542c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-e8a1a54f-a761-43a8-8bcb-30793434854f,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-7f624fde-d642-4bbc-aa0e-873e8c39a1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44454,DS-988a5afb-e621-4d17-a032-6d9b038c482a,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-eb907f3c-567e-462e-a8aa-4dc4ac5aa898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2029820658-172.17.0.8-1597360686494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34699,DS-3c847480-9248-4532-b7b5-66662a29af99,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-a88e0a56-5f5d-4c17-a9a5-e5ea02e95497,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-17099297-62d4-48ce-822c-8055255d09f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-5def2f0f-fc6c-42dc-ab1e-2cac07b21b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-9173a83f-5126-4eec-b354-cdfbf45a7b98,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-85e296b2-a623-4bf6-bd2d-3b8534065117,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-bc1e4b12-0ef9-4e6c-baee-1ade714434b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-34d90c66-83fc-4cd6-ba31-1885efaded7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2029820658-172.17.0.8-1597360686494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34699,DS-3c847480-9248-4532-b7b5-66662a29af99,DISK], DatanodeInfoWithStorage[127.0.0.1:36415,DS-a88e0a56-5f5d-4c17-a9a5-e5ea02e95497,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-17099297-62d4-48ce-822c-8055255d09f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-5def2f0f-fc6c-42dc-ab1e-2cac07b21b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-9173a83f-5126-4eec-b354-cdfbf45a7b98,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-85e296b2-a623-4bf6-bd2d-3b8534065117,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-bc1e4b12-0ef9-4e6c-baee-1ade714434b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41204,DS-34d90c66-83fc-4cd6-ba31-1885efaded7b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-192667588-172.17.0.8-1597360721840:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44467,DS-a56b35fb-35ff-4d11-b6fd-eb8358282ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-6ab57d0b-d593-465e-9b56-1d952a8602b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-9099aec6-270c-4be0-a782-05cfdedb7855,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-a4fc37f2-df0a-4680-a518-5ee539fdf08c,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-1fffe01f-3d11-46d0-bc57-e1519df376cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-a347ece1-9184-4de9-829d-6c978626575f,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-30fd6906-1bcb-42e4-a2d3-6718fa7cb027,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-b31f86a4-f9e0-462e-aea2-4b2959f49955,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-192667588-172.17.0.8-1597360721840:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44467,DS-a56b35fb-35ff-4d11-b6fd-eb8358282ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-6ab57d0b-d593-465e-9b56-1d952a8602b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-9099aec6-270c-4be0-a782-05cfdedb7855,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-a4fc37f2-df0a-4680-a518-5ee539fdf08c,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-1fffe01f-3d11-46d0-bc57-e1519df376cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-a347ece1-9184-4de9-829d-6c978626575f,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-30fd6906-1bcb-42e4-a2d3-6718fa7cb027,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-b31f86a4-f9e0-462e-aea2-4b2959f49955,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 6000000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1055007171-172.17.0.8-1597361032950:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39537,DS-ae82fac3-8d5a-40c3-af17-f0c2ad7439e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-44206831-dc24-47db-9dc1-561b3068c2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-5e556dca-9b58-4bd5-a34f-e9c7eca6bb91,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-226b3ef1-08c4-41c8-abbd-e837a503276b,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-342397bc-321b-4230-8220-d7844e3760da,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-82866bb2-c810-4717-adda-53f8ccf82f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-8b3393a1-af14-4a01-9df1-6bf7c892d527,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-6b52cf6c-96da-4abf-84ed-79b22c6f1a22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1055007171-172.17.0.8-1597361032950:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39537,DS-ae82fac3-8d5a-40c3-af17-f0c2ad7439e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33084,DS-44206831-dc24-47db-9dc1-561b3068c2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-5e556dca-9b58-4bd5-a34f-e9c7eca6bb91,DISK], DatanodeInfoWithStorage[127.0.0.1:34567,DS-226b3ef1-08c4-41c8-abbd-e837a503276b,DISK], DatanodeInfoWithStorage[127.0.0.1:41870,DS-342397bc-321b-4230-8220-d7844e3760da,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-82866bb2-c810-4717-adda-53f8ccf82f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-8b3393a1-af14-4a01-9df1-6bf7c892d527,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-6b52cf6c-96da-4abf-84ed-79b22c6f1a22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5316
