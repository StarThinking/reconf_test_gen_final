reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-103788929-172.17.0.21-1597422387510:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39535,DS-c14c28fc-9a8c-456e-ba4e-4dde43a7e0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-3cd9a7bb-af79-4bd6-855a-1ab498e970f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-b24df9af-5faa-462f-bf75-0e1e81353564,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-18ac9700-2942-4117-a42a-764b72a1faa9,DISK], DatanodeInfoWithStorage[127.0.0.1:44131,DS-4ad40ff3-5798-4a78-9724-6727a5927052,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-9c20133a-d43d-4797-a3f4-f5f4cfdde1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-5b47b8c1-9756-47c6-b4fd-9a49739bed40,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-028d1e8d-20cf-4c4f-bf0f-f81be625a3f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-103788929-172.17.0.21-1597422387510:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39535,DS-c14c28fc-9a8c-456e-ba4e-4dde43a7e0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-3cd9a7bb-af79-4bd6-855a-1ab498e970f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-b24df9af-5faa-462f-bf75-0e1e81353564,DISK], DatanodeInfoWithStorage[127.0.0.1:38801,DS-18ac9700-2942-4117-a42a-764b72a1faa9,DISK], DatanodeInfoWithStorage[127.0.0.1:44131,DS-4ad40ff3-5798-4a78-9724-6727a5927052,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-9c20133a-d43d-4797-a3f4-f5f4cfdde1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-5b47b8c1-9756-47c6-b4fd-9a49739bed40,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-028d1e8d-20cf-4c4f-bf0f-f81be625a3f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-593717965-172.17.0.21-1597422927860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46298,DS-01fbbc03-85ba-4511-b450-6d37cd6434be,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-204b7985-557a-4cb4-841f-35980440b3af,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-ceb1342f-c29c-4c81-9aa9-ede2aa0205c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-39e7f521-beea-4e62-a6a0-26b88ea10b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-d41dda26-ce49-4d23-a714-09b39a44d977,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-02841305-5539-4402-93f6-4a29d20b72fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-5a08191a-c53b-4a3b-aa92-1d683a00bc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-3928ad59-4b91-4b3e-8b21-c9e908f3ca46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-593717965-172.17.0.21-1597422927860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46298,DS-01fbbc03-85ba-4511-b450-6d37cd6434be,DISK], DatanodeInfoWithStorage[127.0.0.1:45433,DS-204b7985-557a-4cb4-841f-35980440b3af,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-ceb1342f-c29c-4c81-9aa9-ede2aa0205c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33466,DS-39e7f521-beea-4e62-a6a0-26b88ea10b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33969,DS-d41dda26-ce49-4d23-a714-09b39a44d977,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-02841305-5539-4402-93f6-4a29d20b72fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-5a08191a-c53b-4a3b-aa92-1d683a00bc2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-3928ad59-4b91-4b3e-8b21-c9e908f3ca46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1432240512-172.17.0.21-1597423112835:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38114,DS-07f4d201-7893-43a5-adce-d1badd30ffd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-54cc0648-60cf-46bd-bcc8-0f4faf44060c,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-79875948-e6d9-4fbd-bfab-ecd8613113b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-965dfb9f-275d-4be5-8a28-f36fa842f156,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-807563ad-3a50-4847-bf5d-4b69b266c8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-290cc561-5b35-4f5a-9a72-4f28c074586d,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-1f7994f1-4e41-480a-8ef2-c100f279a80a,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-71222aad-e95e-46f2-af89-aef81bcd50a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1432240512-172.17.0.21-1597423112835:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38114,DS-07f4d201-7893-43a5-adce-d1badd30ffd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42603,DS-54cc0648-60cf-46bd-bcc8-0f4faf44060c,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-79875948-e6d9-4fbd-bfab-ecd8613113b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43471,DS-965dfb9f-275d-4be5-8a28-f36fa842f156,DISK], DatanodeInfoWithStorage[127.0.0.1:41515,DS-807563ad-3a50-4847-bf5d-4b69b266c8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-290cc561-5b35-4f5a-9a72-4f28c074586d,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-1f7994f1-4e41-480a-8ef2-c100f279a80a,DISK], DatanodeInfoWithStorage[127.0.0.1:33100,DS-71222aad-e95e-46f2-af89-aef81bcd50a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1365925661-172.17.0.21-1597423147128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35046,DS-de48efa2-1d43-489e-b68f-0434abb4f00c,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-1ce4735c-2487-4f64-941a-8e7ce7f12fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-2f0a34d4-9d8d-46f3-86eb-2f04da742be6,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-181827e1-fd6f-4766-a9dd-29f8d1cf33d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-274743df-f94a-4b58-8107-912a1188badb,DISK], DatanodeInfoWithStorage[127.0.0.1:40587,DS-501bd809-0564-479e-b8fb-332e7eeca780,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-cd98a748-cb8f-45a0-9cee-1e24c59001ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-852dcb59-f321-4e27-8d8c-dc62c68269c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1365925661-172.17.0.21-1597423147128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35046,DS-de48efa2-1d43-489e-b68f-0434abb4f00c,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-1ce4735c-2487-4f64-941a-8e7ce7f12fe4,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-2f0a34d4-9d8d-46f3-86eb-2f04da742be6,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-181827e1-fd6f-4766-a9dd-29f8d1cf33d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34661,DS-274743df-f94a-4b58-8107-912a1188badb,DISK], DatanodeInfoWithStorage[127.0.0.1:40587,DS-501bd809-0564-479e-b8fb-332e7eeca780,DISK], DatanodeInfoWithStorage[127.0.0.1:40243,DS-cd98a748-cb8f-45a0-9cee-1e24c59001ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34380,DS-852dcb59-f321-4e27-8d8c-dc62c68269c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1823940067-172.17.0.21-1597423362415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45823,DS-773c43e5-73cd-46ba-97b7-fa89c305bab9,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-f4a0f9f2-6c97-4a75-a9a8-3ff1a3e9da88,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-ac22f4c1-dfa9-4f93-a6a5-4e3f32a8b254,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-4ebd22b0-312d-4a58-ba3f-d98c47b44073,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-a7164b80-7e76-45a4-a701-63c8fff4b9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-b8654ef0-dfeb-499d-91bc-4becfb882239,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-ac7201e9-78b6-4e76-bd48-c89316eb9ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-999abff3-4f34-42ad-858e-1ddae5a78094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1823940067-172.17.0.21-1597423362415:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45823,DS-773c43e5-73cd-46ba-97b7-fa89c305bab9,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-f4a0f9f2-6c97-4a75-a9a8-3ff1a3e9da88,DISK], DatanodeInfoWithStorage[127.0.0.1:41597,DS-ac22f4c1-dfa9-4f93-a6a5-4e3f32a8b254,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-4ebd22b0-312d-4a58-ba3f-d98c47b44073,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-a7164b80-7e76-45a4-a701-63c8fff4b9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-b8654ef0-dfeb-499d-91bc-4becfb882239,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-ac7201e9-78b6-4e76-bd48-c89316eb9ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-999abff3-4f34-42ad-858e-1ddae5a78094,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-125911469-172.17.0.21-1597423395677:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38585,DS-787d454a-3ac3-4c44-9c6d-c77cd66076b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-43c5d67a-9d6a-4064-823d-e0414fcc9d48,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-04c37ee0-aedb-43ae-aac3-e5878baeb96e,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-78801e0f-917e-4d5e-adf0-99a2d6ef6894,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-9e4cc2fe-81b8-4784-b01d-51691f682a60,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-3adf0714-1fdb-43b5-b508-d9a1de7083ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-fe038de5-786b-4fcb-85ad-3140e828ebb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-b6a381a8-02c2-4f4b-a4fd-9102f237b8d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-125911469-172.17.0.21-1597423395677:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38585,DS-787d454a-3ac3-4c44-9c6d-c77cd66076b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37816,DS-43c5d67a-9d6a-4064-823d-e0414fcc9d48,DISK], DatanodeInfoWithStorage[127.0.0.1:41683,DS-04c37ee0-aedb-43ae-aac3-e5878baeb96e,DISK], DatanodeInfoWithStorage[127.0.0.1:41656,DS-78801e0f-917e-4d5e-adf0-99a2d6ef6894,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-9e4cc2fe-81b8-4784-b01d-51691f682a60,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-3adf0714-1fdb-43b5-b508-d9a1de7083ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46407,DS-fe038de5-786b-4fcb-85ad-3140e828ebb7,DISK], DatanodeInfoWithStorage[127.0.0.1:36375,DS-b6a381a8-02c2-4f4b-a4fd-9102f237b8d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-494898073-172.17.0.21-1597423425550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35911,DS-faeea3ce-cee3-4e3d-98fe-3db6b3a373ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-8cf57440-ef48-4564-9056-29b9d742dbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-3af84f66-7215-4007-8bf1-8a13f8b367b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-c6a5c6ac-405a-4dc1-81c2-d8a4129b47b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-813f9d3d-22f4-4b48-9193-2152472807bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-364fa63d-31f3-4ada-af69-797d50a06aee,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-08ae5e96-de26-4579-b87d-11e8b737aa3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-732f57b9-9ba1-4689-9376-0b6b7c52d724,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-494898073-172.17.0.21-1597423425550:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35911,DS-faeea3ce-cee3-4e3d-98fe-3db6b3a373ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33290,DS-8cf57440-ef48-4564-9056-29b9d742dbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-3af84f66-7215-4007-8bf1-8a13f8b367b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44753,DS-c6a5c6ac-405a-4dc1-81c2-d8a4129b47b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-813f9d3d-22f4-4b48-9193-2152472807bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-364fa63d-31f3-4ada-af69-797d50a06aee,DISK], DatanodeInfoWithStorage[127.0.0.1:33113,DS-08ae5e96-de26-4579-b87d-11e8b737aa3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33388,DS-732f57b9-9ba1-4689-9376-0b6b7c52d724,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-231901173-172.17.0.21-1597423715219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44348,DS-6a35e88c-6689-446a-8a08-e19576d3c411,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-cdfda3cc-2963-4266-8de7-f0518732797a,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-81affa46-e68a-4ef0-a9c4-072011e85814,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-0f0c8c8f-0fef-4fc2-9dfb-7e0a48752494,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-61fc9d0a-6750-4bca-91a1-6df3c7458eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-cf5fc317-4254-454b-b493-c8ae04ff2bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-a2dbc6b4-a039-4a5f-9cf3-a5eb30bac832,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-df618797-99ab-43ea-a14c-7567be530de5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-231901173-172.17.0.21-1597423715219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44348,DS-6a35e88c-6689-446a-8a08-e19576d3c411,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-cdfda3cc-2963-4266-8de7-f0518732797a,DISK], DatanodeInfoWithStorage[127.0.0.1:33075,DS-81affa46-e68a-4ef0-a9c4-072011e85814,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-0f0c8c8f-0fef-4fc2-9dfb-7e0a48752494,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-61fc9d0a-6750-4bca-91a1-6df3c7458eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-cf5fc317-4254-454b-b493-c8ae04ff2bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:41398,DS-a2dbc6b4-a039-4a5f-9cf3-a5eb30bac832,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-df618797-99ab-43ea-a14c-7567be530de5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1543664606-172.17.0.21-1597424295445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45656,DS-d32bba9a-6393-4b34-b93a-6a66843db18d,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-0224ff27-0549-400e-8971-ea885528f759,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-d65160ff-f712-46d2-a714-3a4c1edd7b04,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-6e3fe54e-843d-4fc2-8711-6db30ce2cb77,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-200637b4-fc09-4466-9bf0-6e63f9a72847,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-69f3264e-df9a-4df5-a2e6-5cd5414f7d39,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-b3cea682-930f-4174-bc28-26f26a02f692,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-ef7ef49c-8983-4ea5-9bd3-3ce843d43a41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1543664606-172.17.0.21-1597424295445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45656,DS-d32bba9a-6393-4b34-b93a-6a66843db18d,DISK], DatanodeInfoWithStorage[127.0.0.1:42147,DS-0224ff27-0549-400e-8971-ea885528f759,DISK], DatanodeInfoWithStorage[127.0.0.1:43910,DS-d65160ff-f712-46d2-a714-3a4c1edd7b04,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-6e3fe54e-843d-4fc2-8711-6db30ce2cb77,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-200637b4-fc09-4466-9bf0-6e63f9a72847,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-69f3264e-df9a-4df5-a2e6-5cd5414f7d39,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-b3cea682-930f-4174-bc28-26f26a02f692,DISK], DatanodeInfoWithStorage[127.0.0.1:38964,DS-ef7ef49c-8983-4ea5-9bd3-3ce843d43a41,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-432247681-172.17.0.21-1597424476395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42193,DS-7f60e4e6-6a8d-4fb2-bbdd-586ab220ca78,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-fb082340-4d55-494e-a8e7-8ca25c5a408f,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-b0fb7acb-fd02-41e4-acec-5c183387208f,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-cabf0111-d7a1-48ef-9747-9777b2424805,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-315bb74a-919d-4864-9643-fad0caff3763,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-eeb6dba6-d73a-46b6-aa3d-6b731eb46304,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-49d6fc34-21cc-4963-8726-5ed7cd8cfcef,DISK], DatanodeInfoWithStorage[127.0.0.1:45849,DS-15559878-f81a-41ee-a686-f06377792e5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-432247681-172.17.0.21-1597424476395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42193,DS-7f60e4e6-6a8d-4fb2-bbdd-586ab220ca78,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-fb082340-4d55-494e-a8e7-8ca25c5a408f,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-b0fb7acb-fd02-41e4-acec-5c183387208f,DISK], DatanodeInfoWithStorage[127.0.0.1:41415,DS-cabf0111-d7a1-48ef-9747-9777b2424805,DISK], DatanodeInfoWithStorage[127.0.0.1:40269,DS-315bb74a-919d-4864-9643-fad0caff3763,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-eeb6dba6-d73a-46b6-aa3d-6b731eb46304,DISK], DatanodeInfoWithStorage[127.0.0.1:38015,DS-49d6fc34-21cc-4963-8726-5ed7cd8cfcef,DISK], DatanodeInfoWithStorage[127.0.0.1:45849,DS-15559878-f81a-41ee-a686-f06377792e5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-592800142-172.17.0.21-1597424509701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37871,DS-e542bc1a-6dab-4954-911a-171fb6b658d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-6de6777a-47ab-449e-9657-0a70df5d9346,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-92b1ece6-7cac-4885-a5e7-c3ba36b3883e,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-bdbfa33f-8715-477b-90f0-7c0c3dbb0597,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-de14c896-7f96-43da-a4a7-55f3e163ea79,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-c0450688-5562-40e7-a252-5aca477eb542,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-00215b67-f828-474b-a2a9-1fcab0e7b343,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-b205d14f-5512-4771-af7e-14e9b12b0bdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-592800142-172.17.0.21-1597424509701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37871,DS-e542bc1a-6dab-4954-911a-171fb6b658d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-6de6777a-47ab-449e-9657-0a70df5d9346,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-92b1ece6-7cac-4885-a5e7-c3ba36b3883e,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-bdbfa33f-8715-477b-90f0-7c0c3dbb0597,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-de14c896-7f96-43da-a4a7-55f3e163ea79,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-c0450688-5562-40e7-a252-5aca477eb542,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-00215b67-f828-474b-a2a9-1fcab0e7b343,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-b205d14f-5512-4771-af7e-14e9b12b0bdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-221250056-172.17.0.21-1597424739374:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43296,DS-c92de0e7-3e66-466e-9cf1-d615e83929ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-0bb5fdc3-2807-4b29-80da-9615281e99b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-afe9f799-d088-44fb-836f-587fc87b53f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-2d820f01-41db-4d83-8776-e6fd5815382f,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-56e0b800-feee-4830-8fff-d79be6f1c987,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-194015ca-2c55-4d47-a7a1-6f3f40b2d456,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-ccb0f566-2072-451e-a635-9e4858e00153,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-0c90dd97-4713-49ff-8dfa-84599589942a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-221250056-172.17.0.21-1597424739374:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43296,DS-c92de0e7-3e66-466e-9cf1-d615e83929ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-0bb5fdc3-2807-4b29-80da-9615281e99b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43926,DS-afe9f799-d088-44fb-836f-587fc87b53f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34795,DS-2d820f01-41db-4d83-8776-e6fd5815382f,DISK], DatanodeInfoWithStorage[127.0.0.1:42419,DS-56e0b800-feee-4830-8fff-d79be6f1c987,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-194015ca-2c55-4d47-a7a1-6f3f40b2d456,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-ccb0f566-2072-451e-a635-9e4858e00153,DISK], DatanodeInfoWithStorage[127.0.0.1:35619,DS-0c90dd97-4713-49ff-8dfa-84599589942a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1273347357-172.17.0.21-1597424886912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35823,DS-f28b13a5-7e20-4644-8d7a-ff79ddd3a737,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-d705300f-6855-4fce-b0f1-768c3e7a9474,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-2ee23fb0-b342-47fc-85ae-0f115d1337e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-96f08a29-5ad3-407c-b23b-a30a5a99235a,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-0a026eab-b7a1-4c3a-966f-a833947c9dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-e470dcdc-20a2-47be-b9dd-3f7d0f790ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-00932854-14b5-4d49-8ff8-1b194481236a,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-af6a0bf1-66ac-45f6-b946-1161d518ea1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1273347357-172.17.0.21-1597424886912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35823,DS-f28b13a5-7e20-4644-8d7a-ff79ddd3a737,DISK], DatanodeInfoWithStorage[127.0.0.1:34472,DS-d705300f-6855-4fce-b0f1-768c3e7a9474,DISK], DatanodeInfoWithStorage[127.0.0.1:33031,DS-2ee23fb0-b342-47fc-85ae-0f115d1337e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45682,DS-96f08a29-5ad3-407c-b23b-a30a5a99235a,DISK], DatanodeInfoWithStorage[127.0.0.1:33613,DS-0a026eab-b7a1-4c3a-966f-a833947c9dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-e470dcdc-20a2-47be-b9dd-3f7d0f790ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-00932854-14b5-4d49-8ff8-1b194481236a,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-af6a0bf1-66ac-45f6-b946-1161d518ea1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-405641309-172.17.0.21-1597425018968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43957,DS-549d4ce5-5253-4b22-bde1-7b3a004e29d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-0fdb213c-8216-492f-9bba-11006fc720da,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-e9111372-4838-4708-8203-f5ce3bd3d6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-d26f63cc-808e-468d-8721-f4f7cf7720b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-cf3d8850-e682-4ef4-a1db-d7cc32106ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-7c198df1-1aba-4141-888c-941629f0bdaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-ce686b32-7af0-48f5-a8b6-2575b86252b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-32891324-969c-46b4-8e35-6e10f77055ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-405641309-172.17.0.21-1597425018968:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43957,DS-549d4ce5-5253-4b22-bde1-7b3a004e29d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-0fdb213c-8216-492f-9bba-11006fc720da,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-e9111372-4838-4708-8203-f5ce3bd3d6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-d26f63cc-808e-468d-8721-f4f7cf7720b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-cf3d8850-e682-4ef4-a1db-d7cc32106ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:44779,DS-7c198df1-1aba-4141-888c-941629f0bdaf,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-ce686b32-7af0-48f5-a8b6-2575b86252b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-32891324-969c-46b4-8e35-6e10f77055ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-729518518-172.17.0.21-1597425202510:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44049,DS-3a947783-cf8e-4925-ae3f-46f3fabadce9,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-5a673ea1-b3aa-4102-841f-35c137f286f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-4d6274db-c598-4a27-9e86-c3a9d832d220,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-26ea4816-6813-4953-83d3-ca05f4ade6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-2585d3ec-b5cd-462f-837b-cc3e5561fc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-d4dd4c37-50b1-45cb-8fc3-c95dc45fdcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-e4f1a0c9-14de-4ce9-b359-e4c47e0f5686,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-c6e3c60b-b954-46b3-944f-f96ae0c64bc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-729518518-172.17.0.21-1597425202510:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44049,DS-3a947783-cf8e-4925-ae3f-46f3fabadce9,DISK], DatanodeInfoWithStorage[127.0.0.1:37346,DS-5a673ea1-b3aa-4102-841f-35c137f286f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45822,DS-4d6274db-c598-4a27-9e86-c3a9d832d220,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-26ea4816-6813-4953-83d3-ca05f4ade6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39822,DS-2585d3ec-b5cd-462f-837b-cc3e5561fc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-d4dd4c37-50b1-45cb-8fc3-c95dc45fdcdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-e4f1a0c9-14de-4ce9-b359-e4c47e0f5686,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-c6e3c60b-b954-46b3-944f-f96ae0c64bc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 512
v2: 0
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-395705534-172.17.0.21-1597425317860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37169,DS-e7e080d8-7a2f-43a0-9ec8-f5e4b2dec576,DISK], DatanodeInfoWithStorage[127.0.0.1:37473,DS-c9536670-e200-4566-b2fd-4f8680387800,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-24e136b6-7226-43ba-892b-ce6e9dc0c5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-a46daa50-d23c-4aca-a0fa-564e96ffcdb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-c43b63bb-b789-4fcf-b37b-e81e181f3f32,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-6aacecec-0719-4ec7-9047-8eaa40c59d11,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-8413f1ba-6223-4994-aa17-4845ae9b4bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-6f848c28-dd9a-4ee9-892d-6adb7e8835a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-395705534-172.17.0.21-1597425317860:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37169,DS-e7e080d8-7a2f-43a0-9ec8-f5e4b2dec576,DISK], DatanodeInfoWithStorage[127.0.0.1:37473,DS-c9536670-e200-4566-b2fd-4f8680387800,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-24e136b6-7226-43ba-892b-ce6e9dc0c5c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38292,DS-a46daa50-d23c-4aca-a0fa-564e96ffcdb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-c43b63bb-b789-4fcf-b37b-e81e181f3f32,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-6aacecec-0719-4ec7-9047-8eaa40c59d11,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-8413f1ba-6223-4994-aa17-4845ae9b4bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36200,DS-6f848c28-dd9a-4ee9-892d-6adb7e8835a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 3326
