reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1704545809-172.17.0.16-1597397131320:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41237,DS-f28222a3-1a1d-4760-bf6d-d155312ba30e,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-335b9257-6713-4275-bd0b-98380ccf725b,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-f3a775f1-ba65-4266-9871-b2ba1130261b,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-70e72077-7d34-450b-a1ac-f5ce4c80b389,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-9238f5db-5910-4833-a936-1866bb0b6010,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-dc0f6422-79f2-4799-9ed3-81704402ca04,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-3a2ac139-6c68-49dc-b66d-1f3b37f77218,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-7524f7b6-63a9-4ea0-8599-45fd88ac76b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1704545809-172.17.0.16-1597397131320:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41237,DS-f28222a3-1a1d-4760-bf6d-d155312ba30e,DISK], DatanodeInfoWithStorage[127.0.0.1:37164,DS-335b9257-6713-4275-bd0b-98380ccf725b,DISK], DatanodeInfoWithStorage[127.0.0.1:39698,DS-f3a775f1-ba65-4266-9871-b2ba1130261b,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-70e72077-7d34-450b-a1ac-f5ce4c80b389,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-9238f5db-5910-4833-a936-1866bb0b6010,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-dc0f6422-79f2-4799-9ed3-81704402ca04,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-3a2ac139-6c68-49dc-b66d-1f3b37f77218,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-7524f7b6-63a9-4ea0-8599-45fd88ac76b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-614691768-172.17.0.16-1597397409629:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33931,DS-303f5a27-3e70-4730-9c7d-67ab4a3fc73e,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-bcfbc222-c2ad-4ae8-8577-1539de9e3149,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-b1043d60-8804-480f-9351-ebe7d3303bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-9ee55fb8-887f-45ef-8ca9-62dc51f8a320,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-b8ad6028-acd1-41cc-ad9d-73d6ca9ab851,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-56f49e21-07a2-4e70-b312-2e02846fc747,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-9c1f4d42-d5b8-4a40-9b9e-4bfd0608d4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-b2852057-0a6c-4aec-ab72-fa611a28086e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-614691768-172.17.0.16-1597397409629:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33931,DS-303f5a27-3e70-4730-9c7d-67ab4a3fc73e,DISK], DatanodeInfoWithStorage[127.0.0.1:42862,DS-bcfbc222-c2ad-4ae8-8577-1539de9e3149,DISK], DatanodeInfoWithStorage[127.0.0.1:41609,DS-b1043d60-8804-480f-9351-ebe7d3303bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-9ee55fb8-887f-45ef-8ca9-62dc51f8a320,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-b8ad6028-acd1-41cc-ad9d-73d6ca9ab851,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-56f49e21-07a2-4e70-b312-2e02846fc747,DISK], DatanodeInfoWithStorage[127.0.0.1:33629,DS-9c1f4d42-d5b8-4a40-9b9e-4bfd0608d4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-b2852057-0a6c-4aec-ab72-fa611a28086e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1339214071-172.17.0.16-1597397653043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42479,DS-7b66e7e4-2b23-4a87-a00f-b535c57baff0,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-31f66a47-e5ce-44af-bba5-6ce7d94e2b47,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-e998dcf3-64d6-44a6-b0d5-47ec08d1ff69,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-fb13a561-51c4-4c1c-b76f-908cb784cb7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-f93e14dd-cfad-4188-a404-54269c57b074,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-1ac9e749-e285-4274-ba17-b88910a26e46,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-d5f9ba9f-c67d-496f-88b5-88792d6e3fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-e0f40de4-342a-4559-81e0-bb472617e338,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1339214071-172.17.0.16-1597397653043:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42479,DS-7b66e7e4-2b23-4a87-a00f-b535c57baff0,DISK], DatanodeInfoWithStorage[127.0.0.1:35009,DS-31f66a47-e5ce-44af-bba5-6ce7d94e2b47,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-e998dcf3-64d6-44a6-b0d5-47ec08d1ff69,DISK], DatanodeInfoWithStorage[127.0.0.1:42486,DS-fb13a561-51c4-4c1c-b76f-908cb784cb7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40640,DS-f93e14dd-cfad-4188-a404-54269c57b074,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-1ac9e749-e285-4274-ba17-b88910a26e46,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-d5f9ba9f-c67d-496f-88b5-88792d6e3fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-e0f40de4-342a-4559-81e0-bb472617e338,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1361716075-172.17.0.16-1597398129874:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46626,DS-7a98b304-6924-46ae-a3cd-4df43082a906,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-dd83112e-249b-45ab-b4a4-11c43e6bf348,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-b095267a-69d4-48da-a0a6-e75af32a2810,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-50895b11-bed8-4d70-8683-49c4b8e464e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-1438e028-bd18-4f95-8ff7-4925cd00054c,DISK], DatanodeInfoWithStorage[127.0.0.1:40675,DS-57120e5c-a972-4857-8d57-1fdbd49288f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-0410a353-7b0a-4d40-9de4-67ef649389d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-d70a9a03-b44e-4fb9-8c6a-402226a36d10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1361716075-172.17.0.16-1597398129874:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46626,DS-7a98b304-6924-46ae-a3cd-4df43082a906,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-dd83112e-249b-45ab-b4a4-11c43e6bf348,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-b095267a-69d4-48da-a0a6-e75af32a2810,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-50895b11-bed8-4d70-8683-49c4b8e464e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-1438e028-bd18-4f95-8ff7-4925cd00054c,DISK], DatanodeInfoWithStorage[127.0.0.1:40675,DS-57120e5c-a972-4857-8d57-1fdbd49288f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-0410a353-7b0a-4d40-9de4-67ef649389d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35064,DS-d70a9a03-b44e-4fb9-8c6a-402226a36d10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-386902015-172.17.0.16-1597398328924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37973,DS-9d6e764b-ae0b-4559-a73c-f29211663962,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-f61cc06d-0f26-430a-b6e8-2a1f2feea966,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-2119ed1c-9211-478c-90c3-ef3b005c688b,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-20ab2ffa-e570-48ef-aa2b-76d932ac8bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-7bf389d0-2888-4f4d-9450-bda6cdbc9a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-e68ff59c-a150-42c8-872a-394625a60483,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-64ae6a09-ae42-46c1-ad5a-306a190706aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-256492b1-23cc-4d2d-9048-793da3e2b237,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-386902015-172.17.0.16-1597398328924:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37973,DS-9d6e764b-ae0b-4559-a73c-f29211663962,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-f61cc06d-0f26-430a-b6e8-2a1f2feea966,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-2119ed1c-9211-478c-90c3-ef3b005c688b,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-20ab2ffa-e570-48ef-aa2b-76d932ac8bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-7bf389d0-2888-4f4d-9450-bda6cdbc9a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-e68ff59c-a150-42c8-872a-394625a60483,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-64ae6a09-ae42-46c1-ad5a-306a190706aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-256492b1-23cc-4d2d-9048-793da3e2b237,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-859651310-172.17.0.16-1597398368264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46727,DS-f84937fc-ee36-43cc-95c7-434d9ba92b73,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-560a7a93-7ce4-4ffc-bea5-7b3c5a76f060,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-2f01d9d0-2707-4b34-a172-6adc016286c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-f11e8645-3c53-4861-a1ae-c62fe0d1c8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-290c826a-4b06-43b8-ab5d-ca85dc7c11b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-3b216c47-6e55-43f0-9274-5eac353929fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-be119f1a-e61c-43f0-baaf-1f12fe21537b,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-9b9223f2-5f0f-49d1-8909-d7b322d3fe84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-859651310-172.17.0.16-1597398368264:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46727,DS-f84937fc-ee36-43cc-95c7-434d9ba92b73,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-560a7a93-7ce4-4ffc-bea5-7b3c5a76f060,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-2f01d9d0-2707-4b34-a172-6adc016286c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-f11e8645-3c53-4861-a1ae-c62fe0d1c8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-290c826a-4b06-43b8-ab5d-ca85dc7c11b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40591,DS-3b216c47-6e55-43f0-9274-5eac353929fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-be119f1a-e61c-43f0-baaf-1f12fe21537b,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-9b9223f2-5f0f-49d1-8909-d7b322d3fe84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1623796709-172.17.0.16-1597398468926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34161,DS-d05f583b-356d-4e60-b865-f0ec9fd8163a,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-38b72747-f099-4b3a-8e42-cb512b372b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-0487ba72-105f-4960-a150-126a7c670914,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-8902d577-a198-4863-bf3f-fee82ae91405,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-d5ffc8d0-8260-4827-99c5-c97036f3d47e,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-fb750bac-7104-415a-ab5b-9259750aa4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-f7f33b97-d87b-401f-a9cc-d21f8bf050c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-9cbc86ff-f397-4f52-995d-eaaaa65f35e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1623796709-172.17.0.16-1597398468926:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34161,DS-d05f583b-356d-4e60-b865-f0ec9fd8163a,DISK], DatanodeInfoWithStorage[127.0.0.1:44519,DS-38b72747-f099-4b3a-8e42-cb512b372b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-0487ba72-105f-4960-a150-126a7c670914,DISK], DatanodeInfoWithStorage[127.0.0.1:40439,DS-8902d577-a198-4863-bf3f-fee82ae91405,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-d5ffc8d0-8260-4827-99c5-c97036f3d47e,DISK], DatanodeInfoWithStorage[127.0.0.1:36029,DS-fb750bac-7104-415a-ab5b-9259750aa4f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-f7f33b97-d87b-401f-a9cc-d21f8bf050c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-9cbc86ff-f397-4f52-995d-eaaaa65f35e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-887015552-172.17.0.16-1597398575042:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38339,DS-5a0e98e9-66a4-4c80-8d06-59fcfc278761,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-53ccb0f0-a3f7-48ed-8bea-143c7d1f2028,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-c9e41663-0fb1-4614-bfe4-510830935ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-16d4efcb-c7dd-47dc-8118-d8ebabfe1b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-a82cdbf2-5a2d-4366-a27a-1f3f5c8e4b66,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-b490bf32-15ce-419d-960d-48c224cc5b44,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-a2743983-f175-4265-af7b-6b88478c1015,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-538174ed-c63b-4d12-a8c0-9f201994abd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-887015552-172.17.0.16-1597398575042:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38339,DS-5a0e98e9-66a4-4c80-8d06-59fcfc278761,DISK], DatanodeInfoWithStorage[127.0.0.1:36835,DS-53ccb0f0-a3f7-48ed-8bea-143c7d1f2028,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-c9e41663-0fb1-4614-bfe4-510830935ce1,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-16d4efcb-c7dd-47dc-8118-d8ebabfe1b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-a82cdbf2-5a2d-4366-a27a-1f3f5c8e4b66,DISK], DatanodeInfoWithStorage[127.0.0.1:42307,DS-b490bf32-15ce-419d-960d-48c224cc5b44,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-a2743983-f175-4265-af7b-6b88478c1015,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-538174ed-c63b-4d12-a8c0-9f201994abd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1223333206-172.17.0.16-1597398675143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40076,DS-cceaa813-a855-46d3-8db7-9409a4b3b6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-5a13cd7a-32ac-4f15-8848-47bdd87a8000,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-8d185a03-94e8-48be-a6c4-a9dacd3e9c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-db151d01-593c-4828-9196-ad84a03a1062,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-d965a48e-f096-48e1-bee7-c3565a353709,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-1bc22d67-89c3-4ad8-8f52-89a3b42563bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-a52421d3-e90b-4e8e-a995-d4b5bb47ad01,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-05859e03-8a73-42dd-9182-f3d3d1bf120a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1223333206-172.17.0.16-1597398675143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40076,DS-cceaa813-a855-46d3-8db7-9409a4b3b6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-5a13cd7a-32ac-4f15-8848-47bdd87a8000,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-8d185a03-94e8-48be-a6c4-a9dacd3e9c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-db151d01-593c-4828-9196-ad84a03a1062,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-d965a48e-f096-48e1-bee7-c3565a353709,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-1bc22d67-89c3-4ad8-8f52-89a3b42563bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43322,DS-a52421d3-e90b-4e8e-a995-d4b5bb47ad01,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-05859e03-8a73-42dd-9182-f3d3d1bf120a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1078567630-172.17.0.16-1597399119491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45780,DS-1bad4beb-ad78-4567-8edf-859afb98d1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-952c38cf-a96b-430c-890e-f386ae023713,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-b4b7256e-8107-4b4a-87ad-978af5a43600,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-6dafc834-47a5-4380-bc52-93c149f5fd47,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-3dbfdfd3-14b7-4122-97d9-d8626acd4164,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-d2a64570-a50e-4dbf-9457-49752e343877,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-e3c1d0cf-13ea-464b-b651-bc74b488f79a,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-6b0cab2e-b9f9-4cc2-bb70-fd17c6c9710e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1078567630-172.17.0.16-1597399119491:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45780,DS-1bad4beb-ad78-4567-8edf-859afb98d1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45845,DS-952c38cf-a96b-430c-890e-f386ae023713,DISK], DatanodeInfoWithStorage[127.0.0.1:41570,DS-b4b7256e-8107-4b4a-87ad-978af5a43600,DISK], DatanodeInfoWithStorage[127.0.0.1:36762,DS-6dafc834-47a5-4380-bc52-93c149f5fd47,DISK], DatanodeInfoWithStorage[127.0.0.1:39791,DS-3dbfdfd3-14b7-4122-97d9-d8626acd4164,DISK], DatanodeInfoWithStorage[127.0.0.1:39770,DS-d2a64570-a50e-4dbf-9457-49752e343877,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-e3c1d0cf-13ea-464b-b651-bc74b488f79a,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-6b0cab2e-b9f9-4cc2-bb70-fd17c6c9710e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1830886508-172.17.0.16-1597399304083:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46357,DS-90887c4b-e569-4b31-8f69-60bb971d1d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-f370f44d-6514-4419-a916-655b306f9312,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-6c14f902-3624-4148-9a50-e980a4f9fdbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-8495f1e9-1427-4f1f-bdda-80ae358a3c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-3837282b-0138-439f-a047-ef0e005c69db,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-c11327d0-e613-4533-8625-18a8798f079b,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-e522bf10-aace-46af-a630-be3a00b62b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-fdf1a800-d23f-49a2-aca1-86fde5e75d70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1830886508-172.17.0.16-1597399304083:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46357,DS-90887c4b-e569-4b31-8f69-60bb971d1d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-f370f44d-6514-4419-a916-655b306f9312,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-6c14f902-3624-4148-9a50-e980a4f9fdbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-8495f1e9-1427-4f1f-bdda-80ae358a3c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45972,DS-3837282b-0138-439f-a047-ef0e005c69db,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-c11327d0-e613-4533-8625-18a8798f079b,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-e522bf10-aace-46af-a630-be3a00b62b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41207,DS-fdf1a800-d23f-49a2-aca1-86fde5e75d70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1870000823-172.17.0.16-1597399342177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40376,DS-309034d9-3ea2-4967-87d5-7e10a9f6642f,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-0eb65b95-8764-4634-95be-75d601660106,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-9301f56a-6bf9-4faf-8fcc-4618e83bffc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-cdcca488-cded-416d-bb83-27f02c4d782f,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-cd9d4d1b-e014-4395-bd75-b238800c5195,DISK], DatanodeInfoWithStorage[127.0.0.1:34378,DS-9dec952d-e255-4df9-b3a4-958fd9f72274,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-365085c9-6d47-46e1-93c7-1c9fb2e6e027,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-05714f9d-9ee6-4973-936a-6dc0439f24e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1870000823-172.17.0.16-1597399342177:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40376,DS-309034d9-3ea2-4967-87d5-7e10a9f6642f,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-0eb65b95-8764-4634-95be-75d601660106,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-9301f56a-6bf9-4faf-8fcc-4618e83bffc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-cdcca488-cded-416d-bb83-27f02c4d782f,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-cd9d4d1b-e014-4395-bd75-b238800c5195,DISK], DatanodeInfoWithStorage[127.0.0.1:34378,DS-9dec952d-e255-4df9-b3a4-958fd9f72274,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-365085c9-6d47-46e1-93c7-1c9fb2e6e027,DISK], DatanodeInfoWithStorage[127.0.0.1:40085,DS-05714f9d-9ee6-4973-936a-6dc0439f24e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1440776912-172.17.0.16-1597399594304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33044,DS-a03ab4f9-9814-4ce9-9df8-5e5f0db46caa,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-5afa302a-d274-4077-9dd3-49a67836bde7,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-0453ea3a-13c8-4732-938f-5d13dead070d,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-bd627d66-404e-4f86-b8f3-35d2816143b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-712c16b8-3124-4427-b7f5-ce4013a10706,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-e3c80976-a5c8-43f1-bfc3-10b343723e44,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-616be79d-59ba-4ba5-b3bd-d50bccd08e28,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-c2dd884b-532b-47e6-9b33-855ad08df6cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1440776912-172.17.0.16-1597399594304:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33044,DS-a03ab4f9-9814-4ce9-9df8-5e5f0db46caa,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-5afa302a-d274-4077-9dd3-49a67836bde7,DISK], DatanodeInfoWithStorage[127.0.0.1:44473,DS-0453ea3a-13c8-4732-938f-5d13dead070d,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-bd627d66-404e-4f86-b8f3-35d2816143b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-712c16b8-3124-4427-b7f5-ce4013a10706,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-e3c80976-a5c8-43f1-bfc3-10b343723e44,DISK], DatanodeInfoWithStorage[127.0.0.1:34660,DS-616be79d-59ba-4ba5-b3bd-d50bccd08e28,DISK], DatanodeInfoWithStorage[127.0.0.1:37057,DS-c2dd884b-532b-47e6-9b33-855ad08df6cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2135790495-172.17.0.16-1597400131411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35424,DS-2acc31c3-491a-49e4-aa4c-54899a822958,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-2e99daae-9ba7-4ebb-87db-a3de44b5b6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-e3439427-017b-4733-ab01-02cb989b4650,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-fe97ec95-d8ff-46fe-9180-604b02eb918d,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-d5bd878b-f084-4b82-810d-a3e6253da10f,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-4d46360f-e4e3-4ad2-a0be-c4ec2174e159,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-e22f29bc-a94d-4672-b5c1-c84e6e06e3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-3a12ac74-e487-49da-a4b8-c07630a3f69b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2135790495-172.17.0.16-1597400131411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35424,DS-2acc31c3-491a-49e4-aa4c-54899a822958,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-2e99daae-9ba7-4ebb-87db-a3de44b5b6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-e3439427-017b-4733-ab01-02cb989b4650,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-fe97ec95-d8ff-46fe-9180-604b02eb918d,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-d5bd878b-f084-4b82-810d-a3e6253da10f,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-4d46360f-e4e3-4ad2-a0be-c4ec2174e159,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-e22f29bc-a94d-4672-b5c1-c84e6e06e3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-3a12ac74-e487-49da-a4b8-c07630a3f69b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1722504502-172.17.0.16-1597400228724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37476,DS-b96b673e-0de6-4628-85b7-f9e433797e75,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-38e916c9-ac50-4641-88ef-5078bd965da2,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-c6fbe4ff-8bd1-461d-b957-4e4c28aab69e,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-42633fa0-8209-4fb3-a989-4248aec9077d,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-b949b330-c3c8-4e9d-8d11-9e4d7a477775,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-a43a8fb7-5794-4e09-b9d1-ce02a4728d87,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-9f1218b6-aaf8-460c-a1f8-3d791a93155b,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-f55daa21-7cc3-42d1-8a06-7bd406fb7a91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1722504502-172.17.0.16-1597400228724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37476,DS-b96b673e-0de6-4628-85b7-f9e433797e75,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-38e916c9-ac50-4641-88ef-5078bd965da2,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-c6fbe4ff-8bd1-461d-b957-4e4c28aab69e,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-42633fa0-8209-4fb3-a989-4248aec9077d,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-b949b330-c3c8-4e9d-8d11-9e4d7a477775,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-a43a8fb7-5794-4e09-b9d1-ce02a4728d87,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-9f1218b6-aaf8-460c-a1f8-3d791a93155b,DISK], DatanodeInfoWithStorage[127.0.0.1:33520,DS-f55daa21-7cc3-42d1-8a06-7bd406fb7a91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1140468602-172.17.0.16-1597401006825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39205,DS-4d4f0f14-cd02-4550-9ebd-30ccd16fcab7,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-5654e6d3-d895-4a7e-9ca3-7c0ab9941baa,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-666499d2-8c8c-483e-bcfe-115d4de5875d,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-2ad4d897-e52c-43ba-b945-ae2329908b21,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-f4e74230-655e-4a9f-af84-7d1c44ccf37b,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-0ff11766-a095-4081-8042-09c20a94d97a,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-7b0710ee-3fb3-456b-a5f7-61cf69090309,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-549faaa8-1e38-493d-99dd-cd77ff4f3cf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1140468602-172.17.0.16-1597401006825:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39205,DS-4d4f0f14-cd02-4550-9ebd-30ccd16fcab7,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-5654e6d3-d895-4a7e-9ca3-7c0ab9941baa,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-666499d2-8c8c-483e-bcfe-115d4de5875d,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-2ad4d897-e52c-43ba-b945-ae2329908b21,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-f4e74230-655e-4a9f-af84-7d1c44ccf37b,DISK], DatanodeInfoWithStorage[127.0.0.1:44083,DS-0ff11766-a095-4081-8042-09c20a94d97a,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-7b0710ee-3fb3-456b-a5f7-61cf69090309,DISK], DatanodeInfoWithStorage[127.0.0.1:42911,DS-549faaa8-1e38-493d-99dd-cd77ff4f3cf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1187102344-172.17.0.16-1597401041508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34068,DS-e3e25932-4d60-4f0f-90a2-d49596e4dba7,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-bdbfa1ba-b522-40cf-8345-8cdf874766f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-794b18bd-b457-4ad9-b8d7-e88fd84f8938,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-938eef76-7c8c-4300-8865-2710e6e4e602,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-f1d5cb19-26b6-4b56-8154-bef31b68ce69,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-83b8ad10-4ff3-4342-a843-f448e83280f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-12fe8599-a9b1-49b3-91aa-42a0af004559,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-06a0b35c-98d9-4113-a1da-7d0ddde8949e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1187102344-172.17.0.16-1597401041508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34068,DS-e3e25932-4d60-4f0f-90a2-d49596e4dba7,DISK], DatanodeInfoWithStorage[127.0.0.1:34572,DS-bdbfa1ba-b522-40cf-8345-8cdf874766f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-794b18bd-b457-4ad9-b8d7-e88fd84f8938,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-938eef76-7c8c-4300-8865-2710e6e4e602,DISK], DatanodeInfoWithStorage[127.0.0.1:35099,DS-f1d5cb19-26b6-4b56-8154-bef31b68ce69,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-83b8ad10-4ff3-4342-a843-f448e83280f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-12fe8599-a9b1-49b3-91aa-42a0af004559,DISK], DatanodeInfoWithStorage[127.0.0.1:41805,DS-06a0b35c-98d9-4113-a1da-7d0ddde8949e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 5
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-895487822-172.17.0.16-1597401295765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37673,DS-88ecc2cc-45c9-48e5-bc9c-bf476f32be61,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-ec464bc8-eba5-4a99-9aca-5aeae1428a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-a7c366c6-4e92-45ff-9e40-cc7db5401662,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-f0625ca7-0fb6-4dd6-ac46-9ee319e46eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-2c37e924-768f-4950-acf8-d1561ada38c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-640df697-a878-4bc2-9b14-0c552f5378ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-77731c39-032a-4720-8860-2298e668cdd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-7d80e30f-8c1c-47ef-a78c-245b33ed0083,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-895487822-172.17.0.16-1597401295765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37673,DS-88ecc2cc-45c9-48e5-bc9c-bf476f32be61,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-ec464bc8-eba5-4a99-9aca-5aeae1428a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:46249,DS-a7c366c6-4e92-45ff-9e40-cc7db5401662,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-f0625ca7-0fb6-4dd6-ac46-9ee319e46eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-2c37e924-768f-4950-acf8-d1561ada38c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-640df697-a878-4bc2-9b14-0c552f5378ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-77731c39-032a-4720-8860-2298e668cdd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-7d80e30f-8c1c-47ef-a78c-245b33ed0083,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5211
