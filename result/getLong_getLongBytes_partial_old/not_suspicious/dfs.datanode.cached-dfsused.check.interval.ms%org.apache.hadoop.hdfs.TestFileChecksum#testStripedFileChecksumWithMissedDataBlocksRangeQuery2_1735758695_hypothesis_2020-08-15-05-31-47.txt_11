reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134333996-172.17.0.4-1597469627295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38930,DS-4d2cf138-5080-4355-84da-ea3fe88ea4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-aa07b88a-38f4-4e0a-8317-7fc809f87a12,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-0dd895dc-164e-4cc0-9c3b-b5448356a5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-5067dfde-ca83-4ad4-9a13-f44813373c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-d61098b9-db94-4b53-8401-62eb3110e818,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-66bdf75d-6d01-40c0-b405-7792241bc212,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-fbecf4fe-553e-48d8-8183-ca38f5ff8029,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-89dc1e21-92ea-4a87-86d4-b5400b284b00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-134333996-172.17.0.4-1597469627295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38930,DS-4d2cf138-5080-4355-84da-ea3fe88ea4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-aa07b88a-38f4-4e0a-8317-7fc809f87a12,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-0dd895dc-164e-4cc0-9c3b-b5448356a5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43975,DS-5067dfde-ca83-4ad4-9a13-f44813373c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35746,DS-d61098b9-db94-4b53-8401-62eb3110e818,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-66bdf75d-6d01-40c0-b405-7792241bc212,DISK], DatanodeInfoWithStorage[127.0.0.1:41097,DS-fbecf4fe-553e-48d8-8183-ca38f5ff8029,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-89dc1e21-92ea-4a87-86d4-b5400b284b00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-156805675-172.17.0.4-1597469698396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34765,DS-0eaa3c41-5929-40b4-9ea3-8ac7eed707a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-a90ae438-1a41-4f21-bd47-e6edc0e987ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-231a2f77-1d0c-4904-9306-50514d40b242,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-131f4926-b352-45fb-b9f5-0f146f46ae99,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-e731f4be-33e5-4a85-ad16-f9fc6f969b71,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-34d4bb7a-05e7-47d8-9aba-e799ba9f3f07,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-64263b8d-1c9a-4f6d-8a41-17b44d30df71,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-ab8e2b53-7375-405f-ac5b-bbfdf5df204e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-156805675-172.17.0.4-1597469698396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34765,DS-0eaa3c41-5929-40b4-9ea3-8ac7eed707a2,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-a90ae438-1a41-4f21-bd47-e6edc0e987ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-231a2f77-1d0c-4904-9306-50514d40b242,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-131f4926-b352-45fb-b9f5-0f146f46ae99,DISK], DatanodeInfoWithStorage[127.0.0.1:34721,DS-e731f4be-33e5-4a85-ad16-f9fc6f969b71,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-34d4bb7a-05e7-47d8-9aba-e799ba9f3f07,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-64263b8d-1c9a-4f6d-8a41-17b44d30df71,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-ab8e2b53-7375-405f-ac5b-bbfdf5df204e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-750960279-172.17.0.4-1597470328570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44565,DS-a584e6fd-0ea3-4522-9aaa-3754b07625eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-446544d9-1130-43fc-9a3e-c919d1558f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-1ae8e93a-8fd5-4fca-84e4-b43cf1a89607,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-52bdf5e9-f1bc-4316-9d34-2b65586cf7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-49a20dee-a267-419a-8711-4539c2f23bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-7591c368-eb59-4a46-9d7f-40a2891e5cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-5e26dad2-d4f2-4827-998d-e51dc21112eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-b42d7fd2-e0ca-46e9-8398-abbe26e285e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-750960279-172.17.0.4-1597470328570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44565,DS-a584e6fd-0ea3-4522-9aaa-3754b07625eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35717,DS-446544d9-1130-43fc-9a3e-c919d1558f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-1ae8e93a-8fd5-4fca-84e4-b43cf1a89607,DISK], DatanodeInfoWithStorage[127.0.0.1:43040,DS-52bdf5e9-f1bc-4316-9d34-2b65586cf7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-49a20dee-a267-419a-8711-4539c2f23bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-7591c368-eb59-4a46-9d7f-40a2891e5cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43959,DS-5e26dad2-d4f2-4827-998d-e51dc21112eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-b42d7fd2-e0ca-46e9-8398-abbe26e285e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1171268267-172.17.0.4-1597470698712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33250,DS-13fab1de-836c-4025-ba25-3b1639995374,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-6290c21c-f38e-4c74-a4c1-0a53252b3c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-8bb6b3ce-46d1-49f9-9df1-1a2daf23089c,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-19c0ae45-081d-4fc8-8213-717a22d0f83b,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-0407852a-44fa-4b33-9057-334eb205d784,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-53871080-1015-421c-9d17-de243cd5cdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-60e0cf7d-b406-4404-b950-cb3d849493e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-8d43d978-e8b7-4d58-982d-2daa788837b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1171268267-172.17.0.4-1597470698712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33250,DS-13fab1de-836c-4025-ba25-3b1639995374,DISK], DatanodeInfoWithStorage[127.0.0.1:42097,DS-6290c21c-f38e-4c74-a4c1-0a53252b3c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-8bb6b3ce-46d1-49f9-9df1-1a2daf23089c,DISK], DatanodeInfoWithStorage[127.0.0.1:46822,DS-19c0ae45-081d-4fc8-8213-717a22d0f83b,DISK], DatanodeInfoWithStorage[127.0.0.1:33657,DS-0407852a-44fa-4b33-9057-334eb205d784,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-53871080-1015-421c-9d17-de243cd5cdf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-60e0cf7d-b406-4404-b950-cb3d849493e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-8d43d978-e8b7-4d58-982d-2daa788837b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20114752-172.17.0.4-1597471280871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44732,DS-5db18abb-3375-4f74-823d-ec815410703a,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-600f5063-3a4a-4a8b-812d-fe198bc9e6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-09d1911a-0c76-44bd-8300-0dfd2106fa6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-f45ad54c-a8a3-4933-9652-ca323d97d265,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-37df9c24-6b6d-4169-b751-aa47ec575327,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-0c368b35-8df2-410f-979c-8997572cf168,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-c1f98c56-0c4b-4fef-96bb-d2baa8332a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-21be207d-b2f0-4fad-bb40-0a29c20097af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-20114752-172.17.0.4-1597471280871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44732,DS-5db18abb-3375-4f74-823d-ec815410703a,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-600f5063-3a4a-4a8b-812d-fe198bc9e6a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-09d1911a-0c76-44bd-8300-0dfd2106fa6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-f45ad54c-a8a3-4933-9652-ca323d97d265,DISK], DatanodeInfoWithStorage[127.0.0.1:34178,DS-37df9c24-6b6d-4169-b751-aa47ec575327,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-0c368b35-8df2-410f-979c-8997572cf168,DISK], DatanodeInfoWithStorage[127.0.0.1:39161,DS-c1f98c56-0c4b-4fef-96bb-d2baa8332a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38239,DS-21be207d-b2f0-4fad-bb40-0a29c20097af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344114061-172.17.0.4-1597471562782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46768,DS-6d6ac34b-8347-4cc6-bf34-6c7d92bd1c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-6eb565c2-c8a4-452d-bf0f-bf6f5ac13292,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-4819673f-31a7-4ad5-8527-0611b95e2c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-40aac8a4-1ff5-4dfd-9d01-1fa68a1dcdd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-2c3cd916-16fb-4516-bc9f-c0a8afe693c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-ee80b678-1845-4bd1-b8a0-dab12e0f90f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-be241716-ef2e-454e-8846-1233345e2cac,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-e4db7c02-d6c3-46fe-98dc-31f164932842,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-344114061-172.17.0.4-1597471562782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46768,DS-6d6ac34b-8347-4cc6-bf34-6c7d92bd1c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-6eb565c2-c8a4-452d-bf0f-bf6f5ac13292,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-4819673f-31a7-4ad5-8527-0611b95e2c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-40aac8a4-1ff5-4dfd-9d01-1fa68a1dcdd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33608,DS-2c3cd916-16fb-4516-bc9f-c0a8afe693c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-ee80b678-1845-4bd1-b8a0-dab12e0f90f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-be241716-ef2e-454e-8846-1233345e2cac,DISK], DatanodeInfoWithStorage[127.0.0.1:42715,DS-e4db7c02-d6c3-46fe-98dc-31f164932842,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2036232091-172.17.0.4-1597472484337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45040,DS-bfd3965a-a91d-4f75-b668-7579a55fbb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-44041d45-ecda-4936-a0a4-418e6b045b76,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-3f2a4e6f-1c85-4aac-be09-192e60cac2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-d62e7658-7e4a-4726-af6d-bf3ff215030d,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-dca43b4a-c8ff-4e78-ac6a-8af094067786,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-10c37817-1d40-48ca-9d4c-68b9014d61a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-542b9335-3199-455f-90db-a549857cd8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-5d406230-16ff-4147-9aad-061ef0788b0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2036232091-172.17.0.4-1597472484337:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45040,DS-bfd3965a-a91d-4f75-b668-7579a55fbb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:41943,DS-44041d45-ecda-4936-a0a4-418e6b045b76,DISK], DatanodeInfoWithStorage[127.0.0.1:40426,DS-3f2a4e6f-1c85-4aac-be09-192e60cac2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-d62e7658-7e4a-4726-af6d-bf3ff215030d,DISK], DatanodeInfoWithStorage[127.0.0.1:33017,DS-dca43b4a-c8ff-4e78-ac6a-8af094067786,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-10c37817-1d40-48ca-9d4c-68b9014d61a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-542b9335-3199-455f-90db-a549857cd8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-5d406230-16ff-4147-9aad-061ef0788b0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1151722733-172.17.0.4-1597472673965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42572,DS-8c56e1ab-a6ab-4e6c-a630-b731c8e71b40,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-cb6d3192-27b0-4f1a-8ce9-ae77eba6d646,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-0aa2777a-4472-495d-a2ce-c45322c73421,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-b67a5f62-f13d-4c95-b5a8-dde65d49adae,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-6b345cb2-44e3-4eb0-a58a-1027db69cc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-326e1e38-9242-4299-906b-be842f593bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-d62ec44f-c04c-4bd3-86c3-e27228ffe840,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-84252321-612b-43ec-a62c-871302a581df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1151722733-172.17.0.4-1597472673965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42572,DS-8c56e1ab-a6ab-4e6c-a630-b731c8e71b40,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-cb6d3192-27b0-4f1a-8ce9-ae77eba6d646,DISK], DatanodeInfoWithStorage[127.0.0.1:41236,DS-0aa2777a-4472-495d-a2ce-c45322c73421,DISK], DatanodeInfoWithStorage[127.0.0.1:37945,DS-b67a5f62-f13d-4c95-b5a8-dde65d49adae,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-6b345cb2-44e3-4eb0-a58a-1027db69cc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-326e1e38-9242-4299-906b-be842f593bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44411,DS-d62ec44f-c04c-4bd3-86c3-e27228ffe840,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-84252321-612b-43ec-a62c-871302a581df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962814550-172.17.0.4-1597473586011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33922,DS-4e2297f6-3762-4032-af37-6888888752ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-e9de8581-0b65-4c62-ac40-17aab4ae2a83,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-a8266b5b-0210-4d6b-a850-fb11353b88ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-c9d676d4-6148-44e7-ac0f-e4feef6da0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-575b36fb-de77-4659-866a-6bc0e1b62b47,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-27506676-7cb7-4499-a98d-8408da5454ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-cf2c9346-a31b-4113-9943-532ac6c80568,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-c1e27399-056f-4e53-bc0a-74fbb175865d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1962814550-172.17.0.4-1597473586011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33922,DS-4e2297f6-3762-4032-af37-6888888752ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-e9de8581-0b65-4c62-ac40-17aab4ae2a83,DISK], DatanodeInfoWithStorage[127.0.0.1:33553,DS-a8266b5b-0210-4d6b-a850-fb11353b88ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-c9d676d4-6148-44e7-ac0f-e4feef6da0e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-575b36fb-de77-4659-866a-6bc0e1b62b47,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-27506676-7cb7-4499-a98d-8408da5454ba,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-cf2c9346-a31b-4113-9943-532ac6c80568,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-c1e27399-056f-4e53-bc0a-74fbb175865d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-984920967-172.17.0.4-1597473702293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40783,DS-5c3772a7-64a9-45bf-b8ac-e805fe2d2efa,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-09fcf1d7-1456-41c9-8207-901ee29b27d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-238f0635-69c5-4ca4-962b-3eb1f4d3c046,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-6eb01765-e2a1-45ef-a5a9-0d721e1465a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-bf818176-0fe1-4600-a9d1-ecde597be032,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-2036d1e2-99a3-41d7-8d6f-0058ec7136b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-5a289238-3308-4b54-9b8e-5f4ce0a22a60,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-d94b9899-61db-4bdd-bd5d-272419a935d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-984920967-172.17.0.4-1597473702293:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40783,DS-5c3772a7-64a9-45bf-b8ac-e805fe2d2efa,DISK], DatanodeInfoWithStorage[127.0.0.1:34603,DS-09fcf1d7-1456-41c9-8207-901ee29b27d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38014,DS-238f0635-69c5-4ca4-962b-3eb1f4d3c046,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-6eb01765-e2a1-45ef-a5a9-0d721e1465a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-bf818176-0fe1-4600-a9d1-ecde597be032,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-2036d1e2-99a3-41d7-8d6f-0058ec7136b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45644,DS-5a289238-3308-4b54-9b8e-5f4ce0a22a60,DISK], DatanodeInfoWithStorage[127.0.0.1:45756,DS-d94b9899-61db-4bdd-bd5d-272419a935d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1190329505-172.17.0.4-1597474353214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39822,DS-343dbf67-6cd5-485c-ac83-b1bed1eb2b64,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-e0509207-03c2-40e3-bd3f-1abe9760af26,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-e03f8497-4562-427b-a9ef-177094c285ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-2c4e5378-be90-4946-a34c-849316d6a464,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-32e0aa6e-9668-4812-a055-8a537bc0456d,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-be88cd23-d507-4c22-94fe-fcac45fe85fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-1a141b89-7830-4030-a69a-4965edc27a22,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-c433c3f2-7827-4ae3-beee-38d9ec41de78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1190329505-172.17.0.4-1597474353214:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39822,DS-343dbf67-6cd5-485c-ac83-b1bed1eb2b64,DISK], DatanodeInfoWithStorage[127.0.0.1:43985,DS-e0509207-03c2-40e3-bd3f-1abe9760af26,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-e03f8497-4562-427b-a9ef-177094c285ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-2c4e5378-be90-4946-a34c-849316d6a464,DISK], DatanodeInfoWithStorage[127.0.0.1:40420,DS-32e0aa6e-9668-4812-a055-8a537bc0456d,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-be88cd23-d507-4c22-94fe-fcac45fe85fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-1a141b89-7830-4030-a69a-4965edc27a22,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-c433c3f2-7827-4ae3-beee-38d9ec41de78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214866547-172.17.0.4-1597474641745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44047,DS-798e8a4b-6750-4212-8aea-5ed4faadc53a,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-dfc2721a-6eba-46a9-b569-3c2792bdb588,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-926a8fbd-051d-4503-b53f-af98374722b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-d2b901c2-9f5c-474e-acc1-d213706dc2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-b0a8ee92-192f-4228-99e7-cc8d8c03db63,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-d3a296ad-6d52-4654-8097-d714c2a2aecb,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-5b7d39b1-178d-4886-b75f-e44786faa14a,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-b118251f-8332-46b7-9d2a-699a8631c262,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214866547-172.17.0.4-1597474641745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44047,DS-798e8a4b-6750-4212-8aea-5ed4faadc53a,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-dfc2721a-6eba-46a9-b569-3c2792bdb588,DISK], DatanodeInfoWithStorage[127.0.0.1:34272,DS-926a8fbd-051d-4503-b53f-af98374722b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-d2b901c2-9f5c-474e-acc1-d213706dc2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-b0a8ee92-192f-4228-99e7-cc8d8c03db63,DISK], DatanodeInfoWithStorage[127.0.0.1:45399,DS-d3a296ad-6d52-4654-8097-d714c2a2aecb,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-5b7d39b1-178d-4886-b75f-e44786faa14a,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-b118251f-8332-46b7-9d2a-699a8631c262,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.cached-dfsused.check.interval.ms
component: hdfs:DataNode
v1: 600000
v2: 6000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1186423027-172.17.0.4-1597474725972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42554,DS-e057145f-4d76-4824-8242-bb42c8b58c30,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-52eb791e-0f5f-4a4e-b929-93d75507f6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-56c94c08-eb46-4709-8b32-427d983ee2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-048fecb0-cc49-487f-b9b9-df738df3c85d,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-f2b5d8c8-a1d5-452f-9690-1de76b3b815f,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-9b031e01-cfde-4483-8597-08da9c9edfdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-86b926b9-ff41-4aa3-a166-a07892cd9da8,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-e2a14763-c4de-48b4-99ef-08a806366830,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1186423027-172.17.0.4-1597474725972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42554,DS-e057145f-4d76-4824-8242-bb42c8b58c30,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-52eb791e-0f5f-4a4e-b929-93d75507f6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-56c94c08-eb46-4709-8b32-427d983ee2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-048fecb0-cc49-487f-b9b9-df738df3c85d,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-f2b5d8c8-a1d5-452f-9690-1de76b3b815f,DISK], DatanodeInfoWithStorage[127.0.0.1:39962,DS-9b031e01-cfde-4483-8597-08da9c9edfdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-86b926b9-ff41-4aa3-a166-a07892cd9da8,DISK], DatanodeInfoWithStorage[127.0.0.1:41519,DS-e2a14763-c4de-48b4-99ef-08a806366830,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5612
