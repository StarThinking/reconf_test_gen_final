reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-449537333-172.17.0.9-1597543647558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37825,DS-b80e45d7-a898-476f-92e5-fe5d842dd04e,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-94fac17c-7377-45a3-adb9-7dbed3ff09f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-3505a762-7deb-41dd-9885-dfc7623782b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-f881e827-f290-4d32-856e-82954f65ea03,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-753117d3-ccbe-46f4-a9b6-6461887b8777,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-2376b009-9e00-42b3-97bd-06acb28d6eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-16b8fe31-c2fd-42a7-9ea6-b4f9aa4b757a,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-e8ed2fcc-c7d1-4c00-96a9-073161e0145f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-449537333-172.17.0.9-1597543647558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37825,DS-b80e45d7-a898-476f-92e5-fe5d842dd04e,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-94fac17c-7377-45a3-adb9-7dbed3ff09f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33605,DS-3505a762-7deb-41dd-9885-dfc7623782b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-f881e827-f290-4d32-856e-82954f65ea03,DISK], DatanodeInfoWithStorage[127.0.0.1:40815,DS-753117d3-ccbe-46f4-a9b6-6461887b8777,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-2376b009-9e00-42b3-97bd-06acb28d6eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41684,DS-16b8fe31-c2fd-42a7-9ea6-b4f9aa4b757a,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-e8ed2fcc-c7d1-4c00-96a9-073161e0145f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597156151-172.17.0.9-1597543753702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36469,DS-96afb57d-e766-476b-ab05-142c1fb0bf83,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-739d8dbb-4eb6-4da9-8b07-224c545a3544,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-a560ce54-695a-479c-ac83-d79285217741,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-e444fd22-01dd-4017-8008-dd7707f6c6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-0a3966f7-4826-4e5a-8af1-db4207e0f23a,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-0494fe5c-7ba6-4a1d-943e-83348ea9585c,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-ae777f73-c72a-4ed0-b450-dceda73fb968,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-1da58a5a-a099-4f94-ba0e-107ac3ce9171,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597156151-172.17.0.9-1597543753702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36469,DS-96afb57d-e766-476b-ab05-142c1fb0bf83,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-739d8dbb-4eb6-4da9-8b07-224c545a3544,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-a560ce54-695a-479c-ac83-d79285217741,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-e444fd22-01dd-4017-8008-dd7707f6c6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-0a3966f7-4826-4e5a-8af1-db4207e0f23a,DISK], DatanodeInfoWithStorage[127.0.0.1:43877,DS-0494fe5c-7ba6-4a1d-943e-83348ea9585c,DISK], DatanodeInfoWithStorage[127.0.0.1:44475,DS-ae777f73-c72a-4ed0-b450-dceda73fb968,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-1da58a5a-a099-4f94-ba0e-107ac3ce9171,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-426507266-172.17.0.9-1597543954316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41587,DS-a17995e2-7de7-4c7f-a760-853c273e886b,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-ff3a5874-6a6b-4aac-889f-fe1644392642,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-bd3ac469-17c3-42eb-a239-9ba62e54287d,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-6b5ba26a-9b4b-46ac-bc67-be31826791d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-42bcac6a-2d7d-4d97-9774-7c82c9222cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-d717bf3d-b343-45d0-9130-9f25810649e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-9163d81f-811c-4985-a134-bc3266cf55f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43671,DS-10354593-2a4b-4355-b7e3-0482c2022018,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-426507266-172.17.0.9-1597543954316:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41587,DS-a17995e2-7de7-4c7f-a760-853c273e886b,DISK], DatanodeInfoWithStorage[127.0.0.1:39869,DS-ff3a5874-6a6b-4aac-889f-fe1644392642,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-bd3ac469-17c3-42eb-a239-9ba62e54287d,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-6b5ba26a-9b4b-46ac-bc67-be31826791d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36904,DS-42bcac6a-2d7d-4d97-9774-7c82c9222cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-d717bf3d-b343-45d0-9130-9f25810649e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-9163d81f-811c-4985-a134-bc3266cf55f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43671,DS-10354593-2a4b-4355-b7e3-0482c2022018,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-439822813-172.17.0.9-1597543990125:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41040,DS-7f25cce4-a996-4f21-8b3a-94770e98093e,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-4aee715f-8eaa-485b-9d57-ed055712b9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-20615776-3584-4848-ad41-5daa6dfb5aff,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-bc2990ff-bb7b-4e5c-abda-c03ce71d133b,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-8488cd73-6879-4152-9f23-b19c4cb25cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-e5a034f1-c777-4376-98d6-7f7f3dfd32ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-a40df0c5-10da-445f-adeb-634b198d3fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-5ead933a-b321-41d8-a358-ed9b0c262d0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-439822813-172.17.0.9-1597543990125:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41040,DS-7f25cce4-a996-4f21-8b3a-94770e98093e,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-4aee715f-8eaa-485b-9d57-ed055712b9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43555,DS-20615776-3584-4848-ad41-5daa6dfb5aff,DISK], DatanodeInfoWithStorage[127.0.0.1:44069,DS-bc2990ff-bb7b-4e5c-abda-c03ce71d133b,DISK], DatanodeInfoWithStorage[127.0.0.1:43875,DS-8488cd73-6879-4152-9f23-b19c4cb25cd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42267,DS-e5a034f1-c777-4376-98d6-7f7f3dfd32ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37404,DS-a40df0c5-10da-445f-adeb-634b198d3fcb,DISK], DatanodeInfoWithStorage[127.0.0.1:42058,DS-5ead933a-b321-41d8-a358-ed9b0c262d0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-97349361-172.17.0.9-1597544369964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42623,DS-638f7c55-0de5-417c-8f7c-ea1497eb7516,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-d376c39a-1f0c-4668-8f18-4e4bfaba0ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-46494919-d7ee-4805-be84-c956529c3a69,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-ac034102-1724-4ab3-9ff8-ac230c8d8805,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-ae0553bb-386c-4187-9d6a-95688c1e57db,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-706d1036-9c24-47fb-8e23-b6c46986d6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-18a9055e-0a59-4edf-a741-de8eb158117b,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-218d48d3-4d1a-471d-99e2-dae9ae8f120e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-97349361-172.17.0.9-1597544369964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42623,DS-638f7c55-0de5-417c-8f7c-ea1497eb7516,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-d376c39a-1f0c-4668-8f18-4e4bfaba0ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-46494919-d7ee-4805-be84-c956529c3a69,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-ac034102-1724-4ab3-9ff8-ac230c8d8805,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-ae0553bb-386c-4187-9d6a-95688c1e57db,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-706d1036-9c24-47fb-8e23-b6c46986d6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-18a9055e-0a59-4edf-a741-de8eb158117b,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-218d48d3-4d1a-471d-99e2-dae9ae8f120e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1556163981-172.17.0.9-1597544760088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33270,DS-afd68043-21ec-46ac-bdc3-39077916be39,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-d2e7ae33-3e0b-451c-b7d9-4097ac149fef,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-555ed25e-53e5-415b-8963-0257d534d858,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-07a3d53d-39bf-457e-a443-ba08a4842d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-f898b0f8-b9a4-4d4f-a896-97cee8d8d4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-0e9e375b-2aeb-4028-a265-ab3927f4e9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-976d5e7a-3e78-4fcc-a4c3-1e85bd721c97,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-c38fa64f-78de-4cb5-9555-a60f3b027164,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1556163981-172.17.0.9-1597544760088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33270,DS-afd68043-21ec-46ac-bdc3-39077916be39,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-d2e7ae33-3e0b-451c-b7d9-4097ac149fef,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-555ed25e-53e5-415b-8963-0257d534d858,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-07a3d53d-39bf-457e-a443-ba08a4842d8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33544,DS-f898b0f8-b9a4-4d4f-a896-97cee8d8d4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-0e9e375b-2aeb-4028-a265-ab3927f4e9c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44209,DS-976d5e7a-3e78-4fcc-a4c3-1e85bd721c97,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-c38fa64f-78de-4cb5-9555-a60f3b027164,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1277679807-172.17.0.9-1597544941019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43523,DS-c58f6d83-a327-471a-bc19-54b6bdf22e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-c6d1b306-6591-448b-9be6-7aabe676080e,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-5784ffb1-0ea8-4965-974f-9f5746c9b491,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-0fc4301f-42be-403c-a480-f2ef749996f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-9ef8b9fd-54e8-4952-bf5c-7e9cca3163fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-34a02227-adb3-431c-b784-8c764a9ac850,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-75af044b-435d-4e3e-8b75-443615134519,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-2fc2e758-e9f6-4e31-aae0-6032505aaeb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1277679807-172.17.0.9-1597544941019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43523,DS-c58f6d83-a327-471a-bc19-54b6bdf22e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-c6d1b306-6591-448b-9be6-7aabe676080e,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-5784ffb1-0ea8-4965-974f-9f5746c9b491,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-0fc4301f-42be-403c-a480-f2ef749996f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-9ef8b9fd-54e8-4952-bf5c-7e9cca3163fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40119,DS-34a02227-adb3-431c-b784-8c764a9ac850,DISK], DatanodeInfoWithStorage[127.0.0.1:43313,DS-75af044b-435d-4e3e-8b75-443615134519,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-2fc2e758-e9f6-4e31-aae0-6032505aaeb0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-940255304-172.17.0.9-1597545567160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42910,DS-234944d5-6de5-4963-b4fb-19564ff18870,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-96e3a7eb-834a-493b-9973-b134ae2fe93a,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-0b3bea51-0ced-4c7e-b21c-15a87ec5f1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-4094d189-bf0b-42d7-94ad-dbd137424703,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-8aa6838b-d70e-40f9-9719-5d6b7fcb2940,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-07cd4932-241c-41ba-9aa0-c8a125978258,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-ebbc3f49-c616-4e42-9cc3-936dc48af4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-fd453c63-eb37-4dc0-b562-78995d238755,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-940255304-172.17.0.9-1597545567160:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42910,DS-234944d5-6de5-4963-b4fb-19564ff18870,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-96e3a7eb-834a-493b-9973-b134ae2fe93a,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-0b3bea51-0ced-4c7e-b21c-15a87ec5f1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35390,DS-4094d189-bf0b-42d7-94ad-dbd137424703,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-8aa6838b-d70e-40f9-9719-5d6b7fcb2940,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-07cd4932-241c-41ba-9aa0-c8a125978258,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-ebbc3f49-c616-4e42-9cc3-936dc48af4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-fd453c63-eb37-4dc0-b562-78995d238755,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-947172729-172.17.0.9-1597545936997:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38366,DS-aa28a813-aec3-4d57-a883-f081a5deb1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-52096c78-8384-4dad-9fc8-7d9dd76247af,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-5ee85f29-8479-4cc8-a116-04648b63fe8d,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-7b943e16-2fb6-4bc3-9ec2-3a4d9a07ed6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-d0aa3379-18e5-4c79-aca8-e42861b0e770,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-0a5d7072-359c-440c-8e21-6e093a1abe93,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-ed785ebb-7e1a-439a-a6e4-c5b3946abeb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-c3addfc0-5a45-4015-afa8-dd2b436e8a2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-947172729-172.17.0.9-1597545936997:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38366,DS-aa28a813-aec3-4d57-a883-f081a5deb1d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41526,DS-52096c78-8384-4dad-9fc8-7d9dd76247af,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-5ee85f29-8479-4cc8-a116-04648b63fe8d,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-7b943e16-2fb6-4bc3-9ec2-3a4d9a07ed6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-d0aa3379-18e5-4c79-aca8-e42861b0e770,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-0a5d7072-359c-440c-8e21-6e093a1abe93,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-ed785ebb-7e1a-439a-a6e4-c5b3946abeb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42126,DS-c3addfc0-5a45-4015-afa8-dd2b436e8a2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-744418308-172.17.0.9-1597546082225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38080,DS-9208702f-3676-40b7-b68e-45f88f539df5,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-51f8802e-8790-4e90-8480-73550c0224b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-fee6867b-b728-4cf4-bf1a-fa6497416aba,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-3c27fb01-175d-418c-bebf-0d51ffa4f4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-a3ca0fb3-5121-4b2b-9a29-7579b971b491,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-66c7ea9c-fa4b-4ec2-82ff-38aab6fd12c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-017cc418-713f-42bf-a7cb-53af253cee67,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-ad9acc5d-f75d-4170-9a59-2b059bb1a9e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-744418308-172.17.0.9-1597546082225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38080,DS-9208702f-3676-40b7-b68e-45f88f539df5,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-51f8802e-8790-4e90-8480-73550c0224b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-fee6867b-b728-4cf4-bf1a-fa6497416aba,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-3c27fb01-175d-418c-bebf-0d51ffa4f4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-a3ca0fb3-5121-4b2b-9a29-7579b971b491,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-66c7ea9c-fa4b-4ec2-82ff-38aab6fd12c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-017cc418-713f-42bf-a7cb-53af253cee67,DISK], DatanodeInfoWithStorage[127.0.0.1:39607,DS-ad9acc5d-f75d-4170-9a59-2b059bb1a9e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-492574124-172.17.0.9-1597546280750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45380,DS-948f4141-6166-43cd-86b0-e890f1a93bef,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-83398960-7b93-4f3b-80b2-9a5d9eda69f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-6c4505be-22a8-4ef4-a691-ef2d3f2b2573,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-6fcc8dc8-2d33-47e9-bffe-f04bd87e37ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-96ec4710-756e-4178-aad4-2a5c7fffd71a,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-b1648425-698c-44e1-88cc-add57b054b44,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-f2961896-32bf-4b31-ba35-f8ce0a2159d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-27eff113-9a71-48de-ae22-d22666f7d5ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-492574124-172.17.0.9-1597546280750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45380,DS-948f4141-6166-43cd-86b0-e890f1a93bef,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-83398960-7b93-4f3b-80b2-9a5d9eda69f3,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-6c4505be-22a8-4ef4-a691-ef2d3f2b2573,DISK], DatanodeInfoWithStorage[127.0.0.1:37684,DS-6fcc8dc8-2d33-47e9-bffe-f04bd87e37ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-96ec4710-756e-4178-aad4-2a5c7fffd71a,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-b1648425-698c-44e1-88cc-add57b054b44,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-f2961896-32bf-4b31-ba35-f8ce0a2159d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36452,DS-27eff113-9a71-48de-ae22-d22666f7d5ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1143108139-172.17.0.9-1597546350478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43012,DS-9d20e009-d446-409b-ac73-8de7c57468a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-f8cc928d-e4e8-426d-b68c-925d89ad0393,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-5dd05b73-1ee3-46da-9ca7-1ee0220c76f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-2c983e1d-1281-4cc5-8efd-2e898bb3a3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-19b39c2a-6935-499f-bd16-1a41a3aa760a,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-536dc0ee-51e2-4466-ba86-5bacfe71c197,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-9f43079b-32c4-4861-a0df-4442baf59187,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-31037aa2-cce8-4714-9db3-88e53f19e66d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1143108139-172.17.0.9-1597546350478:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43012,DS-9d20e009-d446-409b-ac73-8de7c57468a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-f8cc928d-e4e8-426d-b68c-925d89ad0393,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-5dd05b73-1ee3-46da-9ca7-1ee0220c76f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43059,DS-2c983e1d-1281-4cc5-8efd-2e898bb3a3d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-19b39c2a-6935-499f-bd16-1a41a3aa760a,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-536dc0ee-51e2-4466-ba86-5bacfe71c197,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-9f43079b-32c4-4861-a0df-4442baf59187,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-31037aa2-cce8-4714-9db3-88e53f19e66d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-909055170-172.17.0.9-1597546463871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34916,DS-cbf59008-e39c-40fb-a61a-b6a1fe834045,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-53eef181-b870-4d23-a5dc-de2374cd2d21,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-e8acbe5a-4ac1-4496-9a33-597c5124e5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-9632c6ff-1983-4dac-84d9-9cd92308e0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-f515ad65-f7d3-40f8-a410-56b4af81dc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-4840be00-871f-4f39-a682-8baeea92a43c,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-94ea4f8b-b9f9-4e16-bbac-e8530af94b84,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-a6a6d9cc-c0f1-4fab-9722-93a2d3086658,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-909055170-172.17.0.9-1597546463871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34916,DS-cbf59008-e39c-40fb-a61a-b6a1fe834045,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-53eef181-b870-4d23-a5dc-de2374cd2d21,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-e8acbe5a-4ac1-4496-9a33-597c5124e5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-9632c6ff-1983-4dac-84d9-9cd92308e0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-f515ad65-f7d3-40f8-a410-56b4af81dc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39259,DS-4840be00-871f-4f39-a682-8baeea92a43c,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-94ea4f8b-b9f9-4e16-bbac-e8530af94b84,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-a6a6d9cc-c0f1-4fab-9722-93a2d3086658,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1223280857-172.17.0.9-1597546715500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45959,DS-a2787214-d582-4411-9fdf-912122ec0617,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-3697b096-a65f-4e45-8249-a6b7fb35f156,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-829fc9f1-bb4b-498f-92d4-f4966e1e7646,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-29439405-7a2c-4c4d-81e8-25e6acc4f87d,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-3872d91d-a114-46ec-a5c4-2ab1a564d41b,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-60c4768c-473b-4e7a-8317-a3ad33fbbb33,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-2913a83e-08f8-43c4-8207-26cd32a833d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-86470183-13d0-4dde-b25d-62636d0daf43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1223280857-172.17.0.9-1597546715500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45959,DS-a2787214-d582-4411-9fdf-912122ec0617,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-3697b096-a65f-4e45-8249-a6b7fb35f156,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-829fc9f1-bb4b-498f-92d4-f4966e1e7646,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-29439405-7a2c-4c4d-81e8-25e6acc4f87d,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-3872d91d-a114-46ec-a5c4-2ab1a564d41b,DISK], DatanodeInfoWithStorage[127.0.0.1:43404,DS-60c4768c-473b-4e7a-8317-a3ad33fbbb33,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-2913a83e-08f8-43c4-8207-26cd32a833d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38886,DS-86470183-13d0-4dde-b25d-62636d0daf43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1457230363-172.17.0.9-1597546851152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46245,DS-638cbc25-b9bc-4462-8796-19144b204c50,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-64e5a990-cf99-4a26-8051-25d35768092e,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-ba1a9cae-d19c-4747-b87d-09b2ca385093,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-cc45312d-ec93-4671-aa3b-ce7bc3225296,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-348877ac-8811-4687-af0d-a971c86ab0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-681485a3-7e1d-41ed-8e95-34f3ac7a2219,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-08c4e803-077d-41f0-b035-2175d9ca4fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-791e6591-c185-4d87-ae46-b8d40951af34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1457230363-172.17.0.9-1597546851152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46245,DS-638cbc25-b9bc-4462-8796-19144b204c50,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-64e5a990-cf99-4a26-8051-25d35768092e,DISK], DatanodeInfoWithStorage[127.0.0.1:36543,DS-ba1a9cae-d19c-4747-b87d-09b2ca385093,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-cc45312d-ec93-4671-aa3b-ce7bc3225296,DISK], DatanodeInfoWithStorage[127.0.0.1:37677,DS-348877ac-8811-4687-af0d-a971c86ab0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-681485a3-7e1d-41ed-8e95-34f3ac7a2219,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-08c4e803-077d-41f0-b035-2175d9ca4fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-791e6591-c185-4d87-ae46-b8d40951af34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-148980662-172.17.0.9-1597547156735:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45579,DS-76b60357-5c0c-4a1c-8941-d707cf919177,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-7b296ea0-6b85-4778-8710-89623a6d868b,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-3663fe5f-f917-4061-83d6-8ef1ff11ecc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-5a80dfae-36a1-4634-ad25-766f8b636520,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-bc8288ec-36ba-4955-a09e-458af6834689,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-8dff32c4-2b12-4781-a060-0ada0f016ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-1ee11879-9a99-4059-b351-6bb5fbe64c98,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-e5710737-53cc-4465-942d-cb09d00d77eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-148980662-172.17.0.9-1597547156735:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45579,DS-76b60357-5c0c-4a1c-8941-d707cf919177,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-7b296ea0-6b85-4778-8710-89623a6d868b,DISK], DatanodeInfoWithStorage[127.0.0.1:33123,DS-3663fe5f-f917-4061-83d6-8ef1ff11ecc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46679,DS-5a80dfae-36a1-4634-ad25-766f8b636520,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-bc8288ec-36ba-4955-a09e-458af6834689,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-8dff32c4-2b12-4781-a060-0ada0f016ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:35211,DS-1ee11879-9a99-4059-b351-6bb5fbe64c98,DISK], DatanodeInfoWithStorage[127.0.0.1:46006,DS-e5710737-53cc-4465-942d-cb09d00d77eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1194264821-172.17.0.9-1597547303409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34354,DS-27ae4fcc-83c3-452e-9e1a-10a90cbcfe4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-c22fbc2e-c259-4583-8e80-97553068381c,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-95a1a9a5-6029-4bab-b3bd-57396a35c861,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-200c5a97-ecb3-4d07-aef4-5db875a691ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-cc464656-a1ea-4cd3-8378-6f9a9c96fe29,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-ef7dd1a6-722e-4b5c-8b2c-152f36c1bd25,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-43123de7-91b3-4efc-8cc9-ed3a0de10379,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-5941b59a-7ff9-4e93-b962-03d089c2d74b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1194264821-172.17.0.9-1597547303409:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34354,DS-27ae4fcc-83c3-452e-9e1a-10a90cbcfe4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-c22fbc2e-c259-4583-8e80-97553068381c,DISK], DatanodeInfoWithStorage[127.0.0.1:43954,DS-95a1a9a5-6029-4bab-b3bd-57396a35c861,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-200c5a97-ecb3-4d07-aef4-5db875a691ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43076,DS-cc464656-a1ea-4cd3-8378-6f9a9c96fe29,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-ef7dd1a6-722e-4b5c-8b2c-152f36c1bd25,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-43123de7-91b3-4efc-8cc9-ed3a0de10379,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-5941b59a-7ff9-4e93-b962-03d089c2d74b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-890877127-172.17.0.9-1597547806594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41918,DS-e65a2d6d-b7ec-49f5-b937-2082f5cb2d36,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-eb8f9955-7aa8-4553-b305-498d104aa82d,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-4fa0f305-718e-4510-a37e-6d2dc189e1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-7a31b074-5970-4e42-befd-60dbadb1f60c,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-2a100c2c-57d9-4cbc-aa0b-e4ba7198e670,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-d2ae398f-6ff1-4af6-934f-55674b9dc3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-f76f18c7-522f-4e96-ad07-7f4fb2542856,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-662975a5-b2a9-48b1-82d0-8d9f01e186da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-890877127-172.17.0.9-1597547806594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41918,DS-e65a2d6d-b7ec-49f5-b937-2082f5cb2d36,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-eb8f9955-7aa8-4553-b305-498d104aa82d,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-4fa0f305-718e-4510-a37e-6d2dc189e1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-7a31b074-5970-4e42-befd-60dbadb1f60c,DISK], DatanodeInfoWithStorage[127.0.0.1:42544,DS-2a100c2c-57d9-4cbc-aa0b-e4ba7198e670,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-d2ae398f-6ff1-4af6-934f-55674b9dc3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-f76f18c7-522f-4e96-ad07-7f4fb2542856,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-662975a5-b2a9-48b1-82d0-8d9f01e186da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1577075247-172.17.0.9-1597547984694:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46430,DS-14bd8990-3c7f-406c-a394-715d197364f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-16b4c0f0-a2f8-418f-919c-4d144c685fda,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-ae979e28-fb16-4110-9c66-90abcc6a0501,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-d87437a5-1975-4535-bc80-e23c5bed2349,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-077b24a9-a2dc-47cd-9023-bea380e89231,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-4efd0b19-b3e7-4268-b93b-2297e7df91e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-47b4d401-fbbd-4141-b992-0a82107564c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-94915f8c-7335-4724-b314-cea614a7e305,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1577075247-172.17.0.9-1597547984694:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46430,DS-14bd8990-3c7f-406c-a394-715d197364f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-16b4c0f0-a2f8-418f-919c-4d144c685fda,DISK], DatanodeInfoWithStorage[127.0.0.1:39144,DS-ae979e28-fb16-4110-9c66-90abcc6a0501,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-d87437a5-1975-4535-bc80-e23c5bed2349,DISK], DatanodeInfoWithStorage[127.0.0.1:45344,DS-077b24a9-a2dc-47cd-9023-bea380e89231,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-4efd0b19-b3e7-4268-b93b-2297e7df91e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-47b4d401-fbbd-4141-b992-0a82107564c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-94915f8c-7335-4724-b314-cea614a7e305,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-536362330-172.17.0.9-1597548024881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42196,DS-5a875304-f935-4c0b-a3b7-4db1426018bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-4fae4dc5-337e-4437-ab64-d788e029c899,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-41159be9-f45d-496e-920e-d86264dc3dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34841,DS-fd2cd44e-03cc-44e1-a029-9c2697dc8980,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-99a78747-2b42-4f23-bf35-b124c9c15439,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-7276aa66-d9da-4f38-8b3d-c8627b581221,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-a0cf4930-14a5-4453-885d-e6d35a3eb9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-68832218-c898-4d8d-8568-31f15a9b4279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-536362330-172.17.0.9-1597548024881:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42196,DS-5a875304-f935-4c0b-a3b7-4db1426018bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-4fae4dc5-337e-4437-ab64-d788e029c899,DISK], DatanodeInfoWithStorage[127.0.0.1:43887,DS-41159be9-f45d-496e-920e-d86264dc3dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34841,DS-fd2cd44e-03cc-44e1-a029-9c2697dc8980,DISK], DatanodeInfoWithStorage[127.0.0.1:34231,DS-99a78747-2b42-4f23-bf35-b124c9c15439,DISK], DatanodeInfoWithStorage[127.0.0.1:39088,DS-7276aa66-d9da-4f38-8b3d-c8627b581221,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-a0cf4930-14a5-4453-885d-e6d35a3eb9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39665,DS-68832218-c898-4d8d-8568-31f15a9b4279,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1701722633-172.17.0.9-1597548269800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44425,DS-9af7ef26-3347-4f94-9a0e-a78c6fd80fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-6c70f5e3-2cae-4045-b918-e70e4886ebfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-7c48929f-1040-4870-b69d-ec308bad2a36,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-5108e4f5-e47a-4354-9eac-450ed9ac9593,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-6b765e6a-eec6-4f2f-b51b-924337fef223,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-b1f5b1b1-400f-4e25-96de-ada215fa8dec,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-73d5eaf0-e3b4-41db-842a-f6377e25d7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-ef1b1f46-96c7-4c35-9201-2f8c13b58b60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1701722633-172.17.0.9-1597548269800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44425,DS-9af7ef26-3347-4f94-9a0e-a78c6fd80fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-6c70f5e3-2cae-4045-b918-e70e4886ebfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-7c48929f-1040-4870-b69d-ec308bad2a36,DISK], DatanodeInfoWithStorage[127.0.0.1:34719,DS-5108e4f5-e47a-4354-9eac-450ed9ac9593,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-6b765e6a-eec6-4f2f-b51b-924337fef223,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-b1f5b1b1-400f-4e25-96de-ada215fa8dec,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-73d5eaf0-e3b4-41db-842a-f6377e25d7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-ef1b1f46-96c7-4c35-9201-2f8c13b58b60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 60000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1513050808-172.17.0.9-1597548420837:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42680,DS-8c755032-23e4-481f-89d3-cbb604c0dace,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-30a8bfe3-52a9-44d1-9b16-7cc4031a9fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-12de57c0-5141-4466-9fe6-babf6b8a0001,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-3f9a11ff-4dbf-427e-ae0c-6426cd19dc26,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-9b6c806b-3749-48e2-af29-4d696d2f2300,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-4d0df636-324e-4cdc-a470-a21a8d2ed8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-5dfa82e2-a271-4e9f-a004-9cf1165ed557,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-25c587a7-8c5c-42ee-8db7-72e0e2e382ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1513050808-172.17.0.9-1597548420837:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42680,DS-8c755032-23e4-481f-89d3-cbb604c0dace,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-30a8bfe3-52a9-44d1-9b16-7cc4031a9fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-12de57c0-5141-4466-9fe6-babf6b8a0001,DISK], DatanodeInfoWithStorage[127.0.0.1:33271,DS-3f9a11ff-4dbf-427e-ae0c-6426cd19dc26,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-9b6c806b-3749-48e2-af29-4d696d2f2300,DISK], DatanodeInfoWithStorage[127.0.0.1:45382,DS-4d0df636-324e-4cdc-a470-a21a8d2ed8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-5dfa82e2-a271-4e9f-a004-9cf1165ed557,DISK], DatanodeInfoWithStorage[127.0.0.1:40543,DS-25c587a7-8c5c-42ee-8db7-72e0e2e382ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5331
