reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-157487634-172.17.0.19-1597424496862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45246,DS-ca9202a5-6c40-46bd-90a7-15fc8a891dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-8a187e6f-3983-4172-9d0f-81ec5e8ecbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-144d3059-c9a2-4860-b5fc-f8ce71fd62db,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-27fe8152-e2e7-44b6-a8db-f4c34bf2b1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-8cf07e9b-af0d-4450-aa9a-0a821629e215,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-7ba02ceb-695d-419f-a5fa-fcd0737ad831,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-a8f586ce-c910-4ac0-9211-6a03840f3930,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-d4cb58a5-c925-45b8-ac31-cca7d6feb7a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-157487634-172.17.0.19-1597424496862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45246,DS-ca9202a5-6c40-46bd-90a7-15fc8a891dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-8a187e6f-3983-4172-9d0f-81ec5e8ecbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-144d3059-c9a2-4860-b5fc-f8ce71fd62db,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-27fe8152-e2e7-44b6-a8db-f4c34bf2b1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-8cf07e9b-af0d-4450-aa9a-0a821629e215,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-7ba02ceb-695d-419f-a5fa-fcd0737ad831,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-a8f586ce-c910-4ac0-9211-6a03840f3930,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-d4cb58a5-c925-45b8-ac31-cca7d6feb7a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1067494129-172.17.0.19-1597424612249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37808,DS-0560a783-ad82-45a4-b933-6dce51d94230,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-b3c2f6e2-d1e2-4b93-a1fa-a350c0ad310b,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-863aa23c-276d-403b-ae8d-936bf8716ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-7e39997c-c921-4a5d-ab80-bfe3b441f436,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-3f774bd8-1dc5-4f86-87ca-4f184fb44021,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-5e0499b9-5f26-4d07-a54c-12cd26041b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-f6e12a12-5870-48c8-93e1-1fa6d74cd4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-95563687-af8b-48e2-8460-504cdbf4f1d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1067494129-172.17.0.19-1597424612249:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37808,DS-0560a783-ad82-45a4-b933-6dce51d94230,DISK], DatanodeInfoWithStorage[127.0.0.1:33026,DS-b3c2f6e2-d1e2-4b93-a1fa-a350c0ad310b,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-863aa23c-276d-403b-ae8d-936bf8716ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-7e39997c-c921-4a5d-ab80-bfe3b441f436,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-3f774bd8-1dc5-4f86-87ca-4f184fb44021,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-5e0499b9-5f26-4d07-a54c-12cd26041b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-f6e12a12-5870-48c8-93e1-1fa6d74cd4bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40705,DS-95563687-af8b-48e2-8460-504cdbf4f1d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-496227947-172.17.0.19-1597425103431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43137,DS-e41052fe-439f-43ea-8207-d6c3179364c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-c4a6a1ca-3ad7-4e7f-bf50-6f8afdcc6e02,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-242a8aa9-6ddf-407b-9346-ec8bd9feb67b,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-e9fb7afb-a9bb-4992-ae3b-3f596472d5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-0a64f657-2127-4cb1-afd8-33b3c8457217,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-3c91a806-2709-4a1e-a62d-a4388cdb27a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-78b48c5b-aa69-4d16-a6de-211876772917,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-7854fbf0-ccfd-4547-a942-6c19a4c8c54f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-496227947-172.17.0.19-1597425103431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43137,DS-e41052fe-439f-43ea-8207-d6c3179364c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-c4a6a1ca-3ad7-4e7f-bf50-6f8afdcc6e02,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-242a8aa9-6ddf-407b-9346-ec8bd9feb67b,DISK], DatanodeInfoWithStorage[127.0.0.1:44177,DS-e9fb7afb-a9bb-4992-ae3b-3f596472d5ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42354,DS-0a64f657-2127-4cb1-afd8-33b3c8457217,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-3c91a806-2709-4a1e-a62d-a4388cdb27a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43880,DS-78b48c5b-aa69-4d16-a6de-211876772917,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-7854fbf0-ccfd-4547-a942-6c19a4c8c54f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-838395018-172.17.0.19-1597425409585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34395,DS-7159f4f2-4c56-4ef9-b0b4-e2c140cefe41,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-f2f1f6ea-8369-4fa8-9dcb-014163268aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-e3272f49-e3cf-4b32-b2d4-d14caf02b727,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-13ffff46-29e9-42d1-92f3-c9ec763fff14,DISK], DatanodeInfoWithStorage[127.0.0.1:33514,DS-5c220f58-f709-4c06-9548-b2c2b8b5b077,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-e3224359-e4e5-4a55-8e72-a0389f7d6ede,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-c55c5cc2-d26e-4866-a142-f7bc0fa181b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-e570a36e-a1f3-46db-b312-207f59a7819b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-838395018-172.17.0.19-1597425409585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34395,DS-7159f4f2-4c56-4ef9-b0b4-e2c140cefe41,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-f2f1f6ea-8369-4fa8-9dcb-014163268aa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-e3272f49-e3cf-4b32-b2d4-d14caf02b727,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-13ffff46-29e9-42d1-92f3-c9ec763fff14,DISK], DatanodeInfoWithStorage[127.0.0.1:33514,DS-5c220f58-f709-4c06-9548-b2c2b8b5b077,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-e3224359-e4e5-4a55-8e72-a0389f7d6ede,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-c55c5cc2-d26e-4866-a142-f7bc0fa181b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43706,DS-e570a36e-a1f3-46db-b312-207f59a7819b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1775969336-172.17.0.19-1597425559554:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38594,DS-c1f3e707-b6a6-43f4-a7a4-02c829040f43,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-06a8e50e-6f9b-47f0-bf72-14fb32b43bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-96cd3b6f-fc6c-424e-9ecd-42fa1461c300,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-6999b3bc-bf6d-4ed1-bb8b-9d19c1dc1c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-c7ec9de3-4009-4caa-ba9c-263f598b103d,DISK], DatanodeInfoWithStorage[127.0.0.1:33283,DS-dc28fdfc-d4dd-461f-b2f4-b0107d7dd820,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-b20be223-84aa-43ba-8e58-f153cc3d14e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-f4de36bb-d6e9-4c55-b9b4-864b556d778e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1775969336-172.17.0.19-1597425559554:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38594,DS-c1f3e707-b6a6-43f4-a7a4-02c829040f43,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-06a8e50e-6f9b-47f0-bf72-14fb32b43bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-96cd3b6f-fc6c-424e-9ecd-42fa1461c300,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-6999b3bc-bf6d-4ed1-bb8b-9d19c1dc1c6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-c7ec9de3-4009-4caa-ba9c-263f598b103d,DISK], DatanodeInfoWithStorage[127.0.0.1:33283,DS-dc28fdfc-d4dd-461f-b2f4-b0107d7dd820,DISK], DatanodeInfoWithStorage[127.0.0.1:39504,DS-b20be223-84aa-43ba-8e58-f153cc3d14e8,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-f4de36bb-d6e9-4c55-b9b4-864b556d778e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2093183181-172.17.0.19-1597425822133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39731,DS-29c4dffc-3bf0-45d3-bbc7-fd348da69099,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-245f45cf-4637-41ad-a159-93487880f831,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-2ad72ac3-9706-4372-9cd7-be23313e593b,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-4b200a4f-df0a-4fe3-9098-bee8ee9738fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-b45a09d1-7191-48a3-af75-3b450d1f548b,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-ba658675-a343-4bf3-a64e-255b5a2a15de,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-e20fd35a-1047-4055-8b37-95cf37d6e287,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-637dc144-e8dc-43e4-be2d-d3015bdb16a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2093183181-172.17.0.19-1597425822133:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39731,DS-29c4dffc-3bf0-45d3-bbc7-fd348da69099,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-245f45cf-4637-41ad-a159-93487880f831,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-2ad72ac3-9706-4372-9cd7-be23313e593b,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-4b200a4f-df0a-4fe3-9098-bee8ee9738fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-b45a09d1-7191-48a3-af75-3b450d1f548b,DISK], DatanodeInfoWithStorage[127.0.0.1:34187,DS-ba658675-a343-4bf3-a64e-255b5a2a15de,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-e20fd35a-1047-4055-8b37-95cf37d6e287,DISK], DatanodeInfoWithStorage[127.0.0.1:43310,DS-637dc144-e8dc-43e4-be2d-d3015bdb16a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1473274438-172.17.0.19-1597426818348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37410,DS-620ffc74-1bb8-45d7-bcc3-1b60c6b182c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-474ee806-1865-4f2b-9bf7-04e25f0216f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-0fbe8541-ffce-4ab7-b052-9431bbe73369,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-16ecc004-a9f1-45cf-8491-7b5dbe7bb58b,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-75158104-a06b-42f1-b0b6-cb439c31167b,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-b126073e-2ff4-40bb-8c4e-fdb481a1c191,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-d579c1b8-6b90-4023-8e69-ba71daf987dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-07193a21-1895-411c-b5a5-99e1e2478b9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1473274438-172.17.0.19-1597426818348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37410,DS-620ffc74-1bb8-45d7-bcc3-1b60c6b182c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34042,DS-474ee806-1865-4f2b-9bf7-04e25f0216f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46049,DS-0fbe8541-ffce-4ab7-b052-9431bbe73369,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-16ecc004-a9f1-45cf-8491-7b5dbe7bb58b,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-75158104-a06b-42f1-b0b6-cb439c31167b,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-b126073e-2ff4-40bb-8c4e-fdb481a1c191,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-d579c1b8-6b90-4023-8e69-ba71daf987dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-07193a21-1895-411c-b5a5-99e1e2478b9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-809814068-172.17.0.19-1597426945651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33027,DS-c565afee-2e70-487d-991f-57664f300f29,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-3847c630-8c1b-4fd5-b513-b488fc83b373,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-cc16d51f-3abf-42f6-8765-61ef09ebe3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-bfa8fa6b-9309-4a4c-9a6d-6fea876c690f,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-6e358484-1c43-4aa9-a977-d3757e23360a,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-c9375d21-f94c-4261-a385-3bbbb3bf416e,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-b7f4f9ce-051d-4dc9-b30a-9728244139f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-cdb33e76-f562-4caf-9c91-92dcd000201e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-809814068-172.17.0.19-1597426945651:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33027,DS-c565afee-2e70-487d-991f-57664f300f29,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-3847c630-8c1b-4fd5-b513-b488fc83b373,DISK], DatanodeInfoWithStorage[127.0.0.1:43894,DS-cc16d51f-3abf-42f6-8765-61ef09ebe3ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-bfa8fa6b-9309-4a4c-9a6d-6fea876c690f,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-6e358484-1c43-4aa9-a977-d3757e23360a,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-c9375d21-f94c-4261-a385-3bbbb3bf416e,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-b7f4f9ce-051d-4dc9-b30a-9728244139f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41044,DS-cdb33e76-f562-4caf-9c91-92dcd000201e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-685019216-172.17.0.19-1597426995400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33761,DS-ee8c6404-886b-47f2-b356-0d559da8750f,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-1c60ca7a-de29-4959-80ca-d93767bb6e95,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-e8149ad4-8703-491a-b777-c05ff2f88e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-b8cf4513-2f16-4e5d-b931-0e55c448ad48,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-e7f93a2a-f395-46ea-8cc4-b24acd6aa0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-b8f8e11b-e6df-4b95-b05c-c077b67ac743,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-e69e0cfc-37e0-451f-8218-28afe9104e95,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-b6fe5806-740f-41ac-8f23-9410c5326962,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-685019216-172.17.0.19-1597426995400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33761,DS-ee8c6404-886b-47f2-b356-0d559da8750f,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-1c60ca7a-de29-4959-80ca-d93767bb6e95,DISK], DatanodeInfoWithStorage[127.0.0.1:44606,DS-e8149ad4-8703-491a-b777-c05ff2f88e8b,DISK], DatanodeInfoWithStorage[127.0.0.1:35792,DS-b8cf4513-2f16-4e5d-b931-0e55c448ad48,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-e7f93a2a-f395-46ea-8cc4-b24acd6aa0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-b8f8e11b-e6df-4b95-b05c-c077b67ac743,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-e69e0cfc-37e0-451f-8218-28afe9104e95,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-b6fe5806-740f-41ac-8f23-9410c5326962,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1806827398-172.17.0.19-1597427028585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43277,DS-bc0893ed-ebb6-4de5-8b89-8f5362bb11e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-ea4bcfac-5af8-4dc1-85d3-71a81cf758bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-ac0bb921-d593-4d39-bee6-d044e78c8a53,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-14291360-c59d-4132-9ae4-6979265bd387,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-72f1e6ff-22a0-4a76-8d1b-75f86504256f,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-a9a5b1f8-7cc4-4756-b130-70d50f749108,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-cf9dacda-a4d5-442a-833b-c8f2a74ab15b,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-dde125e6-50fc-47c0-b0a0-12409f8b26c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1806827398-172.17.0.19-1597427028585:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43277,DS-bc0893ed-ebb6-4de5-8b89-8f5362bb11e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-ea4bcfac-5af8-4dc1-85d3-71a81cf758bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-ac0bb921-d593-4d39-bee6-d044e78c8a53,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-14291360-c59d-4132-9ae4-6979265bd387,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-72f1e6ff-22a0-4a76-8d1b-75f86504256f,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-a9a5b1f8-7cc4-4756-b130-70d50f749108,DISK], DatanodeInfoWithStorage[127.0.0.1:40275,DS-cf9dacda-a4d5-442a-833b-c8f2a74ab15b,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-dde125e6-50fc-47c0-b0a0-12409f8b26c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1246923070-172.17.0.19-1597427457895:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43600,DS-ae97726c-8ae0-4ffd-944d-5c27e5ec54e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-357284a7-7932-47b8-bd39-7c772213e580,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-468a05a3-176d-446e-a6eb-bb4bcd302c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-267d0b7d-59d6-4acf-a31d-563e4f58dab6,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-d2931eba-0ca2-4d79-941f-06fc0872118a,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-40bc81ee-068f-4592-9eb2-45568da6d602,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-aa0bb1e0-e949-45e0-84a3-95c693c4c4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-c6ed80e4-3d01-4ee5-9d63-b4d3a6cfe6bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1246923070-172.17.0.19-1597427457895:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43600,DS-ae97726c-8ae0-4ffd-944d-5c27e5ec54e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-357284a7-7932-47b8-bd39-7c772213e580,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-468a05a3-176d-446e-a6eb-bb4bcd302c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:40708,DS-267d0b7d-59d6-4acf-a31d-563e4f58dab6,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-d2931eba-0ca2-4d79-941f-06fc0872118a,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-40bc81ee-068f-4592-9eb2-45568da6d602,DISK], DatanodeInfoWithStorage[127.0.0.1:35939,DS-aa0bb1e0-e949-45e0-84a3-95c693c4c4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-c6ed80e4-3d01-4ee5-9d63-b4d3a6cfe6bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1401321851-172.17.0.19-1597427589785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46230,DS-a40c3a5f-efb6-4474-a488-57bdeba8f5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-08877ddb-57ea-431b-bc06-0c7c81e285fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-4b5de226-cc35-465c-b943-edd7cf2024a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-d63fb86b-9168-455e-9b46-258b363e6a64,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-04991943-4795-461a-b4b3-77dc59d20325,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-7b671bc1-466d-41c5-8a77-8a537fe5950b,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-a2ebbac5-dfb8-4625-b8ca-302353d4c40f,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-0efac4ee-00ae-426e-ad63-9dc73b81a242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1401321851-172.17.0.19-1597427589785:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46230,DS-a40c3a5f-efb6-4474-a488-57bdeba8f5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-08877ddb-57ea-431b-bc06-0c7c81e285fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37201,DS-4b5de226-cc35-465c-b943-edd7cf2024a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-d63fb86b-9168-455e-9b46-258b363e6a64,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-04991943-4795-461a-b4b3-77dc59d20325,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-7b671bc1-466d-41c5-8a77-8a537fe5950b,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-a2ebbac5-dfb8-4625-b8ca-302353d4c40f,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-0efac4ee-00ae-426e-ad63-9dc73b81a242,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1429057541-172.17.0.19-1597427622251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34371,DS-b1b5d0b5-a557-4f53-a2ce-a95ef81660f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-8d900121-68ce-47cb-9982-c04a36bc7c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-a184926a-4ab5-47b9-8a9f-533e742ae20f,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-91101baa-cb22-4b82-a52b-7852bdeac317,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-9eab5c48-3aa6-4bdc-adb1-ad65ed4d6c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-51db954b-c9c4-4a58-a163-ce4489b075e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-082b0f70-6007-42ca-9ecf-ba1fb1561263,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-846a49be-4d6e-4f6c-821c-b2e28e11f4c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1429057541-172.17.0.19-1597427622251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34371,DS-b1b5d0b5-a557-4f53-a2ce-a95ef81660f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43928,DS-8d900121-68ce-47cb-9982-c04a36bc7c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-a184926a-4ab5-47b9-8a9f-533e742ae20f,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-91101baa-cb22-4b82-a52b-7852bdeac317,DISK], DatanodeInfoWithStorage[127.0.0.1:34571,DS-9eab5c48-3aa6-4bdc-adb1-ad65ed4d6c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-51db954b-c9c4-4a58-a163-ce4489b075e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39631,DS-082b0f70-6007-42ca-9ecf-ba1fb1561263,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-846a49be-4d6e-4f6c-821c-b2e28e11f4c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-264522004-172.17.0.19-1597427638807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41886,DS-04890e30-8c5f-4655-a949-9e8836ddc453,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-925419b4-41c2-4d54-8b03-0886083f18d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-84d1bb2b-5cbf-494f-999e-4a9d53513de1,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-55e17129-ea53-471d-9036-ccf0b8da521d,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-56208012-6a52-498b-9d73-636afcbb8235,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-b354a178-e6d1-42f2-9449-4c68cb64680e,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-f1502111-dbc1-4306-bacd-9737b072854a,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-e9176359-44a3-4d25-94ad-7a17ce646db1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-264522004-172.17.0.19-1597427638807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41886,DS-04890e30-8c5f-4655-a949-9e8836ddc453,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-925419b4-41c2-4d54-8b03-0886083f18d6,DISK], DatanodeInfoWithStorage[127.0.0.1:33864,DS-84d1bb2b-5cbf-494f-999e-4a9d53513de1,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-55e17129-ea53-471d-9036-ccf0b8da521d,DISK], DatanodeInfoWithStorage[127.0.0.1:38406,DS-56208012-6a52-498b-9d73-636afcbb8235,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-b354a178-e6d1-42f2-9449-4c68cb64680e,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-f1502111-dbc1-4306-bacd-9737b072854a,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-e9176359-44a3-4d25-94ad-7a17ce646db1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1328154966-172.17.0.19-1597427655726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45936,DS-aaf08da9-cf0f-476c-bb14-b2e9c41653bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-b291f886-f5e2-43c8-b066-0231ad4e7cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-a31fc5b5-7d94-4617-bcf4-74d87571eca0,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-a76801f8-7b6e-4af4-ab0a-74b729071998,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-170afb39-2382-4ef7-882d-f5c1582c8902,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-2f3da386-e0da-416e-9f7d-3344781e844a,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-de538e7c-6f7f-4c7e-ba47-06ce4102287d,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-71292677-d01a-4d11-98ea-f75718e24df5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1328154966-172.17.0.19-1597427655726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45936,DS-aaf08da9-cf0f-476c-bb14-b2e9c41653bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-b291f886-f5e2-43c8-b066-0231ad4e7cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-a31fc5b5-7d94-4617-bcf4-74d87571eca0,DISK], DatanodeInfoWithStorage[127.0.0.1:37524,DS-a76801f8-7b6e-4af4-ab0a-74b729071998,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-170afb39-2382-4ef7-882d-f5c1582c8902,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-2f3da386-e0da-416e-9f7d-3344781e844a,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-de538e7c-6f7f-4c7e-ba47-06ce4102287d,DISK], DatanodeInfoWithStorage[127.0.0.1:40959,DS-71292677-d01a-4d11-98ea-f75718e24df5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-116494181-172.17.0.19-1597427738118:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32996,DS-4e384a98-694c-416a-81bd-8fd628fa1af2,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-662ded3b-fd93-4bed-9003-046051eccc71,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-3da543c5-21c8-4e1a-9f5c-557d2cff1faa,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-41047442-6aa4-4b80-9857-6ae1a81988db,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-816afb40-ad2a-434f-b7c1-4e3ac42abec9,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-151a8aa7-e7ab-4fb8-a95c-85f5852a033b,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-d4e85747-d926-47b5-b8cd-6476c36fc5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-932b100c-e5c3-4b66-a6dd-8489a4204fd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-116494181-172.17.0.19-1597427738118:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32996,DS-4e384a98-694c-416a-81bd-8fd628fa1af2,DISK], DatanodeInfoWithStorage[127.0.0.1:38699,DS-662ded3b-fd93-4bed-9003-046051eccc71,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-3da543c5-21c8-4e1a-9f5c-557d2cff1faa,DISK], DatanodeInfoWithStorage[127.0.0.1:39695,DS-41047442-6aa4-4b80-9857-6ae1a81988db,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-816afb40-ad2a-434f-b7c1-4e3ac42abec9,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-151a8aa7-e7ab-4fb8-a95c-85f5852a033b,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-d4e85747-d926-47b5-b8cd-6476c36fc5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39288,DS-932b100c-e5c3-4b66-a6dd-8489a4204fd0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1344894006-172.17.0.19-1597427835788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38990,DS-c16de561-ecb2-492c-bfe1-9dc0bfe8b145,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-cf186e3a-dad0-40f4-826d-ec82b40dc8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-81fb30b2-39ed-4f9d-b617-19b110be429f,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-3b134354-5181-4873-88f8-086f4e15b792,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-1253966c-1288-4349-b4fd-2eed6720a8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-bfaa3638-b01d-4e5b-befe-c5cb9b64037b,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-83e4aad0-b079-4a77-a0d9-aa48f80f2e08,DISK], DatanodeInfoWithStorage[127.0.0.1:38868,DS-346493a1-b8a3-43b8-aaa3-86fac462ced2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1344894006-172.17.0.19-1597427835788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38990,DS-c16de561-ecb2-492c-bfe1-9dc0bfe8b145,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-cf186e3a-dad0-40f4-826d-ec82b40dc8ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39191,DS-81fb30b2-39ed-4f9d-b617-19b110be429f,DISK], DatanodeInfoWithStorage[127.0.0.1:46022,DS-3b134354-5181-4873-88f8-086f4e15b792,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-1253966c-1288-4349-b4fd-2eed6720a8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-bfaa3638-b01d-4e5b-befe-c5cb9b64037b,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-83e4aad0-b079-4a77-a0d9-aa48f80f2e08,DISK], DatanodeInfoWithStorage[127.0.0.1:38868,DS-346493a1-b8a3-43b8-aaa3-86fac462ced2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-790107424-172.17.0.19-1597427901032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41978,DS-20a0cbd5-affa-42b7-86ba-e796d219eb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-cc079eb8-caf1-4ae2-8805-d5b3ceedaf2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-028340a6-464e-4ba1-a5c2-47ab2c5bc819,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-638648a2-cc8d-4c6a-995c-06471c564584,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-4c1cf0b3-ba1b-493f-8499-df02f7af6d35,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-c1d1db87-d1f8-4ead-8609-a072c69c4357,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-8c818e26-f63d-45b0-b175-360faf14ab94,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-705d1330-5e19-4875-bb3b-269cb021afd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-790107424-172.17.0.19-1597427901032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41978,DS-20a0cbd5-affa-42b7-86ba-e796d219eb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-cc079eb8-caf1-4ae2-8805-d5b3ceedaf2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-028340a6-464e-4ba1-a5c2-47ab2c5bc819,DISK], DatanodeInfoWithStorage[127.0.0.1:41104,DS-638648a2-cc8d-4c6a-995c-06471c564584,DISK], DatanodeInfoWithStorage[127.0.0.1:38633,DS-4c1cf0b3-ba1b-493f-8499-df02f7af6d35,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-c1d1db87-d1f8-4ead-8609-a072c69c4357,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-8c818e26-f63d-45b0-b175-360faf14ab94,DISK], DatanodeInfoWithStorage[127.0.0.1:39513,DS-705d1330-5e19-4875-bb3b-269cb021afd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 4034
