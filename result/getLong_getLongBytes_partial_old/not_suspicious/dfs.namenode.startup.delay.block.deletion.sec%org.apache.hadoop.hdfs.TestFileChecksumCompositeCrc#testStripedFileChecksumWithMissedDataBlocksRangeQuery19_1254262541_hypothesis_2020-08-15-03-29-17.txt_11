reconf_parameter: dfs.namenode.startup.delay.block.deletion.sec
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.startup.delay.block.deletion.sec
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-531426386-172.17.0.19-1597462574594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41411,DS-c1b7fda3-3282-40d2-b1e9-943156f4e624,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-5c5d0450-e3ef-4c9e-aa15-657826d9ade5,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-8dcda256-50b8-4d47-8884-c76f412a49d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-72154369-a706-4e47-9029-b9aa908114b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-1a3b360e-ea95-46f2-b7d7-7930ca32e570,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-3543c9ae-1fb7-41b8-b0f2-cdaed6ae2819,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-5b4857af-2086-4f79-8b16-0eb729d7cd76,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-ffb23e1e-997f-4bbb-a66a-081911a5edf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-531426386-172.17.0.19-1597462574594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41411,DS-c1b7fda3-3282-40d2-b1e9-943156f4e624,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-5c5d0450-e3ef-4c9e-aa15-657826d9ade5,DISK], DatanodeInfoWithStorage[127.0.0.1:40871,DS-8dcda256-50b8-4d47-8884-c76f412a49d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44421,DS-72154369-a706-4e47-9029-b9aa908114b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-1a3b360e-ea95-46f2-b7d7-7930ca32e570,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-3543c9ae-1fb7-41b8-b0f2-cdaed6ae2819,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-5b4857af-2086-4f79-8b16-0eb729d7cd76,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-ffb23e1e-997f-4bbb-a66a-081911a5edf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.startup.delay.block.deletion.sec
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1610498913-172.17.0.19-1597463751735:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36313,DS-eb6e2164-c65e-475b-9c8f-6277be10ad4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-91d5f589-5fc3-4b0b-a744-6029dd81448b,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-ee2ae00a-e4fb-4980-afab-8a0b49674c97,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-74c5f4b9-c48b-4c8f-a92d-63d2d79bf469,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-d3edc158-7bd2-4099-af8c-f83dc61b99b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-d5392ef6-75e0-4c44-b22e-252c21844803,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-79c701bd-cd88-4fec-8e0c-a50b1d73677b,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-8486a74b-4a63-4114-8fd1-86ad01805edf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1610498913-172.17.0.19-1597463751735:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36313,DS-eb6e2164-c65e-475b-9c8f-6277be10ad4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42076,DS-91d5f589-5fc3-4b0b-a744-6029dd81448b,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-ee2ae00a-e4fb-4980-afab-8a0b49674c97,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-74c5f4b9-c48b-4c8f-a92d-63d2d79bf469,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-d3edc158-7bd2-4099-af8c-f83dc61b99b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-d5392ef6-75e0-4c44-b22e-252c21844803,DISK], DatanodeInfoWithStorage[127.0.0.1:41758,DS-79c701bd-cd88-4fec-8e0c-a50b1d73677b,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-8486a74b-4a63-4114-8fd1-86ad01805edf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.startup.delay.block.deletion.sec
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-839778147-172.17.0.19-1597464347566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40922,DS-59cb4ed2-4b82-48a6-abc8-10779ab3cf64,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-f2583724-877e-4fed-8a9c-ab20a01b311d,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-ef371f6c-332a-4181-9180-71d4ebda6522,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-b02ba47a-e3c3-419e-92e4-19f05f56a212,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-47c16bc2-0242-49b1-8f73-5b88004f239c,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-aae566df-2d6f-4e58-9821-fb1662035be1,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-4ea5e92f-d89f-4c73-a019-cad62aaa1960,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-dcae84ab-75c7-471e-8ed2-130eaa5b3b2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-839778147-172.17.0.19-1597464347566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40922,DS-59cb4ed2-4b82-48a6-abc8-10779ab3cf64,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-f2583724-877e-4fed-8a9c-ab20a01b311d,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-ef371f6c-332a-4181-9180-71d4ebda6522,DISK], DatanodeInfoWithStorage[127.0.0.1:40446,DS-b02ba47a-e3c3-419e-92e4-19f05f56a212,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-47c16bc2-0242-49b1-8f73-5b88004f239c,DISK], DatanodeInfoWithStorage[127.0.0.1:33974,DS-aae566df-2d6f-4e58-9821-fb1662035be1,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-4ea5e92f-d89f-4c73-a019-cad62aaa1960,DISK], DatanodeInfoWithStorage[127.0.0.1:34610,DS-dcae84ab-75c7-471e-8ed2-130eaa5b3b2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.startup.delay.block.deletion.sec
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1537779688-172.17.0.19-1597465120104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46100,DS-a75b3506-26af-4f99-969e-140352807499,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-1c2d8fbb-4654-4a2c-b32f-950e4df57eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-549bb748-cf89-453b-9e16-3bf541050bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-0b68e3ff-4826-4a02-ab66-cc1c32dab776,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-1769d9a2-e950-4e39-b371-524a3dffcb79,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-e33d372f-2ebe-4fb2-8597-2662d1814658,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-85e97fab-80ef-4e7f-9fce-900ec842d80a,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-d6c654ca-3481-4a43-bcd5-02f3165d3f1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1537779688-172.17.0.19-1597465120104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46100,DS-a75b3506-26af-4f99-969e-140352807499,DISK], DatanodeInfoWithStorage[127.0.0.1:43188,DS-1c2d8fbb-4654-4a2c-b32f-950e4df57eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46188,DS-549bb748-cf89-453b-9e16-3bf541050bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-0b68e3ff-4826-4a02-ab66-cc1c32dab776,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-1769d9a2-e950-4e39-b371-524a3dffcb79,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-e33d372f-2ebe-4fb2-8597-2662d1814658,DISK], DatanodeInfoWithStorage[127.0.0.1:33743,DS-85e97fab-80ef-4e7f-9fce-900ec842d80a,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-d6c654ca-3481-4a43-bcd5-02f3165d3f1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.startup.delay.block.deletion.sec
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1851419614-172.17.0.19-1597465491588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33178,DS-611a1cd1-c04a-46b7-b062-f404556a2b25,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-d9cf2801-e4a4-444d-b473-d98a52c73350,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-a285cda3-b176-4457-b9fc-62431033c76a,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-12496ada-9f47-4ad0-ad46-a24ac573df49,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-b74a6251-8b8e-4574-a28a-b872285f6a38,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-75efefea-04d9-491f-9c99-6372a7d27762,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-9747e675-7c1c-4644-bca1-aaa7f89069da,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-744ee962-b919-448c-a8f7-9fd2bc93a6c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1851419614-172.17.0.19-1597465491588:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33178,DS-611a1cd1-c04a-46b7-b062-f404556a2b25,DISK], DatanodeInfoWithStorage[127.0.0.1:42848,DS-d9cf2801-e4a4-444d-b473-d98a52c73350,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-a285cda3-b176-4457-b9fc-62431033c76a,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-12496ada-9f47-4ad0-ad46-a24ac573df49,DISK], DatanodeInfoWithStorage[127.0.0.1:43742,DS-b74a6251-8b8e-4574-a28a-b872285f6a38,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-75efefea-04d9-491f-9c99-6372a7d27762,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-9747e675-7c1c-4644-bca1-aaa7f89069da,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-744ee962-b919-448c-a8f7-9fd2bc93a6c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.startup.delay.block.deletion.sec
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1898912314-172.17.0.19-1597465775015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33466,DS-9730afd1-2537-40eb-a48e-e98be6dabde5,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-cd93224e-ee14-415f-8dd6-4a9c04924452,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-18196130-fcfc-4c17-9e08-7e53180abf7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-71b341fc-a124-4066-afa6-b66e6e97a5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-bf5a204b-4e06-4dca-b9c4-70aef6c501f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-01465ceb-28e8-417f-8fc6-abbd549cf6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-1f7e6a6a-fc37-4312-a95c-0a87c41c87d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-7c7f8c3a-cf84-44c8-9f58-b7f72ade835c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1898912314-172.17.0.19-1597465775015:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33466,DS-9730afd1-2537-40eb-a48e-e98be6dabde5,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-cd93224e-ee14-415f-8dd6-4a9c04924452,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-18196130-fcfc-4c17-9e08-7e53180abf7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-71b341fc-a124-4066-afa6-b66e6e97a5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33103,DS-bf5a204b-4e06-4dca-b9c4-70aef6c501f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-01465ceb-28e8-417f-8fc6-abbd549cf6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-1f7e6a6a-fc37-4312-a95c-0a87c41c87d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-7c7f8c3a-cf84-44c8-9f58-b7f72ade835c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.startup.delay.block.deletion.sec
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2070646906-172.17.0.19-1597465914147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34475,DS-04e263bc-36f6-46de-b6ef-b92754b23b64,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-783547ab-9bf5-4d98-9eb9-cecd7b04e615,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-fdf4b234-cb4f-4e03-a9bb-a00239b2a1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-adb2446f-5b17-46bb-ae95-0c62ed0b5360,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-c02e6fc1-6623-472d-a5cc-612854032cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-e0dbda0b-a766-4bfb-9ebb-5273eb825ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-7a479e0c-20f4-4d71-91f0-8023f2c723b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-4fca1568-5f4d-40aa-a443-ab843627e4dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2070646906-172.17.0.19-1597465914147:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34475,DS-04e263bc-36f6-46de-b6ef-b92754b23b64,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-783547ab-9bf5-4d98-9eb9-cecd7b04e615,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-fdf4b234-cb4f-4e03-a9bb-a00239b2a1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41212,DS-adb2446f-5b17-46bb-ae95-0c62ed0b5360,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-c02e6fc1-6623-472d-a5cc-612854032cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:38116,DS-e0dbda0b-a766-4bfb-9ebb-5273eb825ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-7a479e0c-20f4-4d71-91f0-8023f2c723b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44021,DS-4fca1568-5f4d-40aa-a443-ab843627e4dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.startup.delay.block.deletion.sec
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1747801862-172.17.0.19-1597467082914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33683,DS-c3ff0398-719b-4048-a0e2-ce3e9ba2de60,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-1ac12604-2b8f-4201-9e66-cbc51c264a43,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-184b3797-8006-4a00-9345-61e75cc3530c,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-0fce73a2-931d-4177-81f8-fdf9f58b1bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-ff66c085-c924-45cf-933c-57e6c78046c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-9453a0c5-b4b6-46bb-b006-ee5c4d60d824,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-a0356b43-e87d-4b35-a533-37754091c694,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-0a3fbe7e-a495-4bae-962c-06d504c2b79e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1747801862-172.17.0.19-1597467082914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33683,DS-c3ff0398-719b-4048-a0e2-ce3e9ba2de60,DISK], DatanodeInfoWithStorage[127.0.0.1:45560,DS-1ac12604-2b8f-4201-9e66-cbc51c264a43,DISK], DatanodeInfoWithStorage[127.0.0.1:33099,DS-184b3797-8006-4a00-9345-61e75cc3530c,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-0fce73a2-931d-4177-81f8-fdf9f58b1bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-ff66c085-c924-45cf-933c-57e6c78046c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-9453a0c5-b4b6-46bb-b006-ee5c4d60d824,DISK], DatanodeInfoWithStorage[127.0.0.1:33155,DS-a0356b43-e87d-4b35-a533-37754091c694,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-0a3fbe7e-a495-4bae-962c-06d504c2b79e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.startup.delay.block.deletion.sec
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1146963778-172.17.0.19-1597467114909:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45381,DS-e9e2774a-a214-4429-8209-f215da0bca1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-3994f31b-b517-497f-82b0-098f2bb791cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-9708a246-88eb-461a-84f7-a47df4bb6c55,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-d22e5824-e9cd-4945-bd3d-a67951219e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-41701c9b-03c8-47b9-9ae0-7bbd091c3988,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-3a222cbe-e51e-4b75-a19b-691f84d89e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-0b7ecf2d-df2f-462e-9d6c-2cd35f5a8833,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-76cf61bc-c693-4a0a-9825-d6cd9a253d83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1146963778-172.17.0.19-1597467114909:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45381,DS-e9e2774a-a214-4429-8209-f215da0bca1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43237,DS-3994f31b-b517-497f-82b0-098f2bb791cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-9708a246-88eb-461a-84f7-a47df4bb6c55,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-d22e5824-e9cd-4945-bd3d-a67951219e5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45167,DS-41701c9b-03c8-47b9-9ae0-7bbd091c3988,DISK], DatanodeInfoWithStorage[127.0.0.1:33249,DS-3a222cbe-e51e-4b75-a19b-691f84d89e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36625,DS-0b7ecf2d-df2f-462e-9d6c-2cd35f5a8833,DISK], DatanodeInfoWithStorage[127.0.0.1:44496,DS-76cf61bc-c693-4a0a-9825-d6cd9a253d83,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.startup.delay.block.deletion.sec
component: hdfs:NameNode
v1: 0
v2: 600
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1425880914-172.17.0.19-1597467218496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40248,DS-74d76666-6a95-4f19-b75c-5613fcfc098e,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-33ef4031-a6d7-4fbb-91db-c8305f2ef849,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-62033c62-d7b8-46da-8e6b-d91825a8657f,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-5d45fcf1-e782-4213-842f-3e63fe36126f,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-5bc82381-ea2d-4884-a70f-f00b9418ea4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-33f5371c-dbd7-4875-9ee9-6bc4fcf0657a,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-d965480a-bdeb-404c-8d4c-bb1d4df4be70,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-862af512-52b0-4130-bcab-ff5d9023ee4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1425880914-172.17.0.19-1597467218496:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40248,DS-74d76666-6a95-4f19-b75c-5613fcfc098e,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-33ef4031-a6d7-4fbb-91db-c8305f2ef849,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-62033c62-d7b8-46da-8e6b-d91825a8657f,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-5d45fcf1-e782-4213-842f-3e63fe36126f,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-5bc82381-ea2d-4884-a70f-f00b9418ea4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-33f5371c-dbd7-4875-9ee9-6bc4fcf0657a,DISK], DatanodeInfoWithStorage[127.0.0.1:35233,DS-d965480a-bdeb-404c-8d4c-bb1d4df4be70,DISK], DatanodeInfoWithStorage[127.0.0.1:38902,DS-862af512-52b0-4130-bcab-ff5d9023ee4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5490
