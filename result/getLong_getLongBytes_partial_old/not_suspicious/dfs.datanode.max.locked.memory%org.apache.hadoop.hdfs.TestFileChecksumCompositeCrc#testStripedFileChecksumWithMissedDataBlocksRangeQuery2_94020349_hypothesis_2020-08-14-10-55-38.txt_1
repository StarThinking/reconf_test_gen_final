reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1898748891-172.17.0.20-1597402676212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42787,DS-34d36d3c-69f4-42dd-85a6-9d90a67069a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-556a606b-f348-4535-9327-72b58c947cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-9a193918-83c4-4806-b26d-55e4201d1813,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-fb26fe3f-f5e3-422d-957d-385075669bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-a74e9e99-5c69-49b4-9461-395f385b05fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-c2ab2122-5b13-4ca5-a393-838a3e3d5823,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-6f6a5730-2e1d-45df-8499-b20b70e58469,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-767b8bb7-bae4-4f75-ad65-f39faf49050b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1898748891-172.17.0.20-1597402676212:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42787,DS-34d36d3c-69f4-42dd-85a6-9d90a67069a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-556a606b-f348-4535-9327-72b58c947cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-9a193918-83c4-4806-b26d-55e4201d1813,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-fb26fe3f-f5e3-422d-957d-385075669bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-a74e9e99-5c69-49b4-9461-395f385b05fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-c2ab2122-5b13-4ca5-a393-838a3e3d5823,DISK], DatanodeInfoWithStorage[127.0.0.1:33655,DS-6f6a5730-2e1d-45df-8499-b20b70e58469,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-767b8bb7-bae4-4f75-ad65-f39faf49050b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1419855797-172.17.0.20-1597402903650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46147,DS-b0235e65-d16a-4600-a488-c00c7a7a2851,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-0cfa38ac-b875-40e9-b8e0-a26a98de8b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-316bd29d-827b-42ab-8aa0-0b8857151ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-129f922e-9de1-43c8-91b8-ca91862bcd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-a5ee915e-6214-495d-8cad-ce7b11042630,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-29d8fc15-bc3c-4d0a-bb5b-652aa18f9239,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-4b6d39f3-c6f4-46f1-8075-84017bfba598,DISK], DatanodeInfoWithStorage[127.0.0.1:45849,DS-dd921527-5493-440b-ad8b-282e33c22b06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1419855797-172.17.0.20-1597402903650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46147,DS-b0235e65-d16a-4600-a488-c00c7a7a2851,DISK], DatanodeInfoWithStorage[127.0.0.1:43614,DS-0cfa38ac-b875-40e9-b8e0-a26a98de8b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:40527,DS-316bd29d-827b-42ab-8aa0-0b8857151ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-129f922e-9de1-43c8-91b8-ca91862bcd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37713,DS-a5ee915e-6214-495d-8cad-ce7b11042630,DISK], DatanodeInfoWithStorage[127.0.0.1:32857,DS-29d8fc15-bc3c-4d0a-bb5b-652aa18f9239,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-4b6d39f3-c6f4-46f1-8075-84017bfba598,DISK], DatanodeInfoWithStorage[127.0.0.1:45849,DS-dd921527-5493-440b-ad8b-282e33c22b06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906135821-172.17.0.20-1597403202586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33935,DS-ca86f8d3-90de-48d9-8234-46e2d07136f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-940cb902-07ba-4883-91d9-13b13b8e1870,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-63535642-c8ea-4485-b878-802e9fdb1a77,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-513826f0-8031-4cda-bca7-6086f75db56a,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-0965d5b0-d925-4139-a9db-b0728a6571b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-590cf8e5-43fb-4df3-8204-2820def2c317,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-7ce11b1e-b731-4be6-aac1-d6e83f595bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-501e3ec1-11a4-4326-804d-046d131921f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906135821-172.17.0.20-1597403202586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33935,DS-ca86f8d3-90de-48d9-8234-46e2d07136f0,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-940cb902-07ba-4883-91d9-13b13b8e1870,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-63535642-c8ea-4485-b878-802e9fdb1a77,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-513826f0-8031-4cda-bca7-6086f75db56a,DISK], DatanodeInfoWithStorage[127.0.0.1:33050,DS-0965d5b0-d925-4139-a9db-b0728a6571b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-590cf8e5-43fb-4df3-8204-2820def2c317,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-7ce11b1e-b731-4be6-aac1-d6e83f595bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33254,DS-501e3ec1-11a4-4326-804d-046d131921f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353801054-172.17.0.20-1597403781125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45681,DS-a8e9b687-8b89-4241-8050-9d924ec44e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-a0655b99-2ed6-48ae-8ea1-1957dad65fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-c5c49b2d-defc-4480-a6ff-bc845d8de1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-2e2acd94-6ee8-4cb2-a740-19ba8d11c9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-b39853c9-5cbb-4523-a036-31f32142668b,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-a51ab143-b270-4ee2-a271-0fa4e64647f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-cf1bcb43-30b2-4aeb-900c-db0791cc58cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-fe549129-c3b5-47d6-8982-d0b27cc3ec99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1353801054-172.17.0.20-1597403781125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45681,DS-a8e9b687-8b89-4241-8050-9d924ec44e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-a0655b99-2ed6-48ae-8ea1-1957dad65fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-c5c49b2d-defc-4480-a6ff-bc845d8de1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-2e2acd94-6ee8-4cb2-a740-19ba8d11c9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-b39853c9-5cbb-4523-a036-31f32142668b,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-a51ab143-b270-4ee2-a271-0fa4e64647f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-cf1bcb43-30b2-4aeb-900c-db0791cc58cc,DISK], DatanodeInfoWithStorage[127.0.0.1:38308,DS-fe549129-c3b5-47d6-8982-d0b27cc3ec99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1784410029-172.17.0.20-1597403917550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34454,DS-15dac368-26c5-4e88-96a7-f7f4a546e488,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-e2c651e5-e5a0-4404-85da-a5708c0e7b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-77898909-4608-4922-bfdd-017875419b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-3ef2d4f0-5aeb-43dc-8459-536e57bfac8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-f2f526b2-e1ca-4a0d-95d2-c2b29593a284,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-770095af-cd6f-449a-a47e-9e1e1f11869f,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-d09fd008-f343-49a7-934a-6fb56b43dc07,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-14a76cde-c109-41d7-94d7-55fe71a97024,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1784410029-172.17.0.20-1597403917550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34454,DS-15dac368-26c5-4e88-96a7-f7f4a546e488,DISK], DatanodeInfoWithStorage[127.0.0.1:42472,DS-e2c651e5-e5a0-4404-85da-a5708c0e7b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37633,DS-77898909-4608-4922-bfdd-017875419b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-3ef2d4f0-5aeb-43dc-8459-536e57bfac8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-f2f526b2-e1ca-4a0d-95d2-c2b29593a284,DISK], DatanodeInfoWithStorage[127.0.0.1:44260,DS-770095af-cd6f-449a-a47e-9e1e1f11869f,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-d09fd008-f343-49a7-934a-6fb56b43dc07,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-14a76cde-c109-41d7-94d7-55fe71a97024,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1847740370-172.17.0.20-1597404573469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44412,DS-fadf2847-faf2-41f2-b3c8-e55d32b27add,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-d04b9a50-c086-4a64-9d9b-a417088a6e50,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-5f1bc3bf-d032-49e6-932a-b763f53d0daa,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-453ad6be-7bcf-4335-91a8-2e2c8c51d23f,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-a066dfdd-1b2b-4c93-83a5-204883c29c47,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-461c2909-4873-49e8-a84a-06e343f8ea65,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-bda90ef9-6a04-46ee-8da9-c1fd7c7e8756,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-0303b2c9-e3b5-4f3a-9f5c-8d2949b7b6c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1847740370-172.17.0.20-1597404573469:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44412,DS-fadf2847-faf2-41f2-b3c8-e55d32b27add,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-d04b9a50-c086-4a64-9d9b-a417088a6e50,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-5f1bc3bf-d032-49e6-932a-b763f53d0daa,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-453ad6be-7bcf-4335-91a8-2e2c8c51d23f,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-a066dfdd-1b2b-4c93-83a5-204883c29c47,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-461c2909-4873-49e8-a84a-06e343f8ea65,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-bda90ef9-6a04-46ee-8da9-c1fd7c7e8756,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-0303b2c9-e3b5-4f3a-9f5c-8d2949b7b6c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54926453-172.17.0.20-1597405323649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40677,DS-ffd209d0-5ca1-424b-898f-fd1d36c4db14,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-168783bd-5328-4220-85c0-d94443d5566f,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-2a3ecc0f-6ac8-4fab-9f92-16d32847b02e,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-da7d4d21-7f5d-4d9d-8651-1220403bd450,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-53017b7b-4206-4e9a-9671-3031049d291d,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-5a7c4cd7-0d74-42eb-91f9-31eb2c3768ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-3179c9fe-25ab-488f-987e-dd47c287bdee,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-1781df8f-98ef-4644-8858-dff5c95d2666,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54926453-172.17.0.20-1597405323649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40677,DS-ffd209d0-5ca1-424b-898f-fd1d36c4db14,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-168783bd-5328-4220-85c0-d94443d5566f,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-2a3ecc0f-6ac8-4fab-9f92-16d32847b02e,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-da7d4d21-7f5d-4d9d-8651-1220403bd450,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-53017b7b-4206-4e9a-9671-3031049d291d,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-5a7c4cd7-0d74-42eb-91f9-31eb2c3768ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-3179c9fe-25ab-488f-987e-dd47c287bdee,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-1781df8f-98ef-4644-8858-dff5c95d2666,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-141894978-172.17.0.20-1597405662798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39618,DS-600551b9-db42-4bdc-ae91-7cc1489e8b29,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-060be96d-36f7-483f-b7fa-5ef70b37a97d,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-e0ebd09b-783b-48fc-88c3-1cb6ba91e9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-737adc26-73e2-4063-a7ae-0f87df198446,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-5c317971-72d7-4f64-bac6-b55ed4f558c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-efc939ce-d1b1-4fdc-bd3f-ac1c3b417bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-261d0a8b-9ae6-4fee-ad1f-372d2b85bc89,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-52a7c48e-128f-4f95-aee8-a86e0db889c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-141894978-172.17.0.20-1597405662798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39618,DS-600551b9-db42-4bdc-ae91-7cc1489e8b29,DISK], DatanodeInfoWithStorage[127.0.0.1:39372,DS-060be96d-36f7-483f-b7fa-5ef70b37a97d,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-e0ebd09b-783b-48fc-88c3-1cb6ba91e9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-737adc26-73e2-4063-a7ae-0f87df198446,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-5c317971-72d7-4f64-bac6-b55ed4f558c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-efc939ce-d1b1-4fdc-bd3f-ac1c3b417bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-261d0a8b-9ae6-4fee-ad1f-372d2b85bc89,DISK], DatanodeInfoWithStorage[127.0.0.1:38421,DS-52a7c48e-128f-4f95-aee8-a86e0db889c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1477567672-172.17.0.20-1597405782795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35114,DS-12e80cfc-5381-47a0-8df1-407a2ca44b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40996,DS-3f63c7f1-5d92-466c-a217-42ba1bf592fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-c7e1a18f-def6-4225-9c1b-9bb2138a7c74,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-c8262c3b-e487-4aaf-8561-f01d0d8f8207,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-c43a5b6a-e9d7-4dcb-b500-893d71604d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-ba7ac49a-a15e-4c3c-96c9-3c716e774d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-dc61156f-5772-4bff-bed0-8b0104e90557,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-f49d0ff2-a38a-4e2b-90ef-055ceefdf822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1477567672-172.17.0.20-1597405782795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35114,DS-12e80cfc-5381-47a0-8df1-407a2ca44b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:40996,DS-3f63c7f1-5d92-466c-a217-42ba1bf592fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35578,DS-c7e1a18f-def6-4225-9c1b-9bb2138a7c74,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-c8262c3b-e487-4aaf-8561-f01d0d8f8207,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-c43a5b6a-e9d7-4dcb-b500-893d71604d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35536,DS-ba7ac49a-a15e-4c3c-96c9-3c716e774d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:41367,DS-dc61156f-5772-4bff-bed0-8b0104e90557,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-f49d0ff2-a38a-4e2b-90ef-055ceefdf822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255089361-172.17.0.20-1597406552606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38903,DS-af1e5baf-220f-4df6-b302-906f65ae4c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-5fb207ed-6958-4048-8a0a-796ea6374af6,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-05f09e43-4214-45b3-bf96-26787a09f650,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-2956e44d-a963-4768-b30c-a94e58855d18,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-b5985ece-dcf9-4685-a1fc-82099ba54259,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-4471486c-ffd7-43be-8460-f1990aa4541f,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-55bf4f1e-6175-456a-9fff-4856a7fee8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-b6e8193a-3352-4c69-9c9e-67a1ff68f5fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1255089361-172.17.0.20-1597406552606:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38903,DS-af1e5baf-220f-4df6-b302-906f65ae4c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-5fb207ed-6958-4048-8a0a-796ea6374af6,DISK], DatanodeInfoWithStorage[127.0.0.1:37627,DS-05f09e43-4214-45b3-bf96-26787a09f650,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-2956e44d-a963-4768-b30c-a94e58855d18,DISK], DatanodeInfoWithStorage[127.0.0.1:45638,DS-b5985ece-dcf9-4685-a1fc-82099ba54259,DISK], DatanodeInfoWithStorage[127.0.0.1:36953,DS-4471486c-ffd7-43be-8460-f1990aa4541f,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-55bf4f1e-6175-456a-9fff-4856a7fee8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-b6e8193a-3352-4c69-9c9e-67a1ff68f5fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246957107-172.17.0.20-1597406594187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37584,DS-278223de-3452-4e05-ba8f-dba2fa433254,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-0b76c9ef-30a5-4118-83d0-bb5630c41d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-b9a3cda2-fb48-4afc-9402-33b01c3d658d,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-5de5427a-bbf6-4de0-a3ef-187243b6c0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-88ee6e71-37b5-4b45-8d20-d2c69b2a9c55,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-8a384056-1039-42ac-a23b-b8a12cd3378c,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-f8f47b6c-9cc7-4fce-8b90-e9cf47d5b81b,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-4b27bc7c-b075-4bb7-a3be-786d139d76b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246957107-172.17.0.20-1597406594187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37584,DS-278223de-3452-4e05-ba8f-dba2fa433254,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-0b76c9ef-30a5-4118-83d0-bb5630c41d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46386,DS-b9a3cda2-fb48-4afc-9402-33b01c3d658d,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-5de5427a-bbf6-4de0-a3ef-187243b6c0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-88ee6e71-37b5-4b45-8d20-d2c69b2a9c55,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-8a384056-1039-42ac-a23b-b8a12cd3378c,DISK], DatanodeInfoWithStorage[127.0.0.1:42914,DS-f8f47b6c-9cc7-4fce-8b90-e9cf47d5b81b,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-4b27bc7c-b075-4bb7-a3be-786d139d76b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-693602913-172.17.0.20-1597406717699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40365,DS-f112e0ff-8bf1-4949-b159-d4f4e6f516ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-1a5289e1-902a-4380-a5e2-834c53ed3935,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-58d07dbb-5ac3-464c-bb2b-992599ff3b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-6d13405f-90e8-46d5-b8c2-6fd851ef9c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-260f27a7-52d1-45d2-9f18-86c33c3bb372,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-d3317395-41e6-4ba2-9a8f-679fe2732b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-f758c63c-a8ef-44b6-a6d6-12f6842a4930,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-d9b57957-ad48-4cbd-b97e-71ebab18352b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-693602913-172.17.0.20-1597406717699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40365,DS-f112e0ff-8bf1-4949-b159-d4f4e6f516ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-1a5289e1-902a-4380-a5e2-834c53ed3935,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-58d07dbb-5ac3-464c-bb2b-992599ff3b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44540,DS-6d13405f-90e8-46d5-b8c2-6fd851ef9c0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-260f27a7-52d1-45d2-9f18-86c33c3bb372,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-d3317395-41e6-4ba2-9a8f-679fe2732b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-f758c63c-a8ef-44b6-a6d6-12f6842a4930,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-d9b57957-ad48-4cbd-b97e-71ebab18352b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1072125739-172.17.0.20-1597406948324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34084,DS-44861301-3b69-46ac-94c9-bc2078f11366,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-cab29696-7898-4053-8538-da42b2b785de,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-ff452a95-afcb-44d1-ad90-b89641b26bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-1d6b7e38-e5c5-42be-8cb4-b9a8bc229209,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-ec8b5339-3e1c-47f2-a5d3-58694abaadae,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-8fdaaa51-12e6-4940-a3ad-365b4dabfca6,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-d8a54865-5ca4-4c21-9f7f-eb0fb18a0034,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-f6fc7b47-e5eb-453a-9d7e-51cd1dba9eba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1072125739-172.17.0.20-1597406948324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34084,DS-44861301-3b69-46ac-94c9-bc2078f11366,DISK], DatanodeInfoWithStorage[127.0.0.1:44076,DS-cab29696-7898-4053-8538-da42b2b785de,DISK], DatanodeInfoWithStorage[127.0.0.1:44182,DS-ff452a95-afcb-44d1-ad90-b89641b26bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-1d6b7e38-e5c5-42be-8cb4-b9a8bc229209,DISK], DatanodeInfoWithStorage[127.0.0.1:46177,DS-ec8b5339-3e1c-47f2-a5d3-58694abaadae,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-8fdaaa51-12e6-4940-a3ad-365b4dabfca6,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-d8a54865-5ca4-4c21-9f7f-eb0fb18a0034,DISK], DatanodeInfoWithStorage[127.0.0.1:40716,DS-f6fc7b47-e5eb-453a-9d7e-51cd1dba9eba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1143941544-172.17.0.20-1597407303037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43224,DS-dfcd98fb-1821-4117-a7dd-19cf3c005efc,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-a065238f-6e7b-4ae0-b6a2-32d6ca6eb7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-c6f88716-bca3-42c0-89c6-ee069f17d8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-0516483d-afe6-4ec8-8a8b-1ce7cb442315,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-f16fdfda-ef2e-4a2d-ba85-577f5ba3e390,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-f187200d-fdcb-4c28-b1f1-79306e6ff5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-f7c501f1-2174-441e-92a5-2c6b7d96707a,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-8049080d-1140-4f6d-873d-e44c7df96519,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1143941544-172.17.0.20-1597407303037:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43224,DS-dfcd98fb-1821-4117-a7dd-19cf3c005efc,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-a065238f-6e7b-4ae0-b6a2-32d6ca6eb7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-c6f88716-bca3-42c0-89c6-ee069f17d8ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-0516483d-afe6-4ec8-8a8b-1ce7cb442315,DISK], DatanodeInfoWithStorage[127.0.0.1:46483,DS-f16fdfda-ef2e-4a2d-ba85-577f5ba3e390,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-f187200d-fdcb-4c28-b1f1-79306e6ff5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-f7c501f1-2174-441e-92a5-2c6b7d96707a,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-8049080d-1140-4f6d-873d-e44c7df96519,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1009406991-172.17.0.20-1597407406402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40371,DS-986ec7be-1ee4-435c-b202-2fc22d3451ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-a2ea0143-73f8-4e74-8ade-790e7316c395,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-e74e1811-e735-48cd-918a-ca5b462e0aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-26d7a170-9f01-4899-b1d7-264a41880331,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-1ee0c741-03cc-4d27-b0d3-fd241521ffc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-bd5983f4-3bd4-4c01-91e3-de125426cacb,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-18852e3c-3b38-4159-8e40-9801bd25678b,DISK], DatanodeInfoWithStorage[127.0.0.1:36258,DS-1b02bbc3-589a-4892-b9dc-303776bdb79b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1009406991-172.17.0.20-1597407406402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40371,DS-986ec7be-1ee4-435c-b202-2fc22d3451ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-a2ea0143-73f8-4e74-8ade-790e7316c395,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-e74e1811-e735-48cd-918a-ca5b462e0aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:34793,DS-26d7a170-9f01-4899-b1d7-264a41880331,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-1ee0c741-03cc-4d27-b0d3-fd241521ffc9,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-bd5983f4-3bd4-4c01-91e3-de125426cacb,DISK], DatanodeInfoWithStorage[127.0.0.1:37191,DS-18852e3c-3b38-4159-8e40-9801bd25678b,DISK], DatanodeInfoWithStorage[127.0.0.1:36258,DS-1b02bbc3-589a-4892-b9dc-303776bdb79b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1602900554-172.17.0.20-1597407646696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36250,DS-41ba47c6-5372-4207-9f73-f2ebd81dd717,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-12c936ab-23f4-4c1a-8842-28b4035218e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-1d965fd0-b883-4719-a34d-b2216694e7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-d8087443-4daa-49c7-b8f1-d5258e903418,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-0ba5ece6-850e-4156-83ef-a40a82990b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-137ee459-718a-4544-b92f-6a25f18b2064,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-7e2fdf82-ac23-4d7d-9dc3-bdfa84471373,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-075b8a67-e33c-4e41-9f4f-48f2ca80a152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1602900554-172.17.0.20-1597407646696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36250,DS-41ba47c6-5372-4207-9f73-f2ebd81dd717,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-12c936ab-23f4-4c1a-8842-28b4035218e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-1d965fd0-b883-4719-a34d-b2216694e7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-d8087443-4daa-49c7-b8f1-d5258e903418,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-0ba5ece6-850e-4156-83ef-a40a82990b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-137ee459-718a-4544-b92f-6a25f18b2064,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-7e2fdf82-ac23-4d7d-9dc3-bdfa84471373,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-075b8a67-e33c-4e41-9f4f-48f2ca80a152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612775183-172.17.0.20-1597407929495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40015,DS-bca986ba-43e5-4bc0-8d99-fed497cce9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-c83fc13e-b020-463d-b918-ac7fbb8d6e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-c2fb4337-c9bd-453b-ab6f-9b7b9d9eb98d,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-0a450142-78ba-4198-b92d-7caff552f00a,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-449c3374-3a9d-46d6-8e55-cbd53ce13f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-e84a4ea1-3b61-4bea-9b32-f67682c076d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-73794bfb-af8e-4537-b85c-8a6b43af86df,DISK], DatanodeInfoWithStorage[127.0.0.1:39103,DS-b40e70c9-d8d3-4060-b207-a6364845b60f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-612775183-172.17.0.20-1597407929495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40015,DS-bca986ba-43e5-4bc0-8d99-fed497cce9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34056,DS-c83fc13e-b020-463d-b918-ac7fbb8d6e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46290,DS-c2fb4337-c9bd-453b-ab6f-9b7b9d9eb98d,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-0a450142-78ba-4198-b92d-7caff552f00a,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-449c3374-3a9d-46d6-8e55-cbd53ce13f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-e84a4ea1-3b61-4bea-9b32-f67682c076d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-73794bfb-af8e-4537-b85c-8a6b43af86df,DISK], DatanodeInfoWithStorage[127.0.0.1:39103,DS-b40e70c9-d8d3-4060-b207-a6364845b60f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1638405975-172.17.0.20-1597408126811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41508,DS-3907aeb1-8be6-410e-ab42-efc356d01ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-01f18bea-7c54-49ad-b414-dd99523115fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-76269078-0edb-46b5-ae7b-f3bcb10cf16a,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-ee1d34d7-7f2e-4940-97b7-ee5855c3d82b,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-f02bafd9-a062-4570-a8f9-fec9fd77c1be,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-38201c7b-232d-496f-95ba-a0f2bcf5d333,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-87b4e61e-9ce2-4335-bc9a-50de4921df54,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-023b433a-fcdc-4552-8958-b9d5a60ab94a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1638405975-172.17.0.20-1597408126811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41508,DS-3907aeb1-8be6-410e-ab42-efc356d01ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-01f18bea-7c54-49ad-b414-dd99523115fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-76269078-0edb-46b5-ae7b-f3bcb10cf16a,DISK], DatanodeInfoWithStorage[127.0.0.1:33621,DS-ee1d34d7-7f2e-4940-97b7-ee5855c3d82b,DISK], DatanodeInfoWithStorage[127.0.0.1:42394,DS-f02bafd9-a062-4570-a8f9-fec9fd77c1be,DISK], DatanodeInfoWithStorage[127.0.0.1:37857,DS-38201c7b-232d-496f-95ba-a0f2bcf5d333,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-87b4e61e-9ce2-4335-bc9a-50de4921df54,DISK], DatanodeInfoWithStorage[127.0.0.1:42053,DS-023b433a-fcdc-4552-8958-b9d5a60ab94a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.max.locked.memory
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-45251504-172.17.0.20-1597408203332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34065,DS-a70da84d-46ac-488c-818e-95c2091d4cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-32530f09-61e1-4ecc-a264-1bc5fadaa2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-b33e1831-4cdd-4ee2-b860-4e5d376eebcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-d79f1f2c-ec3c-4033-ba88-aabc30908472,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-19ddaf99-ed42-4209-b9bd-3d3b568bf9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-72fd92c5-a471-4799-951d-ec19fd0ed0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-92b17ac0-70c9-41e8-a4b7-834caa474aff,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-58e139cb-cb8a-4e1b-a499-6a02845fa1e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-45251504-172.17.0.20-1597408203332:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34065,DS-a70da84d-46ac-488c-818e-95c2091d4cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-32530f09-61e1-4ecc-a264-1bc5fadaa2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-b33e1831-4cdd-4ee2-b860-4e5d376eebcb,DISK], DatanodeInfoWithStorage[127.0.0.1:41474,DS-d79f1f2c-ec3c-4033-ba88-aabc30908472,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-19ddaf99-ed42-4209-b9bd-3d3b568bf9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-72fd92c5-a471-4799-951d-ec19fd0ed0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40566,DS-92b17ac0-70c9-41e8-a4b7-834caa474aff,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-58e139cb-cb8a-4e1b-a499-6a02845fa1e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5778
