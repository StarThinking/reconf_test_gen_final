reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-549941077-172.17.0.3-1597526834170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36143,DS-f507feec-15ce-4741-8566-5ffb576fed8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-493837b4-3582-4017-9017-39b3aae382aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-e32f0207-7eb8-42be-8bf1-ba05ce783ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-7e6fd035-8617-490f-86c3-8b9306567b79,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-e63713d9-cb52-42de-960d-5b9aa524637a,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-1722a45a-be34-4642-bd92-617f10b1203c,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-ce166866-cc2b-42a6-b68b-2e793829df5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-eebe5c10-fef7-4474-b1b8-a9f008abd1d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-549941077-172.17.0.3-1597526834170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36143,DS-f507feec-15ce-4741-8566-5ffb576fed8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-493837b4-3582-4017-9017-39b3aae382aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-e32f0207-7eb8-42be-8bf1-ba05ce783ce9,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-7e6fd035-8617-490f-86c3-8b9306567b79,DISK], DatanodeInfoWithStorage[127.0.0.1:43821,DS-e63713d9-cb52-42de-960d-5b9aa524637a,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-1722a45a-be34-4642-bd92-617f10b1203c,DISK], DatanodeInfoWithStorage[127.0.0.1:37359,DS-ce166866-cc2b-42a6-b68b-2e793829df5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-eebe5c10-fef7-4474-b1b8-a9f008abd1d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-224645932-172.17.0.3-1597527370269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37717,DS-fc742b1e-2ec6-4773-8273-b526d5e5c10c,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-4e2d41c5-9a22-4df0-a7ab-4d7ef5adcd31,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-47233877-db74-4ee7-96a7-1af613afe698,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-f5b87dba-c9c1-45e0-bcbf-7d26af092842,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-61c39375-356e-4252-bd5b-f2527883402b,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-508f24d2-626a-4430-9504-2f179d24eabc,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-30d1d345-5695-4fda-b9c9-bb261460c5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-f53d2e12-9cdc-46a8-963b-6162fb6aacf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-224645932-172.17.0.3-1597527370269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37717,DS-fc742b1e-2ec6-4773-8273-b526d5e5c10c,DISK], DatanodeInfoWithStorage[127.0.0.1:38692,DS-4e2d41c5-9a22-4df0-a7ab-4d7ef5adcd31,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-47233877-db74-4ee7-96a7-1af613afe698,DISK], DatanodeInfoWithStorage[127.0.0.1:39848,DS-f5b87dba-c9c1-45e0-bcbf-7d26af092842,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-61c39375-356e-4252-bd5b-f2527883402b,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-508f24d2-626a-4430-9504-2f179d24eabc,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-30d1d345-5695-4fda-b9c9-bb261460c5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33682,DS-f53d2e12-9cdc-46a8-963b-6162fb6aacf4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-720359340-172.17.0.3-1597527517515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43314,DS-5dc13fc3-1d96-4898-92e7-77070c8f7b74,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-be82cd83-c4f9-455e-8c4d-7792f80eb6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-4fd3cc3e-4e15-4571-bb51-1995a242a89c,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-9e8c5594-b2aa-45c7-91b3-e3eae668192c,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-a751c670-96ff-408b-8746-306839f461ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44434,DS-831882bc-854d-413a-b8d3-ef602fcc2505,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-fa25462e-7395-4572-aa59-93737ca22550,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-0f42b91c-430f-4671-9938-580e121e1e08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-720359340-172.17.0.3-1597527517515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43314,DS-5dc13fc3-1d96-4898-92e7-77070c8f7b74,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-be82cd83-c4f9-455e-8c4d-7792f80eb6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35974,DS-4fd3cc3e-4e15-4571-bb51-1995a242a89c,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-9e8c5594-b2aa-45c7-91b3-e3eae668192c,DISK], DatanodeInfoWithStorage[127.0.0.1:46449,DS-a751c670-96ff-408b-8746-306839f461ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44434,DS-831882bc-854d-413a-b8d3-ef602fcc2505,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-fa25462e-7395-4572-aa59-93737ca22550,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-0f42b91c-430f-4671-9938-580e121e1e08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022881861-172.17.0.3-1597527622415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39024,DS-0491d141-517d-4481-97e1-1c19a29e7bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-b9fd3b69-2336-4eb2-9322-54944f65366f,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-a35c0765-6f1f-4805-9737-0e0f0bed795b,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-d960cc5f-0541-4321-b2d9-dc643fee8d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-48be22e9-203f-42b3-af62-7a13faac7fec,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-efeb8d10-5cb6-49eb-a31b-3539c2270eee,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-c3a565e0-608e-4bf8-8518-a6f1c5982645,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-2b387b3c-87cf-464a-ad92-99bb33478489,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022881861-172.17.0.3-1597527622415:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39024,DS-0491d141-517d-4481-97e1-1c19a29e7bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36687,DS-b9fd3b69-2336-4eb2-9322-54944f65366f,DISK], DatanodeInfoWithStorage[127.0.0.1:35508,DS-a35c0765-6f1f-4805-9737-0e0f0bed795b,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-d960cc5f-0541-4321-b2d9-dc643fee8d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:39575,DS-48be22e9-203f-42b3-af62-7a13faac7fec,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-efeb8d10-5cb6-49eb-a31b-3539c2270eee,DISK], DatanodeInfoWithStorage[127.0.0.1:34568,DS-c3a565e0-608e-4bf8-8518-a6f1c5982645,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-2b387b3c-87cf-464a-ad92-99bb33478489,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1935530707-172.17.0.3-1597527951573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42485,DS-d76d485c-857d-46f2-b88e-fbb562b4b7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-00697c6a-622f-46a9-a1b0-10d55a656929,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-eb5f84d8-adf5-4912-87fd-ad743281b1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-7bc1a67e-2e7f-4810-874d-aeab14b909af,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-429452c3-cd14-4723-83a3-c7feb2043036,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-115b4d10-7172-4749-ae3b-e3e55c8f37ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-67b92f6f-a0ac-4f05-a918-66616993ac6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-7fe344a5-2d25-4176-bcc9-09139112281a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1935530707-172.17.0.3-1597527951573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42485,DS-d76d485c-857d-46f2-b88e-fbb562b4b7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-00697c6a-622f-46a9-a1b0-10d55a656929,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-eb5f84d8-adf5-4912-87fd-ad743281b1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-7bc1a67e-2e7f-4810-874d-aeab14b909af,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-429452c3-cd14-4723-83a3-c7feb2043036,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-115b4d10-7172-4749-ae3b-e3e55c8f37ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-67b92f6f-a0ac-4f05-a918-66616993ac6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42275,DS-7fe344a5-2d25-4176-bcc9-09139112281a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-50834429-172.17.0.3-1597528243669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45902,DS-f480f97e-8eab-44ab-a0fd-d4498a29106d,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-47eb5713-da42-4c3e-a379-7af746e01cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-dcbb4f1a-964a-4f92-8704-f2a5f1dfc99c,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-c864e848-2b44-4b2b-8368-a580bacb8cba,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-7b60e699-dff2-4f96-9576-72c80a57694b,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-67840ae9-e7b9-4f76-88c7-6b8ee2365058,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-06e01b42-e4d8-4c81-a250-7f68cb6004e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-6a564c30-280d-47e8-b60b-178108312101,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-50834429-172.17.0.3-1597528243669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45902,DS-f480f97e-8eab-44ab-a0fd-d4498a29106d,DISK], DatanodeInfoWithStorage[127.0.0.1:33082,DS-47eb5713-da42-4c3e-a379-7af746e01cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-dcbb4f1a-964a-4f92-8704-f2a5f1dfc99c,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-c864e848-2b44-4b2b-8368-a580bacb8cba,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-7b60e699-dff2-4f96-9576-72c80a57694b,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-67840ae9-e7b9-4f76-88c7-6b8ee2365058,DISK], DatanodeInfoWithStorage[127.0.0.1:38054,DS-06e01b42-e4d8-4c81-a250-7f68cb6004e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-6a564c30-280d-47e8-b60b-178108312101,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-569242952-172.17.0.3-1597528673085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41320,DS-16510911-0e59-42bd-abfc-54b8982543cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-152431e5-521e-42a9-b54b-19cbbf210925,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-92dce2d8-1cfb-472a-9542-b20adaaf0b06,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-6da35c8b-31fa-4be9-8c18-b6d9063d68fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-69278922-037d-4ecd-816f-ae259d418abb,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-09a608f5-bb09-41a9-83bc-b0850a7773d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-e893f33d-3067-44ad-9fec-2022e4dae3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-7e971490-85c7-408d-8d2b-6793f34eceac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-569242952-172.17.0.3-1597528673085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41320,DS-16510911-0e59-42bd-abfc-54b8982543cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-152431e5-521e-42a9-b54b-19cbbf210925,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-92dce2d8-1cfb-472a-9542-b20adaaf0b06,DISK], DatanodeInfoWithStorage[127.0.0.1:44840,DS-6da35c8b-31fa-4be9-8c18-b6d9063d68fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-69278922-037d-4ecd-816f-ae259d418abb,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-09a608f5-bb09-41a9-83bc-b0850a7773d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-e893f33d-3067-44ad-9fec-2022e4dae3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45759,DS-7e971490-85c7-408d-8d2b-6793f34eceac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-28756542-172.17.0.3-1597528790877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43715,DS-f5f631c5-2cfa-4eb2-8dbe-3ea82517de6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-f339d251-686b-410c-b9ed-bf263ba9a638,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-8e9906c0-eb19-43e8-8535-63b376f18b56,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-bf62b4c6-e212-472e-a1ce-a3bac99cb68f,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-bfd5ccc3-5893-4aa7-abdc-db329ea8f0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-25036fa7-10df-4884-82d4-e10222146f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-1e55f5dd-22aa-429f-b294-4c64c0add9de,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-bc7ef98d-5b07-46b9-a297-14d6d18894f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-28756542-172.17.0.3-1597528790877:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43715,DS-f5f631c5-2cfa-4eb2-8dbe-3ea82517de6e,DISK], DatanodeInfoWithStorage[127.0.0.1:36561,DS-f339d251-686b-410c-b9ed-bf263ba9a638,DISK], DatanodeInfoWithStorage[127.0.0.1:41461,DS-8e9906c0-eb19-43e8-8535-63b376f18b56,DISK], DatanodeInfoWithStorage[127.0.0.1:42670,DS-bf62b4c6-e212-472e-a1ce-a3bac99cb68f,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-bfd5ccc3-5893-4aa7-abdc-db329ea8f0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-25036fa7-10df-4884-82d4-e10222146f5d,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-1e55f5dd-22aa-429f-b294-4c64c0add9de,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-bc7ef98d-5b07-46b9-a297-14d6d18894f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1676543582-172.17.0.3-1597529411936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38063,DS-50dbb2d8-e613-4fe5-a1a9-491b2a80b0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-04ef9a18-c533-45cf-a643-171b9e77c077,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-7ab009e9-2d5f-4dcd-9f40-eb581a0a87fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-a0040f08-bf1a-4506-b4e7-12c327e4d7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-6e33115c-99c7-4a84-b421-dcc93695e067,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-5d2b41cc-13e4-43f2-a872-df7fb1cb5c66,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-76b2b7a5-f6fe-43ad-ad22-f65140ba0704,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-029a4b0c-704a-4abb-aa8f-301f6d3bdfda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1676543582-172.17.0.3-1597529411936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38063,DS-50dbb2d8-e613-4fe5-a1a9-491b2a80b0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-04ef9a18-c533-45cf-a643-171b9e77c077,DISK], DatanodeInfoWithStorage[127.0.0.1:46042,DS-7ab009e9-2d5f-4dcd-9f40-eb581a0a87fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-a0040f08-bf1a-4506-b4e7-12c327e4d7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-6e33115c-99c7-4a84-b421-dcc93695e067,DISK], DatanodeInfoWithStorage[127.0.0.1:33088,DS-5d2b41cc-13e4-43f2-a872-df7fb1cb5c66,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-76b2b7a5-f6fe-43ad-ad22-f65140ba0704,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-029a4b0c-704a-4abb-aa8f-301f6d3bdfda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421671044-172.17.0.3-1597529959628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44235,DS-66eb9ac2-16d0-4214-8969-6ebc00ef65ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-e12bb2b0-70ca-416b-9382-84dc6a949767,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-c126b2f5-0d67-4857-8034-6391bfc6385a,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-f2f54f41-582c-4443-8a7c-cba10e11851d,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-f01911fc-91a5-4f2c-919e-eba78593e04b,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-2d593139-b360-416e-9c54-1c49a05a145e,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-ae7d85ed-6210-46c5-ae5d-35be04c9d973,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-401d419d-1d62-45ad-bfb6-633b99438c96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-421671044-172.17.0.3-1597529959628:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44235,DS-66eb9ac2-16d0-4214-8969-6ebc00ef65ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-e12bb2b0-70ca-416b-9382-84dc6a949767,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-c126b2f5-0d67-4857-8034-6391bfc6385a,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-f2f54f41-582c-4443-8a7c-cba10e11851d,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-f01911fc-91a5-4f2c-919e-eba78593e04b,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-2d593139-b360-416e-9c54-1c49a05a145e,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-ae7d85ed-6210-46c5-ae5d-35be04c9d973,DISK], DatanodeInfoWithStorage[127.0.0.1:39039,DS-401d419d-1d62-45ad-bfb6-633b99438c96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853253923-172.17.0.3-1597530114522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33384,DS-ea86d4ed-dfaa-4448-a3d9-de4436ebe98b,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-b09d9bc9-08a0-4ddc-9416-22b29568efec,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-5daff43e-c469-47cc-828c-281ce8c33bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-ffc39194-c936-43fb-99fb-9a10b4e12551,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-e77f1cb3-7df8-484d-b6ff-8170d30908ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-6c7b4efb-56ef-4ba7-970c-1863cf9d3d85,DISK], DatanodeInfoWithStorage[127.0.0.1:35541,DS-ae6089ec-0c06-4364-bc58-0ddb8309c321,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-c6a1271f-1696-4d8f-9571-111d4138cfc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853253923-172.17.0.3-1597530114522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33384,DS-ea86d4ed-dfaa-4448-a3d9-de4436ebe98b,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-b09d9bc9-08a0-4ddc-9416-22b29568efec,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-5daff43e-c469-47cc-828c-281ce8c33bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-ffc39194-c936-43fb-99fb-9a10b4e12551,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-e77f1cb3-7df8-484d-b6ff-8170d30908ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-6c7b4efb-56ef-4ba7-970c-1863cf9d3d85,DISK], DatanodeInfoWithStorage[127.0.0.1:35541,DS-ae6089ec-0c06-4364-bc58-0ddb8309c321,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-c6a1271f-1696-4d8f-9571-111d4138cfc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-655348051-172.17.0.3-1597530193061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46821,DS-4343e1c9-f0c5-4fce-bc7d-27d76cbac8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-4d62178b-c380-42a7-8f5e-cdc3e0727bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-736a99d7-2cb2-4bc7-a5c5-c6c1c802f299,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-2a89488c-a07f-4edb-bf10-f722fae21734,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-bce7b043-85fc-40de-bc87-75b3a8114c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-cc72aecc-4501-483c-9545-192c13df1254,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-3464185f-2a04-4398-81d6-6f4e82a1ca56,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-9c7c7e7c-e925-4f3c-b035-4b253125ee6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-655348051-172.17.0.3-1597530193061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46821,DS-4343e1c9-f0c5-4fce-bc7d-27d76cbac8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-4d62178b-c380-42a7-8f5e-cdc3e0727bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-736a99d7-2cb2-4bc7-a5c5-c6c1c802f299,DISK], DatanodeInfoWithStorage[127.0.0.1:36231,DS-2a89488c-a07f-4edb-bf10-f722fae21734,DISK], DatanodeInfoWithStorage[127.0.0.1:41959,DS-bce7b043-85fc-40de-bc87-75b3a8114c4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42882,DS-cc72aecc-4501-483c-9545-192c13df1254,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-3464185f-2a04-4398-81d6-6f4e82a1ca56,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-9c7c7e7c-e925-4f3c-b035-4b253125ee6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1270174583-172.17.0.3-1597530231436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45113,DS-c526064a-ff0c-4b90-b9ff-55023c2cd54a,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-aa39e547-3ba7-41bf-8efd-0dfe6a980921,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-9a488a74-dcd9-4146-b9da-254e8565c61f,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-66ea97fa-bd49-4147-aa73-d654231a2db0,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-265457b2-6e7e-4c5f-9aaa-9e9f0eb66b92,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-3dbc6322-1d3f-450f-a658-c8182bb89b10,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-4fe82175-546f-4c2f-8900-28e42dddabe6,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-cded34cb-997d-4f7d-ae39-d14cc2bfa1f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1270174583-172.17.0.3-1597530231436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45113,DS-c526064a-ff0c-4b90-b9ff-55023c2cd54a,DISK], DatanodeInfoWithStorage[127.0.0.1:37743,DS-aa39e547-3ba7-41bf-8efd-0dfe6a980921,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-9a488a74-dcd9-4146-b9da-254e8565c61f,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-66ea97fa-bd49-4147-aa73-d654231a2db0,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-265457b2-6e7e-4c5f-9aaa-9e9f0eb66b92,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-3dbc6322-1d3f-450f-a658-c8182bb89b10,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-4fe82175-546f-4c2f-8900-28e42dddabe6,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-cded34cb-997d-4f7d-ae39-d14cc2bfa1f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-860731678-172.17.0.3-1597530343749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40544,DS-5d03a1c1-7647-4fe1-9904-26a42693b9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-a3ad490b-2470-45c5-afde-2fe711b203ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-6d8d9f7c-24a9-4670-9f69-a52545dc2628,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-7f7576a0-c67b-460b-b223-be86a4e08222,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-939b6bfb-c2a1-427b-927e-f27cf7fd8bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-19d6b30a-f770-4877-9f7e-5287427d6138,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-d04e430a-162d-40a8-b61c-7e15857de12b,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-c4c03b26-9a0f-41bc-9f21-8864bdfe5e6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-860731678-172.17.0.3-1597530343749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40544,DS-5d03a1c1-7647-4fe1-9904-26a42693b9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-a3ad490b-2470-45c5-afde-2fe711b203ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-6d8d9f7c-24a9-4670-9f69-a52545dc2628,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-7f7576a0-c67b-460b-b223-be86a4e08222,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-939b6bfb-c2a1-427b-927e-f27cf7fd8bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33503,DS-19d6b30a-f770-4877-9f7e-5287427d6138,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-d04e430a-162d-40a8-b61c-7e15857de12b,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-c4c03b26-9a0f-41bc-9f21-8864bdfe5e6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234927230-172.17.0.3-1597530492687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42329,DS-a6a4c1df-7d73-499b-b2f0-89d0048ef41a,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-2c1c0846-21a9-43ba-b740-78cf42e7383e,DISK], DatanodeInfoWithStorage[127.0.0.1:39041,DS-7ef58f95-5d5b-4a3e-82c6-c72383bc4016,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-f41f5aad-1586-4d4c-b640-3af43ba9f633,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-aa6ca12a-4dcc-4828-becc-ef6d3b000186,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-7f96f07a-7174-4a88-b36f-3842bff7fb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-5d50e1a3-b219-4290-a204-791b08e8a51d,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-218c5128-c060-429b-8f5f-a88b10f74b2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234927230-172.17.0.3-1597530492687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42329,DS-a6a4c1df-7d73-499b-b2f0-89d0048ef41a,DISK], DatanodeInfoWithStorage[127.0.0.1:40806,DS-2c1c0846-21a9-43ba-b740-78cf42e7383e,DISK], DatanodeInfoWithStorage[127.0.0.1:39041,DS-7ef58f95-5d5b-4a3e-82c6-c72383bc4016,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-f41f5aad-1586-4d4c-b640-3af43ba9f633,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-aa6ca12a-4dcc-4828-becc-ef6d3b000186,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-7f96f07a-7174-4a88-b36f-3842bff7fb5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-5d50e1a3-b219-4290-a204-791b08e8a51d,DISK], DatanodeInfoWithStorage[127.0.0.1:40552,DS-218c5128-c060-429b-8f5f-a88b10f74b2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-79854729-172.17.0.3-1597530566992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37544,DS-2953d16a-992b-4659-bb91-4850645ec2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-11647b90-2995-43c0-9e85-f1430e3a16c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-450bdf34-1be0-4c88-a62a-8a9587b3193f,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-bfa70009-e232-4623-87a0-99824a540fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-422b9604-62f1-47f2-b300-d281c3255671,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-8bb0f64a-8437-4d0f-9722-0aa31c3377a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-b5ea9ae7-600a-412f-9a1c-3560bbcb4834,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-c298c891-be7e-4813-a1cb-c81d23f47fc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-79854729-172.17.0.3-1597530566992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37544,DS-2953d16a-992b-4659-bb91-4850645ec2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-11647b90-2995-43c0-9e85-f1430e3a16c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36873,DS-450bdf34-1be0-4c88-a62a-8a9587b3193f,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-bfa70009-e232-4623-87a0-99824a540fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-422b9604-62f1-47f2-b300-d281c3255671,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-8bb0f64a-8437-4d0f-9722-0aa31c3377a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-b5ea9ae7-600a-412f-9a1c-3560bbcb4834,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-c298c891-be7e-4813-a1cb-c81d23f47fc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1064728507-172.17.0.3-1597530603133:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45906,DS-4402e012-8021-4c7e-b112-99f715808c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-ec91c76e-56f3-47ed-a1aa-62ced48444ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-9d81715f-65ca-42d2-89d4-df1a9ac66de5,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-bdddecd1-2693-4ac6-b0bc-f4daaab7b206,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-9e425745-8214-4201-b9ca-609286aeadd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-3e7daaec-7a7f-440c-911e-cce1f2a470d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-df2c3ed8-5d8b-40f8-9f0d-47d1c29dcf13,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-71d36d1a-6770-49c2-843e-8c7d30083e03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1064728507-172.17.0.3-1597530603133:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45906,DS-4402e012-8021-4c7e-b112-99f715808c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-ec91c76e-56f3-47ed-a1aa-62ced48444ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-9d81715f-65ca-42d2-89d4-df1a9ac66de5,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-bdddecd1-2693-4ac6-b0bc-f4daaab7b206,DISK], DatanodeInfoWithStorage[127.0.0.1:39554,DS-9e425745-8214-4201-b9ca-609286aeadd4,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-3e7daaec-7a7f-440c-911e-cce1f2a470d9,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-df2c3ed8-5d8b-40f8-9f0d-47d1c29dcf13,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-71d36d1a-6770-49c2-843e-8c7d30083e03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1996209434-172.17.0.3-1597530983420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37990,DS-867fe0db-326a-4149-b6f5-1514b224dbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-16a7a0a3-0977-41ea-b785-e91280854468,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-914ff4d2-4e94-45d1-92d8-06bc57c49b14,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-2664a70c-c50f-4329-9898-0bb0017edc90,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-a5d6e0e1-8adf-4fb2-8be5-2a6906b56ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-3de3c970-4f05-41e6-81d7-8c6f50c236ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-b2ee0c26-2aa5-4a0c-ba49-6b49ed44fa15,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-65fca2e9-1f5a-46fc-99dd-76e3ea28303a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1996209434-172.17.0.3-1597530983420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37990,DS-867fe0db-326a-4149-b6f5-1514b224dbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-16a7a0a3-0977-41ea-b785-e91280854468,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-914ff4d2-4e94-45d1-92d8-06bc57c49b14,DISK], DatanodeInfoWithStorage[127.0.0.1:45048,DS-2664a70c-c50f-4329-9898-0bb0017edc90,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-a5d6e0e1-8adf-4fb2-8be5-2a6906b56ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-3de3c970-4f05-41e6-81d7-8c6f50c236ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-b2ee0c26-2aa5-4a0c-ba49-6b49ed44fa15,DISK], DatanodeInfoWithStorage[127.0.0.1:42712,DS-65fca2e9-1f5a-46fc-99dd-76e3ea28303a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-822757404-172.17.0.3-1597531554197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46115,DS-282a24a8-a824-4f76-8469-f17bb75a4e72,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-dadd128e-39dd-4934-a63f-5df085e598c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-66ba6c0c-967a-4eb4-a516-4927150328b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-85f5c743-6795-4183-a150-d05afd4c49ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-871a93f5-f591-451e-8b96-6b8cbb4eeb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-027a8542-e527-4503-b1d7-2e19a016ab10,DISK], DatanodeInfoWithStorage[127.0.0.1:42201,DS-6d30bf9e-9bc5-444a-b1de-28e6be7998ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-be146426-3036-4db2-9e66-70006430e09d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-822757404-172.17.0.3-1597531554197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46115,DS-282a24a8-a824-4f76-8469-f17bb75a4e72,DISK], DatanodeInfoWithStorage[127.0.0.1:36009,DS-dadd128e-39dd-4934-a63f-5df085e598c6,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-66ba6c0c-967a-4eb4-a516-4927150328b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42536,DS-85f5c743-6795-4183-a150-d05afd4c49ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46171,DS-871a93f5-f591-451e-8b96-6b8cbb4eeb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-027a8542-e527-4503-b1d7-2e19a016ab10,DISK], DatanodeInfoWithStorage[127.0.0.1:42201,DS-6d30bf9e-9bc5-444a-b1de-28e6be7998ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-be146426-3036-4db2-9e66-70006430e09d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.cachereport.intervalMsec
component: hdfs:DataNode
v1: 10
v2: 10000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-640217887-172.17.0.3-1597531803530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36207,DS-e34d8756-2537-41af-8e61-7842adbcc33d,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-213cdae9-4d51-4d7f-be11-82f51a2b9295,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-1cbb7821-7203-4085-aca2-495872ca10a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-0ff9b38f-e723-42df-9b59-4ef497ba6c89,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-cbd885ea-17e0-423e-9f65-48f10eba68bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-b9a1da43-2d0b-435a-94a2-0f63ad5f0d33,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-fb407752-77ea-42f3-b3e2-6e8d5635386a,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-6e108acb-b79e-4ce8-9661-bd2183ddb114,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-640217887-172.17.0.3-1597531803530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36207,DS-e34d8756-2537-41af-8e61-7842adbcc33d,DISK], DatanodeInfoWithStorage[127.0.0.1:38146,DS-213cdae9-4d51-4d7f-be11-82f51a2b9295,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-1cbb7821-7203-4085-aca2-495872ca10a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-0ff9b38f-e723-42df-9b59-4ef497ba6c89,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-cbd885ea-17e0-423e-9f65-48f10eba68bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-b9a1da43-2d0b-435a-94a2-0f63ad5f0d33,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-fb407752-77ea-42f3-b3e2-6e8d5635386a,DISK], DatanodeInfoWithStorage[127.0.0.1:42870,DS-6e108acb-b79e-4ce8-9661-bd2183ddb114,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5652
