reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-51240188-172.17.0.11-1597540108560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37736,DS-dacc7dcf-af14-4e8f-a501-6dc0bbba15c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-ce35f28c-6d8a-44a6-b6a1-1777e0fba1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-7e62ec59-df0b-46a6-95de-fe2d251f18cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-acb0fe2d-d3f6-4b38-8de6-aaa9ba8dac3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-63a9eab7-ae5f-4f0b-9341-14267cb58d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-8adb0905-5c68-4393-959e-b43e9103c002,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-e10a44db-b31c-4cba-b8c8-0aedd64fa3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-27be457d-d517-4609-aa46-ce2904d32b2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-51240188-172.17.0.11-1597540108560:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37736,DS-dacc7dcf-af14-4e8f-a501-6dc0bbba15c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-ce35f28c-6d8a-44a6-b6a1-1777e0fba1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-7e62ec59-df0b-46a6-95de-fe2d251f18cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43551,DS-acb0fe2d-d3f6-4b38-8de6-aaa9ba8dac3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42851,DS-63a9eab7-ae5f-4f0b-9341-14267cb58d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-8adb0905-5c68-4393-959e-b43e9103c002,DISK], DatanodeInfoWithStorage[127.0.0.1:33923,DS-e10a44db-b31c-4cba-b8c8-0aedd64fa3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36826,DS-27be457d-d517-4609-aa46-ce2904d32b2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-114814756-172.17.0.11-1597540349998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35696,DS-0bcfe399-02ca-4b29-b4b3-7e98e9f6c36f,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-254b479b-fc94-4012-aaa5-e484b7f07140,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-322117cf-2913-4490-8a2f-d2aa78c7fbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-247402af-2ad9-4566-9467-17ed1b025eae,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-e459b4cb-9070-4cde-bb74-d391dc32d50d,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-d0e1f45c-f2d4-4441-bf93-82c9aec923e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-f8318ab6-80e5-40f9-91a1-2ae40e67eb71,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-52ecdd93-5861-4c14-aebf-f0217f451e55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-114814756-172.17.0.11-1597540349998:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35696,DS-0bcfe399-02ca-4b29-b4b3-7e98e9f6c36f,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-254b479b-fc94-4012-aaa5-e484b7f07140,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-322117cf-2913-4490-8a2f-d2aa78c7fbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-247402af-2ad9-4566-9467-17ed1b025eae,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-e459b4cb-9070-4cde-bb74-d391dc32d50d,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-d0e1f45c-f2d4-4441-bf93-82c9aec923e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-f8318ab6-80e5-40f9-91a1-2ae40e67eb71,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-52ecdd93-5861-4c14-aebf-f0217f451e55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324856221-172.17.0.11-1597541656132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44861,DS-d43b5053-000c-4c49-b600-bbc923843e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-ee85e4d0-351a-4f4a-9b35-791d4fe369bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-11e19c0d-cf9e-4e2d-866e-c22456fc8a24,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-f7cdb0ee-2320-4186-85a2-ba8c7f892502,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-4e4cd28d-8bd1-44c8-b670-62a1a07490fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-e30d3d15-e747-460b-97f3-64e17ac120f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-2b0779c4-cc32-4cb0-8fbc-215d8863d57a,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-398aab32-2cd0-4a0b-8a72-011f74d02593,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324856221-172.17.0.11-1597541656132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44861,DS-d43b5053-000c-4c49-b600-bbc923843e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-ee85e4d0-351a-4f4a-9b35-791d4fe369bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40630,DS-11e19c0d-cf9e-4e2d-866e-c22456fc8a24,DISK], DatanodeInfoWithStorage[127.0.0.1:41205,DS-f7cdb0ee-2320-4186-85a2-ba8c7f892502,DISK], DatanodeInfoWithStorage[127.0.0.1:40170,DS-4e4cd28d-8bd1-44c8-b670-62a1a07490fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-e30d3d15-e747-460b-97f3-64e17ac120f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-2b0779c4-cc32-4cb0-8fbc-215d8863d57a,DISK], DatanodeInfoWithStorage[127.0.0.1:44579,DS-398aab32-2cd0-4a0b-8a72-011f74d02593,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2064626844-172.17.0.11-1597541844551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32957,DS-bf0fe441-f93f-44a0-96cb-59bf6c680a52,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-5adbb9f4-e570-4629-a41a-810e9180c807,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-791e1977-d5f1-4f37-91b5-c11a57eb11ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-fe8a8a60-52a6-4601-8a4f-624f091705a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-4d19f8ce-252e-4d96-8d9c-255bcf710a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-cbb6fad4-2dcc-4b0d-a2c2-9c912900e17f,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-1a7d6317-5361-41e0-a47c-4b2cc5f9e82c,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-843d2a01-5b67-4a00-808f-e3ffbeba77c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2064626844-172.17.0.11-1597541844551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32957,DS-bf0fe441-f93f-44a0-96cb-59bf6c680a52,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-5adbb9f4-e570-4629-a41a-810e9180c807,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-791e1977-d5f1-4f37-91b5-c11a57eb11ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-fe8a8a60-52a6-4601-8a4f-624f091705a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36698,DS-4d19f8ce-252e-4d96-8d9c-255bcf710a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-cbb6fad4-2dcc-4b0d-a2c2-9c912900e17f,DISK], DatanodeInfoWithStorage[127.0.0.1:43524,DS-1a7d6317-5361-41e0-a47c-4b2cc5f9e82c,DISK], DatanodeInfoWithStorage[127.0.0.1:33862,DS-843d2a01-5b67-4a00-808f-e3ffbeba77c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-502320213-172.17.0.11-1597541967198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37609,DS-86c6ec62-9843-49f0-a0b0-bfe6e8bc3a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-43406665-426a-487e-9a8e-c3bd81a99414,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-53d6e2e2-ab70-4fe5-b3f8-b2c94ad7aad0,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-2dbd16fc-0b47-438b-9296-5b07ecc00ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-3a21faa6-e76e-48fb-a24c-c2beb4c45ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-3f1d8792-476b-45d5-9b4d-7a241800dbed,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-eeb41d35-54b8-44b1-b80a-29a462653557,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-4048f1f3-a94f-4f5e-9a70-50f8dcd5edb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-502320213-172.17.0.11-1597541967198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37609,DS-86c6ec62-9843-49f0-a0b0-bfe6e8bc3a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-43406665-426a-487e-9a8e-c3bd81a99414,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-53d6e2e2-ab70-4fe5-b3f8-b2c94ad7aad0,DISK], DatanodeInfoWithStorage[127.0.0.1:37556,DS-2dbd16fc-0b47-438b-9296-5b07ecc00ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-3a21faa6-e76e-48fb-a24c-c2beb4c45ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:34625,DS-3f1d8792-476b-45d5-9b4d-7a241800dbed,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-eeb41d35-54b8-44b1-b80a-29a462653557,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-4048f1f3-a94f-4f5e-9a70-50f8dcd5edb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-716533687-172.17.0.11-1597542464210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40171,DS-be6c454e-fe8f-4aec-82fa-9c05ed36414c,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-c94836ad-33b1-48e3-b612-f652a6d618f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-713f413f-2d6a-41c1-b8a7-df032832418e,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-b44ad2f6-e7a1-46b7-ab5c-c55ab4eeeb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-ef05ca1c-8270-49aa-8da6-8262f25fafeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-1ff2d1ba-d7ed-436f-8317-9b00a5a13c66,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-0f8d7be8-4e37-4098-899c-71260109a514,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-eefb830d-adb1-4951-bb87-cf92e3c0c28d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-716533687-172.17.0.11-1597542464210:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40171,DS-be6c454e-fe8f-4aec-82fa-9c05ed36414c,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-c94836ad-33b1-48e3-b612-f652a6d618f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45735,DS-713f413f-2d6a-41c1-b8a7-df032832418e,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-b44ad2f6-e7a1-46b7-ab5c-c55ab4eeeb0c,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-ef05ca1c-8270-49aa-8da6-8262f25fafeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43545,DS-1ff2d1ba-d7ed-436f-8317-9b00a5a13c66,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-0f8d7be8-4e37-4098-899c-71260109a514,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-eefb830d-adb1-4951-bb87-cf92e3c0c28d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-872760950-172.17.0.11-1597542502153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45898,DS-6bcba2ac-b647-4e6f-adc3-31ec7b19ced6,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-d2e21b58-4147-44d9-856e-3bd7f67a5e45,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-04528061-1ab7-49b3-a4eb-6647545f9cca,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-280c9e00-626f-47d0-91a3-f9bd1ec84539,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-f361f1ec-014f-4b98-b229-f07079cc162a,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-eca7b788-1af8-4319-9ef2-0b1c35801b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-22a31db8-6811-454e-9506-e51c2cd5e4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-7e41bbac-b4aa-4517-9f87-cdd85caacb19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-872760950-172.17.0.11-1597542502153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45898,DS-6bcba2ac-b647-4e6f-adc3-31ec7b19ced6,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-d2e21b58-4147-44d9-856e-3bd7f67a5e45,DISK], DatanodeInfoWithStorage[127.0.0.1:42282,DS-04528061-1ab7-49b3-a4eb-6647545f9cca,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-280c9e00-626f-47d0-91a3-f9bd1ec84539,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-f361f1ec-014f-4b98-b229-f07079cc162a,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-eca7b788-1af8-4319-9ef2-0b1c35801b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46125,DS-22a31db8-6811-454e-9506-e51c2cd5e4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-7e41bbac-b4aa-4517-9f87-cdd85caacb19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869716416-172.17.0.11-1597542882184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42230,DS-d1f4c745-d6a6-492f-9911-1e3b458f2fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-799a39b5-e0c8-4d0f-b59e-37f98ff91225,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-c7f00b88-90a1-4087-93d2-eaeb7c2be7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-e994e1fe-5ff7-4e6d-9a3e-ea3dda7e09bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-60df5f93-763b-42c4-b3b7-14d56fc96b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-2c4a815a-324e-49f3-9816-42b4f7068290,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-0eaecba5-3fd7-47eb-8d00-7604c6cbd7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-2f98dd2b-3068-460d-9c5b-f1c71956e241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869716416-172.17.0.11-1597542882184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42230,DS-d1f4c745-d6a6-492f-9911-1e3b458f2fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-799a39b5-e0c8-4d0f-b59e-37f98ff91225,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-c7f00b88-90a1-4087-93d2-eaeb7c2be7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-e994e1fe-5ff7-4e6d-9a3e-ea3dda7e09bf,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-60df5f93-763b-42c4-b3b7-14d56fc96b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-2c4a815a-324e-49f3-9816-42b4f7068290,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-0eaecba5-3fd7-47eb-8d00-7604c6cbd7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-2f98dd2b-3068-460d-9c5b-f1c71956e241,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850488154-172.17.0.11-1597543080872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45949,DS-a8cf50a0-2796-421a-8d92-4537f3a8d75f,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-8639483a-e3ae-499d-abaa-0e87d094940e,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-2b275188-db54-46f5-9087-825ce81146f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-993f71cc-35e8-4dc2-b6aa-42ae081aa9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-79e1a610-499a-4089-b0f4-8d32047a6c64,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-1f9aa6eb-141a-4a8a-af83-2313c77d9070,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-938614dc-21d9-4abf-88be-ad16c4595332,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-66249c76-e919-47cb-a8ae-c215efd16449,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850488154-172.17.0.11-1597543080872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45949,DS-a8cf50a0-2796-421a-8d92-4537f3a8d75f,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-8639483a-e3ae-499d-abaa-0e87d094940e,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-2b275188-db54-46f5-9087-825ce81146f7,DISK], DatanodeInfoWithStorage[127.0.0.1:44146,DS-993f71cc-35e8-4dc2-b6aa-42ae081aa9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37899,DS-79e1a610-499a-4089-b0f4-8d32047a6c64,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-1f9aa6eb-141a-4a8a-af83-2313c77d9070,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-938614dc-21d9-4abf-88be-ad16c4595332,DISK], DatanodeInfoWithStorage[127.0.0.1:42448,DS-66249c76-e919-47cb-a8ae-c215efd16449,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1785524485-172.17.0.11-1597543163790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41626,DS-7b3cdaab-59f7-48ba-839c-c35180e91cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-5c15b38f-9568-4e27-a541-f92c8ea2012a,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-b9380ff0-61e9-49c7-989b-3ae6ee1d9cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-2a591046-8807-4604-9191-a5fa5050de2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-ea24df85-717f-44c0-bfbf-db5943a70bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-111e50a2-c8e0-44e3-a3b7-a740f851b076,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-85626866-346c-4ff9-be77-cc9c0369188d,DISK], DatanodeInfoWithStorage[127.0.0.1:44557,DS-359bdcfd-a020-42d2-bac3-fc8088bd4d2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1785524485-172.17.0.11-1597543163790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41626,DS-7b3cdaab-59f7-48ba-839c-c35180e91cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-5c15b38f-9568-4e27-a541-f92c8ea2012a,DISK], DatanodeInfoWithStorage[127.0.0.1:41417,DS-b9380ff0-61e9-49c7-989b-3ae6ee1d9cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-2a591046-8807-4604-9191-a5fa5050de2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44331,DS-ea24df85-717f-44c0-bfbf-db5943a70bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-111e50a2-c8e0-44e3-a3b7-a740f851b076,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-85626866-346c-4ff9-be77-cc9c0369188d,DISK], DatanodeInfoWithStorage[127.0.0.1:44557,DS-359bdcfd-a020-42d2-bac3-fc8088bd4d2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1901617805-172.17.0.11-1597543356102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33148,DS-2c042282-42c9-4d9e-93e4-08dd72930b28,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-064528dd-edef-4ea3-8723-192b7faac63e,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-fb8f28c6-d347-4a89-b0b6-8881091c4cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-93cf044b-812c-4926-8934-aec21237e506,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-02419f41-691e-4597-80b4-3c4e3a2cdff5,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-cd58a68e-8552-4122-9fb4-dd2c948aaf7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-f770d730-02db-462b-8cb6-cfb4b07e48f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-96fbdecb-4f69-4ed8-a48a-10eb75ca3f1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1901617805-172.17.0.11-1597543356102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33148,DS-2c042282-42c9-4d9e-93e4-08dd72930b28,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-064528dd-edef-4ea3-8723-192b7faac63e,DISK], DatanodeInfoWithStorage[127.0.0.1:39749,DS-fb8f28c6-d347-4a89-b0b6-8881091c4cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36303,DS-93cf044b-812c-4926-8934-aec21237e506,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-02419f41-691e-4597-80b4-3c4e3a2cdff5,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-cd58a68e-8552-4122-9fb4-dd2c948aaf7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-f770d730-02db-462b-8cb6-cfb4b07e48f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44885,DS-96fbdecb-4f69-4ed8-a48a-10eb75ca3f1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1983431809-172.17.0.11-1597543469336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44302,DS-6f96b335-e077-4483-afc5-dd7241d8124b,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-81061c67-a145-428e-b78e-756c1b9751b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-944a218f-f296-499b-9a55-ab17a222223d,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-9b89bc8c-9156-4c68-bc77-5b7aa69438c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-67557068-cdb0-49f4-ae44-d8dabc8edd14,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-6d2e5cde-1b1b-4524-b2c9-c38291195914,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-c779a3f2-521b-49c1-881e-a8b27c9b47b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-13d1b8f5-7507-4ff7-8606-fbc1f676cea6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1983431809-172.17.0.11-1597543469336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44302,DS-6f96b335-e077-4483-afc5-dd7241d8124b,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-81061c67-a145-428e-b78e-756c1b9751b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39577,DS-944a218f-f296-499b-9a55-ab17a222223d,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-9b89bc8c-9156-4c68-bc77-5b7aa69438c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-67557068-cdb0-49f4-ae44-d8dabc8edd14,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-6d2e5cde-1b1b-4524-b2c9-c38291195914,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-c779a3f2-521b-49c1-881e-a8b27c9b47b7,DISK], DatanodeInfoWithStorage[127.0.0.1:40501,DS-13d1b8f5-7507-4ff7-8606-fbc1f676cea6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553211537-172.17.0.11-1597543715503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40117,DS-7831abf4-81dc-4425-82ff-78a0aa621c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-929ed2ea-5476-49d2-a639-d0a04fcf7a54,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-11033e23-8373-4efb-a227-56e5de5b97dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-344a3dc8-45cd-4355-8e64-13283d2c57df,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-daf7aa02-bbb7-48c9-922f-70596e776267,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-66e0c2b7-ab05-4496-ac35-38a431f39c72,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-56d3a3ec-144d-4b0e-b182-af9954e61d88,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-6c3869d9-8ab1-4fa2-b677-526d4c40ffb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-553211537-172.17.0.11-1597543715503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40117,DS-7831abf4-81dc-4425-82ff-78a0aa621c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-929ed2ea-5476-49d2-a639-d0a04fcf7a54,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-11033e23-8373-4efb-a227-56e5de5b97dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-344a3dc8-45cd-4355-8e64-13283d2c57df,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-daf7aa02-bbb7-48c9-922f-70596e776267,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-66e0c2b7-ab05-4496-ac35-38a431f39c72,DISK], DatanodeInfoWithStorage[127.0.0.1:46883,DS-56d3a3ec-144d-4b0e-b182-af9954e61d88,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-6c3869d9-8ab1-4fa2-b677-526d4c40ffb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469127849-172.17.0.11-1597543836435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39616,DS-e2a48fbc-63a5-4a96-80b8-1d76a89cd5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-10248383-9092-4f22-ade9-a3ed23e7cbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-728ccfdb-3def-4756-bad0-6dae697134a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-aca2f7f5-5c47-4a2f-81e6-e98a71ff2c98,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-46661ecd-ca33-414f-9d7a-6034de403bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-a66501fe-f094-48f6-8354-95c30f87daf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-fd01d0c4-c9d4-4107-97c8-c88f2ca3a5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34377,DS-d4643cb5-2539-4518-ba9d-166fbad9c64d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-469127849-172.17.0.11-1597543836435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39616,DS-e2a48fbc-63a5-4a96-80b8-1d76a89cd5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-10248383-9092-4f22-ade9-a3ed23e7cbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34155,DS-728ccfdb-3def-4756-bad0-6dae697134a0,DISK], DatanodeInfoWithStorage[127.0.0.1:36013,DS-aca2f7f5-5c47-4a2f-81e6-e98a71ff2c98,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-46661ecd-ca33-414f-9d7a-6034de403bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-a66501fe-f094-48f6-8354-95c30f87daf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-fd01d0c4-c9d4-4107-97c8-c88f2ca3a5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34377,DS-d4643cb5-2539-4518-ba9d-166fbad9c64d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-45193026-172.17.0.11-1597544069398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41414,DS-191de064-2162-4f1e-807e-7e319cc93b79,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-8b04e82d-8402-4b0f-bf2b-88c4da43b279,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-9bc4fdbd-3a9d-422a-98ad-017fae31b1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-159f8774-ceda-429f-ada9-0e1b4fe717c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-d3f07866-b7e0-4351-9fed-1ce9462d0ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-580af829-a3de-40f9-8f26-36858729daa5,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-e8a9487c-cce4-4c06-aad5-cb655b59b2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-47f94cba-e2f1-4ca6-a9aa-060ec3a1300d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-45193026-172.17.0.11-1597544069398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41414,DS-191de064-2162-4f1e-807e-7e319cc93b79,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-8b04e82d-8402-4b0f-bf2b-88c4da43b279,DISK], DatanodeInfoWithStorage[127.0.0.1:36646,DS-9bc4fdbd-3a9d-422a-98ad-017fae31b1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-159f8774-ceda-429f-ada9-0e1b4fe717c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-d3f07866-b7e0-4351-9fed-1ce9462d0ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-580af829-a3de-40f9-8f26-36858729daa5,DISK], DatanodeInfoWithStorage[127.0.0.1:33507,DS-e8a9487c-cce4-4c06-aad5-cb655b59b2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35969,DS-47f94cba-e2f1-4ca6-a9aa-060ec3a1300d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-825033519-172.17.0.11-1597544225953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44961,DS-6ca14999-6f98-4247-aff9-8e54457888b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-b1739d1d-763a-4bc6-8727-820e25ac3ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-25dc4fad-5c81-4e67-a2b5-9b5b39c3e7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-b25dc5be-a856-4e9e-9e5b-60bc6666993a,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-d86f6d36-de5d-4e95-b271-47e485039865,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-dc4613c8-2f09-47bc-8d6e-f2f9fc0f3101,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-5c6153fd-72b8-4f9a-9db8-07e87779f5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-b239cbf1-ddf3-4514-9de6-1cb841028c11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-825033519-172.17.0.11-1597544225953:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44961,DS-6ca14999-6f98-4247-aff9-8e54457888b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-b1739d1d-763a-4bc6-8727-820e25ac3ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:34151,DS-25dc4fad-5c81-4e67-a2b5-9b5b39c3e7d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-b25dc5be-a856-4e9e-9e5b-60bc6666993a,DISK], DatanodeInfoWithStorage[127.0.0.1:34912,DS-d86f6d36-de5d-4e95-b271-47e485039865,DISK], DatanodeInfoWithStorage[127.0.0.1:37183,DS-dc4613c8-2f09-47bc-8d6e-f2f9fc0f3101,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-5c6153fd-72b8-4f9a-9db8-07e87779f5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34910,DS-b239cbf1-ddf3-4514-9de6-1cb841028c11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302640251-172.17.0.11-1597544958388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46769,DS-1a4e227c-1a8f-4524-bd39-c4850ce44ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-1728d41d-61f3-4cb5-8aaf-6f07bbe40d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-024d8aa4-e271-441d-8474-fdbd85ef589f,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-54637b3b-54bb-4b9d-81a7-fa73bc068c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-c7dbc032-6cf6-4c81-bb1c-e5f6d37e16e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-5052edb3-30c1-405b-b656-da04f2019818,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-f167c615-690b-454c-a234-3665756ebfdc,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-aede8a62-4d0f-4698-8b01-abdcd36bdda1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302640251-172.17.0.11-1597544958388:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46769,DS-1a4e227c-1a8f-4524-bd39-c4850ce44ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-1728d41d-61f3-4cb5-8aaf-6f07bbe40d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-024d8aa4-e271-441d-8474-fdbd85ef589f,DISK], DatanodeInfoWithStorage[127.0.0.1:35617,DS-54637b3b-54bb-4b9d-81a7-fa73bc068c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45448,DS-c7dbc032-6cf6-4c81-bb1c-e5f6d37e16e2,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-5052edb3-30c1-405b-b656-da04f2019818,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-f167c615-690b-454c-a234-3665756ebfdc,DISK], DatanodeInfoWithStorage[127.0.0.1:35574,DS-aede8a62-4d0f-4698-8b01-abdcd36bdda1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-292338944-172.17.0.11-1597545039016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40154,DS-72ed6f1e-1556-4795-8d2d-2151460f3a46,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-e329ad13-66b1-49e0-ab79-b767b978403e,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-eaba9766-57ab-48d9-8e80-9b06329ca637,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-70031268-b628-4499-bd41-3675de4284b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-ee0867c4-705d-428d-8c43-bb17bee05dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-d64aa615-196e-4bb2-8206-25fea0ca5a33,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-9dc38f03-9b55-4fdf-87ff-f8b8e027549c,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-97964bef-7f4d-4822-a1fe-8337e7b4a42a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-292338944-172.17.0.11-1597545039016:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40154,DS-72ed6f1e-1556-4795-8d2d-2151460f3a46,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-e329ad13-66b1-49e0-ab79-b767b978403e,DISK], DatanodeInfoWithStorage[127.0.0.1:32820,DS-eaba9766-57ab-48d9-8e80-9b06329ca637,DISK], DatanodeInfoWithStorage[127.0.0.1:32915,DS-70031268-b628-4499-bd41-3675de4284b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-ee0867c4-705d-428d-8c43-bb17bee05dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-d64aa615-196e-4bb2-8206-25fea0ca5a33,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-9dc38f03-9b55-4fdf-87ff-f8b8e027549c,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-97964bef-7f4d-4822-a1fe-8337e7b4a42a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-336772061-172.17.0.11-1597545240749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43818,DS-4753b3d3-409d-4629-a2a0-fa856328df1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-772a58af-5b94-4e2a-9104-8e09259a09a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-3c9a7760-18f2-4f50-b134-5601956e549b,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-ab98fa19-3ada-4ab8-830c-93d29fcea2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-23eb043c-2641-4bd3-8ff4-6fda49b4febe,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-aa8b6923-90d5-42c8-85d9-c5ed69b28822,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-e12e571d-65ad-422e-831d-8c24141a532a,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-61d04142-0c1d-44e3-a673-e164b6f05db2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-336772061-172.17.0.11-1597545240749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43818,DS-4753b3d3-409d-4629-a2a0-fa856328df1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-772a58af-5b94-4e2a-9104-8e09259a09a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-3c9a7760-18f2-4f50-b134-5601956e549b,DISK], DatanodeInfoWithStorage[127.0.0.1:45785,DS-ab98fa19-3ada-4ab8-830c-93d29fcea2f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36238,DS-23eb043c-2641-4bd3-8ff4-6fda49b4febe,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-aa8b6923-90d5-42c8-85d9-c5ed69b28822,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-e12e571d-65ad-422e-831d-8c24141a532a,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-61d04142-0c1d-44e3-a673-e164b6f05db2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889275144-172.17.0.11-1597545319867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39023,DS-6b946245-8a44-432f-8fa7-f9b1312f1859,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-4518335a-dbcd-4f58-b0bc-e52fc95576e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-194ce41b-6ed2-4f40-923c-d6ee6da5e559,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-11611b5e-5c91-4b85-8396-5e0d6be2f730,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-c53aeff5-47e0-4ed8-a34f-6c3636144d75,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-88295ed9-a4af-4000-9453-8a7b26aceffa,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-d658e458-c71b-4ab1-96e9-4aef97a6078a,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-a3b89421-723c-4c83-a521-680128ed5608,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889275144-172.17.0.11-1597545319867:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39023,DS-6b946245-8a44-432f-8fa7-f9b1312f1859,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-4518335a-dbcd-4f58-b0bc-e52fc95576e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46253,DS-194ce41b-6ed2-4f40-923c-d6ee6da5e559,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-11611b5e-5c91-4b85-8396-5e0d6be2f730,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-c53aeff5-47e0-4ed8-a34f-6c3636144d75,DISK], DatanodeInfoWithStorage[127.0.0.1:46121,DS-88295ed9-a4af-4000-9453-8a7b26aceffa,DISK], DatanodeInfoWithStorage[127.0.0.1:41129,DS-d658e458-c71b-4ab1-96e9-4aef97a6078a,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-a3b89421-723c-4c83-a521-680128ed5608,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.du.reserved
component: hdfs:DataNode
v1: 0
v2: 512
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-463856225-172.17.0.11-1597545399515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40190,DS-01c2b260-3047-4eef-9a82-06d169cc1299,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-cc204fbc-e0fe-43ae-a795-b61bb3b2cbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-a398fad8-9c25-42a8-95eb-9fabcecc9c15,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-2f8fb36c-b85c-46c4-a023-936c64013a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-33e5c2d9-8c90-4478-9735-3fc8f21d763e,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-84a1dc67-5c80-4cdd-804a-f6a4197b0b58,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-dcb6c266-ac8e-44b1-9222-d71ed9e227c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-e79bed50-c551-4f30-9815-f7395100d299,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-463856225-172.17.0.11-1597545399515:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40190,DS-01c2b260-3047-4eef-9a82-06d169cc1299,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-cc204fbc-e0fe-43ae-a795-b61bb3b2cbc8,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-a398fad8-9c25-42a8-95eb-9fabcecc9c15,DISK], DatanodeInfoWithStorage[127.0.0.1:34992,DS-2f8fb36c-b85c-46c4-a023-936c64013a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-33e5c2d9-8c90-4478-9735-3fc8f21d763e,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-84a1dc67-5c80-4cdd-804a-f6a4197b0b58,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-dcb6c266-ac8e-44b1-9222-d71ed9e227c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-e79bed50-c551-4f30-9815-f7395100d299,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5835
