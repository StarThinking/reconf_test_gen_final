reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1685297901-172.17.0.3-1597508301612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38004,DS-bbe1be37-2e75-4de7-b98a-d51ac2fc484e,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-a9decd88-b165-4188-be56-c0a25e308d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-25057ce8-2298-4312-a846-cd8a042e06d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-98ff00e6-87ee-436b-88c0-2b0a710e0a77,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-310f7b47-3b5f-46e5-98b0-3ff7bc37b92f,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-467824e1-d5c2-4987-8219-f16fcb12f152,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-5caab5cb-90d2-4d9c-920b-f831d5076dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-ed24f447-aadb-4f50-8b2a-958253ef74f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1685297901-172.17.0.3-1597508301612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38004,DS-bbe1be37-2e75-4de7-b98a-d51ac2fc484e,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-a9decd88-b165-4188-be56-c0a25e308d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-25057ce8-2298-4312-a846-cd8a042e06d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-98ff00e6-87ee-436b-88c0-2b0a710e0a77,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-310f7b47-3b5f-46e5-98b0-3ff7bc37b92f,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-467824e1-d5c2-4987-8219-f16fcb12f152,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-5caab5cb-90d2-4d9c-920b-f831d5076dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-ed24f447-aadb-4f50-8b2a-958253ef74f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155434697-172.17.0.3-1597508852404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37587,DS-3fb2f5ce-b1d5-4277-b4e2-343d9daa12a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-3d016221-56a2-4084-b8af-74147646f6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-b8c203d1-37e2-431e-a26a-d6fef6e39be3,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-427d224d-02c8-435e-b3e8-729bc56f8d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-7d931108-d5cb-4e9e-b22d-f913d60d1cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-a3eb2ae0-18e0-4f53-91ee-60d7f1f00796,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-9bff9ab7-0cbb-43fc-81ab-ee57bc5d03d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-16bc9954-b9bc-4a3c-89f3-7bc6d1816827,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155434697-172.17.0.3-1597508852404:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37587,DS-3fb2f5ce-b1d5-4277-b4e2-343d9daa12a4,DISK], DatanodeInfoWithStorage[127.0.0.1:42339,DS-3d016221-56a2-4084-b8af-74147646f6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-b8c203d1-37e2-431e-a26a-d6fef6e39be3,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-427d224d-02c8-435e-b3e8-729bc56f8d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-7d931108-d5cb-4e9e-b22d-f913d60d1cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41490,DS-a3eb2ae0-18e0-4f53-91ee-60d7f1f00796,DISK], DatanodeInfoWithStorage[127.0.0.1:39186,DS-9bff9ab7-0cbb-43fc-81ab-ee57bc5d03d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-16bc9954-b9bc-4a3c-89f3-7bc6d1816827,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647996065-172.17.0.3-1597508987944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40729,DS-e78a857a-adfd-4738-87b0-ec3b6d51d6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-cb63916c-ec31-4bb9-bf38-8f865e40aa37,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-34e10904-cc06-4634-93e3-ef63affb9d70,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-0efe42bc-0325-4136-86c1-2ea0ffde02f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-6287f982-79b0-4bce-b361-4b58358b13a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-68957bfa-7d3b-45d0-9177-4c4ed7808ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-5bc9ab09-6f90-4e02-a779-3448c2f881f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-0cd45b13-5000-430f-82a4-23ef4feea33c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1647996065-172.17.0.3-1597508987944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40729,DS-e78a857a-adfd-4738-87b0-ec3b6d51d6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39217,DS-cb63916c-ec31-4bb9-bf38-8f865e40aa37,DISK], DatanodeInfoWithStorage[127.0.0.1:34856,DS-34e10904-cc06-4634-93e3-ef63affb9d70,DISK], DatanodeInfoWithStorage[127.0.0.1:35072,DS-0efe42bc-0325-4136-86c1-2ea0ffde02f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-6287f982-79b0-4bce-b361-4b58358b13a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-68957bfa-7d3b-45d0-9177-4c4ed7808ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:42229,DS-5bc9ab09-6f90-4e02-a779-3448c2f881f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-0cd45b13-5000-430f-82a4-23ef4feea33c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-125100516-172.17.0.3-1597509784430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34578,DS-b72bbb86-3e31-4686-9a4e-ce84f278e9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-6524266d-2eec-4096-a705-0036e92b9005,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-0faa3308-46c3-4156-9c9a-f8b3a5ac37b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-b2c99f9e-4d00-4585-82e1-3ba3ebf84ece,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-a3021c83-e7ee-4e83-bdc0-ef2d1ea35278,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-9b57a07b-a5ab-4c4f-8097-99d2e0fc3620,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-40b86269-3791-4449-acd9-82a1c78258cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-bfc90b73-fef5-45fd-840e-c641c332d388,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-125100516-172.17.0.3-1597509784430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34578,DS-b72bbb86-3e31-4686-9a4e-ce84f278e9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-6524266d-2eec-4096-a705-0036e92b9005,DISK], DatanodeInfoWithStorage[127.0.0.1:43523,DS-0faa3308-46c3-4156-9c9a-f8b3a5ac37b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-b2c99f9e-4d00-4585-82e1-3ba3ebf84ece,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-a3021c83-e7ee-4e83-bdc0-ef2d1ea35278,DISK], DatanodeInfoWithStorage[127.0.0.1:39107,DS-9b57a07b-a5ab-4c4f-8097-99d2e0fc3620,DISK], DatanodeInfoWithStorage[127.0.0.1:37655,DS-40b86269-3791-4449-acd9-82a1c78258cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-bfc90b73-fef5-45fd-840e-c641c332d388,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846036384-172.17.0.3-1597511440657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37086,DS-5465f6e3-995f-4706-b0fc-fe051dbeb323,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-ebe09031-6df8-468a-a3d6-fa381fa16c73,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-d445307e-3383-4c05-aaf7-ca0acee56058,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-90071cca-1916-4e29-9d94-df6ac60116f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-f3a25084-de7a-425e-936e-d7a510c3175c,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-2a64000d-533a-4b1d-b4b3-af72fe8c148a,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-093096b2-3a26-417f-b193-771109813f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-2ceb5ff1-e621-4dbc-b04f-654c74705f7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846036384-172.17.0.3-1597511440657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37086,DS-5465f6e3-995f-4706-b0fc-fe051dbeb323,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-ebe09031-6df8-468a-a3d6-fa381fa16c73,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-d445307e-3383-4c05-aaf7-ca0acee56058,DISK], DatanodeInfoWithStorage[127.0.0.1:40210,DS-90071cca-1916-4e29-9d94-df6ac60116f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-f3a25084-de7a-425e-936e-d7a510c3175c,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-2a64000d-533a-4b1d-b4b3-af72fe8c148a,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-093096b2-3a26-417f-b193-771109813f7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41185,DS-2ceb5ff1-e621-4dbc-b04f-654c74705f7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-637632239-172.17.0.3-1597511597373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35275,DS-9dcd15d6-0c79-4fb1-b77f-22e76b0e063d,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-9f9e77c9-500a-4b64-bb9d-f76498cf19d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-ee942496-bad1-4fc6-bca2-da40a8e6218d,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-c4e2dd75-381d-4eb8-95c5-f41aec6b6355,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-cc180429-ad9d-45b4-82be-a81f40ead15e,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-c4ab9d54-efb4-4635-9dbe-3e55bb80bc90,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-f249babd-78ec-48f4-a3a9-be33bfa0066c,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-ea0cbf9f-6e46-4c26-9dff-7ca0fda60dd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-637632239-172.17.0.3-1597511597373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35275,DS-9dcd15d6-0c79-4fb1-b77f-22e76b0e063d,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-9f9e77c9-500a-4b64-bb9d-f76498cf19d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-ee942496-bad1-4fc6-bca2-da40a8e6218d,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-c4e2dd75-381d-4eb8-95c5-f41aec6b6355,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-cc180429-ad9d-45b4-82be-a81f40ead15e,DISK], DatanodeInfoWithStorage[127.0.0.1:40571,DS-c4ab9d54-efb4-4635-9dbe-3e55bb80bc90,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-f249babd-78ec-48f4-a3a9-be33bfa0066c,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-ea0cbf9f-6e46-4c26-9dff-7ca0fda60dd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85455671-172.17.0.3-1597512171862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41838,DS-7a0a5c46-d1af-429b-a57f-7e57b7e54566,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-f8a3bfcc-0adb-436f-be5a-8d0cc3f8de36,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-3269920a-e431-45a4-9066-eebbb0a72725,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-1c6356cd-b42f-4ce6-a18b-3702a0e82ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-0afbbde4-5f43-439c-acae-8e305a97b5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-aa1d59e5-8070-42d6-9c21-ae93073eaf8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-aa05fb5b-a4ad-404e-a2aa-c59584e36b30,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-9223ccfc-a4a1-4f0d-8700-983f8dd3f68e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-85455671-172.17.0.3-1597512171862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41838,DS-7a0a5c46-d1af-429b-a57f-7e57b7e54566,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-f8a3bfcc-0adb-436f-be5a-8d0cc3f8de36,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-3269920a-e431-45a4-9066-eebbb0a72725,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-1c6356cd-b42f-4ce6-a18b-3702a0e82ce6,DISK], DatanodeInfoWithStorage[127.0.0.1:44694,DS-0afbbde4-5f43-439c-acae-8e305a97b5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-aa1d59e5-8070-42d6-9c21-ae93073eaf8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-aa05fb5b-a4ad-404e-a2aa-c59584e36b30,DISK], DatanodeInfoWithStorage[127.0.0.1:37050,DS-9223ccfc-a4a1-4f0d-8700-983f8dd3f68e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921814175-172.17.0.3-1597513038677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45842,DS-8c9e1513-6870-442c-a52b-3e15bfbdda46,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-f0c48cdd-68eb-4dd8-a7b3-7e72b505b46f,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-3c83b0ec-02f1-41e2-9270-327459b48847,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-36030bcb-6efd-4340-91f9-ac0205344cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-f97cf04f-85b1-470a-978e-b4f41c26fc30,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-dacd2b39-d568-4084-b229-7bc9e0d1e651,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-0a803734-ba34-40fa-894f-527c32c881c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-adb7a97c-4505-4a45-8e10-c701d5ea82d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-921814175-172.17.0.3-1597513038677:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45842,DS-8c9e1513-6870-442c-a52b-3e15bfbdda46,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-f0c48cdd-68eb-4dd8-a7b3-7e72b505b46f,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-3c83b0ec-02f1-41e2-9270-327459b48847,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-36030bcb-6efd-4340-91f9-ac0205344cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-f97cf04f-85b1-470a-978e-b4f41c26fc30,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-dacd2b39-d568-4084-b229-7bc9e0d1e651,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-0a803734-ba34-40fa-894f-527c32c881c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-adb7a97c-4505-4a45-8e10-c701d5ea82d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1840973636-172.17.0.3-1597513287501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39698,DS-52eaa81a-a29c-4b8c-b3fc-b3563ab88ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-79ee0474-62d2-47e7-94c8-98ed830d5ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-fce2e858-b711-4753-ab71-13cf76ccbe25,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-3fe8b0c4-c0e2-454d-8b12-b00dcf857adb,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-966d9000-7ba5-4d6b-a217-35c998f89531,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-0a126e21-0afc-4b5a-97b9-fc24a0a6c2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-aeb53f06-96db-4c30-848c-76b7109e68d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-37ffaa90-32f2-4666-9eb6-503cb041d911,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1840973636-172.17.0.3-1597513287501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39698,DS-52eaa81a-a29c-4b8c-b3fc-b3563ab88ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-79ee0474-62d2-47e7-94c8-98ed830d5ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:40200,DS-fce2e858-b711-4753-ab71-13cf76ccbe25,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-3fe8b0c4-c0e2-454d-8b12-b00dcf857adb,DISK], DatanodeInfoWithStorage[127.0.0.1:43447,DS-966d9000-7ba5-4d6b-a217-35c998f89531,DISK], DatanodeInfoWithStorage[127.0.0.1:38924,DS-0a126e21-0afc-4b5a-97b9-fc24a0a6c2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-aeb53f06-96db-4c30-848c-76b7109e68d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-37ffaa90-32f2-4666-9eb6-503cb041d911,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1754190568-172.17.0.3-1597513407870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34840,DS-c06c1550-7276-47b5-861c-3f889d153a06,DISK], DatanodeInfoWithStorage[127.0.0.1:41055,DS-6c7aff4e-1b1a-4600-af6a-b003f84257b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-a9845244-8953-4080-be75-71ca79d3c24f,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-2af590ad-8940-43ae-8885-2e67ebab6840,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-42eecf33-8a8e-408d-8e29-b85d92344ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-e1433481-5ee9-48fa-8cf3-725f98420ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-fca209a8-7751-4dfb-9d7f-871bd9223503,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-fd6eee03-af94-4e13-aa15-a07a2dd77cbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1754190568-172.17.0.3-1597513407870:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34840,DS-c06c1550-7276-47b5-861c-3f889d153a06,DISK], DatanodeInfoWithStorage[127.0.0.1:41055,DS-6c7aff4e-1b1a-4600-af6a-b003f84257b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-a9845244-8953-4080-be75-71ca79d3c24f,DISK], DatanodeInfoWithStorage[127.0.0.1:36989,DS-2af590ad-8940-43ae-8885-2e67ebab6840,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-42eecf33-8a8e-408d-8e29-b85d92344ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-e1433481-5ee9-48fa-8cf3-725f98420ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-fca209a8-7751-4dfb-9d7f-871bd9223503,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-fd6eee03-af94-4e13-aa15-a07a2dd77cbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-799625691-172.17.0.3-1597513593902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42694,DS-9a2b89a4-dd10-4eb7-9551-adb9cc10c553,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-4bb78036-4475-48dd-8e7a-cd0c40f5fa81,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-78329196-2a77-4eb9-b9cd-beafa3aa1b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-f3655f0e-0627-4a1a-acfe-f6543b68be98,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-9b14433d-e1ea-4e55-a0fe-cc37030fddb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-331043da-5973-461b-9f57-8dd77d43191f,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-8db5906a-9656-46eb-a39d-6700bf40bf8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-b57c4a39-73ae-4b16-a9fc-6bf2f877c97e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-799625691-172.17.0.3-1597513593902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42694,DS-9a2b89a4-dd10-4eb7-9551-adb9cc10c553,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-4bb78036-4475-48dd-8e7a-cd0c40f5fa81,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-78329196-2a77-4eb9-b9cd-beafa3aa1b4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-f3655f0e-0627-4a1a-acfe-f6543b68be98,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-9b14433d-e1ea-4e55-a0fe-cc37030fddb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42361,DS-331043da-5973-461b-9f57-8dd77d43191f,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-8db5906a-9656-46eb-a39d-6700bf40bf8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46314,DS-b57c4a39-73ae-4b16-a9fc-6bf2f877c97e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-277464420-172.17.0.3-1597513879603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36176,DS-9b4d1119-b8fa-4b99-862d-0ed9309130da,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-352a1f4b-2cb3-4003-aa98-7fc057c7ed8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-abc3f928-150f-4967-bcf1-d84493bc787d,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-b02895ca-44a3-41cb-a054-c061e65c38ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-0958148b-c099-4fda-a19a-68162cebb7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-cd0a279e-05b1-4329-9d20-26acc1a36511,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-9c4d5b6e-093e-47b1-a272-c88075025391,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-f91fbe85-5ba1-4f44-b9a6-b40b920540f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-277464420-172.17.0.3-1597513879603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36176,DS-9b4d1119-b8fa-4b99-862d-0ed9309130da,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-352a1f4b-2cb3-4003-aa98-7fc057c7ed8a,DISK], DatanodeInfoWithStorage[127.0.0.1:45978,DS-abc3f928-150f-4967-bcf1-d84493bc787d,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-b02895ca-44a3-41cb-a054-c061e65c38ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43202,DS-0958148b-c099-4fda-a19a-68162cebb7f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-cd0a279e-05b1-4329-9d20-26acc1a36511,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-9c4d5b6e-093e-47b1-a272-c88075025391,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-f91fbe85-5ba1-4f44-b9a6-b40b920540f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.slow.io.warning.threshold.ms
component: hdfs:DataNode
v1: 300
v2: 3
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1381542808-172.17.0.3-1597513997278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35519,DS-eb7915da-6598-434f-a14b-c77cf373bbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-9efb6b36-6c22-4fdf-962a-3cbe97a493e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-6839c5c7-1c00-420e-99ed-0646e2fa5c47,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-169f176c-fcd2-4ba4-b1d4-eae7f05758c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-4982a212-08bd-4185-891d-8aaa9de02a28,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-2a3bf17b-c614-4483-a00b-ada16c85d7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-c518f6a7-72aa-4b21-90c7-589a8dfc34b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-d4b2e817-dd2b-42a6-b5e9-126ee83a86bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1381542808-172.17.0.3-1597513997278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35519,DS-eb7915da-6598-434f-a14b-c77cf373bbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-9efb6b36-6c22-4fdf-962a-3cbe97a493e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-6839c5c7-1c00-420e-99ed-0646e2fa5c47,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-169f176c-fcd2-4ba4-b1d4-eae7f05758c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33087,DS-4982a212-08bd-4185-891d-8aaa9de02a28,DISK], DatanodeInfoWithStorage[127.0.0.1:43257,DS-2a3bf17b-c614-4483-a00b-ada16c85d7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-c518f6a7-72aa-4b21-90c7-589a8dfc34b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43922,DS-d4b2e817-dd2b-42a6-b5e9-126ee83a86bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5860
