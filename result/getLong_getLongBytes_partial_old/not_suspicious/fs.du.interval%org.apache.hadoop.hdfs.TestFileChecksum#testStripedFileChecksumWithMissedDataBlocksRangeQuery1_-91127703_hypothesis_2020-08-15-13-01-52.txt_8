reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951872565-172.17.0.14-1597496971538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34751,DS-99b67bb2-9280-428e-8e8c-da97e5adec7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-1e6e0215-6506-4f8d-9c80-53914712c952,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-73aee409-9da3-4961-a363-b71b7df361bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-0b4054d1-47de-4cbc-9b99-1e99563d2238,DISK], DatanodeInfoWithStorage[127.0.0.1:35891,DS-97c16c87-5a4e-4db2-9244-16418e392e42,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-ed1ba082-4a35-4b8f-ad2c-987549d55001,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-2582d11f-0b1b-4a8d-ad78-f411a1f53e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-ffd527c1-6679-49ae-bfbb-161d92236024,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-951872565-172.17.0.14-1597496971538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34751,DS-99b67bb2-9280-428e-8e8c-da97e5adec7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-1e6e0215-6506-4f8d-9c80-53914712c952,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-73aee409-9da3-4961-a363-b71b7df361bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34503,DS-0b4054d1-47de-4cbc-9b99-1e99563d2238,DISK], DatanodeInfoWithStorage[127.0.0.1:35891,DS-97c16c87-5a4e-4db2-9244-16418e392e42,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-ed1ba082-4a35-4b8f-ad2c-987549d55001,DISK], DatanodeInfoWithStorage[127.0.0.1:40013,DS-2582d11f-0b1b-4a8d-ad78-f411a1f53e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-ffd527c1-6679-49ae-bfbb-161d92236024,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388299065-172.17.0.14-1597497465350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46756,DS-90f4f032-1a8b-4934-b21a-f03dd3a87799,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-73bd3fdc-42eb-42d2-a929-a78f8d1336d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-c0c89633-dca6-493b-8ce9-7071e5eed044,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-b8b12c27-f865-41da-9c49-8be49abf5ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-b1ba8afc-5b51-462d-b0d6-f7f16e2fcf13,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-c7dd1297-4989-44a9-9afa-4b05e3af7548,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-a8fad760-21a9-433b-a820-b129dde91934,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-38a7b723-4161-4755-af3f-114df01d2f75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388299065-172.17.0.14-1597497465350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46756,DS-90f4f032-1a8b-4934-b21a-f03dd3a87799,DISK], DatanodeInfoWithStorage[127.0.0.1:40114,DS-73bd3fdc-42eb-42d2-a929-a78f8d1336d8,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-c0c89633-dca6-493b-8ce9-7071e5eed044,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-b8b12c27-f865-41da-9c49-8be49abf5ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-b1ba8afc-5b51-462d-b0d6-f7f16e2fcf13,DISK], DatanodeInfoWithStorage[127.0.0.1:38039,DS-c7dd1297-4989-44a9-9afa-4b05e3af7548,DISK], DatanodeInfoWithStorage[127.0.0.1:41137,DS-a8fad760-21a9-433b-a820-b129dde91934,DISK], DatanodeInfoWithStorage[127.0.0.1:40666,DS-38a7b723-4161-4755-af3f-114df01d2f75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553013030-172.17.0.14-1597497613117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37866,DS-5063d0c4-5387-42bc-8e90-0f8fcd604701,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-6929b4e5-6d65-42c6-87fc-3780a2de4dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-6afe15ef-8787-489a-8227-b01cc5c83517,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-80e84a02-96f4-4bb8-bf51-8d81b7f6450a,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-85b96a5c-1748-4bf6-954a-9a6899118f93,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-f95294fd-b3d0-4217-bcb3-12b344b262ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-47b8e428-059d-4d69-9239-3260518ac186,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-500406f3-98a7-4b83-9b8c-96617e9ba45d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553013030-172.17.0.14-1597497613117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37866,DS-5063d0c4-5387-42bc-8e90-0f8fcd604701,DISK], DatanodeInfoWithStorage[127.0.0.1:36261,DS-6929b4e5-6d65-42c6-87fc-3780a2de4dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40263,DS-6afe15ef-8787-489a-8227-b01cc5c83517,DISK], DatanodeInfoWithStorage[127.0.0.1:33598,DS-80e84a02-96f4-4bb8-bf51-8d81b7f6450a,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-85b96a5c-1748-4bf6-954a-9a6899118f93,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-f95294fd-b3d0-4217-bcb3-12b344b262ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-47b8e428-059d-4d69-9239-3260518ac186,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-500406f3-98a7-4b83-9b8c-96617e9ba45d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-236334667-172.17.0.14-1597498374967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40207,DS-344d6622-baa9-4132-b436-facce1972900,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-4e8edcdd-d4ee-41b0-baec-08c6d68a4518,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-88b71784-83fc-4018-acd0-2d2a90090e03,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-47c54587-78e7-44d1-917d-d8375353614b,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-53cd5eb8-a0cd-4041-bb03-b69246317f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-902d3f83-aa2c-4112-8ccf-316b1b6120b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-965c0819-9279-4dd1-9bab-dc4c7563641c,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-d91fc0c0-402e-49c0-9457-028c034c2aa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-236334667-172.17.0.14-1597498374967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40207,DS-344d6622-baa9-4132-b436-facce1972900,DISK], DatanodeInfoWithStorage[127.0.0.1:43600,DS-4e8edcdd-d4ee-41b0-baec-08c6d68a4518,DISK], DatanodeInfoWithStorage[127.0.0.1:35752,DS-88b71784-83fc-4018-acd0-2d2a90090e03,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-47c54587-78e7-44d1-917d-d8375353614b,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-53cd5eb8-a0cd-4041-bb03-b69246317f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-902d3f83-aa2c-4112-8ccf-316b1b6120b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39726,DS-965c0819-9279-4dd1-9bab-dc4c7563641c,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-d91fc0c0-402e-49c0-9457-028c034c2aa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-406511276-172.17.0.14-1597498632173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41782,DS-9fdc1fa8-10ac-45a5-affd-9bee55085af8,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-dc68ee69-6b43-4986-8ab6-adf5bd7dce8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-2eb979dc-4852-433e-aa21-ca3acd08d269,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-3a7a4af8-03af-4c38-9a98-a8fc3bf34019,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-ac5448ab-bd2a-45e2-8200-9ffc339f0087,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-e6f8277a-783f-4b79-afc4-9ac7bb195f83,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-94a3ad9d-8abd-4c38-a6bd-61ba09a7d62d,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-bb0ad8d4-a741-4967-8784-3bf3e84439e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-406511276-172.17.0.14-1597498632173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41782,DS-9fdc1fa8-10ac-45a5-affd-9bee55085af8,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-dc68ee69-6b43-4986-8ab6-adf5bd7dce8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-2eb979dc-4852-433e-aa21-ca3acd08d269,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-3a7a4af8-03af-4c38-9a98-a8fc3bf34019,DISK], DatanodeInfoWithStorage[127.0.0.1:44957,DS-ac5448ab-bd2a-45e2-8200-9ffc339f0087,DISK], DatanodeInfoWithStorage[127.0.0.1:33140,DS-e6f8277a-783f-4b79-afc4-9ac7bb195f83,DISK], DatanodeInfoWithStorage[127.0.0.1:33901,DS-94a3ad9d-8abd-4c38-a6bd-61ba09a7d62d,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-bb0ad8d4-a741-4967-8784-3bf3e84439e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1462360245-172.17.0.14-1597498757197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41745,DS-df783153-51ba-4c96-8664-746ba3fa931c,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-c6464f7a-fdd2-4941-b9ff-9281a06cec33,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-ca229172-9431-404b-89c0-d532ad9ae0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-a0814145-83be-436e-b1ae-76ca2a05944e,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-d2ca1341-cb41-4f61-825f-d966c38d7325,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-2f1e3312-2e91-495c-b86e-fba2bc6f9408,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-e3135f21-5ebe-4b42-b1c1-85fa5e9b200c,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-ce278f0e-ed0d-4ad1-bc77-c2c95e3c9b03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1462360245-172.17.0.14-1597498757197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41745,DS-df783153-51ba-4c96-8664-746ba3fa931c,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-c6464f7a-fdd2-4941-b9ff-9281a06cec33,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-ca229172-9431-404b-89c0-d532ad9ae0e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-a0814145-83be-436e-b1ae-76ca2a05944e,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-d2ca1341-cb41-4f61-825f-d966c38d7325,DISK], DatanodeInfoWithStorage[127.0.0.1:37091,DS-2f1e3312-2e91-495c-b86e-fba2bc6f9408,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-e3135f21-5ebe-4b42-b1c1-85fa5e9b200c,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-ce278f0e-ed0d-4ad1-bc77-c2c95e3c9b03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1570289914-172.17.0.14-1597499584054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37201,DS-fe2dd49c-2697-42b4-9ce8-5e6e1d4f9419,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-758ea8b3-7270-4c76-a13d-b915ee50ba0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-9af3c43b-80af-4bde-96f1-d2a23c4632f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-d5b6102d-ce13-4a22-962e-a2fe35961cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-3c2f5382-bf3b-4b2a-b4ce-9003c8d847fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-ab3b6940-a0b4-4057-b924-3c1dc953599f,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-c83606e7-f9ed-409d-8c38-6968e8f7f5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-ab2bc052-2491-42bf-badf-aeb6f356306a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1570289914-172.17.0.14-1597499584054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37201,DS-fe2dd49c-2697-42b4-9ce8-5e6e1d4f9419,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-758ea8b3-7270-4c76-a13d-b915ee50ba0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37823,DS-9af3c43b-80af-4bde-96f1-d2a23c4632f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-d5b6102d-ce13-4a22-962e-a2fe35961cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-3c2f5382-bf3b-4b2a-b4ce-9003c8d847fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-ab3b6940-a0b4-4057-b924-3c1dc953599f,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-c83606e7-f9ed-409d-8c38-6968e8f7f5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-ab2bc052-2491-42bf-badf-aeb6f356306a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1947417127-172.17.0.14-1597499665054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37135,DS-9bfec808-253b-4fb8-ab18-76bd4f6cae90,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-59da03cb-ab78-4008-b75f-30359a61a8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-7330a368-8aa7-47e6-8fba-ef703168efcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-56542051-d745-4705-bb88-e42c7a662188,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-ee1956d9-4d5a-4fcc-8ff8-46d396965c83,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-250eacdd-d566-4c4d-8b8b-7882cf016f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-ed336a64-acf0-44c2-a93f-da4aa0b5eea3,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-5b2ef9b5-e283-4292-9e6f-9aa0e2bde303,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1947417127-172.17.0.14-1597499665054:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37135,DS-9bfec808-253b-4fb8-ab18-76bd4f6cae90,DISK], DatanodeInfoWithStorage[127.0.0.1:39986,DS-59da03cb-ab78-4008-b75f-30359a61a8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-7330a368-8aa7-47e6-8fba-ef703168efcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-56542051-d745-4705-bb88-e42c7a662188,DISK], DatanodeInfoWithStorage[127.0.0.1:35058,DS-ee1956d9-4d5a-4fcc-8ff8-46d396965c83,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-250eacdd-d566-4c4d-8b8b-7882cf016f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-ed336a64-acf0-44c2-a93f-da4aa0b5eea3,DISK], DatanodeInfoWithStorage[127.0.0.1:42632,DS-5b2ef9b5-e283-4292-9e6f-9aa0e2bde303,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-90551890-172.17.0.14-1597500058968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37330,DS-363b6279-0afc-4d4e-9f72-1f54192ddfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-7c9954e4-8172-496e-82cd-3959f8ba7fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-5780f8d3-18c9-4863-8233-2da9dfd42adf,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-663bc5f4-868a-4d44-abe2-7fa836678206,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-8cfb07a9-8dd9-4f4b-8b91-e9880a5d72e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-a78d604e-c761-4379-8fa8-d10c197226a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-1a0c6826-1c71-466f-ace5-7d9b91d016a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-463e55e0-1f33-4cfd-8009-89569c9f6e68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-90551890-172.17.0.14-1597500058968:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37330,DS-363b6279-0afc-4d4e-9f72-1f54192ddfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-7c9954e4-8172-496e-82cd-3959f8ba7fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-5780f8d3-18c9-4863-8233-2da9dfd42adf,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-663bc5f4-868a-4d44-abe2-7fa836678206,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-8cfb07a9-8dd9-4f4b-8b91-e9880a5d72e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-a78d604e-c761-4379-8fa8-d10c197226a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40145,DS-1a0c6826-1c71-466f-ace5-7d9b91d016a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-463e55e0-1f33-4cfd-8009-89569c9f6e68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1291908137-172.17.0.14-1597500133102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38643,DS-84ef6574-bfe9-47c2-908f-2bcc61bc214a,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-acc2b919-57f0-49ba-aaa1-7814ca2c77a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-a31ea72a-f587-46c9-b51b-912e52a4cb39,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-ebf15896-65b7-40e0-afd3-be3fc58e06cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-396ec5b7-27ee-4e44-9b39-0e986d790faf,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-bb9d0121-be40-4d53-a8af-c3bd9df5a802,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-93610ab0-5671-4f1a-8972-037ca7a206c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-906f07f2-9f78-4839-acb1-3ef77ebcee4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1291908137-172.17.0.14-1597500133102:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38643,DS-84ef6574-bfe9-47c2-908f-2bcc61bc214a,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-acc2b919-57f0-49ba-aaa1-7814ca2c77a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45778,DS-a31ea72a-f587-46c9-b51b-912e52a4cb39,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-ebf15896-65b7-40e0-afd3-be3fc58e06cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-396ec5b7-27ee-4e44-9b39-0e986d790faf,DISK], DatanodeInfoWithStorage[127.0.0.1:35075,DS-bb9d0121-be40-4d53-a8af-c3bd9df5a802,DISK], DatanodeInfoWithStorage[127.0.0.1:32881,DS-93610ab0-5671-4f1a-8972-037ca7a206c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-906f07f2-9f78-4839-acb1-3ef77ebcee4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192192997-172.17.0.14-1597500248984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43672,DS-fc2bd3c2-1fc5-4b25-9842-2aa39284c5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-65b6ff12-b0bc-455c-b775-42bbb84cd131,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-1823b93c-86ae-4b75-afd8-36f0451b4d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-a41d6204-4465-43cc-8821-4f75814c2d41,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-f4624cd6-c5c7-49c3-b8e4-aaa4482486e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-12366023-d718-4f9a-bba4-78944194a8db,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-2b802a88-2c43-447c-8771-2ab6eb33a02a,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-e7775087-9ecc-4e68-89f4-982b9009e144,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192192997-172.17.0.14-1597500248984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43672,DS-fc2bd3c2-1fc5-4b25-9842-2aa39284c5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37767,DS-65b6ff12-b0bc-455c-b775-42bbb84cd131,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-1823b93c-86ae-4b75-afd8-36f0451b4d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-a41d6204-4465-43cc-8821-4f75814c2d41,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-f4624cd6-c5c7-49c3-b8e4-aaa4482486e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-12366023-d718-4f9a-bba4-78944194a8db,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-2b802a88-2c43-447c-8771-2ab6eb33a02a,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-e7775087-9ecc-4e68-89f4-982b9009e144,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1780985467-172.17.0.14-1597500501077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39520,DS-bbbb9ffb-901a-4cec-a415-30d21be2519a,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-f4d0c2b1-34f5-4763-a38a-5a863521973d,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-e6b7ab02-0536-4cdb-87e1-e10fbf309271,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-966ff1e9-f8d5-4b7d-a5d7-03fd2df96968,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-115c0990-5835-4ed7-8a2e-df254beb008c,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-02dd189e-e589-4dcd-aa1d-d91b84c190c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-2d35f7aa-793c-42b7-be4e-f0b68c25c378,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-2645fe46-7078-4b93-95a2-4420b0203245,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1780985467-172.17.0.14-1597500501077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39520,DS-bbbb9ffb-901a-4cec-a415-30d21be2519a,DISK], DatanodeInfoWithStorage[127.0.0.1:41289,DS-f4d0c2b1-34f5-4763-a38a-5a863521973d,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-e6b7ab02-0536-4cdb-87e1-e10fbf309271,DISK], DatanodeInfoWithStorage[127.0.0.1:45511,DS-966ff1e9-f8d5-4b7d-a5d7-03fd2df96968,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-115c0990-5835-4ed7-8a2e-df254beb008c,DISK], DatanodeInfoWithStorage[127.0.0.1:44848,DS-02dd189e-e589-4dcd-aa1d-d91b84c190c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-2d35f7aa-793c-42b7-be4e-f0b68c25c378,DISK], DatanodeInfoWithStorage[127.0.0.1:46726,DS-2645fe46-7078-4b93-95a2-4420b0203245,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486805745-172.17.0.14-1597500543049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41363,DS-f948ecb2-c670-4bdf-88b4-d68cc72511b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-7c7110e2-5e96-49e3-a1f8-ed9e571ee75e,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-bb422951-fa45-439e-a5eb-a2589ed4739e,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-4be73aff-2f5d-4229-930d-abe35910c9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-dc847da1-b839-43a5-ba00-17f17608f8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-7e072bb3-1447-4a57-a208-f7af86f80076,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-09a3b43b-821e-4465-931b-e3ec5d7a68b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-3e13bd65-2bb5-46fb-b9d9-6fc3b6c4d3d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486805745-172.17.0.14-1597500543049:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41363,DS-f948ecb2-c670-4bdf-88b4-d68cc72511b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-7c7110e2-5e96-49e3-a1f8-ed9e571ee75e,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-bb422951-fa45-439e-a5eb-a2589ed4739e,DISK], DatanodeInfoWithStorage[127.0.0.1:45473,DS-4be73aff-2f5d-4229-930d-abe35910c9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-dc847da1-b839-43a5-ba00-17f17608f8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-7e072bb3-1447-4a57-a208-f7af86f80076,DISK], DatanodeInfoWithStorage[127.0.0.1:35334,DS-09a3b43b-821e-4465-931b-e3ec5d7a68b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36647,DS-3e13bd65-2bb5-46fb-b9d9-6fc3b6c4d3d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1407196448-172.17.0.14-1597500625092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38660,DS-40107a53-bd02-4047-8a5b-9c5fd8021315,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-20771b80-2adb-48e5-8e94-c24221f1e694,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-26ee0140-6197-4288-8b69-32fbb97dff03,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-a451f650-c406-4d1a-bf5a-286305fb3643,DISK], DatanodeInfoWithStorage[127.0.0.1:36743,DS-0175b98a-3fc2-462f-9dce-c296e19d0748,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-2dc3a46f-a4b4-4e45-b4fc-978498022721,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-cc1aad38-d3a5-403c-8d30-a2cb78425d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-f6d3b4e9-41b7-4f5d-9669-eb5726271088,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1407196448-172.17.0.14-1597500625092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38660,DS-40107a53-bd02-4047-8a5b-9c5fd8021315,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-20771b80-2adb-48e5-8e94-c24221f1e694,DISK], DatanodeInfoWithStorage[127.0.0.1:38598,DS-26ee0140-6197-4288-8b69-32fbb97dff03,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-a451f650-c406-4d1a-bf5a-286305fb3643,DISK], DatanodeInfoWithStorage[127.0.0.1:36743,DS-0175b98a-3fc2-462f-9dce-c296e19d0748,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-2dc3a46f-a4b4-4e45-b4fc-978498022721,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-cc1aad38-d3a5-403c-8d30-a2cb78425d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37738,DS-f6d3b4e9-41b7-4f5d-9669-eb5726271088,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587097147-172.17.0.14-1597500968697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37016,DS-e5d98380-1107-43c1-a10e-d7b20cdfc34e,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-72333646-175f-46b3-8871-0a494bc05c21,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-ac5e23b7-b139-4767-9017-c94521fbde52,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-60f39449-3375-46ef-8b1c-a7aaa081f104,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-335c5c03-f832-43e3-98aa-e6cb3837fb97,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-5e45bb28-8c84-411b-be26-5d12a584076b,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-9159a74a-82dd-42e4-8e5f-e0b89a349ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-a13917f4-10a9-4488-9464-db5de00ef3c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587097147-172.17.0.14-1597500968697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37016,DS-e5d98380-1107-43c1-a10e-d7b20cdfc34e,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-72333646-175f-46b3-8871-0a494bc05c21,DISK], DatanodeInfoWithStorage[127.0.0.1:46126,DS-ac5e23b7-b139-4767-9017-c94521fbde52,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-60f39449-3375-46ef-8b1c-a7aaa081f104,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-335c5c03-f832-43e3-98aa-e6cb3837fb97,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-5e45bb28-8c84-411b-be26-5d12a584076b,DISK], DatanodeInfoWithStorage[127.0.0.1:39908,DS-9159a74a-82dd-42e4-8e5f-e0b89a349ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-a13917f4-10a9-4488-9464-db5de00ef3c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-604386381-172.17.0.14-1597501270367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33722,DS-6e30990d-e5b8-42a3-9f5a-04b1a73f7ade,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-0c61fd22-b00a-4e85-ac34-b9d043f471f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-1eeacf8d-855a-439a-afaa-0f3aad3da3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-03478fef-284c-4373-bceb-b814acaaa9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-ad33a3d6-ab21-46d9-81dc-3a14b8656aac,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-0d827bd2-7b69-4219-8d7a-9b8414bb627b,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-4a37d539-2180-4016-8937-c9c5456d3302,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-9eea476e-4bdd-4871-a2d7-0b0833ede092,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-604386381-172.17.0.14-1597501270367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33722,DS-6e30990d-e5b8-42a3-9f5a-04b1a73f7ade,DISK], DatanodeInfoWithStorage[127.0.0.1:44953,DS-0c61fd22-b00a-4e85-ac34-b9d043f471f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34374,DS-1eeacf8d-855a-439a-afaa-0f3aad3da3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-03478fef-284c-4373-bceb-b814acaaa9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-ad33a3d6-ab21-46d9-81dc-3a14b8656aac,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-0d827bd2-7b69-4219-8d7a-9b8414bb627b,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-4a37d539-2180-4016-8937-c9c5456d3302,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-9eea476e-4bdd-4871-a2d7-0b0833ede092,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319546331-172.17.0.14-1597501462640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43237,DS-8f93f386-92e5-4b11-a2f6-bf5d8028f9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-e9f9a0ff-5dc9-4dff-8f11-105043d09d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-8ff1475a-681b-4152-b723-d486703db3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-a5920c7e-0c77-469d-a2d3-36a17d3222aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-795051bd-827e-4f86-8c5f-701705007da1,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-ed8bf7d6-6a90-480a-a060-2221aa5952f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-40cd9b05-ccac-4b7e-a4e9-d55422bae437,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-660c1c09-85b6-431d-b31f-44fccc0b8cac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319546331-172.17.0.14-1597501462640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43237,DS-8f93f386-92e5-4b11-a2f6-bf5d8028f9f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41562,DS-e9f9a0ff-5dc9-4dff-8f11-105043d09d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:37032,DS-8ff1475a-681b-4152-b723-d486703db3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-a5920c7e-0c77-469d-a2d3-36a17d3222aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-795051bd-827e-4f86-8c5f-701705007da1,DISK], DatanodeInfoWithStorage[127.0.0.1:44996,DS-ed8bf7d6-6a90-480a-a060-2221aa5952f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43047,DS-40cd9b05-ccac-4b7e-a4e9-d55422bae437,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-660c1c09-85b6-431d-b31f-44fccc0b8cac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603229828-172.17.0.14-1597501686285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46849,DS-9f0f95f9-f15e-47bf-a062-1a649ad5205e,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-12a26c71-bb6b-497d-9142-cf3a9a2303f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-256c9336-d329-4505-809c-10f55134f91a,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-4b56a551-6042-44b3-8730-ce88c89dc261,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-7def710d-5a8a-427f-bb00-7631a526919f,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-1603c4cf-0b09-415a-80dc-c66c724864ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-b3a8ef0d-3b10-48bc-9e01-798be613ac04,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-a28daaa8-2811-40fe-973d-74a584e1bf71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603229828-172.17.0.14-1597501686285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46849,DS-9f0f95f9-f15e-47bf-a062-1a649ad5205e,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-12a26c71-bb6b-497d-9142-cf3a9a2303f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-256c9336-d329-4505-809c-10f55134f91a,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-4b56a551-6042-44b3-8730-ce88c89dc261,DISK], DatanodeInfoWithStorage[127.0.0.1:45710,DS-7def710d-5a8a-427f-bb00-7631a526919f,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-1603c4cf-0b09-415a-80dc-c66c724864ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39779,DS-b3a8ef0d-3b10-48bc-9e01-798be613ac04,DISK], DatanodeInfoWithStorage[127.0.0.1:45915,DS-a28daaa8-2811-40fe-973d-74a584e1bf71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739306393-172.17.0.14-1597501924764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41358,DS-73e46b42-567d-4ebd-92c8-7b4f417d4c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-2b5ab274-13c7-425f-b824-6712d1dabea1,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-13df5f5e-54c0-43e3-bb0b-fa441f2eb54c,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-d43bed3a-8670-4215-b8f8-afc9d413916a,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-4aec054e-f405-4382-8587-84abd098f4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-9c5bffc1-a673-4084-9d91-6c25d7649328,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-a3d36da1-d4e8-4207-8632-60fab12ac24e,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-162a9d5c-469f-42b8-a190-82a4a35240ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1739306393-172.17.0.14-1597501924764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41358,DS-73e46b42-567d-4ebd-92c8-7b4f417d4c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-2b5ab274-13c7-425f-b824-6712d1dabea1,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-13df5f5e-54c0-43e3-bb0b-fa441f2eb54c,DISK], DatanodeInfoWithStorage[127.0.0.1:39527,DS-d43bed3a-8670-4215-b8f8-afc9d413916a,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-4aec054e-f405-4382-8587-84abd098f4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39422,DS-9c5bffc1-a673-4084-9d91-6c25d7649328,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-a3d36da1-d4e8-4207-8632-60fab12ac24e,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-162a9d5c-469f-42b8-a190-82a4a35240ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 600000
v2: 70000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1725342455-172.17.0.14-1597501969599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42783,DS-9ffd3076-b549-4b00-8cd1-643c1628f114,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-94cde45d-b90d-42e8-90ec-8ad0dc728ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-5124ea65-c7f2-4ce8-b1b0-2b4249b65838,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-bf36ccda-04c8-49b8-9ca5-d1de7f372b01,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-2ded11b5-87eb-4987-869f-1d17c3768d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-ae733697-db12-40de-94d8-030595d82db6,DISK], DatanodeInfoWithStorage[127.0.0.1:35505,DS-1696e347-eea6-41ea-922b-6548a4727a29,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-d3f9c890-cdfa-4d68-ab97-ef6098906216,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1725342455-172.17.0.14-1597501969599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42783,DS-9ffd3076-b549-4b00-8cd1-643c1628f114,DISK], DatanodeInfoWithStorage[127.0.0.1:39699,DS-94cde45d-b90d-42e8-90ec-8ad0dc728ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-5124ea65-c7f2-4ce8-b1b0-2b4249b65838,DISK], DatanodeInfoWithStorage[127.0.0.1:45279,DS-bf36ccda-04c8-49b8-9ca5-d1de7f372b01,DISK], DatanodeInfoWithStorage[127.0.0.1:42501,DS-2ded11b5-87eb-4987-869f-1d17c3768d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-ae733697-db12-40de-94d8-030595d82db6,DISK], DatanodeInfoWithStorage[127.0.0.1:35505,DS-1696e347-eea6-41ea-922b-6548a4727a29,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-d3f9c890-cdfa-4d68-ab97-ef6098906216,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5711
